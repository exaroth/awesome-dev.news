<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Tech</title><link>https://www.awesome-dev.news</link><description></description><item><title>Flawed Diamonds Are a Quantum Sensor’s Best Friend</title><link>https://spectrum.ieee.org/quantum-sensors-2671182149</link><author>Dina Genkina</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjU2MjQ4MC9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTgwMTk5NzcyN30.loo801SNgzyVATCIIVnex4SB2jlSslJIGlThemv8LaQ/image.png?width=600" length="" type=""/><pubDate>Sun, 23 Feb 2025 13:00:04 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[Tiny faults could find big applications for chips, art history, and more]]></content:encoded></item><item><title>Unexpected Shape of Lead-208 Nucleus of May Force Scientists to Reevaluate Atomic Nuclei Models</title><link>https://science.slashdot.org/story/25/02/23/0051225/unexpected-shape-of-lead-208-nucleus-of-may-force-scientists-to-reevaluate-atomic-nuclei-models?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 23 Feb 2025 12:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA["An international research collaboration led by the University of Surrey's Nuclear Physics Group has overturned the long-standing belief that the atomic nucleus of lead-208 is perfectly spherical," reports Phys.org. 

They add that the discovery "challenges fundamental assumptions about nuclear structure and has far-reaching implications for our understanding of how the heaviest elements are formed in the universe..."


[A] new study published in Physical Review Letters used a high-precision experimental probe to examine its shape and found that rather than being perfectly spherical, the nucleus of lead-208 is slightly elongated, resembling a rugby ball (prolate spheroid)... Using the state-of-the-art GRETINA gamma-ray spectrometer at Argonne National Laboratory in Illinois, U.S., scientists bombarded lead atoms with high-speed particle beams accelerated to 10% of the speed of light — equivalent to circling the Earth every second. The interactions created unique gamma-ray fingerprints of the properties of excited quantum states in lead-208 nuclei — in other words, the nuclei were energized — which, in turn, were used to determine its shape. 


Theoretical physicists, including those at the Surrey Nuclear Theory Group, are now re-examining the models used to describe atomic nuclei, as the experiments suggest that nuclear structure is far more complex than previously thought.
]]></content:encoded></item><item><title>AMD Preparing New GPU Support For Their Kernel Graphics Driver In Linux 6.15</title><link>https://www.phoronix.com/news/AMDGPU-Linux-6.15</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 23 Feb 2025 11:51:11 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[AMD has sent out their initial pull request of "new stuff" for their AMDGPU kernel graphics driver and AMDKFD compute driver of feature additions they want to make for the upcoming Linux 6.15 kernel. Most notable from this week's submission to DRM-Next is preparing a lot of new GPU hardware support...]]></content:encoded></item><item><title>OneXPlayer Linux Driver Catching Up To The Windows Monitoring Driver</title><link>https://www.phoronix.com/news/OneXPlayer-Linux-Driver-2025</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 23 Feb 2025 11:36:57 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[OneXPlayer produces a line of handheld gaming consoles powered by AMD or Intel SoCs. These devices ship with Windows out-of-the-box but  given they are x86_64 software have worked alright with Linux and there's been a OneXPlayer Linux driver for supporting sensor readings and other device-specific information from these handhelds. In a big patch series this weekend, that OneXPlayer Linux driver is catching up to its official Windows counterpart...]]></content:encoded></item><item><title>SVT-AV1 3.0 Released With Faster CPU-Based AV1 Encoding</title><link>https://www.phoronix.com/news/SVT-AV1-3.0-Released</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 23 Feb 2025 09:00:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[SVT-AV1 as the open-source, CPU-based AV1 encoder that was started by Intel software engineers and now led by the Alliance for Open Media is out this week with the big SVT-AV1 3.0 release. Here's some details on SVT-AV1 3.0 as well as some initial performance benchmarks for this speedy AV1 encoder, especially on modern Intel and AMD processors...]]></content:encoded></item><item><title>Amazon Is Killing the Ability to Download eBooks to Your Computer</title><link>https://news.slashdot.org/story/25/02/23/0529220/amazon-is-killing-the-ability-to-download-ebooks-to-your-computer?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 23 Feb 2025 08:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA["Amazon has long allowed you to download its ebooks to your computer," notes PCMag.com, "where they can serve as a backup or be transferred to other devices. 
"However, that feature will end on February 26, 2025, along with the ability to transfer books from your computer to your Kindle via USB."
If you attempt to download your ebooks right now, a message says: "Starting February 26, 2025, the 'Download & Transfer via USB' option will no longer be available. You can still send Kindle books to your Wi-Fi-enabled devices by selecting the 'Deliver or Remove from Device' option." After February 26, you will still be able to download Kindle books [onto your Kindle] from the Kindle Store via Wi-Fi, and you can also use the Send to Kindle page on Amazon to send a variety of files to your Kindle. 

Should you want to transfer your titles from your Kindle to your computer while you still can, go to Amazon.com, sign in, and click Accounts & Lists > Content Library > Books. Navigate to the book you want to download and click More actions > Download & transfer via USB.
 

Tom's Guide shares their reaction:

Most people probably won't notice this latest example of an Amazon service getting worse, but the feature has existed for over a decade and is useful for backing up your purchases or converting them to formats compatible with other non-Kindle e-Readers or devices. It's also useful for those times when you don't have access to Wi-Fi, and of course, there's peace of mind knowing you have copies of your books... All in all it is a reminder that you don't actually own many or most of your digital purchases, as what you are typically actually "buying" are licenses to use content that can be revoked at any time. 

If you find this decision annoying and want to find alternatives, here are a few. To start, might we recommend the Libby app which lets you borrow ebooks from your local library. You can also borrow audiobooks... You can also try purchasing books from places like Google Books and Apple Books, both of which offer a number of ebooks. eBooks.com offers DRM free books and EPUB formats. For those looking for free ebooks there is always Project Gutenberg which has over 75,000 free books largely those in the public domain though there are some more recent titles as well.
]]></content:encoded></item><item><title>Mesa&apos;s Venus Now Exposes Vulkan 1.4 Support</title><link>https://www.phoronix.com/news/Mesa-Venus-Vulkan-1.4</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 23 Feb 2025 08:00:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[The Mesa Venus driver code for use with VirtIO-GPU for exposing accelerated Vulkan API support within virtualized environments (VMs) now is advertising Vulkan 1.4 API support...]]></content:encoded></item><item><title>The TechBeat: The Stupidest Requests on the Dark Web Come from Regular People (2/23/2025)</title><link>https://hackernoon.com/2-23-2025-techbeat?source=rss</link><author>Techbeat</author><category>tech</category><pubDate>Sun, 23 Feb 2025 07:10:51 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[By @rootstock_io [ 3 Min read ] 
 Rootstock merges Bitcoin’s security with Ethereum’s flexibility, enabling AI-driven blockchain apps for trustless governance, security, and fraud detection. Read More.By @stellar [ 5 Min read ] 
 Regulatory shifts in 2025 will shape crypto wallets. Learn how compliance, DeFi, and Stellar’s Soroban ecosystem will impact the future of Web3 wallets. Read More.By @buzzpy [ 7 Min read ] 
 This article is dedicated to any developer who wants to try something new or exciting (which is game development, yes). Read More.By @noda [ 4 Min read ] 
 2025 is the tipping point for pay-by-bank. Lower fees, instant payments, and new regulations make it the future of digital transactions.  Read More.By @mexcmedia [ 7 Min read ] 
 Altcoin season sees altcoins outperform Bitcoin, offering lucrative opportunities. Learn key signs, strategies, & how to benefit from MEXC’s diverse offerings. Read More.By @2077research [ 11 Min read ] 
 Explore how multidimensional EIP-1559 updates Ethereum's gas efficiency by separating resource costs, enhancing scalability, and improving network utilization. Read More.By @blackheart [ 1 Min read ] 
 As someone who’s spent time digging through dark web marketplaces, forums, and Telegram groups, I’ve seen it all. Here’s what no one tells you. Read More.By @mexcmedia [ 6 Min read ] 
 Liquidity is key to crypto trading, ensuring price stability, seamless transactions, and reduced slippage. Learn how MEXC excels in liquidity management. Read More.By @hayday [ 4 Min read ] 
 Is the rise of vibe coding also the end of software engineering? How will vibeware change the nature of the software entrepreneur, and the meaning of work? Read More.By @2077research [ 11 Min read ] 
 Explore the evolution of crypto options and perpetual futures, diving into innovations like panoptions, liquidity challenges, and decentralized trading. Read More.By @mexcmedia [ 5 Min read ] 
 Discover key crypto trends of 2025, from Bitcoin’s surge to MEXC’s role in shaping the future of digital asset trading with liquidity, security, & innovation. Read More.By @proflead [ 5 Min read ] 
 In this guide, I will walk you through a method using GitHub and Git that allows you to keep your notes in sync without spending a dime. Read More.By @alexandersimonov [ 6 Min read ] 
 AI and cats can be random. Learn why AI isn’t always deterministic, how stochastic processes shape its decisions, and why it self-corrects and hallucinates. Read More.By @linearization [ 6 Min read ] 
 This study evaluates 44 DPFL methods, comparing accuracy, efficiency, and generalizability in power system computations. Read More.By @oleksiijko [ 13 Min read ] 
 The project is built on the principle of microservice architecture, which allows you to divide functionality into independent services.  Read More.By @antonvoichenkovokrug [ 4 Min read ] 
 While the whole world watches with interest as ChatGPT and OpenAI progress toward creating AGI, Nirvanic has announced  an even more ambitious goal. Read More.By @ekaterinaandreeva [ 15 Min read ] 
 How to level up your IT career? A step-by-step guide, proven career tracks, and practical checklists for confident growth – read the full article Read More.By @dataengonline [ 6 Min read ] 
 Firms increasingly make use of artificial intelligence (AI) infrastructures to host and manage autonomous workloads. Read More.]]></content:encoded></item><item><title>Lithium Batteries Reignited Tuesday at the Moss Landing Power Plant Fire Site</title><link>https://hardware.slashdot.org/story/25/02/23/039220/lithium-batteries-reignited-tuesday-at-the-moss-landing-power-plant-fire-site?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 23 Feb 2025 05:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Remember that battery plant fire last month in Moss Landing, California? Tuesday night local firefighters "determined that a group of lithium batteries in an area that had previously burned during the January 16 fire had smoldered and reignited," reports SFGate. 

 Fire Chief Joel Mendoza said the flames burned at varying intensities throughout Tuesday night before the fire burned itself out at about 8 a.m. on Wednesday.

Additional flare-ups at the site are expected due to weather exposure and damage to the remaining batteries. "Rekindling is very, very likely — almost a certainty," said EPA onsite coordinator Eric Sandusky, adding that rain and humidity can interact with the damaged batteries, leading to short circuits and reignition. To further reduce fire risk, Sandusky said the EPA is working with Vistra to begin "de-linking the batteries," a process that disconnects them to lower the risk of propagation and prevent a large-scale fire... 

"Vistra said that since the January 16 fire, they have brought in a private fire crew that is on-site at all times to monitor the Moss 300 building," according to a local news site. 

 Fire Chief Joel Mendoza shared more details with the digital newspaper Lookout Santa Cruz. "We've been saying all along that batteries exposed to heat that didn't burn can ignite. We were hoping that it wouldn't happen, but it did."]]></content:encoded></item><item><title>AI May Not Impact Tech-Sector Employment, Projects US Department of Labor</title><link>https://it.slashdot.org/story/25/02/23/0034221/ai-may-not-impact-tech-sector-employment-projects-us-department-of-labor?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 23 Feb 2025 02:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[America's Labor Department includes the fact-finding Bureau of Labor Statistics — and they recently explained how AI impacts their projections for the next 10 years. Their conclusion, writes Investopedia, was that "tech workers might not have as much to worry about as one might think."

Employment in the professional, scientific, and technical services sector is forecast to increase by 10.5% from 2023 to 2033, more than double the national average. According to the BLS, the impact AI will have on tech-sector employment is highly uncertain. For one, AI is adept at coding and related tasks. But at the same time, as digital systems become more advanced and essential to day-to-day life, more software developers, data managers, and the like are going to be needed to manage those systems. "Although it is always possible that AI-induced productivity improvements will outweigh continued labor demand, there is no clear evidence to support this conjecture," according to BLS researchers. 
Their employment projections through 2033 predict the fastest-growing sector within the tech industry will be computer system design, while the fastest-growing occupation will be data scientist. 

And they also project that from 2023 through 2033 AI will "primarily affect occupations whose core tasks can be most easily replicated by GenAI in its current form." So over those 10 years they project a 4.7% drop in employment of medical transcriptionists and a 5.0% drop in employment of customer service representatives.


Other occupations also may see AI impacts, although not to the same extent. For instance, computer occupations may see productivity impacts from AI, but the need to implement and maintain AI infrastructure could in actuality boost demand for some occupations in this group.
 

They also project decreasing employment for paralegals, but with actual lawyers being "less affected."]]></content:encoded></item><item><title>Wine Staging 10.2 Adds Support For AF_UNIX Sockets</title><link>https://www.phoronix.com/news/Wine-Staging-10.2</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 23 Feb 2025 01:18:52 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Following Friday's release of Wine 10.2, Wine Staging 10.2 is out for testing as this more experimental/leading-edge version of Wine that is shipping with 300+ extra patches for testing...]]></content:encoded></item><item><title>Will Consumer Data Collection Lead to Algorithm-Adjusted &apos;Surveillance Pricing&apos;?</title><link>https://yro.slashdot.org/story/25/02/22/230253/will-consumer-data-collection-lead-to-algorithm-adjusted-surveillance-pricing?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 23:03:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[An anonymous reader shared this report from the Washington Post's "Tech Brief":


Last fall, reports that Kroger was considering bringing facial recognition technology into its stores sparked outcry from lawmakers and customers. They worried personalized data could be used to charge different prices for different customers based on their shopping habits, financial circumstances or appearance. Kroger, the country's largest supermarket chain, had already been using digital price tags in its stores. 

Kroger told lawmakers that it doesn't use facial recognition to help it set prices, a stance the company reiterated to the Tech Brief on Thursday. Still, the uproar helped to spark a push by consumer advocates who warn that the threat of invasive, personalized pricing schemes is real. Now, Democratic lawmakers in several states are working to ban so-called "surveillance pricing" — when businesses charge customers more or less for the same item based on their personal information. 

Besides a bill in California, three more bill were introduced this month in Colorado, Georgia, and Illinois that also ban "surveillance wages," which the article defines as employers adjusting wages based on how much data an employee collects. "Both surveillance pricing and surveillance wages really disrupt fundamental ideals of fairness," University of California, Irvine law professor Veena Dubal tells the Washington Post. 

Dubal is one of the consumer advocates behind a new report which notes information released last month by America's consumer-protecting FTC that "suggests that surveillance pricing tools are being actively developed and marketed across a range of industries, including consumer-facing businesses like 'grocery stores, apparel retailers, health and beauty retailers, home goods and furnishing stores, convenience stores, building and hardware stores, and general merchandise retailers such as department or discount stores." The consumer advocates (which include the Electronic Privacy Information Center) put it this way. 
"Imagine walking into a grocery store and seeing a price for milk that's higher than what the next shopper pays because an algorithm calculated that you're willing to spend more..."]]></content:encoded></item><item><title>Did xAI lie about Grok 3’s benchmarks?</title><link>https://techcrunch.com/2025/02/22/did-xai-lie-about-grok-3s-benchmarks/</link><author>Kyle Wiggers</author><category>tech</category><pubDate>Sat, 22 Feb 2025 22:55:14 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Debates over AI benchmarks — and how they’re reported by AI labs — are spilling out into public view. This week, an OpenAI employee accused Elon Musk’s AI company, xAI, of publishing misleading benchmark results for its latest AI model, Grok 3. One of the co-founders of xAI, Igor Babushkin, insisted that the company was […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>New EV Batteries are Making Electric Cars Cheaper and Safer</title><link>https://hardware.slashdot.org/story/25/02/22/1840228/new-ev-batteries-are-making-electric-cars-cheaper-and-safer?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 22:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[The Washington Post looks at a new kind of battery that "could make American EVs cheaper and safer, experts say."

If you bought an EV with a lithium iron phosphate (LFP) battery, you could expect lower car payments, less fire risk and more years of use out of your car — but you wouldn't be able to go as far on a single charge as you could with the nickel manganese cobalt (NMC) batteries commonly found in American and European electric cars. That trade-off has made LFP batteries the go-to choice for standard-range EVs in China, helping to make electric cars more affordable and limit pollution. Now, American companies are starting to build their own LFP batteries to catch up to their Chinese rivals... But there are plenty of barriers for U.S. companies that want to adopt a technology dominated by Chinese firms. Tariffs and tax credit restrictions have made it too expensive for most American automakers to import LFP batteries from China, and national security concerns have made it hard for American companies to partner with Chinese battery makers to build factories in the United States... 


Although American scientists invented LFP batteries in 1997, U.S. automakers didn't invest in the technology. Instead, they bet on NMC batteries because they have longer range, a big concern for American EV buyers. "Everyone in the West thought LFP was a nonstarter five or six years ago," said Adrian Yao, who founded STEER, a technology research group within Stanford University. "We really did have a myopic focus on" range, he added. That left the door open for Chinese companies to perfect LFP batteries, which have a few advantages. Instead of pricey nickel and cobalt, they use iron, which makes them 20 percent cheaper than NMC batteries, according to the International Energy Agency. While NMC batteries can be recharged up to about 1,000 times before they go kaput — which is enough to put 200,000 miles on most EVs — LFP batteries can last two or three times as long, according to Moura. Plus, LFP batteries' chemistry makes them less likely to catch fire and easier to extinguish. An NMC battery, on the other hand, is so flammable that "you could put it underwater or in space, and it'll keep burning because the oxygen it needs to keep the flame going is embedded within itself," Moura said. 

That safety advantage is key, because Chinese firms figured out they could pack LFP cells closer together inside a battery pack without risking a fire. That meant they could cram more energy into LFP batteries and nearly catch up to the range of NMC batteries. Last year, the Chinese battery giant CATL made the first LFP battery with more than 600 miles of range. Since LFP batteries are made from common materials and last longer, they also have a smaller environmental footprint than NMC batteries. 
Ford used LFP batteries in its Mach-E sedan (2023) and F-150 Lightning pickup trucks (2024), according to the article, "while Rivian began using them in the basic trims of its R1S SUV and R1T pickup truck this year... American LFP factories are slated to open this year in St. Louis and next year in Arizona."
And an environmental engineering professor at the University of California at Berkeley predicts LFP battery factories in the U.S. will "grow quite rapidly over the next five to 10 years."]]></content:encoded></item><item><title>This Week In Techdirt History: February 16th – 22nd</title><link>https://www.techdirt.com/2025/02/22/this-week-in-techdirt-history-february-16th-22nd/</link><author>Leigh Beadon</author><category>tech</category><pubDate>Sat, 22 Feb 2025 21:45:00 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Rust Developer Survey Finds Increasing Usage, Especially on Linux</title><link>https://developers.slashdot.org/story/25/02/22/042227/rust-developer-survey-finds-increasing-usage-especially-on-linux?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 21:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[This year's "State of Rust" survey was completed by 7,310 Rust developers. DevClass note some key findings:

When asked about their biggest worries for Rust's future, 45.5 percent cited "not enough usage in the tech industry," up from 42.5 percent last year, just ahead of the 45.2 percent who cited complexity as a concern... Only 18.6 percent declared themselves "not worried," though this is a slight improvement on 17.8 percent in 2023... 
Another question asks whether respondents are using Rust at work. 38.2 percent claimed to use it for most of their coding [up from 34% in 2023], and 13.4 percent a few times a week, accounting for just over half of responses. At the organization level there is a similar pattern. 45.5 percent of organizations represented by respondents make "non-trivial use of Rust," up from 38.7 percent last year. 

More details from I Programmer:

On the up are "Using Rust helps us achieve or goals", now 82% compared to 72% in 2022; "We're likely to use Rust again in the future", up 3% to 78%; and "Using Rust has been worth the cost of Adoption". Going down are "Adopting Rust has been challenging", now 34.5% compared to 38.5% in 2022; and "Overall adopting Rust has slowed down our team" down by over 2% to 7%. 



"According to the survey, organizations primarily choose Rust for building correct and bug-free software (87.1%), performance characteristics (84.5%), security and safety properties (74.8%), and development enjoyment (71.2%)," writes The New Stack:

 Rust seems to be especially popular for creating server backends (53.4%), web and networking services, cloud technologies and WebAssembly, the report said. It also seems to be gaining more traction for embedded use cases... Regarding the preferred development environment, Linux remains the dominant development platform (73.7%). 

However, although VS Code remains the leading editor, its usage dropped five percentage points, from 61.7% to 56.7%, but the Zed editor gained notable traction, from 0.7% to 8.9%. Also, "nine out of 10 Rust developers use the current stable version, suggesting strong confidence in the language's stability," the report said... 

Overall, 82% of respondents report that Rust helped their company achieve its goals, and daily Rust usage increased to 53% (up four percentage points from 2023). When asked why they use Rust at work, 47% of respondents cited a need for precise control over their software, which is up from 37% when the question was asked two years ago.]]></content:encoded></item><item><title>US AI Safety Institute could face big cuts</title><link>https://techcrunch.com/2025/02/22/us-ai-safety-institute-could-face-big-cuts/</link><author>Anthony Ha</author><category>tech</category><pubDate>Sat, 22 Feb 2025 21:22:36 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[The National Institute of Standards and Technology could fire as many as 500 staffers, according to multiple reports — cuts that further threaten a fledgling AI safety organization. Axios reported this week that the US AI Safety Institute (AISI) and Chips for America, both part of NIST, would be “gutted” by layoffs targeting probationary employees […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>How I Podcast: Summer Album / Winter Album’s Jody Avirgan</title><link>https://techcrunch.com/2025/02/22/how-i-podcast-summer-album-winter-albums-jody-avirgan/</link><author>Brian Heater</author><category>tech</category><pubDate>Sat, 22 Feb 2025 20:41:53 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[The beauty of podcasting is that anyone can do it. It’s a rare medium that’s nearly as easy to make as it is to consume. And as such, no two people do it exactly the same way. There are a wealth of hardware and software solutions open to potential podcasters, so setups run the gamut […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Glitches for Windows 11 Update Include Breaking File Explorer</title><link>https://tech.slashdot.org/story/25/02/22/183257/glitches-for-windows-11-update-include-breaking-file-explorer?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 20:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Five days ago on Patch Tuesday, Microsoft released patch KB5051987 for Windows 11 version 24H2, writes the XDA Developers site. 

But "As reported by Windows Latest and various communities like Reddit and Microsoft's help forum, many users have encountered a major issue..." 
Some have reported that, in addition to File Explorer failing to launch, they're unable to open folders from the desktop, save Office files, or even download files. Clicking on a folder icon may display its subfolders, but the contents within remain inaccessible... Some users on Microsoft's help forum and Reddit have also reported that the KB5051987 patch fails to install entirely. The update gets stuck at a certain percentage for hours before eventually displaying an error code. While these are among the most widely reported issues, others have surfaced as well, including problems with Taskbar preview animations, the camera, and more. 

"Microsoft keeps running into brick walls with the 2024 version of Windows 11," writes ZDNet. "Each new update designed to fix the outstanding bugs ends up introducing other problems..."
Among the glitches resolved were ones that affected digital audio converters, USB audio drivers, USB cameras, and passkeys. The update also patched several security vulnerabilities, including some that were deemed critical.... 

Other glitches that may pop up include a stuttering mouse, an undetectable camera, .NET apps that cannot be installed inside the Windows Sandbox, and the Taskbar's new preview animation that does not work properly. You may also encounter other roadblocks. One person in the Windows Feedback Hub said that after installing the update, the battery life shows only 2.5 hours versus 6 hours previously. Another person found that the clipboard history no longer copies items from Microsoft Word... 
Each annual Windows update can suffer from bugs, especially after being rolled out to millions of users. However, Windows 11 24H2 has been more problematic than usual. Since its official launch last October, the 2024 version has carried with it a host of known issues, many of which still haven't been resolved.
]]></content:encoded></item><item><title>The pain of discontinued items, and the thrill of finding them online</title><link>https://techcrunch.com/2025/02/22/the-pain-of-discontinued-items-and-the-thrill-of-finding-them-online/</link><author>Connie Loizos</author><category>tech</category><pubDate>Sat, 22 Feb 2025 20:02:49 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[We’ve all been there. A favorite item is suddenly unavailable for purchase. Couldn’t the manufacturer have given you advance warning? Whether owing to low sales, changing habits, production costs, or even because something is a little wrong with your favorite product (shh), discontinued items are part of life. In a weekend piece, the New York […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>California Sues Data-Harvesting Company NPD, Enforcing Strict Privacy Law</title><link>https://yro.slashdot.org/story/25/02/22/1512258/california-sues-data-harvesting-company-npd-enforcing-strict-privacy-law?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 19:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[California sued to fine a data-harvesting company, reports the Washington Post, calling it "a rare step to put muscle behind one of the strongest online privacy laws in the United States."

Even when states have tried to restrict data brokers, it has been tough to make those laws stick. That has generally been a problem for the 19 states that have passed broad laws to protect personal information, said Matt Schwartz, a policy analyst for Consumer Reports. He said there has been only 15 or so public enforcement actions by regulators overseeing all those laws. Partly because companies aren't held accountable, they're empowered to ignore the privacy standards. "Noncompliance is fairly widespread," Schwartz said. "It's a major problem." 

 That's why California is unusual with a data broker law that seems to have teeth. To make sure state residents can order all data brokers operating in the state to delete their personal records [with a single request], California is now requiring brokers to register with the state or face a fine of $200 a day. The state's privacy watchdog said Thursday that it filed litigation to force one data broker, National Public Data, to pay $46,000 for failing to comply with that initial phase of the data broker law. NPD declined to comment through an attorney... This first lawsuit for noncompliance, Schwartz said, shows that California is serious about making companies live up to their privacy obligations... "If they can successfully build it and show it works, it will create a blueprint for other states interested in this idea," he said. 
Last summer NPD "spilled hundreds of millions of Americans' Social Security Numbers, addresses, and phone numbers online," according to the blog Krebs on Security, adding that another NPD data broker sharing access to the same consumer records "inadvertently published the passwords to its back-end database in a file that was freely available from its homepage..." 
California's attempt to regulate the industry inspired the nonprofit Consumer Reports to create an app called Permission Slip that reveals what data companies collect and, for people in U.S. states, will "work with you to file a request, telling companies to stop selling your personal information." 

Other data-protecting options suggested by The Washington Post:
 Use Firefox, Brave or DuckDuckGo, "which can automatically tell websites not to sell or share your data. Those demands from the web browsers are legally binding or will be soon in at least nine states."
Use Privacy Badger, an EFF browser extension which the EFF says "automatically tells websites not to sell or share your data including where it's required by state law."]]></content:encoded></item><item><title>ArcaOS (OS/2 Warp OEM) 5.1.1 Has Been Released</title><link>https://tech.slashdot.org/story/25/02/22/0748224/arcaos-os2-warp-oem-511-has-been-released?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 18:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA["IBM stopped supporting OS/2 at the end of 2006," write the makers of ArcaOS, an OEM distribution of OS/2's discontinued Warp operating system. 

And now long-time Slashdot reader martiniturbide tells us that ArcaOS 5.1.1 has been released, and that many of it's components have been updated too. From this week's announcement:

ArcaOS 5.1.1 continues to support installation on the latest generation of UEFI-based systems, as well as the ability to install to GPT-based disk layouts. This enables ArcaOS 5.1.1 to install on a wide array of modern hardware. Of course, ArcaOS 5.1.1 is just as much at home on traditional BIOS-based systems, offering enhanced stability and performance across both environments.... 
Need more convincing? How about a commercial operating system which doesn't spy on you, does not report your online activity to anyone, and gives you complete freedom to choose the applications you want to use, however you want to use them? How about an operating system which isn't tied to any specific hardware manufacturer, allowing you to choose the platform which is right for you, and fits perfectly well in systems with less than 4GB of memory or even virtual machines?
]]></content:encoded></item><item><title>The fallout from HP’s Humane acquisition</title><link>https://techcrunch.com/2025/02/22/the-fallout-of-hps-humane-acquisition/</link><author>Cody Corrall</author><category>tech</category><pubDate>Sat, 22 Feb 2025 18:05:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Welcome back to Week in Review. This week we’re looking at the internal chaos surrounding HP’s $116 million acquisition of AI Pin maker Humane; Mira Murati’s new AI venture coming out of stealth; Duolingo killing its iconic owl mascot with a Cybertruck; and more! Let’s get into it. Humane’s AI pin is dead. The hardware […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Microsoft Makes More Of Their DirectX Compiler Code Open-Source</title><link>https://www.phoronix.com/news/DirectXShaderCompiler-2025</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 17:37:52 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Back in 2017 was the initial open-source DirectX Shader Compiler milestone and since then Microsoft has continued iterating on it with better Linux support, new features, and ironing out other gaps in this "DirectXShaderCompiler" project. On Friday they released the newest version of this DirectX Shader Compiler that features another newly open-sourced component...]]></content:encoded></item><item><title>Encrypted Messages Are Being Targeted, Google Security Group Warns</title><link>https://it.slashdot.org/story/25/02/22/0724228/encrypted-messages-are-being-targeted-google-security-group-warns?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 17:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Google's Threat Intelligence Group notes "the growing threat to secure messaging applications." While specifically acknowledging "wide ranging efforts to compromise Signal accounts," they add that the threat "also extends to other popular messaging applications such as WhatsApp and Telegram, which are also being actively targeted by Russian-aligned threat groups using similar techniques. 

"In anticipation of a wider adoption of similar tradecraft by other threat actors, we are issuing a public warning regarding the tactics and methods used to date to help build public awareness and help communities better safeguard themselves from similar threats." 

Computer Weekly reports:

Analysts predict it is only a matter of time before Russia starts deploying hacking techniques against non-military Signal users and users of other encrypted messaging services, including WhatsApp and Telegram. Dan Black, principal analyst at Google Threat Intelligence Group, said he would be "absolutely shocked" if he did not see attacks against Signal expand beyond the war in Ukraine and to other encrypted messaging platforms... 

Russia-backed hackers are attempting to compromise Signal's "linked devices" capability, which allows Signal users to link their messaging account to multiple devices, including phones and laptops, using a quick response (QR) code. Google threat analysts report that Russia-linked threat actors have developed malicious QR codes that, when scanned, will give the threat actor real-time access to the victim's messages without having to compromise the victim's phone or computer. In one case, according to Black, a compromised Signal account led Russia to launch an artillery strike against a Ukrainian army brigade, resulting in a number of casualties... Google also warned that multiple threat actors have been observed using exploits to steal Signal database files from compromised Android and Windows devices. 

The article notes that the attacks "are difficult to detect and when successful there is a high risk that compromised Signal accounts can go unnoticed for a long time." And it adds that "The warning follows disclosures that Russian intelligence created a spoof website for the Davos World Economic Forum in January 2025 to surreptitiously attempt to gain access to WhatsApp accounts used by Ukrainian government officials, diplomats and a former investigative journalist at Bellingcat." 

Google's Threat Intelligence Group notes there's a variety of attack methods, though the "linked devices" technique is the most widely used. "We are grateful to the team at Signal for their close partnership in investigating this activity," Google's group says in their blog post, adding that "the latest Signal releases on Android and iOS contain hardened features designed to help protect against similar phishing campaigns in the future. Update to the latest version to enable these features."]]></content:encoded></item><item><title>Trump administration reportedly shutting down federal EV chargers nationwide</title><link>https://techcrunch.com/2025/02/22/trump-administration-reportedly-shutting-down-federal-ev-chargers-nationwide/</link><author>Anthony Ha</author><category>tech</category><pubDate>Sat, 22 Feb 2025 16:55:41 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[The General Services Administration, the agency that manages buildings owned by the federal government, is planning to shut down its entire network of electric vehicle chargers, according to a report in The Verge. The GSA reportedly operates a network of hundreds of EV chargers with a total of 8,000 plugs that can be used to […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>James Bond&apos;s Next Assignment: Amazon Pays $1 Billion for Full Creative Control</title><link>https://entertainment.slashdot.org/story/25/02/22/0638211/james-bonds-next-assignment-amazon-pays-1-billion-for-full-creative-control?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 16:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[ Deadline reports:
It's taking around $1 billion to have 007 stewards Barbara Broccoli and Michael G. Wilson cede creative oversight of their family's storied James Bond franchise to Amazon MGM Studios, sources tell us. Amazon originally overpaid on its purchase of MGM in a deal orchestrated by then-MGM board chair Kevin Ulrich. Though valued between $3.5 billion-$4 billion, the legendary motion picture studio was absorbed by the streamer for $8.5 billion, the hefty sum propped up by the potential access of the 007 franchise. However, Amazon couldn't fully freely develop Bond with Broccoli and Wilson in the mix. Hence, it took another $1 billion to ensure that they could fully steer and exploit the Ian Fleming IP. 
The article suggests Broccoli's long hold-out came from "Amazon's desire to expand the James Bond franchise into its own universe akin to Marvel or Star Wars."
In the past, filmmakers including Quentin Tarantino and Christopher Nolan have expressed an interest in putting their stamp on Bond; both however, required complete creative control, which wasn't possible under the reign of Broccoli and Wilson. Now, with the producers on the side, Amazon can move forward to attract a top-tier director. 

Also available to come to life in the new deal finally are a slew of Bond villains and women in their own series or features. The last time an attempt was made to spin off the Bond franchise was in 2003 with a stand-alone movie about the spy's girlfriend Jinx, played by Halle Berry in Die Another Day. Bond scribes Neal Purvis and Rob Wade were attached to pen that, with Stephen Frears circling, but Broccoli and Wilson put the kibosh to the idea due to creative differences. 
In a related note, the article adds that Amazon "is looking to have an international theatrical distribution arm fully operational by some time in 2026." 

Jeff Bezos asked his followers on X.com who should play James Bond in the next movie, reports IGN, "and the answer was loud and clear." On X.com the "clear fan favorite" was DC Extended Universe actor Henry Cavill. (Besides playing Superman, Cavill also appeared in the 2024 film spy action-comedy Argyle, and fought Tom Cruise's character in 2018's Mission Impossible: Fallout — and played Geralt of Rivia in the Netflix series The Witcher.)]]></content:encoded></item><item><title>The HackerNoon Newsletter: The Secret Hidden Power of Questions (2/22/2025)</title><link>https://hackernoon.com/2-22-2025-newsletter?source=rss</link><author>Noonification</author><category>tech</category><pubDate>Sat, 22 Feb 2025 16:05:04 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[🪐 What’s happening in tech today, February 22, 2025?By @scottdclary [ 8 Min read ] Most people are running on default questions they never chose to install. Read More.By @textmodels [ 4 Min read ] A smarter way to allocate computing resources in AI transformers is making them faster and more efficient. Read More.By @luminousmen [ 3 Min read ] Discover different archetypes of data engineers and how their collaboration drives data-driven success. Read More.🧑‍💻 What happened in your world this week?We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, 
 The HackerNoon Team ✌️]]></content:encoded></item><item><title>O.XYZ Launches OCEAN – Cerebras-Powered AI Engine, 10x Faster Than ChatGPT</title><link>https://hackernoon.com/oxyz-launches-ocean-cerebras-powered-ai-engine-10x-faster-than-chatgpt?source=rss</link><author>o.xyz</author><category>tech</category><pubDate>Sat, 22 Feb 2025 16:00:12 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[\
O.XYZ is thrilled to announce the official launch of , a next-generation decentralized AI assistant powered by the industry-leading Cerebras CS-3 wafer-scale chips. On February 22, the company unveiled this new platform, touting speeds ten times faster than ChatGPT and positioning OCEAN as a truly transformative solution in both B2C and B2B markets. From blazing response times to a broad feature set that includes voice interaction and a commitment to decentralization, OCEAN represents a major leap forward in how users worldwide can engage with AI.\
OCEAN’s speed and real-time response capabilities are central to its unique value. Ahmad Shadid, Founder of O and IO, explains that one of the reasons for such swift performance is the adoption of Cerebras’s cutting-edge hardware.\
"The Cerebras CS-3 chip, known as the Wafer Scale Engine (WSE-3), has 900,000 AI-optimized cores and four trillion transistors on a single chip. Traditional GPU-based systems often require complex orchestration and distributed programming to handle large models, but the Cerebras approach offers simplicity and scalability." – claims Shadid.\
Cerebras can scale from one billion to 24 trillion parameters without requiring code changes, freeing users from the delays commonly associated with AI assistants. With 21 PB/s of memory bandwidth, Cerebras-based processing provides low-latency, high-efficiency performance that far surpasses traditional GPU systems.\
While speed and performance are crucial, OCEAN brings more than just high-octane AI. Shadid refers to OCEAN as “the world’s fastest AI search engine,” emphasizing that beyond raw computational power, the platform delivers a sleek, intuitive user experience. This includes a voice interaction system that will allow users to speak their prompts directly to “Miss O,” who can respond in audio format. This conversational style, along with advanced AI agent capabilities slated for future versions, puts OCEAN on a path that goes beyond just answering text-based queries.\
From a product standpoint, OCEAN adopts a dual approach, serving both individual consumers and enterprises. For users who simply want a next-level AI-powered search engine, the app offers quick responses, privacy-focused features, and a decentralized framework to ensure data security. For business clients, OCEAN plans to roll out an API service powered by the very same Cerebras infrastructure that underpins its consumer operations.\
The O community has gained exclusive access to the closed testnet of the OCEAN Assistant, and initial tests  it may run up to 20 times faster than popular AI services like ChatGPT and DeepSeek. X is already flooded with dozens of comparison videos demonstrating the remarkable speed difference, prompting widespread excitement and curiosity about the assistant’s capabilities.\
In the next five years, O.XYZ envisions OCEAN becoming a fully integrated platform with advanced routing intelligence. The proprietary “O Routing Intelligence” (ORI), developed by O.RESEARCH, will dynamically route subtasks to the most suitable model, whether it is an open-source option or a specialized AI for more complex requirements. ORI will help optimize costs without compromising speed or accuracy. This first-of-its-kind technology lays the groundwork for building a massive AI library featuring hundreds of thousands of models. Over time, this expansion is expected to bring OCEAN closer to artificial general intelligence (AGI), while still emphasizing security and user data ownership. With ORI, the team presents a unified intelligence technology similar to the one that OpenAI  this February. ORI will select from over 100,000 open-source models, routing tasks to the best one in real time. ORI will be integrated into OCEAN in spring 2025.\
ORI will be the central hub for AI innovation, seamlessly integrating multiple AI models into a unified intelligence. Through its integration with OCEAN, users will effortlessly harness the power of diverse AI models in one place. aims to reshape artificial intelligence by developing systems independent of corporate control. It focuses on making AI technology accessible, transparent, and community-driven, ensuring superintelligence serves humanity's interests.\
O.XYZ's technical foundation centers on building an AI ecosystem designed to be shutdown-resistant and self-led. Their key initiatives include developing 'Sovereign Super Intelligence,' creating decentralized infrastructure, and researching hyper-fast AI systems.\
The project operates under the O.Systems Foundation, led by Ahmad Shadid. Shadid, who previously founded IO.NET– a $4.5B Solana DePIN – brings his experience to O.XYZ's work on building an autonomous, community-led AI ecosystem.]]></content:encoded></item><item><title>The Secret Hidden Power of Questions</title><link>https://hackernoon.com/the-secret-hidden-power-of-questions?source=rss</link><author>Scott D. Clary</author><category>tech</category><pubDate>Sat, 22 Feb 2025 16:00:03 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[We all think we're good at asking questions.\
In reality, most of us are terrible at it.\
Not because we lack curiosity or intelligence, but because we've been trained to focus on answers. School rewards students who memorize facts, not those who challenge assumptions. Work promotes people who execute known solutions, not those who explore unknown possibilities.\
Yet, look at anyone who has achieved extraordinary results in any field. The difference between good and great isn't in having more answers—it's in asking better questions.\
When Elon Musk questioned why rockets cost so much, he didn't start by studying aerospace engineering. He started by breaking down the raw material costs of rockets and asking why each component was so expensive. This fundamental questioning led to SpaceX revolutionizing the space industry.\
The same pattern shows up everywhere. Jeff Bezos asked why people couldn't buy any book they wanted instantly. Steve Jobs asked why computers couldn't be beautiful and intuitive. They didn't begin with solutions. They began with questions that challenged basic assumptions.\
But here's what nobody tells you about questions.\
They're not just tools for learning—they're tools for transformation.\
The right question can instantly shift your perspective. It can take a problem that seemed impossible and make the solution obvious. It can turn confusion into clarity. Overwhelm into focus. Stagnation into momentum.\
The quality of your life is directly proportional to the quality of questions you regularly ask yourself.\
Think about that for a second.\
What questions do you ask yourself when you wake up? When you face a challenge? When you're stuck? When you're deciding what to do with your time?\
Most people unconsciously ask questions that keep them trapped. Questions like "Why is this happening to me?" or "What if I fail?" or "What will others think?"\
These questions program your brain to look for evidence of problems, failures, and judgments. They create a self-fulfilling prophecy of mediocrity.\
The path to extraordinary results starts with extraordinary questions.Your mind is running on questions whether you realize it or not.\
Think of questions as lines of code in your mental software. Some questions create bugs in your thinking. Others unlock new capabilities you didn't know you had.\
Most people are running on default questions they never chose to install.\
These are the mental programs you inherited from parents, teachers, and society. They might have served a purpose once, but now, they're outdated. Running in the background. Draining your mental energy and limiting your potential.\
Want to spot the questions running your life? Look at your results.\
If you're constantly stressed about money, you might be running questions like "How can I avoid going broke?" Instead of "How can I create more value?"\
If your relationships are unfulfilling, you might be asking "Why don't people understand me?" Instead of "How can I understand others more deeply?"\
Questions shape reality by directing your focus.\
When you ask better questions, you literally upgrade your mental operating system. Your brain starts noticing opportunities it was blind to before. Solutions appear that were invisible when you were asking surface-level questions.\
This isn't just theory. It's how breakthroughs happen.\
Breaking through plateaus in any area comes down to asking questions nobody else is asking. Questions that challenge core assumptions. Questions that reframe the entire problem.\
The gap between 1x and 1000x performance isn't in having more answers. It's in having better questions.Let's talk about returns.\
Most people play small because they ask small questions. They stay stuck at 1x thinking because their questions never challenge their fundamental assumptions about what's possible.\
The jump from 1x to 10x starts with questions that break limiting patterns.\
Instead of asking "How can I get more clients?" you ask "Why do clients need what I'm selling in the first place?" This simple shift can reveal entire markets you were missing.\
The 10x to 100x leap happens when your questions reframe the entire game.\
This is where you stop asking "How can I be the best player?" and start asking "How can I change the rules?" These questions break you out of competition and into creation.\
But the real magic happens in the jump from 100x to 1000x.\
This is where Lady Luck enters the picture. But luck isn't random - it's attracted to certain types of questions.\
Questions that combine fields nobody has combined before. Questions that challenge assumptions are so basic that nobody sees them as assumptions. Questions that make people uncomfortable because they threaten the status quo.\
Warren Buffett didn't just ask "What stocks should I buy?" He asked, "What businesses are so fundamental to society that they'll be valuable for the next 50 years?" This question led him to invest in Coca-Cola, American Express, and other companies that have generated astronomical returns.\
When everyone else is asking "How can I compete?" you need to be asking "What game should I be playing instead?"\
The right question doesn't just solve problems - it eliminates them entirely.Most people think asking better questions is about being smarter.\
It's about being more precise.\
Vague questions create vague results. When you ask "How can I be more successful?" your brain has nothing concrete to work with. It's like trying to build a house without blueprints.\
But ask "What specific skills would make me irreplaceable in my industry?" and your mind immediately starts generating actionable insights.\
This is the art of question architecture.\
Start with "what" instead of "why." "Why" questions often lead to rationalizations and excuses. "What" questions lead to observations and actions.\
"Why am I stuck?" becomes "What small step would create momentum?" "Why don't I have enough time?" becomes "What am I currently spending time on that doesn't serve my goals?"\
The more specific your question, the more useful the answer.\
Your internal dialogue is just a series of questions and answers. Most people let this run on autopilot. But when you consciously architect your questions, you transform your mental landscape.\
Think of questions as doorways. A poorly designed doorway leads to a closet. A well-designed doorway opens into a universe of possibilities.\
The goal isn't to find the one perfect question. It's to develop a framework for generating better questions.\
This is how you turn confusion into clarity. Overwhelm into action. Stagnation into progress.\
Master learners don't just ask better questions. They have a system for generating them.\
First, they recognize that timing matters. There's a massive difference between asking questions to understand and asking questions to act.\
Understanding questions open up possibilities. Action questions narrow them down.\
When you're exploring a new field, you want broad questions that challenge basic assumptions. "What if everything I know about this is wrong?" This creates space for genuine insight.\
But when it's time to execute, you need focused questions that drive specific outcomes. "What's the smallest step I can take right now that makes all other steps easier?"\
The key is knowing which mode you're in.\
Most people get stuck because they ask action questions during exploration mode, or exploration questions during action mode. They try to optimize before they understand. Or they keep exploring when they should be executing.\
Master learners also build a question database. They collect powerful questions like others collect answers.\
"What would this look like if it were easy?" "What am I not seeing?" "What would I do if I knew I couldn't fail?"\
These aren't just motivational quotes. They're mental tools that break you out of limited thinking patterns.\
But the real power comes from creating your own questions.\
Questions that address your specific blindspots. Questions that challenge your deepest assumptions. Questions that force you to think in new ways.Here's what most people miss about questions.\
They're not just tools for solving problems. They're tools for living.\
Questions determine how you experience reality itself.\
When you ask "What's wrong with my life?" you'll find endless problems. When you ask "What's working in my life?" you'll find endless opportunities. Both questions reveal truth, but they reveal different truths.\
This isn't positive thinking. It's about understanding how your mind constructs reality.\
Every answer closes doors. It settles something. Finalizes it. Puts it in a box. But . They create possibilities that didn't exist before.\
Smart people often fall into the trap of being "answer-oriented." They pride themselves on knowing things. On being right. On having it figured out.\
But wisdom comes from maintaining a state of question.\
Think about it. The most profound experiences in life don't come from finding answers. They come from encountering better questions.\
Questions that make you reevaluate everything. Questions that expand your sense of what's possible. Questions that connect you to something larger than yourself.\
The goal isn't to eliminate uncertainty. It's to get better at dancing with it.\
Life becomes more interesting when you stop demanding answers and start embracing questions. When you stop trying to be certain and start getting curious.You're probably wondering what to do with all this.\
Take the questions you ask yourself every day and upgrade them. Don't try to force massive changes. Just make them slightly better.\
Small shifts in your questions create massive shifts in your life.\
Instead of asking "What do I have to do today?" ask "What's the most important thing I could accomplish today?"\
Pay attention to warning signs of poor questions. When you feel stuck, stressed, or overwhelmed, pause and notice what questions arerunning through your mind.\
Are they empowering or limiting? Are they specific or vague? Are they opening new possibilities or closing them off?\
The beauty of questions is that you can change them instantly.\
Your brain is like a search engine. It will find answers to whatever questions you feed it. Feed it better questions, and you'll get better answers.\
But there's something even more powerful at work here.\
Questions compound. Each better question leads to better insights, which leads to better questions. It's an upward spiral of understanding and capability.\
This is how you future-proof yourself.\
In a world of artificial intelligence and rapid change, the ability to ask better questions becomes increasingly valuable. AI can give you answers, but it can't tell you what questions to ask.\
That's where the real opportunity lies.\
Not in having all the answers, but in knowing how to find the questions that matter.]]></content:encoded></item><item><title>Despite 2024 Layoffs, Tech Jobs Expected to Take Off</title><link>https://spectrum.ieee.org/tech-jobs</link><author>Gwendolyn Rak</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjU2Mjc1OS9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc0OTA5MTQ5OX0.INl7Nce1q6TXLdMcV5dbkJPmcPgnRjMqUxidu7HD8yw/image.png?width=600" length="" type=""/><pubDate>Sat, 22 Feb 2025 16:00:03 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[Big data and AI specialist roles are expanding rapidly]]></content:encoded></item><item><title>Torvalds: Rust Kernel Code Isn&apos;t Forced In Over Maintainers&apos; Objections</title><link>https://linux.slashdot.org/story/25/02/22/0524210/torvalds-rust-kernel-code-isnt-forced-in-over-maintainers-objections?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 22 Feb 2025 15:54:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[ Linus Torvalds responded Thursday to kernel developer Christoph Hellwig, who had claimed Torvalds merged Rust code into the kernel even over his objections as the original C code's maintainer. Highlights from Torvalds' response:

The fact is, the pull request you objected to DID NOT TOUCH THE DMA LAYER AT ALL. It was literally just another user of it, in a completely separate subdirectory, that didn't change the code you maintain in _any_ way, shape, or form... Honestly, what you have been doing is basically saying "as a DMA maintainer I control what the DMA code is used for". 

And that is not how *any* of this works. What's next? Saying that particular drivers can't do DMA, because you don't like that device, and as a DMA maintainer you control who can use the DMA code? That's _literally_ exactly what you are trying to do with the Rust code. You are saying that you disagree with Rust — which is fine, nobody has ever required you to write or read Rust code. But then you take that stance to mean that the Rust code cannot even use or interface to code you maintain... 

You don't have to like Rust. You don't have to care about it. That's been made clear pretty much from the very beginning, that nobody is forced to suddenly have to learn a new language, and that people who want to work purely on the C side can very much continue to do so. So to get back to the very core of your statement: 

 "The document claims no subsystem is forced to take Rust" 

that is very much true. You are not forced to take any Rust code, or care about any Rust code in the DMA code. You can ignore it... 

You can't have it both ways. You can't say "I want to have nothing to do with Rust", and then in the very next sentence say "And that means that the Rust code that I will ignore cannot use the C interfaces I maintain".... So when you change the C interfaces, the Rust people will have to deal with the fallout, and will have to fix the Rust bindings. That's kind of the promise here: there's that "wall of protection" around C developers that don't want to deal with Rust issues in the promise that they don't *have* to deal with Rust. 

But that "wall of protection" basically goes both ways. If you don't want to deal with the Rust code, you get no *say* on the Rust code. Put another way: the "nobody is forced to deal with Rust" does not imply "everybody is allowed to veto any Rust code".
 
Torvalds also made sure to add some kind remarks, including "I respect you technically, and I like working with you."]]></content:encoded></item><item><title>Explore the online world of Apple TV’s ‘Severance’</title><link>https://techcrunch.com/2025/02/22/explore-the-online-world-of-apple-tvs-severance/</link><author>Sarah Perez</author><category>tech</category><pubDate>Sat, 22 Feb 2025 15:00:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Apple has been steadily working to expand the world of the Apple TV+ series “Severance,” through online materials, e-books, podcasts, and other content – and so have its fans. Taking advantage of its platform power, the Cupertino tech giant has been able to easily distribute supplemental material that adds to the show’s storytelling abilities, offering […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Asahi Linux&apos;s Honeykrisp Vulkan Driver Gains Sparse Support In Mesa 25.1</title><link>https://www.phoronix.com/news/Honeykrisp-Sparse-Mesa-25.1</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 14:14:47 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Alyssa Rosenzweig has carried out a fresh sync of the Asahi Linux AGX Gallium3D and Honeykrisp Vulkan driver changes of the work that was being carried by the Asahi Linux development tree and now upstreamed to Mesa proper...]]></content:encoded></item><item><title>Mozambique Retools Weather Tech for Impactful Forecasting</title><link>https://spectrum.ieee.org/disaster-response-tech-mozambique</link><author>Maurizio Arseni</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjU1ODQ1Mi9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc2NzYxNjQ4M30.BkrN-0JVFqGthtNaOHUl1-7PJN95BugC26I-YqQOVcY/image.jpg?width=600" length="" type=""/><pubDate>Sat, 22 Feb 2025 14:00:03 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[Drones and situation rooms inform responses to floods and cyclones]]></content:encoded></item><item><title>Scientists Discover Ancient Farms in the Deep Sea</title><link>https://www.404media.co/scientists-discover-ancient-farms-in-the-deep-sea/</link><author>Becky Ferreira</author><category>tech</category><enclosure url="https://www.404media.co/content/images/2025/02/image4-1.jpg" length="" type=""/><pubDate>Sat, 22 Feb 2025 14:00:01 +0000</pubDate><source url="https://www.404media.co/">404</source><content:encoded><![CDATA[Welcome back to the Abstract! It’s hard to keep up with all the news about all the giant gassy orbiters out there. I’m speaking, of course, about hot Jupiters, a class of planets that takes the concept of “inhospitable” to dazzling and creative new levels, and which had an epic news week.Then, what did scientists find in cores taken from deep-sea trenches? The answer might surprise you. Next, mice administer “first aid.” Last, fish can see you for who you really are (though yummy treats will certainly not be refused). Hot Jupiters Are So Hot Right Now (and at All Other Times)Hot Jupiters are the low-hanging fruit of exoplanet discoveries. As the name implies, they are Jupiter-sized worlds that orbit extremely close to their stars, a proximity that makes them—you guessed it—hot. Given that they are both giant in scale and have short years lasting only hours or days, hot Jupiters are the easiest exoplanets to spot, which is why our catalog of distant worlds is packed with them. In fact, a study came out  that identified seven new ones.But while it’s not all that novel to discover these worlds (which is kind of amazing in itself), scientists have now peered deep into the atmosphere of the hot Jupiter WASP-121, nicknamed Tylos, which is about 850 light years from Earth. It’s the first time several distinct atmospheric layers and processes have been observed on an exoplanet.   “Ultra-hot Jupiters, an extreme class of planets not found in our solar system, provide a unique window into atmospheric processes,” said researchers led by Julia Seidel of the European Southern Observatory (ESO). “Here we show a dramatic shift in atmospheric circulation in an ultra-hot Jupiter” including “the first vertical characterization of a high-altitude, super-rotational atmospheric jet stream.”  Tylos is slightly bigger than Jupiter, but it is so close to its star that its year lasts only 30 hours. As a consequence, it is tidally locked, meaning that one side is always facing the star, and the other always faces away. The star-lit side is about 2,300°C (4,200°F) which is, as advertised, quite hot. Using the ESO’s Very Large Telescope, the researchers spotted the aforementioned equatorial jet stream and saw flows of hot gas moving from the hot day side to the cooler night side—which is still pretty hot at around 700°C (1,340°F). The weather report on Tylos is permanently fatal with a chance of titanium rain, according to a third study that came out this week (that’s a hot Jupiter hat-trick). Taken together, the research represents a new emerging era of exoplanet observations in which astronomers can peek under the hood of these distant atmospheres and start to get a real vertical cross-section of otherworldly skies. Down the line, this will lead to better characterizations of the atmospheres of potentially habitable exoplanets, which could contain detectable signs of alien life. But for now, on this late winter weekend, let's be satisfied with warming ourselves  into certain oblivion in the bellies of hot Jupiters. From the Hadal to the Grave To cool off, we shall now dive straight into the deepest parts of the ocean, the hadal zone, where strange things are inherently afoot. Scientists took sediment cores from seafloors at depths of over 4.6 miles in the Japan Trench which is, in my opinion, asking for trouble. But in this case, the results revealed an activity that you might not expect to find in one of the most inhospitable places on Earth—farming.   I should just say, the “farmers” are probably invertebrates, like sea cucumbers or bivalves, that cultivate microbes that help break down organic matter for them. Still, a basic form of “agrichnial” farming is preserved in trace fossils, like burrows, the team found in the cores. “The hadal zone, >6 km deep, remains one of the least understood ecosystems on Earth,” said researchers led by Jussi Hovikoski of the Geological Survey of Finland. The cores open a rare window into this otherworldly region and reveal “slender spiral, lobate and deeply penetrating straight and ramifying burrow systems…interpreted to include burrows of microbe farming and chemosymbiotic invertebrates.” The study also gets points for its title, “Bioturbation in the hadal zone,” which sounds like an early aughts prog rock album. \m/ Somebody Call an EMT! (Emergency Mouse Technician)Humans produce a lot of selfish psychos, if you hadn’t noticed, but one nice thing about our species is we generally share a prosocial instinct to help people during a medical crisis. As it turns out, we’re not alone in this behavior, according to a new study that monitored the reactions of mice to ailing, unconscious, or dead conspecifics. “Anecdotal observations across several species in the wild, including nonhuman primates, dolphins, and elephants have reported intriguing behaviors of animals toward unresponsive conspecifics that have collapsed because of sickness, injury, or death,” said researchers led by  Wenjian Sun of the University of Southern California. “These animals…display various behavioral responses, including touching, grooming, nudging, and sometimes even more intense physical actions, such as striking, toward the collapsed peers. Some of these actions toward incapacitated conspecifics are reminiscent of human emergency responses, especially those involving sensory stimulation.”To bring these anecdotal reports in an experimental setting, the team videotaped mice responding to cagemates that had been anesthetized into unconsciousness, as well as their reactions  to dead mice. The r mice interacted with unconscious cage-mates  about ten times as much as with an active partner, and may have even performed basic versions of first aid.“Our results suggest that the actions of mouth/ tongue biting and tongue pulling may have rescue-like effects, reminiscent of human first aid efforts in reviving unconscious individuals with physical stimulation and airway maintenance,” the researchers said.  “The consequences of the behaviors, such as improved airway opening or clearance and expedited recovery, are clearly beneficial to the recipient,” they added, though they also cautioned that “it is challenging to determine the motivational needs behind these distinctive ‘reviving-like’ behaviors.”  Familiarity played a strong role in the experiment's outcome; mice heaped much more attention on dead or unconscious cage-mates that they knew well compared to strangers. At the risk of anthropomorphizing, it’s kind of sad to think about these mice being confronted with their passed-out or dead friends, but the silver lining is an empirical validation of widespread prosocial behaviors. I’m also going to assume it means that the Disney franchise , starring mice humanitarians, is a documentary.The Adventures of Left Hump and FriendsThe next time you go for an ocean swim, why not introduce yourself to some neighboring fish? They might learn to recognize you as an individual and start following you around, especially if you give them something nice to eat. That’s the conclusion of a new study that found fish can tell individual divers apart based on visual cues—and that they rapidly learn which divers are generous with treats (in this case: shrimp).Researchers Maëlan Tomasek and Katinka Soller conducted several dives at the STARESO research station in Corsica, France. Soller was the designated shrimp dispenser, and the wild fish “volunteers” rapidly learned to distinguish her visually from Tomasek, the shrimp miser.“Two species voluntarily took part in our experiments: saddled sea bream and black sea bream ,” said the researchers. “Of specific individuals, the saddled bream (Bernie) was first identified at dive 5 of the training, four black bream at dives 12 (Left Hump), 15 (Kasi), 19 (Alfi), 21 (Julius) and the last black bream (Geraldine) on the first session of experiment 1. Note that this marks the moment from which we were able to reliably identify them (i.e. identify with absolute certainty at each apparition from one dive to the next) but that they most likely appeared several days prior to this.”First of all, fantastic names. I’m already shipping Julius and Geraldine as a celebrity fish couple called Juladine. Left Hump will officiate the wedding. But setting aside the fish fanfic, the team demonstrated that the fish learned to visually tell the researchers apart, leading to a clear preference for following Soller. “The fact that wild bream can discriminate between divers adds scientific evidence to the numerous accounts suggesting differentiated relationships between fish and specific humans,” the team said. “Our study thus encourages a reappraisal of the methodological avenues to study cognitive abilities of wild fish under natural conditions.” “It also demonstrates a potential difficulty when conducting such experiments that could be disturbed by fish following specific experimenters,” the researchers said, concluding with an implied wink: “Researchers might not always want to be followed all around by fish, but if they do, they will not be disappointed.”Thanks for reading! See you next week.]]></content:encoded></item><item><title>AI Models Are Learning to Prioritize Their Thoughts—And It’s Wildly Effective</title><link>https://hackernoon.com/ai-models-are-learning-to-prioritize-their-thoughtsand-its-wildly-effective?source=rss</link><author>Writings, Papers and Blogs on Text Models</author><category>tech</category><pubDate>Sat, 22 Feb 2025 12:00:07 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) David Raposo, Google DeepMind and with equal contribution;(2) Sam Ritter, Google DeepMind;(3) Blake Richards, Google DeepMind and McGill University & Mila;(4) Timothy Lillicrap, Google DeepMind;(5) Peter Conway Humphreys, Google DeepMind;(6) Adam Santoro, Google DeepMind and with equal contribution.:::tip
Editor's note: this is part 5 of 5 of a study detailing a way to make transformer-based language models more efficient by dynamically allocating computational resources. Read the rest below.3.1. Defining a compute budget3.2. Routing around transformer blocks3.4. Routing implementation3.5. Sampling and 3.6. Training methods4.1. Training, isoFLOP comparisons4.2. Auto-regressive Evaluation and 4.3. Mixture-of-Depths-and-Experts (MoDE)Mixture-of-Depths transformers empirically demonstrate that one can improve on isoFLOP-optimal baseline performance with models that use fewer FLOPs per forward pass. This means that—for a given training FLOP budget—we can train models that are both faster and better performing than their baseline counterparts. Previously, to train models that are both faster and as- or better-performing than isoFLOP-optimal models, one would have to use surplus compute to overtrain smaller models (notably, this overtraining technique is still possible with MoD transformers, and speed gains should compound).\
While MoD transformers require fewer FLOPs per forward pass, one cannot forego FLOPs indiscriminately. Rather, it is crucial to use learned routing decisions—much like in Mixture-of-Experts transformers—to determine whether a token should participate in self-attention and the subsequent MLP (requiring FLOPs), or not (saving FLOPs).We can then use any saved FLOPs by, for example, making the model bigger or training it for longer. Our results show that indeed FLOPs may be inefficiently used in vanilla transformer models, and that there may be more efficient ways for them to be expended.\
Learned routing mechanisms are sometimes non-causal; that is, information about the future is used to determine a given token’s routing decision. This is generally true for top-k routing mechanisms, which are useful because they forego the need for auxiliary balancing losses. However, top-k routing mechanisms present difficulties in post-training autoregressive sampling, where it is impossible to use information about future token identities to determine routing decisions. In this work we show that one can successfully use a top-k routing scheme during training, but not require it during later autoregressive sampling. Eiher a simple auxiliary classifier, or auxiliary loss on the router, is sufficient to learn the top-𝑘 routing decisions such that it can mimic the top-𝑘 decisions during autoregressive\
sampling, with minimal to no performance degradation.\
Intuitively, a token might learn to route around blocks because the prediction being made at that step is easier, and hence, does not require as much compute. However, this strategy is undoubtedly not all that the network learns. If a token does not participate in self-attention at a certain block, then later tokens will also not be able to attend to it. Thus, whether tokens decide to route or not impacts both the current step’s prediction and future predictions via causal self-attention, and how the network balances these effects is guided by their influence on the overall language modeling objective.\
This insight opens the door to MoD variants that decouple the routing for queries, keys and values. For example, perhaps a token would prefer to be among the queries, but not the keys, for a given self-attention computation. One can imagine extending this idea even further into the domain of "long-term memory": perhaps there are tokens that would be extremely valuable as keys, regardless of whether it is useful for them to also be among the queries at the step of their occurrence. Learned routing could be a powerful mechanism for deciding which tokens these might be, perhaps funnelling them into a long-term memory buffer that is available during future self-attention. One advantage of such an approach to long-term memory is that tokens decide once, at the moment of "memory encoding", whether they should be retrieved in the future. This is more computationally efficient than performing a full content-based lookup across an entire memory buffer for each step in the future, and could be one step towards drastically increasing the context-length available for making a prediction.\
Unlike MoE transformers that route between effectively the same computation (usually MLPs), MoD transformers demonstrate the value of routing among different types of computations. In this work the types were either the conventional transformer block, or a null computation (functionally equivalent to multiplying by zero). However, one can imagine extending this idea further by routing between even more types of computation. For example, perhaps some tokens are routed to "memory lookup" functions, and others are routed to "tool use" functions. In general, the routing machinery we deployed provides a knob for adjusting the types of computations available to the network and their relative cost (in total FLOPs); if one wants to introduce an expensive computation, then this can be offset by setting its capacity to some small amount, and hence, by routing only a small number of tokens to it.\
Altogether, MoD transformers are another tool one can use to tune a model’s compute per forward pass (and hence inference time). The machinery used to implement MoD is also generic, and opens the doors to many extensions and integration with other techniques, such as MoE.J. Ainslie, T. Lei, M. de Jong, S. Ontañón, S. Brahma, Y. Zemlyanskiy, D. Uthus, M. Guo, J. LeeThorp, Y. Tay, Y.-H. Sung, and S. Sanghai. Colt5: Faster long-range transformers with conditional computation, 2023.\
A. Bapna, N. Arivazhagan, and O. Firat. Controlling computation versus quality for neural sequence models. CoRR, abs/2002.07106, 2020. URL https://arxiv.org/abs/2002.07106.\
E. Bengio, P.-L. Bacon, J. Pineau, and D. Precup. Conditional computation in neural networks for faster models, 2016.\
Y. Bengio. Deep learning of representations: Looking forward, 2013.\
Y. Bengio, N. Léonard, and A. Courville. Estimating or propagating gradients through stochastic neurons for conditional computation, 2013.\
D. Bolya, C.-Y. Fu, X. Dai, P. Zhang, C. Feichtenhofer, and J. Hoffman. Token merging: Your vit but faster, 2023.\
K. Cho and Y. Bengio. Exponentially increasing the capacity-to-computation ratio for conditional computation in deep learning, 2014.\
M. Dehghani, S. Gouws, O. Vinyals, J. Uszkoreit, and Ł. Kaiser. Universal transformers. arXiv preprint arXiv:1807.03819, 2018.\
M. Elbayad, J. Gu, E. Grave, and M. Auli. Depth-adaptive transformer. CoRR, abs/1910.10073, 2019. URL http://arxiv.org/abs/1910.10073.\
W. Fedus, B. Zoph, and N. Shazeer. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity, 2022.\
A. Graves. Adaptive computation time for recurrent neural networks. CoRR, abs/1603.08983, 2016. URL http://arxiv.org/abs/1603.08983.\
M. Guo, J. Ainslie, D. Uthus, S. Ontanon, J. Ni, Y.-H. Sung, and Y. Yang. Longt5: Efficient text-to-text transformer for long sequences, 2022.\
M. Gupta and P. Agrawal. Compression of deep learning models for text: A survey, 2021.\
J. He, C. Zhou, X. Ma, T. Berg-Kirkpatrick, and G. Neubig. Towards a unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366, 2021.\
Y. Jernite, E. Grave, A. Joulin, and T. Mikolov. Variable computation in recurrent neural networks, 2017.\
T. Lei, J. Bai, S. Brahma, J. Ainslie, K. Lee, Y. Zhou, N. Du, V. Y. Zhao, Y. Wu, B. Li, Y. Zhang, and M.-W. Chang. Conditional adapters: Parameter-efficient transfer learning with fast inference, 2023.\
D. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen. Gshard: Scaling giant models with conditional computation and automatic sharding. arXiv preprint arXiv:2006.16668, 2020.\
Z. Liu, Z. Xu, H.-J. Wang, T. Darrell, and E. Shelhamer. Anytime dense prediction with confidence adaptivity. arXiv preprint arXiv:2104.00749, 2021.\
T. Schuster, A. Fisch, J. Gupta, M. Dehghani, D. Bahri, V. Q. Tran, Y. Tay, and D. Metzler. Confident adaptive language modeling, 2022.\
N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint arXiv:1701.06538, 2017.\
A. Simoulin and B. Crabbé. How many layers and why? An analysis of the model depth in transformers. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop, pages 221–228, Online, Aug. 2021. Association for Computational Linguistics. doi: 10.18653/v1/ 2021.acl-srw.23. URL https://aclanthology.org/2021.acl-srw.23.\
Y. Tay, M. Dehghani, D. Bahri, and D. Metzler. Efficient transformers: A survey. CoRR, abs/2009.06732, 2020. URL https://arxiv.org/abs/2009.06732.\
X. Wang, F. Yu, Z. Dou, and J. E. Gonzalez. Skipnet: Learning dynamic routing in convolutional networks. CoRR, abs/1711.09485, 2017. URL http://arxiv.org/abs/1711.09485.\
B. Zoph, I. Bello, S. Kumar, N. Du, Y. Huang, J. Dean, N. Shazeer, and W. Fedus. St-moe: Designing stable and transferable sparse expert models, 2022.]]></content:encoded></item><item><title>Game Developers Revolt Against Microsoft&apos;s New AI Gaming Tool</title><link>https://games.slashdot.org/story/25/02/22/0244244/game-developers-revolt-against-microsofts-new-ai-gaming-tool?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Sat, 22 Feb 2025 12:00:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Microsoft's newly announced Muse AI model for game development has triggered immediate backlash from industry professionals. "Fuck this shit," responded David Goldfarb, founder of The Outsiders, arguing that such AI tools primarily serve to "reduce capital expenditure" while devaluing developers' collective artistic contributions. 

Multiple developers told Wired that the tool is aimed at shareholders rather than actual developers. "Nobody will want this. They don't CARE that nobody will want this," one AAA developer said, noting that internal criticism remains muted due to job security concerns amid industry-wide layoffs. 

The resistance comes as developers increasingly view AI initiatives as threats to job security rather than helpful tools. One anonymous developer called it "gross" that they needed to remain unnamed while criticizing Muse, as their studio still depends on potential Game Pass deals with Microsoft. Even in prototyping, where Microsoft sees AI potential, Creative Assembly's Marc Burrage warns that automated shortcuts could undermine crucial learning experiences in game development.]]></content:encoded></item><item><title>SystemV Filesystem Being Removed From The Linux Kernel</title><link>https://www.phoronix.com/news/Removing-SystemV-Filesystem</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 11:57:05 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[The SystemV file-system that implements Xenix FS, SystemV/386 FS, and Coherent FS is set to be removed from the Linux kernel. The SystemV file-system was orphaned back in 2023 while now is set to be removed entirely after developers realized the code was fundamentally broken...]]></content:encoded></item><item><title>FreeBSD 13.5 Beta 3 Drops KDE Packages From DVD ISOs</title><link>https://www.phoronix.com/news/FreeBSD-13.5-Beta-3</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 11:49:10 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[FreeBSD 13.5 Beta 3 is out this weekend in being the newest weekly development version leading towards next month's stable release to cap off the FreeBSD 13 series...]]></content:encoded></item><item><title>What If AI Could Skip the Boring Parts? Google Researchers Just Made It Happen</title><link>https://hackernoon.com/what-if-ai-could-skip-the-boring-parts-google-researchers-just-made-it-happen?source=rss</link><author>Writings, Papers and Blogs on Text Models</author><category>tech</category><pubDate>Sat, 22 Feb 2025 11:45:07 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) David Raposo, Google DeepMind and with equal contribution;(2) Sam Ritter, Google DeepMind;(3) Blake Richards, Google DeepMind and McGill University & Mila;(4) Timothy Lillicrap, Google DeepMind;(5) Peter Conway Humphreys, Google DeepMind;(6) Adam Santoro, Google DeepMind and with equal contribution.:::tip
Editor's note: this is part 4 of 5 of a study detailing a way to make transformer-based language models more efficient by dynamically allocating computational resources. Read the rest below.3.1. Defining a compute budget3.2. Routing around transformer blocks3.4. Routing implementation3.5. Sampling and 3.6. Training methods4.1. Training, isoFLOP comparisons4.2. Auto-regressive Evaluation and 4.3. Mixture-of-Depths-and-Experts (MoDE)We first trained models with a relatively small FLOP budget (6e18) to determine optimal hyperparameters (see figure 3). In general, we found that MoD transformers drag the baseline isoFLOP curve "down and to the right". That is, the optimal MoD transformer achieves a lower loss than the optimal baseline, and also has more parameters. A fortunate consequence of this effect is that there exist smaller MoD models that, while they are not themselves isoFLOP optimal for their hyperparameter setting, are nevertheless as- or better-performing than the optimal baseline model while being faster to step. For example, a 220M parameter MoD (figure 3 model #3) variant slightly outperforms the isoFLOP optimal baseline (also 220M, figure 3 model #1), but is upwards of 60% faster to step during training. Crucially, when run on equivalent hardware these two model variants take take approximately the same amount of wall-clock time to train (figure 3).\
We tested routing every block or every other block, using capacities from 12.5% to 95% of the total sequence. While routing every other block was crucial for strong performance, we found that aggressive capacity reduction was best (gradual improvements were observed when reducing the capacity down to 12.5% of the total sequence, corresponding to 87.5% of tokens routing around blocks, with performance degrading beyond this point). So, it seems the network is robust to significant capacity reductions as long as there is frequent opportunity for full capacity self-attention and MLP computations.\
Learned routing is crucial, as MoD transformers that use stochastic routing (implemented using a top-𝑘 operation on router weights sampled from a Gaussian distribution) perform drastically worse than both the baseline and normal MoD transformer (figure 3).\
Depicted in figure 4 is an isoFLOP analysis for 6e18, 2e19, and 1e20 total FLOPs. The trend that FLOP-optimal MoD transformers have more parameters than the baseline continues for these larger FLOP budgets. Notably, there exist MoD variants that are appreciably faster to step than the isoFLOP-optimal baseline (measured as steps per second when training on equivalent hardware) while also achieving a lower loss (in figure 4 we depict normalized FLOPs per forward pass rather than wall-clock step time per se, but from our experiments the two are tightly correlated. A similar plot can be produced showing relative wall-clock step times and the same basic trend is present).\
Step-wise speed gains come from two sources. First, the FLOP-per-parameter ratio in MoD transformers is less than in the baselines because some proportion of tokens are routed around blocks. So, for a given model size, a transformer requires fewer FLOPs per forward pass. Second, since isoFLOP-optimal MoD transformers are both bigger and achieve a lower loss than the isoFLOP-optimal baseline, there exist smaller MoD variants that perform as well or better than the isoFLOP-optimal baseline, and these variants are faster to step because they are smaller. Altogether, then, there exist MoD transformers that perform as well as isoFLOP-optimal baselines and are faster to step, both because they use fewer FLOPs per parameter and because they use fewer parameters.\
\
Figure 4 also reveals another important finding: the optimal MoD transformer is that which uses as many FLOPs per forward pass as the isoFLOP optimal baseline. This finding allows one to directly predict which sized MoD transformer will perform optimally for a given isoFLOP training budget: one just needs to tune the model size for a given MoD configuration (i.e., capacity and routing frequency) to produce a model that uses as many FLOPs per forward pass as the isoFLOP-optimal baseline, and they will have the optimally performing MoD variant for that configuration. Empirically, we find that it is better to add depth than to add width when adding FLOPs to the model.\
Nevertheless, while the FLOPs per forward pass determines which model will be the isoFLOP optimal, it does not predict whether the optimal loss will improve upon the baseline (see figure 3. Namely, the optimal capacity appears to be empirically determinable. We found that it is best to use 12.5% capacity blocks, every other block.\
We noticed that MoD transformers had memory savings relative to equivalently sized baseline models at larger sizes, with some variants requiring fewer total devices (i.e., a smaller TPU topology). We did not study this extensively, but we anticipate that as one scales to larger models, these savings could be an important consideration when choosing model variants to train, and could have significant positive effects in regards to the KV cache size during autoregressive sampling.\
Figure 5 shows the routing decisions for an MoD transformer trained with interleaved routing blocks. Despite aggressive routing around the blocks, transformers are able to achieve performance improvements relative to baselines. We observe patterns that might warrant further study; namely, some tokens appear to engage each block along the transformer’s depth, while others decide to route around blocks whenever possible. Preliminary analyses suggest that the tokens that engage with blocks more frequently are correlated with output predictions that have higher entropy, which possibly corresponds to predictions that are more difficult to make.4.2. Auto-regressive EvaluationWe evaluated MoD variants during auto-regressive sampling (see figure 6). Each model was tested on exactly the same held-out data comprising 256000 sequences (500M tokens). When switching from the top-𝑘 routing method to the predictor-based routing method we observed little performance degradation. As in the training setting, there exist MoD variants that are better performing than the isoFLOP-optimal baseline, while requiring fewer FLOPs per forward pass. These results suggest that the compute savings offered by MoD transformers should translate beyond the training setting.4.3. Mixture-of-Depths-and-Experts (MoDE)The MoD technique can be naturally integrated with MoE models (together comprising MoDE models) in addition to vanilla transformers. In figure 7 we present results showing that the performance improvments offered by MoD compound with those of MoE. We tried two variants: in staged MoDE, which routes tokens around or towards blocks prior to the self-attention step, and integrated MoDE, which implements MoD routing by integrating “no-op” experts among the conventional MLP experts. The former is advantageous because it allows for tokens to skip the self-attention step, while the latter is advantageous because it simplifies the routing machinery. We noticed that implementing MoDE in the integrated manner was distinctly better than simply reducing the capacity of experts in conventional MoE models, and relying on token dropping to implement residual routing. We believe this is because with the integrated MoDE machinery, tokens explicitly learn to choose the residual path around the experts, as opposed to preferring an expert but being dropped when implemented as a capacity reduction.]]></content:encoded></item><item><title>Niri 25.02 &amp; Labwc 0.8.3 Wayland Compositors Released</title><link>https://www.phoronix.com/news/Niri-25.02-Labwc-0.8.3</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 11:41:39 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[The Niri and Labwc Wayland compositor projects are both out with new releases this weekend to further their efforts...]]></content:encoded></item><item><title>This Clever AI Hack Could Cut Processing Costs in Half</title><link>https://hackernoon.com/this-clever-ai-hack-could-cut-processing-costs-in-half?source=rss</link><author>Writings, Papers and Blogs on Text Models</author><category>tech</category><pubDate>Sat, 22 Feb 2025 11:30:03 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) David Raposo, Google DeepMind and with equal contribution;(2) Sam Ritter, Google DeepMind;(3) Blake Richards, Google DeepMind and McGill University & Mila;(4) Timothy Lillicrap, Google DeepMind;(5) Peter Conway Humphreys, Google DeepMind;(6) Adam Santoro, Google DeepMind and with equal contribution.:::tip
Editor's note: this is part 3 of 5 of a study detailing a way to make transformer-based language models more efficient by dynamically allocating computational resources. Read the rest below.3.1. Defining a compute budget3.2. Routing around transformer blocks3.4. Routing implementation3.5. Sampling and 3.6. Training methods4.1. Training, isoFLOP comparisons4.2. Auto-regressive Evaluation and 4.3. Mixture-of-Depths-and-Experts (MoDE)Our high-level strategy is as follows:\
• Set a static compute budget that is less than that of an equivalent vanilla transformer by limiting the number of tokens in a sequence that can participate in a block’s computations (i.e., selfattention and subsequent MLP). For example, while a vanilla transformer might permit all the tokens in a sequence to participate in self-attention, we might limit the number to 50% of the tokens in a sequence. See section 3.1.\
• Use a per-block router to emit a scalar weight for each token, which expresses the router’s preference for that token to participate in a block’s computations or to route around it. See section 3.2.\
• Identify the top-𝑘 scalar weights (per sequence, per block) to select those tokens that will participate in a block’s computations. Since precisely 𝑘 tokens will participate in the block’s computations, the computation graph and tensor sizes remain static throughout training; it is merely the tokens’ participation that is dynamic and context-sensitive, as determined by the router. See section 3.3.\
We then discuss some complications when sampling post-training in section 3.5.To enforce a total compute budget per forward pass we leverage the notion of , which defines the total number of tokens that comprise the input to a given computation (e.g., the tokens participating in self-attention, a given expert in MoE transformers, etc). For example, the self-attention and MLP in each vanilla transformer block have a capacity of 𝑇—the total number of tokens across the sequence and batch. MoE transformers, on the other hand, use a capacity less than 𝑇 per expert MLP so as to more evenly divide the total compute across each expert. But, since they use multiple experts per block, their total capacity is approximately equal to that of a vanilla transformer.\
Generally, it is the token capacity that determines the total FLOPs for transformers that use conditional computation, rather than the outcomes of any routing decisions. This is because staticgraph implementations account for the worst-case scenarios decisions; e.g., a computation’s inputs will be padded to its capacity amount even if relatively few tokens actually end up routing to it, and/or tokens will be dropped from the computation if the capacity is exceeded.\
We can achieve our goal of using a smaller compute budget per forward pass compared to a vanilla transformer by lowering the capacity of the computations. However, using a smaller compute budget haphazardly will result in a performance degradation. We hypothesize that certain tokens might not require as much processing as others, and these tokens can be identified through learning. Therefore, if the network learns to choose the right tokens to fill up its capacities, then it may preserve its performance. In the following we describe routing schemes that can be used for this purpose.We consider the setting whereby we route tokens to one of two computational paths: (1) self-attention and MLP blocks, and (2) a residual connection. The latter is computationally cheap, and results in a block output that is entirely determined by the value of its input. The former path is computationally expensive.\
\
\
Intuitively, the total FLOPs per forward pass decreases (and the time to complete a forward pass decreases) in proportion to how aggressively we shrink the blocks’ capacities. However, downstream performance will also be affected by how aggressively we shrink the blocks capacities, and by the routing algorithm we implement.\
At one extreme, if we leave each block’s capacity at 𝑇 and route every token to (rather than around) each block, then we recover a vanilla transformer. At the other extreme, if we set each block’s capacity to 0 and route all tokens around each block, then we’re left with a very fast model that doesn’t engage with the vast majority of the transformer’s parameters, and undoubtedly has poor downstream performance. We hypothesize that somewhere between these two extremes is an optimal model that is faster than a vanilla Transformer and performs as well, if not better, all while being faster to step.Naively, one can leverage stochasticity to route tokens, akin to layer or block “dropout”. We present this routing scheme as a control, and will show that it significantly under-performs relative to vanilla transformers.\
We hypothesize that learned routing is preferable. Intuitively, the network should be able to learn which tokens require more or less processing than others. If we are correct that Transformers often expend more compute than they need to make their predictions, then it is an empirical question as to how aggressively we can shrink each block’s capacity, and hence, how many tokens we can afford to route around each block.\
There are two learned routing schemes we consider (see figure 2): token-choice and expert-choice. In token-choice routing, a router produces per-token probability distributions across computational paths (e.g., across expert identities in MoE Transformers). Tokens are then shuttled to the path they prefer—i.e., that with the highest probability—and auxiliary losses ensure that all tokens don’t converge to the same path. Token-choice routing can have load balancing problems since there isn’t a guarantee that tokens divide themselves appropriately between the possible paths. “Expert choice routing” flips this recipe on its head: rather than having tokens choose the path they prefer, each path instead chooses the top-𝑘 tokens based on the tokens’ preferences. This ensures a perfect load balance since 𝑘 tokens are guaranteed to be shuttled to each path. However, it could result in over- or under-processing of some tokens, since some tokens may be among the top-𝑘 for multiple paths, or for none of them.\
We decided to leverage expert-choice routing for a few reasons. First, it obviates the need for an auxiliary balancing loss. Second, since the top-𝑘 operation depends on the magnitude of the router weights, this routing scheme allows for relative routing weights to help determine which tokens most need the block’s computations; routers can try to ensure that the most critical tokens are among the top-𝑘 by setting their weight appropriately, which is not possible with token-choice routing schemes. For our specific use-case, wherein one computational path is essentially a null operation, it might be critical that important tokens are routed away from the null operation. Third, because we only route through two paths, a single top-𝑘 operation can efficiently split the tokens into two mutually exclusive sets, one for each computational path, preventing the over- or under-processing problem mentioned above.3.4. Routing implementationAs a reminder of the high-level intuition, each token is processed by a router to produce a scalar weight, and the top-𝑘 weights are then used to choose the token identities that will route through a transformer’s block, which comprises self-attention and the subsequent MLP.\
\
\
\
\
Notably, we multiply the output of the function 𝑓 by the router weights. This puts the router weights along the “gradient path”, thus subjecting them to the forces of gradient descent through the course of the language modeling task (We experimented with versions where the router weights are also included along the computational path for those tokens that bypass the block’s computations, but it seems to be sufficient—and implementationally simpler—to only include the router weights along the computational path for those tokens that do not bypass the block’s computations).While expert-choice routing has a number of advantages, it has one distinct problem: the top-𝑘 operation is non-causal. This means that whether a given token’s routing weight is among the top-𝑘 for the sequence depends on the values of the routing weights for tokens that come after it, which we don’t have access to when autoregressively sampling.\
We tested two methods to work around this problem. The first introduces a simple auxiliary loss that empirically affects the primary language modeling objective by approximately 0.2 − 0.3%, but allows us to sample from the model autoregressively. We use a binary cross-entropy loss wherein the router’s outputs provide the logits, and the top-𝑘 selections of these logits provide the targets (i.e. 1 if a token was among the top-𝑘, and 0 if not). Intuitively, this loss centers the sigmoid of the router’s outputs around 0.5; those tokens that are selected among the top-k are pressured to produce router outputs above 0.5, and those not among the top-k will be pressured to produce router outputs below 0.5. The second method introduces a small auxiliary MLP predictor (akin to a second router) that receives the same inputs as the router (with a stop gradient), but whose output is a prediction whether that token will be among the top-𝑘 or not in the sequence. This method does not affect the language modeling objective, and empirically does not significantly impact the step speed.\
Equipped with these new methods, we can sample autoregressively by choosing to route tokens to or around a block based on the router’s output, which does not depend on any information from future tokens. We provide empirical evidence that this is a relatively easy auxiliary task that quickly achieves 99% accuracy.All models use the same basic hyperparameter configurations (e.g. cosine schedules equal to 1× the training steps, 128 batch size, 2048 sequence length) except for changes to the number of layers, heads, and embedding size to produce differently sized models during isoFLOP analyses.]]></content:encoded></item><item><title>KDE Plasma 6.4 Preps Improvement To Help KWin Reduce Frame Drops</title><link>https://www.phoronix.com/news/Plasma-6.4-Less-KWin-Frame-Drop</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 11:28:23 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[In addition to this week's release of Plasma 6.3.1, KDE developers have been busy preparing more bug fixes for what will become Plasma 6.3.2 next month. Additionally, more feature code for Plasma 6.4 continues to bake...]]></content:encoded></item><item><title>New AI Method Lets Models Decide What to Think About</title><link>https://hackernoon.com/new-ai-method-lets-models-decide-what-to-think-about?source=rss</link><author>Writings, Papers and Blogs on Text Models</author><category>tech</category><pubDate>Sat, 22 Feb 2025 11:15:04 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) David Raposo, Google DeepMind and with equal contribution;(2) Sam Ritter, Google DeepMind;(3) Blake Richards, Google DeepMind and McGill University & Mila;(4) Timothy Lillicrap, Google DeepMind;(5) Peter Conway Humphreys, Google DeepMind;(6) Adam Santoro, Google DeepMind and with equal contribution.:::tip
Editor's note: this is part 2 of 5 of a study detailing a way to make transformer-based language models more efficient by dynamically allocating computational resources. Read the rest below.3.1. Defining a compute budget3.2. Routing around transformer blocks3.4. Routing implementation3.5. Sampling and 3.6. Training methods4.1. Training, isoFLOP comparisons4.2. Auto-regressive Evaluation and 4.3. Mixture-of-Depths-and-Experts (MoDE)The transformer architecture has become the workhorse of a revolution in practical artificial intelligence, bringing unprecedented capabilities at the cost of expensive training runs and serving procedures. This has spurred tremendous interest in making transformer architectures more efficient (Gupta and Agrawal, 2021; Tay et al., 2020). One of the promising approaches is conditional computation, whereby learned mechanisms determine when and how to expend computation. This terminology was introduced by Bengio (2013), and the concept was explored further over the next several years (Bengio et al., 2016, 2013; Cho and Bengio, 2014; Graves, 2016; Jernite et al., 2017; Wang et al., 2017).\
A wide variety of recent work has developed conditional computation methods for transformers. Some of this work focuses on "early exiting", that is, learning to decide when to end computation on a given token, allowing the token to skip any remaining transformer layers after the exit decision is made (Elbayad et al., 2019; Liu et al., 2021; Schuster et al., 2022). In MoD, unlike in early-exit methods, a token can skip middle layers, then be updated via self-attention with tokens that that have gone through all the middle layers. We speculate that this might be a useful property.\
Other work has developed methods for iterating transformer layers with shared weights for an adaptive number of steps (Dehghani et al., 2018; Simoulin and Crabbé, 2021). Bolya et al. (2023) developed a method for choosing tokens to merge when running inference on a trained vision transformer which notably requires no learning. Lei et al. (2023) make use of conditional computation in a fine tuning setting by building on adapter approaches (He et al., 2021) to learn to skip blocks of frozen pre-trained weights in favor of running only a small fine-tuned adapter.\
CoLT5 (Ainslie et al., 2023) uses conditional routing to select whether a given token will pass through a heavy or light pathway for each feedforward layer. Further, they use the same routing mechanism to select whether a token will attend to all other tokens or to a select few, as in Guo et al. (2022). Like MoD, CoLT5 uses soft top-k for making routing decisions. However, CoLT5 focuses on a encoder-decoder setting, and thus does need to contend with the problem of efficient sequential decoding given the non-causal nature of the top-k operation. In contrast, our current work with\
MoD focuses on the decoder-only setting, and so we propose a predictive router to enable efficient inference for conditional computation in transformers.\
One successful formulation of conditional computation is the the "mixture-of-experts" layer (MoE) as introduced by Shazeer et al. (2017). Developed initially in the context of LSTMs, later work showed compelling empirical results for MoE with transformers (Fedus et al., 2022; Lepikhin et al., 2020; Zoph et al., 2022). Unlike other conditional computation approaches that try to conserve or expend additional compute, MoE transformers use conditional logic to route tokens to one of many expert MLPs while keeping total compute expenditure constant. Our mixture-of-depths method can be thought of as using the routing logic from MoE transformers, but rather than having multiple experts, MoD deploys a single expert which can be dynamically skipped.]]></content:encoded></item><item><title>Google Researchers Develop New AI Tech That Doesn&apos;t Waste Brainpower on Useless Words</title><link>https://hackernoon.com/google-researchers-develop-new-ai-tech-that-doesnt-waste-brainpower-on-useless-words?source=rss</link><author>Writings, Papers and Blogs on Text Models</author><category>tech</category><pubDate>Sat, 22 Feb 2025 11:00:06 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) David Raposo, Google DeepMind and with equal contribution;(2) Sam Ritter, Google DeepMind;(3) Blake Richards, Google DeepMind and McGill University & Mila;(4) Timothy Lillicrap, Google DeepMind;(5) Peter Conway Humphreys, Google DeepMind;(6) Adam Santoro, Google DeepMind and with equal contribution.:::tip
Editor's note: this is part 1 of 5 of a study detailing a way to make transformer-based language models more efficient by dynamically allocating computational resources. Read the rest below.3.1. Defining a compute budget3.2. Routing around transformer blocks3.4. Routing implementation3.5. Sampling and 3.6. Training methods4.1. Training, isoFLOP comparisons4.2. Auto-regressive Evaluation and 4.3. Mixture-of-Depths-and-Experts (MoDE)\
Transformer-based language models spread FLOPs uniformly across input sequences. In this work we demonstrate that transformers can instead learn to dynamically allocate FLOPs (or compute) to specific positions in a sequence, optimising the allocation along the sequence for different layers across the model depth. Our method enforces a total compute budget by capping the number of tokens (𝑘) that can participate in the self-attention and MLP computations at a given layer. The tokens to be processed are determined by the network using a top-𝑘 routing mechanism. Since 𝑘 is defined a priori, this simple procedure uses a static computation graph with known tensor sizes, unlike other conditional computation techniques. Nevertheless, since the identities of the 𝑘 tokens are fluid, this method can expend FLOPs non-uniformly across the time and model depth dimensions. Thus, compute expenditure is entirely predictable in sum total, but dynamic and context-sensitive at the token-level. Not only do models trained in this way learn to dynamically allocate compute, they do so efficiently. These models match baseline performance for equivalent FLOPS and wall-clock times to train, but require a fraction of the FLOPs per forward pass, and can be upwards of 50% faster to step during post-training sampling.Not all problems require the same amount of time or effort to solve. Analogously, in language modeling not all tokens and sequences require the same time or effort to accurately make a prediction. And yet, transformer models expend the same amount of compute per token in a forward pass. Ideally, transformers would use smaller total compute budgets by not spending compute unnecessarily.\
Conditional computation is a technique that tries to reduce total compute by expending it only when needed (Bengio et al., 2016; Bengio, 2013; Bengio et al., 2013). Various algorithms offer solutions to when and how much compute should be used (Ainslie et al., 2023; Bapna et al., 2020; Fedus et al., 2022). However, general formulations of this challenging problem may not work well with existing hardware constraints since they tend to introduce dynamic computation graphs (Dehghani et al., 2018; Graves, 2016). The most promising conditional computation methods may instead be those that are harmonious with our current hardware stack, which prioritizes static computation graphs, and known tensor sizes that are selected to maximize hardware utilization.\
Here we consider the problem of language modeling using a static compute budget that can be made less than that used by a vanilla transformer. The network must learn how to dynamically allocate the available compute by making decisions per-token, in each layer, about where to spend compute from the available budget. In our implementation total compute is user defined and unchanging prior to training, rather than being a function of the network’s on-the-fly decisions. Thus, hardware efficiency gains—such as reduced memory footprint, or reduced FLOPs per forward pass—can be anticipated and exploited ahead of time. As we will show, these gains can be had without sacrificing overall performance.\
We leverage an approach akin to Mixture of Experts (MoE) transformers, in which dynamic token-level routing decisions are made across the network depth. Departing from MoE, we choose to either apply a computation to a token (as would be the case for a standard transformer), or pass it through a residual connection (remaining unchanged and saving compute). Also in contrast to MoE, we apply this routing to both forward MLPs and multi-head attention. Since this therefore also impacts the keys and queries we process, the routing makes decisions not only about which tokens to update, but also which tokens are made available to attend to. We refer to this strategy as Mixture-of-Depths (MoD) to emphasize how individual tokens pass through different numbers of layers, or blocks, through the depth of the transformer (see figure 1).\
The MoD technique also allows one to trade-off performance with speed. On the one hand, one can train an MoD transformer that improves upon vanilla transformers by as much as 1.5% on the final log probability training objective for equivalent training FLOPs (isoFLOP), and while taking an equivalent amount of wall-clock time to train. On the other hand, one can train an MoD transformer that achieves training loss parity with an isoFLOP optimal vanilla transformer, but which uses a fraction of the FLOPs (upwards of 50%) per forward pass, and hence is faster to step. Together, these results imply that MoD transformers learn to route intelligently (i.e., skipping computations that are unnecessary) since they can achieve equal or better log probabilities per sequence despite a smaller FLOP footprint per forward pass.]]></content:encoded></item><item><title>NASA Rover Discovers Liquid Water &apos;Ripples&apos; Carved Into Mars Rock</title><link>https://science.slashdot.org/story/25/02/22/013239/nasa-rover-discovers-liquid-water-ripples-carved-into-mars-rock?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 22 Feb 2025 10:00:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Scientists have discovered evidence of ancient, shallow lakes on Mars that once had liquid water exposed to the atmosphere, challenging previous theories that all Martian water was covered in ice. Live Science reports: The patterns, which were photographed by NASA's Curiosity rover, are known as wave ripples -- minute ridge-like structures that form along the shores of lakebeds. This means that exposed liquid water must have flowed across Mars' surface at some point in its history. The ripples were present in two separate lakebeds in Gale Crater, which Curiosity has been exploring since Aug. 2012. "The shape of the ripples could only have been formed under water that was open to the atmosphere and acted upon by wind," study first author Claire Mondro, a sedimentologist at CalTech, said in a statement.
 
The researchers also analyzed the height and spacing of the ripple waves to determine the size of the lake that formed them. The structures are approximately 0.2 inches (6 millimeters) tall and about 1.6 to 2 inches (4 to 5 centimeters) apart, indicating they were left by small waves. Based on these dimensions, the researchers believe the Martian lake must have been less than 2 meters (6.5 feet) deep. Both dry lakebeds appear to have formed around 3.7 billion years ago, indicating that Mars had an atmosphere dense and warm enough to support liquid water for longer than previously thought -- which could have intriguing implications. "Extending the length of time that liquid water was present extends the possibilities for microbial habitability later into Mars's history," Mondro said. In other words: living organisms may have had a longer window in which they could have evolved on the Red Planet. The findings have been published in the journal Science Advances.]]></content:encoded></item><item><title>The TechBeat: How to Fit an Elephant in a Spreadsheet (2/22/2025)</title><link>https://hackernoon.com/2-22-2025-techbeat?source=rss</link><author>Techbeat</author><category>tech</category><pubDate>Sat, 22 Feb 2025 07:10:59 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[By @moonlock [ 19 Min read ] 
 Moonlock Lab dives deep into a campaign tricking blockchain developers with fake job interviews to deploy malware that installs a backdoor and targets MetaMask. Read More.By @bigmao [ 6 Min read ] 
 The case against content marketing, and how to do inbound marketing in the post-content age.  Read More.By @marutitechlabs [ 6 Min read ] 
 Discover innovative solutions for fleet management with a cutting-edge mobile app and enhanced web portal.  Read More.By @juancguerrero [ 3 Min read ] 
 Tether is one of the largest holders of U.S. government debt. It's not just a stablecoin company – it's becoming America's new strategic reserve buyer. Read More.By @obyte [ 3 Min read ] 
 Crypto trading is a legitimate practice, but it involves financial risks. Also, there are fake crypto trading platforms, making empty promises to their victims. Read More.By @bigredeye [ 21 Min read ] 
 Perforator is a continuous profiling system developed by Yandex, now open-sourced.   Read More.By @thebojda [ 4 Min read ] 
 Are we living in a simulation, and if so, can we escape? This article explores Roman Yampolskiy's radical ideas on hacking reality. Read More.By @fewshot [ 6 Min read ] 
 Researchers have developed a practical, efficient alternative to massive AI models for time series forecasting.  Read More.By @jacktian [ 5 Min read ] 
 EffConPy is an open-source Python library designed to study time series beyond correlation and prediction. It provides many tools for causal discovery. Read More.By @dmitriislabko [ 14 Min read ] 
 Let's review in detail the most common mistake in relation to IEnumerable - repeated enumeration. Read More.By @scripting [ 6 Min read ] 
 Discover a faster way to cluster massive datasets without sacrificing accuracy. Read More.By @thisweekinaieng [ 5 Min read ] 
 Mistral AI has introduced Le Chat, featuring Cerebras-powered Flash Answers for enhanced response speeds.  Read More.By @muhammdusman [ 9 Min read ] 
 Complete Blockchain Development Roadmap! Learn about blockchain careers, salaries, programming languages like Solidity and JavaScript, smart contracts and more. Read More.By @uxdilettante [ 10 Min read ] 
 Do you ever feel that many job-related skills, knowledge, and expertise are becoming outdated at an almost cosmic speed nowadays? Read More.By @threadmaster [ 5 Min read ] 
 Main scenarios of using Vision with code examples that will help you understand how to work with it, understand that it is not difficult and start applying it i Read More.By @modeltuning [ 4 Min read ] 
 AI’s efficiency may unintentionally narrow human knowledge, leading to “knowledge collapse.” Learn how this shift affects innovation and cultural diversity. Read More.By @andreydidovskiy [ 7 Min read ] 
 Supply in crypto is superabundant. When supply outpaces demand, attention is diverted, liquidity gets spread unevenly, and order books become thin. But, when… Read More.By @ombirsharma [ 5 Min read ] 
 AI is transforming industries by automating tasks, enhancing efficiency, and reshaping jobs. While it replaces some roles, it creates new opportunities, Read More.]]></content:encoded></item><item><title>First Look At Secretive X-37B Space Plane In Orbit</title><link>https://science.slashdot.org/story/25/02/22/0056236/first-look-at-secretive-x-37b-space-plane-in-orbit?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 22 Feb 2025 07:00:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[The U.S. Space Force released the first-ever public image of its secretive X-37B space plane in orbit, captured during its ongoing seventh mission that launched on December 28, 2023. Space.com reports: The photo, released on Thursday (Feb. 20), was taken by a camera onboard the X-37B while the secretive space plane orbited high above the African continent. One of the plane's solar panels is visible on the left side of the photo, while what appears to be its open payload bay is visible along the top edge. The vehicle has been in orbit for well over a year now, having launched on its seventh mission on Dec. 28, 2023 atop a SpaceX Falcon Heavy rocket.
 
And now, the X-37B has notched another milestone with the Space Force's release of this photo, the first-ever image of this space plane in orbit that has been shown to the public. While the photo contains scant details about the vehicle and what it's currently testing, it offers a look at Earth far in the background, revealing just how high the vehicle is flying on its seventh mission. We've gotten only one other glimpse at the X-37B in orbit prior to this. During the livestream of its most recent launch, a brief shot of the spacecraft deploying from Falcon Heavy's upper stage was seen while its service module was still attached.]]></content:encoded></item><item><title>Ubuntu 25.04 Working To Better Cope With BitLocker-Enabled Windows, Other Improvements</title><link>https://www.phoronix.com/news/Ubuntu-25.04-Mid-Desktop</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 05:00:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Jean Baptiste Lallement was recently appointed at Canonical as the new Director of Engineering for Ubuntu Desktop. Jean Baptiste Lallement has a decade and a half history at Canonical working on Ubuntu QA, Ubuntu Phone / Unity, and other projects while now he is leading the charge on further enhancing the Ubuntu desktop initiatives. As somewhat of a mid-point for the Ubuntu 25.04 cycle, he published a Discourse post on Friday to outline some of the recent and ongoing improvements for the Ubuntu desktop...]]></content:encoded></item><item><title>Trump’s DC US Attorney Launches “Project Whirlwind” To Investigate Critics For Their Speech</title><link>https://www.techdirt.com/2025/02/21/trumps-dc-us-attorney-launches-project-whirlwind-to-investigate-critics-for-their-speech/</link><author>Mike Masnick</author><category>tech</category><pubDate>Sat, 22 Feb 2025 03:39:00 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[The Trump DOJ retribution tour has begun, as Ed Martin, Trump’s interim US Attorney for the District of Columbia, launches a series of politically motivated investigations targeting critics of Trump and Elon Musk. Martin, a former talk radio host and “Stop the Steal” supporter with no prosecutorial experience, is transforming what should be an independent office into what appears to be a personal intimidation squad.After years of baselessly crying “lawfare” over legitimate investigations into January 6th and other matters, MAGA Republicans are now demonstrating what actual politically motivated investigations look like. This is after Trump-fluffing media like the National Review declared upon Trump’s election victory that it would lead to “the end of lawfare.”Not surprisingly, we’re seeing the reverse. There are too many examples to cover right now, as the whole of the MAGA movement in government, including at both the FTC and FCC, appear to be engaging in frivolous lawfare to attack and harass those who are insufficiently sycophantic towards Trump and Elon Musk. And Ed Martin seems to be leading the pack.For what it’s worth, Martin has no background as a prosecutor. He was one of those rightwing talk radio hosts for many years as well as an occasional (unsuccessful) candidate for political office. He was one of the foolish “stop the steal” supporters who has admitted to being at the Capitol on January 6th in 2021, and claimed that what happened there was “nothing out of hand.” As a lawyer, he represented some of the January 6th defendants, raising some ethical eyebrows as one of his first moves as US Attorney was to move to dismiss a case against a defendant he himself represented. This has already resulted in a bar complaint.But Martin’s most concerning actions involve his apparent eagerness to serve as a personal attack dog for the administration. Soon after criticism of Musk’s DOGE initiative began mounting, Martin sent a particularly stupid letter to Musk and Steve Davis (one of Musk’s inner circle hatchet men), saying that he would “chase… to the end of the Earth to hold… accountable” anyone who “acted simply unethically” in regards to the government smashing that DOGE was doing.If you can’t see the image, the text reads:Thank you for the referral of individuals and networks who appear to be stealing government property and/or threatening government employees. After your referral, as is my practice, I will begin an inquiry.Please let me reiterate again: if people are discovered to have broken the law or even acted simply unethically, we will investigate them andwe will chase them to the end of the Earth to hold them accountable. We will not rest or cease in this. No one should abuse American taxpayer dollars nor American taxpayer workers.I am proud that we have been able to assist local law-enforcement in protecting the DOGE workers and others over the past week or so. A safe DC is a priority for President Trump and all of us.Please keep in touch and continue to refer matters to me as soon as possible.Setting aside Martin’s peculiar spelling choices, his letter represents a fundamental misunderstanding (or deliberate misuse) of the DOJ’s role and constitutional limitations. The DOJ is not supposed to be the personal Gestapo of anyone in the executive branch, though Martin clearly feels otherwise. Indeed, he claimed that part of the job of his office is to “protect DOGE” and “federal workers,” which seems like an odd thing to say as it is DOGE and Musk who are going around threatening and firing federal workers:In an email obtained by Rolling Stone, former “Stop the Steal” organizer turned interim U.S. Attorney Ed Martin claimed that members of Elon Musk’s so-called Department of Government Efficiency (DOGE) were receiving “despicable” threats.“We are the D.C. U.S. Attorney’s office; we are the guardians of federal workers. You and I must do whatever possible to ensure that government work is safe for all involved,” Martin wrote Wednesday, as his boss dubiously and unceremoniously fires tens of thousands of federal workers en masse, with little oversight, accountability, or rationale.But Martin’s most dangerous overreach is his attempt to criminalize what he calls “simply unethical” behavior — a standard that exists nowhere in federal law and would violate basic First Amendment principles. While there are narrow exceptions for “true threats,” decades of Supreme Court precedent has carefully limited the government’s ability to punish speech.As just one example, in the US v. Bagdasarian, the courts determined that truly horrendous speech from someone who said that President Obama should be shot (in much more graphic and problematic language) was not a true threat. To be a “true threat” speech has to show an actual “intent to commit an act of unlawful violence.”Yet Martin seems determined to ignore these well-established constitutional boundaries. Instead, he’s ramped up these politically motivated intimidation tactics, with what he’s calling “Project Whirlwind.” This is a silly name for what appears to be a plan to open frivolous investigations into Democrats who criticize Trump or Musk, falsely claiming they are “threats.”This is simple intimidation lawfare tactics of a political goon, given too much power. He kicked off this campaign with letters to Senator Chuck Schumer and Rep. Robert Garcia, claiming to be “letter of inquiry after request” which is not an actual thing.The absurdity of Martin’s campaign is perfectly illustrated by his letter to Rep. Garcia. Garcia’s supposed “threat” consisted of calling Musk a “dick” on CNN and using an obvious metaphor about bringing “weapons to this bar fight” while discussing Congress’s role in protecting democracy. Any first-year law student could tell you this is constitutionally protected speech, yet Martin treated it as grounds for a federal investigation.No one in their right mind would think that’s a threat, true or not. But Martin uses it to threaten Garcia with an investigation:As United States Attorney for the District of Columbia. I receive requests for information and clarification. I take these requests seriously and act on them with letters like this one you are receiving.At this time, I respectfully request that you clarify your comments from February 12, 2025. During a live interview with CNN, when asked how Democrats can stop Elon Musk, you spoke clearly: “What the American public wants is for us to bring actual weapons to this bar fight. This is an actual fight for democracy.”This sounds to some like a threat to Mr. Musk – an appointed representative of President Donald Trump who you call a “dick” and government staff who work for him. Their concerns have led to this inquiry.We take threats against public officials very seriously. I look forward to your cooperation with my letter of inquiry after request. Thank you in advance for your assistance. Please respond by February 24, 2025. Should you have further questions regarding this matter, please do not hesitate to call my office or schedule a time to meet in person.If the Garcia investigation seems like overreach, Martin’s pursuit of Chuck Schumer ventures into the realm of the absurd. Martin is attempting to investigate five-year-old comments Schumer made during a rally at the Supreme Court in support of Roe v. Wade (before the Court overturned it) — comments that have already been publicly debated and for which Schumer previously apologized. Schumer’s comments were pretty mild, to be honest, and clearly did not rise to the level of true threats:“I want to tell you, Gorsuch, I want to tell you, Kavanaugh, you have, and you will pay the price,” Schumer said.Martin’s choice of “Project Whirlwind” as a name — clearly meant to mock Schumer’s five-year-old “whirlwind” comment — reveals both the pettiness and political motivation behind these investigations. Martin sent a series of letters to Schumer demanding he explain himself, saying “no one is above the law.” Even while Schumer’s office did respond to Martin saying (accurately) that his comments were “not a threat to physically harm any person,” Martin still sent another letter nearly a week later falsely claiming that Schumer never responded. Hilariously, Martin says:You have failed to respond which is a personal disappointment and professionally unacceptable.Martin’s performative outrage over a “personal disappointment” would be comical if it weren’t so dangerous. His willingness to investigate five-year-old comments that resulted in exactly zero acts of violence demonstrates this isn’t about public safety — it’s about intimidation.The real “professionally unacceptable” behavior here is Martin’s transformation of the DC US Attorney’s office into a political weapon aimed at critics of the administration. Indeed, not that they care, but Martin’s actions quite clearly violate the Trump Executive Order “ending federal censorship” which declares that no federal government employee should engage in “any conduct that would unconstitutionally abridge the free speech of any American citizen.”There may be a silver lining to Martin’s amateurish, heavy-handed approach. As former Justice Department prosecutor Brendan Ballou points out, Martin’s obvious political motivations and incompetence might be his undoing.Because of Martin’s inexperience, he will need to persuade someone in his office to carry out his projects. Thus far, he seems to have done a terrible job of ingratiating himself to others: Most recently, the office’s topcriminal prosecutor resignedrather than follow his allegedly improper orders. One former prosecutor in the office said, “He’s a fantastically bad manager—a tone deaf bully who inspires ridicule rather than trust.” Perhaps as a result, Martin’s officewide emails are often leaked,including a message complaining about leaksAnd this is where public discontent can play a role. The more unpopular Martin’s unethical or illegal schemes can be made, the less likely it is that he will find lawyers willing to implement them. The more unpopular his plans, the less likely he will be to receive the permanent position: If the Senate does not confirm Martin within 120 days of his interim appointment, the D.C. court may choose a replacement until the body acts.The public should continue to speak out—in articles, in protests, and in tweets. Former leaders of the U.S. attorney’s office should talk too. They may be reluctant to criticize Martin’s most egregious actions, for fear of seeming to politicize the work of the office. But that work is already being politicized, and former senior prosecutors can speak to returning the office to the best of what it was and can be again.The MAGA movement’s hypocrisy is so blatant and so obvious that they don’t seem to care much if anyone realizes they’re absolutely and gleefully doing the very kinds of things they falsely accused the Biden administration of doing.But for people who live in reality, it is important not to look away from what they’re doing and to call out the truth.]]></content:encoded></item><item><title>A Brief Review of the Lie Group and the Geometries of SPD Manifolds</title><link>https://hackernoon.com/a-brief-review-of-the-lie-group-and-the-geometries-of-spd-manifolds?source=rss</link><author>Batching</author><category>tech</category><pubDate>Sat, 22 Feb 2025 03:34:54 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[3. Revisiting NormalizationThis section provides a brief review of the Lie group and the geometries of SPD manifolds. For more in-depth discussions, please refer to Tu (2011); Do Carmo & Flaherty Francis (1992).\
A Lie group is a group and also a manifold. The most natural Riemannian metric on a Lie group is the left-invariant metric[1]. Similarly, one can define the right-invariant metric as Def. 2.2. A biinvariant Riemannian metric is the one with both left and right invariance. Given the analogous properties of left and right-invariant metrics, this paper focuses on left-invariant metrics.\
The idea of pullback is ubiquitous in differential geometry and can be considered as a natural counterpart of bijection in the set theory.[1] Left invariant metric always exists for every Lie group (Do Carmo & Flaherty Francis, 1992).(1) Ziheng Chen, University of Trento;(2) Yue Song, University of Trento and a Corresponding author;(3) Yunmei Liu, University of Louisville;(4) Nicu Sebe, University of Trento.]]></content:encoded></item><item><title>Mark Zuckerberg&apos;s Makeover Didn&apos;t Make People Like Him, Study Shows</title><link>https://tech.slashdot.org/story/25/02/22/0048209/mark-zuckerbergs-makeover-didnt-make-people-like-him-study-shows?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 22 Feb 2025 03:30:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[An anonymous reader quotes a report from TechCrunch: A study by the Pew Research Center found that Americans' views of Elon Musk and Mark Zuckerberg skew more negative than positive. While Zuckerberg has sparked chatter in Silicon Valley with his sudden interest in high fashion, the Meta CEO is less popular than President Trump's right-hand man, Elon Musk, the report found. While about 54% of U.S. adults say they have an unfavorable view of Musk, 67% feel negatively toward Zuckerberg. [...] But Zuckerberg, the Facebook founder, is more universally disliked, though he draws more ire from the left-leaning demographic. While 60% of Republican and Republican-leaning respondents hold an unfavorable view of Zuckerberg, 76% of their Democratic counterparts share that sentiment.
 
So, while Zuck may be playing the part of the cool guy, Americans haven't been fooled by his gold chains or musical ambitions, it seems. Pew's study involved a panel of 5,086 randomly selected U.S. adults. The survey was conducted from January 27, 2025, through February 2, 2025, so these responses reflect people's recent opinions.]]></content:encoded></item><item><title>A Lie Group Approach to Riemannian Batch Normalization</title><link>https://hackernoon.com/a-lie-group-approach-to-riemannian-batch-normalization?source=rss</link><author>Batching</author><category>tech</category><pubDate>Sat, 22 Feb 2025 03:27:49 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[3. Revisiting NormalizationManifold-valued measurements exist in numerous applications within computer vision and machine learning. Recent studies have extended Deep Neural Networks (DNNs) to manifolds, and concomitantly, normalization techniques have also been adapted to several manifolds, referred to as Riemannian normalization. Nonetheless, most of the existing Riemannian normalization methods have been derived in an ad hoc manner and only apply to specific manifolds. This paper establishes a unified framework for Riemannian Batch Normalization (RBN) techniques on Lie groups. \
Our framework offers the theoretical guarantee of controlling both the Riemannian mean and variance. Empirically, we focus on Symmetric Positive Definite (SPD) manifolds, which possess three distinct types of Lie group structures. Using the deformation concept, we generalize the existing Lie groups on SPD manifolds into three families of parameterized Lie groups. Specific normalization layers induced by these Lie groups are then proposed for SPD neural networks. We demonstrate the effectiveness of our approach through three sets of experiments: radar recognition, human action recognition, and electroencephalography (EEG) classification. The code is available at https://github.com/GitZH-Chen/LieBN.git.Over the past decade or so, Deep Neural Networks (DNNs) have achieved remarkable progress across various scientific fields (Hochreiter & Schmidhuber, 1997; Krizhevsky et al., 2012; He et al., 2016; Vaswani et al., 2017). Conventionally, DNNs have been developed with the underlying assumption of the Euclidean geometry inherent to input data. Nonetheless, there exists a plethora of applications wherein the latent spaces are defined by non-Euclidean structures such as manifolds (Bronstein et al., 2017). \
To address this issue, researchers have attempted to extend various types of DNNs to manifolds based on the theories of Riemannian geometry (Huang & Van Gool, 2017; Huang et al., 2017; 2018; Ganea et al., 2018; Chakraborty et al., 2018; Brooks et al., 2019a;e;c;d; Brooks, 2020; Brooks et al., 2020; Chen et al., 2020; Chakraborty et al., 2020; Chakraborty, 2020; Chen et al., 2021; Wang et al., 2022b;a; Nguyen, 2022a;b; Nguyen & Yang, 2023; Chen et al., 2023c;e;b; Wang et al., 2024).\
Motivated by the great success of normalization techniques within DNNs (Ioffe & Szegedy, 2015; Ba et al., 2016; Ulyanov et al., 2016; Wu & He, 2018; Chen et al., 2023a), researchers have sought to devise normalization layers tailored for manifold-valued data. Brooks et al. (2019b) introduced Riemannian Batch Normalization (RBN) specifically designed for SPD manifolds, with the ability to regulate the Riemannian mean. This approach was further refined in Kobler et al. (2022b) to extend the control over the Riemannian variance. However, the above methods are constrained within the affine-invariant metric (AIM) on SPD manifolds, limiting their applicability and generality. \
On the other hand, Chakraborty (2020) proposed two distinct Riemannian normalization frameworks, one tailored for Riemannian homogeneous spaces and the other catering to matrix Lie groups. Nonetheless, the normalization designed for Riemannian homogeneous spaces cannot regulate mean nor variance, while the normalization approach for matrix Lie groups is confined to a specific type of distance (Chakraborty, 2020, Sec. 3.2). A principled Riemannian normalization framework capable of controlling both Riemannian mean and variance remains unexplored.\
Given that Batch Normalization (BN) (Ioffe & Szegedy, 2015) serves as the foundational prototype for various types of normalization, our paper only concentrates on RBN currently and can be readily extended to other normalization techniques. As several manifold-valued measurements form Lie groups, including SPD manifolds, Special Orthogonal (SO) groups, and Special Euclidean (SE) groups, we further direct our attention towards Lie groups. We propose a general framework for RBN over Lie groups, referred to as LieBN, and validate our approach in normalizing both the Riemannian mean and variance. \
On the empirical side, we focus on SPD manifolds, where three distinct types of Lie groups have been recognized in the literature. We generalize these existing Lie groups into parameterized forms through the deformation concept. Then, we showcase our LieBN framework on SPD manifolds under these Lie groups and propose specific normalization layers. Extensive experiments conducted on widely-used SPD benchmarks demonstrate the effectiveness of our framework. We highlight that our work is entirely theoretically different from Brooks et al. (2019b); Kobler et al. (2022a); Lou et al. (2020), and more general than Chakraborty (2020). The previous RBN methods are either designed for a specific manifold or metric (Brooks et al., 2019b; Kobler et al., 2022a; Chakraborty, 2020), or fail to control mean and variance (Lou et al., 2020), while our LieBN guarantees the normalization of mean and variance on general Lie groups. \
In summary, our main contributions are as follows: (a) a general Lie group batch normalization framework with controllable first- and second-order statistical moments, and (b) the specific construction of our LieBN layers on SPD manifolds based on three deformed Lie groups and their application on SPD neural networks. Due to page limites, all the proofs are placed in App. I.(1) Ziheng Chen, University of Trento;(2) Yue Song, University of Trento and a Corresponding author;(3) Yunmei Liu, University of Louisville;(4) Nicu Sebe, University of Trento.]]></content:encoded></item><item><title>Appendices on Our Dark Matter Study</title><link>https://hackernoon.com/appendices-on-our-dark-matter-study?source=rss</link><author>Phenomenology Technology</author><category>tech</category><pubDate>Sat, 22 Feb 2025 02:54:20 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[\
The kinetic term for the fermions (leptons and quarks) is given by\
The Yukawa interactions for the leptons and quarks are given byOur universe at a large scale can be described well if we assume isotropy and homogeneity of space. The Friedmann-Lemaitre-Robertson-Walker (FLRW) metric hold these assumptions, which is given by,\
\
here p and 𝜌 are the pressure and energy density of the fluid respectively whereas 𝑢𝜇 is the velocity vector in comoving coordinates. One can now derive the Friedmann equations as\
\
Using the above two equations, one can derive the density evolution equation,\
\
where H is the Hubble parameter.C Type I seasaw mechanism\
\
here subscript c stands for charge conjugation. Now one can write the above expression as follows\
\
One can diagonalize the above mass matrix and can get mass eigenstates corresponding to\
\
This naturally explains the smallness of neutrino masses.The relevant Feynman diagram for relic density analysis of scalar and fermion DM are shown in Figs. D.1 and D.2, respectively.[1] Y. Sofue, Y. Tutui, M. Honma, A. Tomita, T. Takamiya, J. Koda, and Y. Takeda, Central rotation curves of spiral galaxies, The Astrophysical Journal 523 no. 1, (Sep, 1999) 136–146. https://doi.org/10.1086/307731.\
[2] D. Clowe, M. Bradač, A. H. Gonzalez, M. Markevitch, S. W. Randall, C. Jones, and D. Zaritsky, A direct empirical proof of the existence of dark matter, The Astrophysical Journal 648 no. 2, (Aug., 2006) L109–L113. http://dx.doi.org/10.1086/508162.\
[3] K. Garrett and G. Duda, Dark matter: A primer, Advances in Astronomy 2011 (2011) 1–22. https://doi.org/10.1155%2F2011%2F968283.\
[4] J. Cooley, Overview of non-liquid noble direct detection dark matter experiments, Physics of the Dark Universe 4 (Sep, 2014) 92–97. https://doi.org/10.1016%2Fj.dark.2014.10.005.\
[5] Limits to dark matter annihilation cross-section from a combined analysis of MAGIC and fermi-LAT observations of dwarf satellite galaxies, Feb, 2016. https://doi.org/10.1088%2F1475-7516%2F2016%2F02%2F039.\
[6] G. Elor, N. L. Rodd, T. R. Slatyer, and W. Xue, Model-Independent Indirect Detection Constraints on Hidden Sector Dark Matter, JCAP 06 (2016) 024, arXiv:1511.08787 [hep-ph].\
[7] HESS Collaboration, H. Abdallah et al., Search for 𝛾-Ray Line Signals from Dark Matter Annihilations in the Inner Galactic Halo from 10 Years of Observations with H.E.S.S., Phys. Rev. Lett. 120 no. 20, (2018) 201101, arXiv:1805.05741 [astro-ph.HE].\
[8] Fermi-LAT Collaboration, M. Ackermann et al., Search for Gamma-ray Spectral Lines with the Fermi Large Area Telescope and Dark Matter Implications, Phys. Rev. D 88 (2013) 082002, arXiv:1305.5597 [astro-ph.HE].\
[9] ALEPH, DELPHI, L3, OPAL, LEP Electroweak Collaboration, S. Schael et al., Electroweak Measurements in Electron-Positron Collisions at W-Boson-Pair Energies at LEP, Phys. Rept. 532 (2013) 119–244, arXiv:1302.3415 [hep-ex].\
[10] ATLAS Collaboration, G. Aad et al., Search for high-mass dilepton resonances using 139 fb−1 of 𝑝 𝑝 collision data collected at √ 𝑠 =13 TeV with the ATLAS detector, Phys. Lett. B 796 (2019) 68–87, arXiv:1903.06248 [hep-ex].\
[11] CMS Collaboration, Search for a narrow resonance in high-mass dilepton final states in proton-proton collisions using 140 fb−1 of data at √ 𝑠 = 13 TeV, 2019.\
[12] ATLAS Collaboration, Search for New Phenomena in Dĳet Events using 139 fb−1 of 𝑝 𝑝 collisions at √ 𝑠 = 13TeV collected with the ATLAS Detector, 3, 2019.\
[13] CMS Collaboration, A. M. Sirunyan et al., Search for narrow and broad dĳet resonances in proton-proton collisions at √ 𝑠 = 13 TeV and constraints on dark matter mediators and other new particles, JHEP 08 (2018) 130, arXiv:1806.00843 [hep-ex].\
[14] A. Das, P. S. B. Dev, Y. Hosotani, and S. Mandal, Probing the minimal 𝑈(1)𝑋 model at future electron-positron colliders via the fermion pair-production channel, arXiv:2104.10902 [hep-ph]\
[15] J. de Blas et al., The CLIC Potential for New Physics, arXiv:1812.02093 [hep-ph].\
[16] LEP Working Group for Higgs boson searches, ALEPH, DELPHI, L3, OPAL Collaboration, R. Barate et al., Search for the standard model Higgs boson at LEP, Phys. Lett. B 565 (2003) 61–75, arXiv:hep-ex/0306033.\
[17] Y. Wang, M. Berggren, and J. List, ILD Benchmark: Search for Extra Scalars Produced in Association with a 𝑍 boson at √ 𝑠 = 500 GeV, arXiv:2005.06265 [hep-ex].\
[18] XENON Collaboration, E. Aprile et al., Dark Matter Search Results from a One Ton-Year Exposure of XENON1T, Phys. Rev. Lett. 121 no. 11, (2018) 111302, arXiv:1805.12562 [astro-ph.CO].\
[19] J. Billard, L. Strigari, and E. Figueroa-Feliciano, Implication of neutrino backgrounds on the reach of next generation dark matter direct detection experiments, Phys. Rev. D 89 no. 2, (2014) 023524, arXiv:1307.5458 [hep-ph].\
[20] PandaX Collaboration, H. Zhang et al., Dark matter direct search sensitivity of the PandaX-4T experiment, Sci. China Phys. Mech. Astron. 62 no. 3, (2019) 31011, arXiv:1806.02229 [physics.ins-det].\
[21] LUX-ZEPLIN Collaboration, D. S. Akerib et al., Projected WIMP sensitivity of the LUX-ZEPLIN dark matter experiment, Phys. Rev. D 101 no. 5, (2020) 052002, arXiv:1802.06039 [astro-ph.IM].\
[22] LZ Collaboration, J. Aalbers et al., First Dark Matter Search Results from the LUX-ZEPLIN (LZ) Experiment, Phys. Rev. Lett. 131 no. 4, (2023) 041002, arXiv:2207.03764 [hep-ex].\
[23] XENON Collaboration, E. Aprile et al., Projected WIMP sensitivity of the XENONnT dark matter experiment, JCAP 11 (2020) 031, arXiv:2007.08796 [physics.ins-det].\
[24] E. Aprile and K. e. Abe, First dark matter search with nuclear recoils from the xenonnt experiment, Physical Review Letters 131 no. 4, (July, 2023) . http://dx.doi.org/10.1103/PhysRevLett.131.041003.\
[25] GADMC Collaboration, C. Galbiati et al., Future Dark Matter Searches with Low-Radioactivity Argon, 2018. https://indico.cern.ch/event/765096/contributions/3295671/ attachments/1785196/2906164/DarkSide-ArgoDec2017.pdf.\
[26] DARWIN Collaboration, J. Aalbers et al., DARWIN: towards the ultimate dark matter detector, JCAP 11 (2016) 017, arXiv:1606.07001 [astro-ph.IM].\
[27] J. Billard et al., Direct Detection of Dark Matter – APPEC Committee Report, arXiv:2104.07634 [hep-ex].\
[28] M. G. Baring, T. Ghosh, F. S. Queiroz, and K. Sinha, New limits on the dark matter lifetime from dwarf spheroidal galaxies using fermi-LAT, Physical Review D 93 no. 10, (May, 2016) . https://doi.org/10.1103%2Fphysrevd.93.103009.\
[29] C. A. J. O’Hare, New definition of the neutrino floor for direct dark matter searches, Physical Review Letters 127 no. 25, (Dec, 2021) . https://doi.org/10.1103%2Fphysrevlett.127.251802.\
[30] A. Das, S. Gola, S. Mandal, and N. Sinha, Two-component scalar and fermionic dark matter candidates in a generic U(1)X model, Phys. Lett. B 829 (2022) 137117, arXiv:2202.01443 [hep-ph].\
[31] S. Profumo, K. Sigurdson, and L. Ubaldi, Can we discover multi-component WIMP dark matter?, JCAP 12 (2009) 016, arXiv:0907.4374 [hep-ph].\
[32] M. Lisanti, Lectures on Dark Matter Physics, in Theoretical Advanced Study Institute in Elementary Particle Physics: New Frontiers in Fields and Strings, pp. 399–446. 2017. arXiv:1603.03797 [hep-ph].\
[33] E. W. Kolb and M. S. Turner, The Early Universe, 1990.\
[34] M. Bartelmann and P. Schneider, Weak gravitational lensing, Phys. Rept. 340 (2001) 291–472, arXiv:astro-ph/9912508.\
[35] D. Clowe, A. Gonzalez, and M. Markevitch, Weak lensing mass reconstruction of the interacting cluster 1E0657-558: Direct evidence for the existence of dark matter, Astrophys. J. 604 (2004) 596–603, arXiv:astro-ph/0312273.\
[36] D. Harvey, R. Massey, T. Kitching, A. Taylor, and E. Tittley, The non-gravitational interactions of dark matter in colliding galaxy clusters, Science 347 (2015) 1462–1465, arXiv:1503.07675 [astro-ph.CO].\
[37] WMAP Collaboration, G. Hinshaw et al., Nine-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations: Cosmological Parameter Results, Astrophys. J. Suppl. 208 (2013) 19, arXiv:1212.5226 [astro-ph.CO].\
[38] Planck Collaboration, P. A. R. Ade et al., Planck 2015 results. XIII. Cosmological parameters, Astron. Astrophys. 594 (2016) A13, arXiv:1502.01589 [astro-ph.CO].\
[39] Planck Collaboration, N. Aghanim et al., Planck 2018 results. VI. Cosmological parameters, Astron. Astrophys. 641 (2020) A6, arXiv:1807.06209 [astro-ph.CO].\
[40] W. T. Kelvin, The index, p. [695]-703, was issued separately with cover-title: Index to Lord Kelvin’s volume of Baltimore lectures. Cambridge, Printed at the University press, 1905, Cambridge, Printed at the University press (1904) .\
[41] J. H. Oort, The force exerted by the stellar system in the direction perpendicular to the galactic plane and some related problems, bain 6 (Aug., 1932) 249.\
[42] F. Zwicky, On the Masses of Nebulae and of Clusters of Nebulae, apj 86 (Oct., 1937) 217.\
[43] V. C. Rubin, Dark matter in spiral galaxies, Scientific American 248 no. 6, (1983) 96–109. http://www.jstor.org/stable/24968923.\
[44] D. Walsh, R. F. Carswell, and R. J. Weymann, 0957+561 A, B: twin quasistellar objects or gravitational lens?, nat 279 (May, 1979) 381–384.\
[45] A. A. Penzias and R. W. Wilson, A Measurement of Excess Antenna Temperature at 4080 Mc/s., apj 142 (July, 1965) 419–421.\
[46] G. Bertone and D. Hooper, History of dark matter, Oct, 2018. https://doi.org/10.1103%2Frevmodphys.90.045002.\
[47] C. A. Argüelles, K. J. Kelly, and V. M. Muñoz, Millicharged particles from the heavens: single- and multiple-scattering signatures, Journal of High Energy Physics 2021 no. 11, (Nov., 2021) . http://dx.doi.org/10.1007/JHEP11(2021)099.\
[48] S. Profumo, L. Giani, and O. F. Piattella, An Introduction to Particle Dark Matter, Universe 5 no. 10, (2019) 213, arXiv:1910.05610 [hep-ph].\
[49] Planck Collaboration, N. Aghanim et al., Planck 2018 results. VI. Cosmological parameters, Astron. Astrophys. 641 (2020) A6, arXiv:1807.06209 [astro-ph.CO].\
[50] G. Danby, J.-M. Gaillard, K. Goulianos, L. M. Lederman, N. Mistry, M. Schwartz, and J. Steinberger, Observation of high-energy neutrino reactions and the existence of two kinds of neutrinos, Phys. Rev. Lett. 9 (Jul, 1962) 36–44. https://link.aps.org/doi/10.1103/PhysRevLett.9.36.\
[51] T. Kajita, Nobel Lecture: Discovery of atmospheric neutrino oscillations, Rev. Mod. Phys. 88 no. 3, (2016) 030501.\
[52] A. de Gouvêa, Neutrino mass models, Annual Review of Nuclear and Particle Science 66 no. 1, (2016) 197–217, https://doi.org/10.1146/annurev-nucl-102115-044600. https://doi.org/10.1146/annurev-nucl-102115-044600.\
[53] P. F. de Salas, D. V. Forero, S. Gariazzo, P. Martínez-Miravé, O. Mena, C. A. Ternes, M. Tórtola, and J. W. F. Valle, 2020 global reassessment of the neutrino oscillation picture, JHEP 02 (2021) 071, arXiv:2006.11237 [hep-ph].\
[54] M. Lattanzi and M. Gerbino, Status of neutrino properties and future prospects - Cosmological and astrophysical constraints, Front. in Phys. 5 (2018) 70, arXiv:1712.07109 [astro-ph.CO].\
[55] V. De Luca, A. Mitridate, M. Redi, J. Smirnov, and A. Strumia, Colored dark matter, Physical Review D 97 no. 11, (June, 2018) . http://dx.doi.org/10.1103/PhysRevD.97.115024.\
[56] S.-M. Choi, J. Kim, P. Ko, and J. Li, A multi-component SIMP model with 𝑈(1)𝑋 → 𝑍2 × 𝑍3, JHEP 09 (2021) 028, arXiv:2103.05956 [hep-ph].\
[57] S.-Y. Ho, P. Ko, and C.-T. Lu, Scalar and Fermion Two-component SIMP Dark Matter with an Accidental Z4 Symmetry, arXiv:2201.06856 [hep-ph].\
[58] G. Bélanger, F. Boudjema, A. Goudelis, A. Pukhov, and B. Zaldivar, micrOMEGAs5.0 : Freeze-in, Comput. Phys. Commun. 231 (2018) 173–186, arXiv:1801.03509 [hep-ph].\
[59] T. Bringmann, P. F. Depta, M. Hufnagel, J. T. Ruderman, and K. Schmidt-Hoberg, Dark matter from exponential growth, Physical Review Letters 127 no. 19, (Nov., 2021) . http://dx.doi.org/10.1103/PhysRevLett.127.191802.\
[60] L. Di Luzio, M. Giannotti, E. Nardi, and L. Visinelli, The landscape of qcd axion models, Physics Reports 870 (July, 2020) 1–117. http://dx.doi.org/10.1016/j.physrep.2020.06.002.\
[61] E. G. M. Ferreira, Ultra-light dark matter, The Astronomy and Astrophysics Review 29 no. 1, (Sept., 2021) . http://dx.doi.org/10.1007/s00159-021-00135-6.\
[62] A. Boyarsky, M. Drewes, T. Lasserre, S. Mertens, and O. Ruchayskiy, Sterile neutrino dark matter, Progress in Particle and Nuclear Physics 104 (Jan., 2019) 1–45. http://dx.doi.org/10.1016/j.ppnp.2018.07.004.\
[63] D. Hooper and S. Profumo, Dark matter and collider phenomenology of universal extra dimensions, Physics Reports 453 no. 2–4, (Dec., 2007) 29–115. http://dx.doi.org/10.1016/j.physrep.2007.09.003.\
[64] C. e. Alcock, Eros and macho combined limits on planetary-mass dark matter in the galactic halo, The Astrophysical Journal 499 no. 1, (May, 1998) L9–L12. http://dx.doi.org/10.1086/311355.\
[65] LUX Collaboration, D. S. Akerib et al., Results from a search for dark matter in the complete LUX exposure, Phys. Rev. Lett. 118 no. 2, (2017) 021303, arXiv:1608.07648 [astro-ph.CO].\
[66] XENON Collaboration, E. Aprile et al., Dark Matter Search Results from a One Ton-Year Exposure of XENON1T, Phys. Rev. Lett. 121 no. 11, (2018) 111302, arXiv:1805.12562 [astro-ph.CO].\
[67] IceCube Collaboration Collaboration, A. et al., Limits on a muon flux from neutralino annihilations in the sun with the icecube 22-string detector, Phys. Rev. Lett. 102 (May, 2009) 201302. https://link.aps.org/doi/10.1103/PhysRevLett.102.201302.\
[69] PAMELA Collaboration, O. Adriani et al., An anomalous positron abundance in cosmic rays with energies 1.5-100 GeV, Nature 458 (2009) 607–609, arXiv:0810.4995 [astro-ph].\
[70] M. Bauer and T. Plehn, Yet Another Introduction to Dark Matter: The Particle Physics Approach, vol. 959 of Lecture Notes in Physics. Springer, 2019. arXiv:1705.01987 [hep-ph].\
[71] P. Minkowski, 𝜇 → 𝑒𝛾 at a Rate of One Out of 109 Muon Decays?, Phys. Lett. B 67 (1977) 421–428.\
[72] J. Schechter and J. W. F. Valle, Neutrino Masses in SU(2) x U(1) Theories, Phys. Rev. D 22 (1980) 2227.\
[73] R. N. Mohapatra and G. Senjanovic, Neutrino Mass and Spontaneous Parity Nonconservation, Phys. Rev. Lett. 44 (1980) 912.\
[74] J. Schechter and J. W. F. Valle, Neutrino Decay and Spontaneous Violation of Lepton Number, Phys. Rev. D 25 (1982) 774.\
[75] I. Dorsner and P. Fileviez Perez, Upper Bound on the Mass of the Type III Seesaw Triplet in an SU(5) Model, JHEP 06 (2007) 029, arXiv:hep-ph/0612216.\
[76] B. Bajc, M. Nemevsek, and G. Senjanovic, Probing seesaw at LHC, Phys. Rev. D 76 (2007) 055011, arXiv:hep-ph/0703080.\
\
[77] A. de Gouvea, J. Jenkins, and N. Vasudevan, Neutrino Phenomenology of Very Low-Energy Seesaws, Phys. Rev. D 75 (2007) 013003, arXiv:hep-ph/0608147.\
[78] A. de Gouvea, GeV seesaw, accidentally small neutrino masses, and Higgs decays to neutrinos, arXiv:0706.1732 [hep-ph].\
[79] A. Abada and M. Lucente, Looking for the minimal inverse seesaw realisation, Nucl. Phys. B 885 (2014) 651–678, arXiv:1401.1507 [hep-ph].\
[80] D. Borah and A. Dasgupta, Common origin of neutrino mass, dark matter and dirac leptogenesis, Journal of Cosmology and Astroparticle Physics 2016 no. 12, (Dec, 2016) 034–034. https://doi.org/10.1088/1475-7516/2016/12/034.\
[81] P. Das and M. K. Das, Phenomenology of 𝑘𝑒𝑉 sterile neutrino in minimal extended seesaw, Int. J. Mod. Phys. A 35 no. 22, (2020) 2050125, arXiv:1908.08417 [hep-ph].\
[82] A. Merle, keV sterile neutrino Dark Matter, PoS NOW2016 (2017) 082, arXiv:1702.08430 [hep-ph].\
[83] M. Drewes et al., A White Paper on keV Sterile Neutrino Dark Matter, JCAP 01 (2017) 025, arXiv:1602.04816 [hep-ph].\
[84] A. Abada, G. Arcadi, and M. Lucente, Dark Matter in the minimal Inverse Seesaw mechanism, JCAP 10 (2014) 001, arXiv:1406.6556 [hep-ph].\
[85] R. D. Peccei, QCD, strong CP and axions, J. Korean Phys. Soc. 29 (1996) S199–S208, arXiv:hep-ph/9606475.\
[86] R. D. Peccei, The Strong CP problem and axions, Lect. Notes Phys. 741 (2008) 3–17, arXiv:hep-ph/0607268.\
[87] J. E. Kim and G. Carosi, Axions and the Strong CP Problem, Rev. Mod. Phys. 82 (2010) 557–602, arXiv:0807.3125 [hep-ph]. [Erratum: Rev.Mod.Phys. 91, 049902 (2019)].\
[88] A. Hook, TASI Lectures on the Strong CP Problem and Axions, PoS TASI2018 (2019) 004, arXiv:1812.02669 [hep-ph].\
[89] M. P. Lombardo and A. Trunin, Topology and axions in QCD, Int. J. Mod. Phys. A 35 no. 20, (2020) 2030010, arXiv:2005.06547 [hep-lat].\
[90] S. Weinberg, A New Light Boson?, Phys. Rev. Lett. 40 (1978) 223–226.\
[91] F. Wilczek, Problem of Strong 𝑃 and 𝑇 Invariance in the Presence of Instantons, Phys. Rev. Lett. 40 (1978) 279–282.\
[92] Z. G. Berezhiani and M. Y. Khlopov, Cosmology of Spontaneously Broken Gauge Family Symmetry, Z. Phys. C 49 (1991) 73–78.\
[93] J. E. Kim, Weak Interaction Singlet and Strong CP Invariance, Phys. Rev. Lett. 43 (1979) 103.\
[94] M. A. Shifman, A. I. Vainshtein, and V. I. Zakharov, Can Confinement Ensure Natural CP Invariance of Strong Interactions?, Nucl. Phys. B 166 (1980) 493–506.\
[95] M. Dine, W. Fischler, and M. Srednicki, A Simple Solution to the Strong CP Problem with a Harmless Axion, Phys. Lett. B 104 (1981) 199–202.\
[96] A. Hook, S. Kumar, Z. Liu, and R. Sundrum, High Quality QCD Axion and the LHC, Phys. Rev. Lett. 124 no. 22, (2020) 221801, arXiv:1911.12364 [hep-ph].\
[97] K. J. Kelly, S. Kumar, and Z. Liu, Heavy Axion Opportunities at the DUNE Near Detector, arXiv:2011.05995 [hep-ph].\
[98] H. Georgi, D. B. Kaplan, and L. Randall, Manifesting the Invisible Axion at Low-energies, Phys. Lett. B 169 (1986) 73–78.\
[99] I. Brivio, M. Gavela, L. Merlo, K. Mimasu, J. No, R. del Rey, and V. Sanz, ALPs Effective Field Theory and Collider Signatures, Eur. Phys. J. C 77 no. 8, (2017) 572, arXiv:1701.05379 [hep-ph].\
[100] A. Salvio, A. Strumia, and W. Xue, Thermal axion production, JCAP 01 (2014) 011, arXiv:1310.6982 [hep-ph].\
[101] Y. Hochberg, E. Kuflik, R. Mcgehee, H. Murayama, and K. Schutz, Strongly interacting massive particles through the axion portal, Phys. Rev. D 98 no. 11, (2018) 115031, arXiv:1806.10139 [hep-ph].\
[102] K. Mimasu and V. Sanz, ALPs at Colliders, JHEP 06 (2015) 173, arXiv:1409.4792 [hep-ph].\
[103] J. Jaeckel and M. Spannowsky, Probing MeV to 90 GeV axion-like particles with LEP and LHC, Phys. Lett. B 753 (2016) 482–487, arXiv:1509.00476 [hep-ph].\
[104] A. Alves, A. G. Dias, and K. Sinha, Diphotons at the 𝑍-pole in Models of the 750 GeV Resonance Decaying to Axion-Like Particles, JHEP 08 (2016) 060, arXiv:1606.06375 [hep-ph].\
[105] M. J. Dolan, F. Kahlhoefer, C. McCabe, and K. Schmidt-Hoberg, A taste of dark matter: Flavour constraints on pseudoscalar mediators, JHEP 03 (2015) 171, arXiv:1412.5174 [hep-ph]. [Erratum: JHEP 07, 103 (2015)].\
[106] E. Izaguirre, T. Lin, and B. Shuve, Searching for Axionlike Particles in Flavor-Changing Neutral Current Processes, Phys. Rev. Lett. 118 no. 11, (2017) 111802, arXiv:1611.09355 [hep-ph].\
[107] K. Choi, K. Kang, and J. E. Kim, Effects of 𝜂 ′ in low-energy axion physics, Physics Letters B 181 no. 1, (1986) 145–149. https: //www.sciencedirect.com/science/article/pii/0370269386912736.\
[108] A. Salvio and S. Scollo, Axion-Sterile-Neutrino Dark Matter, arXiv:2104.01334 [hep-ph].\
[109] A. Salvio, A Simple Motivated Completion of the Standard Model below the Planck Scale: Axions and Right-Handed Neutrinos, Phys. Lett. B 743 (2015) 428–434, arXiv:1501.03781 [hep-ph].\
[110] A. Alves, A. G. Dias, and D. D. Lopes, Probing alp-sterile neutrino couplings at the lhc, arXiv:1911.12394 [hep-ph].\
[111] A. Atre, T. Han, S. Pascoli, and B. Zhang, The Search for Heavy Majorana Neutrinos, JHEP 05 (2009) 030, arXiv:0901.3589 [hep-ph].\
[112] Particle Data Group Collaboration, K. A. Olive et al., Review of Particle Physics, Chin. Phys. C 38 (2014) 090001.\
[113] N. Vinyoles, A. Serenelli, F. L. Villante, S. Basu, J. Redondo, and J. Isern, New axion and hidden photon constraints from a solar data global fit, JCAP 10 (2015) 015, arXiv:1501.01639 [astro-ph.SR].\
[114] G. G. Raffelt, Astrophysical axion bounds, Lect. Notes Phys. 741 (2008) 51–71, arXiv:hep-ph/0611350.\
[115] A. Friedland, M. Giannotti, and M. Wise, Constraining the Axion-Photon Coupling with Massive Stars, Phys. Rev. Lett. 110 no. 6, (2013) 061101, arXiv:1210.1271 [hep-ph].\
[116] A. Ayala, I. Domínguez, M. Giannotti, A. Mirizzi, and O. Straniero, Revisiting the bound on axion-photon coupling from Globular Clusters, Phys. Rev. Lett. 113 no. 19, (2014) 191302, arXiv:1406.6053 [astro-ph.SR].\
[117] CMS Collaboration, V. Khachatryan et al., Search for dark matter, extra dimensions, and unparticles in monojet events in proton–proton collisions at √ 𝑠 = 8 TeV, Eur. Phys. J. C 75 no. 5, (2015) 235, arXiv:1408.3583 [hep-ex].\
[118] ATLAS Collaboration, G. Aad et al., Search for new phenomena in final states with an energetic jet and large missing transverse momentum in pp collisions at √ 𝑠 =8 TeV with the ATLAS detector, Eur. Phys. J. C 75 no. 7, (2015) 299, arXiv:1502.01518 [hep-ex]. [Erratum: Eur.Phys.J.C 75, 408 (2015)].\
[119] G. Krnjaic, Probing Light Thermal Dark-Matter With a Higgs Portal Mediator, Phys. Rev. D 94 no. 7, (2016) 073009, arXiv:1512.04119 [hep-ph].\
[120] J. D. Clarke, R. Foot, and R. R. Volkas, Phenomenology of a very light scalar (100 MeV < 𝑚ℎ < 10 GeV) mixing with the SM Higgs, JHEP 02 (2014) 123, arXiv:1310.8042 [hep-ph].\
[121] XENON100 Collaboration, E. Aprile et al., First Axion Results from the XENON100 Experiment, Phys. Rev. D 90 no. 6, (2014) 062009, arXiv:1404.1455 [astro-ph.CO]. [Erratum: Phys.Rev.D 95, 029904 (2017)].\
[122] N. Viaux, M. Catelan, P. B. Stetson, G. Raffelt, J. Redondo, A. A. R. Valcarce, and A. Weiss, Neutrino and axion bounds from the globular cluster M5 (NGC 5904), Phys. Rev. Lett. 111 (2013) 231301, arXiv:1311.1669 [astro-ph.SR].\
[123] O. Rodríguez-Tzompantzi, Conserved laws and dynamical structure of axions coupled to photons, Int. J. Mod. Phys. A 36 no. 33, (2021) 2150259, arXiv:2001.07101 [hep-th].\
[124] CAST Collaboration, V. Anastassopoulos et al., New CAST Limit on the Axion-Photon Interaction, Nature Phys. 13 (2017) 584–590, arXiv:1705.02290 [hep-ex].\
[125] M. Bauer, M. Heiles, M. Neubert, and A. Thamm, Axion-Like Particles at Future Colliders, Eur. Phys. J. C 79 no. 1, (2019) 74, arXiv:1808.10323 [hep-ph].\
[126] N. Vinyoles, A. Serenelli, F. L. Villante, S. Basu, J. Redondo, and J. Isern, New axion and hidden photon constraints from a solar data global fit, Journal of Cosmology and Astroparticle Physics 2015 no. 10, (2015) 015.\
[127] BaBar Collaboration, J. P. Lees et al., Search for an Axionlike Particle in 𝐵 Meson Decays, Phys. Rev. Lett. 128 no. 13, (2022) 131802, arXiv:2111.01800 [hep-ex].\
[128] E787 Collaboration, S. Adler et al., Further search for the decay K+ —> pi+ nu anti-nu in the momentum region P < 195-MeV/c, Phys. Rev. D 70 (2004) 037102, arXiv:hep-ex/0403034.\
[129] CHARM Collaboration, F. Bergsma et al., Search for Axion Like Particle Production in 400-GeV Proton - Copper Interactions, Phys. Lett. B 157 (1985) 458–462.\
[130] A. Alloul, N. D. Christensen, C. Degrande, C. Duhr, and B. Fuks, FeynRules 2.0 - A complete toolbox for tree-level phenomenology, Comput. Phys. Commun. 185 (2014) 2250–2300, arXiv:1310.1921 [hep-ph].\
[131] A. Belyaev, N. D. Christensen, and A. Pukhov, CalcHEP 3.4 for collider physics within and beyond the Standard Model, Comput. Phys. Commun. 184 (2013) 1729–1769, arXiv:1207.6082 [hep-ph].\
[132] C. Boehm, M. J. Dolan, C. McCabe, M. Spannowsky, and C. J. Wallace, Extended gamma-ray emission from Coy Dark Matter, JCAP 05 (2014) 009, arXiv:1401.6458 [hep-ph].\
[133] M. Freytsis and Z. Ligeti, On dark matter models with uniquely spin-dependent detection possibilities, Phys. Rev. D 83 (2011) 115009, arXiv:1012.5317 [hep-ph].\
[134] H.-Y. Cheng and C.-W. Chiang, Revisiting Scalar and Pseudoscalar Couplings with Nucleons, JHEP 07 (2012) 009, arXiv:1202.1292 [hep-ph].\
[135] S. Banerjee, D. Barducci, G. Bélanger, B. Fuks, A. Goudelis, and B. Zaldivar, Cornering pseudoscalar-mediated dark matter with the LHC and cosmology, JHEP 07 (2017) 080, arXiv:1705.02327 [hep-ph].\
[136] G. Jungman, M. Kamionkowski, and K. Griest, Supersymmetric dark matter, Phys. Rept. 267 (1996) 195–373, arXiv:hep-ph/9506380.\
[137] G. Bertone, D. Hooper, and J. Silk, Particle dark matter: Evidence, candidates and constraints, Phys. Rept. 405 (2005) 279–390, arXiv:hep-ph/0404175.\
[138] D. Hooper and S. Profumo, Dark Matter and Collider Phenomenology of Universal Extra Dimensions, Phys. Rept. 453 (2007) 29–115, arXiv:hep-ph/0701197.\
[139] J. McDonald, Gauge singlet scalars as cold dark matter, Phys. Rev. D 50 (1994) 3637–3649, arXiv:hep-ph/0702143.\
[140] C. P. Burgess, M. Pospelov, and T. ter Veldhuis, The Minimal model of nonbaryonic dark matter: A Singlet scalar, Nucl. Phys. B 619 (2001) 709–728, arXiv:hep-ph/0011335.\
[141] L. Lopez Honorez, E. Nezri, J. F. Oliver, and M. H. G. Tytgat, The Inert Doublet Model: An Archetype for Dark Matter, JCAP 02 (2007) 028, arXiv:hep-ph/0612275.\
[142] R. Barbieri, L. J. Hall, and V. S. Rychkov, Improved naturalness with a heavy Higgs: An Alternative road to LHC physics, Phys. Rev. D 74 (2006) 015007, arXiv:hep-ph/0603188.\
[143] L. Lopez-Honorez, T. Schwetz, and J. Zupan, Higgs portal, fermionic dark matter, and a Standard Model like Higgs at 125 GeV, Phys. Lett. B 716 (2012) 179–185, arXiv:1203.2064 [hep-ph].\
[144] N. Okada and S. Okada, 𝑍 ′ -portal right-handed neutrino dark matter in the minimal U(1)𝑋 extended Standard Model, Phys. Rev. D 95 no. 3, (2017) 035025, arXiv:1611.02672 [hep-ph].\
[145] P. Bandyopadhyay, E. J. Chun, and R. Mandal, Implications of right-handed neutrinos in 𝐵 − 𝐿 extended standard model with scalar dark matter, Phys. Rev. D 97 no. 1, (2018) 015001, arXiv:1707.00874 [hep-ph].\
[146] A. Das, S. Goswami, K. N. Vishnudath, and T. Nomura, Constraining a general U(1)′ inverse seesaw model from vacuum stability, dark matter and collider, Phys. Rev. D 101 no. 5, (2020) 055026, arXiv:1905.00201 [hep-ph].\
[147] A. Das, S. Oda, N. Okada, and D.-s. Takahashi, Classically conformal U(1)’ extended standard model, electroweak vacuum stability, and LHC Run-2 bounds, Phys. Rev. D 93 no. 11, (2016) 115038, arXiv:1605.01157 [hep-ph].\
[148] E. Ma, Verifiable radiative seesaw mechanism of neutrino mass and dark matter, Phys. Rev. D 73 (2006) 077301, arXiv:hep-ph/0601225.\
[149] M. Hirsch, R. A. Lineros, S. Morisi, J. Palacio, N. Rojas, and J. W. F. Valle, WIMP dark matter as radiative neutrino mass messenger, JHEP 10 (2013) 149, arXiv:1307.8134 [hep-ph].\
[150] A. Merle, M. Platscher, N. Rojas, J. W. F. Valle, and A. Vicente, Consistency of WIMP Dark Matter as radiative neutrino mass messenger, JHEP 07 (2016) 013, arXiv:1603.05685 [hep-ph].\
[151] I. M. Ávila, V. De Romeri, L. Duarte, and J. W. F. Valle, Phenomenology of scotogenic scalar dark matter, Eur. Phys. J. C 80 no. 10, (2020) 908, arXiv:1910.08422 [hep-ph].\
[152] S. Mandal, R. Srivastava, and J. W. F. Valle, The simplest scoto-seesaw model: WIMP dark matter phenomenology and Higgs vacuum stability, Phys. Lett. B 819 (2021) 136458, arXiv:2104.13401 [hep-ph].\
[153] S. Mandal, N. Rojas, R. Srivastava, and J. W. F. Valle, Dark matter as the origin of neutrino mass in the inverse seesaw mechanism, Phys. Lett. B 821 (2021) 136609, arXiv:1907.07728 [hep-ph].\
[154] D. Feldman, Z. Liu, P. Nath, and G. Peim, Multicomponent Dark Matter in Supersymmetric Hidden Sector Extensions, Phys. Rev. D 81 (2010) 095017, arXiv:1004.0649 [hep-ph].\
[155] H. Baer, A. Lessa, S. Rajagopalan, and W. Sreethawong, Mixed axion/neutralino cold dark matter in supersymmetric models, JCAP 06 (2011) 031, arXiv:1103.5413 [hep-ph].\
[156] M. Aoki, M. Duerr, J. Kubo, and H. Takano, Multi-Component Dark Matter Systems and Their Observation Prospects, Phys. Rev. D 86 (2012) 076015, arXiv:1207.3318 [hep-ph].\
[157] S. Bhattacharya, A. Drozd, B. Grzadkowski, and J. Wudka, Two-Component Dark Matter, JHEP 10 (2013) 158, arXiv:1309.2986 [hep-ph].\
[158] L. Bian, R. Ding, and B. Zhu, Two Component Higgs-Portal Dark Matter, Phys. Lett. B 728 (2014) 105–113, arXiv:1308.3851 [hep-ph].\
[159] Y. Kajiyama, H. Okada, and T. Toma, Multicomponent dark matter particles in a two-loop neutrino model, Phys. Rev. D 88 no. 1, (2013) 015029, arXiv:1303.7356 [hep-ph].\
[160] S. Esch, M. Klasen, and C. E. Yaguna, A minimal model for two-component dark matter, JHEP 09 (2014) 108, arXiv:1406.0617 [hep-ph].\
[161] S. Bhattacharya, P. Poulose, and P. Ghosh, Multipartite Interacting Scalar Dark Matter in the light of updated LUX data, JCAP 04 (2017) 043, arXiv:1607.08461 [hep-ph].\
[162] S. Bhattacharya, P. Ghosh, A. K. Saha, and A. Sil, Two component dark matter with inert Higgs doublet: neutrino mass, high scale validity and collider searches, JHEP 03 (2020) 090, arXiv:1905.12583 [hep-ph].\
[163] S. Bhattacharya, N. Chakrabarty, R. Roshan, and A. Sil, Multicomponent dark matter in extended 𝑈(1)𝐵−𝐿: neutrino mass and high scale validity, JCAP 04 (2020) 013, arXiv:1910.00612 [hep-ph].\
[164] S. Bhattacharya, P. Ghosh, T. N. Maity, and T. S. Ray, Mitigating Direct Detection Bounds in Non-minimal Higgs Portal Scalar Dark Matter Models, JHEP 10 (2017) 088, arXiv:1706.04699 [hep-ph].\
[165] B. Díaz Sáez, P. Escalona, S. Norero, and A. R. Zerwekh, Fermion singlet dark matter in a pseudoscalar dark matter portal, JHEP 10 (2021) 233, arXiv:2105.04255 [hep-ph].\
[166] A. Mohamadnejad, Electroweak phase transition and gravitational waves in a two-component dark matter model, arXiv:2111.04342 [hep-ph].\
[167] CMS Collaboration, A. M. Sirunyan et al., Search for invisible decays of a Higgs boson produced through vector boson fusion in proton-proton collisions at √ 𝑠 = 13 TeV, Phys. Lett. B 793 (2019) 520–551, arXiv:1809.05937 [hep-ex].\
[168] ATLAS Collaboration, M. Aaboud et al., Combination of searches for invisible Higgs boson decays with the ATLAS experiment, Phys. Rev. Lett. 122 no. 23, (2019) 231801, arXiv:1904.05105 [hep-ex].\
[169] V. D. Barger, W.-Y. Keung, and E. Ma, Doubling of Weak Gauge Bosons in an Extension of the Standard Model, Phys. Rev. Lett. 44 (1980) 1169.\
\
[172] D. Buttazzo, D. Redigolo, F. Sala, and A. Tesi, Fusing Vectors into Scalars at High Energy Lepton Colliders, JHEP 11 (2018) 144, arXiv:1807.04743 [hep-ph].\
[173] K. Mekala, A. F. Zarnecki, B. Grzadkowski, and M. Iglicki, Searches for invisible scalar decays at CLIC, in 28th International Workshop on Deep Inelastic Scattering and Related Subjects. 7, 2021. arXiv:2107.13903 [hep-ex].\
[174] PandaX-II Collaboration, A. Tan et al., Dark Matter Results from First 98.7 Days of Data from the PandaX-II Experiment, Phys. Rev. Lett. 117 no. 12, (2016) 121303, arXiv:1607.07400 [hep-ex].\
[175] F. Staub, Exploring new models in all detail with SARAH, Adv. High Energy Phys. 2015 (2015) 840780, arXiv:1503.04200 [hep-ph].\
[176] G. Belanger, A. Mjallal, and A. Pukhov, Recasting direct detection limits within micrOMEGAs and implication for non-standard Dark Matter scenarios, Eur. Phys. J. C 81 no. 3, (2021) 239, arXiv:2003.08621 [hep-ph].\
[177] G. Belanger, K. Kannike, A. Pukhov, and M. Raidal, Impact of semi-annihilations on dark matter phenomenology - an example of 𝑍𝑁 symmetric scalar dark matter, JCAP 04 (2012) 010, arXiv:1202.2962 [hep-ph].\
[178] Q.-H. Cao, E. Ma, J. Wudka, and C. P. Yuan, Multipartite dark matter, arXiv:0711.3881 [hep-ph].\
\
[180] J. M. Cline, K. Kainulainen, P. Scott, and C. Weniger, Update on scalar singlet dark matter, Phys. Rev. D 88 (2013) 055025, arXiv:1306.4710 [hep-ph]. [Erratum: Phys.Rev.D 92, 039906 (2015)].\
[181] G. Arcadi, S. Profumo, F. S. Queiroz, and C. Siqueira, Right-handed Neutrino Dark Matter, Neutrino Masses, and non-Standard Cosmology in a 2HDM, JCAP 12 (2020) 030, arXiv:2007.07920 [hep-ph].\
[182] LUX Collaboration, D. S. Akerib et al., Results from a search for dark matter in the complete LUX exposure, Phys. Rev. Lett. 118 no. 2, (2017) 021303, arXiv:1608.07648 [astro-ph.CO].\
[183] PandaX-II Collaboration, A. Tan et al., Dark Matter Results from First 98.7 Days of Data from the PandaX-II Experiment, Phys. Rev. Lett. 117 no. 12, (2016) 121303, arXiv:1607.07400 [hep-ex].\
[184] M. Schumann, Direct detection of WIMP dark matter: concepts and status, Journal of Physics G: Nuclear and Particle Physics 46 no. 10, (Aug, 2019) 103003. https://doi.org/10.1088%2F1361-6471%2Fab2ea5.\
[185] C. Gross, O. Lebedev, and T. Toma, Cancellation mechanism for dark-matter–nucleon interaction, Physical Review Letters 119 no. 19, (Nov, 2017) . https://doi.org/10.1103%2Fphysrevlett.119.191801.\
[186] Y. Abe, T. Toma, and K. Tsumura, Pseudo-nambu-goldstone dark matter from gauged u(1)b-l symmetry, Journal of High Energy Physics 2020 no. 5, (May, 2020) . https://doi.org/10.1007%2Fjhep05%282020%29057.\
[187] Y. Abe, T. Toma, K. Tsumura, and N. Yamatsu, Pseudo-nambu-goldstone dark matter model inspired by grand unification, Physical Review D 104 no. 3, (Aug, 2021) . https://doi.org/10.1103%2Fphysrevd.104.035011.\
[188] S. Gola, S. Mandal, and N. Sinha, ALP-portal majorana dark matter, Int. J. Mod. Phys. A 37 no. 22, (2022) 2250131, arXiv:2106.00547 [hep-ph].\
[189] N. Okada, D. Raut, and Q. Shafi, Pseudo-goldstone dark matter in a gauged 𝑏 − 𝑙 extended standard model, Physical Review D 103 no. 5, (Mar, 2021). https://doi.org/10.1103%2Fphysrevd.103.055024.\
[190] S. Oda, N. Okada, and D. suke Takahashi, Classically conformal u(1)′ extended standard model and higgs vacuum stability, Physical Review D 92 no. 1, (Jul, 2015). https://doi.org/10.1103%2Fphysrevd.92.015026.\
[191] A. Das, N. Okada, S. Okada, and D. Raut, Probing the seesaw mechanism at the 250 GeV ILC, Physics Letters B 797 (Oct, 2019) 134849. https://doi.org/10.1016%2Fj.physletb.2019.134849.\
[192] A. Das, S. Mandal, T. Nomura, and S. Shil, Heavy majorana neutrino pair production from z‘ at hadron and lepton colliders, Physical Review D 105 no. 9, (May, 2022) . https://doi.org/10.1103%2Fphysrevd.105.095031.\
[193] N. Darvishi, M. Masouminia, and A. Pilaftsis, Maximally symmetric three-higgs-doublet model, Physical Review D 104 no. 11, (Dec, 2021) . https://doi.org/10.1103%2Fphysrevd.104.115017.\
[194] T. Robens, T. Stefaniak, and J. Wittbrodt, Two-real-scalar-singlet extension of the SM: LHC phenomenology and benchmark scenarios, The European Physical Journal C 80 no. 2, (Feb, 2020) . https://doi.org/10.1140%2Fepjc%2Fs10052-020-7655-x.\
[195] K. Kannike, Vacuum Stability Conditions From Copositivity Criteria, Eur. Phys. J. C 72 (2012) 2093, arXiv:1205.3781 [hep-ph].\
[196] A. Djouadi, The anatomy of electroweak symmetry breaking, Physics Reports 457 no. 1-4, (Feb, 2008) 1–216. https://doi.org/10.1016%2Fj.physrep.2007.10.004.\
[197] ATLAS Collaboration, A. et.al., Combination of searches for invisible Higgs boson decays with the ATLAS experiment,.\
[198] K. Ishiwata and T. Toma, Probing pseudo nambu-goldstone boson dark matter at loop level, Journal of High Energy Physics 2018 no. 12, (Dec, 2018) . https://doi.org/10.1007%2Fjhep12%282018%29089.\
[199] S. L. Glashow, Partial Symmetries of Weak Interactions, Nucl. Phys. 22 (1961) 579–588.\
[200] S. Weinberg, A Model of Leptons, Phys. Rev. Lett. 19 (1967) 1264–1266.(1) Shivam Gola, The Institute of Mathematical Sciences, Chennai.]]></content:encoded></item><item><title>Dark Matter Study: Examining Several Models of WIMP</title><link>https://hackernoon.com/dark-matter-study-examining-several-models-of-wimp?source=rss</link><author>Phenomenology Technology</author><category>tech</category><pubDate>Sat, 22 Feb 2025 02:44:03 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[This thesis examines several models of Weakly Interacting Massive Particle (WIMP) dark matter and their implications from a phenomenological standpoint. These models are particularly intriguing due to the stringent constraints of direct detection experiments. In chapters 2 and 4, we explore models where the pseudo-scalar properties serve as both a mediator and a dark matter candidate, allowing them to evade the direct detection bounds. Additionally, in chapter 3, we delve into a two-component dark matter model and its relevant phenomenological features. Here, we provide a concise overview of each of these chapters.\
Chapter 2 focuses on an ALP portal fermion dark matter model. This model is minimal, consisting of three right-handed neutrinos (RHNs) and one pseudo-scalar mediator known as ALP. The two RHNs mix with the three active neutrinos, generating neutrino masses through Type I seesaw mechanism (detailed in Appendix-C). The stability of the third RHN is ensured by a Z2 symmetry, making it a viable dark matter candidate. We then proceed to analyze the constraints imposed by neutrino mixing and ALP couplings to Standard Model (SM) particles. By incorporating these experimental bounds, we investigate the parameter space that allows for fermion dark matter, taking into account relic density, direct detection, and indirect detection constraints. Remarkably, the model exhibits a significant parameter space that satisfies the relic density constraint, and it also possesses detectable signatures for indirect searches such as Fermi-LAT or HESS.\
In chapter 3, we explore a model of dark matter consisting of a scalar and fermion as components. This model is based on a generic U(1)𝑋 extension of the Standard Model (SM). To ensure the consistency of the model, we introduce three right-handed neutrinos, which necessitate the presence of the U(1)𝑋 gauge symmetry. Additionally, we incorporate two new complex scalars into the model. These scalars are singlets under the SM but carry charges under the U(1)𝑋 gauge symmetry. One of the scalars breaks the U(1)𝑋 gauge symmetry, while the other scalar is responsible for the scalar dark matter (DM).\
In this model, we also include two Z2 symmetries. One of these symmetries applies to the right-handed neutrinos, while the other symmetry applies to the new scalar. As a result, both the scalars and fermions can potentially act as DM candidates. Furthermore, the two remaining right-handed neutrinos mix with the three active neutrinos, leading to the generation of neutrino masses through a Type I seesaw mechanism\
Finally, we explore a few more U(1) models that allow for parameter space accommodating the two-component DM. This model offers a rich phenomenology and provides opportunities for testing and collaboration with colleagues. \n We have previously discussed the WIMP DM models within the framework of the ALP portal and U(1)𝑋 extension. These models have been thoroughly analyzed, taking into account various theoretical and experimental constraints. The model we have discussed addresses certain issues associated with WIMP models, particularly the lack of direct detection of WIMP DM. Additionally, our models incorporate neutrino physics, including oscillation and mass mechanisms. These bottom-up models offer a fascinating range of phenomenology that can be explored through collider-based experiments. \
However, it is worth noting that the standard DM mass in these WIMP DM models is limited to the range of a few GeV to TeV, which restricts the scope of our explored DM scenarios. There are other intriguing mass ranges for DM, such as ultralight dark matter, sub-GeV DM, and primordial black holes, among others. I intend to investigate these scenarios in future research. Furthermore, apart from considering different DM candidates, exploring the production mechanisms of DM is also an intriguing avenue for further exploration and study. \n (1) Shivam Gola, The Institute of Mathematical Sciences, Chennai.]]></content:encoded></item><item><title>Scientists Question Microsoft&apos;s Quantum Computing Claims</title><link>https://science.slashdot.org/story/25/02/22/0232239/scientists-question-microsofts-quantum-computing-claims?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Sat, 22 Feb 2025 02:33:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Microsoft's announcement of a breakthrough in quantum computing faces skepticism from physicists, who say evidence supporting the company's claims remains insufficient. 

The tech giant reported creating Majorana particles - a development it says could revolutionize quantum computing - but the accompanying peer-reviewed paper in Nature does not conclusively demonstrate this achievement, according to multiple quantum physics experts who reviewed the research. 

Microsoft's corporate vice president for quantum hardware, Chetan Nayak, acknowledged the Nature paper wasn't meant to prove the particles' existence, though he claimed measurements suggested "95% likelihood" of topological activity. The company plans to publish additional findings. 

The announcement has drawn particular scrutiny given the field's history of retracted claims. Two previous Nature papers on similar discoveries were withdrawn in 2017 and 2018, while a 2020 paper in Science involving Microsoft researchers remains under review. "This is where you cross over from the realm of science to advertising," said Jay Sau, a theoretical physicist at the University of Maryland who sometimes consults for Microsoft but wasn't involved in the current research.]]></content:encoded></item><item><title>Dark Matter Analysis: A Lifetime Study</title><link>https://hackernoon.com/dark-matter-analysis-a-lifetime-study?source=rss</link><author>Phenomenology Technology</author><category>tech</category><pubDate>Sat, 22 Feb 2025 02:12:33 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[\
 : We have fixed the following independent parameters throughout the paper for the study of our pseudo scalar particle candidate to DM.4.4.2 Relic density analysis(1) Shivam Gola, The Institute of Mathematical Sciences, Chennai.]]></content:encoded></item><item><title>Firefox 137 To Support HEVC/H.265 Video Playback On Linux With VA-API</title><link>https://www.phoronix.com/news/Firefox-137-VA-API-HEVC</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 01:33:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Anticipated for the April release of the Mozilla Firefox 137 web browser is finally supporting HEVC (H.265) video playback in an accelerated manner using the Video Acceleration API (VA-API)...]]></content:encoded></item><item><title>Data Is Very Valuable, Just Don&apos;t Ask Us To Measure It, Leaders Say</title><link>https://slashdot.org/story/25/02/22/006233/data-is-very-valuable-just-dont-ask-us-to-measure-it-leaders-say?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 22 Feb 2025 01:30:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[The Register's Lindsay Clark reports: Fifteen years of big data hype, and guess what? Less than one in four of those in charge of analytics projects actually measure the value of the activity to the organization they work for. The result from Gartner -- a staggering one considering the attention heaped on big data and its various hype-oriented successors -- found that in a survey of chief data and analytics (D&A) officers, only 22 percent had defined, tracked, and communicated business impact metrics for the bulk of their data and analytics use cases.
 
It wasn't for lack of interest though. For more than 90 percent of the 504 respondents, value-focused and outcome-focused areas of the D&A leader's role have gained dominance over the past 12 to 18 months, and will continue to be a concern in the future. It is difficult, though: 30 percent of respondents say their top challenge is the inability to measure data, analytics and AI impact on business outcomes.
 
"There is a massive value vibe around data, where many organizations talk about the value of data, desire to be data-driven, but there are few who can substantiate it," said Michael Gabbard, senior director analyst at Gartner. He added that while most chief data and analytics officers were responsible for data strategy, a third do not see putting in place an operating model as a primary responsibility. "There is a perennial gap between planning and execution for D&A leaders," he said.]]></content:encoded></item><item><title>The Judicial Conference Should Continue to Liberally Allow Amicus Briefs, a Critical Advocacy Tool</title><link>https://www.eff.org/deeplinks/2025/02/judicial-conference-should-continue-liberally-allow-amicus-briefs-critical</link><author>Sophia Cope</author><category>tech</category><enclosure url="https://www.eff.org/files/banner_library/eff30-banner-blue.jpg" length="" type=""/><pubDate>Sat, 22 Feb 2025 00:56:25 +0000</pubDate><source url="https://www.eff.org/rss/updates.xml">Deeplinks</source><content:encoded><![CDATA[EFF does a lot of things, including impact litigation, legislative lobbying, and technology development, all to fight for your civil liberties in the digital age. With litigation, we directly represent clients and also file “amicus” briefs in court cases.An amicus brief, also called a “friend-of-the-court” brief, is when we don’t represent one of the parties on either side of the “v”—instead, we provide the court with a helpful outside perspective on the case, either on behalf of ourselves or other groups, that can help the court make its decision.Amicus briefs are a core part of EFF’s legal work. Over the years, courts at all levels have extensively engaged with and cited our amicus briefs, showing that they value our thoughtful legal analysis, technical expertise, and public interest mission.EFF filed comments with the Judicial Conference sharing our thoughts on the proposed rule changes (a total of 407 comments were filed). Two proposed changes are particularly concerning.First, amicus briefs would be “disfavored” if they address issues “already mentioned” by the parties. This language is extremely broad and may significantly reduce the amount and types of amicus briefs that are filed in the circuit courts. As we said in our comments:We often file amicus briefs that expand upon issues only briefly addressed by the parties, either because of lack of space given other issues that party counsel must also address on appeal, or a lack of deep expertise by party counsel on a specific issue that EFF specializes in. We see this often in criminal appeals when we file in support of the defendant. We also file briefs that address issues mentioned by the parties but additionally explain how the relevant technology works or how the outcome of the case will impact certain other constituencies.We then shared examples of EFF amicus briefs that may have been disfavored if the “already mentioned” standard had been in effect, even though our briefs provided help to the courts. Just two examples are:In , we filed an amicus brief that addressed the core issue of the case—whether the border search exception to the Fourth Amendment’s warrant requirement applies to cell phones. We provided a detailed explanation of the privacy interests in digital devices, and a thorough Fourth Amendment analysis regarding why a warrant should be required to search digital devices at the border. The Ninth Circuit extensively engaged with our brief to vacate the defendant’s conviction.In NetChoice, LLC v. Attorney General of Florida, a First Amendment case about social media content moderation (later considered by the Supreme Court), we filed an amicus brief that elaborated on points only briefly made by the parties about the prevalence of specialized social media services reflecting a wide variety of subject matter focuses and political viewpoints. Several of the examples we provided were used by the 11th Circuit in its opinion.Second, the proposed rules would require an amicus organization (or person) to file a motion with the court and get formal approval before filing an amicus brief. This would replace the current rule, which also allows an amicus brief to be filed if both parties in the case consent (which is commonly what happens).As we stated in our comments: “Eliminating the consent provision will dramatically increase motion practice for circuit courts, putting administrative burdens on the courts as well as amicus brief filers.” We also argued that this proposed change “is not in the interests of justice.” We wrote:Having to write and file a separate motion may disincentivize certain parties from filing amicus briefs, especially people or organizations with limited resources … The circuits should … facilitate the participation by diverse organizations at all stages of the appellate process—where appeals often do not just deal with discrete disputes between parties, but instead deal with matters of constitutional and statutory interpretation that will impact the rights of Americans for years to come.Amicus briefs are a crucial part of EFF’s work in defending your digital rights, and our briefs provide valuable arguments and expertise that help the courts make informed decisions. That’s why we are calling on the Judicial Conference to reject these changes and preserve our ability to file amicus briefs in the federal appellate courts that make a difference.Your support is essential in ensuring that we can continue to fight for your digital rights—in and out of court.]]></content:encoded></item><item><title>Asus Continues Fragrant Device Trend With an Aromatic Mouse</title><link>https://hardware.slashdot.org/story/25/02/22/002225/asus-continues-fragrant-device-trend-with-an-aromatic-mouse?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 22 Feb 2025 00:50:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Asus has introduced the Fragrance Mouse, a hybrid wireless mouse that features a removable container for fragrance oils. Despite not being a gaming mouse, it includes premium features like PTFE pads, low-noise clicks rated for up to 10 million presses, and three fixed DPI settings (1200, 1600, 2400). Tom's Hardware reports: The selling point of the new mouse is its fragrance-producing capabilities. Under the mouse (right behind the AA battery housing) is a small semi-translucent container designed to house oils that give the mouse a pleasing aroma. There's no limit to what scents can be used; the container can be washed and refilled with different scents. Last year, the peripheral maker debuted an aroma-dispensing laptop that featured a fragrance dispenser at the center of the lid.]]></content:encoded></item><item><title>10 Mistakes Beginning AI Practitioners Make That You Should Avoid</title><link>https://hackernoon.com/10-mistakes-beginning-ai-practitioners-make-that-you-should-avoid?source=rss</link><author>Ravi Kumar</author><category>tech</category><pubDate>Sat, 22 Feb 2025 00:40:26 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[ shows how over 85% of AI startups fail. One of the biggest reasons is a lack of expertise, which surprisingly isn't just about numbers. The industry now suffers from a lack of professionals who can implement AI tasks effectively.\
As an AI practitioner, you're expected to understand machine learning, AI algorithms, and data analysis. You should also be able to design and implement AI solutions in real-world situations. However, attempting to do all this fast may spur a series of mistakes that reduce your expertise. Read on as I break down the 10 most common mistakes I've seen new AI practitioners make and how you can avoid them.Not Familiarizing Yourself with Foundational AI TopicsFrom the first time you chose to practice in AI, you've been bound to encounter several learning roadmaps. I wrote on one of those frameworks, and without a doubt, they're there to guide you on what to learn and how.\
The problem is most AI learners attempt to jump hoops. For instance, many people underplay the importance of basic mathematics and statistics and jump straight to data structures or Python. No, it's not okay as long as you know Python. Understanding these core topics will help you interpret data and make effective decisions when the time comes.Staying Stuck on Data PreparationSomeone called this the "" It's a trap because, most of the time, over-preparation doesn't necessarily translate to perfection. You could spend hours preparing, cleaning, and organizing data before analysis; at the end of the day, you lose sight of what matters.\
I know you're told to spend 50-80% of your time on data wrangling. While that's valid, knowing when you've done enough is equally important. The time you spend on discovery, cleaning, structuring, enriching, and validating will depend on the quality and quantity of the raw data. However, this should not exceed 70% of the time allocated to that assignment.Underestimating the Importance of Data CleaningData cleansing is a part of the data wrangling process. And yes, I mentioned not staying stuck on data wrangling. But here's the deal. Spend half the total time allocated to data wrangling on cleansing. As it's impossible to strip your skin of all the microorganisms on it, you'll still have a negligible percentage of inaccuracy after cleaning your data.\
However, if this amount is significant, it might lead to a ton of inaccurate insights that will cost you and the organization time, effort, and money. You wouldn't be inclined to use ChatGPT if every time you ask it, 'Who are you?', it says 'DeepSeek .' As a new AI practitioner, you might want to rush the process for the joy of a new AI system. But don't. Always take your time to identify and handle any issues in the dataset.Using Fancy Algorithms Without Understanding ThemOne of Rob Pike's 5 programming rules is that fancy algorithms are buggier than simple ones and are much more complicated to implement. This is also true when dealing with AI algorithms. As a beginning AI practitioner, you may be tempted to learn complex algorithms like GANs. They may make you seem cool, but not understanding them well enough is a recipe for disaster. You don't want to be caught using reinforcement learning for basic image classification.\
When starting, focus on the simple algorithms that can save you tons of hours debugging. You can slowly transition into adopting the fancy ones by practicing them on less sophisticated datasets. They'll help you ease into them and pave the way for the expert you're becoming.Having Too Many Tools in Your ToolboxAs a professional, you probably have several tools you rely on for your workflow. You wouldn't also be an engineer if you weren't tempted to try every 'great' tool that drops in the market. But whether it's data cleansing, analysis, or machine learning, it's best to master one or two tools for each part of your workflow for now.\
For example, you could choose between TensorFlow, PyTorch, or Scikit-learn for machine learning, but not all. SpaCy, Natural Language Toolkit (NLTK), and Hugging Face Transformers are all viable options for natural language processing, but don't be tempted to roll with them all.Focusing Too Much Or Too Little on MathsMathematics is as essential as any other core subject in AI learning. Concepts like algebra, probability, calculus, and statistics set the ground for future more complex theorems. As an AI practitioner, it's also crucial that you have a good understanding of maths so that you don't just know what works but how it works as well.\
Of course, computers do the math for us through programming and high-level frameworks. But it will deprive you of becoming an expert who understands the nitty-gritty of what's going on behind the code. At the same time, you do not need to know everything in mathematics to train your first neural network.Ignoring Model ValidationModel validation and evaluation is another important aspect of creating working AI solutions. If your machine learning model does not perform well on the holdout set, how can you trust it to make accurate predictions on your new dataset?\
You must always evaluate your models and measure key indicators like accuracy, recall, precision, mean squared error (MSE), F1-score, etc. Don't just split the data into two folds. Use multiple folds to train on some and assess it on others.Ignoring communication skillsIf you work for a small organization, you might be the only AI practitioner in the room most of the time. You may have to deal with only the CTO knowing what you mean by 'I employed adversarial training to augment the robustness of their convolutional neural network (CNN) against norm-bounded perturbations.'\
The truth is that even the CTO might need to digest that twice. Make explaining yourself in layman's terms second nature. Your jargon won't help the marketing team understand what's delaying the process and won't help the situation.Focusing on More Theory without Hands-on PracticeLearning is good, but you don't want to be caught in the 'ever learning, never practicing' curse. As you learn about frameworks like Keras, Numpy, or Tensorflow, ensure you practice them.\
As you dive into machine learning or deep learning algorithms, practice them. You also want to teach other people what you've learned. If you don't have mentees, write blogs about them. That's how you go from beginner to expert.The world has advanced significantly. In my opinion, part of that advancement is not needing to spend four years behind the walls of a college and thousands of dollars on tuition.\
If you already have a degree in a related field, that will make the ride easier. But if you don't, invest in online courses and certifications. Employers no longer want to see fancy degrees on your CV. They want evidence of practical experience and recognized certifications like the AWS Certified AI Practitioner.As a beginning AI practitioner, you may feel pressured to jump hoops to match everyone else's pace. But doing that will cost you knowledge and opportunities. Avoid these 10 mistakes, and you're well on becoming a professional AI practitioner.]]></content:encoded></item><item><title>Wine 10.2 Upgrades VKD3D, Supports Setting Thread Priorities</title><link>https://www.phoronix.com/news/Wine-10.2-Released</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 22 Feb 2025 00:25:59 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Following last month's release of Wine 10.0 one month ago, Wine 10.2 is now available as the newest bi-weekly development release that will culminate with the Wine 11.0 stable release in early 2026...]]></content:encoded></item><item><title>OpenAI Bans Chinese Accounts Using ChatGPT To Edit Code For Social Media Surveillance</title><link>https://tech.slashdot.org/story/25/02/21/2356205/openai-bans-chinese-accounts-using-chatgpt-to-edit-code-for-social-media-surveillance?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Sat, 22 Feb 2025 00:10:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[OpenAI has banned a group of Chinese accounts using ChatGPT to develop an AI-powered social media surveillance tool. Engadget reports: The campaign, which OpenAI calls Peer Review, saw the group prompt ChatGPT to generate sales pitches for a program those documents suggest was designed to monitor anti-Chinese sentiment on X, Facebook, YouTube, Instagram and other platforms. The operation appears to have been particularly interested in spotting calls for protests against human rights violations in China, with the intent of sharing those insights with the country's authorities.
 
"This network consisted of ChatGPT accounts that operated in a time pattern consistent with mainland Chinese business hours, prompted our models in Chinese, and used our tools with a volume and variety consistent with manual prompting, rather than automation," said OpenAI. "The operators used our models to proofread claims that their insights had been sent to Chinese embassies abroad, and to intelligence agents monitoring protests in countries including the United States, Germany and the United Kingdom."
 
According to Ben Nimmo, a principal investigator with OpenAI, this was the first time the company had uncovered an AI tool of this kind. "Threat actors sometimes give us a glimpse of what they are doing in other parts of the internet because of the way they use our AI models," Nimmo told The New York Times. Much of the code for the surveillance tool appears to have been based on an open-source version of one of Meta's Llama models. The group also appears to have used ChatGPT to generate an end-of-year performance review where it claims to have written phishing emails on behalf of clients in China.]]></content:encoded></item><item><title>The Most Effective Way to Run a Sprint Retrospective</title><link>https://hackernoon.com/the-most-effective-way-to-run-a-sprint-retrospective?source=rss</link><author>Just Another Tech Lead</author><category>tech</category><pubDate>Sat, 22 Feb 2025 00:05:12 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[I’ve been running Sprint Reviews for the last 15 years, and I truly believe them to be useful when done well.\
When Sprint Reviews are not done well, however, they are at best a waste of time and at worst give you a reduction in morale.For Sprint Retrospectives to be effective, you have to adhere to the basic rules of setting up a good scrum team:Scrum Teams should not be too big. No more than 6 people. If they are larger than that, split them. It’s harder to build team-wide trust with a larger team.A safe and open environment: You will get nothing out of a retrospective if people are afraid to speak their minds. Without real input, you will not get good actionable outcomes.Actioning: If you and your team do not put into effect the outcomes of your retros, people will lose faith and stop participating.Right. Now that we’ve got that out of the way, let’s look at the process.What is a Start, Stop, Continue Retrospective?As the name suggests, this approach focuses on three simple questions for the team:What should we  doing?What should we  doing?This framework cuts through the noise and focuses directly on actionable changes.\
Let me break down how I run these effectively.When team members suggest "start" items, they're looking at practices or behaviors we should add to our workflow.Getting customer feedback on features earlierSetting up acceptance tests with stakeholders before codingImplementing code reviewsBeing punctual for standup meetingsFocusing on finishing stories before picking up new ones\
The "" list captures inefficiencies or time-wasters. Common examples I've seen teams identify:Committing code without ensuring tests passLetting daily scrums run longer than 15 minutesSkipping refinement sessions when we feel behind scheduleThe "continue" section highlights positive practices that aren't yet habitual. Items from either the start or stop categories can move here once they're being implemented but need reinforcement. Once something becomes second nature to the team, we remove it from the list to keep it manageable.To prevent  (it’s real, believe me), I vary how we collect ideas:Sometimes, I'll simply open the floor for suggestions in any categoryOther times, I'll go around the room, asking each person to contribute one itemWhen I notice specific issues, I might focus exclusively on "" items firstOccasionally, I'll combine approaches, going person-by-person for one category, then opening up for general discussionThis flexibility keeps the format fresh even after many sprints with the same team.When idea generation slows down, it's time to vote.\
I typically use multi-voting - giving each team member three votes they can use as they wish.\
I prefer multi-voting because many retrospective actions don't actually require additional time - they're behavioral shifts. For example, being punctual for standups doesn't consume time; it saves it. Multi-voting allows us to select 2-3 key focus areas without overwhelming the team.\
We also review the "continue" list to see if any items have become habits or are no longer relevant.For the following retrospective, I bring a large sheet with all the previous ideas - both chosen and not chosen. I don't make a big deal about it - I simply tape it to the wall as a reference point.\
Then we begin a fresh , , and  the discussion.In my experience across various companies and team structures, this method is efficient, accessible, and productive.\
It's action-oriented rather than feelings-focused. Compounding is well known in the financial arena but is very rarely mentioned when it comes to team improvement. Team Retrospectives allow you to make little changes over a long period of time. If you compare the morale and ability to deliver in a team over the course of a year, with the right retrospectives in place and happening regularly, I would expect to see a large and positive change.\
While understanding emotions can be valuable in some contexts, this approach gets straight to behavioral changes.\
Every item generated leads directly to an action: starting something new, stopping something ineffective, or continuing something valuable until it becomes ingrained.\
For teams that value practical outcomes over extended discussion, the start, stop, and continue framework delivers consistently strong results.]]></content:encoded></item><item><title>Meta, X approved ads containing violent anti-Muslim, antisemitic hate speech ahead of German election, study finds</title><link>https://techcrunch.com/2025/02/21/meta-x-approved-ads-containing-violent-anti-muslim-antisemitic-hate-speech-ahead-of-german-election-study-finds/</link><author>Natasha Lomas</author><category>tech</category><pubDate>Sat, 22 Feb 2025 00:01:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Social media giants Meta and X approved ads targeting users in Germany with violent anti-Muslim and anti-Jew hate speech in the run-up to the country’s federal elections, according to new research from Eko, a corporate responsibility nonprofit campaign group. The group’s researchers tested whether the two platforms’ ad review systems would approve or reject submissions […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>The Protesters Who Want To Ban AGI Before It Even Exists</title><link>https://slashdot.org/story/25/02/21/2157258/the-protesters-who-want-to-ban-agi-before-it-even-exists?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 21 Feb 2025 23:30:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[An anonymous reader quotes a report from The Register: On Saturday at the Silverstone Cafe in San Francisco, a smattering of activists gathered to discuss plans to stop the further advancement of artificial intelligence. The name of their non-violent civil resistance group, STOP AI, makes its mission clear. The organization wants to ban something that, by most accounts, doesn't yet exist -- artificial general intelligence, or AGI, defined by OpenAI as "highly autonomous systems that outperform humans at most economically valuable work."
 
STOP AI outlines a broader set of goals on its website. For example, "We want governments to force AI companies to shut down everything related to the creation of general-purpose AI models, destroy any existing general-purpose AI model, and permanently ban their development." In answer to the question "Does STOP AI want to ban all AI?", the group's answer is, "Not necessarily, just whatever is necessary to keep humanity alive." The group, which has held protests outside OpenAI's office and plans another outside the company's San Francisco HQ on February 22, has bold goal: rally support from 3.5 percent of the U.S. population, or 11 million people. That's the so-called "tipping point" needed for societal change, based on research by political scientist Erica Chenoweth.
 
"The implications of artificial general intelligence are so immense and dangerous that we just don't want that to come about ever," said Finn van der Velde, an AI safety advocate and activist with a technical background in computer science and AI specifically. "So what that will practically mean is that we will probably need an international treaty where the governments across the board agree that we don't build AGI. And so that means disbanding companies like OpenAI that specifically have the goal to build AGI." It also means regulating compute power so that no one will be able to train an AGI model.]]></content:encoded></item><item><title>Associated Press Sues Trump Officials After Ban Over ‘Gulf Of Mexico/America’ Nonsense</title><link>https://www.techdirt.com/2025/02/21/associated-press-sues-trump-officials-after-ban-over-gulf-of-mexico-america-nonsense/</link><author>Dark Helmet</author><category>tech</category><pubDate>Fri, 21 Feb 2025 23:24:40 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[The Trump administration’s dumbest saga so far just got a bit more serious, thankfully. For the past couple of weeks, we have been talking about how, after Donald Trump ordered the government to change the name of the continental shelf extending from American land be renamed from the all-encompassing “Gulf of Mexico,” as the whole body of water has been named for centuries, to the “Gulf of America,” the administration began banning the AP from some press activities over the AP’s refusal to make that change in its influential AP Stylebook. To be more specific, the Stylebook refers to the body of water by its traditional (actual) name, while also acknowledging the new name that Trump has given it. After that initial ban, the administration actually expanded the ban on what the AP could attend while also stating that the ban is “indefinite.”In my post on the topic, I mentioned that a well-functioning press pool would at this point band together and fight back on behalf of the AP. After all, an attack on one member of the press is, in fact, an attack on all of them in the long run. Initially, this did not happen. In fact, some of the more idiotic members of the press tried to argue that any attempt to fight back would be giving Trump what he wants. As opposed to, I guess, simply letting him trample on the rights of the press and speech rights. Somehow  would  be giving him what he wants, though I can’t explain how that would be.Fortunately, the rest of the press eventually got around to doing something in the form of signing onto a protest letter. Oh, and the AP has now sued the administration for a violation of both its First and Fifth Amendment rights. The suit is embedded below for all to read, but let’s acknowledge first that the press pool, including far-right outlets, finally partook in some collective action, tepid though it may be.This week, about 40 news organizations signed onto a letter organized by the White House Correspondents Association, urging the White House to reverse its policy against the AP.Reporting indicates that signatories to that letter included both Fox News and Newsmax. When is pushing back on Trump over an attack on the press, that should really mean something.But now, onto the lawsuit. As mentioned, it claims that the administration’s actions violate both the AP’s due process rights, as well as its speech rights.The ban violates the Due Process Clause of the Fifth Amendment to the U.S. Constitution. As the D.C. Circuit has made clear, journalists’ “first amendment interest” in access to the White House “undoubtedly qualifies as liberty which may not be denied without due process of law under the fifth amendment.” Sherrill v. Knight, 569 F.2d 124, 130-31 (D.C. Cir. 1977). Defendants gave the AP no prior or written notice of, and no formal opportunity to challenge, their arbitrary determination that the AP would indefinitely lose access to the Oval Office, Air Force One, and other limited areas as a member of the press pool – as well as access to larger locations open to a wider group of journalists and reporters with White House press credentials – unless the AP adopted the Administration’s preferred language in its reporting.The ban also violates the First Amendment to the U.S. Constitution. The D.C. Circuit has made clear that denying journalists access to White House press events “based upon the content of the journalist’s speech” is “prohibited under the first amendment.” Sherrill, 569 F.2d at 129. Having opened the White House and certain areas to the press, the First Amendment “requires that this access not be denied arbitrarily or for less than compelling reasons.” Ateba v. Jean-Pierre, 706 F. Supp. 3d 63, 75-76 (D.D.C. 2023) (quoting Sherrill, 569 F.2d at 129) (emphasis in original), appeal argued, No. 24-5004 (D.C. Cir. Oct. 15, 2024). Defendants have not provided, nor could they provide, any compelling reason for their arbitrary denial of the AP’s access. Rather, Defendants’ actions are impermissibly based on their dislike of the content of the AP’s expression and what they perceive as the AP’s viewpoint reflected in the content of its expression. The White House ban of the AP also constitutes impermissible retaliation, as it was instituted to punish the AP for its constitutionally protected speech in ways that would chill the speech of a reasonable person of ordinary firmness.Remember all of those claims about how Trump learned lessons from his first term and would be more effective, learned, and efficient at governing this go around? Well, it appears that won’t always be the case. Trump did this in his first term, banning CNN’s Jim Acosta from the press pool because Trump didn’t like his questions. CNN sued, just like the AP has, and eventually Acosta was allowed back in. That will almost certainly be how this thing goes, too, unless Trump takes this all the way to a suspiciously compliant Supreme Court. Even then, this might be a bridge to far for those gods in black robes.And there should be no question that this is all due to Trump’s pettiness. The administration may attempt to obfuscate that in its legal response, but the Dear Leader has been quite clear as to what is driving all of this in very public comments.In stopping the AP from attending press events at the White House and Mar-a-Lago, or flying on Air Force One in the agency’s customary spot, the Trump team directly cited the AP’s decision not to fully follow the president’s renaming.“We’re going to keep them out until such time as they agree that it’s the Gulf of America,” Trump said Tuesday.Describing this suit as an “open and shut” case of a First Amendment violation at a minimum probably doesn’t do it justice. This is more of an attempted assault of the First Amendment and it will be quite telling to see how the courts respond.Anything less than a temporary restraining order to reinstate the AP’s access, followed by a swift finding for the AP, would be the courts stomping all over our First, and I would argue most important, Amendment.]]></content:encoded></item><item><title>Court filings show Meta staffers discussed using copyrighted content for AI training</title><link>https://techcrunch.com/2025/02/21/court-filings-show-meta-staffers-discussed-using-copyrighted-content-for-ai-training/</link><author>Kyle Wiggers</author><category>tech</category><pubDate>Fri, 21 Feb 2025 23:15:38 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[For years, Meta employees have internally discussed using copyrighted works obtained through legally questionable means to train the company’s AI models, according to court documents unsealed on Thursday. The documents were submitted by plaintiffs in the case Kadrey v. Meta, one of many AI copyright disputes slowly winding through the U.S. court system. The defendant, […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>The GSA Is Shutting Down Its EV Chargers</title><link>https://hardware.slashdot.org/story/25/02/21/2143227/the-gsa-is-shutting-down-its-ev-chargers?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 21 Feb 2025 22:50:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[The General Services Administration (GSA) is shutting down its nationwide electric vehicle (EV) chargers, deeming them "not mission critical." The U.S. government agency also plans to offload newly purchased EVs, reversing initiatives from the Biden administration aimed at transitioning the federal vehicle fleet to electric. The Verge reports: The GSA currently operates several hundred EV chargers across the country, with approximately 8,000 plugs that are available for government-owned EVs as well as federal employees' personally owned vehicles.
 
The official guidance instructing federal workers to begin the process of shutting down the chargers will be announced internally next week, according to a source with knowledge of the plans. Some regional offices have been told to start taking their chargers offline, according to an email viewed by The Verge. "As GSA has worked to align with the current administration, we have received direction that all GSA owned charging stations are not mission critical," the email reads.
 
The GSA is working on the timing of canceling current network contracts that keep the EV chargers operational. Once those contracts are canceled, the stations will be taken out of service and "turned off at the breaker," the email reads. Other chargers will be turned off starting next week. "Neither Government Owned Vehicles nor Privately Owned Vehicles will be able to charge at these charging stations once they're out of service," it concludes.]]></content:encoded></item><item><title>Brian Armstrong says Coinbase spent $50M fighting SEC lawsuit — and beat it</title><link>https://techcrunch.com/2025/02/21/brian-armstrong-says-coinbase-spent-50m-fighting-sec-lawsuit-and-beat-it/</link><author>Julie Bort</author><category>tech</category><pubDate>Fri, 21 Feb 2025 22:38:22 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Coinbase on Friday said the SEC has agreed to drop the lawsuit against the company with prejudice, meaning it cannot be filed again.  The move, which is still subject to the approval of the SEC’s Commissioners, is yet another signal that the Trump administration plans to be more friendly to crypto than the SEC was […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>OpenAI Plans To Shift Compute Needs From Microsoft To SoftBank</title><link>https://slashdot.org/story/25/02/21/2131244/openai-plans-to-shift-compute-needs-from-microsoft-to-softbank?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 21 Feb 2025 22:10:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[According to The Information (paywalled), OpenAI plans to shift most of its computing power from Microsoft to SoftBank-backed Stargate by 2030. TechCrunch reports: That represents a major shift away from Microsoft, OpenAI's biggest shareholder, who fulfills most of the startup's power needs today. The change won't happen overnight. OpenAI still plans to increase its spending on Microsoft-owned data centers in the next few years.
 
During that time, OpenAI's overall costs are set to grow dramatically. The Information reports that OpenAI projects to burn $20 billion in cash during 2027, far more than the $5 billion it reportedly burned through in 2024. By 2030, OpenAI reportedly forecasts that its costs around running AI models, also known as inference, will outpace what the startup spends on training AI models.]]></content:encoded></item><item><title>Leaked chat logs expose inner workings of secretive ransomware group</title><link>https://arstechnica.com/security/2025/02/leaked-chat-logs-expose-inner-workings-of-secretive-ransomware-group/</link><author>Dan Goodin</author><category>tech</category><enclosure url="https://cdn.arstechnica.net/wp-content/uploads/2023/09/code-vulnerability-security-1000x648.jpg" length="" type=""/><pubDate>Fri, 21 Feb 2025 21:47:32 +0000</pubDate><source url="https://arstechnica.com/">Biz &amp; IT – Ars Technica</source><content:encoded><![CDATA[More than a year’s worth of internal communications from one of the world’s most active ransomware syndicates have been published online in a leak that exposes tactics, trade secrets, and internal rifts of its members.The communications come in the form of logs of more than 200,000 messages members of Black Basta sent to each other over the Matrix chat platform from September 2023 to September 2024, researchers said. The person who published the messages said the move was in retaliation for Black Basta targeting Russian banks. The leaker's identity is unknown; it’s also unclear if the person responsible was an insider or someone outside the group who somehow gained access to the confidential logs.How to be your own worst enemyLast year, the FBI and Cybersecurity and Infrastructure Security Agency said Black Basta had targeted 12 of the 16 US critical infrastructure sectors in attacks mounted on 500 organizations around the world. One notable attack targeted Ascention, a St. Louis-based health care system with 140 hospitals in 19 states. Other victims include Hyundai Europe, UK-based outsourcing firm Capita, the Chilean Government Customs Agency, and UK utility company Southern Water. The native Russian-speaking group has been active since at least 2022.]]></content:encoded></item><item><title>iOS 18.4 will bring Apple Intelligence-powered ‘Priority Notifications’</title><link>https://techcrunch.com/2025/02/21/ios-18-4-will-bring-apple-intelligence-powered-priority-notifications/</link><author>Aisha Malik</author><category>tech</category><pubDate>Fri, 21 Feb 2025 21:34:27 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Apple on Friday released its first developer beta for iOS 18.4, which adds a new “Priority Notifications” feature, powered by Apple Intelligence. The addition aims to help users manage their notifications by prioritizing important alerts and minimizing distractions from less important ones.  These priority notifications are displayed in a separate section on the phone’s Lock […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Profiles In Cowardice: The Nobody Saw This Coming Brigade</title><link>https://www.techdirt.com/2025/02/21/profiles-in-cowardice-the-nobody-saw-this-coming-brigade/</link><author>Mike Masnick</author><category>tech</category><pubDate>Fri, 21 Feb 2025 21:27:16 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[Republican senators have seen the mass graves. They’ve met Zelensky. They’ve walked through bombed cities and witnessed firsthand the evidence of Russian atrocities. Yet now, faced with Trump’s embrace of Putin and denunciation of Ukraine, they can’t even muster the courage to state simple truths they know from direct personal experience.While Trump openly declares the Ukrainian president is a “dictator” and blames Ukraine for Russia’s invasion, Senate Republicans respond with a masterclass in institutional paralysis. Some pretended to be on phone calls. Others claimed they hadn’t heard the comments. A few muttered hopes about “negotiating strategy.” This would be comedic if it weren’t so catastrophically dangerous.Let’s cut through the bullshit: This isn’t just policy disagreement or political maneuvering. It’s the complete collapse of the post-war security architecture that has prevented great power war for three generations. And our political class is responding with all the urgency of someone scheduling a dental cleaning.The reason for their silence? Fear of mean tweets—many generated by bot networks. Fear of being primaried. Fear of the digital mob that Elon Musk can direct with a few keystrokes—a mob increasingly composed of artificial accounts and coordinated influence operations. These aren’t just personal failures of courage—they represent something far more dangerous: the complete surrender of democratic institutions to manufactured technological intimidation.Let’s be clear about the historical magnitude of this choice: They’re trading their eyewitness testimony of war crimes for social media comfort. They’re choosing X followers—most of whom are probably bots tied to various influence operations, both foreign and domestic—over the international order that has prevented nuclear war for three generations.The supreme irony is that the pressure they’re surrendering to isn’t even real. These senators are abandoning witnessed truth about war crimes in response to artificially generated outrage. They’re choosing bot approval over bomb evidence. The digital mob they fear is largely synthetic—but the consequences of their cowardice will be catastrophically real.Consider the grotesque math these senators are doing: They’re weighing firsthand evidence of war crimes against the threat of hostile posts on X. They’re balancing their direct knowledge of Russian aggression against the risk of Musk funding a primary challenger. And they’re choosing digital self-preservation over defense of basic reality.This isn’t just cowardice—it’s a revelation of how thoroughly our democratic institutions have been captured by technological intimidation. When United States senators cannot state truths they’ve witnessed with their own eyes because they fear a billionaire’s social media platform, we’re not just watching individual moral failure—we’re seeing the complete collapse of institutional independence.Two plus two equals four. Russia invaded Ukraine. Mass graves don’t tweet.The sheer audacity of this surrender is breathtaking. Senator Lindsey Graham, who has positioned himself as one of Ukraine’s strongest allies and has personally seen the evidence of Russian atrocities, responds to Trump’s pro-Putin statement by suggesting Trump is Ukraine’s “best hope.” This isn’t just lying—it’s actively participating in the destruction of .Two plus two equals four. These senators know what they’ve seen. They know who invaded whom. They’ve walked among the mass graves, seen the bombed hospitals, counted the dead. Yet they’ve decided that appeasing digital mobs—swollen by bots and algorithmic rage—matters more than defending democracy itself.When future generations ask how we allowed democratic institutions to be dismantled by social media mobs, these profiles in cowardice will stand as perfect examples. They saw the truth with their own eyes—and chose to stay silent for fear of mean tweets.Consider the sheer audacity of the gaslighting: The same senators who hailed Zelensky as a modern Churchill in 2022 now can’t muster even tepid defense of basic reality. They’re not just abandoning an ally—they’re actively participating in the dismantling of the international system that has kept nuclear powers from direct conflict.Two plus two equals four. Russia invaded Ukraine. This isn’t complicated. Yet we watch senators who know better—who have visited mass graves in Ukraine, who have met Zelensky personally—engage in elaborate rhetorical contortions to avoid stating simple truth. When Senator Kevin Cramer suggests Trump’s embrace of Putin might be “negotiating strategy,” he’s not just being cowardly—he’s actively helping normalize the destruction of democratic alliances.The most revealing response came from those who simply pretended not to hear the question, marching past reporters with phones pressed to their ears. This isn’t just evasion—it’s a perfect metaphor for how institutional actors respond to existential threats: by pretending they don’t exist.But here’s what makes this moment particularly dangerous: These aren’t just individual acts of cowardice. They represent the systematic failure of democratic institutions to defend themselves. When senators who have seen the evidence of Russian atrocities firsthand cannot even maintain basic moral clarity about aggression and self-defense, they’re not just failing Ukraine—they’re participating in the destruction of the very framework that prevents great power war.The comfortable blindness that precedes catastrophe is on full display. Our political class continues to treat the dismantling of global security architecture as if it were normal political development rather than an existential threat to international stability. They maintain institutional proprieties while the foundations of peace crumble.History will not be kind to these profiles in cowardice. When future generations ask how we allowed the system that prevented World War III to be dismantled, these senators’ elaborate evasions will stand as perfect examples of institutional failure in the face of obvious catastrophe.What we are witnessing isn’t mere cowardice—though the spectacle of United States senators cowering before artificial X accounts certainly qualifies. No, this is something Hannah Arendt would recognize immediately: the banality of (digital) evil. The quiet, procedural way that moral atrocity becomes acceptable, not through dramatic villainy, but through the simple choice to value one’s social media standing over witnessed truth.These are men and women who have stood in mass graves. Who have walked through bombed hospitals. Who have seen firsthand the evidence of Putin’s barbarism. And now, faced with the simple task of stating these obvious truths, they perform their own small acts of evil—not with grand malice, but with the bureaucratic efficiency of checking their X metrics.Like Arendt’s subjects, they would protest that they are simply being “practical,” that they are “working within the system.” But their practicality consists of trading their eyewitness testimony of war crimes for bot approval. Their system is the methodical destruction of truth itself.When future generations ask how we allowed the post-war order to collapse, how we permitted the system that prevented World War III to be dismantled, these profiles in cowardice will stand as perfect examples. They didn’t just fail to defend democracy—they processed its destruction through their social media management routines.The Nobody Saw This Coming Brigade is already drafting their excuses.But they did see it coming.They’re watching it happen—eyes wide open, hearts locked shut.They saw the truth with their own eyes.Two plus two equals four.And the blood of what comes next will be on their hands.“No one has the right to obey.” — Hannah ArendtMike Brock is a former tech exec who was on the leadership team at Block. Originally published at his Notes From the Circus.]]></content:encoded></item><item><title>India&apos;s &apos;Human Calculator Kid&apos; Shatters 6 World Records In a Single Day</title><link>https://science.slashdot.org/story/25/02/21/2125209/indias-human-calculator-kid-shatters-6-world-records-in-a-single-day?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>BeauHD</author><category>tech</category><pubDate>Fri, 21 Feb 2025 21:26:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[An anonymous reader quotes a report from Gizmodo: Fourteen-year-old Aaryan Shukla cruised through six mental math calculation world records in a single day, according to a Guinness World Records statement published on February 12, earning the well-deserved nickname, "human calculator kid." Specifically, it took Shukla:
 - 30.9 seconds to mentally add 100 four-digit numbers - One minute and 9.68 seconds to mentally add 200 four-digit numbers - 18.71 seconds to mentally add 50 five-digit numbers - Five minutes and 42 seconds to mentally divide a 20-digit number by a ten-digit number ten times - 51.69 seconds to mentally multiply two five-digit numbers ten times - Two minutes and 35.41 seconds to mentally multiply two eight-digit numbers ten times
 
According to the statement, these are among the most difficult mental calculation world records ever attempted. Shukla's frankly mind-boggling achievement also comes in the wake of another world record he broke in April 2024 at the age of 13: fastest time to mentally add 50 five-digit numbers. It took him just 25.19 seconds. That's an addition every half a second. I wouldn't be surprised if students seeking "shortcuts" in their math homework started phoning up Shukla instead of reaching for their ChatGPT browser tab. Guinness World Records published a video about Shukla's accomplishments on YouTube.]]></content:encoded></item><item><title>Cornered by the UK’s Demand for an Encryption Backdoor, Apple Turns Off Its Strongest Security Setting</title><link>https://www.eff.org/deeplinks/2025/02/cornered-uks-demand-encryption-backdoor-apple-turns-its-strongest-security-setting</link><author>Andrew Crocker</author><category>tech</category><enclosure url="https://www.eff.org/files/banner_library/OG-Encryption-DefendEncryption.png" length="" type=""/><pubDate>Fri, 21 Feb 2025 21:17:35 +0000</pubDate><source url="https://www.eff.org/rss/updates.xml">Deeplinks</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Nvidia CEO Jensen Huang says market got it wrong about DeepSeek’s impact</title><link>https://techcrunch.com/2025/02/21/nvidia-ceo-jensen-huang-says-market-got-it-wrong-about-deepseeks-impact/</link><author>Rebecca Szkutak</author><category>tech</category><pubDate>Fri, 21 Feb 2025 20:36:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Nvidia founder and CEO Jensen Huang said the market got it wrong when it comes to DeepSeek’s technological advancements and its potential to negatively impact the chipmaker’s business. Instead, Huang called DeepSeek’s R1 open source reasoning model “incredibly exciting” while speaking with Alex Bouzari, CEO of DataDirect Networks, in a pre-recorded interview that was released […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Report: OpenAI plans to shift compute needs from Microsoft to SoftBank</title><link>https://techcrunch.com/2025/02/21/report-openai-plans-to-shift-compute-needs-from-microsoft-to-softbank/</link><author>Maxwell Zeff</author><category>tech</category><pubDate>Fri, 21 Feb 2025 20:22:40 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[OpenAI is forecasting a major shift in the next five years around who it gets most of its computing power from, The Information reported on Friday. By 2030, OpenAI expects to get three-quarters of its data center capacity from Stargate, a project that’s expected to be heavily financed by SoftBank, one of OpenAI’s newest financial […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Yes, You Have The Right To Film ICE</title><link>https://www.techdirt.com/2025/02/21/yes-you-have-the-right-to-film-ice/</link><author>Mike Masnick</author><category>tech</category><pubDate>Fri, 21 Feb 2025 20:11:17 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[Across the United States, Immigration and Customs Enforcement (ICE) has already begun increasing enforcement operations, including highly publicized raids. As immigrant communities, families, allies, and activists think about what can be done to shift policy and protect people, one thing is certain: similar to filming the police as they operate, you have the right to film ICE, as long as you are not obstructing official duties.Filming ICE agents making an arrest or amassing in your town helps promote transparency and accountability for a system that often relies on intimidation and secrecy and obscures abuse and law-breaking. While it is crucial for people to help aid in transparency and accountability, there are considerations and precautions you should take. For an in-depth guide by organizations on the frontlines of informing people who wish to record ICE’s interactions with the public, review these handy resources from the hard-working folks at WITNESS and NYCLU. At EFF, here are our general guidelines when it comes to filming law enforcement, including ICE: What to Know When Recording Law EnforcementYou have the right to record law enforcement officers exercising their official duties in public. with law enforcement. If you are a bystander, stand at a safe distance from the scene that you are recording.You may take photos or record video and/or audio.Law enforcement cannot order you to move  you are recording, but they may order you to move for public safety reasons even if you are recording.Law enforcement may not search your cell phone or other device without a warrant based on probable cause from a judge, even if you are under arrest. Thus, you may refuse a request from an officer to review or delete what you recorded. You also may refuse to unlock your phone or provide your passcode.Despite reasonably exercising your First Amendment rights, law enforcement officers may illegally retaliate against you in a number of ways including with arrest, destruction of your device, and bodily harm. They may also try to retaliate by harming the person being arrested. We urge you to remain alert and mindful about this possibility.Consider the sensitive nature of recording in the context of an ICE arrest. The person being arrested or their loved ones may be concerned about exposing their immigration status, so think about obtaining consent or blurring out faces in any version you publish to focus on ICE’s conduct (while still retaining the original video).Your First Amendment Right to Record Law Enforcement Officers Exercising Their Official Duties in PublicFederal appellate courts typically frame the right to record law enforcement as the right to record officers exercising their official duties in public. This right extends to private places, too, where the recorder has a legal right to be, such as in their own home. However, if the law enforcement officer is off-duty or is in a private space that you don’t have a right to be in, your right to record the officer may be limited. Special Considerations for Recording AudioThe right to record law enforcement unequivocally includes the right to take pictures and record video. There is an added legal wrinkle when —whether with or without video. Some law enforcement officers have argued that recording audio without their consent violates wiretap laws. Courts have generally rejected this argument. The Seventh Circuit, for example, held that the Illinois wiretap statute violated the First Amendment as applied to audio recording on-duty police.There are two kinds of wiretaps laws: those that require “all parties” to a conversation to consent to audio recording (12 states), and those that only require “one party” to consent (38 states, the District of Columbia, and the federal statute). Thus, if you’re in a  state, and you’re involved in an incident with law enforcement (that is, you’re a party to the conversation) and you want to record audio of that interaction, you are the one party consenting to the recording and you don’t also need the law enforcement officer’s consent. If you’re in an , and your cell phone or recording device is in plain view, your open audio recording puts the officer on notice and thus their consent might be implied.Additionally, wiretap laws in both all-party consent states and one-party consent states typically only prohibit audio recording of —that is, when the parties to the conversation have a reasonable expectation of privacy. Law enforcement officers exercising their official duties, particularly in public, do not have a reasonable expectation of privacy. Neither do civilians in public places who speak to law enforcement in a manner audible to passersby. Thus, if you’re a bystander, you may legally audio record an officer’s interaction with another person, regardless of whether you’re in a state with an all-party or one-party consent wiretap statute. However, you should take into consideration that ICE arrests may expose the immigration status of the person being arrested or their loved ones. As WITNESS puts it: “[I]t’s important to keep in mind the privacy and dignity of the person being targeted by law enforcement. They may not want to be recorded or have the video shared publicly. When possible, make eye contact or communicate with the person being detained to let them know that you are there to observe and document the cops’ behavior. Always respect their wishes if they ask you to stop filming.” You may also want to consider blurring faces to focus on ICE’s conduct if you publish the video online (while still retaining the original version)Moreover, whether you may  record law enforcement (whether with photos, video or audio) is important to understand, given that officers may retaliate against individuals who  record them. At least one federal appellate court, the First Circuit, has affirmed the First Amendment right to secretly audio record law enforcement performing their official duties in public. On the other hand, the Ninth Circuit recently upheld Oregon’s law that generally bans secret recordings of in-person conversations without all participants’ consent, and only allows recordings of conversations where police officers are participants if “[t]he recording is made openly and in plain view of the participants in the conversation.” Unless you are within the jurisdiction of the First Circuit (Maine, Massachusetts, New Hampshire, Puerto Rico and Rhode Island), it’s probably best to have your recording device in plain view of police officers.Do Not Interfere With Law EnforcementWhile the weight of legal authority provides that individuals have a First Amendment right to record law enforcement, courts have also stated one important caveat: you may not interfere with officers doing their jobs.The Seventh Circuit, for example, said, “Nothing we have said here immunizes behavior that obstructs or interferes with effective law enforcement or the protection of public safety.” The court further stated, “While an officer surely cannot issue a ‘move on’ order to a person  he is recording, the police may order bystanders to disperse for reasons related to public safety and order and other legitimate law enforcement needs.”Just because you have the right, however, does not mean law enforcement will always acknowledge and uphold your right in that moment. Be safe and be alert. If you have reason to think your devices might be seized or you may run the risk of putting yourself under surveillance, make sure to check out our Surveillance Self-Defense guides and our field guide to identifying and understanding the surveillance tools law enforcement may employ.]]></content:encoded></item><item><title>Norway’s 1X is building a humanoid robot for the home</title><link>https://techcrunch.com/2025/02/21/norways-1x-is-building-a-humanoid-robot-for-the-home/</link><author>Brian Heater</author><category>tech</category><pubDate>Fri, 21 Feb 2025 19:32:11 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Norwegian robotics firm 1X unveiled its latest home robot, Neo Gamma, on Friday. The humanoid system will succeed Neo Beta, which debuted in August. Like its predecessors, the Neo Gamma is a prototype designed for testing in the home environment. Images of the robot show it performing a number of household tasks like making coffee, […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Sakana walks back claims that its AI can dramatically speed up model training</title><link>https://techcrunch.com/2025/02/21/sakana-walks-back-claims-that-its-ai-can-dramatically-speed-up-model-training/</link><author>Kyle Wiggers</author><category>tech</category><pubDate>Fri, 21 Feb 2025 19:19:49 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[This week, Sakana AI, an Nvidia-backed startup that’s raised hundreds of millions of dollars from VC firms, made a remarkable claim. The company said it had created an AI system, the AI CUDA Engineer, that could effectively speed up the training of certain AI models by a factor of up to 100x. The only problem […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Despite recent layoffs, Meta is expanding in India</title><link>https://techcrunch.com/2025/02/21/despite-recent-layoffs-meta-is-expanding-in-india/</link><author>Charles Rollet, Ivan Mehta</author><category>tech</category><pubDate>Fri, 21 Feb 2025 19:17:34 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Meta is expanding in India, despite recent layoffs of what the tech giant controversially deemed "low performers."© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>IEEE Offers AI Training Courses and a Mini MBA Program</title><link>https://spectrum.ieee.org/ieee-ai-training-mini-mba</link><author>Angelique Parashis</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjUzNTE3MC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc5MTY3Mjc1NH0.7ev26z2TPTpO56FW-jo3GzzSjYNchXWodvlrJOAyyn8/image.jpg?width=600" length="" type=""/><pubDate>Fri, 21 Feb 2025 19:00:06 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[The courses cover chip design and fabrication plus edge computing]]></content:encoded></item><item><title>The Two Types of Data Engineers You Meet at Work</title><link>https://hackernoon.com/the-two-types-of-data-engineers-you-meet-at-work?source=rss</link><author>luminousmen</author><category>tech</category><pubDate>Fri, 21 Feb 2025 19:00:04 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Data engineering is a crucial element of the data ecosystem, comprised of diverse professionals who play essential roles in managing and processing data. While the job title may be the same, as I’ve seen over the years, data engineers often fall into two distinct archetypes: the "businessy" data engineer and the "techy" data engineer as I like to call them. In this blog post, we will explore these two archetypes, their characteristics, and their contributions to the world of data engineering.The Businessy Data Engineer\
These folks are all about solving business problems. They are passionate about tracking metrics, Key Performance Indicators (KPIs), and building interactive dashboards. Often, they have extensive SQL experience and possess coding skills in versatile languages like Python, ideal for data manipulation and analysis.\
: Their primary focus on translating business needs into data solutions. They build data pipelines to collect, transform, and load data, enabling meaningful insights for decision-makers. These professionals are often referred to as Business Intelligence (BI) Engineers.\
: A typical day may involve gathering requirements from stakeholders, designing dashboards, scripting in Python or SQL for data extraction and transformation, and collaborating with business teams to ensure data-driven decision-making.\
On the other hand, techy data engineers are drawn to solving scale problems. They thrive on exploring and implementing new technologies, and often prefer coding in languages like Scala or Java. They are responsible for building scalable data pipelines that can handle massive volumes of data.\
: Techy data engineers focus on building and maintaining robust data infrastructure. They ensure that data pipelines are scalable, reliable, and capable of handling large datasets. They are proficient in tools like Apache Spark, Apache Flink and Apache Airflow, which are vital for processing vast amounts of data and know intricacies of cloud tools.\
: A typical day for a techy data engineer might involve optimizing data pipelines, troubleshooting performance issues, experimenting with new data storage and processing technologies, and collaborating with data scientists to deploy machine learning models.While these two archetypes of data engineers have distinct roles and responsibilities, there is immense potential when they work together. The businessy data engineer's ability to understand and translate business requirements complements the techy data engineer's expertise in building scalable solutions. The businessy folks understand what the suits want, and the techy folks build the data powerhouse to support those needs. Collaboration between these two types of data engineers can lead to the creation of powerful data-driven solutions. Teamwork makes the dream work, right?\
Now, here's the thing: most data engineering training focuses on the techy side of things, leaving a gap for the businessy data engineer. We need content that showcases their role, assists individuals in identifying suitable job postings, and guides them on their learning journey.\
Which type do you identify with?]]></content:encoded></item><item><title>Fintech founder Charlie Javice’s criminal trial has begun</title><link>https://techcrunch.com/2025/02/21/fintech-founder-charlie-javices-criminal-trial-has-begun/</link><author>Mary Ann Azevedo</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:57:55 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[The criminal trial against fintech startup founder Charlie Javice began on Friday, with lawyers laying out their opening arguments, Reuters reported.  Lawyers reiterated their original claims and defenses from the lawsuit filed by JPMorgan Chase against Javice in December of 2022. The financial services giant alleges that Javice helped “fake millions of customers in order […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>As the Kernel Turns: Rust in Linux saga reaches the “Linus in all-caps” phase</title><link>https://arstechnica.com/gadgets/2025/02/linux-leaders-pave-a-path-for-rust-in-kernel-while-supporting-c-veterans/</link><author>Kevin Purdy</author><category>tech</category><enclosure url="https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-566440151-1152x648.jpg" length="" type=""/><pubDate>Fri, 21 Feb 2025 18:55:11 +0000</pubDate><source url="https://arstechnica.com/">Biz &amp; IT – Ars Technica</source><content:encoded><![CDATA[Rust, a modern and notably more memory-safe language than C, once seemed like it was on a steady, calm, and gradual approach into the Linux kernel.By late 2024, however, Rust enthusiasts were frustrated with stalls and blocks on their efforts, with the Rust for Linux lead quitting over "nontechnical nonsense." Torvalds said at the time that he understood it was slow, but that "old-time kernel developers are used to C" and "not exactly excited about having to learn a new language." Still, this could be considered a normal amount of open source debate.]]></content:encoded></item><item><title>While Democracy Burns, Democrats Prioritize… Demolishing Section 230?</title><link>https://www.techdirt.com/2025/02/21/while-democracy-burns-democrats-prioritize-demolishing-section-230/</link><author>Mike Masnick</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:48:45 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[You might think — in a moment when democracy itself seems to be unraveling and the American experiment teetering on the brink — that Democratic leadership would focus on, oh I don’t know, preserving the basic functions of government. But no, they’ve decided that what we really need right now is to demolish the legal framework that makes online discourse possible.(Forgive the lack of a profile image on that screenshot — at the time I made the screenshot literally every profile image on ExTwitter is just a gray circle, because things are operating greeeeeaaaat over there while the boss is away destroying the country).Senator Dick Durbin, ranking member of the Judiciary Committee, has emerged with what can only be described as a masterclass in missing the point. In a press release that reads like it was written in an alternate universe where the biggest threat to democracy is… … website comment sections, Durbin announced his excitement about taking away Section 230.This week, Durbin will join U.S. Senators Lindsey Graham (R-SC), Sheldon Whitehouse (D-RI), Josh Hawley (R-MO), Amy Klobuchar (D-MN), and Marsha Blackburn (R-TN) to introduce a bill that would sunset Section 230 of the Communications Decency Act in two years.  Section 230—and the legal immunity it provides to Big Tech—has been on the books since 1996—long before social media became a part of our daily lives. To the extent this protection was ever needed, its usefulness has long since passed.Let’s unpack this for a moment. At a time when an unelected billionaire is effectively running the government via his own social media platform, Democrats have decided to partner with… … the very Republicans who’ve been helping enable this takeover, to eliminate the law that makes alternative social media platforms possible in the first place. The thing is, this isn’t just regular old political malpractice — this is advanced political malpractice. We’ve known for years that these same Republican senators have been quite open about their plans to use Section 230’s removal as a weapon against speech they don’t like. It’s right there in their public statements! This isn’t some clever political chess move — it’s handing matches to an arsonist who has loudly declared his intention to burn your house down, while insisting it’s necessary to improve fire safety.But Durbin’s fundamental mischaracterization of Section 230 as mere “legal immunity for big tech” betrays either willful ignorance or calculated misdirection. Section 230 is, at its core, a shield for  – your speech, my speech, everyone’s speech. It protects individuals and small websites far more than it protects Silicon Valley giants. It’s what keeps you safe when you forward an email or share a post. It’s what enables sites for people to review doctors or mechanics or employers. It’s what makes it possible for Wikipedia to exist. It’s what enables the very digital discourse we need to maintain democracy.The dumbest part: removing Section 230 would actually entrench Big Tech’s power, not diminish it. The giants would survive just fine — most cases against them would still fail on First Amendment grounds. But defending speech under the First Amendment is far more complex and expensive than Section 230’s straightforward protections. Meta, Google, and their ilk have armies of lawyers to handle this. Everyone else? Not so much.This explains why Mark Zuckerberg has been practically begging Congress to eliminate Section 230. It’s not because he suddenly developed a burning passion for content moderation reform. It’s because he’s looked at the math and realized: “Hey, we can afford buildings full of lawyers. Our competitors can’t.” When Zuckerberg advocates for eliminating Section 230, he’s not confessing his sins — he’s pitching his business plan.Without Section 230 “Big Tech” would be fine. First of all, in nearly all cases that are filed against websites would still lose, because almost all of these decisions are protected by the First Amendment. But — and this is the important part — having to defend it under the First Amendment is way more expensive. And takes way longer. Which means that smaller defendants, especially, will likely cave in to threats.The end result? Big Tech gets bigger, smaller platforms disappear, and the “monopolies” that Durbin claims to be fighting become actual monopolies — now with congressional approval! It’s like trying to punish Standard Oil by making it illegal for anyone except Standard Oil to sell kerosene.Durbin’s claim that Section 230’s “usefulness has long since passed” isn’t just wrong — it’s dangerous. The law is more vital now than ever, as demonstrated by countless cases where it’s protected essential online discourse. At a moment when we desperately need more venues for protected speech and democratic dialogue, Durbin is proposing to demolish the very framework that makes such dialogue possible.The consequences would be predictable and devastating: a cascade of frivolous lawsuits designed to silence critics and suppress inconvenient truths. Without Section 230’s efficient dismissal process, even completely baseless legal threats become effective censorship tools. Think about it: if you’re running a small community forum and someone threatens to sue you because they don’t like a user’s post about their business, what are you going to do? Spend hundreds of thousands of dollars defending your First Amendment rights, or just take down the post? This isn’t theoretical — it’s basic economics.The end result is that it becomes that much easier to suppress dissent.The timing of this crusade against Section 230 is particularly revealing. While democracy itself is under assault, while an unelected billionaire consolidates unprecedented power over government systems, Durbin has chosen to champion a proposal that would:Make Big Tech even more powerfulHand MAGA forces a powerful weapon for silencing opposition through legal harassmentCripple the digital infrastructure needed for organizing democratic resistanceThis isn’t just Durbin being out of touch — though at 80 years old, that’s certainly part of it. This is a catastrophic misreading of both technology and democracy that would be almost comical if it weren’t so dangerous. Here we have a Democratic leader eagerly collaborating with the very senators actively undermining democracy, on legislation that would further enable their authoritarian aims, while apparently convinced he’s doing something about “Big Tech.” The Democrats desperately need new leadership, and not just because Durbin doesn’t understand how the internet works. They need leaders who understand that defending democracy requires actually defending the tools that make democratic discourse possible. Instead, we have Durbin, essentially proposing to solve the problem of book-burning by making it illegal to publish books. His Section 230 crusade makes it painfully clear: he’s not just the wrong leader for this moment — he’s actively making things worse.]]></content:encoded></item><item><title>Daily Deal: The 2025 Graphic Design for Beginners Bundle</title><link>https://www.techdirt.com/2025/02/21/daily-deal-the-2025-graphic-design-for-beginners-bundle-2/</link><author>Daily Deal</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:43:05 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[The 2025 Graphic Design for Beginners Bundle has 4 courses to help you learn about graphic design. Courses cover working with Adobe Illustrator, using your iPhone for filming, and starting your own graphic design business. It’s on sale for $30.Note: The Techdirt Deals Store is powered and curated by StackCommerce. A portion of all sales from Techdirt Deals helps support Techdirt. The products featured do not reflect endorsements by our editorial team.]]></content:encoded></item><item><title>DeepSeek To Share Some AI Model Code</title><link>https://news.slashdot.org/story/25/02/21/1842227/deepseek-to-share-some-ai-model-code?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:41:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Chinese startup DeepSeek will make its models' code publicly available, it said on Friday, doubling down on its commitment to open-source artificial intelligence. From a report: The company said in a post on social media platform X that it will open source 5 code repositories next week, describing the move as "small but sincere progress" that it will share "with full transparency." 

"These humble building blocks in our online service have been documented, deployed and battle-tested in production." the post said. DeepSeek rattled the global AI industry last month when it released its open-source R1 reasoning model, which rivaled Western systems in performance while being developed at a lower cost.]]></content:encoded></item><item><title>System76 Releases COSMIC Alpha 6 Desktop Environment</title><link>https://www.phoronix.com/news/COSMIC-Alpha-6-Released</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:34:03 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[System76 engineers remain quite busy working on their Rust-written COSMIC desktop environment to be used by their Pop!_OS operating system as well as other Linux distributions moving forward...]]></content:encoded></item><item><title>Apple takes on recipe apps with Apple News+ Food</title><link>https://techcrunch.com/2025/02/21/apple-takes-on-recipe-apps-with-apple-news-food/</link><author>Sarah Perez</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:30:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Recipe app developers just got new competition. On Friday, Apple introduced a soon-to-launch feature for Apple News+ subscribers called Apple News+ Food, a new section that will allow users to search, discover, save, and easily cook recipes from dozens of existing News+ publishing partners. It’s set to roll out as part of iOS 18.4 and […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Microsoft’s new chip looks like science fiction…</title><link>https://www.youtube.com/watch?v=jwnez8HdN7E</link><author>Fireship</author><category>tech</category><category>video</category><enclosure url="https://www.youtube.com/v/jwnez8HdN7E?version=3" length="" type=""/><pubDate>Fri, 21 Feb 2025 18:24:14 +0000</pubDate><source url="https://www.youtube.com/channel/UCsBjURrPoezykLs9EqgamOA">Fireship</source><content:encoded><![CDATA[Sign up for CodeRabbit using FIRESHIP code, and get free CodeRabbit for 1-month https://bit.ly/41rLUxm

Microsoft just announced a new quantum computing chip called Majorana 1. It is the first chip capable of topological quantum computing 

#tech #science #thecodereport 

💬 Chat with Me on Discord

https://discord.gg/fireship

🔗 Resources

Majorana Announcement https://news.microsoft.com/source/features/ai/microsofts-majorana-1-chip-carves-new-path-for-quantum-computing/
Google Willow Chip https://youtu.be/IJHrPjx4egM
Tech Trends 2025 https://youtu.be/v4H2fTgHGuc

🔥 Get More Content - Upgrade to PRO

Upgrade at https://fireship.io/pro
Use code YT25 for 25% off PRO access 

🎨 My Editor Settings

- Atom One Dark 
- vscode-icons
- Fira Code Font

🔖 Topics Covered

- Majorana particle explained
- How does Microsoft's Majorana chip work?
- Latest advancements in quantum computing
- How do qubits work? 
- Quantum decoherence explained simply]]></content:encoded></item><item><title>Notorious crooks broke into a company network in 48 minutes. Here’s how.</title><link>https://arstechnica.com/security/2025/02/notorious-crooks-broke-into-a-company-network-in-48-minutes-heres-how/</link><author>Dan Goodin</author><category>tech</category><enclosure url="https://cdn.arstechnica.net/wp-content/uploads/2021/02/evil-packet.jpg" length="" type=""/><pubDate>Fri, 21 Feb 2025 18:17:28 +0000</pubDate><source url="https://arstechnica.com/">Biz &amp; IT – Ars Technica</source><content:encoded><![CDATA[In December, roughly a dozen employees inside a manufacturing company received a tsunami of phishing messages that was so big they were unable to perform their day-to-day functions. A little over an hour later, the people behind the email flood had burrowed into the nether reaches of the company's network. This is a story about how such intrusions are occurring faster than ever before and the tactics that make this speed possible.The speed and precision of the attack—laid out in posts published Thursday and last month—are crucial elements for success. As awareness of ransomware attacks increases, security companies and their customers have grown savvier at detecting breach attempts and stopping them before they gain entry to sensitive data. To succeed, attackers have to move ever faster.ReliaQuest, the security firm that responded to this intrusion, said it tracked a 22 percent reduction in the “breakout time” threat actors took in 2024 compared with a year earlier. In the attack at hand, the breakout time—meaning the time span from the moment of initial access to lateral movement inside the network—was just 48 minutes.]]></content:encoded></item><item><title>The Vision Pro is getting Apple Intelligence in April</title><link>https://techcrunch.com/2025/02/21/the-vision-pro-is-getting-apple-intelligence-in-april/</link><author>Brian Heater</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:07:17 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Apple Intelligence is heading to the Vision Pro as part of an upcoming operating system update. Apple confirmed on Friday that its generative AI platform will arrive on the extended reality headset as part of visionOS 2.4. A beta version of the software is currently available for developers. The public version is set for an […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Augury and Hightouch are in the unicorn club</title><link>https://techcrunch.com/2025/02/21/augury-and-hightouch-joined-the-unicorn-club/</link><author>Anna Heim</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:05:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Welcome to Startups Weekly — your weekly recap of everything you can’t miss from the world of startups. Want it in your inbox every Friday? Sign up here. Startup life is a story of births and deaths. This week confirmed this, and it confirmed that unicorn rounds are not dead. Most interesting startup stories from […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Crypto exchange Bybit says it was hacked and lost around $1.4B</title><link>https://techcrunch.com/2025/02/21/crypto-exchange-bybit-says-it-was-hacked-and-lost-around-1-4-billion/</link><author>Lorenzo Franceschi-Bicchierai</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:00:33 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Crypto exchange Bitby disclosed a breach that that amounts to a loss of $1.4 billion, the largest crypto theft of all time. © 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Fast-Coresets: A Nearly-Linear Time Algorithm for Efficient Clustering</title><link>https://hackernoon.com/fast-coresets-a-nearly-linear-time-algorithm-for-efficient-clustering?source=rss</link><author>Scripting Technology</author><category>tech</category><pubDate>Fri, 21 Feb 2025 18:00:06 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) Andrew Draganov, Aarhus University and All authors contributed equally to this research;(2) David Saulpic, Université Paris Cité & CNRS;(3) Chris Schwiegelshohn, Aarhus University.2 Preliminaries and Related Work8 Proofs, Pseudo-Code, and ExtensionsWe put the proofs, pseudo-code and algorithmic extensions towards the end of the paper for improved readability of the primary text. Algorithm 2 corresponds to the discussion in Section 4.1 and Algorithm 3 corresponds to the discussion in Section 4.2.8.1 Proof of Corollary 3.2In our argument, the only step specific to k-median is computing the upper-bound U on the cost of the solution. Provided such an upper-bound, rounding points and shifting the box would work exactly alike for k-means. Therefore, the next lemma is enough to extend our reduction of the spread to k-means:8.3 Estimation of the Optimal Cost in a Tree8.4 Extensions to Algorithm 1[1] Marcel R. Ackermann, Marcus Märtens, Christoph Raupach, Kamil Swierkot, Christiane Lammersen, and Christian Sohler. Streamkm++: A clustering algorithm for data streams. ACM J. Exp. Algorithmics, 17(1), 2012. doi: 10.1145/2133803.2184450. URL https://doi.org/10. 1145/2133803.2184450.\
[2] David Arthur and Sergei Vassilvitskii. k-means++: the advantages of careful seeding. In Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2007, New Orleans, Louisiana, USA, January 7-9, 2007, pages 1027–1035, 2007. URL http: //dl.acm.org/citation.cfm?id=1283383.1283494.\
[3] Pranjal Awasthi and Or Sheffet. Improved spectral-norm bounds for clustering. In Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques - 15th International Workshop, APPROX 2012, and 16th International Workshop, RANDOM 2012, Cambridge, MA, USA, August 15-17, 2012. Proceedings, pages 37–49, 2012. doi: 10.1007/978-3-642-32512-04. URL http://dx.doi.org/10.1007/978-3-642-32512-04.\
[4] Olivier Bachem, Mario Lucic, Hamed Hassani, and Andreas Krause. Fast and provably good seedings for k-means. Advances in neural information processing systems, 29, 2016.\
[5] Olivier Bachem, Mario Lucic, S. Hamed Hassani, and Andreas Krause. Approximate k-means++ in sublinear time. In Dale Schuurmans and Michael P. Wellman, editors, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA, pages 1459–1467. AAAI Press, 2016. doi: 10.1609/AAAI.V30I1.10259. URL https: //doi.org/10.1609/aaai.v30i1.10259.\
[6] Olivier Bachem, Mario Lucic, and Andreas Krause. Scalable k-means clustering via lightweight coresets. In Yike Guo and Faisal Farooq, editors, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD 2018, London, UK, August 19-23, 2018, pages 1119–1127. ACM, 2018. doi: 10.1145/3219819.3219973. URL https: //doi.org/10.1145/3219819.3219973.\
[7] Mihai Badoiu, Sariel Har-Peled, and Piotr Indyk. Approximate clustering via core-sets. In Proceedings on 34th Annual ACM Symposium on Theory of Computing, May 19-21, 2002, Montréal, Québec, Canada, pages 250–257, 2002. doi: 10.1145/509907.509947. URL https: //doi.org/10.1145/509907.509947.\
[8] Sayan Bandyapadhyay, Fedor V. Fomin, and Kirill Simonov. On coresets for fair clustering in metric and euclidean spaces and their applications. In Nikhil Bansal, Emanuela Merelli, and James Worrell, editors, 48th International Colloquium on Automata, Languages, and Programming, ICALP 2021, July 12-16, 2021, Glasgow, Scotland (Virtual Conference), volume 198 of LIPIcs, pages 23:1–23:15. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2021. doi: 10.4230/LIPIcs. ICALP.2021.23. URL https://doi.org/10.4230/LIPIcs.ICALP.2021.23.\
[9] Luca Becchetti, Marc Bury, Vincent Cohen-Addad, Fabrizio Grandoni, and Chris Schwiegelshohn. Oblivious dimension reduction for k-means: beyond subspaces and the johnson-lindenstrauss lemma. In Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix, AZ, USA, June 23-26, 2019, pages 1039–1050, 2019. doi: 10.1145/3313276. 3316318. URL https://doi.org/10.1145/3313276.3316318.\
[10] Shai Ben-David. A framework for statistical clustering with constant time approximation algorithms for K-median and K-means clustering. Mach. Learn., 66(2-3):243–257, 2007. doi: 10.1007/s10994-006-0587-3. URL https://doi.org/10.1007/s10994-006-0587-3.\
[11] Jon Louis Bentley and James B. Saxe. Decomposable searching problems I: static-to-dynamic transformation. J. Algorithms, 1(4):301–358, 1980. doi: 10.1016/0196-6774(80)90015-2. URL https://doi.org/10.1016/0196-6774(80)90015-2.\
[12] Thierry Bertin-Mahieux, Daniel P. W. Ellis, Brian Whitman, and Paul Lamere. The million song dataset. pages 591–596, 2011. doi: 10.7916/D8NZ8J07. URL http://ismir2011.ismir.net/ papers/OS6-1.pdf.\
[13] Jock A Blackard and Denis J Dean. Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables. Computers and electronics in agriculture, 24(3):131–151, 1999. doi: 10.1016/S0168-1699(99)00046-0. URL https://doi.org/10.1016/S0168-1699(99)00046-0.\
[14] Vladimir Braverman, Shaofeng H.-C. Jiang, Robert Krauthgamer, and Xuan Wu. Coresets for clustering in excluded-minor graphs and beyond. In Dániel Marx, editor, Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms, SODA 2021, Virtual Conference, January 10 - 13, 2021, pages 2679–2696. SIAM, 2021. doi: 10.1137/1.9781611976465.159. URL https://doi.org/10.1137/1.9781611976465.159.\
[15] Vladimir Braverman, Vincent Cohen-Addad, Shaofeng H.-C. Jiang, Robert Krauthgamer, Chris Schwiegelshohn, Mads Bech Toftrup, and Xuan Wu. The power of uniform sampling for coresets. In 63rd IEEE Annual Symposium on Foundations of Computer Science, FOCS 2022, Denver, CO, USA, October 31 - November 3, 2022, pages 462–473. IEEE, 2022. doi: 10.1109/FOCS54457. 2022.00051. URL https://doi.org/10.1109/FOCS54457.2022.00051.\
[16] Ke Chen. On coresets for k-median and k-means clustering in metric and euclidean spaces and their applications. SIAM J. Comput., 39(3):923–947, 2009. doi: 10.1137/070699007. URL https://doi.org/10.1137/070699007.\
[17] Flavio Chierichetti, Nilesh N. Dalvi, and Ravi Kumar. Correlation clustering in mapreduce. In Sofus A. Macskassy, Claudia Perlich, Jure Leskovec, Wei Wang, and Rayid Ghani, editors, The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’14, New York, NY, USA - August 24 - 27, 2014, pages 641–650. ACM, 2014. doi: 10.1145/2623330.2623743. URL https://doi.org/10.1145/2623330.2623743.\
[18] Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvitskii. Fair clustering through fairlets. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett, editors, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 5029–5037, 2017. URL https://proceedings.neurips.cc/ paper/2017/hash/978fce5bcc4eccc88ad48ce3914124a2-Abstract.html.\
[19] Michael B. Cohen, Sam Elder, Cameron Musco, Christopher Musco, and Madalina Persu. Dimensionality reduction for k-means clustering and low rank approximation. In Rocco A. Servedio and Ronitt Rubinfeld, editors, Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, STOC 2015, Portland, OR, USA, June 14-17, 2015, pages 163–172. ACM, 2015. doi: 10.1145/2746539.2746569. URL https://doi.org/10.1145/2746539.2746569.\
[20] Michael B. Cohen, Yin Tat Lee, Gary L. Miller, Jakub Pachocki, and Aaron Sidford. Geometric median in nearly linear time. In Daniel Wichs and Yishay Mansour, editors, Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016, pages 9–21. ACM, 2016. doi: 10.1145/2897518.2897647. URL https://doi.org/10.1145/2897518.2897647.\
[21] Vincent Cohen-Addad and Jason Li. On the fixed-parameter tractability of capacitated clustering. In 46th International Colloquium on Automata, Languages, and Programming, ICALP 2019, July 9-12, 2019, Patras, Greece, pages 41:1–41:14, 2019. doi: 10.4230/LIPIcs.ICALP.2019.41. URL https://doi.org/10.4230/LIPIcs.ICALP.2019.41.\
[22] Vincent Cohen-Addad and Chris Schwiegelshohn. On the local structure of stable clustering instances. In 58th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2017, Berkeley, CA, USA, October 15-17, 2017, pages 49–60, 2017. doi: 10.1109/FOCS.2017.14. URL https://doi.org/10.1109/FOCS.2017.14.\
[23] Vincent Cohen-Addad, Silvio Lattanzi, Ashkan Norouzi-Fard, Christian Sohler, and Ola Svensson. Fast and accurate k-means++ via rejection sampling. Advances in Neural Information Processing Systems, 33:16235–16245, 2020. URL https://proceedings.neurips.cc/paper/2020/hash/ babcff88f8be8c4795bd6f0f8cccca61-Abstract.html.\
[24] Vincent Cohen-Addad, Silvio Lattanzi, Ashkan Norouzi-Fard, Christian Sohler, and Ola Svensson. Parallel and efficient hierarchical k-median clustering. In Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 20333–20345, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/ aa495e18c7e3a21a4e48923b92048a61-Abstract.html.\
[25] Vincent Cohen-Addad, David Saulpic, and Chris Schwiegelshohn. A new coreset framework for clustering. In Samir Khuller and Virginia Vassilevska Williams, editors, STOC ’21: 53rd Annual ACM SIGACT Symposium on Theory of Computing, Virtual Event, Italy, June 21-25, 2021. ACM, 2021. doi: 10.1145/3406325.3451022. URL https://doi.org/10.1145/3406325.3451022.\
[26] Vincent Cohen-Addad, David Saulpic, and Chris Schwiegelshohn. Improved coresets and sublinear algorithms for power means in euclidean spaces. In Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 21085–21098, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/ b035d6563a2adac9f822940c145263ce-Abstract.html.\
[27] Vincent Cohen-Addad, Kasper Green Larsen, David Saulpic, and Chris Schwiegelshohn. Towards optimal lower bounds for k-median and k-means coresets. In Stefano Leonardi and Anupam Gupta, editors, STOC ’22: 54th Annual ACM SIGACT Symposium on Theory of Computing, Rome, Italy, June 20 - 24, 2022, pages 1038–1051. ACM, 2022. doi: 10.1145/3519935.3519946. URL https://doi.org/10.1145/3519935.3519946.\
[28] Vincent Cohen-Addad, Kasper Green Larsen, David Saulpic, Chris Schwiegelshohn, and Omar Ali Sheikh-Omar. Improved coresets for euclidean k-means. In NeurIPS, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/ 120c9ab5c58ba0fa9dd3a22ace1de245-Abstract-Conference.html.\
[29] Robson Leonardo Ferreira Cordeiro, Caetano Traina Jr., Agma Juci Machado Traina, Julio César López-Hernández, U Kang, and Christos Faloutsos. Clustering very large multi-dimensional datasets with mapreduce. In Chid Apté, Joydeep Ghosh, and Padhraic Smyth, editors, Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Diego, CA, USA, August 21-24, 2011, pages 690–698. ACM, 2011. doi: 10.1145/2020408. 2020516. URL https://doi.org/10.1145/2020408.2020516.\
[30] Artur Czumaj and Christian Sohler. Sublinear-time approximation algorithms for clustering via random sampling. Random Struct. Algorithms, 30(1-2):226–256, 2007. doi: 10.1002/RSA.20157. URL https://doi.org/10.1002/rsa.20157.\
[31] Yichuan Deng, Zhao Song, Yitan Wang, and Yuanyuan Yang. A nearly optimal size coreset algorithm with nearly linear time. CoRR, abs/2210.08361, 2022. doi: 10.48550/arXiv.2210.08361. URL https://doi.org/10.48550/arXiv.2210.08361.\
[32] Dheeru Dua and Casey Graff. UCI machine learning repository, 2017. URL http://archive. ics.uci.edu/ml.\
[33] Alina Ene, Sungjin Im, and Benjamin Moseley. Fast clustering using mapreduce. In Chid Apté, Joydeep Ghosh, and Padhraic Smyth, editors, Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Diego, CA, USA, August 21-24, 2011, pages 681–689. ACM, 2011. doi: 10.1145/2020408.2020515. URL https: //doi.org/10.1145/2020408.2020515.\
[34] Georgios Exarchakis, Omar Oubari, and Gregor Lenz. A sampling-based approach for efficient clustering in large datasets. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022, pages 12393–12402. IEEE, 2022. doi: 10.1109/CVPR52688.2022.01208. URL https://doi.org/10.1109/CVPR52688.2022.01208.\
[35] Jittat Fakcharoenphol, Satish Rao, and Kunal Talwar. A tight bound on approximating arbitrary metrics by tree metrics. In Lawrence L. Larmore and Michel X. Goemans, editors, Proceedings of the 35th Annual ACM Symposium on Theory of Computing, June 9-11, 2003, San Diego, CA, USA, pages 448–455. ACM, 2003. doi: 10.1145/780542.780608. URL https://doi.org/10. 1145/780542.780608.\
[36] Dan Feldman. Introduction to core-sets: an updated survey. arXiv preprint arXiv:2011.09384, 2020. doi: 10.1002/widm.1335.\
[37] Dan Feldman and Michael Langberg. A unified framework for approximating and clustering data. In Lance Fortnow and Salil P. Vadhan, editors, Proceedings of the 43rd ACM Symposium on Theory of Computing, STOC 2011, San Jose, CA, USA, 6-8 June 2011, pages 569–578. ACM, 2011. doi: 10.1145/1993636.1993712. URL https://doi.org/10.1145/1993636.1993712.\
[38] Hendrik Fichtenberger, Marc Gillé, Melanie Schmidt, Chris Schwiegelshohn, and Christian Sohler. Bico: Birch meets coresets for k-means clustering. In European symposium on Algorithms, pages 481–492. Springer, 2013.\
[39] Sariel Har-Peled. Geometric approximation algorithms. Number 173. American Mathematical Soc., 2011. doi: 10.1090/surv/173.\
[40] Sariel Har-Peled and Soham Mazumdar. On coresets for k-means and k-median clustering. In László Babai, editor, Proceedings of the 36th Annual ACM Symposium on Theory of Computing, Chicago, IL, USA, June 13-16, 2004, pages 291–300. ACM, 2004. doi: 10.1145/1007352.1007400. URL https://doi.org/10.1145/1007352.1007400.\
[41] Qinghao Hu, Jiaxiang Wu, Lu Bai, Yifan Zhang, and Jian Cheng. Fast k-means for large scale clustering. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, pages 2099–2102, 2017. doi: 10.1145/3132847.3133091.\
[42] Lingxiao Huang and Nisheeth K. Vishnoi. Coresets for clustering in euclidean spaces: importance sampling is nearly optimal. In Konstantin Makarychev, Yury Makarychev, Madhur Tulsiani, Gautam Kamath, and Julia Chuzhoy, editors, Proccedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, STOC 2020, Chicago, IL, USA, June 22-26, 2020, pages 1416–1429. ACM, 2020. doi: 10.1145/3357713.3384296. URL https://doi.org/10.1145/ 3357713.3384296.\
[43] Lingxiao Huang, Shaofeng H.-C. Jiang, and Nisheeth K. Vishnoi. Coresets for clustering with fairness constraints. In NeurIPS, pages 7587–7598, 2019. URL https://proceedings.neurips. cc/paper/2019/hash/810dfbbebb17302018ae903e9cb7a483-Abstract.html.\
[44] Lingxiao Huang, Jian Li, and Xuan Wu. Towards optimal coreset construction for (k, z)-clustering: Breaking the quadratic dependency on k. CoRR, abs/2211.11923, 2022. doi: 10.48550/arXiv. 2211.11923. URL https://doi.org/10.48550/arXiv.2211.11923.\
[45] Lingxiao Huang, Shaofeng H.-C. Jiang, and Jianing Lou. The power of uniform sampling for kmedian. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pages 13933–13956. PMLR, 2023. URL https://proceedings.mlr.press/v202/huang23j.html.\
[46] Amit Kumar and Ravindran Kannan. Clustering with spectral norm and the k-means algorithm. In 51th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2010, October 23-26, 2010, Las Vegas, Nevada, USA, pages 299–308, 2010. doi: 10.1109/FOCS.2010.35. URL http://dx.doi.org/10.1109/FOCS.2010.35.\
[47] Michael Langberg and Leonard J. Schulman. Universal epsilon-approximators for integrals. In Moses Charikar, editor, Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2010, Austin, Texas, USA, January 17-19, 2010, pages 598–607. SIAM, 2010. doi: 10.1137/1.9781611973075.50. URL https://doi.org/10.1137/1.9781611973075.50.\
[48] Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proc. IEEE, 86(11):2278–2324, 1998. doi: 10.1109/5.726791. URL https://doi.org/10.1109/5.726791.\
[49] Stuart P. Lloyd. Least squares quantization in PCM. IEEE Trans. Inf. Theory, 28(2):129–136, 1982. doi: 10.1109/TIT.1982.1056489. URL https://doi.org/10.1109/TIT.1982.1056489.\
[50] Konstantin Makarychev, Yury Makarychev, and Ilya P. Razenshteyn. Performance of johnsonlindenstrauss transform for k-means and k-medians clustering. In Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix, AZ, USA, June 23-26, 2019, pages 1027–1038, 2019. doi: 10.1145/3313276.3316350. URL https://doi.org/10. 1145/3313276.3316350.\
[51] Adam Meyerson, Liadan O’Callaghan, and Serge A. Plotkin. A k-median algorithm with running time independent of data size. Mach. Learn., 56(1-3):61–87, 2004. doi: 10.1023/B: MACH.0000033115.78247.F0. URL https://doi.org/10.1023/B:MACH.0000033115.78247.f0.\
[52] Luis Moreira-Matias, Michel Ferreira, Joao Mendes-Moreira, L. L., and J. J. Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015. UCI Machine Learning Repository, 2015. DOI: https://doi.org/10.24432/C55W25.\
[53] N/A, 1990. URL https://archive.ics.uci.edu/ml/datasets/US+Census+Data+(1990).\
[54] R. Ostrovsky, Y. Rabani, L. J. Schulman, and C. Swamy. The effectiveness of Lloyd-type methods for the k-means problem. J. ACM, 59(6):28, 2012. doi: 10.1145/2395116.2395117. URL http://doi.acm.org/10.1145/2395116.2395117.\
[55] Pixabay. Shooting star sky night royalty-free vector graphic, 2023. URL https://pixabay.com/ vectors/shooting-star-sky-night-dark-stars-2024127/. [Online; accessed Jan 8th 2024].\
[56] Melanie Schmidt, Chris Schwiegelshohn, and Christian Sohler. Fair coresets and streaming algorithms for fair k-means. In Approximation and Online Algorithms - 17th International Workshop, WAOA 2019, Munich, Germany, September 12-13, 2019, Revised Selected Papers, pages 232–251, 2019. doi: 10.1007/978-3-030-39479-0\16. URL https://doi.org/10.1007/ 978-3-030-39479-016.\
[57] Chris Schwiegelshohn and Omar Ali Sheikh-Omar. An empirical evaluation of k-means coresets. In Shiri Chechik, Gonzalo Navarro, Eva Rotenberg, and Grzegorz Herman, editors, 30th Annual European Symposium on Algorithms, ESA 2022, September 5-9, 2022, Berlin/Potsdam, Germany, volume 244 of LIPIcs, pages 84:1–84:17. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2022. doi: 10.4230/LIPIcs.ESA.2022.84. URL https://doi.org/10.4230/LIPIcs.ESA.2022.84.\
[58] Tian Zhang, Raghu Ramakrishnan, and Miron Livny. BIRCH: an efficient data clustering method for very large databases. pages 103–114, 1996. doi: 10.1145/233269.233324. URL https://doi.org/10.1145/233269.233324.]]></content:encoded></item><item><title>The real reason why oil and gas companies are bullish on carbon capture</title><link>https://techcrunch.com/2025/02/21/the-real-reason-why-oil-and-gas-companies-are-bullish-on-carbon-capture/</link><author>Tim De Chant</author><category>tech</category><pubDate>Fri, 21 Feb 2025 17:41:46 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Occidental CEO Vicki Hollub compared using CO2 in enhanced oil recovery to fracking, the technology that sent U.S. oil and gas production skyrocketing.© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>HP Ends Forced 15-Minute Wait Times for Customer Support</title><link>https://it.slashdot.org/story/25/02/21/1740213/hp-ends-forced-15-minute-wait-times-for-customer-support?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 21 Feb 2025 17:40:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[HP has ended its controversial practice of imposing mandatory 15-minute wait times for customer support calls in several European countries, following internal pushback and customer complaints. 

The company confirmed the reversal and said it will "continue to prioritize timely access to live phone support."]]></content:encoded></item><item><title>Utah GOP Lawmaker Pushes Bill That Bans Pride Flags While Allowing Nazi Flags To Be Displayed</title><link>https://www.techdirt.com/2025/02/21/utah-gop-lawmaker-pushes-bill-that-bans-pride-flags-while-allowing-nazi-flags-to-be-displayed/</link><author>Tim Cushing</author><category>tech</category><pubDate>Fri, 21 Feb 2025 17:35:00 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[Utah state Rep. Trevor Lee is not going to like this headline. Too bad. It’s accurate, even if he’d like to pretend it isn’t.Trevor Lee is again pushing a bill that would ban government agencies from displaying pride flags, but would allow Nazi and Confederate flags to be displayed in classrooms, so long as they are part of the so-called educational experience.This bill originally only targeted schools, but the first amending of the bill expanded its coverage to all government entities, state and local. Here’s the Salt Lake Tribune’s original reporting that managed to anger Rep. Lee so much he demanded a retraction: The bill, , originally applied only to schools. But an update to the bill released ahead of Thursday’s House Education Committee hearing expands the ban to all government buildings or property. The updated bill was favorably recommended by the committee, with the committee’s two Democrats — Reps. Sahara Hayes and Carol Moss — casting the only “nays.” It will now be heard on the full House floor.Approved flags for display in government buildings and schools would include the Utah state and U.S. flags, military flags, flags for other countries, flags for Native American tribes and official flags for colleges and universities. The bill also allows for the flying of a “historic version of a flag … that is temporarily displayed for educational purposes,” which Lee, R-Layton, said would include the Confederate and Nazi flags.Shortly after this was published, the bill was amended to make it exactly as bad as Trevor Lee’s defense of his original bill in its un-amended form. While this was happening, Rep. Lee was going after the Salt Lake City Tribune, claiming it was spreading lies by publishing direct quotes of things he said while trying to push his bill forward. “There are instances where in classrooms, you have curriculum that is needed to use flags such as World War II, Civil War,” he said. “You may have a Nazi flag. You may have a Confederate flag, and so you are allowed to display those flags for the purpose of those lesson plans if it’s part of the curriculum, and that is okay.”And here’s what he said after the Tribune posted its report with a headline that said (completely truthfully) that the bill would ban displays of the pride flag in schools but allow the display of Nazi and Confederate flags.In an interview that night, Lee denied that he ever said there would be instances where a teacher could “display” a Nazi flag, and expressed displeasure that The Tribune would publish his testimony about displaying Nazi and Confederate flags in classrooms.“There is a difference between displaying flags in curriculum when you’re teaching on them,” he said. “You don’t censor history here. That’s not what we’re doing.” When asked to further explain his remarks, Lee hung up the phone.Well, a pride flag is also a historical flag, but there appears to be no exception specifically written into the law to allow its use “in curriculum.” And when Lee’s extended explanation was [checks notes] hanging up the phone, it’s completely fair to categorize the bill as a ban on pride flags, while allowing exceptions for symbols of hate, provided any teacher with the temerity to insist the only way to teach history is to display these symbols of hate in their classrooms, rather than just rely on depictions contained in textbooks or presentations.Hanging up on Tribune reporters wasn’t enough for Rep. Lee. He insisted on having the last, insipidly incoherent, word. Asked Friday morning about the amended bill, Lee commented only on the headline of the previous story on his bill. “Redact your ridiculous headline,” he wrote in a text message, before adding that The Tribune should “apologize for sowing divide and spreading hate to the general public.”Sowing divide and spreading hate is pretty much Rep. Lee’s day job. The representative prefers the reporting of another Utah News source, touting its article on the preferred platform for sowing divide and spreading hate: xTwitter.A ban on MAGA and Pride flags? GOP lawmakers say yes for cities, counties and classroomsWhile it’s true the bill would (perhaps accidentally) forbid displaying the MAGA flag, there was literally no one mentioning their opposition to government workers displaying MAGA flags. That might be because no government employee has. It also might be that several have done this but no “concerned citizen” has bothered to complain about it during comment periods. In fact, the only incident described in public testimony about the law is something that probably never happened, at least not in the way it’s described here.Two years ago, Lehi resident Aaron Bullen’s 10-year-old son came home upset from elementary school because a rainbow flag had been placed in his computer lab, he told the committee.The rainbow, or pride, flag, which represents LGBTQ acceptance, was taken down after a complaint was made to the principal, but it temporarily allowed the school to promote a symbol that was offensive to his son, Bullen said.“This message conflicts with my family’s religious beliefs. It tells my son that his faith, his parents and his values are wrong,” Bullen said. “That is not neutrality; that is religious discrimination at a public institution.”Aaron Bullen is a ridiculous person and is telling a ridiculous story. I cannot imagine a ten-year-old coming home distraught because they saw a flag in a classroom. I can certainly imagine them  it and their parents getting all shitty about it because of their own ingrained bigotry. And a flag does not “conflict” with “religious beliefs,” no matter what’s on it. You still get to keep your religious beliefs. No flag can take that away from you. And calling it “religious discrimination” is especially stupid and inadvertently hilarious because, as far as I can tell, sexual orientation is not a religion. For all of Rep. Lee’s claims that this is about preventing the display of “divisive” flags (which may include MAGA flags), the real point of this bill is exactly how it’s described in the Tribune article that turned Lee into a corncob. He has admitted as much on ExTwitter:If you can’t see the embed, it says:My bill specifies which flags can be displayed in classrooms. It would ban Pride flags from schools. Parents could sue the school district if it’s violated.His private ExTwitter account (which was public until journalists started digging into his hateful posts during his election run) is even worse than his official one. A long article detailing his social media activity shows Rep. Lee spent years using anti-LGBTQ+ slurs, insulting the looks of female politicians and judges he didn’t agree with, spreading 2020 election conspiracies, and engaging with others as an avid supporter of a Latter Day Saints splinter group that advocates against the perceived “wokeness” of the religion’s current leadership.So, when Lee says (before acting like yelling and hanging up on people is some form of rebuttal) he will outlaw pride flags but provide exceptions for Nazi and Confederate flags, it’s best to take him at his word. And if he doesn’t like the headlines it generates, maybe he should do something to stop generating them… like dropping the bill or just not being the sort of asshole who prefers Nazi flags to rainbows.]]></content:encoded></item><item><title>EFF at RightsCon 2025</title><link>https://www.eff.org/deeplinks/2025/02/eff-rightscon-2025</link><author>Paige Collings</author><category>tech</category><enclosure url="https://www.eff.org/files/banner_library/rightscon2025.jpg" length="" type=""/><pubDate>Fri, 21 Feb 2025 17:31:37 +0000</pubDate><source url="https://www.eff.org/rss/updates.xml">Deeplinks</source><content:encoded><![CDATA[Day 0 (Monday 24 February)Mutual Support: Amplifying the Voices of Digital Rights Defenders in Taiwan and East AsiaPlatform accountability in crisis? Global perspective on platform accountability frameworksDay 1 (Tuesday 25 February) Criminalization of Tor in Ola Bini’s case? Lessons for digital experts in the Global SouthThe counter-surveillance supply chainDay 3 (Wednesday 26 February) Derecho a no ser objeto de decisiones automatizadas: desafíos y regulaciones en el sector judicialA través de este panel se analizarán casos específicos de México, Perú y Colombia para comprender las implicaciones éticas y jurídicas del uso de la inteligencia artificial en la redacción y motivación de sentencias judiciales. Con este diálogo se busca abordar el derecho a no ser objeto de decisiones automatizadas y las implicaciones éticas y jurídicas sobre la automatización de sentencias judiciales. Algunas herramientas pueden reproducir o amplificar estereotipos discriminatorios, además de posibles violaciones a los derechos de privacidad y protección de datos personales, entre otros.Prying Open the Age-Gate: Crafting a Human Rights Statement Against Age Verification MandatesThe session will engage participants in considering the issues and seeding the drafting of a global human rights statement on online age verification mandates. After a background presentation on various global legal models to challenge such mandates (with the facilitators representing Asia, Africa, Europe, US), participants will be encouraged to submit written inputs (that will be read during the session) and contribute to a discussion. This will be the start of an ongoing effort that will extend beyond RightsCon with the goal of producing a human rights statement that will be shared and endorsed broadly. Day 4 (Thursday 27 February) Let's talk about the elephant in the room: transnational policing and human rightsQueer over fear: cross-regional strategies and community resistance for LGBTQ+ activists fighting against digital authoritarianism]]></content:encoded></item><item><title>&apos;The Bigotry Is Astounding:&apos; Engineers Waste Time and Money Scanning .Gov Sites for &apos;Transgender&apos; and Other Terms</title><link>https://www.404media.co/the-bigotry-is-astounding-engineers-waste-time-and-money-scanning-gov-sites-for-transgender-and-other-terms/</link><author>Emanuel Maiberg</author><category>tech</category><enclosure url="https://www.404media.co/content/images/2025/02/President_Donald_Trump_signing_executive_orders_-04-.jpg" length="" type=""/><pubDate>Fri, 21 Feb 2025 17:31:18 +0000</pubDate><source url="https://www.404media.co/">404</source><content:encoded><![CDATA[The U.S. Department of Health and Human Services (HHS) is wasting workers’ time and taxpayer dollars on “a witch hunt to find any content deemed ‘bad,’” according to a source familiar with the work and internal communications viewed by 404 Media. Specifically, people who work on HHS websites are spending days scanning those sites and any documents they share in search of a list terms like “gay,” “sexuality,” “non-binary,” “inclusion,” “queer,” and “gender,” potentially so they could be later removed to comply with Trump’s executive orders attacking diversity, equity, and inclusion in the federal government.“The most obvious issue to me about this list is that it’s being done in the name of ‘efficiency and saving money.’ It is not efficient to take engineers off their work to scan old content for any keywords this new administration hates. The bigotry is astounding,” the source who is familiar with the work and who asked to be anonymous because they were not permitted to speak to the press, told me. “If they were being true to the concept, sure, they could say that moving forward, we will no longer support creation of new data about these topics. But to go backward decades, scrubbing for stuff they hate, that’s not a savings of time and money, that’s a huge expenditure. It's hypocritical on top of it all.”Do you know anything else about DOGE and how Trump's executive orders are impacting HHS or other agencies? I would love to hear from you. Using a non-work device, you can message me securely on Signal at ‪emanuel.404‬. Otherwise, send me an email at emanuel@404media.co.The source said that part of what makes the work so time consuming is that the current HHS administration doesn’t just want to know about every page on its sites that include these terms, but also pages that link out to .PDF files that include those terms. For example, last week we reported that the Trump administration added a note rejecting “gender ideology” on a Substance Abuse and Mental Health Services Administration’s website page that shared a .PDF of a study about substance abuse among gay, lesbian, bisexual, or other nonheterosexual adolescents. According to the source, HHS administrators want that page added to a spreadsheet of pages and documents that include the terms it's looking for because of the content of the study. Since HHS websites share thousands of .PDFs, the source said, “very expensive” engineers spent multiple days scanning the files for the list of terms instead of doing their regular tasks. Other terms on the list include “they/them” pronouns, “pregnant ‘people,’” “Biden,” and “intersex,” according to a copy of the list seen by 404 Media.The fact that the government is wasting resources finding every instance of a term it finds objectionable directly contradicts Trump’s and Musk’s stated goal of “government efficiency.” Finding these terms in thousands of studies and papers and potentially removing them is not saving any taxpayer dollars, but just purging government sites with a perspective it disagrees with. Other agencies have also scrambled to find similar terms.  reported that DOGE representatives at the National Oceanic and Atmospheric Administration are searching for “DEI content” and  has reported that a number of federal health agencies are searching grants for “taboo words” like “trans” and “diversity.” “The spitefulness is such a waste of time and money. It's infuriating,” the source said. “Sure, they might argue not to do anything inclusive or helpful in the future, but to burn so much time and money trying to scrub out any content he [Trump] hates from past decades is ... I'm kinda at a loss for words.”At the moment, it appears that HHS is not removing pages that contain the terms it’s looking for because a federal judge ordered it and other agencies to restore several webpages they removed as a result of Trump’s executive order. The court ordered the administration to restore the webpages to their versions as of January 30, 2025, meaning they were supposed to revert the webpages to what they looked like on January 30 with no changes. The versions that have been restored now have this additional disclaimer about “gender ideology” we reported on last week.]]></content:encoded></item><item><title>Make Big Data More Manageable with Smart Sampling</title><link>https://hackernoon.com/make-big-data-more-manageable-with-smart-sampling?source=rss</link><author>Scripting Technology</author><category>tech</category><pubDate>Fri, 21 Feb 2025 17:30:02 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) Andrew Draganov, Aarhus University and All authors contributed equally to this research;(2) David Saulpic, Université Paris Cité & CNRS;(3) Chris Schwiegelshohn, Aarhus University.2 Preliminaries and Related WorkIn this work, we discussed the theoretical and practical limits of compression algorithms for center-based clustering. We proposed the first nearly-linear time coreset algorithm for k-median and k-means. Moreover, the algorithm can be parameterized to achieve an asymptotically optimal coreset size. Subsequently, we conducted a thorough experimental analysis comparing this algorithm with fast sampling heuristics. In doing so, we find that although the Fast-Coreset algorithm achieves the best compression guarantees among its competitors, naive uniform sampling is already a sufficient compression for downstream clustering tasks in well-behaved datasets. Furthermore, we find that intermediate heuristics interpolating between uniform sampling and coresets play an important role in balancing efficiency and accuracy.\
Although this closes the door on the highly-studied problem of optimally small and fast coresets for k-median and k-means, open questions of wider scope still remain. For example, when does sensitivity sampling guarantee accurate compression with optimal space in linear time and can these conditions be formalized? Furthermore, sensitivity sampling is incompatible with paradigms such as fair-clustering [8, 15, 21, 43, 56] and it is unclear whether one can expect that a linear-time method can optimally compress a dataset while adhering to the fairness constraints.Andrew Draganov and Chris Schwiegelshohn are partially supported by the Independent Research Fund Denmark (DFF) under a Sapere Aude Research Leader grant No 1051-00106B. David Sauplic has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 101034413.]]></content:encoded></item><item><title>Behind the Blog: Chatbots as Gospel, Books and Birds</title><link>https://www.404media.co/behind-the-blog-chatbots-as-gospel-books-and-birds/</link><author>Samantha Cole</author><category>tech</category><enclosure url="https://www.404media.co/content/images/2025/02/btb2.21--1-.png" length="" type=""/><pubDate>Fri, 21 Feb 2025 17:04:48 +0000</pubDate><source url="https://www.404media.co/">404</source><content:encoded><![CDATA[This is Behind the Blog, where we share our behind-the-scenes thoughts about how a few of our top stories of the week came together. This week, we discuss the new Murderbot show, ChatGPT for journalism, and birdwatching from afar.: Yesterday Apple released the first two images from its upcoming sci-fi show, , and announced that it will debut on May 16 this year. I, like many fans of the  books the series is based on, am very excited about the show, but also already disappointed with one major deviation from the source material that’s obvious just from these two still images. The gist is in the show Murderbot is played by Alexander Skarsgård, who in the images looks like a guy, while in the books Murderbot is neither a he or a she, but an “it,” and while it’s not at all the focus of the story, the fact that the main character is androgynous make it much more interesting. To back up,  are set in the far, far future and follow a “SecUnit,” a super advanced, super lethal cyborg who does private security for scientists and corporations exploring deep space and dangerous planets. Eventually the SecUnit, who we come to know as Murderbot hacks the governing module that keeps it enslaved and has to choose what to do with its independence as it goes off on a series of pulpy space adventures. ]]></content:encoded></item><item><title>Video Friday: Helix</title><link>https://spectrum.ieee.org/video-friday-helix</link><author>Evan Ackerman</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjU2MzQxMy9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc2ODQ0MDE3NX0.4hvjtcrpmoM_e-TOk1dXbqY4mjzsR0IDso31LXGPJ4k/image.png?width=600" length="" type=""/><pubDate>Fri, 21 Feb 2025 17:00:05 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[Your weekly selection of awesome robot videos]]></content:encoded></item><item><title>How automotive exec Crystal Brown founded CircNova, an AI drug discovery biotech</title><link>https://techcrunch.com/2025/02/21/how-automotive-exec-crystal-brown-founded-circnova-an-ai-drug-discovery-biotech/</link><author>Julie Bort</author><category>tech</category><pubDate>Fri, 21 Feb 2025 17:00:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Tiny Michigan biotech startup CircNova has raised a $3.3 million seed round for its technology that uses AI to target “circular RNA.” The development holds promise as a new method to quickly develop therapies for conditions that currently have no drug treatments. The new funding is also a victory lap for co-founder and CEO Crystal […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Bybit CEO Confirms Exchange Was Hacked for $1.46B, Says His Firm Can Cover The Loss</title><link>https://it.slashdot.org/story/25/02/21/1630207/bybit-ceo-confirms-exchange-was-hacked-for-146b-says-his-firm-can-cover-the-loss?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 21 Feb 2025 16:45:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Cryptocurrency exchange Bybit has experienced $1.46 billion worth of "suspicious outflows," according to blockchain sleuth ZachXBT. From a report: The wallet in question appears to have sent 401,346 ETH ($1.1 billion) as well as several other iterations of staked ether (stETH) to a fresh wallet, which is now liquidating mETH and stETH on decentralized exchanges, etherscan shows. The wallet has sold around $200 million worth of stETH so far. Bybit CEO Ben Zhou wrote on X that a hacker "took control of the specific ETH cold wallet and transferred all the ETH in the cold wallet to this unidentified address."]]></content:encoded></item><item><title>Five of the most important fintech VCs investing heavily in the sector</title><link>https://techcrunch.com/2025/02/21/the-most-important-fintech-vcs-investing-heavily-in-the-sector/</link><author>Mary Ann Azevedo</author><category>tech</category><pubDate>Fri, 21 Feb 2025 16:30:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Global investing in fintech startups is starting to see an uptick. Just this week, KPMG issued its Pulse of Fintech report for the second half of 2024. In the fourth quarter of 2024, investment climbed to $25.9 billion from $18 billion in the third quarter, according to KPMG. Granted, this is not the enthusiasm of […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Linux&apos;s FineIBT Protections &quot;Critically Flawed&quot; Until Intel CPUs Appear With FRED</title><link>https://www.phoronix.com/news/Linux-FineIBT-Critically-Flawed</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 21 Feb 2025 16:28:37 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[FineIBT is a Linux kernel initiative led by Intel engineers that aimed to combine the best of Intel Control-flow Enforcement Technology (CET) and Control Flow Integrity. FineIBT was merged in 2022 for the Linux 6.2 kernel as an alternative control flow integrity implementation. Some FineIBT weaknesses were previously addressed but now the implementation has been determined to be "critically flawed" at least until next-generation Intel processors appear with FRED...]]></content:encoded></item><item><title>New WinRAR Version Strips Windows Metadata In Privacy Push</title><link>https://yro.slashdot.org/story/25/02/21/1616245/new-winrar-version-strips-windows-metadata-in-privacy-push?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 21 Feb 2025 16:16:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[WinRAR 7.10 now lets users remove potentially sensitive metadata from downloaded files while preserving core Windows security features. The file compression tool's latest release introduces a "Zone value only" setting that strips download locations and IP addresses from Windows' Mark-of-the-Web security flags during file extraction. 

The new privacy control, enabled by default, maintains only the basic security zone identifier that triggers Windows' safety prompts for downloaded files. This change prevents recipients of shared archives from accessing metadata that could reveal where files originated. The update from win.rar GmbH, whose compression software claims 500 million users worldwide, also adds performance improvements through larger memory page support and introduces a dark mode interface.]]></content:encoded></item><item><title>Report: AI coding assistants aren’t a panacea</title><link>https://techcrunch.com/2025/02/21/report-ai-coding-assistants-arent-a-panacea/</link><author>Kyle Wiggers</author><category>tech</category><pubDate>Fri, 21 Feb 2025 16:11:09 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[As they gain in popularity, AI coding assistants such as GitHub Copilot may appear to be boosting productivity. But in reality, they could be causing overall code quality to decline. That’s the top-line finding from a new report released by software engineering platform GitClear, which analyzed 211 million code lines from 2020 to 2024. According […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Utah Bill Aims to Make Officers Disclose AI-Written Police Reports</title><link>https://www.eff.org/deeplinks/2025/02/utah-bill-aims-make-officers-disclose-ai-written-police-reports</link><author>Matthew Guariglia</author><category>tech</category><enclosure url="https://www.eff.org/files/banner_library/police-surveillance-hat.jpg" length="" type=""/><pubDate>Fri, 21 Feb 2025 16:07:23 +0000</pubDate><source url="https://www.eff.org/rss/updates.xml">Deeplinks</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>The HackerNoon Newsletter: IBM Researchers Create Mini AI Model That Predicts the Future (2/21/2025)</title><link>https://hackernoon.com/2-21-2025-newsletter?source=rss</link><author>Noonification</author><category>tech</category><pubDate>Fri, 21 Feb 2025 16:04:48 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[🪐 What’s happening in tech today, February 21, 2025?By @hackernooncontests [ 2 Min read ] Join the #blockchain Writing Contest and share your insights on decentralized AI, cloud, or dePIN. Win up to $2,000! Contest open Feb 5–May 7, 2025. Read More.By @oleksiijko [ 13 Min read ] The project is built on the principle of microservice architecture, which allows you to divide functionality into independent services.  Read More.By @allan-grain [ 4 Min read ] While China’s AI race is managed by the government, in the U.S., AI is primarily driven by tech giants. Read More.By @maxo1st [ 5 Min read ] NFT Paris 2025 review: A vibrant Web3 event showcasing NFTs, tokenization, AI, Bitcoin Ordinals and innovation—but onboarding challenges still hold us back.  Read More.By @fewshot [ 6 Min read ] Researchers have developed a practical, efficient alternative to massive AI models for time series forecasting.  Read More.🧑‍💻 What happened in your world this week?We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, 
 The HackerNoon Team ✌️]]></content:encoded></item><item><title>TSJ Diversified Group, Smart Mountain, Self-employed in Austria: HackerNoon Startups of The Week</title><link>https://hackernoon.com/tsj-diversified-group-smart-mountain-self-employed-in-austria-hackernoon-startups-of-the-week?source=rss</link><author>Startups Of The Week</author><category>tech</category><pubDate>Fri, 21 Feb 2025 16:00:06 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[\
Welcome to another Startups of the Week feature!\
Each week, the HackerNoon team highlights standout Startups from our Startups of the Year database. Every featured startup, has been nominated as the best in their respective technology category or region.:::tip
Want to be nominated for HackerNoon’s Startups of The Year? Learn how .Meet the Startups of the WeekTSJ Diversified Group is a dynamic company operating across digital marketing, IT solutions, and technology-driven innovation. Committed to excellence and forward-thinking solutions, the company empowers businesses with cutting-edge strategies that enhance growth and efficiency.:::info
Support TSJ Diversified Group by voting Smart Mountain is a Deeptech Climate Finance project developing Proof-of-Concept for what would be the world's first Generative AI Environmental Financial Institution (EFI). Its goal is to create a digital platform that reduces risks in financing blue carbon projects by verifying impacts and using an offset model to scale innovative Smart Impact Special Purpose Vehicles (SPVs).:::info
Vote for Smart Mountain .Self-Employed in Austria (SEA) simplifies self-employment for English speakers in Austria by providing clear resources, expert guidance, and a supportive community. Founded in 2020, it has grown from a Facebook group into a trusted hub with 7,000+ members, offering guidebooks, articles, and an interactive forum to help entrepreneurs navigate Austria’s legal and tax landscape with confidence.:::info
Support Self-Employed in Austria, vote Featured Interview of the Week\
For your free interview, you can choose from our , tailored to specific industries and regions. For example, the  helps Lagos-based startups highlight their journey, impact, and vision. This template guides founders in showcasing how the Lagos startup ecosystem has shaped their growth, what sets them apart, and how they’re making a difference.\
TSJ Diversified Group opted for our , where they shared why Startups of the Year 2024 is a rare opportunity for emerging businesses:Being nominated for Startups of the Year 2024 is not just an honor, but a validation of the hard work and dedication our team has put into building TSJ Diversified Group. This recognition means that our efforts to innovate and diversify have resonated within the industry, and it motivates us to continue pushing the boundaries of what we can achieve. More than just a milestone, it’s an opportunity to reflect on our growth and look forward to what’s next.Featured Startups Special PackageDiscover our Lead Generation package, delivering 1M impressions through the HackerNoon Newsletter!\
With this package, you’ll get:That’s all for this week, hackers!]]></content:encoded></item><item><title>Apply to Speak at TechCrunch Sessions: AI before the deadline</title><link>https://techcrunch.com/2025/02/21/apply-to-speak-at-techcrunch-sessions-ai-before-the-deadline/</link><author>TechCrunch Events</author><category>tech</category><pubDate>Fri, 21 Feb 2025 16:00:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[AI Innovators, seize your moment! Have insights that could inspire 1,200 AI founders, investors, and enthusiasts eager to advance the future of AI? Take center stage, influence the AI conversation, and exchange ideas at TechCrunch Sessions: AI on June 5 at UC Berkeley’s Zellerbach Hall. We’re gathering top AI visionaries from the startup world to […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Apple pulls iCloud end-to-end encryption feature for UK users after government demanded backdoor</title><link>https://techcrunch.com/2025/02/21/apple-pulls-icloud-end-to-end-encryption-feature-for-uk-users-after-government-demanded-backdoor/</link><author>Lorenzo Franceschi-Bicchierai</author><category>tech</category><pubDate>Fri, 21 Feb 2025 15:58:24 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[In an unprecedented step, Apple caved to a reported U.K. government’s demand to prevent users from using end-to-end encryption in iCloud.© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>HP realizes that mandatory 15-minute support call wait times isn’t good support</title><link>https://arstechnica.com/gadgets/2025/02/misguided-hp-customer-support-approach-included-forced-15-minute-call-wait-times/</link><author>Scharon Harding</author><category>tech</category><enclosure url="https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-1400844458-1152x648.jpg" length="" type=""/><pubDate>Fri, 21 Feb 2025 15:45:17 +0000</pubDate><source url="https://arstechnica.com/">Biz &amp; IT – Ars Technica</source><content:encoded><![CDATA[In an odd approach to trying to improve customer tech support, HP allegedly implemented mandatory, 15-minute wait times for people calling the vendor for help with their computers and printers in certain geographies.Callers from the United Kingdom, France, Germany, Ireland, and Italy were met with the forced holding periods, The Register reported on Thursday. The publication cited internal communications it saw from February 18 that reportedly said the wait times aimed to "influence customers to increase their adoption of digital self-solve, as a faster way to address their support question. This involves inserting a message of high call volumes, to expect a delay in connecting to an agent and offering digital self-solve solutions as an alternative.”Even if HP's telephone support center wasn't busy, callers would reportedly hear:]]></content:encoded></item><item><title>DeepSeek to open source parts of online services code</title><link>https://techcrunch.com/2025/02/21/deepseek-to-open-source-parts-of-online-services-code/</link><author>Kyle Wiggers</author><category>tech</category><pubDate>Fri, 21 Feb 2025 15:36:46 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Chinese AI lab DeepSeek plans to open source portions of its online services’ code as part of an “open source week” event next week. DeepSeek will open source five code repositories that have been “documented, deployed and battle-tested in production,” the company said in a post on X on Thursday. Code repositories are storage locations […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Apple Removes Cloud Encryption Feature From UK After Backdoor Order</title><link>https://apple.slashdot.org/story/25/02/21/1529255/apple-removes-cloud-encryption-feature-from-uk-after-backdoor-order?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>msmash</author><category>tech</category><pubDate>Fri, 21 Feb 2025 15:29:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Apple is removing its most advanced, end-to-end encrypted security feature for cloud data in the United Kingdom [alternative source], in a stunning development after the government ordered the company to build a backdoor for accessing user data. From a report: The company said Friday that Advanced Data Protection, an optional feature that adds end-to-end encryption to a wide assortment of user data is no longer available in the UK for new users. 

This layer of security covers iCloud data storage, device backups, web bookmarks, voice memos, notes, photos, reminders and text message backups. "We are gravely disappointed that the protections provided by ADP will not be available to our customers in the UK given the continuing rise of data breaches and other threats to customer privacy," the company said in a statement. "ADP protects iCloud data with end-to-end encryption, which means the data can only be decrypted by the user who owns it, and only on their trusted devices."]]></content:encoded></item><item><title>A huge trove of leaked Black Basta chat logs expose the ransomware gang’s key members and victims</title><link>https://techcrunch.com/2025/02/21/a-huge-trove-of-leaked-black-basta-chat-logs-expose-the-ransomware-gangs-key-members-and-victims/</link><author>Carly Page, Zack Whittaker</author><category>tech</category><pubDate>Fri, 21 Feb 2025 15:22:20 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[A leaker allegedly published the leaked internal messages after the group allegedly targeted Russian banks© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>How ‘Event Scripts’ Structure Our Personal Memories</title><link>https://www.quantamagazine.org/how-event-scripts-structure-our-personal-memories-20250221/</link><author>Ingrid Wickelgren</author><category>Quanta Magazine</category><category>tech</category><enclosure url="https://www.quantamagazine.org/wp-content/uploads/2025/02/Memory-Scripts_crKouzou-Sakai-Default-1.webp" length="" type=""/><pubDate>Fri, 21 Feb 2025 15:18:14 +0000</pubDate><source url="https://www.quantamagazine.org/">Quanta Magazine</source><content:encoded><![CDATA[After shuffling the cards in a standard 52-card deck, Alex Mullen, a three-time world memory champion, can memorize their order in under 20 seconds. As he flips though the cards, he takes a mental walk through a house. At each point in his journey — the mailbox, front door, staircase and so on — he attaches a card. To recall the cards, he relives the trip. This technique, called “method of loci”…]]></content:encoded></item><item><title>RISC-V was supposed to change everything—How&apos;s it going?</title><link>https://www.youtube.com/watch?v=1565YYsFmd4</link><author>Jeff Geerling</author><category>tech</category><category>video</category><enclosure url="https://www.youtube.com/v/1565YYsFmd4?version=3" length="" type=""/><pubDate>Fri, 21 Feb 2025 15:00:01 +0000</pubDate><source url="https://www.youtube.com/channel/UCR-DXc1voovS8nhAvccRZhg">Jeff Goerling yt channel</source><content:encoded><![CDATA[RISC-V shenanigans with GPUs and AAA games on the HiFive Premier P550.

The HiFive Premier P550 and case were provided by SiFive for my review and testing. They did not pay for this video or have any input into its production—however because the hardware was provided for review, I mark the video with YouTube's 'includes paid sponsorship' option. See my sponsorship and review unit policies here: https://github.com/geerlingguy/youtube?tab=readme-ov-file#sponsorships

Resources mentioned in this video:

  - SiFive HiFive Premier P550: https://www.sifive.com/boards/hifive-premier-p550
  - ALL my test data: https://github.com/geerlingguy/sbc-reviews/issues/65
  - Guide for installing Box64, Box32, and Wine on the P550: https://www.jeffgeerling.com/blog/2025/build-box64-box32-x86-emulation-on-risc-v-linux
  - Explaining Computers P550 Overview: https://www.youtube.com/watch?v=9KTbi8dJjzQ
  - Chips and Cheese Article on P550: https://chipsandcheese.com/p/a-risc-v-progress-check-benchmarking

Support me on Patreon: https://www.patreon.com/geerlingguy
Sponsor me on GitHub: https://github.com/sponsors/geerlingguy
Merch: https://www.redshirtjeff.com
2nd Channel: https://www.youtube.com/@GeerlingEngineering
3rd Channel: https://www.youtube.com/@Level2Jeff

Contents:

00:00 - RISC architecture's gonna change everything
01:14 - The fastest RISC-V Dev Board
03:24 - Hardware overview and quirks
05:13 - Potential, not realized
06:25 - PCIe - NVMe performance
07:40 - PCIe - AMD GPU support
08:58 - What about AAA Windows x86 games?
11:52 - What about Indie Windows x86 games?
12:23 - LLMs make more sense than games
13:39 - You probably won't buy it]]></content:encoded></item><item><title>Three reasons every founder and VC should be at TechCrunch All Stage 2025</title><link>https://techcrunch.com/2025/02/21/3-big-reasons-to-attend-techcrunch-all-stage-2025-if-you-are-a-founder-or-vc/</link><author>TechCrunch Events</author><category>tech</category><pubDate>Fri, 21 Feb 2025 15:00:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[From idea to IPO — where are you on your startup journey? If any of that sounds like you — or if you’re in between stages and ready to level up — TechCrunch All Stage 2025 (formerly Early Stage) is the place to be. Join 1,200 founders to exchange ideas and meet the right VC […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>TechCrunch Disrupt 2025: Lowest prices of the year end in 7 days</title><link>https://techcrunch.com/2025/02/21/techcrunch-disrupt-2025-lowest-prices-of-the-year-end-in-7-days/</link><author>TechCrunch Events</author><category>tech</category><pubDate>Fri, 21 Feb 2025 15:00:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[You read that headline correctly! The best deals for TechCrunch Disrupt 2025 tickets are about to end in just 7 days. Save up to $1,130 on individual passes and up to 30% on group tickets. Don’t wait — these offers end on February 28 at 11:59 p.m. PT. Join us in celebrating 20 years of […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>YouTube reportedly launching new ‘premium lite’ tier soon</title><link>https://techcrunch.com/2025/02/21/youtube-reportedly-launching-new-premium-lite-tier-soon/</link><author>Aisha Malik</author><category>tech</category><pubDate>Fri, 21 Feb 2025 14:40:11 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[YouTube is close to announcing a new lower-priced “premium lite” version of its subscription service, Bloomberg reports. The new tier is expected to launch in the United States, Australia, Germany, and Thailand “soon.” The tier will give users access to YouTube’s library of podcasts and how-to clips without ads, Bloomberg notes. Premium lite will be […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Elon Musk’s DOGE comes for agency that regulates autonomous vehicles</title><link>https://techcrunch.com/2025/02/21/elon-musks-doge-comes-for-agency-that-regulates-autonomous-vehicles/</link><author>Rebecca Bellan</author><category>tech</category><pubDate>Fri, 21 Feb 2025 14:27:34 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Elon Musk’s Department of Government Efficiency is firing nearly half of a small government team that regulates autonomous vehicles, The Washington Post reported. The firings are part of a broader 10% reduction at the National Highway Traffic Safety Administration (NHTSA) as a result of firings of probationary workers and buyout offers, The Post reported, citing […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Can Blockchain Make AI Systems More Transparent? Share Your Thoughts to Win From $2000</title><link>https://hackernoon.com/can-blockchain-make-ai-systems-more-transparent-share-your-thoughts-to-win-from-$2000?source=rss</link><author>HackerNoon Writing Contests Announcements</author><category>tech</category><pubDate>Fri, 21 Feb 2025 14:21:59 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[HackerNoon and Aleph Cloud are putting decentralization in the spotlight with the # With  up for grabs, we’re inviting writers, developers, and industry experts to discuss how , , and  are transforming tech scaling, user interactions, and data management.:::info
Below is a list of questions to help you get started on your entry. You can take them for a spin How Can Blockchain Technology Make AI Systems More Transparent?Describe the current state of AI Systems—how they work, their benefits, and limitations.What does it mean for an AI system to be transparent? Why does it matter?Introduce blockchain technology and its key features.2. Blockchain and AI TransparencyHow can blockchain tech make AI systems more transparent?How can blockchain tech make AI systems more reliable?Share a case study to illustrate blockchain’s value-add to the AI industry.3. Challenges & SolutionsWhat are the biggest obstacles to integrating blockchain with AI systems?How can these challenges be addressed?What developments could further strengthen the relationship between AI and the blockchain?Why should developers, businesses, and policymakers care about the relationship between blockchain and AI?Summarize the importance of transparent AI and blockchain’s role in achieving it.\
That’s all for today folks!Confident To Get Started?:::info
Start a  or use this template to enter! Submissions close on May 7, 2025.:::tip
Not feeling this template? No worries,  you can write about for the #blockchain Writing Contest:Good luck! We can’t wait to read your amazing drafts!]]></content:encoded></item><item><title>Mawari Pioneers City-Wide AI Experience in Osaka’s Namba District: How Osaka is Entering the Future</title><link>https://hackernoon.com/mawari-pioneers-city-wide-ai-experience-in-osakas-namba-district-how-osaka-is-entering-the-future?source=rss</link><author>Ishan Pandey</author><category>tech</category><pubDate>Fri, 21 Feb 2025 14:03:10 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[What if your daily commute could transform into an interactive digital experience? In a bustling Osaka station, commuters may soon encounter real-time 3D digital guides as part of a new urban initiative. Mawari has partnered with Nankai Electric Railway Co., Ltd., Meta Osaka Co., Ltd., and e-stadium Co., Ltd. to launch Digital Entertainment City Namba, a project that will integrate AI-driven 3D avatars, extended reality (XR), and decentralized physical infrastructure (DePIN) across the city. The initiative will deploy AI agents capable of providing tourist guidance and customer service in public spaces using real-time 3D streaming and edge computing devices installed throughout Nankai’s network.\
The project aims to transform traditional transit spaces into interactive digital hubs. By combining AI, XR, and DePIN, the new ecosystem seeks to support multilingual assistance for tourists and create flexible employment opportunities for remote workers and others. Mawari, with experience from over 50 XR projects globally, will use its patented technology to manage the high-quality streaming of digital content while reducing bandwidth requirements.\
Local stakeholders emphasize that the project is expected to enhance urban engagement and improve the overall experience of public spaces. Nankai Electric Railway, one of Japan’s long-established transportation providers, is positioning the initiative as a way to modernize its stations and surrounding areas. Meta Osaka and e-stadium contribute their expertise in regional development and digital strategy to help shape the project’s implementation.The Digital Entertainment City Namba project marks a notable experiment in blending digital and physical urban experiences at a city-wide scale. While the initiative may improve user engagement and support local economies through innovative digital services, it also invites careful scrutiny regarding infrastructure resilience and digital accessibility for all citizens. Observers will be keen to see how this integrated approach performs as a model for future urban development.\
Mawari, serving as the principal client in this collaboration, underscores its commitment to pushing the boundaries of spatial computing. Building on a legacy of over 50 XR projects worldwide, Mawari leverages its cutting-edge edge compute solutions and real-time 3D streaming to forge an urban landscape that blends digital innovation with everyday life. The company’s strategic investment in decentralized infrastructure aims to not only enhance public interaction through lifelike AI avatars but also set a replicable model for smart city initiatives globally. This venture reaffirms Mawari’s vision of making immersive digital experiences accessible, efficient, and transformative for communities across Osaka.\
Don’t forget to like and share the story! :::tip
Vested Interest Disclosure: This author is an independent contributor publishing via our . HackerNoon has reviewed the report for quality, but the claims herein belong to the author. #DYOR]]></content:encoded></item><item><title>Reinforcement Learning Triples Spot’s Running Speed</title><link>https://spectrum.ieee.org/ai-institute</link><author>Evan Ackerman</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjU1Mjc4OC9vcmlnaW4uZ2lmIiwiZXhwaXJlc19hdCI6MTc2NjkyNDI2OH0.mZ2_tLw8Srd0MdLBwx9bQDupbBvQzwywfhf3tx1LQQ8/image.gif?width=600" length="" type=""/><pubDate>Fri, 21 Feb 2025 14:00:05 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[The Robotics and AI Institute is teaching robot dogs to run and bicycles to jump]]></content:encoded></item><item><title>Benchmarks: Excellent Power Efficiency With 5th Gen AMD EPYC Using amd-pstate &amp; Power Profiles</title><link>https://www.phoronix.com/review/amd-epyc-pstate-efficiency</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 21 Feb 2025 14:00:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[The AMD EPYC 9005 "Turin" processors that launched last year offer excellent performance and power efficiency out-of-the-box. For those wanting to pursue maximum power efficiency and running in the most optimal configuration for performance-per-Watt, AMD EPYC BIOS tunables as well as recent Linux kernel driver improvements can help in driving even greater efficiency. Today's article is a look at the impact of the AMD P-State driver usage and options with recent kernel versions as well as the Power Profile Selection BIOS option for the impact on 5th Gen EPYC performance and power efficiency.]]></content:encoded></item><item><title>Trump EO Tries To Destroy Whatever Corporate Regulatory Oversight Hasn’t Been Already Killed By DOGE And The Supreme Court</title><link>https://www.techdirt.com/2025/02/21/trump-eo-tries-to-destroy-whatever-corporate-regulatory-oversight-hasnt-been-already-killed-by-doge-and-the-supreme-court/</link><author>Karl Bode</author><category>tech</category><pubDate>Fri, 21 Feb 2025 13:45:40 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[Welcome to the golden age of corruption. Last year I warned repeatedly how a concussive series of Supreme Court rulings like Loper Bright were poised to dismantle already shaky regulatory authority and corporate oversight, turning most U.S. regulators into the legal and policy equivalent of decorative seasonal gourds. It was the ultimate victory in a generational war on accountability by consolidated corporate power and rich assholes. Falsely framed as some sort of “noble rebalancing of constitutional authority” by bad faith lobbyists and think tankers, the goal wasn’t “balanced regulation” or “reining in out of control regulators,” it was the dismantling of nearly all meaningful corporate oversight. So even before Trump won the election, labor rights, consumer protection, environmental law, and public safety were already in  serious trouble. Now Trump has come out with an Executive Order that attempts to finish the job. The misleadingly named “Ensuring Accountability For All Agencies” effectively tries to declare that no U.S. regulatory agency can do much of anything without the explicit approval of a mad king. An accompanying “fact sheet” proclaims that “so called” agencies like the FCC and FTC will not be able to take any actions that contradict the will of the President:“No employee of the executive branch acting in their official capacity may advance an interpretation of the law as the position of the United States that contravenes the President or the Attorney General’s opinion on a matter of law, including but not limited to the issuance of regulations, guidance, and positions advanced in litigation, unless authorized to do so by the President or in writing by the Attorney General.”The EO requires that all U.S. regulatory agencies must “submit for review all proposed and final significant regulatory actions to the Office of Information and Regulatory Affairs (OIRA) within the Executive Office of the President before publication in the Federal Register.” It also declares the President will “adjust so-called independent agencies’ apportionments to ensure tax dollars are spent wisely.”It basically ensures that even if our captured regulators  somehow come up with a coherent proposal that challenges corporate power (already a rarity thanks to the corrupt, revolving door nature of most agencies), the President has the exclusive right to kill it, regardless of whether or not it’s within the confines of Congressional approval, or broadly, democratically popular. The axing of Chevron had  made it so regulators can’t do much of anything without the explicit approval of Congress. Proponents wanted you to ignore that Congress and our court system are too corrupt to function, ensuring that pretty much  that challenges corporate or billionaire power will be declared  and . These efforts willsteadily have disastrous downstream impacts that  kill people at scale across countless sectors. But most of the media coverage I read about it has a bizarre, clinical detachment that puts the reader to sleep by the fourth paragraph, and fails to convey any sense of the dire stakes at play. Despite what big companies and billionaires might tell you, U.S. regulators have already been on the ropes for years. They’re generally understaffed, under-funded, stocked with only the kind of dull careerists that can survive the corrupt congressional nomination process (see: what happened to Gigi Sohn), and boxed in by industry lobbying, a very broken Congress, and a steady parade of shitty court rulings. I’ve covered the FCC for decades. The agency rarely actually tries to seriously protect consumers. And when it does try (net neutrality, privacy), those efforts routinely never last long in the face of corruption. Real consumer protection almost uniformly fails. Still, somehow in Republican and Libertarian circles a narrative has long been entrenched that agencies like the FCC have been “running amok.” That narrative persists because of its value in selling a lie: what most of these billionaires and companies want isn’t reasonable regulation, or sensible, well crafted oversight: it’s . Freedom to rip off consumers, to pollute, to violate labor law, and to generally misbehave in the quest for improved quarterly earnings with zero accountability. Freedom to “innovate” and acquire and consume and expand with zero concern about the downstream impact of bad choices.As I saw these efforts unfolding last year I got increasingly vocal about it, but was often met by an arched eyebrow by cocksure policy tut-scolds, drunk on normalization bias, confident that the . Well, the system is not holding. We’re entering the golden age of fraud and corruption.As with everything Trump, this is extremely legally dodgy and will indisputably see a court challenge. But collectively between this, DOGE, and the Supreme Court’s locked-in majority, it’s hard to believe U.S. regulators will coherently function with any sort of independence from corporate power and petulant billionaires for a very, very long time. Even under the best case scenario where the electorate tires of the coming cascading system failures and puts an end to our dipshit kakistocracy, reversing the damage in a system now specifically designed to prevent progressive reform will be a very steep uphill climb. That’s not to say we can’t survive and build better things. The destruction of coherent federal governance shifts most battles to the local and state level. The country can still function as a loose assortment of fractured nation states each with their varying degrees of labor protection, consumer rights, and environmental protection. Which state you live in suddenly matters more than ever. But for now, any dream of unified, federal coherence or corporate oversight has been murdered by a loose collection of sociopaths and self-serving Dunning Kruger hustlebros, keen on stripping and selling the American experiment for scrap off the back loading dock. ]]></content:encoded></item><item><title>Ubuntu 25.04 Working On More Improvements For Snapdragon X1 Elite Laptop Support</title><link>https://www.phoronix.com/news/Ubuntu-25.04-More-X1E</link><author>Michael Larabel</author><category>tech</category><pubDate>Fri, 21 Feb 2025 13:30:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[We are nearing one year since the first Qualcomm Snapdragon X1 Elite laptops shipped with Windows 11 ARM. For the upcoming Ubuntu 25.04 release it's looking like more of these ARM-powered laptops will have somewhat usable support at least for those wanting to avoid Intel Core Ultra or AMD Ryzen laptops...]]></content:encoded></item><item><title>Here&apos;s How the Pros Choose the Right Load Balancer</title><link>https://hackernoon.com/heres-how-the-pros-choose-the-right-load-balancer?source=rss</link><author>Suleiman Dibirov</author><category>tech</category><pubDate>Fri, 21 Feb 2025 13:13:40 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[In today’s digital landscape, the demand for high availability and performance is more crucial than ever. Whether you’re running a small web application or managing a complex microservices architecture, ensuring that traffic is efficiently routed and balanced across your infrastructure is vital to providing a seamless user experience. This is where load balancers come into play.\
Load balancers are a foundational component in modern systems, distributing network or application traffic across multiple servers to ensure no single server bears too much load. This not only improves performance but also ensures high availability by redirecting traffic in case of server failures.\
In this article, we will dive deep into the concepts, features, and best practices surrounding load balancers. From understanding the various load balancing algorithms to optimizing for high availability and performance, by the end of this guide, you’ll have the knowledge to leverage load balancers effectively in your own infrastructure.A load balancer is a crucial component in distributed systems, acting as an intermediary that distributes incoming traffic across multiple servers or backend services. By doing so, it ensures no single server becomes overwhelmed, enhancing both system performance and reliability. Load balancers are particularly valuable in environments where uptime and responsiveness are paramount.\
There are different types of load balancers based on where they operate within the OSI model:: These operate at the transport layer (TCP/UDP) and make routing decisions based on IP addresses and port numbers. They are fast and efficient but offer less granularity in traffic management.: These operate at the application layer and can inspect HTTP headers, URLs, and cookies to make more informed routing decisions. This allows for more sophisticated traffic distribution but at the cost of higher processing overhead.\
Load balancers can be implemented as hardware devices, but more commonly today, they exist as software solutions that can run in the cloud or on-premises. They are used in various scenarios such as distributing web traffic, managing microservices, and handling APIs. By balancing the load, these systems prevent downtime and ensure a smoother user experience.Key Features of Load BalancersLoad balancers are more than just traffic directors; they come equipped with a range of features that enhance both system performance and availability. Understanding these key features is essential to fully leveraging the potential of load balancing in your infrastructure.1. Load Distribution StrategiesLoad balancers use various algorithms to distribute incoming traffic across available servers. Some common strategies include:: Simple cyclic distribution: Server 1 → 2 → 3 → 1.: Servers get traffic based on capacity. Stronger servers receive more requests.: Sends traffic to a server handling the fewest current requests.: Routes to fastest-responding server.: Maps client IPs to specific servers, maintaining session persistence.: Distributes based on server metrics (CPU, memory).: Randomly picks any available server.2. Health Checks and FailoverOne of the primary functions of a load balancer is to ensure traffic is only routed to healthy servers. It performs regular health checks on the backend servers, monitoring factors like CPU load, response times, or even specific application metrics. If a server fails a health check, the load balancer redirects traffic to the remaining healthy servers, ensuring continuous service without downtime.3. Session Persistence (Sticky Sessions)In certain scenarios, it is essential to maintain user sessions on the same server for consistency, such as during a shopping cart transaction. Load balancers offer session persistence, also known as sticky sessions, where requests from a particular user are consistently routed to the same server based on cookies or other identifiers.Load balancers can handle SSL (Secure Sockets Layer) encryption and decryption, offloading this task from the backend servers. This process, known as SSL termination, reduces the processing overhead on application servers and improves performance, especially for HTTPS traffic.\
These features collectively make load balancers highly effective in managing traffic, reducing server overload, and ensuring that systems are robust, resilient, and perform optimally under heavy load.Load balancers rely on various algorithms to determine how traffic is distributed across multiple servers. Choosing the right algorithm can significantly impact the performance and availability of your system. Below are some of the most commonly used load balancing algorithms, each suited to different scenarios.: Traffic is evenly circularly distributed across servers, one server at a time.: Ideal for environments where servers have similar specifications and loads are relatively consistent. It’s simple and easy to implement but may not account for servers with varying capacities.: Requests are routed to the server with the fewest active connections at the time.: Best suited for situations where traffic is uneven, or some requests require longer processing times. It helps balance traffic based on real-time server load.: Similar to round robin, but servers are assigned weights based on their processing capabilities. Servers with higher weights receive more requests.: Useful in environments with servers of different capacities, where you want to direct more traffic to more powerful servers.: The client’s IP address is hashed to determine which server will handle the request. This ensures that requests from the same client are always sent to the same server.: Effective in maintaining session persistence without requiring sticky sessions, ensuring the same server handles all requests from a particular user.: Requests are routed to the server with the lowest average response time.: Ideal for applications where latency is a key concern, ensuring users are directed to the fastest-responding server.: Traffic is randomly assigned to any server in the pool.: While simple, this method is rarely used as it doesn’t account for server load or capacity, leading to potential performance issues.\
Each algorithm has its strengths and weaknesses, and selecting the best one depends on your infrastructure, server specifications, and the type of workload your application handles. In many cases, a combination of algorithms may be used to optimize both performance and reliability.Load Balancers and High AvailabilityHigh availability is one of the primary reasons organizations implement load balancers. Ensuring that applications and services remain available despite traffic surges or server failures is critical in modern infrastructure. Here’s how load balancers contribute to high availability:1. Eliminating Single Points of FailureLoad balancers distribute traffic across multiple backend servers, ensuring that no single server is responsible for all incoming requests. If one server fails, the load balancer automatically redirects traffic to healthy servers. This redundancy prevents system outages due to server failure.For even greater resilience, some infrastructures implement multiple load balancers to avoid a single point of failure at the load balancer level. This often involves using active-active or active-passive load balancer configurations.Modern cloud environments often integrate load balancers with auto-scaling systems. As traffic increases, new server instances can be automatically provisioned and added to the pool of servers behind the load balancer.The load balancer dynamically adjusts, routing traffic to new instances as they come online and removing them when they are no longer needed. This elasticity allows services to handle unexpected traffic spikes without impacting availability.3. Geographic Load BalancingFor applications with a global user base, geographic load balancing ensures that users are connected to the nearest data center or server, minimizing latency and providing a faster, more reliable experience.In case of a data center failure or network outage in one region, the load balancer can automatically route traffic to another region, maintaining service availability for users.4. Health Monitoring and FailoverLoad balancers continuously perform health checks on the backend servers. When a server becomes unresponsive or performs poorly, the load balancer marks it as unhealthy and stops sending traffic to it.In multi-data-center setups, load balancers can even handle failover between entire data centers, ensuring that your service remains available even during large-scale outages.\
By intelligently routing traffic and enabling redundancy at multiple levels, load balancers play a crucial role in ensuring high availability. They provide the infrastructure necessary for 24/7 uptime, even in the face of server failures, traffic surges, or regional outages.In addition to ensuring high availability, load balancers are essential for optimizing the performance of your infrastructure. By efficiently distributing traffic, reducing latency, and offloading certain tasks from backend servers, load balancers play a key role in enhancing user experience.Load balancers distribute requests to the server that can respond the fastest, reducing response times for users. Algorithms such as  ensure that users are connected to the server that can process their requests the quickest.Geographic load balancing also minimizes latency by routing users to the nearest available data center or server.2. Offloading SSL TerminationSSL/TLS encryption and decryption can be resource-intensive for backend servers. By offloading this task to the load balancer (a process known as SSL termination), backend servers are freed up to focus on application logic and processing user requests.This improves the overall speed and efficiency of the system, particularly for applications with high volumes of HTTPS traffic.Load balancers can integrate with caching mechanisms to store frequently requested content closer to the user. By serving cached content directly from the load balancer, you can reduce the load on backend servers and deliver content more quickly.Similarly, load balancers can apply compression techniques to reduce the size of transmitted data, leading to faster delivery times and improved performance for users with slower connections.4. Traffic PrioritizationIn scenarios where different types of traffic have different performance requirements, load balancers can prioritize traffic. For example, real-time services such as video conferencing or gaming can be prioritized over standard web traffic.This ensures that critical services remain responsive, even during times of high load or network congestion.Load balancers can pool connections to backend servers, reducing the overhead of opening and closing connections for every client request. This improves performance, especially in high-traffic environments where connection management can become a bottleneck.6. Content Delivery Network (CDN) IntegrationLoad balancers can work alongside CDNs to serve static content (such as images, videos, and stylesheets) from edge servers located closer to the end users. By integrating with CDNs, load balancers help reduce the load on backend servers and accelerate content delivery.\
By optimizing how traffic is handled, load balancers significantly enhance system performance. They reduce the strain on backend servers, improve response times, and ensure that users experience smooth, uninterrupted service, even under heavy load. These performance optimizations are especially important in large-scale, global applications.Choosing the Right Load BalancerSelecting the right load balancer for your system is critical to optimizing traffic management and ensuring both performance and availability. There are several factors to consider when choosing between hardware-based, software-based, or cloud-based load balancing solutions, as well as which specific technology to implement.1. Hardware vs. Software Load Balancers: These are dedicated physical devices designed to manage network traffic. They offer high performance, scalability, and security features. However, they can be expensive to implement and maintain, and may not offer the flexibility required for dynamic, cloud-based environments.: These are flexible, cost-effective solutions that run on commodity hardware or virtual machines. Software load balancers such as , , and  are popular choices in many environments because they can be customized and scaled according to your specific needs.2. Cloud-Based Load BalancersFor cloud-native environments, cloud providers offer integrated load balancing solutions that are easy to deploy and scale. These include:AWS Elastic Load Balancer (ELB): Provides three types — Application Load Balancer (Layer 7), Network Load Balancer (Layer 4), and Gateway Load Balancer.Google Cloud Load Balancing: Offers both global and regional load balancing, along with support for both TCP/UDP and HTTP(S) traffic.: Provides load balancing at both Layer 4 (transport) and Layer 7 (application), as well as the ability to integrate with virtual machines and containerized services.When choosing a load balancer, consider the following criteria:: Determine whether you need Layer 4 (transport-level) or Layer 7 (application-level) load balancing. If you need more granular control over HTTP/HTTPS traffic, a Layer 7 load balancer is essential.: Consider whether your load balancer needs to handle traffic spikes and large-scale operations. Cloud-based solutions tend to be more scalable, as they can automatically adapt to varying traffic loads.: Cloud-based load balancers offer easy integration with cloud-native environments, while on-premise solutions give you more control over configuration and security.: Cloud-based load balancers are typically priced based on usage, which can be more cost-effective for smaller applications or variable traffic loads. Hardware load balancers involve significant upfront and maintenance costs.4. Popular Load Balancing Solutions: A versatile open-source solution known for its reverse proxy and Layer 7 load balancing capabilities.: A high-performance, open-source load balancer that supports both Layer 4 and Layer 7 traffic, widely used in enterprise environments.: A well-known provider of enterprise-grade hardware load balancers that offer advanced security and performance features.: A modern cloud-native solution designed for containerized applications, commonly used in Kubernetes environments.\
Choosing the right load balancer involves balancing performance, scalability, cost, and flexibility based on your application’s specific needs. Carefully evaluating these options will ensure that you select a solution capable of handling both current and future traffic demands.Modern Load Balancing ArchitecturesService Mesh ArchitectureModern applications often employ a service mesh architecture, which provides advanced load balancing capabilities:Each service has a proxy sidecarHandles service-to-service communicationProvides automatic load balancingEnables advanced traffic managementCloud-Native Load BalancingMulti-Cloud Load BalancingGlobal traffic management across cloud providersAutomatic failover between regionsCost optimization across providersUnified traffic managementEvent-driven load balancingFunction-level traffic distributionAuto-scaling based on event volumeContainer Orchestration IntegrationInternal load balancing (Service types)SSL/TLS termination at edgeModern Load Balancing PatternsZero-downtime deploymentsTraffic shifting between versionsCircuit Breaking PatternsAutomatic failure detectionSelf-healing capabilitiesChallenges and Best PracticesWhile load balancers are essential for ensuring high availability and performance, their configuration and maintenance come with challenges. Understanding these challenges and following best practices will help you optimize your system and avoid common pitfalls.Although load balancers help distribute traffic, they themselves can become bottlenecks if not properly scaled. A single load balancer handling too much traffic may introduce latency or fail under high loads.: Use multiple load balancers in an active-active configuration to distribute the load among them, or leverage auto-scaling features in cloud environments.Distributed Denial of Service (DDoS) attacks can overwhelm load balancers with massive amounts of traffic, causing system outages.: Implement DDoS protection mechanisms at the network level, such as rate-limiting, IP whitelisting, and using Web Application Firewalls (WAFs) in conjunction with load balancers.Session Persistence (Sticky Sessions)Maintaining session persistence can become problematic when the load balancer fails, as it could disrupt user sessions.: Use cookie-based session persistence or session replication across multiple servers to avoid dependency on a single server or load balancer.Misconfigured Health ChecksImproperly configured health checks can lead to traffic being routed to unhealthy or underperforming servers.: Regularly fine-tune health checks to monitor critical application-level performance metrics, such as response time and CPU utilization.Monitor and Optimize RegularlyContinuously monitor your load balancers to identify performance bottlenecks or failures early. Tools like  and  can help visualize metrics.: Analyze logs to detect unusual traffic patterns and fine-tune traffic distribution algorithms or scaling policies.Use Auto-scaling FeaturesIn dynamic environments where traffic fluctuates, manually scaling your load balancers and servers can be inefficient.: Cloud-based load balancers often come with built-in auto-scaling capabilities. Ensure that your infrastructure is set up to scale both horizontally and vertically based on traffic loads.Always ensure redundancy for both your load balancers and backend servers. Use multiple load balancers in failover or active-active setups to avoid single points of failure.: Implement global load balancing across multiple data centers to further increase fault tolerance.Secure Your Load BalancersAs entry points into your network, load balancers are critical security components. Use secure configurations, apply patches regularly, and encrypt all communication using SSL/TLS.: Consider deploying Web Application Firewalls (WAFs) and Intrusion Detection Systems (IDS) alongside your load balancers to provide extra layers of security.Distribute Traffic Based on PerformanceNot all servers in your environment may have the same capacity or performance. Using weighted load balancing allows you to send more traffic to higher-performing servers.: Regularly assess server performance and adjust load balancer settings to reflect the capacity of each server.3. Disaster Recovery PlanningEnsure that your load balancers are integrated into your disaster recovery plan. Load balancers can fail, and having a clear plan for traffic rerouting and failover is crucial.: Regularly test failover mechanisms to ensure that they function as expected during a real-world outage.\
By anticipating challenges and adhering to best practices, you can make your load balancing setup resilient, scalable, and secure. Proper configuration and continuous monitoring will ensure your infrastructure performs optimally, even under heavy loads or during unexpected failures.Load balancers are an essential tool for any organization aiming to achieve high availability, optimal performance, and scalability in their infrastructure. Whether you are managing a small application or an enterprise-grade global service, load balancers help distribute traffic efficiently, prevent downtime, and maintain a seamless user experience.\
In this article, we have explored the core concepts of load balancing, from understanding the different types of load balancers and algorithms to optimizing for high availability and performance. We also covered the importance of choosing the right load balancer for your environment, discussed challenges and best practices, and highlighted real-world examples of companies leveraging load balancers to great effect.Load balancing is crucial for distributing traffic and ensuring redundancy.Different algorithms serve different use cases; select the one that fits your workload.Load balancers optimize both system performance and availability through features like auto-scaling, SSL termination, and geographic distribution.Challenges such as DDoS attacks and misconfigured health checks can be mitigated with proper planning and monitoring.Real-world examples show that effective load balancing enables companies to handle traffic spikes, reduce latency, and provide a consistent, reliable service.\
By mastering load balancers and implementing them as part of your infrastructure, you can future-proof your systems against traffic surges and potential failures, ensuring both optimal performance and continuous service availability for your users.As you continue to refine your infrastructure, consider how you can further optimize load balancing to meet your specific performance and availability goals. Experiment with different strategies, monitor traffic patterns and adapt as your user base grows.\
I hope this article has provided valuable insights into load balancing and its impact on modern infrastructure. Keep exploring, learning, and implementing best practices to master traffic management for high availability and performance in your systems.]]></content:encoded></item></channel></rss>