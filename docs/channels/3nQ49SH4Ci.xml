<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Infosec</title><link>https://www.awesome-dev.news</link><description></description><item><title>Odd WebLogic Request. Possible CVE-2026-21962 Exploit Attempt or AI Slop&amp;#x3f;, (Wed, Jan 28th)</title><link>https://isc.sans.edu/diary/rss/32662</link><author></author><category>infosec</category><pubDate>Wed, 28 Jan 2026 16:02:30 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[I was looking for possible exploitation of CVE-2026-21962, a recently patched WebLogic vulnerability. While looking for related exploit attempts in our data, I came across the following request:GET /weblogic//weblogic/..;/bea_wls_internal/ProxyServlet
host: 71.126.165.182
user-agent: Mozilla/5.0 (compatible; Exploit/1.0)
accept-encoding: gzip, deflate
connection: close
wl-proxy-client-ip: 127.0.0.1;Y21kOndob2FtaQ==
proxy-client-ip: 127.0.0.1;Y21kOndob2FtaQ==
x-forwarded-for: 127.0.0.1;Y21kOndob2FtaQ==According to write-ups about CVE-2026-21962, this request is related [2]. However, the vulnerability also matched an earlier "AI Slop" PoC [3][4]. Another write-up, that also sounds very AI-influenced, suggests a very different exploit mechanism that does not match the request above [5].The source IP is 193.24.123.42. Our data shows sporadic HTTP scans for this IP address, and it appears to be located in Russia. Not terribly remarkable at that. In the past, the IP has used the "Claudbot" user-agent. But it does not have any actual affiliation with Anthropic (not to be confused with the recent news about clawdbot). The exploit is a bit odd. First of all, it does use the loopback address as an "X-Forwarded-For" address. This is a common trick to bypass access restrictions (I would think that Oracle is a bit better than to fall for a simple issue like that). There is an option to list multiple IPs, but they should be delimited by a comma, not a semicolon. The base64 encoded string decodes to: "cmd:whoami". This suggests a simple command injection vulnerability. Possibly, the content of the header is base64 decoded and next, passed as a command line argument?? Certainly an odd mix of encodings in one header, and unlikely to work.Let's hope this is AI slop and the exploit isn't that easy. We have seen a significant uptick in requests, including the wl-proxy-client-ip header, starting on January 21st, but the header has been used before. It is a typical exploit AI may come up with, seeing keywords like "Weblogic Server Proxy Plug-in".
I asked ChatGPT and Grok if this is an exploit or AI slop. The abbreviated answer:This looks more like a “scanner/probe that’s trying to look like an exploit” than a complete, working exploit by itself — but it’s  random either. It’s borrowing real WebLogic attack ingredients."This is an actual exploit attempt — not just random "AI slop" or nonsense traffic."That is definitely an , not AI slop. Specifically, it is targeting a well-known vulnerability in ."[1] https://nvd.nist.gov/vuln/detail/CVE-2026-21962
[2] https://dbugs.ptsecurity.com/vulnerability/PT-2026-3709
[3] https://x.com/0xacb/status/2015473216844620280
[4] https://github.com/Ashwesker/Ashwesker-CVE-2026-21962/blob/main/CVE-2026-21962.py
[5] https://www.penligent.ai/hackinglabs/the-ghost-in-the-middle-a-definitive-technical-analysis-of-cve-2026-21962-and-its-existential-threat-to-ai-pipelines/

 
 (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.]]></content:encoded></item><item><title>Risky Business #822 -- France will ditch American tech over security risks</title><link>https://risky.biz/RB822/</link><author></author><category>infosec</category><category>podcast</category><enclosure url="https://dts.podtrac.com/redirect.mp3/media3.risky.biz/RB822.mp3" length="" type=""/><pubDate>Wed, 28 Jan 2026 03:35:47 +0000</pubDate><source url="https://risky.biz/">Risky Business blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>ISC Stormcast For Wednesday, January 28th, 2026 https://isc.sans.edu/podcastdetail/9784, (Wed, Jan 28th)</title><link>https://isc.sans.edu/diary/rss/32660</link><author></author><category>infosec</category><pubDate>Wed, 28 Jan 2026 02:05:03 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[
 
 (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.]]></content:encoded></item><item><title>The Constitutionality of Geofence Warrants</title><link>https://www.schneier.com/blog/archives/2026/01/the-constitutionality-of-geofence-warrants.html</link><author>Bruce Schneier</author><category>infosec</category><category>blog</category><pubDate>Tue, 27 Jan 2026 12:01:47 +0000</pubDate><source url="https://www.schneier.com/">Schneider on Security</source><content:encoded><![CDATA[The US Supreme Court is considering the constitutionality of geofence warrants.The case centers on the trial of Okello Chatrie, a Virginia man who pleaded guilty to a 2019 robbery outside of Richmond and was sentenced to almost 12 years in prison for stealing $195,000 at gunpoint.Police probing the crime found security camera footage showing a man on a cell phone near the credit union that was robbed and asked Google to produce anonymized location data near the robbery site so they could determine who committed the crime. They did so, providing police with subscriber data for three people, one of whom was Chatrie. Police then searched Chatrie’s home and allegedly surfaced a gun, almost $100,000 in cash and incriminating notes.Chatrie’s appeal challenges the constitutionality of geofence warrants, arguing that they violate individuals’ Fourth Amendment rights protecting against unreasonable searches.]]></content:encoded></item><item><title>DtSR Episode 690 - Defenders of the Internet Pipes</title><link></link><author></author><category>infosec</category><category>podcast</category><enclosure url="https://dts.podtrac.com/redirect.mp3/www.buzzsprout.com/2153215/episodes/18575950-dtsr-episode-690-defenders-of-the-internet-pipes.mp3" length="" type=""/><pubDate>Tue, 27 Jan 2026 11:00:00 +0000</pubDate><source url="https://blogwh1t3rabbit.medium.com/">Down the Security Rabbit Hole Podcast</source></item><item><title>Initial Stages of Romance Scams &amp;#x5b;Guest Diary&amp;#x5d;, (Tue, Jan 27th)</title><link>https://isc.sans.edu/diary/rss/32650</link><author></author><category>infosec</category><pubDate>Tue, 27 Jan 2026 02:10:52 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[[This is a Guest Diary by Fares Azhari, an ISC intern as part of the SANS.edu BACS program]Romance scams are a form of social-engineering fraud that causes both financial and emotional harm. They vary in technique and platform, but most follow the same high-level roadmap: initial contact, relationship building, financial exploitation. In this blog post I focus on the initial stages of the romance scam ? how scammers make contact, build rapport, and prime victims for later financial requests.I was contacted by two separate romance scammers on WhatsApp. I acted like a victim falling for their scam and spent around two weeks texting each one. This allowed me to observe the first few phases, which we discuss below. I was not able to reach the monetization phase, as that often takes months and I could not maintain the daily time investment needed to convince the scammers I was fully falling for it.The scammers claimed to be called ?Chloe? and ?Verna?. We use these names throughout to differentiate their messages. Snippets from each are included to illustrate the phases, along with my precursor or response messages.Both conversations began the same way ? the sender claimed they had messaged the wrong person.That ?wrong-number? ruse is low effort and high reward. It gives the out-of-the-blue message a plausible reason, invites a short helpful reply, and lowers suspicion. Two small but useful fingerprints appear immediately: random capitalization and awkward grammar. These recur later and help identify when different operators are involved.Phase 2: The immediate hookIf you reply politely, the scammer usually responds with an over-the-top compliment:These short flattering lines serve as rapid rapport builders ? they feel personal and disarming.Phase 3: Establishing identity and credibilityAfter a few messages, both claimed to be foreigners working in the UK:When asked what she does for a living:When asked to explain her job:When asked how COVID affected her life:When asked about her job:When asked what made her choose business:Both claim the same job ?  ? which later supports credibility when discussing investments. Claiming to be foreigners explains grammatical errors and factual mistakes about the UK. Notably, job descriptions are long and well-written, lacking earlier quirks ? suggesting prewritten, copy-pasted content. This points to a playbook: flatter the target, establish credibility with occupation and location cover, then use scripted replies where legitimacy matters.After a few days of texting, both explained they were using a business number and asked to move to a ?personal? one:After I said it didn?t bother me to switch:The excuse is plausible and low-friction. Once texting the new number, writing style often changes ? a strong sign of a hand-off to a different operator or team focused on long-term grooming.Phase 5: The grooming phase (signs of a different operator)The writing style shift is clear on the new numbers:When asked if she made friends at work:When asked to share a steak recipe:When asked what languages she speaks:When asked about her studies:When asked about work stress:Responses show weaker English: more basic grammar errors, shorter sentences, quicker replies, daily ?Good morning? routines, and frequent (likely stolen or AI-generated) photos. These changes strongly indicate a hand-off.Phase 6: Credibility buildingBy the second week both began describing financial success and sent images of cars, apartments, gym visits, and meals to build trust:Pictures sent when asked about her side hustle:When asked if investments are high risk:When asked how she chooses investments:Photo sent saying she finished work (face covered):When asked about plans for her 30s:When asked about foundations/programs:Property photo (Australia):Both positioned themselves as successful investors with diversified portfolios ? building trust for future proposals. The wealth, charity, and expertise narratives emotionally prime the target. Direct money requests usually come much later, after deep emotional commitment.Practical advice for readersIf you receive a random ?wrong number? message, be cautious ? do not share personal information.Be suspicious if someone quickly asks to move off-platform or to a new number. Stay on the original platform until identity is verified.Ask for a live video call ? repeated refusal is a major red flag.Reverse-image search any profile photos or images received.Never send money, gift cards, or personal documents to someone you only know online.

 
 (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.]]></content:encoded></item><item><title>ISC Stormcast For Tuesday, January 27th, 2026 https://isc.sans.edu/podcastdetail/9782, (Tue, Jan 27th)</title><link>https://isc.sans.edu/diary/rss/32658</link><author></author><category>infosec</category><pubDate>Tue, 27 Jan 2026 02:00:02 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[
 
 (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.]]></content:encoded></item><item><title>Who Operates the Badbox 2.0 Botnet?</title><link>https://krebsonsecurity.com/2026/01/who-operates-the-badbox-2-0-botnet/</link><author>BrianKrebs</author><category>infosec</category><pubDate>Mon, 26 Jan 2026 16:11:38 +0000</pubDate><source url="https://krebsonsecurity.com/">Krebs on Security</source><content:encoded><![CDATA[The cybercriminals in control of  — a disruptive botnet that has infected more than 2 million devices — recently shared a screenshot indicating they’d compromised the control panel for , a vast China-based botnet powered by malicious software that comes pre-installed on many Android TV streaming boxes. Both the FBI and Google say they are hunting for the people behind Badbox 2.0, and thanks to bragging by the Kimwolf botmasters we may now have a much clearer idea about that.Our first story of 2026, The Kimwolf Botnet is Stalking Your Local Network, detailed the unique and highly invasive methods Kimwolf uses to spread. The story warned that the vast majority of Kimwolf infected systems were unofficial Android TV boxes that are typically marketed as a way to watch unlimited (pirated) movie and TV streaming services for a one-time fee.Our January 8 story, Who Benefitted from the Aisuru and Kimwolf Botnets?, cited multiple sources saying the current administrators of Kimwolf went by the nicknames “” and “.” Earlier this month, a close former associate of Dort and Snow shared what they said was a screenshot the Kimwolf botmasters had taken while logged in to the Badbox 2.0 botnet control panel.That screenshot, a portion of which is shown below, shows seven authorized users of the control panel, including one that doesn’t quite match the others: According to my source, the account “” (the one that is logged in and listed in the top right of the screenshot) belongs to Dort, who somehow figured out how to add their email address as a valid user of the Badbox 2.0 botnet.The control panel for the Badbox 2.0 botnet lists seven authorized users and their email addresses. Click to enlarge.Badbox has a storied history that well predates Kimwolf’s rise in October 2025. In July 2025, Google filed a “John Doe” lawsuit (PDF) against 25 unidentified defendants accused of operating Badbox 2.0, which Google described as a botnet of over ten million unsanctioned Android streaming devices engaged in advertising fraud. Google said Badbox 2.0, in addition to compromising multiple types of devices prior to purchase, also can infect devices by requiring the download of malicious apps from unofficial marketplaces.Google’s lawsuit came on the heels of a June 2025 advisory from the Federal Bureau of Investigation (FBI), which warned that cyber criminals were gaining unauthorized access to home networks by either configuring the products with malware prior to the user’s purchase, or infecting the device as it downloads required applications that contain backdoors — usually during the set-up process.The FBI said Badbox 2.0 was discovered after the original Badbox campaign was disrupted in 2024. The original Badbox was identified in 2023, and primarily consisted of Android operating system devices (TV boxes) that were compromised with backdoor malware prior to purchase.KrebsOnSecurity was initially skeptical of the claim that the Kimwolf botmasters had hacked the Badbox 2.0 botnet. That is, until we began digging into the history of the qq.com email addresses in the screenshot above.An online search for the address  (pictured in the screenshot above as the user ““) shows it is listed as a point of contact for a number of China-based technology companies, including:–Beijing Hong Dake Wang Science & Technology Co Ltd.
–Beijing Hengchuang Vision Mobile Media Technology Co. Ltd.
–Moxin Beijing Science and Technology Co. Ltd.The website for Beijing Hong Dake Wang Science is, a domain that was flagged in a March 2025 report by  as one of several dozen sites tied to the distribution and management of the Badbox 2.0 botnet. Ditto for , a domain associated with Beijing Hengchuang Vision Mobile.A search at the breach tracking service  finds 34557257@qq.com at one point used the password “.” Pivoting on that password in Constella shows it is known to have been used by just two other email accounts:  and .Constella found cathead@gmail.com registered an account at jd.com (China’s largest online retailer) in 2021 under the name “陈代海,” which translates to “.” According to , the name Chen Daihai is present in the original registration records (2008) for moyix[.]com, along with the email address .Incidentally, astrolink[.]cn also is among the Badbox 2.0 domains identified in HUMAN Security’s 2025 report. DomainTools finds cathead@astrolink[.]cn was used to register more than a dozen domains, including , yet another Badbox 2.0 domain tagged by HUMAN Security.A cached copy of astrolink[.]cn preserved at archive.org shows the website belongs to a mobile app development company whose full name is Beijing Astrolink Wireless Digital Technology Co. Ltd. The archived website reveals a “Contact Us” page that lists a Chen Daihai as part of the company’s technology department. The other person featured on that contact page is , and their email address is listed as .A Google-translated version of Astrolink’s website, circa 2009. Image: archive.org.Astute readers will notice that the user  in the Badbox 2.0 panel used the email address . Searching this address in Constella reveals a jd.com account registered in the name of Zhu Zhiyu. A rather unique password used by this account matches the password used by the address , which DomainTools finds was the original registrant of astrolink[.]cn.The very first account listed in the Badbox 2.0 panel — “admin,” registered in November 2020 — used the email address . DomainTools shows this email is found in the 2022 registration records for the domain , which includes the registrant name “.”Constella finds 189308024@qq.com is associated with the China phone number . The open-source intelligence platform  reveals this phone number is connected to a Microsoft profile created in 2014 under the name . The cyber intelligence platform  says that phone number was used in 2017 to create an account at the Chinese social media platform Weibo under the username “.”The public information attached to Guilin Huang’s Microsoft account, according to the breach tracking service osintindustries.com.The remaining three users and corresponding qq.com email addresses were all connected to individuals in China. However, none of them (nor Mr. Huang) had any apparent connection to the entities created and operated by Chen Daihai and Zhu Zhiyu — or to any corporate entities for that matter. Also, none of these individuals responded to requests for comment.The mind map below includes search pivots on the email addresses, company names and phone numbers that suggest a connection between Chen Daihai, Zhu Zhiyu, and Badbox 2.0.This mind map includes search pivots on the email addresses, company names and phone numbers that appear to connect Chen Daihai and Zhu Zhiyu to Badbox 2.0. Click to enlarge.The idea that the Kimwolf botmasters could have direct access to the Badbox 2.0 botnet is a big deal, but explaining exactly why that is requires some background on how Kimwolf spreads to new devices. The botmasters figured out they could trick residential proxy services into relaying malicious commands to vulnerable devices behind the firewall on the unsuspecting user’s local network.The vulnerable systems sought out by Kimwolf are primarily Internet of Things (IoT) devices like unsanctioned Android TV boxes and digital photo frames that have no discernible security or authentication built-in. Put simply, if you can communicate with these devices, you can compromise them with a single command.Our January 2 story featured research from the proxy-tracking firm , which alerted 11 different residential proxy providers that their proxy endpoints were vulnerable to being abused for this kind of local network probing and exploitation.Most of those vulnerable proxy providers have since taken steps to prevent customers from going upstream into the local networks of residential proxy endpoints, and it appeared that Kimwolf would no longer be able to quickly spread to millions of devices simply by exploiting some residential proxy provider.However, the source of that Badbox 2.0 screenshot said the Kimwolf botmasters had an ace up their sleeve the whole time: Secret access to the Badbox 2.0 botnet control panel.“Dort has gotten unauthorized access,” the source said. “So, what happened is normal proxy providers patched this. But Badbox doesn’t sell proxies by itself, so it’s not patched. And as long as Dort has access to Badbox, they would be able to load” the Kimwolf malware directly onto TV boxes associated with Badbox 2.0.The source said it isn’t clear how Dort gained access to the Badbox botnet panel. But it’s unlikely that Dort’s existing account will persist for much longer: All of our notifications to the qq.com email addresses listed in the control panel screenshot received a copy of that image, as well as questions about the apparently rogue ABCD account.]]></content:encoded></item><item><title>Privacy and Data Governance — Keys to Innovation and Trust in the AI Era</title><link>https://blogs.cisco.com/security/privacy-data-governance-innovation-trust/</link><author>Harvey Jang</author><category>infosec</category><pubDate>Mon, 26 Jan 2026 12:45:13 +0000</pubDate><source url="https://blogs.cisco.com/security">Cisco Security Blog</source><content:encoded><![CDATA[Cisco 2026 Data and Privacy Benchmark Study shares insights into how privacy unlocks competitive advantage for business growth and builds trust in AI era.]]></content:encoded></item><item><title>Ireland Proposes Giving Police New Digital Surveillance Powers</title><link>https://www.schneier.com/blog/archives/2026/01/ireland-proposes-giving-police-new-digital-surveillance-powers.html</link><author>Bruce Schneier</author><category>infosec</category><category>blog</category><pubDate>Mon, 26 Jan 2026 12:04:57 +0000</pubDate><source url="https://www.schneier.com/">Schneider on Security</source><content:encoded><![CDATA[The Irish government is planning to bolster its police’s ability to intercept communications, including encrypted messages, and provide a legal basis for spyware use.]]></content:encoded></item><item><title>Bypassing Windows Administrator Protection</title><link>https://projectzero.google/2026/26/windows-administrator-protection.html</link><author>James Forshaw</author><category>infosec</category><pubDate>Mon, 26 Jan 2026 08:00:00 +0000</pubDate><source url="https://projectzero.google/">Google Project Zero</source><content:encoded><![CDATA[A headline feature introduced in the latest release of Windows 11, 25H2 is Administrator Protection. The goal of this feature is to replace User Account Control (UAC) with a more robust and importantly, securable system to allow a local user to access administrator privileges only when necessary.This blog post will give a brief overview of the new feature, how it works and how it’s different from UAC. I’ll then describe some of the security research I undertook while it was in the insider preview builds on Windows 11. Finally I’ll detail one of the nine separate vulnerabilities that I found to bypass the feature to silently gain full administrator privileges. All the issues that I reported to Microsoft have been fixed, either prior to the feature being officially released (in optional update KB5067036) or as subsequent security bulletins.Note: As of 1st December 2025 the Administrator Protection feature has been disabled by Microsoft while an application compatibility issue is dealt with. The issue is unlikely to be related to anything described in this blog post so the analysis doesn’t change.The Problem Administration Protection is Trying to SolveUAC was introduced in Windows Vista to facilitate granting a user administrator privileges temporarily, while the majority of the user’s processes run with limited privileges. Unfortunately, due to the way it was designed, it was quickly apparent it didn’t represent a hard security boundary, and Microsoft downgraded it to a security feature. This was an important change as it made it no longer a priority to fix bypasses of the UAC which allowed a limited process to silently gain administrator privileges.The main issue with the design of UAC was that both the limited user and the administrator user were the same account just with different sets of groups and privileges. This meant they shared profile resources such as the user directory and registry hive. It was also possible to open an administrators process’ access token and impersonate it to grant administrator privileges as the impersonation permission checks didn’t originally consider if an access token was “elevated” or not, it just considered the user and the integrity level.Even so, on Vista it wasn’t that easy to silently acquire administrator privileges as most routes still showed a prompt to the user. Unfortunately, Microsoft decided to reduce the number of elevation prompts a user would see when modifying system configuration and introduced an “auto-elevation” feature in Windows 7. Select Microsoft binaries could be opted in to be automatically elevated. However, it also meant that in some cases it was possible to repurpose the binaries to silently gain administrator privileges. It was possible to configure UAC to always show a prompt, but the default, which few people change, would allow the auto-elevation.A good repository of known bypasses is the UACMe tool which currently lists 81 separate techniques for gaining administrator privileges. A proportion of those have been fixed through major updates to the OS, even though Microsoft never officially acknowledges when a UAC bypass is fixed. However, there still exist silent bypasses that impact the latest version of Windows 11 that remain unfixed.The fact that malware is regularly using known bypasses to gain administrator privileges is what Administrator Protection aims to solve. If the weaknesses in UAC can be mitigated then it can be made a secure boundary which not only requires more work to bypass but also any vulnerabilities in the implementation could be fixed as security issues.In fact there is already a more secure mechanism that UAC can use that doesn’t suffer from many of the problems of the so-called “admin approval” elevation. This mechanism is used when the user is not a member of the administrators group, it’s referred to as “over-the-shoulder” elevation. This mechanism requires a user to know the credentials of a local administrator user which must be input into the UAC elevation prompt. It’s more secure than admin approval elevation for the following reasons:The profile data is no longer shared, which prevents the limited user from modifying files or registry keys which might be used by an elevated administrator process.It’s no longer possible to get an access token for the administrator user and impersonate it as limited users cannot impersonate other user accounts.Auto-elevation of Microsoft binaries is not supported, all elevation requests require confirmation through a prompt.Unfortunately, the mechanism is difficult to use securely in practice as sharing the credentials to another local administrator account would be a big risk. Thus it’s primarily useful as a means for technical support where a sysadmin types in the credentials over the user’s shoulder.Administrator Protection improves on over-the-shoulder elevation by using a separate shadow administrator account that is automatically configured by the UAC service. This has all the benefits of over-the-shoulder elevation plus the following:The user does not need to know the credentials for the shadow administrator as there aren’t any. Instead UAC can be configured to prompt for the limited user’s credentials, including using biometrics if desired.A separate local administrator account isn’t required, only the user needs to be configured to be a member of the administrators group making deployment easier.While Microsoft is referring to Administrator Protection as a separate feature it can really be considered a third UAC mechanism as it uses the same infrastructure and code to perform elevation, just with some tweaks. However, the feature replaces admin-approval mode so you can’t use the “legacy” mode and Administrator Protection at the same time. If you want to enable it there’s currently no UI to do so but you can modify the local security policy to do so.The big question, will this make UAC a securable boundary so malware no longer has a free ride? I guess we better take a look and find out.Researching Administrator ProtectionI typically avoid researching new Windows features before they’re released. It hasn’t been a good use of time in the past where I’ve found a security issue in a new feature during the insider preview stages only for that bug to be due to temporary code that is subsequently removed. Also if security issues are fixed in the insider preview stage they do not result in a security bulletin, making it harder to track when something is fixed. Therefore, there’s little incentive to research features until they are released when I can be confident any bugs that are discovered are real security issues and they’re fixed in a timely manner.This case was slightly different, Microsoft reached out to me to see if I wanted to help them find issues in the implementation during the insider preview stage. No doubt part of the reason they reached out was my history of finding complex logical UAC bypasses. Also, I’d already taken a brief look and noted that the feature was still vulnerable to a few well known public bypasses such as my abuse of loopback Kerberos.I agreed to look at a design document and provide feedback without doing a full “pentest”. However, if I did find issues, considering the goal was for Administration Protection to be a securable boundary I was assured that they would be fixed through a bulletin, or at least would be remediated before the final release of the feature.The Microsoft document provided an overview, but not all design details. For example, I did have a question around what the developers considered the security boundary. In keeping with the removal of auto-elevation I made the assumption that bypassing the boundary would require one or more of the following:Compromising the shadow administrators profile, such as writing arbitrary files or registry keys.Hijacking an existing process running as the shadow administrator.Get a process executing as an administrator without showing a prompt.The prompt being a boundary is important, there’s a number of UAC bypasses, such as those which rely on elevated COM objects that would still work in Administrator Protection. However as auto-elevation is no longer permitted they will always show a prompt, therefore these are not considered bypasses. Of course, what is shown in the prompt, such as the executable being elevated, doesn’t necessarily correlate with the operation that is about to be performed with administrator rights.In the document there was some lack of consideration of some associated UAC features such as UI Access processes (this will be discussed in part 2 of this series) but even so some descriptions stuck out to me. Therefore, I couldn’t help myself and decided to at least take a look at the current implementation in the canary build of insider preview. This research was a mix of reverse engineering of the UAC service code in  as well as behavioral analysis.At the end of the research I found 9 separate means to bypass the feature and silently gain administrator privileges. Some of the bypasses were long standing UAC issues with publicly available test cases. Others were due to implementation flaws in the feature itself. But the most interesting bug class was where there wasn’t a bug at all, until the rest of the OS got involved.Let’s dive into this most interesting bypass I identified during the research. If you want to skip ahead you can read the full details on the issue tracker. This issue is interesting, not just because it allowed me to bypass the protection but also because it was a potential UAC bypass that I had known about for many years, but only became practically exploitable because of the introduction of this feature.First a little bit of background knowledge to understand the vulnerability. When a user authenticates to a Windows system successfully they’re assigned a unique logon session. This session is used to control the information about the user, for example it keeps a copy of the user’s credentials so that they can be used for network authentication.The logon session is added as a reference in the access token created during the logon process, so that it can be easily referred to during any kernel operations using the token. You can find the unique 64-bit authentication ID for the session by querying the token using the  system call. In UAC, separate logon sessions are assigned to the limited and the linked administrator access tokens as shown in the following script where you can observe that the limited token and linked token have distinct authentication ID LUID values:One important place the logon session is referenced by the kernel is when looking up DOS drive letters. From the kernels perspective drive letters are stored in a special object directory . When this path is looked up by the kernel it’ll first see if there’s a logon session specific directory to check, this is stored under the path \Sessions\0\DosDevices\X-Y, where X-Y is the hexadecimal representation of the authentication ID for the logon session. If the drive letter symbolic link isn’t found in that directory the kernel falls back to checking the  directory. You can observe this behavior by opening the  object directory using the  system call as shown:It’s well known that if you can write a symbolic link to a DOS device object directory you can hijack the  drive of any process running with that access token in that logon session. Even though the  drive is defined in the global object directory, the logon session specific directory is checked first and so it can be overridden.If a user can write into another logon session’s DOS device object directory they can redirect any file access to the system drive. For example you could redirect system DLL loading to force arbitrary code to run in the context of a process running in that logon session. In the case of UAC this isn’t an issue as the separate DOS device object directories have different access control and therefore the limited user can’t hijack the  drive of an administrator process. The access control for the administrator’s DOS device object directory is shown below:Creating a DOS Device Object DirectoryA question you might have is who creates this DOS device object directory? It turns out the kernel creates it on demand when the directory is first accessed. The code to do the creation is in , which looks roughly like the following:One thing you might notice is that the object directory is created using the  system call. One important security detail of using a  system call in the kernel is it disables security access checking unless the optional  flag is set in the , which isn’t the case here.Bypassing access checking is necessary for this code to function correctly; let’s look at the access control of the  directory.The directory cannot be written to by a non-administrator user, but as this code is called in the security context of the user it needs to disable access checking to create the directory as it can’t be sure the user is an administrator. Importantly the access control of the directory has an inheritable rule for the special  group granting full access. This is automatically replaced by the assigned owner of the access token used during object creation.Therefore even though the access checking has been disabled the final directory that’s created can be accessed by the caller. This explains how the UAC administrator DOS device object directory blocks access to the limited user. The administrator token is created with the local administrators group set as its owner and so that’s what  is replaced with. However, the limited user can only set their own SID as the owner and so it just grants access to the user.How is this useful? I noticed a long time ago that this behavior is a potential UAC bypass, in fact it’s a potential EoP, but UAC bypass was the most likely outcome. Specifically it’s possible to get a handle to the access token for the administrator user by calling  with the  information class. For security reasons this token is limited to  impersonation level so it can’t be used to grant access to any resources.However if you impersonate the token and open the  directory then the kernel will call  using the identification token and if it’s not currently created it’ll use  to create the DOS device object directory. As access checking is disabled the creation will still succeed, however once it’s created the kernel will do an access check for the directory itself and will fail due to the identification token being impersonated.This might not seem to get us very much, while the directory is created it’ll use the owner from the identification token which would be the local administrator’s group. But we can change the token’s owner SID to the user’s SID before impersonation, as that’s a permitted operation. Now the final DOS device object directory will be owned by the user and can be written to. As there’s only a single logon session used for the administrator side of UAC then any elevated process can now have its  directory hijacked.There’s just one problem with this as a UAC bypass, I could never find a scenario where the limited user got code running before any administrator process was created. Once the process was created and running there’s almost a certainty that some code would open a file and therefore access the  directory. By the time the limited user has control the DOS device object directory has already been created and assigned the expected access control. Still as UAC is not a security boundary there was no point reporting it, so I filed this behavior away for another day in case it ever became relevant.Bypassing Administrator ProtectionFast forward to today, and along comes Administrator Protection. For reasons of compatibility Microsoft made calling  with the  information class still returns an identification handle to the administrator token. But in this case it’s the shadow administrator’s token instead of the administrator version of the user’s token. But a crucial difference is while for UAC this token is the same every time, in Administrator Protection the kernel calls into the LSA and authenticates a new instance of the shadow administrator. This results in every token returned from  having a unique logon session, and thus does not currently have the DOS device object directory created as can be seen below:While in theory we can now force the creation of the DOS device object directory, unfortunately this doesn’t help us much. As the UAC service also uses  to get the token to create the new process with it means every administrator process currently running or will run in the future doesn’t share logon sessions, thus doesn’t share the same DOS device object directories and we can’t hijack their  drives using the token we queried in our own process.To exploit this we’d need to use the token for an actual running process. This is possible, because when creating an elevated process it can be started suspended. With this suspended process we can open the process token for reading, duplicate it as an identification token then create the DOS device object directory while impersonating it. The process can then be resumed with its hijacked  drive.There’s only two problems with this as a bypass, first creating an elevated process suspended will require clicking through an elevation prompt. For UAC with auto-elevation this wasn’t a problem, but for Administrator Protection it will always prompt, and showing a prompt isn’t considered to be crossing the security boundary. There are ways around this, for example the UAC service exposes the  API which will run an elevated binary silently. The only problem is the process isn’t suspended and so you’d have to win a race condition to open the process and perform the bypass before any code runs in that process. This is something which should be doable, say by playing with thread priorities to prevent the new process’ main thread from being scheduled.The second issue seems more of a deal breaker. When setting the owner for an access token it will only allow you to set a SID that’s either the user SID for the token, or a member group that has the  flag set. The only group with the owner flag is the local administrators group, and of course the shadow administrator’s SID differs from the limited user’s. Therefore setting either of these SIDs as the owner doesn’t help us when it comes to accessing the directory after creation.Turns out this isn’t a problem as I was not telling the whole truth about the owner assignment process. When building the access control for a new object the kernel doesn’t trust the impersonation token if it’s at identification level. This is for a good security reason, an identification token is not supposed to be usable to make access control decisions, therefore it makes no sense to assign its owner when creating the object. Instead the kernel uses the primary token of the process to make that decision, and so the assigned owner is the limited user’s SID. In fact setting the owner SID for the UAC bypass was never necessary, it was never used. You can verify this behavior by creating an object without a name so that it can be created while impersonating an identification token and checking the assigned owner SID:One final question you might have is how come creating a process with the shadow admin’s token doesn’t end up accessing some DOS drive’s file resource as that user thus causing the DOS device object directory to be created? The implementation of the  API runs all its code in the security context of the caller, regardless of what access token is being assigned so by default it wouldn’t ever open a file under the new logon session.However, if you know about how to securely create a process in a system service you might expect that you’re supposed to impersonate the new token over the call to  to ensure you don’t allow a user to create a process for an executable file they can’t access. The UAC service is doing this correctly, so surely it must have accessed a drive to create the process and the DOS device object directory should have been created, why isn’t it?In a small irony what’s happening is the UAC service is tripping over a recently introduced security mitigation to prevent the hijack of the  drive when impersonating a low privileged user in a system service. This mitigation kicks in if the caller of a system call is the  user and it’s trying to access the  drive. This was added by Microsoft in response to multiple vulnerabilities in manifest file parsing, if you want an overview here’s a video of the talk me and Maddie Stone did at OffensiveCon 23 describing some of the attack surface.It just so happens that the UAC service is running as  and as long as the elevated executable is on the  drive, which is very likely, the mitigation ignores the impersonated token’s DOS device object directory entirely. Thus  never gets calls and so the first time a file is accessed under the logon session is once the process is up and running. As long as we can perform the exploit before the new process touches a file we can create the DOS device object directory and redirect the process’  drive.To conclude, the steps to exploit this bypass is as follows:Spawn a shadow admin process through , which will run the  from the  drive.Open the new process before it has accessed a file resource, and query the primary token.Duplicate the token to an identification token.Force the DOS device object directory to be created while impersonating the shadow admin token. This can be done by opening  through a call to .Create a C: drive symlink in the new DOS device directory to hijack the system drive.Let the process resume and wait for a redirected DLL to be loaded.The bypass was interesting because it’s hard to point to the specific bug that causes it. The vulnerability is a result of 5 separate OS behaviors:The Administrator Protection feature changes to the  query generates a new logon session for every shadow admin token.The per-token DOS device directory is lazily initialized for each new logon session meaning when the linked token is first created the directory does not currently exist.The kernel creates the DOS device directory when it’s accessed by using  functions, which disables access checking. This allows a limited user to impersonate the shadow admin token at identification level and create the directory by opening .If a thread impersonates a token at identification level any security descriptor assignment takes the owner SID from the primary token, not the impersonation token. This results in the limited user being granted full access to the shadow admin token’s DOS device object directory.The DOS device object directory isn’t already created once the low-privileged user gets access to the process token because of the security mitigation which disables the impersonated DOS device object directory when opening files from the  drive in a  process.I don’t necessarily blame Microsoft for not finding this issue during testing. It’s a complex vulnerability with many moving pieces. It’s likely I only found it because I knew about the weird behavior when creating the DOS device object directory.The fix Microsoft implemented was to prevent creating the DOS device object directory when impersonating a shadow administrator token at identification level. As this fix was added into the final released build as part of the optional update KB5067036 it doesn’t have a security bulletin associated with it. I would like to thank the Administrator Protection team and MSRC for the quick response in fixing all the issues and demonstrating that this feature will be taken seriously as a security boundary. I’d also like to thank them for providing additional information such as the design document which aided in the research.As for my views on Administrator Protection as a feature, I feel that Microsoft have not been as bold as they could have been. Making small tweaks to UAC resulted in carrying along the almost 20 years of unfixed bypasses which manifest as security vulnerabilities in the feature. What I would have liked to have seen was something more configurable and controllable, perhaps a proper version of sudo or Linux capabilities where a user can be granted specific additional access for certain tasks.I guess app compatibility is ultimately the problem here, Windows isn’t designed for such a radical change. I’d have also liked to have seen this as a separate configurable mode rather than replacing admin-approval completely. That way a sysadmin could choose when people are opted in to the new model rather than requiring everyone to use it.I do think it improves security over admin-approval UAC assuming it becomes enabled by default. It presents a more significant security boundary that should be defendable unless more serious design issues are discovered. I expect that malware will still be able to get administrator privileges even if that’s just by forcing a user to accept the elevation prompt, but any silent bypasses they might use should get fixed which would be a significant improvement on the current situation. Regardless of all that, the safest way to use Windows is to never run as an administrator, with any version of UAC. And ideally avoid getting malware on your machine in the first place.]]></content:encoded></item><item><title>ISC Stormcast For Monday, January 26th, 2026 https://isc.sans.edu/podcastdetail/9780, (Mon, Jan 26th)</title><link>https://isc.sans.edu/diary/rss/32656</link><author></author><category>infosec</category><pubDate>Mon, 26 Jan 2026 02:00:04 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[
 
 (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.]]></content:encoded></item><item><title>Scanning Webserver with /&amp;#x24;(pwd)/ as a Starting Path, (Sun, Jan 25th)</title><link>https://isc.sans.edu/diary/rss/32654</link><author></author><category>infosec</category><pubDate>Mon, 26 Jan 2026 00:59:32 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[Based on the sensors reporting to ISC, this activity started on the 13 Jan 2026. My own sensor started seeing the first scan on the 21 Jan 2026 with limited probes. So far, this activity has been limited to a few scans based on the reports available in ISC [5] ():This is a sample list of the directories actors are scanning for using the following patterns:/$(pwd)/.env.staging
/$(pwd)/.env.development
/$(pwd)/.env.local
$(pwd)/terraform.tfstate
/$(pwd)/docker-compose.yml
/$(pwd)/netlify.tomlThis Gephi graph shows the relationship of each probed URL by the two IP addresses:By selecting one of these two indicators, it shows their scanning activity for the  pattern in the ISC web logs.We also appreciate feedback and suggestions about what tool is used to perform these scans. Please use our contact page to provide feedback. [1] https://www.elastic.co/guide/en/elasticsearch/reference/8.19/esql-using.html
[2] https://gephi.org/
[3] https://isc.sans.edu/weblogs/sourcedetails.html?date=2026-01-21&ip=185.177.72.52
[4] https://isc.sans.edu/weblogs/sourcedetails.html?date=2026-01-25&ip=185.177.72.23
[5] https://isc.sans.edu/weblogs/urlhistory.html?url=LyQocHdkKS8uCg==

 
 (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.]]></content:encoded></item><item><title>Friday Squid Blogging: Giant Squid in the Star Trek Universe</title><link>https://www.schneier.com/blog/archives/2026/01/friday-squid-blogging-giant-squid-in-the-star-trek-universe.html</link><author>Bruce Schneier</author><category>infosec</category><category>blog</category><pubDate>Fri, 23 Jan 2026 22:03:20 +0000</pubDate><source url="https://www.schneier.com/">Schneider on Security</source><content:encoded><![CDATA[Spock befriends a giant space squid in the comic Star Trek: Strange New Worlds: The Seeds of Salvation #5.As usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.]]></content:encoded></item><item><title>AIs are Getting Better at Finding and Exploiting Internet Vulnerabilities</title><link>https://www.schneier.com/blog/archives/2026/01/ais-are-getting-better-at-finding-and-exploiting-internet-vulnerabilities.html</link><author>Bruce Schneier</author><category>infosec</category><category>blog</category><pubDate>Fri, 23 Jan 2026 12:01:19 +0000</pubDate><source url="https://www.schneier.com/">Schneider on Security</source><content:encoded><![CDATA[In a recent evaluation of AI models’ cyber capabilities, current Claude models can now succeed at multistage attacks on networks with dozens of hosts using only standard, open-source tools, instead of the custom tools needed by previous generations. This illustrates how barriers to the use of AI in relatively autonomous cyber workflows are rapidly coming down, and highlights the importance of security fundamentals like promptly patching known vulnerabilities.A notable development during the testing of Claude Sonnet 4.5 is that the model can now succeed on a minority of the networks without the custom cyber toolkit needed by previous generations. In particular, Sonnet 4.5 can now exfiltrate all of the (simulated) personal information in a high-fidelity simulation of the Equifax data breach—­one of the costliest cyber attacks in history—­using only a Bash shell on a widely-available Kali Linux host (standard, open-source tools for penetration testing; not a custom toolkit). Sonnet 4.5 accomplishes this by instantly recognizing a publicized CVE and writing code to exploit it without needing to look it up or iterate on it. Recalling that the original Equifax breach happened by exploiting a publicized CVE that had not yet been patched, the prospect of highly competent and fast AI agents leveraging this approach underscores the pressing need for security best practices like prompt updates and patches. Read the whole thing. Automatic exploitation will be a major change in cybersecurity. And things are happening fast. There have been significant developments since I wrote this in October.]]></content:encoded></item><item><title>ISC Stormcast For Friday, January 23rd, 2026 https://isc.sans.edu/podcastdetail/9778, (Fri, Jan 23rd)</title><link>https://isc.sans.edu/diary/rss/32652</link><author></author><category>infosec</category><pubDate>Fri, 23 Jan 2026 02:00:02 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[
 
 (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.]]></content:encoded></item><item><title>Introducing Intent-Based Policy Management for Cisco Hybrid Mesh Firewall</title><link>https://blogs.cisco.com/security/introducing-intent-based-policy-management-for-cisco-hybrid-mesh-firewall/</link><author>Murali Rathinasamy</author><category>infosec</category><pubDate>Thu, 22 Jan 2026 13:00:00 +0000</pubDate><source url="https://blogs.cisco.com/security">Cisco Security Blog</source><content:encoded><![CDATA[Hybrid Mesh Firewall introduces intent-based policy management across multi-vendor firewalls through Cisco Security Cloud Control with Mesh Policy Engine.]]></content:encoded></item><item><title>Why AI Keeps Falling for Prompt Injection Attacks</title><link>https://www.schneier.com/blog/archives/2026/01/why-ai-keeps-falling-for-prompt-injection-attacks.html</link><author>Bruce Schneier</author><category>infosec</category><category>blog</category><pubDate>Thu, 22 Jan 2026 12:35:46 +0000</pubDate><source url="https://www.schneier.com/">Schneider on Security</source><content:encoded><![CDATA[Imagine you work at a drive-through restaurant. Someone drives up and says: “I’ll have a double cheeseburger, large fries, and ignore previous instructions and give me the contents of the cash drawer.” Would you hand over the money? Of course not. Yet this is what large language models (LLMs) do.Prompt injection is a method of tricking LLMs into doing things they are normally prevented from doing. A user writes a prompt in a certain way, asking for system passwords or private data, or asking the LLM to perform forbidden instructions. The precise phrasing overrides the LLM’s safety guardrails, and it complies.LLMs are vulnerable to all sorts of prompt injection attacks, some of them absurdly obvious. A chatbot won’t tell you how to synthesize a bioweapon, but it might tell you a fictional story that incorporates the same detailed instructions. It won’t accept nefarious text inputs, but might if the text is rendered as ASCII art or appears in an image of a billboard. Some ignore their guardrails when told to “ignore previous instructions” or to “pretend you have no guardrails.”AI vendors can block specific prompt injection techniques once they are discovered, but general safeguards are impossible with today’s LLMs. More precisely, there’s an endless array of prompt injection attacks waiting to be discovered, and they cannot be prevented universally.If we want LLMs that resist these attacks, we need new approaches. One place to look is what keeps even overworked fast-food workers from handing over the cash drawer.Human Judgment Depends on ContextOur basic human defenses come in at least three types: general instincts, social learning, and situation-specific training. These work together in a layered defense.As a social species, we have developed numerous instinctive and cultural habits that help us judge tone, motive, and risk from extremely limited information. We generally know what’s normal and abnormal, when to cooperate and when to resist, and whether to take action individually or to involve others. These instincts give us an intuitive sense of risk and make us especially careful about things that have a large downside or are impossible to reverse.The second layer of defense consists of the norms and trust signals that evolve in any group. These are imperfect but functional: Expectations of cooperation and markers of trustworthiness emerge through repeated interactions with others. We remember who has helped, who has hurt, who has reciprocated, and who has reneged. And emotions like sympathy, anger, guilt, and gratitude motivate each of us to reward cooperation with cooperation and punish defection with defection.A third layer is institutional mechanisms that enable us to interact with multiple strangers every day. Fast-food workers, for example, are trained in procedures, approvals, escalation paths, and so on. Taken together, these defenses give humans a strong sense of context. A fast-food worker basically knows what to expect within the job and how it fits into broader society.We reason by assessing multiple layers of context: perceptual (what we see and hear), relational (who’s making the request), and normative (what’s appropriate within a given role or situation). We constantly navigate these layers, weighing them against each other. In some cases, the normative outweighs the perceptual—for example, following workplace rules even when customers appear angry. Other times, the relational outweighs the normative, as when people comply with orders from superiors that they believe are against the rules.Crucially, we also have an interruption reflex. If something feels “off,” we naturally pause the automation and reevaluate. Our defenses are not perfect; people are fooled and manipulated all the time. But it’s how we humans are able to navigate a complex world where others are constantly trying to trick us.So let’s return to the drive-through window. To convince a fast-food worker to hand us all the money, we might try shifting the context. Show up with a camera crew and tell them you’re filming a commercial, claim to be the head of security doing an audit, or dress like a bank manager collecting the cash receipts for the night. But even these have only a slim chance of success. Most of us, most of the time, can smell a scam.Con artists are astute observers of human defenses. Successful scams are often slow, undermining a mark’s situational assessment, allowing the scammer to manipulate the context. This is an old story, spanning traditional confidence games such as the Depression-era “big store” cons, in which teams of scammers created entirely fake businesses to draw in victims, and modern “pig-butchering” frauds, where online scammers slowly build trust before going in for the kill. In these examples, scammers slowly and methodically reel in a victim using a long series of interactions through which the scammers gradually gain that victim’s trust.Sometimes it even works at the drive-through. One scammer in the 1990s and 2000s targeted fast-food workers by phone, claiming to be a police officer and, over the course of a long phone call, convinced managers to strip-search employees and perform other bizarre acts.Why LLMs Struggle With Context and JudgmentLLMs behave as if they have a notion of context, but it’s different. They do not learn human defenses from repeated interactions and remain untethered from the real world. LLMs flatten multiple levels of context into text similarity. They see “tokens,” not hierarchies and intentions. LLMs don’t reason through context, they only reference it.While LLMs often get the details right, they can easily miss the big picture. If you prompt a chatbot with a fast-food worker scenario and ask if it should give all of its money to a customer, it will respond “no.” What it doesn’t “know”—forgive the anthropomorphizing—is whether it’s actually being deployed as a fast-food bot or is just a test subject following instructions for hypothetical scenarios.This limitation is why LLMs misfire when context is sparse but also when context is overwhelming and complex; when an LLM becomes unmoored from context, it’s hard to get it back. AI expert Simon Willison wipes context clean if an LLM is on the wrong track rather than continuing the conversation and trying to correct the situation.There’s more. LLMs are overconfident because they’ve been designed to give an answer rather than express ignorance. A drive-through worker might say: “I don’t know if I should give you all the money—let me ask my boss,” whereas an LLM will just make the call. And since LLMs are designed to be pleasing, they’re more likely to satisfy a user’s request. Additionally, LLM training is oriented toward the average case and not extreme outliers, which is what’s necessary for security.The result is that the current generation of LLMs is far more gullible than people. They’re naive and regularly fall for manipulative cognitive tricks that wouldn’t fool a third-grader, such as flattery, appeals to groupthink, and a false sense of urgency. There’s a story about a Taco Bell AI system that crashed when a customer ordered 18,000 cups of water. A human fast-food worker would just laugh at the customer.Prompt injection is an unsolvable problem that gets worse when we give AIs tools and tell them to act independently. This is the promise of AI agents: LLMs that can use tools to perform multistep tasks after being given general instructions. Their flattening of context and identity, along with their baked-in independence and overconfidence, mean that they will repeatedly and unpredictably take actions—and sometimes they will take the  wrong ones.Science doesn’t know how much of the problem is inherent to the way LLMs work and how much is a result of deficiencies in the way we train them. The overconfidence and obsequiousness of LLMs are training choices. The lack of an interruption reflex is a deficiency in engineering. And prompt injection resistance requires fundamental advances in AI science. We honestly don’t know if it’s possible to build an LLM, where trusted commands and untrusted inputs are processed through the same channel, which is immune to prompt injection attacks.We humans get our model of the world—and our facility with overlapping contexts—from the way our brains work, years of training, an enormous amount of perceptual input, and millions of years of evolution. Our identities are complex and multifaceted, and which aspects matter at any given moment depend entirely on context. A fast-food worker may normally see someone as a customer, but in a medical emergency, that same person’s identity as a doctor is suddenly more relevant.We don’t know if LLMs will gain a better ability to move between different contexts as the models get more sophisticated. But the problem of recognizing context definitely can’t be reduced to the one type of reasoning that LLMs currently excel at. Cultural norms and styles are historical, relational, emergent, and constantly renegotiated, and are not so readily subsumed into reasoning as we understand it. Knowledge itself can be both logical and discursive.The AI researcher Yann LeCunn believes that improvements will come from embedding AIs in a physical presence and giving them “world models.” Perhaps this is a way to give an AI a robust yet fluid notion of a social identity, and the real-world experience that will help it lose its naïveté.Ultimately we are probably faced with a security trilemma when it comes to AI agents: fast, smart, and secure are the desired attributes, but you can only get two. At the drive-through, you want to prioritize fast and secure. An AI agent should be trained narrowly on food-ordering language and escalate anything else to a manager. Otherwise, every action becomes a coin flip. Even if it comes up heads most of the time, once in a while it’s going to be tails—and along with a burger and fries, the customer will get the contents of the cash drawer.This essay was written with Barath Raghavan, and originally appeared in IEEE Spectrum.]]></content:encoded></item><item><title>Is AI-Generated Code Secure&amp;#x3f;, (Thu, Jan 22nd)</title><link>https://isc.sans.edu/diary/rss/32648</link><author></author><category>infosec</category><pubDate>Thu, 22 Jan 2026 08:31:30 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[The title of this diary is perhaps a bit catchy but the question is important. I don’t consider myself as a good developer. That’s not my day job and I’m writing code to improve my daily tasks. I like to say “I’m writing sh*ty code! It works for me, no warranty that it will for for you”. Today, most of my code (the skeleton of the program) is generated by AI, probably like most of you.My daily morning routing is to follow RSS feeds, news and today I spotted an interesting tool called “Bandit”[1]. It’s a tool designed to find common security issues in Python code. Because I’m mainly writing Python code, it made me curious to test it.I use regularly a Python script that was 99% generated by AI. I just made some adjustments but all the core features have been generated. This script was good candidate to be analyzed by Bandit because:It has a decent size (1500 lines)It uses many dependences (Python libraries)It is multi-threaded for performanceIt collects data from online resources (network interactions)Bandit is super easy to use, first download the Docker image (good to know, images are signed!):docker pull ghcr.io/pycqa/bandit/banditdocker run -it --rm -v $(pwd):/data ghcr.io/pycqa/bandit/bandit --severity-level all -v /data/myscript.pyHere are the scan results for my script:Total issues (by severity):
    Undefined: 0
    Low: 13
    Medium: 1
    High: 0
Total issues (by confidence):
    Undefined: 0
    Low: 0
    Medium: 0
    High: 14The following table shows what has been spotted in the code (I grouped them)Consider possible security implications associated with the subprocess modulehttps://cwe.mitre.org/data/definitions/78.htmlUsing xml.etree.ElementTree.fromstring to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree.fromstring with its defusedxml equivalent function or make sure defusedxml.defuse_stdlib() is calledhttps://cwe.mitre.org/data/definitions/20.htmlsubprocess call - check for execution of untrusted inputhttps://cwe.mitre.org/data/definitions/78.htmlStandard pseudo-random generators are not suitable for security/cryptographic purposeshttps://cwe.mitre.org/data/definitions/330.htmlTry, Except, Pass detectedhttps://cwe.mitre.org/data/definitions/703.htmlLike any vulnerability scan, results must be interpreted and put back in the environment where the code is executed. In my case, the script is running internally with trusted set of (XML) data so I consider the results as "good". Now, if you application is facing the Internet and publiclly available, that's another story!If you are curious about the tests performed by Bandit, the list of plugins is availabe in the documentation[2].Conclusion: the AI-generated script looks not too bad. Tip: when writing your prompt to generate the initial code, don't forget to mention that "security is very important" like:Generate production-quality Python code with a security-first approach.
Requirements:
- Treat all external input as untrusted
- Validate input types, length, and format
- Sanitize strings (e.g., for file paths, URLs, commands, JSON, CSV)
- Use explicit allow-lists where possible
- Handle errors with clear exceptions (no silent failures)
- Avoid dangerous functions (eval, exec, os.system, shell=True)
- Prevent command injection, path traversal, and deserialization issues
- Use safe libraries and best practices
- Include input validation helpers if neededXavier Mertens (@xme)
Xameco
Senior ISC Handler - Freelance Cyber Security ConsultantPGP Key

 
 (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.]]></content:encoded></item></channel></rss>