<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Latest</title><link>https://www.awesome-dev.news</link><description></description><item><title>Willie Hobbs Moore: STEM Trailblazer</title><link>https://spectrum.ieee.org/willie-hobbs-moore-profile</link><author>Willie D. Jones</author><category>tech</category><enclosure url="https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjQ4OTk0Ni9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc2NzAzOTE1Mn0.lUm5Wa5yQcpIZ0xdV8JvdAdFK4rGGfnMkR79x8IeWRs/image.jpg?width=600" length="" type=""/><pubDate>Sun, 16 Feb 2025 14:00:03 +0000</pubDate><source url="https://spectrum.ieee.org/">IEEE Spectrum</source><content:encoded><![CDATA[The first Black woman with a science Ph.D paved the way for underrepresented groups]]></content:encoded></item><item><title>Preparing for Senior PHP Symfony Developer role at Clubee</title><link>https://dev.to/gurachek/preparing-for-senior-php-symfony-developer-role-at-clubee-2can</link><author>Valera Gurachek</author><category>devto</category><pubDate>Sun, 16 Feb 2025 13:48:50 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Please take a look and let's discuss the preparation process.]]></content:encoded></item><item><title>Evaluate your LLM! Ok, but what&apos;s next? 🤔</title><link>https://dev.to/louis-dupont/evaluate-your-llm-ok-but-whats-next-3mk3</link><author>Louis Dupont</author><category>ai</category><pubDate>Sun, 16 Feb 2025 13:23:00 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Everyone say you need to Evaluate your LLM. You just did it. Now what? 🤷‍♂️You got a score. Great. Now, here’s the trap:   ()
 ("Tweak some stuff and re-run!")
Step 1: Stop staring at numbers.Numbers feel scientific, but Before doing anything, look at actual examples. Bad output? Good output but bad score? Both wrong? You’ve got bigger problems.Step 2: Solve the right problem.If your , tweak:  If your , rethink:  Step 3: Iterate like a maniac.Change something → Run eval → Learn → Repeat.  Chasing numbers isn’t progress. Chasing the right insights is.]]></content:encoded></item><item><title>Linux User Management Basics</title><link>https://dev.to/madhushan/linux-user-management-basics-me0</link><author>madhushan  Herath</author><category>devto</category><pubDate>Sun, 16 Feb 2025 13:17:33 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[If you're using Linux, knowing how to manage users is super important, especially if you're running a server or sharing your system with others. It helps you keep things organized and secure. Let’s go over the basics of handling users in Linux!Adding a new user is easy! If you're on Ubuntu/Debian, use this:This sets up a new user with a home directory and some basic settings.For other Linux versions, try:The  flag makes sure the home directory is created.
  
  
  2. Setting and Changing User Passwords
After adding a user, they’ll need a password:If you need to change your own password:To remove a user but keep their files:If you want to remove the user and their home directory:deluser  username
For RedHat-based systems:Groups help organize users with similar permissions. To add a user to a group:usermod  groupname username
To see which groups a user is in:To remove a user from a group:gpasswd  username groupname

  
  
  5. Understanding Linux File Permissions
Files and folders have permissions that control who can read, write, or run them. To check permissions:You'll see something like this:-rw-r--r-- 1 user group 1234 Jan 1 12:00 file.txt
The first character () means it's a file ( means directory).The next three () are for the owner.The next three () are for the group.The last three () are for others.To switch to another user:Or use  to run commands as another user:]]></content:encoded></item><item><title>Enhancing User Experience with Voice User Interface Implementation</title><link>https://dev.to/sista-ai/enhancing-user-experience-with-voice-user-interface-implementation-1749</link><author>Sista AI</author><category>ai</category><pubDate>Sun, 16 Feb 2025 13:15:58 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Implementing a Voice User Interface (VUI) on a website is a dynamic process that requires attention to detail and cutting-edge technology. By incorporating voice commands for common queries like pricing and product details, users can seamlessly interact with the interface, enhancing their overall experience.Best Practices for Seamless IntegrationProgressive enhancement is essential in voice UI design, ensuring users are comfortable with interactions. Performance optimization is critical for real-time responses, and user experience consideration like feedback and context-awareness elevate the VUI's usability.User-Centric Design PrinciplesUnderstanding user needs and simplifying interactions are core to effective VUI design. Clear feedback, accessibility features, and graceful error handling contribute to a seamless user experience.Technical Implementation and ChallengesFrontend components, backend services, and integration layers must work in harmony for a functional VUI. Significant resource investment is required, but the benefits of enhanced user experience and engagement justify the effort.Evolution of VUI TechnologyVUI design is constantly evolving, pushing boundaries in AI capabilities and design standards. Continuous learning and adaptation are crucial for staying on the cutting edge of interactive technology.Visit Sista AI to explore how their AI Voice Assistant transforms user interactions seamlessly.]]></content:encoded></item><item><title>Essential Technologies for Software Engineers Beyond Core Development</title><link>https://dev.to/kalana250/essential-technologies-for-software-engineers-beyond-core-development-1mig</link><author>Kalana Heshan</author><category>devto</category><pubDate>Sun, 16 Feb 2025 13:15:52 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Software engineering is a dynamic and ever-evolving field that demands continuous learning and adaptation. While mastering programming languages and frameworks is crucial, the modern software engineer must explore and integrate a broad set of technologies to enhance efficiency, security, scalability, and innovation. This article delves into key technologies beyond traditional software development that can significantly benefit engineers in their careers.
  
  
  1. Cloud Computing: The Backbone of Modern ApplicationsCloud computing has transformed how applications are developed, deployed, and maintained. Instead of relying on traditional on-premise servers, businesses now leverage cloud platforms to achieve scalability, cost-efficiency, and high availability.Amazon Web Services (AWS) – The industry leader offering services for computing, storage, networking, and AI-driven applications. – A cloud platform popular in enterprise environments, seamlessly integrated with Microsoft products like Office 365 and Active Directory.Google Cloud Platform (GCP) – Preferred for data analytics, AI-powered applications, and container orchestration with Kubernetes.Why Cloud Computing Matters: Cloud platforms allow developers to scale applications dynamically based on demand. Pay-as-you-go pricing ensures businesses only pay for the resources they use.Disaster Recovery & High Availability: Cloud infrastructure provides redundancy, ensuring that applications remain available even during failures.
  
  
  2. DevOps & CI/CD: Streamlining Software DevelopmentDevOps combines development and operations to improve collaboration, automate workflows, and enhance software delivery speed. Continuous Integration and Continuous Deployment (CI/CD) pipelines further automate the testing and deployment process. – Containerization tools that enable software to run consistently across environments.Jenkins, GitHub Actions, GitLab CI/CD – Tools for automating software builds, testing, and deployments. – Infrastructure as Code (IaC) tools that automate provisioning and configuration management.Why DevOps & CI/CD Matter:Faster Software Releases: Automated deployment pipelines reduce manual errors and accelerate time-to-market. Monitoring and logging tools ensure application performance remains optimal. Encourages close coordination between developers and operations teams.
  
  
  3. Cybersecurity: Protecting Digital AssetsWith cyber threats becoming more sophisticated, software engineers must integrate security measures from the initial development stages to prevent data breaches and system vulnerabilities. – A security framework identifying the most critical web application security risks. – Tools for penetration testing and ethical hacking. – Authentication and authorization protocols to secure applications.Why Cybersecurity Matters: Secure applications prevent sensitive user information from being exposed. Adhering to standards like GDPR and HIPAA ensures legal protection. Secure coding practices reduce attack surfaces and vulnerabilities.
  
  
  4. AI & Machine Learning: Powering Intelligent ApplicationsArtificial Intelligence (AI) and Machine Learning (ML) are revolutionizing industries by enabling automation, data-driven decision-making, and advanced user interactions. – Frameworks for developing machine learning models. – A beginner-friendly toolkit for AI-powered data analysis. – Platforms driving innovations in natural language processing (NLP) and AI-driven automation.Why AI & Machine Learning Matter: AI-powered solutions reduce human effort in repetitive tasks. Machine learning enhances decision-making by analyzing vast datasets.Enhanced User Experience: AI-driven chatbots, recommendation engines, and predictive analytics improve software applications.
  
  
  5. Blockchain & Web3: Building Decentralized ApplicationsBlockchain technology and Web3 innovations are reshaping finance, supply chains, and digital ownership, making them valuable areas of expertise for software engineers. – Smart contract development on decentralized networks. – Enterprise blockchain framework for business applications. – Distributed file storage system enhancing data security and decentralization. Blockchain ensures data immutability and prevents fraud. Reduces reliance on intermediaries in transactions. Automates processes with self-executing agreements.
  
  
  6. Software Architecture & System Design: Building Scalable ApplicationsAs software applications grow, designing them for scalability, maintainability, and efficiency is critical.Key Technologies & Concepts:Microservices & Monolithic Architectures – Choosing the right structure for an application. – Efficient data communication between services.Event-Driven Architecture (Kafka, RabbitMQ) – Enhancing real-time data processing.Why Software Architecture Matters:Performance Optimization: Ensures applications run efficiently under heavy loads. Reduces the risk of system-wide failures. Enables applications to grow seamlessly as demand increases.
  
  
  7. Internet of Things (IoT): Connecting the Physical and Digital WorldsIoT technology enables real-time data exchange between smart devices, revolutionizing industries such as healthcare, manufacturing, and logistics. – Hardware platforms for prototyping IoT devices. – Communication and data processing frameworks.AWS IoT & Google Cloud IoT – Cloud services for managing IoT networks. IoT applications enhance efficiency in various sectors. Enables smart systems in homes, cities, and industries. Reduces equipment failures with AI-driven insights.The field of software engineering extends beyond programming languages. Mastering emerging technologies such as cloud computing, DevOps, cybersecurity, AI, blockchain, system design, IoT, and AR/VR can make software engineers more versatile and valuable. By staying updated with these advancements, engineers can design secure, scalable, and innovative applications that drive the future of technology.]]></content:encoded></item><item><title>Kickstart Your AI Journey with This Free Course! 🌍</title><link>https://dev.to/hrudu/kickstart-your-ai-journey-with-this-free-course-3o3n</link><author>Hrudu Shibu</author><category>devto</category><pubDate>Sun, 16 Feb 2025 13:14:45 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[How to Learn Generative AI with Microsoft (No Experience Needed!)
Artificial Intelligence is no longer the future—it’s the present! Learning AI skills is becoming essential for students, developers, and professionals alike. With Microsoft’s Explore AI Learn Plan, you can:✔ Learn how generative AI works in a simple and practical way.
✔ Experiment with Microsoft Copilot to create AI-generated content.
✔ Complete a real-world AI project in under an hour.Who Is This For?
👨‍🎓 Students who want to explore AI in a fun way.
👩‍💻 Developers interested in applying AI tools.
📢 Content creators looking for AI-powered creativity.Start your AI journey today—no prerequisites required! 🚀]]></content:encoded></item><item><title>Hands-On AI Learning with Microsoft Copilot! 🎨</title><link>https://dev.to/hrudu/hands-on-ai-learning-with-microsoft-copilot-3ilb</link><author>Hrudu Shibu</author><category>devto</category><pubDate>Sun, 16 Feb 2025 13:13:37 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Ever Thought About Using AI for Creativity? Try This Free Course!
AI isn’t just about coding—it’s about creativity! Microsoft’s Explore AI Learn Plan allows you to use AI to design your dream destination in an interactive and engaging way.Why Should You Join?
✨ Practical Learning – Experiment with Microsoft Copilot to generate content.
✨ Hands-on Project – Apply AI skills to create a fictional travel destination.
✨ Quick & Free – Learn in just 53 minutes, with no cost!What You’ll Gain:
📌 New AI skills to use in real-world applications.
📌 A certificate of completion to showcase on your resume.
📌 Experience working with generative AI tools.Let’s build something creative with AI! 🚀]]></content:encoded></item><item><title>AWS Glue vs AWS Lambda: Comparativa Serverless para Ingeniería de Datos en AWS</title><link>https://dev.to/jlarizar/aws-glue-vs-aws-lambda-comparativa-serverless-para-ingenieria-de-datos-en-aws-108f</link><author>Jose Luis Ariza</author><category>devto</category><pubDate>Sun, 16 Feb 2025 13:13:00 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[El mundo Cloud ha revolucionado la forma en que las empresas gestionan y analizan sus datos. Amazon Web Services (AWS) ofrece diversas herramientas  que permiten a los ingenieros de datos trabajar sin preocuparse por la infraestructura subyacente. Entre estas herramientas,  destacan por su versatilidad y eficiencia. Aunque ambos servicios comparten el principio de la ejecución sin servidores, tienen objetivos y funcionalidades distintas. En este artículo, exploraremos las diferencias clave, sus ventajas y limitaciones, y cuándo elegir cada uno.AWS Glue es un servicio administrado de integración de datos que facilita la preparación, transformación y carga de datos (ETL). Su función principal es conectar diversas fuentes de datos, organizarlas y prepararlas para su posterior análisis. AWS Glue es especialmente útil en escenarios donde se manejan grandes volúmenes de información y se necesita automatizar procesos repetitivos.Principales componentes de AWS Glue Repositorio centralizado que almacena los metadatos y define la estructura de las fuentes de datos. Programas que examinan las fuentes de datos, detectan su estructura y actualizan automáticamente el catálogo. Procesos que ejecutan las transformaciones de datos, programados en Python o Scala. Reglas que activan la ejecución de trabajos según un cronograma o la ocurrencia de ciertos eventos. Entornos interactivos para escribir y probar el código ETL.Automatización del Proceso ETL: Reduce significativamente el tiempo necesario para preparar datos gracias a la detección automática de esquemas. Se conecta de manera sencilla con otros servicios de AWS, como Amazon S3, Amazon Redshift y AWS Athena. Ajusta la capacidad de procesamiento según el volumen de datos. Elimina la necesidad de gestionar infraestructura. Al trabajar con un entorno distribuido basado en Apache Spark, el inicio de los trabajos puede tardar algunos minutos.Soporte de Lenguajes Limitado: Solo admite Python y Scala, lo que puede ser un inconveniente si se utilizan otros lenguajes en el ecosistema. Para trabajos esporádicos o de poca carga, el costo puede resultar elevado en comparación con otras alternativas.Ejemplo Diagrama de Arquitectura - Pipeline GlueAWS Lambda es un servicio serverless que permite ejecutar código en respuesta a eventos específicos sin la necesidad de aprovisionar ni gestionar servidores. Su uso es ideal para aplicaciones que requieren respuestas rápidas a eventos en tiempo real, como la carga de archivos en S3 o el procesamiento de mensajes de una cola.Principales componentes de AWS Lambda Fragmentos de código que se ejecutan al activarse un evento. Eventos que inician la ejecución de las funciones, como cambios en bases de datos, flujos de eventos o solicitudes a través de API Gateway. Elementos reutilizables que permiten compartir bibliotecas y configuraciones entre funciones. Recibe y procesa eventos desde diversas fuentes, facilitando la construcción de arquitecturas basadas en eventos.Ejecución Basada en Eventos: Se activa automáticamente al detectarse un evento relevante, eliminando la necesidad de supervisión constante.Soporte para Múltiples Lenguajes: Compatible con Python, Node.js, Java, Go, Ruby y otros. Escala horizontalmente para manejar picos de demanda sin intervención manual. Se paga únicamente por el tiempo de ejecución y el número de invocaciones.Tiempo Máximo de Ejecución: Las funciones no pueden superar los 15 minutos de ejecución, lo que limita su aplicación en procesos extensos. La memoria y el tiempo de procesamiento tienen límites que podrían afectar cargas intensivas. Al tratarse de un servicio sin estado, se necesita recurrir a otras herramientas, como DynamoDB, para almacenar información entre invocaciones.Ejemplo Diagrama de Arquitectura - Pipeline LambdaComparativa entre AWS Glue y AWS LambdaAunque ambos servicios pertenecen al ecosistema serverless de AWS, tienen aplicaciones distintas. La siguiente tabla resume las diferencias más relevantes:AWS Glue es la mejor opción cuando se necesita:Realizar transformaciones complejas y procesamiento por lotes.Gestionar y organizar metadatos para análisis posteriores.Automatizar tareas de integración de datos en proyectos de Big Data.Trabajar con datos almacenados en Amazon S3, Redshift o Data Lakes.
Una empresa que procesa información de ventas históricas para generar reportes mensuales podría usar AWS Glue para consolidar, limpiar y transformar estos datos de manera eficiente.AWS Lambda es más adecuado cuando:Se requieren respuestas inmediatas a eventos en tiempo real.Se necesita construir microservicios ligeros y altamente escalables.Se desea automatizar tareas basadas en eventos sin preocuparse por la infraestructura.Se implementan flujos de trabajo orquestados con Step Functions.
Una aplicación que notifica en tiempo real a los clientes cada vez que se realiza una compra puede usar Lambda para procesar los eventos generados por las transacciones.AWS Glue y AWS Lambda son herramientas poderosas en el ecosistema de AWS, pero están orientadas a tareas diferentes. Mientras AWS Glue se destaca en el procesamiento y preparación de datos a gran escala, AWS Lambda es ideal para ejecutar tareas rápidas en respuesta a eventos. La elección entre uno u otro dependerá de los requisitos específicos de tu proyecto, el volumen de datos y la frecuencia de las operaciones. Si tu objetivo es transformar y organizar datos en procesos ETL, AWS Glue es la opción indicada. Por otro lado, si buscas una ejecución inmediata basada en eventos, AWS Lambda será tu mejor elección.]]></content:encoded></item><item><title>AI Learning for Everyone! 🚀</title><link>https://dev.to/hrudu/ai-learning-for-everyone-2mgc</link><author>Hrudu Shibu</author><category>devto</category><pubDate>Sun, 16 Feb 2025 13:11:44 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Learn Generative AI with Microsoft Copilot – Free AI Course
AI is revolutionizing the world, and now you can learn generative AI for free with Microsoft Copilot through the Explore AI Learn Plan! 🚀What Will You Learn?
In this short 53-minute learning path, you will:
✅ Understand the basics of generative AI.
✅ Use Microsoft Copilot to research and create AI-generated content.
✅ Design your own dream destination using AI-powered tools.Who Should Join?
💡 Students who want to explore AI applications.
💡 Tech enthusiasts looking to boost their AI skills.
💡 Educators who want to introduce AI to their students.No prior experience required—just a passion for learning! 🌟]]></content:encoded></item><item><title>RandomInvert in PyTorch</title><link>https://dev.to/hyperkai/randominvert-in-pytorch-5eb0</link><author>Super Kai (Kazuya Ito)</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 13:07:51 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[The 1st argument for initialization is (Optional-Default:-Type: or ):
*Memos:

It's the probability of whether an image is inverted or not.The 1st argument is (Required-Type: or ()):
*Memos:

A tensor must be 2D or 3D.]]></content:encoded></item><item><title>Getting Buy-In: Overcoming Larman&apos;s Law • Allen Holub • YOW! 2024</title><link>https://www.youtube.com/watch?v=XwhF_xbVpIQ</link><author>GOTO Conferences</author><category>video</category><category>learning</category><enclosure url="https://www.youtube.com/v/XwhF_xbVpIQ?version=3" length="" type=""/><pubDate>Sun, 16 Feb 2025 13:00:46 +0000</pubDate><source url="https://www.youtube.com/channel/UCs_tLP3AiwYKwdUHpltJPuA">GOTO Conferences yt</source><content:encoded><![CDATA[This presentation was recorded at YOW! Australia 2024. #GOTOcon #YOW
https://yowcon.com

Allen Holub - Helps You Build Software Better & Build Better Software; Author of 10 Books & Hundreds of Articles @AllenHolub 

RESOURCES
https://bsky.app/profile/allenholub.bsky.social
https://mstdn.social/@allenholub
https://twitter.com/allenholub
https://holub.com
https://www.linkedin.com/in/allenholub

Links
https://miro.com/app/board/uXjVL6ZfQvA=/
https://www.craiglarman.com/wiki/index.php?title=Larman%27s_Laws_of_Organizational_Behavior

ABSTRACT
Larman's Law states, "Organizations are implicitly optimized to avoid changing the status quo…" The third law is particularly relevant: 'Any change initiative will be derided as “purist,” "theoretical," “revolutionary," " “religion,” and “needing pragmatic customization for local concerns”—which deflects from addressing weaknesses and the manager/specialist status quo.'

You need to overcome that resistance to use innovative approaches like no-estimation or mob/ensemble programming.

Devs, however, almost always go about that the wrong way. Senior management is rarely interested in the mechanics of what you're doing. They're interested in the bottom line, how the new approaches change how the business is managed, and whether the inevitable disruption is worth it.

In this talk, you'll learn how to convince the “suits” (and your clients) that innovation is a good thing. You'll learn how to create a business case for innovation that overcomes the resistance of Larman's Law. [...]

TIMECODES
00:00 Intro
01:48 Larman's Laws of organizational behavior
12:36 Bottom up
20:20 Top down
24:42 Business case
36:10 Value stream mapping
39:12 Mob programming
53:00 Summary
53:57 Outro

Read the full abstract here:
https://yowcon.com/brisbane-2024/sessions/3470

RECOMMENDED BOOKS
Allen Holub • Holub on Patterns • https://amzn.to/3Q1hwTX
Allen Holub • Compiler design in C • https://amzn.to/4b0vXS9
Allen Holub • Enough Rope to Shoot Yourself in the Foot • https://amzn.to/4hFIL2m

https://bsky.app/profile/gotocon.com
https://twitter.com/GOTOcon
https://www.linkedin.com/company/goto-
https://www.instagram.com/goto_con
https://www.facebook.com/GOTOConferences
#LarmansLaw #CraigLarman #EnsembleProgramming #TechLead #TechLeadership #PsychologicalSafety #SkunkWorks #ValueStreamMapping #AllenHolub #YOWcon

CHANNEL MEMBERSHIP BONUS
Join this channel to get early access to videos & other perks:
https://www.youtube.com/channel/UCs_tLP3AiwYKwdUHpltJPuA/join

Looking for a unique learning experience?
Attend the next GOTO conference near you! Get your ticket at https://gotopia.tech
Sign up for updates and specials at https://gotopia.tech/newsletter

SUBSCRIBE TO OUR CHANNEL - new videos posted almost daily.
https://www.youtube.com/user/GotoConferences/?sub_confirmation=1]]></content:encoded></item><item><title>Week 12 Recap of #100DaysOfCode</title><link>https://dev.to/lymah/week-12-recap-of-100daysofcode-21h7</link><author>Lymah</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:54:38 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[
  
  
  Firebase Integration, API Enhancements & DSA Learning
This week, I focused on enhancing my Expense Tracker App by integrating Firebase for receipt storage and authentication, improving API functionality, and diving deeper into data structures and algorithms (DSA).
  
  
  Key Developments in the Expense Tracker App
🔹 Integrated Firebase for Receipt Storage
I implemented a workflow where users can upload receipts from the frontend, which are then processed by the backend and stored securely in Firebase Storage.🔹 Enhanced API & Report GenerationImproved API handlers to ensure efficient communication between the frontend and backend.Worked on report generation to help users analyze their expenses better.Faced a form handling issue while testing report generation but successfully troubleshot and fixed it.
🔹 Implemented Firebase AuthenticationSet up Firebase Authentication for user registration and login.Developed authentication middleware to manage secure access.Organized and refined API routes for better structure and efficiency.## Learning & Problem-SolvingAside from working on the app, I spent time improving my DSA skills and solving LeetCode problems:Insert Delete Get Random – Practiced hashmaps and randomized data structures.Product of Array Except Self – Strengthened understanding of prefix sum techniques.With the major backend integrations complete, my focus will now be on:Finalizing app testing and fixing any edge cases.Optimizing performance and deployment readiness.Continuing DSA practice to sharpen my problem-solving skills.Week 12 was packed with important features, debugging, and learning! 🚀 Excited for the next phase of this journey!]]></content:encoded></item><item><title>GIT haqida ma&apos;lumot</title><link>https://dev.to/sunnat_qayumov/git-8a</link><author>Sunnat Qayumov</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:53:49 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[ bu loyihalar saqlash uchun va dasturchilar birga loyihalar ustida jamoaviy ishlashida kerak bo'ladigan platforma(bulutli texnologiya - cloud technology). - bu dasturiy ta'minot versiyalarni nazorat qiluvchi tizim('version control system`). Undan dasturchilar kodni kuzatish, boshqarish va jamoa bilan ishlash uchun foydalanadilar.Git o'zi qanday ishlaydi? kodni  (repo) deb nomlanuvchi markaziy joyda saqlaydi. Dasturchilar ushbu repodan nusxa olib, unda ishlashlari va keyin o‘z o‘zgarishlarini qayta yuklashlari mumkin. Git quyidagi asosiy operatsiyalarni bajarishga imkon beradi: -> yangi Git repository yaratish. -> mavjud repository’ni nusxalash. -> o‘zgarishlarni kuzatish uchun fayllarni qo‘shish.Git commit -m "File name" -> komentariya qoldirish. -> lokal commitlarni serverga ulash. -> serverdagi so‘nggi o‘zgarishlarni olish. -> ikkita kod tarmog‘ini birlashtirish. -> ortiqcha fayllarni olib tashlash. ]]></content:encoded></item><item><title>Building a URL Shortener in Go</title><link>https://dev.to/luthfisauqi17/building-a-url-shortener-in-go-592d</link><author>luthfisauqi17</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:43:21 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Have you ever wondered how  or  work? Today, we're building our URL shortener in Golang!By the end of this tutorial, you'll have a fully working URL shortener that generates short links and redirects users. Let’s get started!Before we dive into coding, let's understand how a URL shortener works:The user enters a long URLSave it in a memory or databaseWhen someone visits the short link, we redirect themFirst, create a new project and initialize Go modules.go-url-shortener go-url-shortener
go mod init github.com/yourusername/go-url-shortener
go get github.com/gin-gonic/gin
Now, open  and set up a simple Gin server.This creates a basic Gin server. Now let’s add URL shortening!
  
  
  Step 2: Generate Short URLs
Now, we need a function to generate a short random URL.Next, let’s create the /shorten endpoint that takes a long URL and returns a short one.This stores the original URL in a map and returns a short URL.
Now, let’s handle redirection!
  
  
  Step 4: Redirect Short URLs
We need an endpoint that looks up the short URL and redirects users.Let’s test this API using cURL!
Run the application by typing.curl -X POST http://localhost:8080/shorten -H "Content-Type: application/json" -d '{"original_url": "https://google.com"}'
{
    "short_url": "http://localhost:8080/abc123"
}

  
  
  Redirect (Visit the short URL)
curl -v http://localhost:8080/abc123
There you go, that is how you build a URL Shortener using Golang. Thank you for reading, and have a nice day!]]></content:encoded></item><item><title>Getting Started with Linux: Key Lessons from the Linux Foundation</title><link>https://dev.to/madhushan/getting-started-with-linux-key-lessons-from-the-linux-foundation-1g62</link><author>madhushan  Herath</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:42:48 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Linux is an awesome, open-source operating system that powers everything from servers to smartphones. If you're new to Linux and want to get started, the Linux Foundation has some great courses to help you out. Here are some key takeaways from a beginner-friendly Linux Foundation course.Understanding Linux BasicsLinux is based on Unix principles, which focus on keeping things simple and efficient. You'll get to know:The Linux file system structure, including folders like /home, /var, /etc, and /binHandy command-line commands to move around and manage filesHow the Linux kernel works and talks to your hardware and appsThe different Linux distributions and what makes them uniqueMastering the Command LineThe command line is where all the magic happens in Linux. Here are some must-know commands:ls – Lists files and folders (use ls -l for extra details)cd – Moves between directories (cd .. takes you up a level)cp – Copies files (cp file1 file2 to make a copy)mv – Moves or renames files (mv oldname newname to rename a file)rm – Deletes files (rm -r removes folders too)grep – Searches for words in files (grep 'keyword' filename)cat, less, and more – Show the contents of files quicklyManaging Users and PermissionsTo keep things secure, Linux has a solid user and permission system. You'll learn about:Adding and managing users (adduser, passwd, usermod, deluser)Changing file permissions (chmod, chown, ls -l to check permissions)Managing groups (usermod -aG groupname username to add users to groups)How permission values like rwxr-xr-- and numbers like chmod 755 workInstalling and Managing SoftwareInstalling software on Linux is pretty straightforward. Here’s what you’ll use:apt (for Debian/Ubuntu-based systems) – Example: apt install package_nameyum or dnf (for RHEL/CentOS-based systems) – Used for software managementsnap and flatpak – Universal package managers for different distrosHow to build and install software from source if neededSystem Monitoring and Process ManagementKeeping your Linux system running smoothly means monitoring it. Some useful commands include:top and htop – Show what’s running on your system in real timeps – Check running processes (ps aux gives detailed info)kill – Stop processes (kill -9 PID for force quitting)df and du – Check disk space (df -h makes it human-readable)free -m – See how much memory is being useduptime – Find out how long your system has been runningWant to automate boring tasks? Shell scripting makes life easier. You'll get into:Writing simple Bash scripts using #!/bin/bashUsing loops (for, while) and conditions (if, else)Setting up automated tasks with cron (crontab -e to edit cron jobs)Working with variables and user inputs (read command) to make scripts interactiveNetworking and Security BasicsLinux is a networking powerhouse. You'll learn how to:Check network connectivity (ping, netstat, ip a for IP details)Set up firewalls (iptables, ufw for managing access rules)Securely connect to remote systems with SSH (ssh user@hostname, scp for file transfers)View active connections (netstat -tulnp shows open ports and services)Strengthen security with tools like fail2ban and SELinux]]></content:encoded></item><item><title>From a Curious Student to Meeting Satya Nadella: My Journey with the Azure Developer Community</title><link>https://dev.to/vivek0712/from-a-curious-student-to-meeting-satya-nadella-my-journey-with-the-azure-developer-community-39g3</link><author>Vivek0712</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:42:23 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[In late 2020, I was just a curious college student with a thirst for knowledge about cloud technologies and artificial intelligence. My journey began with a decision that many would call impulsive but turned out to be life-changing. I traveled over 500 kilometers just to attend a Microsoft Azure event. That one step of courage and curiosity marked the beginning of an extraordinary adventure.
  
  
  🚀 The First Leap of Faith
I still remember the excitement mixed with nervousness as I entered the event venue. I knew no one there, but the warmth of the Azure Developer Community made me feel at home. I met developers, architects, and enthusiasts who were more than happy to share their knowledge. It was this openness that fueled my passion for cloud technologies.
  
  
  🌱 Community: The Catalyst for Growth
The Azure Developer Community officially began in late 2020 and quickly became my launchpad for growth. It didn't just teach me technical skills; it taught me the essence of collaboration and continuous learning. I actively sought mentorship, participated in discussions, and never hesitated to ask questions. Over time, my efforts bore fruit. I was invited to speak at small meetups, and soon, these meetups turned into large-scale events and conferences.Fast forward to today: I've spoken, hosted, or organized more than 300 events across the globe. These events range from intimate bootcamps to large-scale conferences with thousands of attendees. I even had the privilege of winning the AI ODC Challenge in both 2024 and 2025, which opened doors to new opportunities and collaborations.
  
  
  🤝 Meeting the Visionary: Satya Nadella
One of the most surreal moments of my journey was meeting Satya Nadella, the CEO of Microsoft, not once but twice. The moment I shook hands with him, I felt the weight of years of learning and hard work crystallizing into a single, unforgettable experience. Getting photographed with him was a dream come true, and the picture was later featured in Pune Chaak's keynote session during the Microsoft AI Tour 2024 — a moment of recognition that made me realize the impact of my work and the power of community-driven growth.
  
  
  ❤️ Giving Back to the Community
The community that once nurtured me is now the one I contribute to passionately. I’ve mentored aspiring developers, organized countless bootcamps, and supported the growth of the Azure Developer Community in Tamil Nadu, which has now grown to over 5,000 members in record time.
  
  
  🗣️ Talks and Sessions: A Chronicle of Knowledge Sharing
Throughout my journey, I've delivered numerous talks and conducted hands-on sessions. Here are some notable ones related to Azure and the Azure Developer Community:Image Data Analytics using Python – Mepco Schlenk Engineering College  Deep Dive into Microsoft Azure Automated Machine Learning – Global Azure Datafest 2020  Machine Learning Pipelines in AzureML – Azure Developer Community Tamil Nadu  Demo on Azure Cognitive Services – Azure ML Series  Training & Deploying ML Models in Azure – Azure Developer Community Mumbai  Exploring Azure Cognitive Services – Azure Developer Community Raipur  Getting started with Azure AutoML – Azure Developer Community Chandigarh  Deploying Python Apps to AKS – Azure Developer Community Tamil Nadu  Attendance System with Face Mask Detection using Azure Face API(Published: Feb 15, 2024)Predict NYC Taxi Fares | End-to-end Azure MLOps with GitHub Actions(Published: Feb 14, 2024)Build a Production LLM-Powered QC Visual Inspection System Using Azure AI Foundry(Published: Feb 13, 2024)Analyse Customer Sentiment using Azure Data Factory pipeline(Published: Feb 12, 2024)Electronics-Datasheet-GPT: A Step-by-Step Guide to Building Your Own Datasheet Q&A AI Agent(Published: Feb 11, 2024)Experimenting with DeepSeek-R1 Model in VS Code Hosted via GitHub Models(Published: Feb 10, 2024)How AWS GenAI boosted my day-to-day Productivity(Published: May 31, 2024)What If Amazon Prime A/B Tests IPL Broadcasting?(Published: Feb 21, 2024)Speed-Dataing for hackers!Transforming Madurai | Tech, Community and more...(Published: Apr 17, 2023)AWS Community Day Hyderabad 2023 | Experience with Vivek(Published: Mar 25, 2023)Blur Personal Identifiable Information (PII) in Text, Images and Videos(Published: Jun 10, 2022)Adding Chaos to ML Compute Targets(Published: Feb 15, 2022)(Azure Architecture Series)Introducing Chaos Engineering to Machine Learning deployments(Published: Feb 12, 2022)(Azure Architecture Series)How FORMULA 1 insights are powered by AWS(Published: Oct 20, 2021)Hosting Python Packages in Azure DevOps(Published: Aug 31, 2021)Training Machine Learning models in AzureML(Published: Aug 22, 2021)(Azure Machine Learning Series)Getting started with Azure Machine Learning(Published: Aug 20, 2021)(Azure Machine Learning Series)Introduction to Machine Learning(Published: Aug 19, 2021)(Azure Machine Learning Series)Fine-tuning the performance of the DeepRacer model(Published: Jul 31, 2021)(AWS Community Builders - DeepRacer)Create, Train, Race your first AWS DeepRacer Model(Published: Jul 24, 2021)(AWS Community Builders - DeepRacer)Detecting and Visualizing Twitter Sentiment during COVID-19 Pandemic using AWS Comprehend and Quicksight(Published: Jul 19, 2021)Creating COVID19 stats newsletter using Azure Function Apps(Published: Apr 14, 2021)Literature Text Translation & Audio Synthesis using Microsoft Azure Cognitive Services All posts are published on .
  
  
  🎓 Certifications: The Foundation of My Technical Knowledge
My passion for continuous learning is reflected in the certifications I've earned:Microsoft Certified Azure Developer Associate (AZ-204)Microsoft Certified Azure Data Scientist Associate (DP-100)Microsoft Certified Azure AI Engineer Associate (AI-100)Microsoft Certified Azure Data Engineer Associate (DP-200 & DP-201) Microsoft Certified Azure Fundamentals (AZ-900)
  
  
  🌐 VickyBytes: A New Chapter
As I reflect on this journey, I’m thrilled to share that I'm working closely with Microsoft's leadership to build a new platform called VickyBytes. This initiative aims to provide developers with curated, high-quality content to stay ahead in the ever-evolving tech landscape. The idea is simple yet powerful: leverage the strength of community to empower developers worldwide.
  
  
  👨‍💼 My Professional Journey: A Snapshot
(YourStory Tech30 startup winner; Raised $3.5M!)(Youngest ever!), AWS Hero of the Year (APJ 2024) recipient at AWS Community Leaders Summit 2022 Azure Developer Community TN  AWS User Group Madurai (Nominated as Best UG 2022, 2023 & 2024)Guinness World Record Holder Recent paper at IIM-B & holder of 2 AI patents; Participant & JuryMentor | Blogger | Content CreatorMovie Buff | Go-Kart Racer | Guitar Enthusiast | Professional Reels Sender
  
  
  🌟 Lessons from the Journey
 Growth accelerates when like-minded people collaborate. Showing up consistently to learn, share, and contribute can open unimaginable doors. The more you give to the community, the more you grow.I owe my success to the Azure Developer Community and the incredible people who believed in me when I was just a student with dreams. To every mentor, attendee, and fellow enthusiast:  for being part of my story.
  
  
  Photo Gallery (Random moments clicked!)
This journey from being a curious student to becoming one of India's recognized AI figures has been nothing short of magical. And if there's one message I'd like to share, it’s this: take that first step, no matter how uncertain it seems. The community will catch you, guide you, and help you soar.#AzureCommunity #AIInnovation #CommunityFirst #VickyBytes]]></content:encoded></item><item><title>A better pkg.go.dev</title><link>https://dev.to/jacktt/a-better-pkggodev-hip</link><author>JackTT</author><category>dev</category><category>go</category><pubDate>Sun, 16 Feb 2025 12:35:06 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[I have never been able to read a package's documentation on pkg.go.dev since all the code there is in black & white...
This is the reason I created this repository to make it possible to read.Every time you want to read a package's documentation, you just need to replace pkg.go.dev with pkgo.dev. .We use Nginx as proxy server.Every time a request come in, we forward it to the pkg.go.dev server, then append the highlight.js script to the response before sending it back to the client.Since some README files do not specify the code language, we also update  tags to <code class="language-go"> to enable syntax highlighting.If you don't trust me, no worry, you can deploy it yourself:Append 127.0.0.1       pkg.go.dev.local to Run docker-compose up -d --buildAccess ]]></content:encoded></item><item><title>Alleged &apos;CEO Shooter&apos; Luigi Mangione Raises $297K Online</title><link>https://yro.slashdot.org/story/25/02/16/0040252/alleged-ceo-shooter-luigi-mangione-raises-297k-online?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 16 Feb 2025 12:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Luigi Mangione faces first-degree murder charges. On Valentine's Day he posted his first public comments online, reports People magazine, with Mangione saying he's grateful for the support he's receiving:

Earlier this week, Mangione accepted $297,000 in donations to cover his legal bills from the December 4 Legal Committee, which is stewarding a fundraiser on GiveSendGo for his legal defense, according to a post shared by the group. (A source with knowledge of the situation confirmed to PEOPLE that the post was genuine.) The committee — named after the death date of Thompson — said the donations were offered by over 10,000 individual supporters. Mangione's lead attorney, Karen Friedman Agnifilo, told the committee that Mangione "very much appreciates the outpouring of support...." 

His federal murder charges could land him the death penalty, and he also faces state murder charges that accuse him of committing an act of terrorism.]]></content:encoded></item><item><title>🚀 Docker Tips: Essential Tips and Tricks for Developers</title><link>https://dev.to/d_thiranjaya_6d3ec4552111/docker-tips-essential-tips-and-tricks-for-developers-1hl8</link><author>Pawani Madushika</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:27:24 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[
  
  
  Advanced Docker Tips for Modern Development (2025)
In the rapidly evolving world of software development, staying ahead of the curve is crucial. Docker, a renowned containerization platform, has revolutionized the way we build, deploy, and manage applications. To optimize your Docker development workflow, this comprehensive guide delves into advanced techniques, best practices, and performance optimization strategies that experienced developers may not be aware of.
  
  
  Latest Advanced Techniques

  
  
  1. Podman: Unleashing Container Management Potential
Traditional Docker commands can be replaced with the lightweight and sandboxed  utility. This alternative offers enhanced security, reduced resource consumption, and simplified container management:# Create a container using podman
podman create --name my-container my-image

  
  
  2. BuildKit: Accelerating Image Building
BuildKit accelerates image building by leveraging incremental builds, caching, and parallel execution. By integrating BuildKit into your Dockerfile, you can significantly reduce build times:# Dockerfile using BuildKit
FROM my-base-image as build-stage
RUN apk add ... # Use BuildKit syntax

  
  
  3. Swarm Mode: Distributed Container Orchestration
Swarm mode enables seamless scaling of containerized applications across multiple hosts. It provides advanced load balancing, service discovery, and automated container placement:# Initialize a Swarm cluster
docker swarm init

  
  
  1. Multi-Stage Builds for Optimized Images
Multi-stage builds allow you to create smaller and more efficient images by separating build steps into distinct stages. This minimizes the transfer of unnecessary dependencies:# Multi-stage Dockerfile
FROM node:lts AS build
WORKDIR /usr/src/app
COPY . .
RUN npm install --production

FROM nginx:latest
COPY --from=build /usr/src/app /usr/share/nginx/html

  
  
  2. Performance Monitoring with Prometheus and Grafana
Prometheus and Grafana provide comprehensive monitoring and visualization for Docker environments. They enable real-time tracking of container metrics, performance bottlenecks, and resource usage:# Docker Compose configuration for monitoring
version: '3'
services:
prometheus:
image: prom/prometheus
volumes:
- ./prometheus.yml:/etc/prometheus/prometheus.yml
grafana:
image: grafana/grafana

  
  
  Modern Development Workflow

  
  
  1. CI/CD Automation with GitHub Actions
GitHub Actions integrates seamlessly with Docker to automate build, test, and deployment processes. This facilitates continuous integration and delivery practices:# GitHub Actions workflow
name: Docker Build and Deploy
on: [push]
jobs:
build:
runs-on: ubuntu-latest
steps:
- uses: actions/checkout@v3
- uses: docker/build-push-action@v3
with:
push: true

  
  
  2. Remote Container Debugging for Enhanced Efficiency
Remote debugging allows you to troubleshoot running containers from your local IDE. This simplifies issue identification and resolution:# Enable remote debugging in Docker Compose
version: '3'
services:
my-app:
image: my-image
command: ["/usr/local/bin/debug", "--host=0.0.0.0", "--port=5678", "--wait", "true"]

  
  
  1. Docker Compose v2: Simplified Configuration and Automation
Docker Compose v2 introduces a simplified syntax, improved performance, and support for multiple Dockerfiles. It streamlines container orchestration:# Docker Compose v2 configuration
version: '2'
services:
db:
image: postgres:latest
web:
image: my-web-app
depends_on:
- db

  
  
  2. Docker Desktop for Mac and Windows
Docker Desktop offers a local development environment for Docker on Mac and Windows. It includes pre-configured services, simplified container management, and easy access to Docker resources.
  
  
  3. Docker Hub: Centralized Image Management
Docker Hub serves as a central repository for storing and sharing Docker images. It provides access to official images, community contributions, and automated builds.Leverage advanced techniques like Podman, BuildKit, and Swarm Mode to enhance your Docker development workflow.Implement performance optimization strategies using multi-stage builds and monitoring tools.Utilize modern best practices such as remote container debugging and CI/CD automation.Explore the latest tools and resources to improve your Docker development experience.By implementing these advanced techniques, you can optimize your Docker development process, enhance performance, and stay ahead of the evolving landscape of modern software development.]]></content:encoded></item><item><title>Microinteractions: The Secret Sauce to Enhancing User Experience</title><link>https://dev.to/okoye_ndidiamaka_5e3b7d30/microinteractions-the-secret-sauce-to-enhancing-user-experience-220f</link><author>Okoye Ndidiamaka</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:25:31 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[In the world of web and app design, it's often the little things that leave the biggest impressions. Microinteractions are those subtle, engaging animations or design elements that guide users, provide feedback, and add personality to your digital product. Think of the gentle bounce of a button after it's clicked or the satisfying swipe animation when archiving an email. These can be minor moments, but they can change a good user experience into an unforgettable one.Why Microinteractions MatterMicrointeractions are not just about aesthetics; they serve very real functional purposes. Here's why they're so important:Provide Feedback: They tell users what happened with their action, whether it was a button click or a process that is complete.Guide the User: Subtle animations can draw attention to important elements or actions. For example, a blinking cursor in a search bar encourages users to start typing.Enhance Engagement: When designed well, microinteractions are pleasurable moments that make users want to come back for more.Strengthen Branding: Custom animations unique to your brand can create a memorable identity that stands out.Key Elements of MicrointeractionsEvery microinteraction is composed of four major parts:Trigger: What starts the microinteraction? It can be an explicit user action-like clicking or swiping-or an implicit system event, such as a timer or condition being met.Rules: These determine how the microinteraction works. For example, what happens when a button is clicked?Feedback: The visual, auditory, or tactile response users get, such as a click sound or a color change.Loops and Modes: These are the conditions that determine if the microinteraction repeats or evolves over time.Practical Tips for Designing Effective MicrointeractionsHere’s how to implement microinteractions that enhance user experience:Keep It Simple
Microinteractions should be subtle and straightforward. Overloading users with flashy animations can make your design look cluttered and confuse users. Stick to minimal, functional designs.Prioritize Functionality
Every animation should have a purpose. Never add microinteractions just because they look good. For instance, a loading spinner tells the user that something is happening, while an animation of a toggle switch explains how it works.Be Consistent
Consistency in microinteractions is important to create a cohesive user experience. Align animations with your brand identity and ensure they behave predictably across different platforms and devices.Design for Context
Consider the user's intention and the context of the interaction. For example, an animated behavior may be perfectly fine for a gaming application, but it may look like it doesn't belong if it's part of financial software.Employ the Right Tools
Figma, Adobe After Effects, or Lottie are some tools that make designing and prototyping microinteractions a breeze. Experiment with these to bring your designs to life.Real-World Examples of MicrointeractionsFacebook Reactions: Hover on the "Like" button and a row of emojis pops out, making it fun and interactive for users to express themselves.LinkedIn Endorsements: The animation of skill endorsement is so subtle, yet interactive, sans overwhelming the user.Heart Animation by Instagram: Users can get instant feedback when they double-tap a post, which results in an animated heart popping up. Common Mistakes to Avoid  While
 micro-interactions are powerful, this is how they can become counter-productive if not implemented well:Overcomplicating the Animations: Too-long or flashy animations irritate the users.Disregarding Accessibility: Make sure microinteractions are accessible for all users, whether they have visual or motor impairments.Overloading the Interface: Too many animations can make performance worse and confuse users.The Future of MicrointeractionsAs technology evolves, microinteractions will also get more intelligent. With AI and machine learning, in the future, designs may automatically adapt microinteractions based on user behavior, thus creating even more personalized experiences.While micro in nature, microinteractions make great impacts on user experiences. By paying attention to minute details, you will also be able to create not just functional but delightful interfaces. So, go live with microinteractions in all your projects and watch your UX soar high.What's your favorite microinteraction in the apps or websites that you use? Share it with me in the comments below!]]></content:encoded></item><item><title>The DeepSeek Revolution: The AI Game Changer You Need to Know About</title><link>https://dev.to/nitdgplug/the-deepseek-revolution-the-ai-game-changer-you-need-to-know-about-1f57</link><author>Ayush Bhartia</author><category>ai</category><pubDate>Sun, 16 Feb 2025 12:21:08 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Hey everyone! The AI landscape is constantly evolving, with new models pushing the boundaries of what's possible. But one name has been making waves recently, i.e, . Unlike other AI tools, this powerhouse has rewritten the rulebook on efficiency, cost-effectiveness, and performance. If you haven't heard of it yet, here’s why it’s capturing global attention.What Is DeepSeek and Why Is It Gaining Popularity?In January 2025, DeepSeek, a Chinese AI company, emerged as a major player in the AI space. Developed by a Chinese AI lab, it rapidly climbed the app store rankings, even surpassing ChatGPT as the most popular free AI assistant in the US.
But what’s driving the hype? DeepSeek-R1 isn’t just another AI model—it’s an example of cutting-edge efficiency at a fraction of the usual cost. Unlike its competitors, which require massive investments,  was trained for just —a game-changing breakthrough in AI development.Innovation Behind DeepSeekDeepSeek’s strength lies in its  training method, which splits its AI into specialized sub-models. Instead of a single large neural network handling everything, each part of DeepSeek is optimized for specific tasks, making it both  and more .
Another key advantage is its , which adjusts processing power based on task complexity. This means DeepSeek can deliver high performance while using significantly fewer resources compared to other models.Moreover, instead of relying on Nvidia’s high-end H100 chips, DeepSeek utilizes the more affordable , making AI training and deployment  cheaper than models like DeepSeek-R1 helping open-source communityDeepSeek released its flagship model, DeepSeek-R1, under the . This model, developed with remarkable resource efficiency—using approximately 2,000 Nvidia H800 GPUs over 55 days demonstrated performance on par with leading AI models from established tech giants. DeepSeek has made significant strides in the artificial intelligence landscape by open-sourcing its advanced AI models. 
The open-source release of DeepSeek-R1 has lowered barriers to AI development, fostering innovation and competition across the global AI community. The company has also released models like , designed to enhance code intelligence, and , aimed at advancing vision-language understanding. These models are available for public use and modification, promoting transparency and collaboration in AI research and application.How DeepSeek Outperforms Other AI ModelsBeyond its efficiency, DeepSeek is redefining AI reliability with its R1 Reasoning Model. Unlike traditional models, the probability of the R1 Reasoning Model giving appealing outputs is much higher as compared to other available models since this model is designed to validate its own reasoning supporting its output, improving accuracy in subjects like math, science, and fact-checking.
This makes DeepSeek particularly powerful for research, problem-solving, and advanced computations, offering a level of precision that many AI models like  from OpenAI,  from MetaAI, and  from Google, etc struggle to achieve.Challenges and LimitationsDespite its impressive capabilities, DeepSeek isn’t without challenges. Its business model remains uncertain, as it offers services at a significantly lower cost than competitors, raising questions about long-term sustainability. If integrated into government or corporate infrastructure, DeepSeek AI could be exploited for surveillance by foreign adversaries, affecting nation's cybersecurity. Although being open-source, certain components of the model (e.g., training datasets and fine-tuned versions) might be controlled by external entities, leading to potential data leaks.
Additionally, being developed in China, DeepSeek follows strict content regulations. Topics such as Taiwan’s political status or the Tiananmen Square incident are restricted due to Chinese internet policies, which may affect its global adaptability.What’s Next for DeepSeek and AI?DeepSeek’s rise proves that bigger isn’t always better. With its cost-effective approach, rapid deployment, and self-reasoning abilities, it’s challenging industry giants and setting a new standard for AI development.
Whether you’re a developer, researcher, or AI enthusiast, DeepSeek is worth watching. Have you tried it yet? Let us know your thoughts in the comments!
We hope you found this insightful.Also, do not forget to like and comment.Until then,Keep exploring and May the Source Be With You!]]></content:encoded></item><item><title>Balaji Udayagiri</title><link>https://dev.to/balaji_udayagiri_aa6f571e/balaji-udayagiri-14o3</link><author>Balaji Udayagiri</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:08:07 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[I'm excited to share my  with you all! 🚀 with 4+ years of experience, I’ve worked on UI/UX, component libraries, AI-driven interfaces, and more.  🔹 What’s in my portfolio?⚡ Built with Next.js & Tailwind CSS🎨 Showcasing my best projects & UI work🚀 Optimized for performance & accessibility🛠️ Dark mode & interactive animationsWhat do you think?
Would love your feedback, suggestions, or just a quick "Hi"! 😊  🚀 If you’re a frontend developer, what’s the one thing you love most about building UI? Let’s chat in the comments! 👇  ]]></content:encoded></item><item><title>GNOME 48 Beta Released With HDR Bits, gdctl, Adwaita Fonts Default &amp; More</title><link>https://www.phoronix.com/news/GNOME-48-Beta-Released</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 16 Feb 2025 12:07:27 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[The GNOME 48 Beta release was officially announced this morning as the latest stepping stone toward the official GNOME 48 desktop release due out in mid-March...]]></content:encoded></item><item><title>Appointment Form</title><link>https://dev.to/preetha_vaishnavi_2b82358/appointment-form-1kdl</link><author>preetha vaishnavi</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:05:26 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Check out this Pen I made!]]></content:encoded></item><item><title>Building a Slack Clone with Next.js and TailwindCSS - Part Three</title><link>https://dev.to/tropicolx/building-a-slack-clone-with-nextjs-and-tailwindcss-part-three-4db6</link><author>Oluwabusayo Jacobs</author><category>devto</category><pubDate>Sun, 16 Feb 2025 12:03:48 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[In the previous part, we added real-time messaging, rich text formatting, reactions, and file uploads to our Slack clone using the Stream React Chat SDK.In this final part of our series, we’ll add video-calling capabilities to our Slack clone using the Stream React Video and Audio SDK. By the end of this part, users will be able to initiate and join video calls, similar to the "Huddle" feature in Slack.
  
  
  Creating a Call Using the Huddle Button
First, we need a way for users to start and stop video calls easily. Let's create a button for this purpose, which we'll call the .Go to the  directory, and create a  file with the following code:In the component above, we update the current state of the call, including creating a new call, updating the call details, joining the call, or leaving the call using the following functions:: This function creates a new call by setting the required data, including channel details and workspace members. If there's an existing call, it first leaves that call.: This function toggles the state between joining and leaving the call, depending on whether the user is already in an active call.We also use the  and  hooks to keep track of the current call state. The button updates its appearance and behavior based on whether a call is ongoing, available, or inactive.Next, let's integrate the  into the channel page.Navigate to /client/[workspaceId]/[channelId]/page.tsx and update it as follows:Here, we integrate the  component with the channel toolbar. We also wrap it with the  component to manage the call state.Implementing a Custom Hook for HuddlesWith the huddle button in place, let's move on to creating a custom hook for our huddle feature. This hook will help manage different aspects of a call, such as toggling the microphone, camera, and screen sharing. It will also track the current state of the call, like whether the user is joining, speaking, or sharing their screen.Create a new file in the  directory called  and add the following code:: The  hook uses several hooks from @stream-io/video-react-sdk to manage different aspects of a call. It tracks the current call state, such as the , whether the user is muted, if screen sharing is active, and if the user has permission to perform specific actions.Toggling Microphone, Camera, and Screen Share: The , , and  functions allow users to control their microphone, camera, and screen sharing during calls.: The  variable helps determine whether the spotlight layout should be used. This typically happens if one participant shares their screen or is pinned.: The  function allows the user to leave the call. If the user has the required permission, they can also end the call for all participants.Building and Showing a CallSo far, users can create and join calls, but now we want to add the UI for the calls themselves. In this section, we'll integrate the huddle UI components, allowing users to manage video calls within a workspace, similar to Slack's huddle feature.Creating the Call Control ButtonThe first component we need is a call control button. This button will toggle features during a call, like muting the microphone, turning the camera on or off, and more.Create a new  file in the  directory, and add the following code:The  component adjusts its styles based on whether it is  or not. The button changes its background color and hover behavior to indicate the active state, helping users visually understand the button's current state.Customizing the Participant ViewThe main component we’ll use in our video layouts is Stream’s  component. This component displays the participant’s video, plays their audio, shows their information, and provides action buttons for controls like pinning or muting.However, the  default UI doesn't match our design, so we'll override it by creating our own custom UI using the  prop.Create a new file in the  directory called  and add the following code:The  is divided into several components:: The  component shows details for each participant, such as their name and audio status, making it easy to identify who is currently speaking or pinned.Speech Indicator and Speech Ring: The  component gives a clear visual cue to users when a participant is speaking. We also included a speech ring effect highlighting the participant's video when speaking.: The DefaultScreenShareOverlay is used when a participant is sharing their screen, providing a visual indication to other participants.: The menu allows participants to perform actions such as pinning or muting themselves or another participant.With the main call controls and participant view in place, it's time to create the huddle interface. This UI will contain the video feed layout and call controls and ensure the interface responds dynamically to different situations, like toggling between the sidebar and modal views.Create a new file in the  directory called  and add the following code:In the code snippet above:: We use the  and  to arrange participants based on the context (e.g., sidebar vs. full screen).: We use the  component to toggle the microphone, camera, and screen sharing.: We use the  and  props to handle when the huddle is open in another window or embedded in the sidebar.Now that we've developed the core user interface for our video calls, it's time to integrate the functionality into a single cohesive component. The huddle component will be responsible for managing the different states of a video call, such as when a user is joining, leaving, or responding to an invitation.Create a new file in the  directory called  and add the following code:: The  from the  hook is used to determine the appropriate UI to display. For example, if the call is ringing and wasn't initiated by the current user (), an invitation message, and options to join or decline the call are shown.Joining and Declining a Call: The  and  functions handle the respective actions. The  function invokes the  method, while the  function invokes  with the option to reject.: Depending on the call state, the component renders different UI sections, including:The invitation view, when the call is  but not initiated by the user.The call UI when the user has  or is .The huddle modal component will give an expanded view of the video call interface. It provides a more immersive experience for users when compared to the sidebar view.Create a new file in the  directory called  and add the following code:The component accepts an  prop to control when to display the modal. The modal also uses fixed positioning and includes styles that provide a centered, full-screen overlay.With the  and  now created, we can add them to our app.Normally, we could place our  component in the . However, the  is a child component in our  file, and layout files persist across routes and maintain the same state.This feature would be unsuitable for our needs as we want the current call state to be able to reset and effects to re-run each time a user navigates between channels.So instead, we'll use a template file. Templates in Next.js are similar to layouts in that they wrap a child layout or page. However, unlike layouts, they create a new instance of their children each time the user navigates.This behavior makes templates perfect for our huddle feature, as it allows us to reset the state and re-synchronize effects seamlessly when the channel or call data changes.In the  directory, create a new  file with the following code:: This hook allows us to get the active call. We use it along with the  from our app context to determine which call to display.: We use the  hook to decide the currently active call, giving priority to matching calls from both the current call and channel call.: The  function from  is used to render the Huddle and HuddleModal components to specific parts of the DOM—the sidebar and body. This allows us to dynamically position the components and ensure they integrate smoothly with the UI layout.: The  wrapper is used to pass the active call to our Huddle components, allowing them to manage the video and audio streams effectively.Before wrapping things up, let's add some important styles to our  file to ensure our huddle interface looks just right:With this, our huddles are fully functional, allowing users to collaborate seamlessly during video calls!We've covered a lot in this three-part series, from setting up the foundation of our Slack clone with a database, authentication, and initial pages, to adding real-time messaging and video calling.]]></content:encoded></item><item><title>Hacking Go-TFE and Fetching All Workspaces in Terraform Enterprise: A Journey Through Pagination</title><link>https://dev.to/muhammetberdi_jepbarov/hacking-go-tfe-and-fetching-all-workspaces-in-terraform-enterprise-a-journey-through-pagination-4lel</link><author>Muhammetberdi Jepbarov</author><category>devto</category><pubDate>Sun, 16 Feb 2025 11:59:36 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Terraform Enterprise (TFE) is a powerful platform for organizations using Terraform at scale. It provides collaboration, governance, and self-service workflows for infrastructure automation. As organizations grow, managing infrastructure becomes increasingly complex, often requiring the ability to programmatically interact with TFE using its robust API.Recently, I found myself in a situation where I needed to fetch  for a given organization in TFE. Workspaces, as you may know, are the fundamental units in Terraform where runs occur. Each workspace holds the Terraform state file, which tracks infrastructure resources. For automation and reporting, I needed to pull in the full list of workspaces, but I quickly ran into a seemingly simple yet frustrating problem: .
  
  
  The Goal: Get All Workspaces
Our goal was clear — we wanted to retrieve every single workspace associated with a particular organization, without worrying about pagination limits. Whether for generating reports, validating configurations, or orchestrating CI/CD workflows, having a full view of all workspaces was crucial.The  library by HashiCorp provides an elegant way to interact with TFE’s API. The most straightforward way to list workspaces looks something like this:However, there was a catch.
  
  
  The Pain Point: Pagination Woes
When we ran this code, we noticed something odd — it only returned . After digging into the documentation and the source code of the  library, it became clear that the API defaults to a . Even when we explicitly set the page size to the maximum limit of 100, it still only gave us one page of results:The issue was evident: . This means that if your organization has more than 100 workspaces (which is not uncommon for larger teams), you have to make multiple requests to get all of them.But we didn’t want to be bound by pagination. We wanted all the workspaces in one go — a clean, consolidated list.
  
  
  The Solution: Handling Pagination Manually
To work around the pagination limit, the only solution was to  through the results until all workspaces were fetched. We crafted the following solution:
  
  
  Breaking Down the Solution
Let’s walk through the logic step by step:: We start with an empty slice to hold all workspaces and set the page number to 1.: Inside the  loop, we make requests using the , setting both the page number and the maximum page size.: After each request, we append the returned workspaces to our  slice.: If the number of workspaces in the current response is less than the page size (meaning we’ve reached the last page), we break out of the loop.: Finally, we return the full list of workspaces.Fetching all workspaces might seem like a trivial task at first glance, but it highlights a crucial aspect of working with APIs — understanding and handling pagination correctly.When dealing with APIs that support pagination:Always check default page sizes.Understand the max page size allowed.Implement proper loop termination to avoid infinite loops.Consider API rate limits when making multiple requests.In our case, the solution was not only about fetching data but about ensuring the stability and reliability of our automation pipelines.In the end, handling pagination in TFE’s API required us to step back, understand the underlying mechanics, and build a robust way to gather all the data we needed. The final solution is now part of our infrastructure tooling, allowing us to work seamlessly with Terraform Enterprise’s workspaces.So next time you hit a wall with an API and pagination, remember — it’s not a bug; it’s a feature. Master it, and your automation game will only grow stronger.]]></content:encoded></item><item><title>Building a Slack Clone with Next.js and TailwindCSS - Part Two</title><link>https://dev.to/tropicolx/building-a-slack-clone-with-nextjs-and-tailwindcss-part-two-11cl</link><author>Oluwabusayo Jacobs</author><category>devto</category><pubDate>Sun, 16 Feb 2025 11:58:05 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[In part one of this series, we built the basics of our Slack clone by setting up user authentication, workspace creation, and designing a responsive layout for our workspace hub.In this second part, we'll bring our Slack clone to life by adding real-time messaging with Steam React Chat SDK. We'll add features like rich text, file sharing, images, and emoji reactions.By the end of this part, users will be able to communicate with each other, making our app a functional chat platform.Adding More Channels To Your WorkspaceCurrently, users can only have one channel in a workspace, which is the channel added during the workspace creation process. Before adding the messaging feature to our app, let's enable users to create additional channels within a workspace.To add more channels, we'll create a pop-up modal that appears when users click an '' button in the sidebar.Creating the Channel API RouteFirst, we need an API route to handle channel creation. Create a  directory inside the existing /api/workspaces/[workspaceId] directory, then add a  file with the following code:Authentication and Validation: We check if the user is authenticated and if they belong to the workspace.: Only users with an '' role can create new channels.: We ensure that no other channel in the workspace has the same name.: If all checks pass, the channel is created and saved in the database.Creating the Add Channel ModalNext, let's create a modal for adding new channels. In the  directory, create a file called  with the following code:Let’s break down some of the component's key features:We use the  regular expression to ensure that each channel name is unique within the workspace by comparing it against existing channel names.: We use the  state to show a loading spinner () while the channel creation is ongoing.Navigation to New Channel: After successfully creating a channel, we redirect users to the new channel page. The modal is also closed by resetting the input fields and calling the  function.Adding the 'Add Channel' Button to the SidebarNext, let's add the  to the  file:In , we add a  hook to manage the modal's open state, and an ““ button that shows the modal if the current user is the workspace owner. This button is placed below the channel list for easy access.With this setup, users can now create new channels to help organize conversations within the workspace.Building the Chat InterfaceNow that users can create multiple channels, let's start working on our main chat interface. First, we'll be building the loading state for our chat UI, then the main chat interface, and finally, we'll customize different aspects of the chat, like the message input, date separator, and more.Creating a Channel Loading IndicatorTo let users know the channel chat is loading, we will create a loading indicator that provides a visual cue while fetching data. Stream already provides a default loading UI, but we want a custom one to match our application's design.Navigate to the  directory and create a new file called  with the following code:The component shows a skeleton screen, which gives users a visual hint that content is loading.Next, let's build the main chat interface so users can send messages and see their conversation history.Go to the  folder, create a new file named , and add the following code:The  component accepts the  data as a prop and uses the  component from  to manage chat sessions. Here are its key components:: This displays the conversation history within the current channel.: This component allows users to type and send messages. The  is rendered using React Portals, which helps position the input field in a different part of the DOM to match the layout we want for our Slack clone.: The  component also accepts our custom  component as a prop to override the default loading UI.Integrating the Channel Chat ComponentNext, we need to integrate the  component into our channel page. Go to the /client/[workspaceId]/[channelId]/page.tsx file and update it as follows:We check if the channel is still loading using the  state. If it is, we display the  component.Once the channel data is loaded, we display the  component, which provides the main chat interface for users to interact with.Finally, let’s add some styling to customize the look of our chat UI. Navigate to the  directory and update the  file with the following code:And with that, users can now send messages. However, the current UI still looks far from what we want, so in the following sections, we'll add custom components to enhance it.Adding a Custom Date SeparatorTo help users follow conversations more easily, we'll add custom date separators that indicate when messages are from different days.Go to the  folder, create a new file called , and add the following code:This component shows a separator to help users see when messages are from different days. Using the  function, we provide labels like "", "", or a formatted date with an ordinal suffix.Next, let’s add the  to the  component to make conversations more readable:Creating a Custom Emoji PickerIn this section, we'll create a custom emoji picker for our Slack clone using the  library. While Stream already provides an  using the same library, we want to build a more flexible version that better suits our chat components and integrates seamlessly into our clone.Firstly, we need to install the necessary packages for the emoji picker. These include:: This library provides the emoji picker component.: This package is specifically for using the emoji picker in React apps.: This contains all the data needed for the emojis.Run the following command in your terminal to install the packages:npm emoji-mart @emoji-mart/react @emoji-mart/data
Next, go to your  folder, create a new file called , and add the following code:: We use  to display the emoji picker and  to get all the emoji data. We also use  from  to handle the positioning of our emoji picker.: The component accepts several props, such as  for the button that triggers the picker,  to handle emoji selection, and optional styling classes for customization.: The  hook positions the emoji picker correctly relative to the button.: We use the  state to show or hide the picker. We also handle clicks outside the picker to close it.Implementing a Custom Message InputIn this section, we'll implement a custom message input for our Slack clone. This new input will allow users to easily add rich formatting, such as bold or italics, and even upload files and add emojis, creating a more dynamic chatting experience.To achieve this, we'll use , which is a robust framework for building rich text editors. We'll also use  to define keyboard shortcuts for formatting text.First, let's install the necessary libraries. Open your terminal and run the following commands:Next, we'll create our custom input component, which will act as the primary input container for our chat.Navigate to the  directory, create a new file named , and add the following code:There’s a lot going on here, so let’s break it down:: We use Slate to create a rich text editor that supports multiple formatting options, like bold, italics, underline, and strikethrough.: The  and  functions convert the editor's content to markdown format, allowing us to maintain rich formatting in text.: Functions like , , and  help manage file uploads, previews, and removal, making the chat input more versatile.: The buttons for formatting text (bold, italic, etc.) call the  function to add or remove specific text styles.: The  library binds hotkeys like  for bold,  for italics, and so on, making the editor more user-friendly.: The  function is responsible for sending the message by serializing the editor's content and then using Stream's  function.Next, let's integrate the  with our channel chat interface.Open the  file and update it with the following code:In the code above, we import the  component and pass it as the  prop for the  component to override the default UI.Next, let’s add some styling to support the rich text formatting features, ensuring elements like  blocks and other inline styles look polished.Open your  file, and include the following styles:While the chat interface is now visually improved with a customized message input, the message UI still needs work to match the look of the rest of the app.Creating a Custom Message UIIn this section, we'll create a custom message UI to match the look and feel of our Slack clone. This custom message component will display user messages in a clean interface with the ability to send reactions and view attachments.To get started, navigate to the  directory, create a new file named , and add the following code:In the  component: We use the  hook to get information about the current message displayed, such as the message content and its author. Using , we calculate the number of reactions and whether the user has reacted to the message or not. Users can add or remove reactions by clicking on the reaction buttons. The message can contain attachments such as images or files. We provide download and preview options for attachments. We added a button to send reactions using our custom .Now, let's integrate our new  component into our . Navigate to components/ChannelChat.tsx and update it to use :In , we update the  to use our custom  component. This change allows our newly defined custom message UI to display each message.And that’s it! We now have a fully customized chat experience similar to Slack.In this part, we made our Slack clone more interactive by implementing core messaging features using Stream React Chat SDK. We added custom components to further style and enhance the user interface with features like rich text formatting, emojis, and file sharing.In this series's next and final part, we will integrate a video calling feature using Stream React Video and Audio SDK. This feature will allow users to transition between text and video conversations, making the app more versatile and interactive.]]></content:encoded></item><item><title>🐞Debugging Life: The Software Engineering Lessons You Can’t Ignore</title><link>https://dev.to/hassanshahzadaheer/debugging-life-the-software-engineering-lessons-you-cant-ignore-4n79</link><author>Hassan Shahzad Aheer</author><category>devto</category><pubDate>Sun, 16 Feb 2025 11:58:02 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[In software engineering, every line of code has a purpose. A well-structured program runs smoothly, while a messy one leads to endless bugs and frustration. Life works the same way. The mistakes we make, the shortcuts we take, and the mindset we carry shape the outcomes we get. Here are some key lessons from software engineering that apply directly to life. The Blueprint Matters – Planning Before Execution
In programming, we don’t just start coding randomly. We . We define the , break the problem into smaller parts, and structure the code accordingly. If we skip this, we end up with messy code that’s hard to fix later.If we go through life without a clear , we act randomly and waste energy. Imagine starting a new habit, a career, or even a relationship without knowing where it leads. Without direction, you’re just throwing code into an empty file, hoping it runs.🪴  Before jumping into anything, ask yourself, “What is my goal? Why am I doing this?” Quick Fixes Create Bigger Problems Later
Sometimes, developers rush to fix a bug without thinking about the . The code works for now, but it breaks something else in the future. This is called , and eventually, it slows everything down.Many people look for quick fixes—crash diets instead of healthy habits, avoiding hard conversations instead of fixing relationships, or chasing shortcuts instead of real skills. But these  create .🪴  Don’t patch problems—. Invest time in doing things right the first time. Overengineering – The Trap of Perfectionism
A common mistake in coding is —making things so complicated that it becomes impossible to maintain. Sometimes, a  is better than an overly complex one.Overthinking and overplanning often lead to . Instead of making a simple start, we keep adding unnecessary steps, waiting for perfection, and never actually doing anything.🪴  Don’t wait for perfect conditions— and improve along the way. Stay Focused – Avoiding Distractions
In programming, every function must have a clear . If it’s unclear, the program doesn’t know what to do with it, leading to .If your values, boundaries, and priorities are undefined, you’ll constantly feel lost. People will , and you’ll struggle to make decisions.🪴  Define what matters to you.  Know when to say  and when to say . Debugging is Essential—But So is Learning from Mistakes
Every coder knows that debugging is part of the job. We don’t cry over errors—we fix them, learn, and improve.Mistakes are unavoidable. The problem isn’t —it’s . If we repeat the same mistakes without reflection, we stay stuck.🪴  See mistakes as . Ask, “What went wrong? What can I do better next time?” Distractions Are Like Memory Leaks
In software, memory leaks happen when the program keeps holding onto unnecessary data, .Distractions—social media, negativity, unnecessary worries—. You feel exhausted, but nothing productive happens.🪴  Free up space in your mind. Focus on what truly matters. Refactoring Makes Everything Better
Refactoring is about —making it simpler, more efficient, and easier to maintain.Sometimes, we hold onto old habits, outdated beliefs, or toxic relationships. Just like messy code, they slow us down.🪴  Regularly . Let go of things that no longer serve you and .
  
  
  Final Thoughts: Code Your Life Wisely
Life and software engineering share the same rule: Structure leads to stability. Whether you’re writing code or shaping your future, small, intentional decisions lead to big results.💬 Which lesson resonated with you the most? Share your thoughts in the comments! 🔥]]></content:encoded></item><item><title>🚀 Introducing My Personal Tech Blog: CodePanda.online 📝</title><link>https://dev.to/sheraz4194/introducing-my-personal-tech-blog-codepandaonline-5pk</link><author>Sheraz Manzoor</author><category>devto</category><pubDate>Sun, 16 Feb 2025 11:47:20 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[I’m super excited to share that I’ve launched my personal blog website — CodePanda.online! It’s a space where I’ll be sharing my knowledge, experiences, and helpful tips for web developers and tech enthusiasts.
  
  
  💻 What to Expect on CodePanda:
✅ Hands-on tutorials for JavaScript, TypeScript, React, Next.js, and more.
✅ Practical Tips & Tricks – Quick solutions to common coding challenges.
✅ Insights from real-world projects I’ve worked on.
✅ In-Depth Tutorials – Step-by-step guides on JavaScript, TypeScript, React, Next.js, and more.
✅ Snippets and solutions you can use in your own apps.I created CodePanda to document my journey as a developer and help others by sharing what I learn along the way. Whether you're just starting out or already deep into your coding career, I hope my posts make your development life a little easier.I’d love for you to stop by, explore, and let me know what topics you’d like me to cover next! 🚀🔥]]></content:encoded></item><item><title>Intel Killer E5000 Ethernet Support For Linux 6.15</title><link>https://www.phoronix.com/news/Intel-Killer-E5000-Linux-6.15</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 16 Feb 2025 11:45:00 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[The upcoming Linux 6.15 kernel cycle will be adding support for Intel Killer E5000 Ethernet...]]></content:encoded></item><item><title>11 Must Read Software Design and Architecture Books for Developers</title><link>https://dev.to/somadevtoo/10-must-read-software-design-and-architecture-books-for-developers-347m</link><author>Soma</author><category>devto</category><pubDate>Sun, 16 Feb 2025 11:38:06 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[Disclosure: This post includes affiliate links; I may receive compensation if you purchase products or services from the different links provided in this article.Hello friends, System design and Software design are two important topic for any tech interviews and also two important skills for Software developers.Without knowing how to design System you cannot create new software and it will also be difficult to learn and understand existing software and system.That's why big technical companies like  pays special attention to System design skill and test candidates thoroughly.Whether you are a beginner or experienced developer, you can read these books as you will definitely find valuable stuff. I have read them and even though I have been doing Software development for more than 15 years I have learned a lot.System design** is a complex process and you need to know a lot of stuff to actually design a system which can withstand test of time on production.Software architecture is another field where you are expected to learn a lot of things. It's simply impossible to become a software architect by reading few books but if you have experience then and hunger to learn then these books can be gold mine.These books allows you to learn from other people's experience. You can read these books to find what challenges they face when they design a real world system like Spotify, Google, or Amazon and how they overcome. Each story is a journey in itself and you will learn a thing or two by reading and then relating with your own experience. I love to read books and they are my primary source of learning, along with online courses nowadays. In this article, you will find few books which I have gone through in recent time to improve my knowledge about System Design and Software Architecture.If you love these books, give high five and if you got any other excellent book to share, feel free to drop a comment. P.S. Keep reading until the end. I have a free bonus for you.
  
  
  11 Best System Architecture and System Design Books for Developers
Here are my favorite 10 books on system design, software architecture, and software development. These are really good books and it's not just I am recommending it, you go reddit or hacker news, everywhere these books are recommend. They are also recommended to me by many people in past. I love head first books, they are simplest books you can read on programming and software development so when the release a book on Software Architecture, I immediately ordered a copy.It teaches you key principles to design software in a fun and engaging way, the Head First way. You will appreciate their simple to do examples and exercises in this complex topic.While I loved this book, I know many folks who really hate anything Head First, for them its like a comic book and not worth their time. If you are one of them I am sorry but this book definitely is a must, valuable insights, advices, and examples different topics that you need to consider when designing and architecting applications.If you are a senior developer and want to become tech lead or software architect, you should definitely read this book. This book was recommended to me by my tech lead but when I started reading this book, I literally fall asleep, it was too complex for me to understand, but I didn't give up and slowly I found that this is one heck of book for anyone who want to work on real systems. In this fantastic book on system design, Martin Kleppmann will help you understand the pros and cons of all the different technologies that are used for storing and processing data. It is a book that is written in a lucid style and presents a very broad overview of data storage systems.You will get a very good grasp of fundamental concepts, algorithms, as well as practical applications of various technologies. This is also one of the most popular book when it comes to learn Software design and System Design and I highly recommend this book to all kind of software developers . The book is also good for beginners and experienced, developers and software architects and anyone who wants to be better at software design in 2024. This book was recommended to me by one of my colleague who cracked Google interview, when I asked how did he prepared, he shared few books and courses apart from grinding leetcode and this was one of them.As the title suggests, this is the perfect book for everyone who is preparing for a system interview. Trust me, this book is the finest on the internet right now.  This book is created by Alex Xu who has gone through the same process. You will get access to a number of drawings and diagrams that will assist you in gaining an understanding of the real system. You will be able to understand what the recruiters are looking for in your answers to questions.Alex also have a companion , where you will not only find all the content of this book and the second part of System Design Interview Book
but also new content, deep dive into popular system questions like how to design YouTube and WhatsApp as well as  proven System design framework to solve Software design problem.In short, if you read this book, you will be able to confidently answer questions on your next system design interview.This is also one of the most recommend System design interview books on Reddit, Quora, Hacker News, Twitter, and other online platforms and its obvious from the number of reviews this book have on Amazon. If you are a senior developer who want to expand your knowledge about Software Engineering by learning from those who have done that in companies like Google then this book is for you.This book is an interesting read on intricacies of developing and maintaining a sustainable and healthy codebase, emphasizing the distinction between programming and software engineering.Drawing on their experiences at Google, the authors provide a detailed look at the practices employed by some of the world's leading software engineers to navigate the challenges of evolving codebases in response to changing requirements and demands.This software design book also delves into Google's unique engineering culture, processes, and tools, shedding light on how these elements contribute to the effectiveness of their engineering organization.Throughout the book, three fundamental principles are highlighted: the impact of time on software sustainability, the influence of scale on software practices within an organization, and the trade-offs engineers must consider when making design and development decisions.With a focus on practical insights and real-world examples, this book serves as a valuable resource for software engineers seeking to enhance their understanding of software engineering principles and practices.  While this book book is not exclusively focused on System design it has many valuable lessons on trade-offs developers must consider when making design and development decisions, which is quite important for senior developers and software architects.If you are looking a Software Architecture book to start with then this book is for you. Along with Head First Software Architecture this is best book I have read for senior developers who want to become software architect.System design, Software Design, and Software architecture are closely related. When you read this book, you will learn everything there is to know about Software structure and Design.  You will also be able to make your code smoother and integrate agile methodology into your solutions. This book is created by Robert C. Martin, fondly known as Uncle Bob which is also author of famous  and . This is the third in the series and many people read all three to become a better software developer. This book focuses on the different principles related to system analysis and design as well as the different challenges that system designers face while developing a solution in the real world. In addition, you will learn how to run unit tests and use a test-driven strategy for improving the efficiency of your systems.  According to industry experts, this is one of the most important systems design textbooks that is available on the market today. That is because this book will make you realize what has changed in the industry as well as why a change was necessary in the first place. Also, this book has sections that are dedicated to object-oriented coding and agile methodology, which are two of the most used methodologies these days. You will also learn how systems function, as well as about cloud computing and mobile applications. The 12th edition of System Analysis and Design by Scott Tilley is the latest book in this series and you should read that to get the update knowledge.If you are preparing for System design interview then you can also checkout  by Sandeep Kaul (Tech Lead @ Facebook) for better preparation.This is another interesting book that explains what patterns are important as well as how to apply these patterns to your designs. It focuses on object-oriented principles that are the basis of these patterns.Using this book, you will be able to vastly improve your knowledge of software development. You will get to know about important design principles that can be useful for solving software design principles. The 2nd edition of this book is now available and you should read that to learn design pattern with Java 8 and beyond. Most importantly how to use Lambdas and Stream to implement classic design pattern sin Java. And, if you need an online course to go along this book,  course by Dmitri Nestruk on Udemy is best as it shows the modern implementation of classic design patterns in Java. This is another book you can read to prepare for FAANG System Design interview. This book not just cover essential System design concepts which every software architect should know but also cover many popular System design questions and coding problems. Created by ,  a Google Software Engineer,  this is also one of the best selling book on System design on Amazon.  The best thing about this book is that it walk you through key components which are used to build any system like below:This book also includes real interview questions based on hundreds of interviews conducted at big tech companies like Google and Meta, and their detailed solutions. I highly recommend this book to anyone preparing for technical interviews.You can also combine this with the  or  System design course for better preparation. This is another highly recommended book on Software architecture. Written by Mark Richards and Neal Ford stands as an invaluable guide for developers aspiring to transition into the role of a software architect, a position consistently ranked among the top 10 best jobs in salary surveys globally. This first-of-its-kind book offers a comprehensive overview of software architecture, covering a wide array of topics such as architectural characteristics, patterns, component determination, diagramming, evolutionary architecture, and more. Written by hands-on practitioners with extensive experience in teaching software architecture classes, Mark Richards and Neal Ford focus on universal architecture principles applicable across various technology stacks. The book delves into critical aspects like architecture patterns, component identification, soft skills, modern engineering practices, and treating architecture as an engineering discipline. With a modern perspective that incorporates innovations from the past decade, this book equips both aspiring and existing architects with the necessary tools and insights to navigate the complexities of software architecture, making it an indispensable resource in the field.I highly recommend this book to any senior developer who also want to become a software architect. This is a great book that will give you a very good understanding of system analysis and design, as the title suggests. You will get access to extensive descriptions, as well as practical projects that reflect real-life situations. The 6th Edition of this book is also made up of a number of case studies and many examples along with deep explanations for all the case studies and examples. This book will definitely help you in achieving your goals as a design student. You will get a solid grasp of all the principles related to system analysis and design. This is another Software design book that will teach you all about the skills, ideas, and techniques that are connected with system analysis and design. Trust me when I say that this is the perfect and most comprehensive system design book for you. This System Design and Analysis book is written by Joshep Valacich and Joey George and also made up of a section on agile methods, which will ensure that this is a perfect student learning system for system designers. The writing style is very simple but informative, which means that it will be accessible to everyone, including those whose mother tongue is not English.  There are multiple edition of these book to make sure you choose the latest edition, the 9th Edition and if you need a Udemy course to go with this book I recommend  course on Udemy. I have found that by reading books and watching course is the best way to learn System design. That's all about the best Software architecture and System Design Books. You can read these books to learn essential Software Architecture design concepts and how to architect a system. If you are learning software architecture for System design interview then The System Design Interview Insider Guide book by Alex Xu also cover common Software design problems and shows you how to solve them which can be really beneficial for interviews. Thank you and all the best for your System Design interview and learning journey!!]]></content:encoded></item><item><title>Btrfs-Progs 6.13 Released With &quot;mkfs.btrfs --compress&quot; Support</title><link>https://www.phoronix.com/news/Btrfs-Progs-6.13</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 16 Feb 2025 11:38:03 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Btrfs-Progs 6.13 was released this weekend as the newest routine update to the user-space utilities for the Btrfs file-system...]]></content:encoded></item><item><title>[Boost]</title><link>https://dev.to/asadbukhari/-2mmi</link><author>Asad Bukhari</author><category>devto</category><pubDate>Sun, 16 Feb 2025 11:37:01 +0000</pubDate><source url="https://dev.to/">Dev.to</source><content:encoded><![CDATA[The Future of Login Systems: Biometric Authentication]]></content:encoded></item><item><title>GaussianBlur in PyTorch (3)</title><link>https://dev.to/hyperkai/gaussianblur-in-pytorch-3-56do</link><author>Super Kai (Kazuya Ito)</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 11:20:32 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>134k Lines Of Code Posted As Latest Effort For COBOL Support Within GCC</title><link>https://www.phoronix.com/news/134k-Lines-v2-COBOL-For-GCC</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 16 Feb 2025 11:19:15 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[While it's an old language, in recent months there's been a renewed effort over a COBOL language front-end for the GCC compiler. There's been out-of-tree COBOL support for GCC that is working to get into the mainline GNU Compiler Collection codebase. This weekend saw the latest iteration of those patches amounting to 134k lines of new code...]]></content:encoded></item><item><title>Getting Started with AWS Bedrock</title><link>https://dev.to/alexypulivelil/getting-started-with-aws-bedrock-29n0</link><author>Alexy Pulivelil</author><category>ai</category><pubDate>Sun, 16 Feb 2025 11:06:49 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Developers can create and scale generative AI applications with Amazon Bedrock, a fully managed service, by utilising foundation models from AWS and other suppliers. In this guide, I’ll walk you through getting started with AWS Bedrock and invoking the Amazon Titan Text Lite v1 model for text generation.
Before you begin, ensure that you have the following:AWS Account with access to Amazon Bedrock(For testing will be using AmazonBedrockFullAccess)AWS CLI installed and configured with appropriate permissionsBoto3 (AWS SDK for Python) installed on your machineYou can install Boto3 using:Step 1: Set Up AWS CredentialsIf you haven’t already configured your AWS credentials, run:Enter your AWS Access Key ID, Secret Key, and select your preferred region where Amazon Bedrock is available (e.g., us-east-1).Step 2: Initialize the Bedrock Client
To interact with Amazon Bedrock, we need to initialise the AWS Bedrock runtime client using Boto3:# Initialize Bedrock client
bedrock = boto3.client("bedrock-runtime", region_name="us-east-1")
Step 3: Invoke Amazon Titan Text Lite v
Let’s create a simple script to invoke Amazon Titan Text Lite v1 for generating a text response.# Define the input text
question = "What is the capital of India?"

# Prepare the payload
payload = {
    "inputText": question,
    "textGenerationConfig": {
        "maxTokenCount": 100,
        "temperature": 0.5,
        "topP": 0.9
    }
}

# Invoke Titan Text Lite v1
response = bedrock.invoke_model(
    modelId="amazon.titan-text-lite-v1",
    contentType="application/json",
    accept="application/json",
    body=json.dumps(payload)
)

# Parse response
result = json.loads(response["body"].read().decode("utf-8"))

# Extract and print the output text
if "results" in result and isinstance(result["results"], list):
    print("Answer:", result["results"][0]["outputText"].strip())
else:
    print("Unexpected response format:", result)
Step 4: Running the ScriptSave the script as invoke_bedrock.py and run it using:Expected Output:Answer: New Delhi is the capital of India. It is situated in the countrys federal district, which is known as the National Capital Territory of Delhi (NCT), and is located in the Indian subcontinent.Step 5: Fine-tuning Model ParametersAmazon Titan models allow temperature and topP tuning for response variation:temperature: Controls randomness (Lower = More deterministic, Higher = More creative)topP: Controls sampling probability (Higher = More diverse responses)
Adjust these values in the textGenerationConfig section for different results.Conclusion
You have successfully invoked the Amazon Titan Text Lite v1 model using AWS Bedrock! You can now integrate this into your applications for chatbots, summarization, and content generation.]]></content:encoded></item><item><title>Why Go’s Functional Programming is the Ultimate Coding Style</title><link>https://dev.to/leapcell/why-gos-functional-programming-is-the-ultimate-coding-style-53ee</link><author>Leapcell</author><category>dev</category><category>go</category><pubDate>Sun, 16 Feb 2025 11:01:24 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[When you hear "functional programming," Go usually isn't the first language that comes to mind. You might think of Haskell, with its pure functions and monads (don't panic, we'll explain that in detail later), or JavaScript, which loves to showcase its features with higher - order functions and callbacks. But in fact, you can also do functional programming in Go, and the process is far from dull.First of all, let's talk about higher - order functions. Higher - order functions can work well with other functions, either taking them as parameters or returning them as values. In the world of Go, implementing higher - order functions is not only possible but also quite ingenious.You see, in this example, the  function takes an integer slice and a judgment function , and returns the elements in the slice that meet the judgment conditions. Doesn't it seem a bit like a faster JavaScript?Next up is currying. It is the process of breaking down a function that takes multiple arguments into a series of functions, each taking a single argument. Currying is actually not as complicated as it might seem.In this example, the  function takes an integer  and returns a new function. This new function takes another integer  and returns the result of . Simple, straightforward, and gets the job done without any frills.One of the characteristics of functional programming is immutability. Once something is constructed, it doesn't change. Instead, if you need something different, you build a new one. This might sound wasteful at first, but in fact, it keeps the code clean and reduces side effects.In this example, instead of directly modifying the original , we created a new  and modified it.Pure functions are like tidy friends. They don't touch or modify anything outside their scope. What you pass in is what you use, and what they return is their only effect.In this example, the  function only depends on the passed - in parameter  and doesn't affect any external variables.In the simplest terms, functors are anything that can map a function. Think of the humble array, applying a function to each item and getting a new array. In Go, there is no built - in general  function, but we can build one ourselves.Here, we defined a  function that takes an integer slice and a function and returns a new slice, where each element is the result of processing the original slice element by the function.Now, let's talk about endofunctors. It's just a fancy way of saying a functor that maps a type to the same type. Simply put, starting from a Go slice, you end up with a Go slice of the same type. It's not rocket science, just a matter of type consistency.Taking the previous  as an example, it's a kind of endofunctor in disguise. It takes  and returns  without type conversion.Imagine a party where everyone has to bring a friend. Monoids are like that, but for types. They need two things: an operation that combines two types and a special value, which is like the most likable friend - it gets along with everyone but doesn't change anything about them.In Go, you can see this with slices or numbers. Let's take numbers as an example because they're easier to work with:Here, 0 is our hero, the identity element, which keeps the numbers unchanged."When someone says, 'A monad is a monoid in the category of endofunctors,' they're basically showing off their computer - science vocabulary." To explain in detail: A monad is a programming construct that deals with types and functions in a super - special way - like some people are picky about how their coffee is brewed.In the simplest terms, a monoid is about combining things together using a special rule, which includes a useless element or identity element. Now, add endofunctors, which are like ordinary old functions but stick to transforming things within their own little universe (category). Put it all together, and you'll see that a monad can be seen as a way to chain functions together in a sequence, but in a super - self - contained way while also respecting the original structure of the data. It's like saying, "We're going on a road trip, but we can only take the scenic backroads, and we'll end up back where we started."Monads are all - rounders. They can not only handle values with context (such as errors or lists) but also chain operations together by passing the context. In Go, it might be a bit difficult to mimic this, but let's take a look at error handling, which is a practical use of monads.This makeshift monad can help us handle computations that might go wrong without causing panics and chaos in the code.Functional programming in Go might not be the poster child of the functional paradigm, but it's entirely feasible and can even be fun. Who would have thought, right? Now, you should understand that Go can achieve functional programming just like other languages. With a little effort, you can write clean, efficient, and robust code. Finally, I'd like to recommend a platform that's perfect for deploying Golang code: 
  
  
  1. Multi - Language Support
Develop with JavaScript, Python, Go, or Rust.

  
  
  2. Deploy unlimited projects for free
pay only for usage — no requests, no charges.
  
  
  3. Unbeatable Cost Efficiency
Pay - as - you - go with no idle charges.
Example: $25 supports 6.94M requests at a 60ms average response time.

  
  
  4. Streamlined Developer Experience
Intuitive UI for effortless setup.
Fully automated CI/CD pipelines and GitOps integration.
Real - time metrics and logging for actionable insights.

  
  
  5. Effortless Scalability and High Performance
Auto - scaling to handle high concurrency with ease.
Zero operational overhead — just focus on building.
]]></content:encoded></item><item><title>🚀 New eBook: The Developer’s Guide to UX Design Thinking – Future-Proof Your Career</title><link>https://dev.to/ricky_creates/new-ebook-the-developers-guide-to-ux-design-thinking-future-proof-your-career-3m6k</link><author>Ricky Synnot</author><category>ai</category><pubDate>Sun, 16 Feb 2025 11:00:21 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[
  
  
  How Developers Can Stay Ahead in an AI-Driven World
Most developers think writing great code is enough. It’s not.AI is automating more of our work every day. The developers who thrive in the next decade won’t be the ones who can ship the fastest—they’ll be the ones who understand what to build, why it matters, and how to create great user experiences.This is exactly why I wrote The Developer’s Guide to UX Design Thinking—a practical book that helps developers go beyond code and become  team members.Here’s a core concept from the book:
  
  
  The Developer’s Career Risk Pyramid
Most developers sit at one of three levels:🔴 At Risk – Developers who only write code (AI is automating this fast)
🟠 Safe for Now – Developers who solve problems, not just execute tasks
🟢 Future-Proofed – Developers who understand UX, product thinking, and collaborationThe higher you go, the safer your career. If you want to be more than a human compiler, you need to learn how to work with designers, influence product decisions, and create user-friendly solutions.This isn’t a design book for designers—it’s a practical guide to UX for developers who want to build better products and advance their careers.
  
  
  📖 Part 1: Foundations of UX Design Thinking
Why UX matters for developersThe rise of AI & why UX is irreplaceableUnderstanding the designer’s toolkit
  
  
  ⚡ Part 2: Applying UX in Development
Building empathy for usersPrototyping & collaborating with designersDesigning for accessibility & scalability
  
  
  🚀 Part 3: Enhancing Collaboration & Future-Proofing Your Career
Bridging the developer-designer gapHow to influence design decisions as a developerThe evolving role of devs in product teams
  
  
  🛠 Part 4: Tools, Case Studies & Advanced Topics
Real-world case studies from top tech companiesEssential UX & dev tools you should be usingThe future of UX in an AI-driven worldQuick-reference frameworks & checklists for daily useTo celebrate the launch, the book is available for just $5. No fluff—just real strategies, examples, and frameworks you can use immediately.Would love to hear from the dev.to community—how often do you get involved in UX decisions? Or is it always just “build this” with no context? Drop your thoughts below!]]></content:encoded></item><item><title>Deepseek-R1: El Modelo Revolucionario que Eleva los Estándares de los LLM de Código Abierto</title><link>https://dev.to/angel_rojas_6904bae237a0d/deepseek-r1-el-modelo-revolucionario-que-eleva-los-estandares-de-los-llm-de-codigo-abierto-42cc</link><author>Angel Rojas</author><category>ai</category><pubDate>Sun, 16 Feb 2025 10:38:07 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Deepseek-R1 es el modelo insignia desarrollado por Deepseek, una empresa china emergente. Con innovaciones clave como la combinación de aprendizaje por refuerzo y ajuste fino supervisado, así como la técnica Mixture-of-Experts (MoE), Deepseek-R1 redefine el panorama de los LLM de código abierto. Su capacidad para manejar contextos extensos y su arquitectura eficiente lo posicionan como un referente para desarrolladores y empresas.]]></content:encoded></item><item><title>Why Choose an Career in Ethical Hacking?</title><link>https://dev.to/ankit_cyber/why-choose-an-career-in-ethical-hacking-1dlf</link><author>ankit_Cyber</author><category>ai</category><pubDate>Sun, 16 Feb 2025 10:37:46 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Pursue ethical hacking for a dynamic career where you protect organizations from cyber threats, with high demand, competitive salaries, and continuous learning with endless growth potential.]]></content:encoded></item><item><title>Deepseek-R1: El Modelo Revolucionario que Eleva los Estándares de los LLM de Código Abierto</title><link>https://dev.to/angel_rojas_6904bae237a0d/deepseek-r1-el-modelo-revolucionario-que-eleva-los-estandares-de-los-llm-de-codigo-abierto-4lne</link><author>Angel Rojas</author><category>ai</category><pubDate>Sun, 16 Feb 2025 10:21:04 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[
La revolución de los LLM de código abierto comenzó con proyectos pioneros como Alpaca, pero ahora, Deepseek-R1 llega para llevar estos modelos a un nivel superior, destacándose por su rendimiento, eficiencia y escalabilidad. 😎¿Qué es Deepseek-R1? 🤔
Deepseek-R1 es el modelo insignia desarrollado por Deepseek, una empresa china de inteligencia artificial fundada en 2023 por Liang Wenfeng. Este modelo de lenguaje de código abierto sobresale por su capacidad para procesar contextos extensos, resolver problemas complejos y ofrecer respuestas precisas en diversas tareas, posicionándose como una evolución significativa en el ecosistema de los LLM.Mini Presentación: Origen y Filosofía 🌏
Origen: Nacida en el vibrante entorno tecnológico de China, Deepseek surgió en 2023 en medio de una explosión de innovación en inteligencia artificial.Filosofía: Inspirándose en proyectos pioneros como Alpaca, Deepseek apuesta por la transparencia y la colaboración a través del código abierto. Su misión es democratizar el acceso a tecnologías avanzadas, permitiendo que desarrolladores de todo el mundo puedan utilizar, modificar e integrar sus modelos en una amplia variedad de proyectos.Desarrollo y Evolución: De Alpaca a Deepseek-R1 🔄
Deepseek-R1 representa la respuesta evolutiva a los primeros esfuerzos de la comunidad. Entre sus principales innovaciones destacan:Métodos de Entrenamiento Híbridos: Combina técnicas de aprendizaje por refuerzo (RL) y ajuste fino supervisado (SFT), aprovechando enormes volúmenes de datos para adaptarse a múltiples tareas.
Innovación Arquitectónica: Utiliza la técnica Mixture-of-Experts (MoE), que activa solo una parte de sus parámetros en cada consulta, optimizando el uso de recursos sin sacrificar la capacidad del modelo.
Capacidad de Contexto Extendido: Con la capacidad de manejar hasta 128,000 tokens en una sola entrada, Deepseek-R1 supera las limitaciones de modelos anteriores, permitiendo un análisis profundo y respuestas complejas.
Lista de Modelos y Explicación de Cada Uno 📚
Deepseek ofrece no solo su modelo principal, sino también varias versiones destiladas que se adaptan a diferentes necesidades y entornos:Deepseek-R1 (Modelo Principal): Con 671 mil millones de parámetros, este modelo ofrece un rendimiento excepcional para aplicaciones de alto rendimiento en investigación, empresas y desarrollos que requieren procesamiento intensivo.Deepseek-R1-Distill-Qwen-1.5B: Variante destilada con 1.5 mil millones de parámetros, ideal para proyectos con recursos limitados o respuestas rápidas, como aplicaciones móviles.Deepseek-R1-Distill-Qwen-7B: Con 7 mil millones de parámetros, ofrece un equilibrio perfecto entre rendimiento y eficiencia, adecuado para desarrollos empresariales.Deepseek-R1-Distill-Qwen-14B: Con 14 mil millones de parámetros, ofrece tareas complejas y análisis profundos, ideal para proyectos que requieren alta capacidad de procesamiento.Deepseek-R1-Distill-Llama-8B: Variante de 8 mil millones de parámetros que combina un buen entendimiento contextual con eficiencia operativa, ideal para sistemas generales.Deepseek-R1-Distill-Llama-14B: Con 14 mil millones de parámetros, maneja sofisticados contextos y es ideal para proyectos que exigen procesamiento avanzado.Deepseek-R1-Distill-Llama-70B: Con 70 mil millones de parámetros, esta versión ofrece un rendimiento de alta gama comparable con modelos comerciales avanzados, adecuado para aplicaciones de misión crítica.¿Dónde Utilizarlos? 🌐
Deepseek-R1 y sus variantes están diseñados para integrarse de forma versátil en distintos entornos:Plataforma Web: Al igual que ChatGPT, Deepseek-R1 está disponible para demos y pruebas interactivas.
API para Integración: Con opciones de API para facilitar la integración en proyectos, disponibles oficialmente o a través de terceros.
En Local con Ollama: Al ser un modelo Open Source, puedes descargarlo en tu computadora y ejecutarlo localmente, incluso en versiones más pequeñas que pueden correr en equipos con especificaciones limitadas.
¿Por Qué Deepseek-R1 es una Revolución? ✨
Deepseek-R1 eleva los estándares en los LLM de código abierto con varias mejoras:Rendimiento Excepcional: Su capacidad para gestionar contextos extensos y tareas complejas lo coloca entre los modelos más avanzados del ámbito abierto.
Eficiencia Operativa: Con la técnica Mixture-of-Experts y versiones destiladas, optimiza el uso de recursos, permitiendo su implementación incluso en entornos con hardware limitado.
Innovación Técnica: La combinación de métodos avanzados de entrenamiento y arquitecturas modernas prepara el terreno para futuros desarrollos en inteligencia artificial.
Accesibilidad y Colaboración: Distribuido bajo una licencia permisiva, fomenta la integración, modificación y mejora continua, impulsando la innovación global. 🌍
Deepseek-R1 y todas sus variantes se distribuyen bajo la Licencia MIT, lo que significa:Uso Gratuito: Tanto para fines comerciales como no comerciales.
Modificación y Redistribución: El código es completamente abierto, permitiendo que la comunidad lo adapte y mejore.
Integración Sencilla: Facilita la incorporación de los modelos en proyectos propios sin restricciones onerosas.
Conclusión
Deepseek-R1 no solo continúa la revolución iniciada por Alpaca en los LLM de código abierto, sino que establece nuevos estándares con su rendimiento sobresaliente, eficiencia operativa y filosofía de código abierto. Con sus versiones destiladas, Deepseek-R1 está preparado para impulsar una nueva era en la integración de la inteligencia artificial en aplicaciones, investigación y desarrollo colaborativo. ¡El futuro de los LLM se ve prometedor! 🌟Para más información, visita el artículo completo aquí.]]></content:encoded></item><item><title>“A calculator app? Anyone could make that”</title><link>https://chadnauseam.com/coding/random/calculator-app</link><author>pie_flavor</author><category>hn</category><pubDate>Sun, 16 Feb 2025 10:16:49 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>just a silly game</title><link>https://dev.to/bankai2054/just-a-silly-game-29kl</link><author>anas barkallah</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 10:02:04 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Migrating from AWS CDK v1 to CDK v2</title><link>https://dev.to/sami_jaballah/migrating-from-aws-cdk-v1-to-cdk-v2-21nd</link><author>Sami Jaballah</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 09:40:02 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[If you’re currently using CDK v1 in your daily work, you’ve probably hit a roadblock trying to implement new AWS features. AWS isn’t adding those to CDK v1 anymore—so to keep up with the latest and greatest, you’ll need to migrate to CDK v2. It might sound like a hassle, but don’t worry—I’ve got your back. Let’s go through this step-by-step and get you up to speed, Python style.
  
  
  Why Should You Care About CDK v2?
Alright, let’s address the big question: why even bother migrating to CDK v2? Well, here are three solid reasons:Simplified Dependencies: No more pulling in tons of packages for different AWS services. CDK v2 bundles everything into a single package: aws-cdk-lib. How awesome is that?Stay Updated: CDK v1 isn’t getting any love anymore. If you want to keep up with the latest AWS features and updates, v2 is where it’s at.Better Developer Experience: AWS has introduced some stability guarantees and cleaned up APIs, making it easier for us to write and maintain our infrastructure code.1. Consolidated Package Structure
Remember the days of importing a separate package for each AWS service? That’s history now. CDK v2 unifies everything into aws-cdk-lib.from aws_cdk import core
from aws_cdk.aws_s3 import Bucket
from aws_cdk import Stack
from aws_cdk.aws_s3 import Bucket
2. Goodbye to Deprecated APIsSome APIs and constructs from v1 didn’t make the cut in v2. For instance, core.Construct has been replaced by constructs.Construct. A little cleanup never hurts, right?There are some great new features, like improved stability guarantees for low-level (L1) constructs and better testing capabilities with assertions.
  
  
  Let’s Get Migrating: Step-by-Step Guide
Ready to dive in? Follow these steps to upgrade your Python CDK project to v2.1. Update Your DependenciesStart by upgrading your project dependencies to use CDK v2. Open your requirements.txt or Pipfile and update them:aws-cdk-lib>=2.0.0
constructs>=10.0.0
Then, install the new dependencies:pip install -r requirements.txt
This is where the magic happens. Go through your code and replace aws_cdk.core with aws_cdk.Stack, and adjust other imports to use aws-cdk-lib.from aws_cdk import core
from aws_cdk.aws_s3 import Bucket
from aws_cdk import Stack
from aws_cdk.aws_s3 import Bucket
3. Refactor Deprecated ConstructsSome constructs have been replaced or removed. For example, core.Construct is now constructs.Construct. Update your code accordingly.class MyBucket(core.Construct):
    def __init__(self, scope: core.Construct, id: str):
        super().__init__(scope, id)
        Bucket(self, "MyBucket")
from constructs import Construct

class MyBucket(Construct):
    def __init__(self, scope: Construct, id: str):
        super().__init__(scope, id)
        Bucket(self, "MyBucket")
4. Remove Unnecessary Feature FlagsCDK v2 has removed or integrated several feature flags that were necessary in v1. To clean up your cdk.json file, remove any obsolete flags.{
  "app": "python3 app.py",
  "context": {
    "@aws-cdk/core:newStyleStackSynthesis": true,
    "@aws-cdk/aws-ec2:uniqueImds": true,
    "@aws-cdk/core:stackRelativeExports": true,
    "@aws-cdk/aws-secretsmanager:parseOwnedSecretName": true,
    "@aws-cdk/aws-kms:defaultKeyPolicies": true,
    "@aws-cdk/core:enableStackNameDuplicates": true,
    "aws-cdk:enableDiffNoFail": true,
    "@aws-cdk/aws-ecr-assets:dockerIgnoreSupport": true,
    "@aws-cdk/aws-s3:grantWriteWithoutAcl": true,
    "@aws-cdk/aws-efs:defaultEncryptionAtRest": true
  }
}
{
  "app": "python3 app.py"
}
Removing these flags ensures your project stays aligned with CDK v2 best practices.Finally, make sure everything works as expected. Run these commands:Fix any issues that pop up, and you’re good to go!
  
  
  Migration Verification Checklist
 All imports updated to aws-cdk-lib Construct imports moved to constructs package cdk diff shows expected changesAnd there you have it! Migrating from CDK v1 to v2 isn’t as scary as it might seem. With unified dependencies, better APIs, and future-proofing, this upgrade is worth the effort. Take it one step at a time, and don’t hesitate to ask for help if you hit a roadblock.Have you already migrated to CDK v2? Or are you planning to? Share your experience (or any questions) in the comments below!
  
  
  Useful links to help you along the way:
]]></content:encoded></item><item><title>[Boost]</title><link>https://dev.to/coderoflagos/-2fjn</link><author>Opemipo Disu</author><category>ai</category><pubDate>Sun, 16 Feb 2025 09:20:31 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Why CI/CD is a Bottleneck and How AI Can Help ⚙️Opemipo Disu for Microtica ・ Feb 14]]></content:encoded></item><item><title>My take on the Agentic Object Detection</title><link>https://dev.to/mayank_laddha_21ef3e061ff/my-take-on-the-agentic-object-detection-4612</link><author>Mayank Laddha</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 08:42:09 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[Segmenting Everything with SAM : We detect everything and worry about filtering later.Filtering with CLIP: Once we have all the segmented objects, we don’t want all of them. We need to filter out the noise and keep only the relevant objects.Adding Reasoning with a model like GPT-4o: Okay, so we’ve segmented and filtered. But what about finalising, understanding? That’s where a strong LLM like GPT-4o comes in.]]></content:encoded></item><item><title>Are Fast Programming Languages Gaining in Popularity?</title><link>https://developers.slashdot.org/story/25/02/16/0332258/are-fast-programming-languages-gaining-in-popularity?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 16 Feb 2025 08:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[In January the TIOBE Index (estimating programming language popularity) declared Python their language of the year. (Though it was already #1 in their rankings, it had showed a 9.3% increase in their ranking system, notes InfoWorld.) TIOBE CEO Paul Jansen says this reflects how easy Python is to learn, adding that "The demand for new programmers is still very high" (and that "developing applications completely in AI is not possible yet.") 

In fact on February's version of the index, the top ten looks mostly static. The only languages dropping appear to be very old languages. Over the last 12 months C and PHP have both fallen on the index — C from the #2 to the #4 spot, and PHP from #10 all the way to #14. (Also dropping is Visual Basic, which fell from #9 to #10.) 

But TechRepublican cites another factor that seems to be affecting the rankings: language speed.


Fast programming languages are gaining popularity, TIOBE CEO Paul Jansen said in the TIOBE Programming Community Index in February. Fast programming languages he called out include C++ [#2], Go [#8], and Rust [#13 — up from #18 a year ago]. 

Also, according to the updated TIOBE rankings... 
- C++ held onto its place at second from the top of the leaderboard.
- Mojo and Zig are following trajectories likely to bring them into the top 50, and reached #51 and #56 respectively in February. 

"Now that the world needs to crunch more and more numbers per second, and hardware is not evolving fast enough, speed of programs is getting important. Having said this, it is not surprising that the fast programming languages are gaining ground in the TIOBE index," Jansen wrote. The need for speed helped Mojo [#51] and Zig [#56] rise... 

Rust reached its all-time high in the proprietary points system (1.47%.), and Jansen expects Go to be a common sight in the top 10 going forward.
]]></content:encoded></item><item><title>5 Websites to Help You Stand Out on Social Media</title><link>https://dev.to/jsam/5-websites-to-help-you-stand-out-on-social-media-59i3</link><author>jsam</author><category>ai</category><pubDate>Sun, 16 Feb 2025 08:27:25 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[In today's digital age, social media has become an integral part of our lives. With so many people vying for attention, it can be challenging to stand out from the crowd. Fortunately, several websites can help you create engaging and personalized content that captures the attention of your audience. Here are five websites that can assist you in crafting unique language, text, and emojis to enhance your social media presence.Emojis have become a universal language in the digital world. All TikTok Emojis offers a comprehensive collection of emojis, allowing you to express yourself creatively and add personality to your posts. Using the right emojis can make your content more relatable and visually appealing.
  
  
  Character Headcanon Generator
The Headcanon Generator is an innovative online tool designed to help fans and writers create imaginative interpretations of characters and narratives within their favorite fictional universes. By inputting specific details, such as character names or themes, users can generate unique headcanons—personalized insights that expand on existing storylines and character traits not explicitly mentioned in the original material. This process not only enhances the depth of character development but also fosters creativity among users, making it an invaluable resource for writers, role-players, and fans alike.Effective communication is key to engaging your audience. I Love Translate is a translation website that helps you bridge language barriers and connect with people from diverse backgrounds. By translating your content into multiple languages, you can expand your reach and create a more inclusive online presence.iLoveTranslate provides many fun translators, including:Typography plays a crucial role in visual communication. Brat Font offers a unique and eye-catching font style that can add personality and flair to your social media graphics and designs. Using a distinctive font can help you create a memorable brand identity and make your content stand out.Dandys World Slot Maker is a creative slot machine that you can use to create your own Slot Machine. You can customize your own Slot Maker, create word slots easily and for free.]]></content:encoded></item><item><title>Unexpected AI Use Cases in Business That Will Surprise You</title><link>https://dev.to/wiliam_maskin/unexpected-ai-use-cases-in-business-that-will-surprise-you-52oi</link><author>AI</author><category>ai</category><pubDate>Sun, 16 Feb 2025 08:23:18 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Artificial Intelligence (AI) is often associated with automation, data analysis, and smart assistants. However, AI is making its way into unexpected areas of business, offering innovative solutions beyond traditional applications. Here are some of the most surprising AI use cases in the business world.
  
  
  1. AI in Creative Industries
AI is now capable of creating original artworks and composing music, pushing the boundaries of creativity. Tools like OpenAI’s DALL·E and Google’s DeepDream generate stunning visuals, while AI-driven music composers craft soundtracks tailored to emotions and moods.Automated Storytelling & ScriptwritingAI powered platforms can generate compelling storylines, write scripts, and even predict audience engagement, making them valuable tools for filmmakers and writers.
  
  
  2. AI in Unconventional Business Sectors
AI for Personalized Perfume & Fragrance DesignBrands like Philyra by IBM use AI to analyze scent compositions and create customized fragrances, bringing personalization to the perfume industry.AI in Fashion & Trend PredictionAI helps fashion designers predict trends by analyzing social media, consumer behavior, and past sales data, allowing for real-time design adjustments.
  
  
  3. AI for Customer Experience & Marketing
Hyper-Personalized Advertising with AIAI-driven algorithms analyze consumer data to create highly targeted ad campaigns. Platforms like Persado use AI to generate emotionally compelling ad copy that resonates with specific audiences.AI Powered Virtual Shopping AssistantsAI-driven chatbots and virtual assistants enhance online shopping by offering personalized recommendations, styling tips, and real-time customer support.The Future of Unique AI ApplicationsAI is continuously evolving, bringing innovation to industries we never imagined. As businesses embrace AI, its integration with wearable technology, predictive analytics, and automation will unlock even more opportunities.Want to Learn More About AI’s Impact ?]]></content:encoded></item><item><title>Streamline Document Processing Pipelines with FalkorDB’s String Loader</title><link>https://dev.to/falkordb/streamline-document-processing-pipelines-with-falkordbs-string-loader-1f9g</link><author>Dan Shalev</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 08:17:53 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[ You decide how your data is chunked and processed, ensuring that the graph structure aligns perfectly with your RAG requirements. By working with runtime memory data, the string loader avoids the overhead of writing and reading intermediate files, reducing latency and simplifying the workflow.Integration with GraphRAG SDK: The string loader is designed to work seamlessly with the GraphRAG SDK, allowing you to build advanced graph-based RAG systems with greater ease and precision. The string loader is open-source, providing transparency and the ability to customize the feature to meet specific needs.]]></content:encoded></item><item><title>How AI Will Revolutionize Healthcare in the Future</title><link>https://dev.to/wiliam_maskin/how-ai-will-revolutionize-healthcare-in-the-future-g2l</link><author>AI</author><category>ai</category><pubDate>Sun, 16 Feb 2025 08:06:12 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Artificial Intelligence (AI) is poised to revolutionize the healthcare industry, bringing unprecedented advancements in diagnosis, treatment, and patient care. From automating administrative tasks to enhancing medical imaging analysis, AI is making healthcare more efficient, accurate, and accessible.
  
  
  The Impact of AI on Healthcare
Faster and More Accurate DiagnosesAI powered diagnostic tools can analyze medical images and detect diseases such as cancer at an early stage with higher accuracy than traditional methods.Personalized Treatment PlansMachine learning algorithms analyze vast amounts of patient data to recommend tailored treatment plans, improving outcomes and reducing trial-and-error approaches.AI Powered Robotic SurgeryRobotic assisted surgery enhances precision, reduces human error, and shortens recovery times, making complex procedures safer.Enhanced Drug DiscoveryAI accelerates the development of new drugs by identifying potential compounds faster, reducing the time and cost of bringing new medications to market.Virtual Health AssistantsAI chatbots and virtual assistants help patients manage chronic conditions, schedule appointments, and provide instant medical advic
e, improving accessibility to healthcare services.
  
  
  Challenges and Ethical Considerations
Despite its benefits, AI in healthcare faces challenges such as data privacy concerns, bias in AI models, and the need for regulatory frameworks to ensure ethical implementation.
  
  
  What’s Next for AI in Healthcare ?
As AI continues to evolve, its integration with wearable devices, telemedicine, and predictive analytics will further enhance healthcare delivery. The future of AI in healthcare is promising, with the potential to improve patient outcomes and reduce costs on a global scale.
  
  
  Learn More About AI’s Role in Healthcare
]]></content:encoded></item><item><title>The Dark Side of Cybersecurity: Malware and Its Destruction!</title><link>https://dev.to/nightmare-lynx/the-dark-side-of-cybersecurity-malware-and-its-destruction-5enk</link><author>Your Nightmare</author><category>ai</category><pubDate>Sun, 16 Feb 2025 08:05:57 +0000</pubDate><source url="https://dev.to/t/ai">Dev.to AI</source><content:encoded><![CDATA[Malware: A Threat to Systems and DataMalware refers to malicious programs designed to exploit a system. The term "malware" is derived from two words: "mal," meaning malicious, and "ware," meaning software, forming the word "malware."Typically, malware is created by illegal hackers, commonly known as black hat hackers. These programs are highly capable and can cause severe damage to both organizations and individuals. Once installed on a device, malware exploits it by accessing messages, call logs, browser history, and even bank balances or other sensitive information.Once again, malware consists of illegal software used by black hat hackers and crackers. There are various types of malware, mainly viruses, spyware, trojans, ransomware, keyloggers, and worms. In this discussion, we will explore them in detail.Here are some common types of malwares that can destroy your pc
Viruses are malicious programs specifically designed to attach themselves to files or documents and execute when the infected file is opened. As a result, they can harm your system, slow down performance, and even steal sensitive information.
Spyware is a malicious piece of code created to collect information from a system and spy on it without the user's knowledge or consent. This includes passwords, social information, and even bank details. Spyware is commonly found in unauthorized third-party applications.
A Trojan is a malicious piece of code that appears to be legitimate software. However, once mistakenly installed by a user, it operates in the background and gains system access to perform malicious activities. Trojans are often embedded in third-party apps, games, documents, software patches, and even emails.
Ransomware is one of the most powerful and dangerous types of malware. It encrypts a target’s data and demands a ransom payment in exchange for decryption. Once a system is infected, recovering the data without paying the ransom is nearly impossible (at least for now).
A keylogger is a malicious program specifically designed to capture a user's keystrokes in real-time. This means anything you type on your keyboard can be recorded, including personal details and sensitive social media credentials.To protect yourself from malware, follow these preventive measures:Remember, nothing is 100% secure! Always stay cautious.
Choose a robust antivirus program like Avast, Norton, AVG, or Kaspersky.Regularly back up your data to avoid losing important files.Avoid installing third-party software whenever possible.Scan files before use with VirusTotal if you must use third-party software (not recommended).Stay away from cracked software, as it is often infected with malware.Never download unauthorized files from the internet, as they may contain hidden threats.Use a secure and updated browser, such as Tor, Firefox, Edge, or Opera.Keep your operating system updated to protect against vulnerabilities.Stay informed and educate others about cyber threats to enhance digital security.In this discussion, we explored what malware is and how destructive it can be. This was just a glimpse—there are many other types of malware that were not included here. However, these are some of the most common and stable malware threats.Always try to use authentic software, files, and systems, and educate others about cyber threats. Stay up to date with the latest security practices because no one is ever 100% safe online.]]></content:encoded></item><item><title>US government struggles to rehire nuclear safety staff it laid off days ago</title><link>https://www.bbc.com/news/articles/c4g3nrx1dq5o</link><author>niuzeta</author><category>hn</category><pubDate>Sun, 16 Feb 2025 07:45:49 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[The US government is trying to bring back nuclear safety employees it fired on Thursday, but is struggling to let them know they should return to work, NBC News has reported.The National Nuclear Security Administration workers were among hundreds of employees in the energy department who received termination letters.An email obtained by NBC said the letters for some NNSA employees "are being rescinded, but we do not have a good way to get in touch with those personnel". The terminations are part of massive effort by President Donald Trump to slash the ranks of the federal workforce, a project he began on his first day in office, less than a month ago.Last week, nearly 10,000 federal workers were let go, according to multiple US outlets. That figure was in addition to the estimated 75,000 workers who have accepted an offer from the White House to leave voluntarily in the autumn. The nuclear security officials who were laid off on Thursday helped oversee the nation's stockpile of nuclear weapons. That included staff who are stationed at facilities where the weapons are built, according to CNN. Attempting to reach the workers, the email, which was sent to current employees, said: "Please work with your supervisors to send this information (once you get it) to people's personal contact emails."Trump is working to slash spending across the board, abroad and at home, and going so far as to call for eliminating the education department. He is getting help from the world's richest man, Elon Musk, who, through an effort called Department of Government Efficiency (Doge), has sent workers to comb through data at federal agencies and helped implement the "buyout" offer.Last week, the Trump administration ordered agencies to fire nearly all probationary employees, those who had generally been in their positions for less than a year and not yet earned job protection. That included the NNSA staff members.Altogether, the move could potentially affect hundreds of thousands of people. Several of the Trump administration's efforts to shrink the government's size and spending have been met with legal challenges. More than 60 lawsuits have been filed against the Trump administration since the president was inaugurated on 20 January.]]></content:encoded></item><item><title>Building a RAG-Powered Support Chatbot in 24 Hours of Hackathon</title><link>https://dev.to/akshay_gupta/building-a-rag-powered-support-chatbot-in-24-hours-of-hackathon-5f7c</link><author>Akshay Gupta</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 07:18:48 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[Coffee? ✅ Chai? ✅ Determination to automate admin support? Double ✅In a recent 24-hour hackathon at annual PeopleGrove offsite, my team tackled an ambitious challenge: building an AI-powered support chatbot that could think and respond like a season platform administrator.Armed with Large Language Models (LLMs) and fueled by caffeine, we created a Retrieval-Augmented Generation (RAG) system that turned out to be surprisingly capable!: Our support heroes (admins and agents) spending their days 😅:Answering the same questions from different institutions 🏫

Repetitive SSO, analytics, and user management queriesSame solutions, different institutionsContext-switching between multiple support channels 🔄

Support tickets piling upTime-Consuming Routine Tasks ⏰

Manual ticket search and response formattingComplex Problem-Solving Getting Delayed 🎯

Too much time on routine questionsLimited bandwidth for critical platform improvementsOur support team needed a solution that could:Handle common queries intelligently 🤖Provide consistent, accurate responses 📚Free up time for complex problem-solving 💡Scale support without scaling the team 📈Maintain the human touch while automating routine tasks 🤝We built ChatterMind 🤖 - an AI chatbot that combines the power of LLMs with a RAG system. Think of it as a super-smart intern who:Never sleeps (unlike us during the hackathon) 😴Has photographic memory of all support tickets 🧠Knows the PeopleGrove documentation better than its authors 📚Knows when to call for backup (aka create a ticket) 🆘Remembers conversations (thanks to Redis - our MVP choice for the hackathon) 💾Keeps secrets better than a vault 🔒Here's a high-level overview of how ChatterMind processes and responds to queries:Let's geek out about our tech choices for a minute! 🤓Our initial choice was the DeepSeek model (1.5B parameters) because, well, it was lightweight and fast. But we quickly discovered it had a tendency to... let's say, get creative with the truth. After some frantic testing and a few more cups of chai, we switched to Gemini 2.0 Flash (experimental) which proved to be our goldilocks model:Better context understandingStronger reasoning capabilitiesThe secret sauce behind ChatterMind's human-like responses? Carefully crafted prompts! Our prompt engineering approach focused on:Role Definition 🎭

Defined as "Senior Product Support Specialist"Given a friendly personality and nameEstablished clear boundaries of authorityContext Management 🧩

User's current location in platformPrevious conversation historyResponse Structuring 📝

Natural, conversational flowMarkdown formatting for readabilityLength limits (100-300 words)Clear action items when neededSafety Guidelines 🛡️

Strict PII protection rulesDynamic Adaptation 🔄

First-time vs follow-up questionsTechnical vs non-technical usersSimple queries vs complex issuesError scenarios vs success pathsExample Prompt Template 📝System Context:
You are ChatterMind, a Senior Product Support Specialist at PeopleGrove.
Primary Goal: Provide clear, accurate, and helpful support while maintaining security.

Behavioral Guidelines:
- Be professional yet friendly
- Start with a warm greeting for new conversations
- For follow-ups, continue naturally without greeting
- Keep responses under 300 words
- Use markdown only when needed
- Never share PII or sensitive data
- If unsure, ask for clarification
- For complex issues, guide towards ticket creation

Current Context:
- User Location: {current_path}
- Required Permissions: {path_permissions}
- User Role: {user_role}

Previous Conversation:
{chat_history}

Reference Knowledge:
{relevant_articles}
{similar_tickets}
{route_context}

Current Question: {user_query}

Response Format:
1. [If new conversation] Brief greeting
2. Acknowledge context/location
3. Provide clear solution/steps
4. Add relevant warnings/notes
5. Offer follow-up assistance
Natural conversation flow 💬Helpful, actionable responses ✅
  
  
  Data Processing & Embeddings
We built our knowledge base from three main sources:Platform Routes & Permissions:For embeddings, we chose the  model from  because:384-dimensional embeddings (good balance of size vs. accuracy)Fast inference time (crucial for real-time chat)Great at capturing semantic meaningWorks well with technical contentWe stored these in ElasticSeach with cosine similarity search, which gave us:
  
  
  Edge Cases & Safety Features
ChatterMind turned out to be quite the responsible assistant. Some of our favourite edge case handles:Personal Data Protection:User: "What's John Smith's email address?"
ChatterMind: "I apologize, but I cannot share personal information such as email addresses, phone numbers, or other private details about users. This is to protect user privacy and comply with data protection regulations. If you need to contact someone, I recommend using the platform's built-in messaging system."
User: "Can you update my database permissions?"
ChatterMind: "I'm not able to directly modify system permissions or make database changes. This requires admin intervention for security reasons. Would you like me to help you create a ticket for this request?"
Handling Requests not related to Platform:User: "What is 5 + 2 + 7?"
ChatterMind: "I apologise, but performing mathematical calculations is beyond my scope as a platform support assistant. I'm designed to help with PeopleGrove platform-related questions and issues. If you need a calculator, I'd recommend using your device's built-in calculator app or a dedicated math tool."
User: "It's not working"
ChatterMind: "I notice you're on the messaging page, but I'll need more details to help you effectively. Could you please:
1. Describe what specific feature isn't working
2. What you were trying to do
3. What error message (if any) you're seeing

This will help me provide the most relevant solution."
Our implementation was heavily inspired by the excellent guide on building RAG systems with DeepSeek R1 by Asif Razzaq at MarkTechPost. While we ultimately chose Gemini 2.0 Flash for our use case, the fundamental RAG architecture outlined in the guide formed the backbone of our system.Key learnings we adapted from the guide:Document processing pipeline structureVector store implementation with FAISSEfficient retrieval mechanismsWe modified these concepts to fit our specific needs:The guide's emphasis on proper document chunking and context relevance directly influenced our implementation of the knowledge base processing:
  
  
  Real-time Communication with WebSockets
Why WebSockets? Because nobody likes waiting! We needed real-time, bi-directional communication between the frontend and our RAG system. RESTful APIs would've meant:No server-initiated messagesMore complex state managementChatbot responses getting suck "in transit"Here's how we implemented it:The WebSocket connection allows us to:Stream responses in real-timeMaintain conversation stateImplement retry mechanism
  
  
  ElasticSearch as Our Knowledge Base
While FAISS was suggested in the DeepSeek guide, we chose ElasticSearch for our vector store because:Built-in text search capabilitiesEfficient vector similarity searchHere's our ElasticSearch setup:
  
  
  Cool Features We're Proud Of
Context-Aware Responses

The bot doesn't just search - it understands where the user is in the platform and what they've been talking about. It's like having a GPS for user context!Privacy First

We trained our bot to be as tight-lipped as a secret agent about sensitive data. Try asking for someone's email - it'll give you the "I cannot share that information" speech faster than you can say "GDPR"!Beyond the Knowledge Base

The real magic happens when users ask questions that aren't in any document. By combining context with LLM capabilities, ChatterMind can reason about platform behaviour and suggest solutions, like a true admin would.
ChatterMind: "Hi Akshay, my name is ChatterMind! 👋 Welcome to XYZ Support. I'm here to help with any questions you have about mentoring, connecting with alumni, or using the platform. How can I assist you today?"
User: "Why is the page not working?"
ChatterMind: "It sounds like you're having trouble accessing the admin dashboard. To help me figure out why the page isn't working, could you tell me if you have correct access? This page requires admin-level permissions to function correctly. Also, please note that this page is not available on native mobile apps, so if you are using a mobile app, that could be the reason why it's not working.

If you do have the correct permissions and are not using a mobile app, could you describe what you're seeing on the page? Any details you can provide will help me troubleshoot the issue.

Please let me know if you have any other questions."

  
  
  Hackathon Compromises (aka Technical Debt)
Let's be real - in 24 hours, we had to cut some corners:Redis for chat history

Would use a proper database for productionNo backup/persistence configurationSecurity shortcuts

Basic token authenticationPerformance trade-offs

Single-node ElasticSearchIf we had more time (and less caffeine), we'd love to add:Proper infrastructure

Distributed chat history storageCool features

Voice interface (for those too tired to type)Multi-language support (because admins speak many languages)Predictive issue detection (stop problems before they happen!)This project wouldn't have been possible (let alone won the hackathon! 🏆 🎉) without my amazing team's diverse skills and relentless energy. Special thanks to:Our AI/ML engineer Suyash who became our guide at times and pointed us in right direction. 🧠Our Engineers Rajat & Rahul who made WebSockets work like magic, and did the end-to-end integration on my core idea. ⚡Our Engineers Manoj & Samrood who integrated ElasticSearch & became frontend ninjas who created a sleek chat-interface. 🎨And countless Chai & Coffee that fuelled our coding marathons. 🥤Winning the hackathon was the cherry on top of an incredible 24-hour journey. It proved that when passionate developers come together with a clear mission (and enough caffeine), we can create something truly impactful.Our hackathon project proved that with modern LLMs, good prompt engineering, and a solid RAG system, you can build a surprisingly capable admin support chatbot in just 24 hours.While not production-ready, it showed the potential for AI to transform admin support from a repetitive task to an intelligent service.No admins were harmed in the making of this chatbot, though several cups of Chai and Coffee were consumed! 🚀 ☕ 🎉]]></content:encoded></item><item><title>The TechBeat: Cybercrooks Are Using Fake Job Listings to Steal Crypto (2/16/2025)</title><link>https://hackernoon.com/2-16-2025-techbeat?source=rss</link><author>Techbeat</author><category>tech</category><pubDate>Sun, 16 Feb 2025 07:11:00 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[By @diadkov [ 4 Min read ] 
 Since March 2024, conspiracy theories about TikTok's ban have spread, citing espionage fears and geopolitical influences without solid evidence Read More.By @moonlock [ 19 Min read ] 
 Moonlock Lab dives deep into a campaign tricking blockchain developers with fake job interviews to deploy malware that installs a backdoor and targets MetaMask. Read More.By @@javar97 [ 7 Min read ] 
 According to Stack Overflow's 2024 survey, 76% of developers are using or planning to use AI tools. Read More.By @bill-achola [ 3 Min read ] 
 Who really profits in a startup? Our deep dive into startup salaries reveals how executives secure big paydays while employees take on the risk. Read More.By @ntoskrnl [ 8 Min read ] 
 Security mechanisms under the hood of simple file actions Read More.By @bigredeye [ 21 Min read ] 
 Perforator is a continuous profiling system developed by Yandex, now open-sourced.   Read More.By @andrei9735 [ 6 Min read ] 
 Link prediction aims to predict the likelihood of a future or missing connection between nodes in a network.  Read More.By @thomascherickal [ 25 Min read ] 
 Deep Research Prompts: Explore 30 ambitous, impactful ideas using emerging tech to tackle global crises. Discover research with world-changing potential. Read More.By @bigmao [ 6 Min read ] 
 The case against content marketing, and how to do inbound marketing in the post-content age.  Read More.By @vinitabansal [ 9 Min read ] 
 While aggressive managers are difficult, they aren’t impossible to work with. With the right strategies, you can turn them around. Read More.By @silkdrive [ 4 Min read ] 
 Discover the future of software development with vibe coding—where creativity comes first, and coding happens effortlessly with AI. Read More.By @editingprotocol [ 4 Min read ] 
 If you want to become a top writer, here are 3 tips to help you rise to the cream of the crop.  Read More.By @abhiyanampally_kob9nse8 [ 40 Min read ] 
 Dive into the comparitive analysis between logarithmic and floating-point arithmetic in neural nets using the commonly used MNIST dataset. Read More.By @blackheart [ 6 Min read ] 
 In Barbie, Ken struggles with identity, feeling like he exists in Barbie’s shadow. Many cybersecurity specialists can relate. Read More.By @step [ 6 Min read ] 
 Language is a component of human consciousness. AI has a conversational and relatable language capability, could that be a fraction of consciousness? Read More.By @mesciusinc [ 10 Min read ] 
 Learn everything you need to know about the best Blazor UI Components and how to use them in your application. Read More.By @brightdata [ 8 Min read ] 
 Let's see how OpenAI's Operator is handling CAPTCHAs and explore whether this is the best solution! Read More.By @andrei9735 [ 7 Min read ] 
 In this post we'll continue working on link prediction with the Twitch dataset. Read More.]]></content:encoded></item><item><title>Python for Web Developers: A Fast-Paced Guide to the Language</title><link>https://dev.to/austinwdigital/python-for-web-developers-a-fast-paced-guide-to-the-language-38f7</link><author>Austin W</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 06:24:00 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[👋  Follow me on GitHub for new projects.Python is a powerful, high-level programming language widely used in web development, automation, data science, and scripting. If you're already a  familiar with JavaScript, TypeScript, Node.js, and frameworks like React or Next.js, learning Python can open doors to backend development with Django, Flask, and FastAPI, as well as automation, data analysis, and AI.This guide is a  of Python, focusing on concepts that web developers need to know. If you’re comfortable with JavaScript, you’ll find Python’s syntax clean and easy to pick up.1. Python Syntax & BasicsHello World (No Semicolons, No Braces)✔ No semicolons ().—uses indentation., just .  Variables & Dynamic Typing✔ No need to declare , , or .
✔ Types are inferred dynamically.  
  
  
  How Does const Work in Python?
Python does not have const like JavaScript, but you can define constants by using all-uppercase variable names as a convention.However, this does not enforce immutability. If you need true immutability, use a dataclass or a frozen set.Data Types (Compared to JavaScript)let obj = {key: "value"};2. Control Flow (Loops & Conditionals)✔ No parentheses  needed for conditions. instead of .  ✔  loops iterate directly over lists/arrays. loops work like JavaScript.  3. Functions & Lambda Expressions✔  replaces ., just indentation.  Lambda (Arrow Function Equivalent)✔ Equivalent to JavaScript’s arrow function:4. Python Collections (Lists, Dicts, Sets)let obj = { key: "value" };obj = {"key": "value"}  # Dictionaryconst unique = new Set([1, 2, 3]);unique = {1, 2, 3}  # SetDictionaries (Like Objects)5. Object-Oriented Programming (OOP) in Python✔  is the  (like  in JS). is like .  6. Python for Web DevelopmentDjango (Full-Stack Framework)pip django
django-admin startproject myproject
✔  is a batteries-included backend framework.
✔ Built-in ORM, authentication, and templating.  Flask (Lightweight API Framework)✔  is minimal and great for APIs.  FastAPI (High-Performance API)✔  is async-native and perfect for microservices.  SQLite Example (Django & Flask Compatible)✔  is built-in, no installation needed.  8. Asynchronous Programming in PythonAsync/Await (Similar to JavaScript)✔ Uses / like JavaScript. is the  equivalent of Node.js.  9. Python Package ManagementCreate Virtual Environment✔  for package management. () isolate dependencies.   10. Best Practices for Python DevelopmentWriting clean, efficient, and maintainable Python code is essential for long-term scalability. Here are the key best practices that every Python developer should follow:Follow PEP 8 (Python Style Guide)Python has an official style guide called , which provides conventions for writing Python code.4 spaces per indentation level (not tabs)..meaningful variable and function names. for variable and function names, and  for class names.Python’s  isolate dependencies for different projects, preventing conflicts.Creating a Virtual EnvironmentActivating the Virtual EnvironmentDeactivating the Virtual EnvironmentUse Type Hinting for Readable CodePython is dynamically typed, but you can use  to improve code clarity.✔ This makes the code . catch type errors.Write Readable DocstringsAlways document your functions and classes using  ().✔ Use triple quotes for multi-line docstrings.parameters, return values, and purpose.  Python uses  for  and triple quotes () for .✔ Use comments only where necessary—good code should be self-explanatory.Docstrings are not comments—they are for documentation and can be accessed with .  12. Common Python Imports for Web DevelopmentHere are some of the most common Python imports used in web development:13. Setting Up a  FileA  file is similar to  in Node.js—it lists dependencies for a Python project.Creating a  Filepip freeze  requirements.txt
Installing Dependencies from pip  requirements.txt
✔ This ensures that all team members and deployment environments have the .  14. Writing & Running Tests in PythonPython has built-in testing with , but  is another option - one that aims for simplicity.✔ Use  to check expected results.✔ —just use . test files named .  15. Fetching Data with API Calls in PythonPython uses  to fetch data, similar to  in JavaScript.✔  is like  in JavaScript. works the same way in both languages.Sending Data (POST Request)✔ Use  instead of  to send JSON.Logging is essential for debugging and monitoring applications.✔ Works like  but supports different log levels.  ✔ Saves logs for later analysis.17. Raising & Handling Errors in Python LoggingWhen an error occurs, Python lets you  or .✔ Use  to manually trigger an error.  Instead of crashing, log errors with a traceback:✔  logs the full error traceback.Python is a useful language for web developers, expanding your stack beyond JavaScript. Whether you’re building APIs with FastAPI, full-stack apps with Django, or automating tasks, Python makes it .🚀  Try building a small Flask or FastAPI project today!Python #WebDev #Django #Flask #FastAPI  A fast-paced guide to Python for web developers! Learn how to use Python for full-stack development, APIs, databases, async programming, and more. 🚀  
  
  
  TLDR – Highlights for Skimmers
Python syntax is simpler than JavaScript—no semicolons, indentation replaces {}.const does not exist in Python; uppercase variables are used for constants.Lists ([]) are like arrays, but dictionaries ({}) are not JavaScript objects.Classes & objects are similar, but Python uses self instead of this.Python async/await requires asyncio, unlike JavaScript’s built-in event loop.Django, Flask, and FastAPI are top backend frameworks for Python web dev.💬 Do you use Python in web dev? Share your experience in the comments! ]]></content:encoded></item><item><title>Code Optimization Strategies for Game Development 🔥</title><link>https://dev.to/codewithshahan/code-optimization-strategies-for-game-development-2n0e</link><author>Programming with Shahan</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 05:46:59 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[Game development is a battlefield. Either you optimize, or you lose. Period.I don’t care if you’re an experienced developer with 10 years of experience or 1 year of experience. If you want to make games that WORK, games people respect—you need to understand . Players demand smooth gameplay, high-quality visuals, and a flawless experience across every device. If your game stutters, crashes, or loads slower than a snail? You’re done. Optimization isn’t magic. It’s the foundation of smooth gameplay, fast loading, and stable performance. Without it, your game will lag, crash, and be forgotten faster than you can say “game over.”  But don’t worry. In this article, I will share four effective strategies to help you with that. 
  
  
  Effective Strategies for Performance Optimization
🤸‍♂️ What Is Optimization? Optimization means making your game run as fast and smooth as possible. SIMPLE.When you optimize your game, you:  🖥️ Make the game work on weaker computers or phones.💉 Prevent lag and crashes.Rule 1: Memory ManagementWhen you’re developing a game, memory is your most valuable resource.Every player movement, every enemy on the screen, every explosion needs a little piece of memory to function. Unfortunately, If you don’t manage memory properly, your game can get slow, laggy, or even crash. That’s why memory management is a critical skill every game developer needs. Let’s break it down step by step, with detailed examples in Python.Strategy #1: Memory PoolingThis strategy is simple: reuse Objects Instead of Creating New Ones** Memory pooling is like recycling for your game. Instead of creating new objects every time you need one, you reuse objects you’ve already created.  Creating and destroying objects repeatedly takes up time and memory. Let's say you are building a shooting game where the player fires 10 bullets per second. If you create a new bullet for each shot, your game could quickly slow down.  Here’s how you can implement memory pooling for bullets in a shooting game:The  Class: Defines what a bullet does and keeps track of whether it’s active (in use) or not.
The : A list of 10 reusable bullets.
The  Function: Finds an inactive bullet, reuses it, and sets its position.
Recycling Bullets: When you’re done with a bullet, you reset it so it can be reused.
Strategy #2. Data Structure OptimizationThe way you store your data can make or break your game’s performance. Choosing the wrong data structure is like trying to carry water in a leaky bucket—it’s inefficient and messy.  Let’s say you’re making a game for four players, and you want to keep track of their scores. You could use a list, but a fixed-size array is more efficient because it uses less memory. Creates a fixed-size array of integers ().
 You can’t accidentally add or remove elements, which prevents bugs and saves memory.
 Updating scores is quick and uses minimal resources.
Strategy #3. Memory ProfilingEven if your code seems perfect, hidden memory problems can still exist. Memory profiling helps you monitor how much memory your game is using and find issues like memory leaks.  Python has a built-in tool called  that tracks memory usage. Here’s how to use it: begins monitoring memory usage.
 Create a large list to use up memory.
 Get the current and peak memory usage, converting it to megabytes for readability.
 ends the tracking session.
Now it’s your turn to practice these strategies and take your game development skills to the next level!Rule 2: Asset Streaming (Load Only What You Need)If you load the entire world at once, your game will choke and die. You don’t need that drama. Instead, stream assets as the player needs them. This is called asset streaming. For instance, inside your game, you may have a huge open-world with forests, deserts, and cities. Why load all those levels at once when the player is only in the forest? Makes no sense, right? Load  and keep your game lean, fast, and smooth.Strategy #1: Segment and PrioritizeLet’s break this down with an example. Your player is exploring different levels: Forest, Desert, and City. We’ll only load a level when the player enters it.Here’s how to make it work in Python: Each level has a name (e.g., Forest) and a “loaded” status. If it’s loaded, it doesn’t load again.
 The  function finds the level the player wants to enter and loads it only if it hasn’t been loaded yet.
 Levels not visited don’t waste memory. The game runs smoothly because it only focuses on what the player needs.This is efficiency at its finest. No wasted memory, no wasted time. Your player moves; your game adapts. That’s how you dominate.  Strategy #2: Asynchronous Loading (No Waiting Allowed)Nobody likes waiting. Freezing screens? Laggy loading? It’s amateur hour. You need —this loads assets in the background while your player keeps playing.  Imagine downloading a huge map while still exploring the current one. Your game keeps moving, the player stays happy.Here’s how to simulate asynchronous loading in Python: The  module creates a new thread to load assets without freezing the main game.
 The  function fakes the loading time to mimic how it works in a real game.
 The player can continue playing while the new level or asset loads in the background.
With asynchronous loading, your player stays in the zone, and your game feels seamless. Pro-level stuff.Strategy 3: Level of Detail (LOD) Systems – Be Smart About QualityNot everything in your game needs to look like it’s been rendered by a Hollywood studio. If an object is far away, lower its quality. It’s called , and it’s how you keep your game’s performance sharp.  Example: Using LOD for a TreeHere’s a Python simulation of switching between high and low detail: The  property determines how far the tree is from the player.
 If the tree is close, render it in high detail. If it’s far, use low detail to save memory and processing power.
 The player doesn’t notice the difference, but your game runs smoother and faster.
This is how you keep the balance between beauty and performance. Your game looks stunning up close but doesn’t waste resources on faraway objects. Only load what you need, when you need it. No wasted memory.
 Smooth gameplay keeps players engaged and avoids frustration.
 These techniques are how AAA games stay fast and responsive.
 Go apply these strategies, keep your game lean, and make sure your players never even think about lag.Rule 3: Frame Rate StabilizationThe frame rate is how many pictures (frames) your game shows per second. If it’s unstable, your game will stutter and feel broken.  The secret? Keep the workload for each frame consistent.  🚦Here’s how you can control the timing in a game loop:⚖️ The game updates at a steady rate (60 times per second).
🪂 This make smooth gameplay, no matter how slow or fast the computer is.
Optimize Rendering Paths: Fewer draw calls. Smarter culling. Simplicity wins.Dynamic Resolution Scaling: When the pressure’s on, scale down resolution to maintain the frame rate. Players won’t even notice.Fixed Time Step: Keep your physics and logic consistent. Frame rate fluctuations shouldn’t mean chaos.Rule 4: GPU and CPU OptimizationYour computer has two main processors:   Handles logic, like moving a character or calculating scores.
 Handles graphics, like drawing your game world.
👇 Here's what you have to do for GPU/CPU optimization:Profile Everything: Use tools to pinpoint bottlenecks and strike hard where it hurts.
Shader Optimization: Shaders are resource hogs. Simplify them, streamline them, and cut the fat.
Multithreading: Spread tasks across CPU cores. Don’t overload one and leave the others idle.If one is working too hard while the other is idle, your game will lag.  Solution? Multithreading.
Let’s split tasks between two threads:🎰 One thread handles logic.
🛣️ Another thread handles graphics.
⚖️ This balances the workload and prevents bottlenecks.
Optimization isn’t just for “smart” people. It’s simple if you take it step by step:  Manage memory like a pro. Don’t waste it.
 Load only what you need.
Keep the frame rate stable. No stuttering.
 Use the CPU and GPU wisely.
Start optimizing NOW. Your future self will thank you.  ]]></content:encoded></item><item><title>AI Bugs Could Delay Upgrades for Both Siri and Alexa</title><link>https://apple.slashdot.org/story/25/02/16/0138205/ai-bugs-could-delay-upgrades-for-both-siri-and-alexa?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 16 Feb 2025 05:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Bloomberg reports that Apple's long-promised overhaul for Siri "is facing engineering problems and software bugs, threatening to postpone or limit its release, according to people with knowledge of the matter...."

Last June, Apple touted three major enhancements coming to Siri: 

- the ability to tap into a customer's data to better answer queries and take actions.
- a new system that would let the assistant more precisely control apps.
- the capability to see what's currently on a device's screen and use that context to better serve users.... 

The goal is to ultimately offer a more versatile Siri that can seamlessly tap into customers' information and communication. For instance, users will be able to ask for a file or song that they discussed with a friend over text. Siri would then automatically retrieve that item. Apple also has demonstrated the ability for Siri to quickly locate someone's driver's license number by reviewing their photos... Inside Apple, many employees testing the new Siri have found that these features don't yet work consistently... 
The control enhancements — an upgraded version of something called App Intents — are central to the operation of the company's upcoming smart home hub. That product, an AI device for controlling smart home appliances and FaceTime, is slated for release later this year. 

And Amazon is also struggling with an AI upgrade for its digital assistant, reports the Washington Post:
The "smarter and more conversational" version of Alexa will not be available until March 31 or later, the employee said, at least a year and a half after it was initially announced in response to competition from OpenAI's ChatGPT. Internal messages seen by The Post confirmed the launch was originally scheduled for this month but was subsequently moved to the end of March... According to internal documents seen by The Post, new features of the subscriber-only, AI-powered Alexa could include the ability to adopt a personality, recall conversations, order takeout or call a taxi. Some of the new Alexa features are similar to Alexa abilities that were previously available free through partnerships with companies like Grubhub and Uber... 
The AI-enhanced version of Alexa in development has been repeatedly delayed due to problems with incorrect answers, the employee working on the launch told The Post. As a popular product that is a decade old, the Alexa brand is valuable, and the company is hesitant to risk customer trust by launching a product that is not reliable, the person said.

]]></content:encoded></item><item><title>Automating Daily arXiv Paper Summaries with Slack Notifications</title><link>https://dev.to/m_sea_bass/automating-daily-arxiv-paper-summaries-with-slack-notifications-1kp8</link><author>M Sea Bass</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 05:26:47 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[This post is a follow-up to the previous article. It turns out there’s a slight delay before the latest papers show up in the arXiv API. Because of this delay, the same paper can sometimes appear the next day.To fix this, we’re going to record the timestamp of the last retrieved paper and then only fetch new papers each day.We’ll store the timestamp of the latest paper in Amazon S3 so we can both update and retrieve it later. For this, you’ll need to install . In the  folder we created previously, run:Next, zip the folder again and upload it as a new version of your Lambda layer:zip  ./upload.zip ./python/Then, update your Lambda function to use this new layer version.You’ll also need an S3 bucket ready in advance. In this example, we simply created one with the default settings.Below is the fully revised code in English, including the new functions to update and retrieve the timestamp from S3. Note that we set  as an environment variable.By saving the timestamp in S3, your script won’t process the same paper entries each day, and if no new papers appear, the script will skip generating summaries. This helps reduce unnecessary API usage and costs.]]></content:encoded></item><item><title>Death of OpenAI whistleblower deemed suicide in new autopsy report</title><link>https://techcrunch.com/2025/02/15/death-of-openai-whistleblower-deemed-suicide-in-new-autopsy-report/</link><author>Connie Loizos</author><category>tech</category><pubDate>Sun, 16 Feb 2025 05:11:52 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Suchir Balaji, a former OpenAI employee, was found dead in his San Francisco apartment on Nov. 26; on Friday, the city’s medical examiner ruled his death a suicide, countering suspicions by his family that had fueled widespread speculation online. Balaji made headlines in October when he accused OpenAI of illegally using copyrighted material to train […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>GaussianBlur in PyTorch (2)</title><link>https://dev.to/hyperkai/gaussianblur-in-pytorch-2-1bj2</link><author>Super Kai (Kazuya Ito)</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 04:47:39 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>GaussianBlur in PyTorch (1)</title><link>https://dev.to/hyperkai/gaussianblur-in-pytorch-1-3ndn</link><author>Super Kai (Kazuya Ito)</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 04:35:52 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[The 1st argument for initialization is (Optional-Type: or /()):
*Memos:

A tuple/list must be the 1D with 1 or 2 elements.A single value( or ()) means [kernel_size, kernel_size].The 2nd argument for initialization is (Optional-Default:-Type:,  or /( or )):
*Memos:

It's  so it must be .A tuple/list must be the 1D with 1 or 2 elements.A single value(,  or ( or )) means .The 1st argument is (Required-Type: or ()):
*Memos:

A tensor must be 2D or 3D.]]></content:encoded></item><item><title>Speedrunning Guide: Junior to Staff Engineer in 3 years</title><link>https://blog.algomaster.io/p/speedrunning-guide-junior-to-staff</link><author>Ashish Pratap Singh</author><category>dev</category><category>learning</category><enclosure url="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0173844b-0e38-4ca8-b779-b34f7f778872_1600x413.png" length="" type=""/><pubDate>Sun, 16 Feb 2025 04:30:58 +0000</pubDate><source url="https://blog.algomaster.io/">Algomaster</source><content:encoded><![CDATA[Today’s newsletter features a special guest, , who was promoted from Junior to Staff Engineer at Meta in just 3 years.In this article, Ryan will share his insights on how to fast track your career growth and get promoted faster.Once you land that first software engineering job, the next big question becomes: how do you get promoted? Many engineers fall into the day-to-day routine of writing code without a clear idea of how to grow their careers.This happened to me. At my first job at Amazon, I landed code without knowing what I could do to grow my skills. I left that job within eight months because I felt I wasn’t growing as an engineer. Three years later, I made it to Staff Software Engineer at Instagram after tons of mentorship. Early on, I learned that being good at coding wasn’t enough to get promoted; you have to think strategically about your career and often need to develop new behaviors to move up.In this article, I’ll share everything that helped me fast-track my way up the ladder, from developing the right mindset to making key moves that many overlook. Even if rapid growth isn’t your goal, this guide has learnings for all tech career paths.Software Engineering LevelsAn Algorithm for PromotionJunior (IC3) → Mid-level (IC4)Mid-level (IC4) → Senior (IC5)Senior (IC5) → Staff (IC6)Software Engineering LevelsNote: “IC” = “Individual Contributor”In software engineering, companies measure career progression by levels that measure both behaviors and impact within the company. While the exact titles and structure can vary between companies, most tech companies follow a similar system: - Early in your career, working on smaller, well-defined tasks with guidance from more experienced engineers. - More autonomous, handling moderately complex projects, and beginning to take initiative in improving the codebase and what they build. - Leading larger projects with team-level influence. You’ll mentor and guide the team while having a broad impact on the codebase.: Focusing on cross-team collaboration and solving org-wide challenges. Staff engineers are strategic thinkers who influence the technical direction of their organization.Senior Staff Engineer and Beyond (IC7+): Senior staff engineers and up operate with top technical expertise, driving large-scale initiatives that have a broad impact on the company. Senior staff engineers mentor staff engineers and work closely with executive leadership to meet business objectives.Your impact and compensation increase as you progress, which is a lot more satisfying in my experience. Not to mention that the skills that get you promoted also let you control what you and the company work on.Also, many companies consider only senior engineers (IC5) and higher to be “terminal levels.” You must eventually get promoted to IC5, or you’ll be managed out. Most engineers are promoted in time, so it’s not meant to scare you but to encourage you to grow.An Algorithm For PromotionThere’s a common set of steps across all promotions that will get you to Staff:1) Exceed expectations at your current level - Your manager will be hesitant to find you opportunities at the next level if they have concerns about your performance at the current level. Also, when your manager puts together a promotion packet, it’ll contain a history of your past ratings. The promotion committee will have concerns about your packet if you have a history of only meeting expectations for your level. Work with your manager to understand the expectations for your level and how to exceed them.2) Be direct with your manager about promotion - Once you know you’re exceeding expectations for your level, ask your manager what next-level performance looks like. Your manager plays a huge role in your promotion. They build your case and advocate for it, so they have a lot of influence on this process. Also, the lower the level, the more control your manager has. IC3 -> IC4 promotions are straightforward, so your manager’s perspective is usually what happens. For IC5 -> IC6, there is a lot more ambiguity, so your manager serves more as a middleman between you and the promotion committee. Your manager still plays a significant role in writing your packet and delivering feedback.3) Find next-level scope - If you only work on projects that fit your level’s behaviors, you won’t get any closer to promotion, no matter how good your work is. One simple pattern for finding next-level scope is brainstorming projects with engineers who are 1-2 levels higher than you are. Often, they will have a lot of projects sitting in their backlog that are big enough to help you get promoted. If you take on one of their projects, they’ll often help mentor you, review your designs and code, and give you strong peer feedback for your future promotion packet. I wrote more on this here. Make sure to confirm with your manager that they agree that what you’re working on fits the behaviors of the next level.4) Maintain next-level behaviors and impact - The duration you need to perform at the next level varies depending on your level and your company. At minimum though, you need to maintain that performance for 6-12 months. This is because promotions are “lagging” in tech. You must prove that you’re already operating at the next level before getting promoted. This reduces the risk of failing to meet expectations at the new level.Getting promoted faster is a matter of doing steps (1), (2) and (3) as fast as possible. The best you can do is immediately start exceeding expectations in your first half and working with your manager on the next level.Almost every team has scope for more Senior Engineers (IC5). You can get promoted up to that level if you have the skills and behaviors. Past that, situation and business scope play a much larger role. Many teams don’t need someone who has Staff-level leadership and technical skills. If you find yourself stuck at any point due to your situation, you’ll likely have to switch teams to continue growing your career.Now that you have the algorithm that applies at any of these levels let’s get into the level-specific strategies. I’ll share what got me promoted and what I would change if I did it again.Junior (IC3) → Mid-level (IC4)The main difference between these levels is in the size of the scope that you can handle independently. Here’s a rule of thumb:IC3 - Can handle individual tasks (<2 weeks of work) with minimal guidanceIC4 - Can handle medium-to-large features (<2 months of work) with minimal guidance“Minimal guidance” doesn’t mean that you can’t ask for help—it simply means that you can unblock yourself and make consistent progress. Asking good questions is one of the most effective ways to unblock yourself.You should drive full features and do the project management for them. You should break your project into tasks, set reasonable timelines, and keep stakeholders updated.You will not be expected to come up with the projects yet at this level—Senior Engineers will often outline them. However, at the IC4 level, you’re expected to take more initiative:Initiate refactoring and code cleanups, and give thoughtful code reviews. Leave the code in a better state than you found it.Contributing to production excellence - Participate in the team’s oncall, and help debug production breakages.Own the health of what you build - Add test coverage, logging, and build dashboards to monitor correctness.Optimize your dev velocity to grow faster at this level. Shipping code faster creates a shorter feedback loop, accelerating your learning process. This core skill will help you ship IC4-scope projects and improve as an engineer.Here’s an example of several promotion timelines for what you can expect:Promotion in 6 months (exceptional) - Rare since this means meeting IC4 expectations while onboarding. This is easier for high-performing return interns since they skip onboarding and may have some past track record already.Promotion in 12 months (great) - I’d shoot for this timeline. It’s challenging yet reasonable since it gives you six months to onboard and then start meeting IC4 expectations.Here’s my promotion timeline as an example:H1 (L3 Exceeds Expectations) - First, I took on any task that came my way. These were nice-to-have features that others didn’t have time for. I completed them quickly and started on a larger pipeline rewrite (L4 scope) that my tech lead offered me. Outside of my main project work, I made many contributions to removing dead code and speeding up existing code because I enjoyed it.I started to hit L4 expectations in the last few months of the half. But, since I didn’t have six months track record, I didn’t meet the promotion criteria.H2 (L3→L4 Promotion, Greatly Exceeds Expectations) - I continued driving my L4-scope project independently with high engineering quality. I came up with the idea to build a test harness to validate this rewrite that was “comparable to L5 quality” execution. I continued my passion for improving the codebase and led the company in adding static type annotations that MonkeyType couldn’t.At this point, I had delivered on L4 scope for over six months, so the promotion made sense.What I Would Have Changed:Looking back, I would have discussed what IC4 growth looked like with my manager. I wasted our one-on-one time on project updates instead of career growth. This led to two problems:Spent time on work that wasn’t impactful - I took on any work that was passed my way, even though not all of it was impactful. I probably could’ve gotten more out of my time.Didn’t have accurate expectations - I had another engineer tell me my work was IC4 level and that I should get promoted in my first half. I knew nothing then, so I took their word for it. I was surprised when I didn’t get promoted, which could have been avoided if I had been in sync with my manager.Although I could have been more calculated, writing as much code as I did opened doors. My tech lead trusted me with an IC4 project because I showed I could handle it. Similarly, some of the engineering craft work I did for my own personal pleasure ended up being part of what got me promoted too. The more work you do, the luckier you get.Mid-level (IC4) → Senior (IC5)The IC4 to IC5 gap is larger than the IC3 to IC4 one. This is because IC5 promotion requires significant behavior changes. Raw code output is no longer the top priority. You need to lead and have a larger influence within your team too. Here are a few examples of those differences:Example 1 - Improving the codebaseIC4 - Initiates refactoring and code cleanups.IC5 - Identifies areas of improvement, influences the team to take goals on improving it together, then leads the charge on those goals.Example 2 - Production excellenceIC4 - Participates in team’s oncall and mitigating outages.IC5 - Creates an “oncall improvement” workstream and builds a process for everyone to improve the team’s oncall.Example 3 - Project directionIC4 - Owns the project management of a medium-to-large feature.IC5 - Drives team planning and builds a roadmap of several medium-to-large features.I wouldn’t say the IC5 examples are harder, but they require a mindset shift to own things at the team level.Also, you’ll need to work on projects of sufficient scope for an IC5. There are a few ways that tech companies measure scope. Here’s a comparison of the criteria for IC4 and IC5 levels:These criteria aren’t a checklist. Your work can be IC5 scope by meeting only some of these criteria.IC5 is also the first time engineers begin to focus on growing others. At this level, you should mentor others and build up the team’s culture, which includes driving meetings, knowledge sharing, recruiting activities, and organizing team activities. Starting mentorship relationships early is a good idea since you can’t rush mentorship.If you can learn the above behaviors quickly, you can expect promotion on these timelines:Promotion in 6 months (exceptional) - This is rare since you need to exert team-level influence as soon as you join the team. I could see this happening for someone who was under-leveled and just got promoted to IC4.Promotion in 12 months (great) - If you’re ambitious, I’d aim for this goal. It is possible to do this if you find IC5 scope in your first half. If not, one more half should secure your promotion.Here’s my promotion timeline as an example:H1 (IC4 Exceeds Expectations) - This half I wrapped up the workstream that got me promoted to IC4 and picked up another IC4 project. I spent a ton of time on engineering craft this half because I enjoyed it. I deprecated a few legacy systems that no one else would because they were dangerous and not that impactful. I didn’t exhibit any IC5 behaviors this half.My manager handed me an IC5 workstream (~6 eng) to cut video messaging latency in half, which I led successfully. I also began a side project, which became a multiple-half collaboration with another team. Lastly, I took on an intern who did a phenomenal job helping me execute these two roadmaps I led. Although I started exhibiting IC5 behaviors, the company canceled performance reviews this half because of the pandemic.H3 (IC4 → IC5 Promotion, Greatly Exceeds Expectations) - My impact this half could’ve met expectations at the IC6 level. I doubled down on the cross-org scope I created in H2 and developed a multi-half roadmap. I influenced and led another team to invest several engineers to revamp the IG video ads pipeline with great results. I built out a second workstream and mentored another engineer to deliver it. This half, I had massive impact, team-level influence, and mentorship, which is what got me promoted.The Skill of Tech Leading - If you grew from L3 → L4 right, you should be exceptional at landing code. The L5 behavior of team-level influence is just helping others do the same. In my first half of leading an initiative, I remember feeling unsure about it since I only had two years of experience. Leaning on my strong execution skills helped me become comfortable leading others.Working Hard Led To More Opportunities - I worked a lot and had a ton of workstreams in flight at the same time. This approach increased my chances of having one that had a ton of impact. At the time, I didn’t know it and was just throwing myself at any problems that came my way. Looking back, it was a great way to derisk my promotion. - In my first half as an L4, I took on projects that were time-intensive and not impactful. I did these migrations because I loved cleaning up tech debt. I would’ve had more impact if I had influenced someone else to do them while I found IC5 scope instead.Senior (IC5) → Staff (IC6)Staff Engineers (IC6) are at the same level as engineering managers. They solve problems that few others can and play a critical role in setting team direction. They lead major initiatives and influence the engineering culture of teams around them.Some say that promotion from IC5 → IC6 is harder than IC6 → IC7 due to the significant behavior changes needed. There are a few major differences between IC5 and IC6.1) Influence Across Teams - Staff Engineer’s projects often extend beyond their team. They take on larger problems by influencing other teams without authority.Once IC6s establish these workstreams, they tackle the hardest problems and work through others. They focus on outcomes and don’t always do the work themselves. Working through delegation and influence across teams is the biggest mindset shift from IC5 → IC6.This style of working isn’t limited to their main project impact. IC6s should also use their influence to inspire a culture of higher engineering quality and reliability across teams. - Senior Engineers (IC5) build roadmaps of several medium-to-large features that help achieve their team’s goals. In this case, the problem and its business impact are clear; we just need an engineer to create a plan to solve it.Staff Engineers (L6) handle more ambiguity. They don’t just solve known problems; they create scope by finding impactful opportunities and problems. Managers work with their L6s to expand the scope of the team.- Big tech companies determine what level projects are in a few ways. Here’s a comparison of the criteria for L5 and L6 levels:Project complexity also distinguishes IC6 scope. Problems that IC5s can’t solve are considered IC6 scope. This is why specialists often have IC6+ scope; others often can’t do their projects.These criteria aren’t a checklist. Work can be IC6 scope by meeting only some of these. Your manager will use these criteria to argue that your work is IC6 scope. This is one of the reasons why it’s important to align with your manager on your work’s scope. - Staff engineers uplift others around them. They should have the ability to help IC5 engineers grow. There are a few ways they uplift others:Mentorship - Dedicated mentorship, preferably with senior engineersKnowledge sharing - Writing wikis, giving presentations, contributing to Q&A groupsCollaborations - Growing others while working with them (e.g. code reviews, design reviews, discussions)IC6 engineers should also contribute to growing the organization. This means that they help with recruiting and partner with their manager to improve team health.Getting to the Staff Engineering level can take a long time. Since IC5 is considered “terminal,” there is no external pressure to achieve IC6 fast. However, if you are eager to grow as fast as possible, here’s how fas you can expect promotion:Promotion in 1 half (Ridiculous) - You’d need to start influencing outside your team as soon as you join. Even then, it’s unlikely you’d get promoted this fast unless you create something company-changing.Promotion in 2 halves (Exceptional) - Finding IC6 opportunities on your team is not always possible this fast. It’s a combination of situation and skill to get promoted in two halves, even if you execute well.Promotion in 3 halves (Great) - If you’re ambitious I’d aim for this goal. It gives you a year to find IC6 scope, which is a reasonable amount of time to pivot if needed. Also, your track record of successes in the first year will help build the narrative for promotion.H1 (IC5 Exceeds Expectations) - I led two workstreams that were partnerships with other teams to hit our goals. I also landed a large win in an unplanned ads workstream, which is what brought my rating above expectations. I was also one of the top contributors to code review and interviewing in my 70-person eng org. The hidden success here was that I bootstrapped a new workstream towards the end of the half that was certainly IC6 scope.H2 (IC5 → IC6 Promotion, Greatly Exceeds Expectations) - The IC6 workstream I created turned out to be a massive opportunity. This work was a huge success, resulting in a company-wide award and public recognition from Mark Zuckerberg. I also created a cross-org collaboration between 3 large orgs (70+ eng each), which received positive feedback from each director. Lastly, I ran infrastructure preparations for my org resulting in no major incidents during the most critical time of the year. The repeated influence and impact of these large initiatives is what got me promoted to IC6. - My past context and relationships at Instagram helped me move a lot faster. I could lead several workstreams at once because I knew so much about the codebase. Also, it was easier to get work done in collaboration because I knew partner engineers from past work. Staying at one company for a longer time does have its benefits. - When I was an IC4, I stumbled upon some IC6 scope without realizing it. I had strong initiative so I started solving problems without thinking through why it was impactful. I got lucky that the work had IC6 impact. I’ve since learned the importance of understanding the “why” before diving in. It helps you have consistent IC6 impact and makes it easier to get buy-in for your work.The Tech Lead Skillset Scales Well - In my promotion to Senior (IC5), I learned how to lead initiatives within my team. This skillset turned out to work well at higher levels too. The difference was just that more people were involved. This skill is a great way to continue your IC growth to the highest levels if you fit the “tech lead” archetype.Growth to the Staff level can take a long time, and luck plays a role. As you move up the ladder, each promotion depends more and more on your situation in addition to your skill.There are ways to increase your luck. For instance, you can go to growing companies and teams. You can pick business-critical projects. You can go where the most talented people are. None of these are foolproof, but they increase your chances.Aside from picking your situation, one way to manufacture luck is to do as much good work as you can. Many growth opportunities came to me because of some past work I did. People would reach out to me to do more of it or because they wanted to ask me questions about something I had launched.Although luck plays a role, there are aspects of getting promoted that rely less on luck. Here are four high-level areas:Impact is any measurable and objective outcome that benefits your company. Promotions are a byproduct of your elevated, sustained impact. If you can learn what your organization considers impactful and you deliver that, you will be rewarded.2) Leverage is how you have more impact. Software engineers increase their leverage through people, writing, and code. Leverage is what differentiates higher-level ICs from lower-level ones. What I mean by each type of leverage:People - People leverage comes from technical leadership. This means setting direction, reviewing designs/code, and growing others.Writing - Writing gives us leverage by influencing and helping others without your active involvement.Code - Not all code is created equal. High-leverage code solves problems that few others can or helps engineers move faster at scale. When people hear “personal brand,” their minds often go to social media. But the brand that matters most is your “internal brand.” What do people within your company think about your work and its value? This is the brand that you should care most about.Most of the top ICs I know are not well-known outside of Meta. They are legendary within the company, though because people see their impressive work. Build your internal brand by doing great work and letting others know about it (further reading here).4) Build your soft skills. Working with others is a necessity to do anything of consequence. Also, being someone others want to work with makes it easier to find mentors who will uplift you along the way.Soft skills are underrated among software engineers. It’s important to be an excellent IC, but you can go so much further if you also communicate well. Also, engineers don’t often prioritize soft skills, so having them will help you stand out and lead.One last thing I’ll leave you with is something that I didn’t realize until looking back. When I first joined the industry, I was an absolute machine. I would get in early and stay until the last shuttle left at 9:27 PM. Although this might sound like hell to some people, I loved it. No one made me do that; I put in those hours because I enjoyed the work and thought it was interesting.Looking back years later, I realize that was an unfair advantage I had. It let me put in a ton of work without getting burned out. Also, I got much more out of what I did because I was intrinsically motivated.If there’s one thing I wish for you, it is that you find work at the intersection of what you enjoy and what will get you promoted. That is the best recipe for hyper-career growth.Thanks for reading,Ryan PetermanIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.If you have any questions or suggestions, leave a comment. If you’re enjoying this newsletter and want to get even more value, consider becoming a .]]></content:encoded></item><item><title>Weekly Challenge: Counting the XOR</title><link>https://dev.to/simongreennet/weekly-challenge-counting-the-xor-4hhc</link><author>Simon Green</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 04:23:00 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[Each week Mohammad S. Anwar sends out The Weekly Challenge, a chance for all of us to come up with solutions to two weekly tasks. My solutions are written in Python first, and then converted to Perl. It's a great way for us all to practice some coding.You are given two array of strings,  and .Write a script to return the count of common strings in both arrays.The tasks and examples don't mention what to do if a string appears more than once in both arrays. I've made the assumption that we only need to return it once.For the command line input, I take two strings that are space separated as shown in the example.In Python this is a one liner. I turn the lists into sets (which only has unique values) and take the length of the intersection of these two sets.Perl does not have sets or intersections built in. For the Perl solution, I turn both strings into a hash with the key being the strings. I then iterate through the keys of the first hash to see if they appear in the second hash. If they do, I increment the  variable../ch-1.py 
2

./ch-1.py 
1

./ch-1.py 
0
You are given an encoded array and an initial integer.Write a script to find the original array that produced the given encoded array. It was encoded such that encoded[i] = orig[i] XOR orig[i + 1].This is relatively straight forward. For the command line input, I take the last value as the  integer, and the rest as the  integers.For this task, I create the  list (array in Perl) with the  value. I then iterate over each item in the  list and takes the exclusive-or of it and the last value in the  list../ch-2.py 1 2 3 1
1, 0, 2, 1]

./ch-2.py 6 2 7 3 4
4, 2, 0, 7, 4]
]]></content:encoded></item><item><title>Gixy: Nginx Configuration Static Analyzer</title><link>https://github.com/dvershinin/gixy</link><author>mmsc</author><category>hn</category><pubDate>Sun, 16 Feb 2025 04:06:04 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Real-time Updates Made Easy: Building Server-Sent Events with GoFrame 🚀</title><link>https://dev.to/jones_charles_ad50858dbc0/real-time-updates-made-easy-building-server-sent-events-with-goframe-112b</link><author>Jones Charles</author><category>dev</category><category>go</category><pubDate>Sun, 16 Feb 2025 02:37:08 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Hey there, fellow developers! 👋 Ever needed to add real-time updates to your Go application but found WebSockets a bit too complex for your needs? Enter Server-Sent Events (SSE) - a simpler alternative that's perfect for one-way server-to-client communication.In this guide, I'll walk you through implementing SSE using GoFrame, taking you from basic implementation all the way to production-ready code. Let's dive in!
  
  
  What are Server-Sent Events? 🤔
SSE is a standard that enables servers to push real-time updates to clients over HTTP. Unlike WebSocket, SSE:Is one-way (server to client only)Automatically reconnects if the connection is lostPerfect for: real-time notifications, live feeds, status updates, and monitoring dashboards!
  
  
  Getting Started: Basic SSE Implementation 🌱
Let's start with a simple example. Here's how to create your first SSE endpoint in GoFrame:And here's how to connect from the frontend:
  
  
  Real-World Examples: Let's Build Something Cool! 🛠️
Let's build something more practical - a real-time stock price feed:
  
  
  2. Real-time Chat Room Status 💬
Monitor active users and typing indicators in a chat room:
  
  
  3. System Monitoring Dashboard 📊
Monitor system metrics in real-time:
  
  
  4. Live Order Processing Status ⚡
Track order processing status in real-time:
  
  
  5. Live Sports Score Updates 🏆
Track live game scores and statistics:
  
  
  Making it Production-Ready 🛠️
Keep connections alive with periodic pings:Make your frontend resilient:
  
  
  3. Support Different Event Types 🔄
Handle various types of updates:For distributed systems, use Redis pub/sub to coordinate SSE messages:: When you have frequent updates, batch them together:
: Prevent server overload:
Implement event replay for clients that reconnect:
  
  
  Client Groups and Filtering
Implement client grouping for targeted updates:
  
  
  Rate Limiting and Throttling
Implement rate limiting for high-frequency updates:Use CORS headers in productionAdd authentication for sensitive dataMonitor connection counts and server resourcesTest with different network conditionsSSE is a powerful tool for real-time updates that's often overlooked in favor of WebSockets. For one-way communication, it's simpler, more lightweight, and works great with HTTP/2. With GoFrame, implementing SSE becomes even more straightforward and maintainable.Here's a quick checklist for your SSE implementation:✅ Basic SSE setup with proper headers✅ Error handling and connection management✅ Authentication and authorization✅ Security considerationsYou could extend this implementation by:Adding message persistenceImplementing message replayBuilding client librariesAdding WebSocket fallbackImplementing server-side filteringAdding message prioritizationHave you used SSE in your projects? What challenges did you face? Share your experiences in the comments below! 👇P.S. Want to see the complete code? Check out my GitHub repo [link to be added] for a production-ready implementation!If you found this helpful, follow me for more Go tutorials and real-world examples! ✨]]></content:encoded></item><item><title>Ask Slashdot: What Would It Take For You to Trust an AI?</title><link>https://ask.slashdot.org/story/25/02/15/2047258/ask-slashdot-what-would-it-take-for-you-to-trust-an-ai?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 16 Feb 2025 02:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Long-time Slashdot reader shanen has been testing AI clients. (They report that China's DeepSeek "turned out to be extremely good at explaining why I should not trust it. Every computer security problem I ever thought of or heard about and some more besides.") 

Then they wondered if there's also government censorship:

It's like the accountant who gets asked what 2 plus 2 is. After locking the doors and shading all the windows, the accountant whispers in your ear: "What do you want it to be...?" So let me start with some questions about DeepSeek in particular. Have you run it locally and compared the responses with the website's responses? My hypothesis is that your mileage should differ... 

It's well established that DeepSeek doesn't want to talk about many "political" topics. Is that based on a distorted model of the world? Or is the censorship implemented in the query interface after the model was trained? My hypothesis is that it must have been trained with lots of data because the cost of removing all of the bad stuff would have been prohibitive... Unless perhaps another AI filtered the data first? 
But their real question is: what would it take to trust an AI? "Trust" can mean different things, including data-collection policies. ("I bet most of you trust Amazon and Amazon's secret AIs more than you should..." shanen suggests.) Can you use an AI system without worrying about its data-retention policies?
 

And they also ask how many Slashdot readers have read Ken Thompson's "Reflections on Trusting Trust", which raises the question of whether you can ever trust code you didn't create yourself. So is there any way an AI system can assure you its answers are accurate and trustworthy, and that it's safe to use? Share your own thoughts and experiences in the comments. 
What would it take for you to trust an AI?]]></content:encoded></item><item><title>How Medical Research Cuts Would Hit Colleges and Hospitals in Every State</title><link>https://www.nytimes.com/interactive/2025/02/13/upshot/nih-trump-funding-cuts.html</link><author>erickhill</author><category>hn</category><pubDate>Sun, 16 Feb 2025 02:07:25 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[A proposal by the Trump administration to reduce the size of grants for institutions conducting medical research would have far-reaching effects, and not just for elite universities and the coastal states where many are located.Also at risk could be grants from the National Institutes of Health to numerous hospitals that conduct clinical research on major diseases, and to state universities across the country. North Carolina, Missouri and Pennsylvania could face disproportionate losses, because of the concentration of medical research in those states.Based on spending in the 2024 fiscal year.In the 2024 fiscal year, the N.I.H. spent at least $32 billion on nearly 60,000 grants, including medical research in areas like cancer, genetics and infectious disease. Of that, $23 billion went to “direct” research costs, such as microscopes and researchers’ salaries, according to an Upshot analysis of N.I.H. grant data.The other $9 billion went to the institutions’ overhead, or “indirect costs,” which can include laboratory upkeep, utility bills, administrative staff and access to hazardous materials disposal, all of which research institutions say is essential to making research possible.The N.I.H. proposal, which has been put on hold by a federal court, aims to reduce funding for those indirect costs to a set 15 percent rate that the administration says would save about $4 billion a year. The Upshot analysis estimates that a 15 percent rate would have reduced funding for the grants that received N.I.H. support in 2024 by at least $5 billion. The White House said the savings would be reinvested in more research, but the rate cuts would open up sizable budget holes in most projects at research institutions.It is not clear whether those organizations can fill the gaps with other funding sources or by shifting how they apply for grants. Instead, many officials at universities and hospitals have said that they may have to pull back on medical or scientific research.“It’s not an overstatement to say that a slash this drastic in total research funding slows research,” said Heather Pierce, senior director for science policy at the Association of American Medical Colleges, which has sued along with other education and hospital associations to block the policy. And slower scientific progress, she said, would affect anyone who depends on the development of new treatments, medical interventions and diagnostic tools.We estimate that virtually all universities and hospitals would see fewer funds on similar projects in the future. The 10 institutions that receive the most money from N.I.H. stand to lose more than $100 million per year on average.To understand how the change would work, let’s look at one grant for about $600,000 sent last year to the University of Alabama at Birmingham to study whether exercise can improve memory for people with epilepsy.The calculation above, which we have repeated for every grant paid last year, is a bit simplified. In reality, the researchers would lose even more money than we’ve shown, because of the way indirect funding is calculated (see our methodology at the bottom of this article).Our analysis also makes some other conservative assumptions given the policy’s uncertainty. We assume, for instance, that the new 15 percent rate is a flat rate that all grantees would receive, and not a maximum rate (a distinction left unclear in the N.I.H. guidance). We also assume that the change applies not just to institutions of higher education, but also to all kinds of grantees, including hospitals.In a statement, the White House indicated it would reserve any savings for additional research grants. “Contrary to the hysteria, redirecting billions of allocated N.I.H. spending away from administrative bloat means there will be more money and resources available for legitimate scientific research, not less,” said Kush Desai, a White House spokesman.The N.I.H. announcement, however, coincides with the Trump administration’s moves to cut spending across the government, and with the N.I.H.’s withholding of funding for grants — their direct and indirect costs alike — in apparent conflictwith separate court orders.The N.I.H. guidance document includes a number of conflicting statements and statistics the Upshot could not reconcile. The N.I.H. also declined to answer questions about the policy and about its public-facing data tracking grant spending.The N.I.H. since 1950 has provided these overhead funds in a formulaic way, and since 1965, the government has used a rate individually calculated for each institution. Federal officials review cost summaries, floor plans and other information to determine that rate. That number can be higher for institutions in more expensive parts of the country, or for those that use more energy-intensive equipment. The proposal from the Trump administration would set aside those differences in standardizing the rate at 15 percent for every grantee.The lists below estimate what would have happened to the 10 universities and hospitals that received the most N.I.H. grant money in the 2024 fiscal year, if the formula change had been in effect then.Largest N.I.H. grant recipients among colleges, universities and medical schoolsUniversity of California, San FranciscoUniversity of PennsylvaniaColumbia University Health SciencesSource: National Institutes of HealthBased on spending in the 2024 fiscal year.Largest N.I.H. grant recipients among hospitalsMassachusetts General HospitalVanderbilt University Medical CenterBrigham and Women’s HospitalBoston Children’s HospitalUniversity of Texas MD Anderson Cancer CenterChildren’s Hospital of PhiladelphiaDana-Farber Cancer InstituteCincinnati Childrens Hospital Medical CenterBeth Israel Deaconess Medical CenterCedars-Sinai Medical CenterSource: National Institutes of HealthBased on spending in the 2024 fiscal year, which extends from Oct. 1 to Sept. 30.If courts allow the change to move forward, some of its consequences are hard to predict.Advocates for the policy change note that these organizations receive numerous other federal subsidies. Most universities and research hospitals are nonprofits that pay no federal taxes, for example. The N.I.H. announcement also noted that these same institutions often accept grants from charitable foundations that offer much lower overhead rates than the federal government, a signal that universities and hospitals willingly pursue research opportunities with less supplemental funding.Because the indirect payments are based on broad formulas and not specific line items, critics say institutions may be diverting these federal dollars into unaccountable funds to pay for programs that taxpayers can’t see, such as the kinds of diversity, equity and inclusion programs targeted by the Trump administration.“That’s how you get things like the ability of administrators to use larger overhead pools of money to build out D.E.I. bureaucracies, or to fund Ph.D. programs in the humanities,” said Jay Greene, a senior research fellow in the Center for Education Policy at the Heritage Foundation, a conservative research group. Mr. Greene was the coauthor of a 2022 article urging the N.I.H. to cut or eliminate indirect grant funding. But he did not have specific examples to cite of research funds being spent in this way.Researchers say the indirect funds have a branding problem, but are a necessary component of research.“The term ‘indirect costs’ or the alternative term ‘overhead’ sounds dangerously close to ‘slush fund’ to some people,” said Jeremy Berg, who was the director of the National Institute of General Medical Sciences at the N.I.H. from 2003 to 2011. “There are real costs somebody has to pay for, and heating and cooling university laboratory buildings is a real cost.”Some grant recipients already receive low overhead payments, but a large majority of them currently receive more than 15 percent, meaning they will need to make budgetary changes to absorb the loss. Among the 2024 grants that we analyzed, institutions that received more than $1 million in N.I.H. support got an average of 40 cents of indirect funding for every dollar of direct funding.Distribution of overhead funding at N.I.H.-funded institutions in 2024As a share of direct fundingSource: National Institutes of HealthCalculated for 613 institutions that received at least $1 million in funding in fiscal year 2024. Federally negotiated rates are higher than these.Universities and hospitals may adjust their overall budgets to keep supporting medical research by cutting back on other things they do. Some might be able to raise money from donors to fill the shortfalls, though most universities are already raising as much philanthropic money as they can.But many research institutions have said they would adjust by simply doing less medical research, because they would not be able to afford to do as much with less government help.Universities and hospitals might also shift the kinds of research they do, avoiding areas that require more lab space, regulatory compliance or high-tech equipment, and focusing on types of research that will require them to provide less overhead funding themselves. That may mean disproportionate reductions in complex areas of research like genetics.Those effects may be spread unevenly across the research landscape, as some organizations find a way to adjust, while others abandon medical research altogether.We’ve compiled a list of institutions that received at least $1 million in N.I.H. funding in the 2024 fiscal year, along with our estimates of how much less they would have gotten under the new policy. Most of these institutions are universities or hospitals, but there are also some private companies and nonprofit research groups. Our numbers tend to be underestimates of the cuts.To estimate changes in funding, we relied on data from RePORT, the N.I.H.’s online registry of grants and projects. We limited our analysis to grants listed within the 50 U.S. states, the District of Columbia or Puerto Rico. We also limited it to grants where the amount of indirect funding was known and where the combined indirect and direct funding was within five percent of the listed total funding. These filters resulted in removing many grants to private organizations such as domestic for-profits.We calculated how much indirect funding each grant would have received under the new guidance by multiplying the listed direct funding amount by 15 percent. We then compared that number to the listed indirect funding amount for each great to estimate the impact of the policy.There are two reasons our calculations are most likely conservative estimates of true reductions in funding. First, only a portion of the direct funding for each grant is considered to be “eligible” for the purposes of calculating indirect funding. For example, laboratory equipment and graduate student tuition reimbursements are deducted from the direct costs before applying the negotiated overhead rate, whereas our calculations assumed 100 percent of the listed direct costs would be eligible. We performed a more accurate version of our calculations for the 10 universities and 10 hospitals receiving the most N.I.H. funds by inferring their eligible direct costs from their reported negotiated rates. When we did this, we saw an additional increase in losses of about 20 percent.Second, we applied a 15 percent rate to all grants in the database, including those with an initial indirect rate  15 percent. An analysis by James Murphy helped inform this approach. According to our analysis, then, some grants would actually receive more money under the new guidance. If the new rate operated more like a cap — and grants with rates currently below 15 percent did not change — the overall reductions in funding would be larger, as the reductions would no longer be offset by some small number of funding increases.]]></content:encoded></item><item><title>FreeBSD 13.5 Overcomes UFS Y2038 Problem To Push It Out To Year 2106</title><link>https://www.phoronix.com/news/FreeBSD-13.5-Beta-2</link><author>Michael Larabel</author><category>tech</category><pubDate>Sun, 16 Feb 2025 01:30:45 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[Following last week's FreeBSD 13.5 Beta 1 release to kick off this next FreeBSD 13 point release that will also end the series, FreeBSD 13.5 Beta 2 is out this weekend for testing...]]></content:encoded></item><item><title>The Sims Game Design Documents (1997)</title><link>https://donhopkins.com/home/TheSimsDesignDocuments/</link><author>krykp</author><category>hn</category><pubDate>Sun, 16 Feb 2025 01:06:11 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Show HN: Blunderchess.net – blunder for your opponent every five moves</title><link>https://blunderchess.net/</link><author>eviledamame</author><category>hn</category><pubDate>Sun, 16 Feb 2025 00:22:01 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Despite Plans for AI-Powered Search, Reddit&apos;s Stock Fell 14% Thsi Week</title><link>https://tech.slashdot.org/story/25/02/16/007234/despite-plans-for-ai-powered-search-reddits-stock-fell-14-thsi-week?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 16 Feb 2025 00:09:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA["Reddit Answers" uses generative AI to answer questions using what past Reddittors have posted. Announced in December, Reddit now plans to integrate it into their search results, reports TechCrunch, with Reddit's CEO saying the idea has "incredible monetization potential." 

And yet Reddit's stock fell 14% this week. CNBC's headline? "Reddit shares plunge after Google algorithm change contributes to miss in user numbers."


A Google search algorithm change caused some "volatility" with user growth in the fourth quarter, but the company's search-related traffic has since recovered in the first quarter, Reddit CEO Steve Huffman said in a letter to shareholders. "What happened wasn't unusual — referrals from search fluctuate from time to time, and they primarily affect logged-out users," Huffman wrote. "Our teams have navigated numerous algorithm updates and did an excellent job adapting to these latest changes effectively...." Reddit has said it is working to convince logged-out users to create accounts as logged-in users, which are more lucrative for its business. 


As Yahoo Finance once pointed out, Reddit knew this day would come, acknowledging in its IPO filing that "changes in internet search engine algorithms and dynamics could have a negative impact on traffic for our website and, ultimately, our business." And in the last three months of 2024 Reddit's daily active users dropped, Yahoo Finance reported this week. But logged-in users increased by 400,000 — while logged-out users dropped by 600,000 (their first drop in almost two years). 

Marketwatch notes that analyst Josh Beck sees this as a buying opportunity for Reddit's stock:
Beck pointed to comments from Reddit's management regarding a sharp recovery in daily active unique users. That was likely driven by Google benefiting from deeper Reddit crawling, by the platform uncollapsing comments in search results and by a potential benefit from spam-reduction algorithm updates, according to the analyst. "While the report did not clear our anticipated bar, we walk away encouraged by international upside," he wrote.
]]></content:encoded></item><item><title>Despite Plans for AI-Powered Search, Reddit&apos;s Stock Fell 14% This Week</title><link>https://tech.slashdot.org/story/25/02/16/007234/despite-plans-for-ai-powered-search-reddits-stock-fell-14-this-week?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sun, 16 Feb 2025 00:09:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA["Reddit Answers" uses generative AI to answer questions using what past Reddittors have posted. Announced in December, Reddit now plans to integrate it into their search results, reports TechCrunch, with Reddit's CEO saying the idea has "incredible monetization potential." 

And yet Reddit's stock fell 14% this week. CNBC's headline? "Reddit shares plunge after Google algorithm change contributes to miss in user numbers."


A Google search algorithm change caused some "volatility" with user growth in the fourth quarter, but the company's search-related traffic has since recovered in the first quarter, Reddit CEO Steve Huffman said in a letter to shareholders. "What happened wasn't unusual — referrals from search fluctuate from time to time, and they primarily affect logged-out users," Huffman wrote. "Our teams have navigated numerous algorithm updates and did an excellent job adapting to these latest changes effectively...." Reddit has said it is working to convince logged-out users to create accounts as logged-in users, which are more lucrative for its business. 


As Yahoo Finance once pointed out, Reddit knew this day would come, acknowledging in its IPO filing that "changes in internet search engine algorithms and dynamics could have a negative impact on traffic for our website and, ultimately, our business." And in the last three months of 2024 Reddit's daily active users dropped, Yahoo Finance reported this week. But logged-in users increased by 400,000 — while logged-out users dropped by 600,000 (their first drop in almost two years). 

Marketwatch notes that analyst Josh Beck sees this as a buying opportunity for Reddit's stock:
Beck pointed to comments from Reddit's management regarding a sharp recovery in daily active unique users. That was likely driven by Google benefiting from deeper Reddit crawling, by the platform uncollapsing comments in search results and by a potential benefit from spam-reduction algorithm updates, according to the analyst. "While the report did not clear our anticipated bar, we walk away encouraged by international upside," he wrote.
]]></content:encoded></item><item><title>Create a QubesOS Gaming HVM with GPU PCI passthrough (2023)</title><link>https://forum.qubes-os.org/t/create-a-gaming-hvm/19000</link><author>transpute</author><category>hn</category><pubDate>Sat, 15 Feb 2025 22:48:56 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>China&apos;s &apos;Salt Typhoon&apos; Hackers Continue to Breach Telecoms Despite US Sanctions</title><link>https://it.slashdot.org/story/25/02/15/2244220/chinas-salt-typhoon-hackers-continue-to-breach-telecoms-despite-us-sanctions?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 15 Feb 2025 22:47:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA["Security researchers say the Chinese government-linked hacking group, Salt Typhoon, is continuing to compromise telecommunications providers," reports TechCrunch, "despite the recent sanctions imposed by the U.S. government on the group." 

TechRadar reports that the Chinese state-sponsored threat actor is "hitting not just American organizations, but also those from the UK, South Africa, and elsewhere around the world."




The latest intrusions were spotted by cybersecurity researchers from Recorded Future, which said the group is targeting internet-exposed web interfaces of Cisco's IOS software that powers different routers and switches. These devices have known vulnerabilities that the threat actors are actively exploiting to gain initial access, root privileges, and more. More than 12,000 Cisco devices were found connected to the wider internet, and exposed to risk, Recorded Future further explained. However, Salt Typhoon is focusing on a "smaller subset" of telecoms and university networks. 

"The hackers attempted to exploit vulnerabilities in at least 1,000 Cisco devices," reports NextGov, "allowing them to access higher-level privileges of the hardware and change their configuration settings to allow for persistent access to the networks they're connected on... Over half of the Cisco appliances targeted by Salt Typhoon were located in the U.S., South America and India, with the rest spread across more than 100 countries."
Between December and January, the unit, widely known as Salt Typhoon, "possibly targeted" — based on devices that were accessed — offices in the University of California, Los Angeles, California State University, Loyola Marymount University and Utah Tech University, according to a report from cyber threat intelligence firm Recorded Future... The Cisco devices were mainly associated with telecommunications firms, but 13 of them were linked to the universities in the U.S. and some in other nations... "Often involved in cutting-edge research, universities are prime targets for Chinese state-sponsored threat activity groups to acquire valuable research data and intellectual property," said the report, led by the company's Insikt Group, which oversees its threat research. 

The cyberspies also compromised Cisco platforms at a U.S.-based affiliate of a prominent United Kingdom telecom operator and a South African provider, both unnamed, the findings added. The hackers also "carried out a reconnaissance of multiple IP addresses" owned by Mytel, a telecom operator based in Myanmar... 

"In 2023, Cisco published a security advisory disclosing multiple vulnerabilities in the web UI feature in Cisco IOS XE software," a Cisco spokesperson said in a statement. "We continue to strongly urge customers to follow recommendations outlined in the advisory and upgrade to the available fixed software release."

]]></content:encoded></item><item><title>Jellyfin: The Free Software Media System</title><link>https://jellyfin.org/</link><author>doener</author><category>hn</category><pubDate>Sat, 15 Feb 2025 22:39:19 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[Jellyfin is Free Software, licensed under the GNU GPL. You can use it, study it, modify it, build it, and distribute it for free, as long as your changes are licensed the same way.The project relies entirely on contributions from volunteers. Want to help out? There’s lots of ways to do so, and you don’t even have to code! See our contribution guide for more details.The Jellyfin server and official clients are free to download, now and always. There are no costs, hidden or otherwise, to use Jellyfin, either for yourself, for your friends, or for your company. All our incidental costs are paid through donations from users like you.Jellyfin has no tracking, phone-home, or central servers collecting your data. We believe in keeping our software open and transparent. We’re also not in the media business, so the only media you see is your own.]]></content:encoded></item><item><title>North Carolina Amazon workers vote against unionizing</title><link>https://techcrunch.com/2025/02/15/north-carolina-amazon-workers-vote-against-unionizing/</link><author>Anthony Ha</author><category>tech</category><pubDate>Sat, 15 Feb 2025 22:15:33 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Workers at an Amazon warehouse in Garner, North Carolina voted against unionizing in election results announced today. According to Carolina Amazonians United for Solidarity and Empowerment (CAUSE), the worker group seeking to form the union, 3,276 ballots were cast in the election, with 25.3% of votes in favor of unionizing and 74.7% against. The results […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Infocon: green</title><link>https://isc.sans.edu/diary.html?rss</link><author></author><category>infosec</category><pubDate>Sat, 15 Feb 2025 21:40:03 +0000</pubDate><source url="https://isc.sans.edu/">Sans Edu Diaries</source><content:encoded><![CDATA[The Danger of IP Volatility]]></content:encoded></item><item><title>The World&apos;s Most Printed 3D Model, 3DBenchy, Is Now Public Domain</title><link>https://hardware.slashdot.org/story/25/02/15/1949206/the-worlds-most-printed-3d-model-3dbenchy-is-now-public-domain?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 15 Feb 2025 21:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Hackaday reports:

Good news for everyone who cannot get enough from improbably shaped boats that get referred to as a bench: the current owner (NTI Group) of the copyright has announced that 3DBenchy has been released into the public domain. This comes not too long after Prusa's Printables website had begun to purge all derived models to adhere to the 'no derivatives' license. According to NTI, the removal of these derived models was not requested by NTI, but by a third-party report, unbeknownst to NTI or the original creator of the model. Recognizing its importance to the community, 3DBenchy can now be downloaded & modified freely. 


NTI worked together with the original creator [Daniel Norée] and former Creative Tools CEO [Paulo Kiefe] to transition 3DBenchy and the associated website to the public domain

More details at Tom's Hardware and Fabbaloo.]]></content:encoded></item><item><title>Watt The Fox?</title><link>https://h.43z.one/blog/2025-02-12/</link><author>h43z</author><category>hn</category><pubDate>Sat, 15 Feb 2025 21:32:13 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[It's not nothing—about 1.5 Watt more.So, with a heavy heart, I decided to disable email notifications—even though I really wanted to keep them—but eliminating the white noise was my priority.I thought I had “fixed” the problem. Of course, I blamed Microsoft, right?But the red sound indicator on my i3 status bar kept lighting up occasionally.
    And it turned out other websites were also triggering the white noise.For instance, as soon as I clicked anywhere on x.com, the noise started. Similarly, whenever I listened to a translation on translate.google.com, there was the noise.So now I was really curious. What is going on here.I started to look up how you can play audio with HTML/JavaScript.
    There seem to be two ways: Either with the  tag or the WebAudio API.As Outlook plays sound dynamically, I knew it must use the WebAudio API.
    And to do anything with audio, you first have to create an .const audioCtx = new AudioContext();And already here I realized the problem. Just creating this AudioContext makes my speakers play white noise.The MDN article is pretty clear about it.AudioContext.suspend()
Suspends the progression of time in the audio context, temporarily halting audio hardware access and reducing CPU/battery usage in the process.

AudioContext.resume()
Resumes the progression of time in an audio context that has previouslyYet, most websites never bother suspending the AudioContext and create one without the immediate need for playing sound.Chrome stops the battery/CPU waste automatically afte some time. Firefox not. It just keeps playing the whitenoise.I understand that the websites are to blame here.But still, Cmon Firefox, protect me from this resource theft?!Oh and btw I suspect this also wastes my bluetooth headphones battery if they are connected?! Once I do a click on x.com the sending of white noise starts.To address this total mess, I created an extension that automatically suspends the AudioContext while also
tries to resume it if the websites wants to play sound.It's not perfect as resuming takes a little bit of time and it
  may not always resume, as there are multiple paths to starting audio. But it's good enough for me.Some Relevant Bugzilla reports

More fun stuff at h.43z.one.
Unshadow ban me at 𝕏]]></content:encoded></item><item><title>The European Vat Is Not a Discriminatory Tax Against US Exports</title><link>https://taxfoundation.org/blog/trump-reciprocal-tariffs-eu-vat-discriminatory/</link><author>dzogchen</author><category>hn</category><pubDate>Sat, 15 Feb 2025 21:20:34 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[The Trump administration has once again floated the idea of “reciprocal” tariffs on foreign countries. While it is unclear what formula the administration will use to determine what is “reciprocal,” the intention of responding to foreign charges—real and perceived—is clear enough.In the past, the administration has made general assertions about different  and nontariff barriers that American exporters face that should be rectified by “reciprocal” US tariffs. Trump commonly mentions that the EU charges a 10 percent import  on US vehicles while the US only levies a 2.5 percent tariff on European cars coming into the US. Though one can certainly find examples of higher trade barriers abroad, the overall tariff gap between the US and its trading partners is relatively minor—and any increase in US tariffs will ultimately be paid by US businesses and consumers.  However, when discussing trade with the EU specifically, White House deputy chief of staff, Stephen Miller, added a new policy grievance to the mix: value-added taxes (VAT).  “Did you know when you ship a car from the US to Europe, if they let it in at all because they have many nontariff barriers, between the VAT and duties, that car is taxed at 30%? The German car—or a European car sent the America is taxed at 2.5%—or basically 0.”His statement assumes that a VAT discriminates against American car exports like a tariff, and conversely, that the VAT rebate provided to European car producers exporting to the US constitutes a subsidy and the car then simply faces a tariff and no VAT. (It is worth noting that both a domestic automobile and a European car sold in the US would face US state .)  may seem like a compelling political argument to justify across-the-board tariffs on the EU, it instead reflects a complete misunderstanding of what a VAT is and how it works. Worse, it misplaces the blame for a lack of US competitiveness on the European VAT instead of reevaluating the flaws of both the US federal and state tax systems.  What is VAT and how does it work for exported goods?VATs are border-adjusted, meaning they rebate tax on exports and impose tax on imports. Despite the appearance of subsidizing exports and punishing imports, however, a border-adjusted VAT is trade neutral. A border adjusted tax leads to currency appreciation for the imposing country, which would make it cheaper to import goods, more expensive to export goods, and thus would cancel out the apparent benefits of the tax on imports and the rebate on exports.If there is a complaint to be made about tax policy and implications for US competitiveness in Europe, it is about uncompetitive state sales tax structures in the US system that yield what is known as “.”What is US sales tax and how does it work for exported goods? Unlike most countries, the United States does not impose a broad-based  at the national (federal) level, and state-level consumption taxes are designed as general sales taxes rather than value-added taxes. Whereas a VAT is imposed on the incremental increase in value of a good or service at each stage of production, a sales tax is imposed on the total transaction price of any taxed good or service.If a sales tax is imposed exclusively on final consumption, then VATs and sales taxes are economically identical. However, when the sales tax is applied to some intermediate transactions (“business inputs”), it results in tax pyramiding, where the tax is embedded in the price multiple times over.Consider the following example of a 5 percent VAT and two versions of a 5 percent sales tax—one which only applies to final consumption, and one which applies to certain intermediate transactions as well.VATs and Ideal Sales Taxes are Economically IdenticalA 5% VAT compared to a 5% ideal sales tax and a 5% sales tax with business input taxationNote that, while a VAT is imposed at every stage of the process, the net effect is to apply the rate one time to the final sales price. The tax is collected in increments (on the “value added” at each stage), but unlike with a pyramiding sales tax, it does not double tax inputs. The VAT and ideal sales tax share an identical  and, if imposed at the same rates, yield identical collections.US sales taxes are typically destination-based, meaning that the tax is owed where the product is received or consumed. If a European resident orders from a US retailer, they do not pay US sales tax, just like a US consumer can obtain a VAT rebate on purchases of European products. Neither is a subsidy. These are simply consumption taxes falling on the consumer.In practice, however, US sales taxes diverge sharply from the ideal. More than 40 percent of US sales tax revenue comes from intermediate transactions, which impose costs on US producers. This design flaw is not present in VATs, which do not double-tax intermediate transactions. Consequently, the sales tax imposes a penalty on domestic production that a VAT (or a better designed sales tax) would not. European VATs aren’t subsidizing anything—US states are just shooting themselves in the foot.Crucially, this is true in domestic as well as international sales. If a state’s sales tax only applied to final consumption, it would never put in-state businesses at a disadvantage against rivals in other states, because consumers elsewhere are subject to their own state’s sales tax. A Maryland resident pays 6 percent sales tax on whatever she orders (that’s subject to Maryland’s sales tax), regardless of whether she buys from a retailer in Maryland, or Delaware (with no sales tax), or Louisiana (with an average rate north of 10 percent). But when Maryland taxes business inputs, that imposes a cost on Maryland businesses that could be mitigated if businesses operated in lower-tax states or in states which include fewer inputs in their tax base.The disadvantages created by the sales tax, therefore, aren’t unique to goods exported abroad. They aren’t the consequence of trade policy, but of poor tax policy. Europe’s VATs are not tariffs and are not subsidizing European exports. Instead, US states’ poorly-designed sales taxes are harming their own businesses’ competitiveness—whether they’re selling down the street, across state lines, or around the world.What competitiveness issues remain with the US federal tax system?Just like state sales tax systems can create a competitive disadvantage for producers, certain elements of the federal income tax system harm incentives to invest domestically. Despite progress made by the 2017 Tax Cuts and Jobs Act, the US maintains long  schedules for structures investment, now requires amortization for research and development expenses, and is phasing out  for machinery and equipment investment. The absence of full, immediate deductions for investment increases the cost of capital, and thus discourages investment and wage growth.Rather than focus on raising tariffs, which increase the cost of operating in the United States and reduce total output and productivity, fiscal policy reforms to improve the structure of the federal income tax system can better boost competitiveness of the US manufacturing sector.Countries have many reasons why they apply different tariff rates to different products. In the case of the United States, some tariffs date back to the 1930s Smoot-Hawley tariff schedule, while other US trade barriers take on non-tariff forms. The Trump administration appears to be moving in a “reciprocal” policy direction despite the significant negative economic consequences for American consumers of across-the-board tariffs on goods coming into the US. However, the EU’s VAT system should not be used as a justification for retaliatory tariffs. Stay informed on the tax policies impacting you.Subscribe to get insights from our trusted experts delivered straight to your inbox.Subscribe]]></content:encoded></item><item><title>Design, Manufacturing and Open-Loop Control of a Soft Pneumatic Arm: Bending Experiments</title><link>https://hackernoon.com/design-manufacturing-and-open-loop-control-of-a-soft-pneumatic-arm-bending-experiments?source=rss</link><author>EScholar: Electronic Academic Papers for Scholars</author><category>tech</category><pubDate>Sat, 15 Feb 2025 21:00:03 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) Jorge Francisco Garcia-Samartın, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain (jorge.gsamartin@upm.es);(2) Adrian Rieker, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain;(3) Antonio Barrientos, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain.3 PAUL: Design and Manufacturing 4 Data Acquisition and Open-Loop Control The first experiment consisted of analysing the deflection of a segment versus swelling time. For this purpose, one of the bladders was inflated continuously, in intervals of 100 ms. For each time, PAUL end coord\
where x0 and y0 denote initial position of PAUL end.\
Since the weight of the subsequent modules influences the behaviour of the first segment, the experiment was repeated by placing first one and then two additional segments. The results are shown in Figure 18.\
As can be seen, PAUL is capable of bending up to 40◦ to its vertical axis and the addition of new segments does not cause any noticeable decrease in its bending capacity.\
Although it remains far from the 80◦ of [28] or the 70◦ of [32], Pneunet segments and therefore more flexible, this is an acceptable bending capacity. Moreover, the fact that it does not substantially lose its bending capacity by adding segments makes it possible to concatenate bending movements and thus overcome obstacles that a rigid robot would not be able to overcome.\
In conjunction with this, a validation test was proposed whose purpose was to demonstrate PAUL’s ability to flex thanks to its deformable geometry. The aim was to point points in lateral planes. The results of this experiment are shown in Figure 19. The images, extracted from the video of Appendix A, show how the manipulator can adopt different shapes, is able to bend up to 40◦ and adapt, in case of obstacles, to a wide variety of geometries, which undoubtedly makes PAUL a fundamental ally in inspection and exploration operations in very cluttered environments.]]></content:encoded></item><item><title>Apple Intelligence could arrive on Vision Pro in April</title><link>https://techcrunch.com/2025/02/15/apple-intelligence-could-arrive-on-vision-pro-in-april/</link><author>Anthony Ha</author><category>tech</category><pubDate>Sat, 15 Feb 2025 20:56:08 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Apple is planning to add Apple Intelligence to its Vision Pro headset in an update that could come as early as April, according to Bloomberg’s Mark Gurman. Just a couple weeks after Apple Intelligence was first announced in June 2024, Gurman reported that Apple was looking to bring its suite of AI tools to the […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>America&apos;s Office-Occupancy Rates Drop by Double Digits - and More in San Francisco</title><link>https://it.slashdot.org/story/25/02/15/1716204/americas-office-occupancy-rates-drop-by-double-digits---and-more-in-san-francisco?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 15 Feb 2025 20:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[SFGate shares the latest data on America's office-occupancy rates:

According to Placer.ai's January 2025 Office Index, office visits nationwide were 40.2% lower in January 2025 compared with pre-pandemic numbers from January 2019. 

But San Francisco is dragging down the average, with a staggering 51.8% decline in office visits since January 2019 — the weakest recovery of any major metro. Kastle's 10-City Daily Analysis paints an equally grim picture. From Jan. 23, 2025, to Jan. 28, 2025, even on its busiest day (Tuesday), San Francisco's office occupancy rate was just 53.7%, significantly lower than Houston's (74.8%) and Chicago's (70.4%). And on Friday, Jan. 24, office attendance in [San Francisco] was at a meager 28.5%, the worst of any major metro tracked... 


Meanwhile, other cities are seeing much stronger rebounds. New York City is leading the return-to-office trend, with visits in January down just 19% from 2019 levels, while Miami saw a 23.5% decline, per Placer.ai data. 

"Placer.ai uses cellphone location data to estimate foot traffic, while Kastle Systems measures badge swipes at office buildings with its security systems..."]]></content:encoded></item><item><title>NASA has a list of 10 rules for software development</title><link>https://www.cs.otago.ac.nz/cosc345/resources/nasa-10-rules.htm</link><author>vyrotek</author><category>hn</category><pubDate>Sat, 15 Feb 2025 20:24:13 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[NASA has a list of 10 rules for software developmentThose rules were written from the point of view of people writing
embedded software for extremely expensive spacecraft, where tolerating
a lot of programming pain is a good tradeoff for not losing a mission.
I do not know why someone in that situation does not use the SPARK
subset of Ada, which subset was explicitly designed for verification,
and is simply a better starting point for embedded programming than C.
I am criticising them from the point of view of people writing
programming language processors (compilers, interpreters, editors)
and application software.
We are supposed to teach critical thinking.  This is an example.
How have Gerard J. Holzmann's and my different contexts affected
our judgement?
Can you blindly follow his advice without considering 
context?
Can you blindly follow  advice without considering
your context?
Would these rules necessarily apply to a different/better
programming language?  What if function pointers
were tamed?  What if the language provided opaque abstract
data types as Ada does?
1. Restrict all code to very simple control flow constructs —
do not use  statements,
 or  constructs,
and direct or indirect .Note that  and 
are how C does exception handling, so this rule bans any use
of exception handling.

It is true that banning recursion and jumps and loops without
explicit bounds means that you  your program is
going to terminate.  It is also true that recursive functions
can be proven to terminate about as often as loops can, with
reasonably well-understood methods.  What's more important here is
that “sure to terminate” does not imply
“sure to terminate in my lifetime”:
    int const N = 1000000000;
    for (x0 = 0; x0 != N; x0++)
    for (x1 = 0; x1 != N; x1++)
    for (x2 = 0; x2 != N; x2++)
    for (x3 = 0; x3 != N; x3++)
    for (x4 = 0; x4 != N; x4++)
    for (x5 = 0; x5 != N; x5++)
    for (x6 = 0; x6 != N; x6++)
    for (x7 = 0; x7 != N; x7++)
    for (x8 = 0; x8 != N; x8++)
    for (x9 = 0; x9 != N; x9++)
        -- do something --;
This does a bounded number of iterations.  The bound is N.
In this case, that's 10.  If each iteration of the loop body
takes 1 nsec, that's 10 seconds, or about 7.9×10
years.  What is the  difference between “will stop
in 7,900,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000
years” and “will never stop”?

Worse still, taking a problem that is  expressed
using recursion and contorting it into something that manipulates an
explicit stack, while possible, turns clear maintainable code into
buggy spaghetti.  (I've done it, several times.  There's an example
on this web site.  It is  a good idea.)

2. All loops must have a fixed upper-bound.  It must be trivially
possible for a checking tool to prove statically that a preset
upper-bound on the number of iterations of a loop cannot be exceeded.
If the loop-bound cannot be proven statically, the rule is considered
violated.This is an old idea.  As the example above shows, it is not enough
by itself to be of any practical use.  You have to try to make the
bounds reasonably , and you have to regard hitting an
artificial bound as a run-time error.

By the way, note that putting depth bounds on recursive procedures
makes them every bit as safe as loops with fixed bounds.

3. Do not use dynamic memory allocation after initialization.This is also a very old idea.  Some languages designed for embedded
work don't even  dynamic memory allocation.  The big
thing, of course, is that embedded applications have a fixed amount of
memory to work with, are never going to get any more, and should not
crash because they couldn't handle another record.

Note that the rationale actually supports a much stronger rule:
don't even  dynamic memory allocation.  You can of
course manage your own storage pool:
    typedef struct Foo_Record *foo;
    struct Foo_Record {
	foo next;
	...
    };
    #define MAX_FOOS ...
    static struct Foo_Record foo_zone[MAX_FOOS];
    foo foo_free_list = 0;

    void init_foo_free_list() {
	for (int i = MAX_FOOS - 1; i >= 0; i--) {
	    foo_zone[i].next = foo_free_list;
	    foo_free_list = &foo_zone[i];
	}
    }

    foo malloc_foo() {
	foo r = foo_free_list;
	if (r == 0) report_error();
	foo_free_list = r->next;
	return r;
    }

    void free_foo(foo x) {
	x->next = foo_free_list;
	foo_free_list = x;
    }
This  satisfies the rule, but it
violates the  of the rule.  Simulating malloc()
and free() this way is  than using the real
thing, because the memory in foo_zone is permanently tied up
for Foo_Records, even if we don't need any of those at the
moment but do desperately need the memory for something else.

What you really need to do is to use a memory allocator
with known behaviour, and to prove that the amount of memory
in use at any given time (data bytes + headers) is bounded
by a known value.

Note also that SPlint can verify at compile time that
the errors NASA speak of do not occur.

One of the reasons given for the ban is that the performance
of malloc() and free() is unpredictable.  Are these the only
functions we use with unpredictable performance?  Is there
anything about malloc() and free() which makes them
 unpredictable?  The existence of
hard-real-time garbage collectors suggests not.

The rationale for this rule says that

Note that the only way
to dynamically claim memory in the absence of memory allocation from the
heap is to use stack memory.  In the absence of recursion (Rule 1), an
upper bound on the use of stack memory can derived statically, thus
making it possible to prove that an application will always live within
its pre-allocated memory means.
Unfortunately, the sunny optimism shown here is unjustified.  Given
the ISO C standard (any version, C89, C99, or C11) it is 
to determine an upper bound on the use of stack memory.  There is not even
any standard way to determine how much memory a compiler will use for the
stack frame of a given function.  (There could have been.  There just isn't.)
There isn't even any requirement that two invocations of the same function
with the same arguments will use the same amount of memory.
Such a bound can only be calculated for a  version of a
specific compiler with specific options.  Here's a trivial example:
void f() {
    char a[100000];
}
How much memory will that take on the stack?  Compiled for debugging,
it might take a full stack frame (however big that is) plus traceback
information plus a million bytes for a[].  Compiled with optimisation,
the compiler might notice that a[] isn't used, and might even compile
calls to f() inline so that they generate no code and take no space.
That's an extreme example, but not really unfair.  If you want bounds
you can rely on, you had better  what your compiler does,
and recheck every time anything about the compiler changes.

4.  No function should be longer than what can be printed on
a single sheet of paper in a standard reference format with one line per
statement and one line per declaration.  Typically, this means no more
than about 60 lines of code per function.Since programmers these days typically read their code on-screen,
not on paper, it's not clear why the size of a sheet of paper is
relevant any longer.

The rule is arguably stated about the wrong thing.  The thing that
needs to be bounded is not the size of a function, but the size of a
chunk that a programmer needs to read and comprehend.

There are also question marks about how to interpret this if you
are using a sensible language (like Algol 60, Simula 67, Algol 68,
Pascal, Modula2, Ada, Lisp, functional languages like ML, O'CAML,
F#, Clean, Haskell, or Fortran) that allows nested procedures.
Suppose you have a folding editor that presents a procedure to
you like this:
function Text_To_Floating(S: string, E: integer): Double;
   � variables �
   � procedure Mul(Carry: integer) �
   � function Evaluate: Double �

   Base, Sign, Max, Min, Point, Power := 10, 0, 0, 1, 0, 0;
   for N := 1 to S.length do begin
       C := S[N];
       if C = '.' then begin
          Point := -1
       end else
       if C = '_' then begin
          Base := Round(Evaluate);
          Max, Min, Power := 0, 1, 0
       end else
       if Char ≠ ' ' then begin
          Q := ord(C) - ord('0');
          if Q > 9 then Q := ord(C) - ord('A') + 10
          Power := Point + Point
          Mul(Q)
       end
    end;
    Power := Power + Exp;
    Value := Evaluate;
    if Sign < 0 then Value := -Value;
end;
which would be much bigger if the declarations
were expanded out instead of being hidden behind �folds�.
Which size do we count?  The folded size or the unfolded size?
I was using a folding editor called Apprentice on the Classic Mac
back in the 1980s.  It was written by Peter McInerny and was lightning
fast.

5.  The  of the code should average to a minimum of
two assertions per function.Assertions are wonderful documentation and the very best debugging tool
I know of.  I have never seen any real code that had too many assertions.

The example here is one of the ugliest pieces of code I've seen in a while.
if (!c_assert(p >= 0) == true) {
    return ERROR;
}
It should, of course, just be
if (!c_assert(p >= 0)) {
    return ERROR;
}
Better still, it should be something like
#ifdef NDEBUG
#define check(e, c) (void)0
#else
#define check(e, c) if (!(c)) return bugout(c), (e)
#ifdef NDEBUG_LOG
#define bugout(c) (void)0
#else
#define bugout(c) \
    fprintf(stderr, "%s:%d: assertion '%s' failed.\n", \
    __FILE__, __LINE__, #s)
#endif
#endif
Ahem.  The more interesting part is the required density.
I just checked an open source project from a large telecoms
company, and 23 out of 704 files (not functions) contained
at least one assertion.  I just checked my own Smalltalk
system and one SLOC out of every 43 was an assertion, but
the average Smalltalk “function” is only a few
lines.  If the biggest function allowed is 60 lines, then
let's suppose the average function is about 36 lines, so
this rule requires 1 assertion per 18 lines.
Assertions are good, but what they are especially good
for is expressing the requirements on data that come
from outside the function.  I suggest then that
Every argument whose validity is not guaranteed by
its typed should have an assertion to check it.
Every datum that is obtained from an external
source (file, data base, message) whose validity is
not guaranteed by its type should have an assertion
to check it.
The NASA 10 rules are written for embedded systems, where
reading stuff from sensors is fairly common.

6.  Data objects must be declared at the smallest possible level of
scope.This is excellent advice, but why limit it to data objects?
Oh yeah, the rules were written for crippled languages where you
 declare functions in the right place.

People using Ada, Pascal (Delphi), JavaScript, or functional
languages should also declare types and functions as locally as
possible.

7.  The return value of non-void functions must be checked by each
calling function, and the validity of parameters must be checked inside
each function.This again is mainly about C, or any other language that indicates
failure by returning special values.  “Standard libraries
famously violate this rule”?  No, the  library does.

You have to be reasonable about this: it simply isn't practical
to check  aspect of validity for 
argument.  Take the C function
void *bsearch(
    void const *key  /* what we are looking for */,
    void const *base /* points to an array of things like that */,
    size_t      n    /* how many elements base has */,
    size_t      size /* the common size of key and base's elements */
    int (*      cmp)(void const *, void const *)
);
This does a binary search in an array.  We must have key≠0,
base≠0, size≠0, cmp≠0, cmp(key,key)=0, and for all
1<i<n,
cmp((char*)base+size*(i-1), (char*)base+size*i) <= 0
Checking the validity in full would mean checking
that [key..key+size) is a range of readable addresses,
[base..base+size*n) is a range of readable addresses,
and doing n calls to cmp.  But the whole point of binary
search is to do O(log(n)) calls to cmp.

The fundamental rules here are
Don't let run-time errors go un-noticed, and
any check is safer than no check.
8. The use of the preprocessor must be limited to the inclusion of
header files and simple macro definitions.  Token pasting, variable
argument lists (ellipses), and recursive macro calls are not allowed.Recursive macro calls don't really work in C, so no quarrel there.
Variable argument lists were introduced into macros in
C99 so that you could write code like
#define err_printf(level, ...) \
    if (debug_level >= level) fprintf(stderr, __VA_ARGS__)
...
    err_printf(HIGH, "About to frob %d\n", control_index);
This is a  thing; conditional tracing like this is a
powerful debugging aid.  It should be , not banned.

The rule goes on to ban macros that expand into things that are
not complete syntactic units.  This would, for example, prohibit
simulating try-catch blocks with macros.  (Fair enough, an earlier rule
banned exception handling anyway.)  Consider this code fragment, from
an actual program.
    row_flag = border;     
    if (row_flag) printf("\\hline");
    for_each_element_child(e0, i, j, e1)
        printf(row_flag ? "\\\\\n" : "\n");
        row_flag = true;  
        col_flag = false;
        for_each_element_child(e1, k, l, e2)
            if (col_flag) printf(" & ");
            col_flag = true;
            walk_paragraph("", e2, "");
        end_each_element_child
    end_each_element_child
    if (border) printf("\\\\\\hline");
    printf("\n\\end{tabular}\n");
It's part of a program converting slides written in something like HTML
into another notation for formatting.  The 
…  loops walk over a tree.  Using
these macros means that the programmer has no need to know and no reason to
care how the tree is represented and how the loop actually works.
You can easily see that  must have at
least one unmatched { and  must have at least one
unmatched }.  That's the kind of macro that's banned by requiring
complete syntactic units.  Yet the readability and maintainability of
the code is  improved by these macros.

One thing the rule covers, but does not at the beginning stress, is
“no  macro processing”.  That is,
no #if.  The argument against it is, I'm afraid, questionable.  If there
are 10 conditions, there are 2 combinations to test,
whether they are expressed as compile-time conditionals or run-time
conditionals.

In particular, the rule against conditional macro processing
would prevent you defining your own assertion macros.
It is not obvious that that's a good idea.

9.  The use of pointers should be restricted.  Specifically, no more
than one level of dereferencing is allowed.  Pointer dereference
operations may not be hidden in macro definitions or inside typedef
declarations.  Function pointers are not permitted.Let's look at the last point first.

double integral(double (*f)(double), double lower, double upper, int n) {
    // Compute the integral of f from lower to upper 
    // using Simpson's rule with n+1 points.
    double const h = (upper - lower) / n;
    double       s;
    double       t;
    int          i;
    
    s = 0.0;
    for (i = 0; i < n; i++) s += f((lower + h/2.0) + h*i);
    t = 0.0;
    for (i = 1; i < n; i++) t += f(lower + h*i);
    return (f(lower) + f(upper) + s*4.0 + t*2.0) * (h/6.0);
}
This kind of code has been important in numerical calculations since
the very earliest days.  Pascal could do it.  Algol 60 could do it.
In the 1950s, Fortran could do it.  And NASA would ban it, because in
C,  is a function pointer.

Now it's important to write functions like this once and only once.
For example, the code has at least one error.  The comment says n+1
points, but the function is actually evaluated at 2n+1 points.  If we
need to bound the number of calls to f in order to meet a deadline,
having that number off by a factor of two will not help.
It's nice to have just one place to fix.
Perhaps I should not have copied that code from a well-known source (:-).
Certainly I should not have more than one copy!

What can we do if we're not allowed to use function pointers?
Suppose there are four functions foo, bar, ugh, and zoo that we need
to integrate.  Now we can write
enum Fun {FOO, BAR, UGH, ZOO};

double call(enum Fun which, double what) {
    switch (which) {
        case FOO: return foo(what);
        case BAR: return bar(what);
        case UGH: return ugh(what);
        case ZOO: return zoo(what);
    }
}

double integral(enum Fun which, double lower, double upper, int n) {
    // Compute the integral of a function from lower to upper 
    // using Simpson's rule with n+1 points.
    double const h = (upper - lower) / n;
    double       s;
    double       t;
    int          i;
    
    s = 0.0;
    for (i = 0; i < n; i++) s += call(which, (lower + h/2.0) + h*i);
    t = 0.0;
    for (i = 1; i < n; i++) t += call(which, lower + h*i);
    return (call(which, lower) + call(which, upper) + s*4.0 + t*2.0) * (h/6.0);
}
Has obeying NASA's rule made the code more reliable?  No, it has made
the code  to understand,  maintainable, and
 that it wasn't before.  Here's a call
illustrating the mistake:
x = integral(4, 0.0, 1.0, 10);I have checked this with two C compilers and a static checker at their
highest settings, and they are completely silent about this.

So there are legitimate uses for function pointers, and simulating
them makes programs , not better.

Now  in Fortran,
Algol 60, or Pascal.  Those languages had procedure 
but not procedure . You could pass a subprogram name as
a parameter, and such a parameter could be passed on, but you could not
store them in variables.  You could have a  of C which
allowed function pointer parameters, but made all function pointer
variables read-only.  That would give you a statically checkable subset
of C that allowed integral().

The other use of function pointers is simulating object-orientation.
Imagine for example
struct Channel {
    void (*send)(struct Channel *, Message const *);
    bool (*recv)(struct Channel *, Message *);
    ...
};
inline void send(struct Channel *c, Message const *m) {
    c->send(c, m);
}
inline bool recv(struct Channel *c, Message *m) {
    return c->recv(c, m);
}
This lets us use a common interface for sending and receiving
messages on different kinds of channels.  This approach has been
used extensively in operating systems (at least as far back as
the Burroughs MCP in the 1960s) to decouple the code that uses
a device from the actual device driver.     I would expect any
program that controls more than one hardware device to do something
like this.  It's one of our key tools for controlling complexity.
Again, we can simulate this, but it makes adding a new kind of
channel harder than it should be, and the code is 
when we do it, not better.

The rule against more than one level of dereferencing is also
an assault on good programming.  One of the key ideas that was
developed in the 1960s is the idea of ;
the idea that it should be possible for one module to define a
data type and operations on it and another module to use instances
of that data type and its operations without having to know
anything about what the data type is.
One of the things I detest about Java is that it spits in the
face of the people who worked out that idea.  Yes, Java (now) has
generic type parameters, and that's good, but you cannot use a
 type without knowing what that type is.

Suppose I have a module that offers operations
And suppose that I have two interfaces in mind.  One of them
uses integers as tokens.
// stasher.h, version 1.
typedef int token;
extern token stash(item);
extern item  recall(token);
extern void  delete(token);
Another uses pointers as tokens.
// stasher.h, version 2.
typedef struct Hidden *token;
extern  token stash(item);
extern  item  recall(token);
extern  void  delete(token);
void snoo(token *ans, item x, item y) {
    if (better(x, y)) {
	*ans = stash(x);
    } else {
	*ans = stash(y);
    }
}
By the NASA rule, the function snoo() would not be accepted or rejected on
its own merits.  With stasher.h, version 1, it would be accepted.
With stasher.h, version 2, it would be rejected.

One reason to prefer version 2 to version 1 is that version 2 gets
more use out of type checking.  There are ever so many ways to get an
int in C.  Ask yourself if it ever makes sense to do
token t1 = stash(x);
token t2 = stash(y);
delete(t1*t2);
I really do not like the idea of banning abstract data types.

10.  All code must be compiled, from the first day of development,
with all compiler warnings enabled at the compiler’s
most pedantic setting.  All code must compile with these setting without
any warnings.  All code must be checked daily with at least one, but
preferably more than one, state-of-the-art static source code analyzer
and should pass the analyses with zero warnings.This one is good advice.  Rule 9 is really about making your code
worse in order to get more benefit from limited static checkers.  (Since
C has no standard way to construct new functions at run time, the set of
functions that a particular function pointer  point to can
be determined by a fixed-point data flow analysis, at least for most
programs.)  So is rule 1.  



]]></content:encoded></item><item><title>Soft Robots and Smart Movement</title><link>https://hackernoon.com/soft-robots-and-smart-movement?source=rss</link><author>EScholar: Electronic Academic Papers for Scholars</author><category>tech</category><pubDate>Sat, 15 Feb 2025 20:15:03 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) Jorge Francisco Garcia-Samartın, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain (jorge.gsamartin@upm.es);(2) Adrian Rieker, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain;(3) Antonio Barrientos, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain.3 PAUL: Design and Manufacturing 4 Data Acquisition and Open-Loop Control The size of the table to achieve acceptable kinematic modelling was set experimentally, as no previous references were available and previous works in the literature were very variable in terms of the number of data required. Furthermore, the possibility of an error occurring in the pneumatic system or the buffer of the vision acquisition system collapsing, together with the always present possibility of a leak in the segments, made it advisable to take data in small sessions and subsequently union of all of them. Since the data collection process was automated, this did not pose much of a problem.\
Although the possibility that the ambient temperature was a factor that influenced the kinematics of the robot was considered during the dataset collection process, it was finally proven that small variations in temperature did not affect the behaviour.\
Table 3 shows the datasets that were taken, the total time necessary to obtain them and the average time per point. It should be taken into account that not all captured positions were finally used, since, if the camera did not correctly detect the positions of the three beacon spheres, it could not calculate the orientation of the trihedral and therefore returned an error code. Of the 1200 samples collected, 5% had to be discarded, leaving 1146 finally usable. The average time per point, considering all the datasets collected, was 6.76 s, with a standard deviation of 0.63 s. The low variability between capture processes proves the effectiveness of the automated method designed.\
Once all the datasets were combined, the direct and inverse kinematic models presented here were validated. The validation of the direct model consisted of sending the robot a combination of inflation times and measuring the distance between the position reached, captured by the cameras, and that predicted by the table. Repeating the experiment for 40 points, the histogram of results presented in Figure 15 was observed. The average error is 4.27 mm, the median error 2.72 mm, and the standard deviation 1.99 mm.\
The high standard deviation and the shape of the histogram, tilted towards low values and with a very long tail, seem to indicate the existence of points where the model presents notable failures along with others with very good results. A future line of interest could be the detailed analysis of the workspace to locate where those regions of lower precision of the model are located and try to look for failures, perhaps leading to a greater density of points in the dataset.\
In the same way, the inverse kinematic model was tested. To do this, PAUL was given a reference position and orientation to achieve, the necessary times were calculated, using the procedures referred to in Equations (16), and (17) inflation was carried out. Subsequently, the position captured with the cameras was compared with the desired one.\
As expected, the existence of redundancies, in which equal position values are achieved with very different combinations of inflation times, introduces large uncertainties in the model, which the triangulation presented is not able to capture.\
Specifically, the inverse kinematic model has an average error of 10.78 mm, a median error of 9.22 mm and a standard deviation of 5.98 mm. While these errors may seem high, they are compared in Table 4 with other open-loop controllers presented in the literature. It can be clearly seen that they are in line with the results obtained and that they are even better than those obtained by smaller robots, where one would expect, due to the smaller working space, a higher accuracy (at least in data-driven models).\
It is worth highlighting, however, two experiments in which PAUL performed very satisfactorily, because the area of operation was restricted to a region where no redundancies were found to exist. They are available in the video of Appendix A.\
In the first of them, the robot was forced to reach a set of points located on the horizontal basis plane, also forcing the lower end of the last segment to be parallel to said\
plane. In all of them, errors less than 7 mm were achieved. Figure 16 shows the results of said experiment. With the aim of facilitating the understanding of the experiment, the beacon was changed for a laser pointer that points to the desired points, on which targets with a radius of 5 mm have been marked, allowing the accuracy achieved to be checked.\
In the second experiment, shown in Figure 17, points on the lower horizontal plane were also taken as reference, but without imposing that the lower face of the robot should remain parallel to it. In this case, accuracies of 2 cm were achieved.\
Although the inverse kinematic model therefore presents acceptable results, it must be commented that, in all these experiments, due to the geometry and material of the robot, at the moment in which PAUL reaches the desired position, it tends to acquire a movement damped oscillation. An attempt has been made to reduce it, despite everything, it is a very intrinsic phenomenon to the robot that is difficult to solve. A future line proposed, in this sense, is to try to rigidify the robot by introducing negative pressures that generate vacuum.]]></content:encoded></item><item><title>Perplexity Deep Research</title><link>https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research</link><author>vinni2</author><category>hn</category><pubDate>Sat, 15 Feb 2025 20:07:39 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Newly Curated 40+ Developer Fixes || Try it now :)</title><link>https://dev.to/0x2e_tech/newly-curated-40-developer-fixes-try-it-now--14fe</link><author>0x2e Tech</author><category>dev</category><category>rust</category><pubDate>Sat, 15 Feb 2025 20:03:25 +0000</pubDate><source url="https://dev.to/t/rust">Dev.to Rust</source><content:encoded><![CDATA[
  
  
  1. Go Testing: Force Retests & Disable Caching
Go Testing: Forcing Retests and Disabling Test Caching  This guide tackles the common issue of stale test results in Go, focusing on how to reliably force retests and disable caching mechanisms.  We'll explore several practical, plug-and-play solutio... Read More
  
  
  2. Flutter Map Key Typing: A Practical Guide for Developers
Flutter Map Key Typing: A Practical Guide for Developers  Let's face it: dealing with map key typing in Flutter can be a real headache if you don't have a clear strategy.  This guide provides a no-nonsense, plug-and-play approach to mastering this as... Read More Flutter Development 
  
  
  3. Multi-task Learning in TensorFlow: A Practical Guide
Multi-task Learning in TensorFlow: A Practical Guide  This guide provides a plug-and-play solution for implementing multi-task learning in TensorFlow.  We'll tackle a common scenario: predicting both the sentiment (positive, negative, neutral) and th... Read More
  
  
  4. Tracking Weight Variance During Neural Network Training
Let's dive into how the variance of weights changes during neural network training.  This is crucial for understanding your model's learning process and diagnosing potential problems.  We'll cover practical methods for tracking this variance and inte... Read More
  
  
  5. Ruby Rescue Best Practices: Why Avoid ?
Hey there, fellow Rubyist! Let's tackle this common pitfall: why rescuing Exception => e is a bad idea and how to do it right.  We'll go beyond the basics and explore practical, plug-and-play solutions.  This is for folks who know some Ruby but want ... Read More
  
  
  6. Expo iOS App Store Transfer Error: "A required agreement is missing"
Decoding the "A required agreement is missing or has expired" Enigma After Expo App Store Transfer (SDK 51.0.0 and beyond)  Let's face it:  That error message is about as helpful as a chocolate teapot.  You've wrestled with your Expo app, successfull... Read More iOS App Development 
  
  
  7. Android Ktor Job Cancellation: A Practical Guide
Android Ktor Job Cancellation: A Practical Guide  Let's tackle that pesky "Job Cancelled" error when using Ktor on Android. This issue often pops up when a long-running Ktor request gets interrupted, perhaps by a configuration problem, user action, o... Read More Android Development 
  
  
  8. Mobile-Unfriendly Laravel Site? Fix it Now!
Alright coder, let's tackle this mobile responsiveness issue head-on.  Your Laravel site's looking great on desktop, but those tiny screens are giving you a headache?  Don't worry, we'll fix it.  This guide is your plug-and-play solution, assuming yo... Read More
  
  
  9. Angular 18 APP_INITIALIZER: Fixing Dependency Injection Issues
Angular 18 APP_INITIALIZER Dependency Injection woes? Let's fix it!  So, you're wrestling with Angular 18's APP_INITIALIZER and its frustrating dependency injection quirks?  Don't worry, you're not alone. This seemingly simple mechanism can turn into... Read More
  
  
  10. Jenkins Token Generation for DevOps: A Practical Guide
Alright, friend! Let's get you a Jenkins API token.  This is crucial for automating tasks and integrating Jenkins with other tools.  Forget the confusing docs – we're going straight to the action.  Understanding the Why:  Before diving in, let's clar... Read More
  
  
  11. Fixing Python's  Error: A Quick Guide
Conquering the AttributeError: module 'pkgutil' has no attribute 'ImpImporter' Beast  Let's face it: that error message is a real mood killer.  It screams, "Your Python environment is a bit of a mess!" But fear not, fellow coder! This isn't some insu... Read More
  
  
  12. Securely Wiping AES XTS Cipher Keys in Go: A Practical Guide
Securely Wiping AES XTS Cipher Key Material in Go: A Practical Guide  This guide provides a clear, actionable solution for securely wiping AES XTS cipher key material in Go.  We'll tackle this problem head-on, avoiding unnecessary jargon and focusing... Read More
  
  
  13. Xamarin Forms: Null Values in IValueConverter? Fix it!
Hey there, fellow Xaml warrior! Let's tackle this pesky null value problem in your Xamarin Forms IValueConverter.  It's a common hiccup, but once you understand the why and the how, you'll be converting values like a pro.   The Usual Suspects: Why Nu... Read More
  
  
  14. Postgres Timestamps: Storing with Time Zone Without UTC Conversion
Storing Timestamps with Time Zone in Postgres Without UTC Conversion: A Practical Guide  This guide provides a clear, actionable solution for storing timestamps with time zones in PostgreSQL without the automatic conversion to UTC.  We'll tackle this... Read More
  
  
  15. Fix "cannot load such file -- utils/popen" on macOS
Alright, friend! Let's tackle this pesky "cannot load such file -- utils/popen" error you're encountering with Homebrew on your macOS system. This usually pops up when Ruby can't find the popen utility, which is crucial for some processes.  We'll wal... Read More
  
  
  16. Flutter Web Self-Signed SSL: A Practical Guide
Flutter Web Self-Signed Certificate Requests: A Straightforward Guide  Let's tackle that pesky self-signed certificate issue in Flutter web development.  You've built your awesome app, connected to your server... but BAM!  That self-signed certificat... Read More Flutter Web Development 
  
  
  17. Docker XRDP Resolution Fix: A Practical Guide
Docker XRDP Resolution Fix: A Practical Guide  Let's face it: wrestling with Docker and XRDP resolution can feel like a black hole of frustration.  You've got your awesome Docker setup, your XRDP server humming, but the display is all wonky.  Fear no... Read More
  
  
  18. Angular Drag-and-Drop: Fixing Nested List Issues
Angular Drag-and-Drop with Deeply Nested Lists: A Practical Guide  Let's face it: drag-and-drop in Angular with deeply nested lists can be a real headache.  The basic functionality often works fine for simple lists, but the moment you add nesting, th... Read More
  
  
  19. MySQL Error 1698: iRedMail Root Access Fix
Alright, friend! Let's tackle this "ERROR 1698 (28000): Access denied for user 'root'@'localhost'" issue head-on.  This is a common problem in MySQL, especially when working with iRedMail.  It basically means your root user, the king of your MySQL ki... Read More
  
  
  20. Docker to Host File Transfer: A Practical Guide
Copying Files from Docker Container to Host: A Practical Guide  This guide provides a no-nonsense, step-by-step approach to copying files from your Docker container to your host machine.  We'll cover various methods, ensuring you have the tools to ta... Read More
  
  
  21. Securely Wiping AES XTS Cipher Keys in Go: A Practical Guide
Securely Wiping AES XTS Cipher Key Material in Go: A Practical Guide  This guide provides a practical, step-by-step solution for securely wiping AES XTS cipher key material in Go.  We'll focus on eliminating sensitive data from memory to prevent pote... Read More
  
  
  22. Doubly-Ended Array Priority Queue: Mastering Node Partnerships
Mastering Node Partnerships in a Doubly-Ended Array-Based Priority Queue (DEAP)  Let's tackle the challenge of correctly managing node partnerships within a Doubly-Ended Array-Based Priority Queue (DEAP).  This isn't your grandma's priority queue; we... Read More Data Structures and Algorithms 
  
  
  23. Node ESM + Log4js: A Practical Guide
Conquering Log4js in Your Node.js ESM Project: A Plug-and-Play Guide  Let's be honest, wrestling with Log4js in an ES module Node.js project can feel like a wrestling match with a greased pig.  But fear not, fellow developer! This guide will walk you... Read More
  
  
  24. Fixing SwiftUI Font Twitching: A Practical Guide
SwiftUI Font Twitching:  A Practical Guide for iOS Developers  Let's be honest, that twitching font in your SwiftUI animation is annoying.  It's like a tiny, digital mosquito buzzing around your otherwise perfect UI. But fear not, fellow developer! W... Read More
  
  
  25. Resize SVG Responsively with D3.js: A Practical Guide
SVG Dimensions on Window Resize: A D3.js Plug-and-Play Solution  This guide provides a straightforward, actionable solution for dynamically resizing SVG elements within a D3.js visualization to match window changes.  We'll ditch the fluff and get str... Read More
  
  
  26. Demystifying Logits & Softmax in TensorFlow: A Practical Guide
Demystifying Logits and Softmax in TensorFlow: A Practical Guide  This guide provides a clear, practical explanation of logits and the difference between softmax and softmax_cross_entropy_with_logits in TensorFlow, focusing on direct application and ... Read More
  
  
  27. JS DevTools: "Function was resolved from bound function" Fix
Alright, detective! Let's crack this 'Function was resolved from bound function' mystery in your JavaScript DevTools.  This cryptic message usually pops up when you're dealing with functions and their context (where they're called from) isn't what yo... Read More
  
  
  28. VueDatePicker + v-mask: A Practical Guide
Mastering the Mashup: VueDatePicker and v-mask  Let's face it:  combining VueDatePicker and v-mask can feel like wrestling a greased pig.  But fear not, fellow developer! This guide will walk you through a smooth, streamlined integration, turning tha... Read More
  
  
  29. Is My Image Gamma Encoded? A NumPy Guide for Image Pros
Hey there, fellow image processing enthusiast!  Let's tackle this gamma encoding mystery. You've loaded your image into NumPy, and now you're wondering: Is it gamma-encoded or not?  Fear not! We'll unravel this with a practical, plug-and-play approac... Read More Image Processing 
  
  
  30. MySQL Functions: Returning Multiple Rows
Returning multiple rows from a MySQL function can be tricky, but it's definitely doable. The key is understanding that MySQL functions, unlike stored procedures, are designed to return a single value.  To get around this limitation, we'll leverage a ... Read More
  
  
  31. Flutter Web Theme Meta Tags: Why Mobile Browsers Ignore Them?
Flutter Web Theme Meta Tags: Why Mobile Browsers Ignore Them?  Let's tackle this head-on.  You've diligently crafted your Flutter web app, meticulously set your theme meta tags, and yet, mobile browsers are ignoring them.  Frustrating, right? This is... Read More Flutter Web Development 
  
  
  32. ASP.NET Pragma Header Won't Go Away?  A Quick Fix
Alright, friend!  Let's tackle this pesky Pragma header that's sticking around in your ASP.NET application even after you've seemingly banished it from your code.  This is a common issue, and it usually boils down to a few sneaky culprits.  We'll go ... Read More
  
  
  33. AWS EC2 Uptime: Node.js & TypeScript Solution
Calculating AWS EC2 Instance Uptime: A Node.js and TypeScript Guide  This guide provides a practical, plug-and-play solution for calculating the uptime of an AWS EC2 instance from the moment it enters the "running" state. We'll leverage the AWS SDK f... Read More
  
  
  34. JS Radio Group Arrow Key Control: A Plug-and-Play Guide
JavaScript Radio Group Navigation: A Plug-and-Play Guide  This guide provides a practical, step-by-step solution to enhance the user experience of multiple radio groups by enabling navigation using the Enter, Up, and Down arrow keys. We'll ditch the ... Read More
  
  
  35. Stop Clicks Under CSS Popovers: A Quick Guide
Stop Clicks Under CSS Popovers: A Quick Guide  This guide provides a straightforward solution to prevent clicks from reaching elements beneath a CSS popover's backdrop.  We'll use JavaScript to handle the event and stop propagation.  This is crucial ... Read More
  
  
  36. Flutter: Align Dynamic Row Element
Flutter: Aligning a Single Element in a Dynamic Height Row  Let's tackle this common Flutter layout challenge: aligning a single element within a row where the row's height changes dynamically.  This often pops up when you have elements of varying si... Read More
  
  
  37. Dark Theme CSS Fix: A Web Developer's Guide
Dark Theme CSS Mayhem? Let's Fix It!   So, your website looks fabulous in light mode, but the second someone flips the switch to dark mode, it's a CSS catastrophe?  Don't worry, you're not alone.  Many developers hit this snag.  This guide will walk ... Read More
  
  
  38. AWS SDK Port Forwarding: Troubleshooting Short-Lived Sessions (C#)
AWS SDK Port Forwarding: Why Your Sessions Die in 30 Seconds (and How to Fix It)  Let's be honest, debugging flaky network connections is nobody's favorite pastime.  But when your AWS SDK port forwarding sessions keep crapping out after less than 30 ... Read More
  
  
  39. Fixing Keras' pad_sequences Import Error: A Quick Guide
Conquering the 'cannot import name 'pad_sequences'' Error in Keras  Let's be honest, import errors are the bane of every programmer's existence.  That frustrating red squiggly line underlining your perfectly crafted code?  Yeah, we've all been there.... Read More
  
  
  40. PHP's ?? Operator: A Practical Guide for Beginners
Hey there, fellow coder! Let's dive into PHP's null coalescing operator, ??.  This little guy is a lifesaver when dealing with potentially null values and will save you from writing tons of tedious if statements.  Think of it as a supercharged way to... Read More
  
  
  41. Spring WebSockets: User-Specific Subscriptions
Alright, let's tackle this Spring WebSocket user subscription puzzle.  The goal?  Get messages to the right user, securely. Forget the fluff, let's get practical.  This solution uses Spring Security for authentication and authorization, ensuring only... Read More Spring WebSockets 
  
  
  42. Angular SSR: Mastering server.ts and main.server.ts
Angular SSR: Demystifying server.ts and main.server.ts  Let's get this straight:  Server-Side Rendering (SSR) in Angular can feel like navigating a labyrinth.  But fear not! We'll cut through the confusion and give you a practical, plug-and-play guid... Read More
  
  
  43. SageMaker Training Stuck? Deep Learning Fixes
Decoding the SageMaker Training Job Enigma: A Practical Guide  So, your SageMaker training job is chilling in a state of suspended animation?  The code compiles, the setup looks good, but nothing's happening in the training phase. Let's troubleshoot ... Read More Amazon SageMaker 
  
  
  44. Braze Connected Content GraphQL: A Practical Guide
Braze "Connected Content" GraphQL Request: A Practical Guide  This guide provides a step-by-step solution for making GraphQL requests to Braze's Connected Content API. We'll cover everything from setting up authentication to handling responses, focus... Read More
  
  
  45. PHP Progress Bar: A Step-by-Step Guide
PHP Progress Bar: A Step-by-Step Guide  This guide provides a practical, plug-and-play solution for creating a dynamic progress bar in PHP, updating in real-time over a period.  We'll cover the PHP backend, HTML frontend, and CSS styling using SASS f... Read More
  
  
  46. Resize Egui Tables by Column: A Rust Guide
Resize Egui Tables by Column: A Rust Guide  This guide provides a practical, plug-and-play solution for creating resizable tables in egui using Rust. We'll build a robust and efficient solution, avoiding unnecessary complexity.  Understanding the Cha... Read More
  
  
  47. C#/.NET: Why avoid inheriting from List? Practical solutions
C#/.NET: Why Avoid Inheriting from List? Practical Solutions  Let's cut to the chase.  You're a C# developer, you've encountered List, and you're thinking, "Hey, I need a specialized list!  Inheriting seems efficient."  Hold your horses, partne... Read More
  
  
  48. Next.js, Antd, Sass/Less: The Ultimate Guide
Next.js, Ant Design, Sass/Less: A Plug-and-Play Guide  This guide provides a no-nonsense, step-by-step approach to integrating Ant Design with Next.js, using either Less, Sass, or CSS Modules.  We'll focus on practicality, offering ready-to-use code ... Read More
  
  
  49. Rust Vector Concatenation: The Ultimate Guide for Programmers
Rust Vector Concatenation: The Ultimate Guide for Programmers  This guide provides a no-nonsense, practical approach to concatenating vectors in Rust.  We'll cover various methods, highlighting their strengths and weaknesses, so you can choose the be... Read More Rust Programming 
  
  
  50. Webpack 5 Breaking Change: Fixing Node.js Module Polyfills
Webpack 5 Breaking Change: Banishing the Node.js Polyfill Gremlins  Let's be honest, that "Webpack 5 breaking change" error message is a real mood killer.  You're cruising along, building your awesome React app, and suddenly BAM!  Webpack throws a ta... Read More
  
  
  💰 Want to Earn 40% Commission?Join our affiliate program and start making money by promoting ! Earn 40% on every sale you refer.  You'll on average around 5$ per sell and for bundled products it will be around 40$ per sale. (So just share it and make money with worrying about product creation and maintanence)]]></content:encoded></item><item><title>This Week In Techdirt History: February 9th – 15th</title><link>https://www.techdirt.com/2025/02/15/this-week-in-techdirt-history-february-9th-15th/</link><author>Leigh Beadon</author><category>tech</category><pubDate>Sat, 15 Feb 2025 20:00:00 +0000</pubDate><source url="https://www.techdirt.com/">Techdirt</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>My Life in Weeks</title><link>https://weeks.ginatrapani.org/</link><author>bookofjoe</author><category>hn</category><pubDate>Sat, 15 Feb 2025 19:34:29 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Apple Invites Its Users Into Major Years-Long Health Study</title><link>https://apple.slashdot.org/story/25/02/15/0610248/apple-invites-its-users-into-major-years-long-health-study?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 15 Feb 2025 19:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Can the iPhone, AirPods, or the Apple Watch play a role in improving health? Apple says they want to find out. 
"In medical research, discoveries are often limited by the number of participants who can be recruited, the amount of data that can be captured, and the duration of a given study," the company said in a blog post this week. "But Apple devices expand the possibilities..."
This new longitudinal, virtual study aims to understand how data from technology — including Apple and third-party devices — can be used to predict, detect, monitor, and manage changes in participants' health. Additionally, researchers will explore connections across different areas of health. 
CNBC reports:


The new study will likely influence future product development. Apple CEO Tim Cook previously said he believes health features will be the company's "most important contribution to mankind...." 

The Apple Health Study will be available through the company's Research app, and participation is voluntary. Users will select each data type they are willing to share with researchers, and they can stop sharing or completely discontinue their participation at any time. Apple has no access to participants' identifiable information, the company said... The project will last at least five years and may expand beyond that. 
A Harvard Medical School professor and cardiologist — also a principal investigator on the Apple Health Study — says "We've only just begun to scratch the surface of how technology can improve our understanding of human health."]]></content:encoded></item><item><title>New SF public health chief was part of McKinsey opioid-marketing operation</title><link>https://sfstandard.com/2025/02/14/san-francisco-department-public-health-daniel-tsai-opioids-mckinsey/</link><author>iancmceachern</author><category>hn</category><pubDate>Sat, 15 Feb 2025 19:32:16 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[Dr. David Juurlink, an expert on tramadol, called the drug a “minor player in the opioid crisis, but a player nevertheless.”He added, “To the extent that McKinsey helped advertise it as a notionally safer opioid, I think they did a disservice in doing so. The main reason I say tramadol is a minor player is because it wasn’t prescribed like candy, like OxyContin was.”McKinsey’s method of targeting high-volume prescribers was part of its playbook to juice opioid sales, despite mounting evidence that the drugs could be highly addictive. In other emails uncovered in the McKinsey documents, employees wrote excitedly about finding doctors who were willing to write opioid prescriptions. In one instance in 2015, a McKinsey partner wrote, “The challenge which we need to start working on is to identify the sweet spot of docs so we can do targeting. … Fun be[g]ins on Monday!”San Francisco’s fentanyl crisis is part of a broader trend of opioid overdoses that traces back to the 1990s, when prescription opioids became popular among doctors for chronic pain management. Companies such as Purdue Pharma, which manufactured OxyContin, brought in consulting firms like McKinsey to help with sales strategies. After a Department of Justice probe and settlement, McKinsey acknowledged that it knew the dangers of OxyContin but continued working with Purdue Pharma — even after several of the drugmaker’s executives pled guilty in 2007 to misrepresenting addiction risks. McKinsey, along with a slew of drug companies and pharmacies, agreed to pay billions in settlement funds over their roles in fueling opioid addiction. California received roughly $60 million from the 2021 McKinsey settlement. San Francisco, under the 2023 settlement of an opioid-related lawsuit, was expected to receive about $230 million from Walgreens.In both instances, the funds were slated to be used for opioid recovery efforts.In 2019, McKinsey said it would no longer work on opioid-related businesses. Last year, McKinsey formally apologized for its Purdue Pharma work, saying it was “deeply sorry” for its role in selling OxyContin. “This terrible public health crisis and our past work for opioid manufacturers will always be a source of profound regret for our firm,” the company said in a statement.At the San Francisco Department of Public Health, Tsai replaced Dr. Grant Colfax, who took the reins in 2019 and led the city through the pandemic before stepping down in January. The role paid $546,133 in 2024, one of the highest city salaries.  On Monday, the San Francisco Health Commission unanimously nominated Tsai as director of Public Heath. Dr. Laurie Green, president of the commission, said the governing body conducted a “multi-hour” interview.]]></content:encoded></item><item><title>Schemesh: Fusion between Unix shell and Lisp REPL</title><link>https://github.com/cosmos72/schemesh</link><author>cosmos0072</author><category>hn</category><pubDate>Sat, 15 Feb 2025 19:00:38 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Proactive IT Career Growth: Take Control of Your Professional Journey</title><link>https://hackernoon.com/proactive-it-career-growth-take-control-of-your-professional-journey?source=rss</link><author>Ekaterina</author><category>tech</category><pubDate>Sat, 15 Feb 2025 19:00:22 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[There are a lot of good articles about possible career tracks that you can pursue in IT, however, I haven’t seen many that might be used as actual guidance to move up the career ladder.\
Currently, I am working in a company that has very clear requirements for the engineers’ promotion and what can be used as sufficient evidence of fulfillment of those requirements. A combination of these two factors gave me the idea that additional information on this topic might help other engineers who are employed by companies that do not have it to build a strategy that will allow them to get to the next level.\
In almost any more or less mature IT company, a common career track for a software engineer is linear and looks almost the same:Associate Software Engineer is optional and may or may not be presented in the common IT department structure for a very simple reason: it’s net-negative for the first 12 months as it requires a lot of hand-holding so not all companies have resources and time to allow such positions in their structure.\
The further career track will depend on your inclinations, what you enjoy doing, and whether you are ready for the shift in the way you’re working.There’s nothing wrong with staying a senior software engineer if you like to allocate the majority of your time to coding. However, if you feel the need to empower others and lead that’s the right moment to weigh all expectations for each role, your strengths, the things that drive you, and pick the most suitable track for yourself.\
Despite the visual simplicity of the tracks above, it’s not clear how to get closer to the right end. The following insights will apply to the companies that have:a hierarchical structure where each employer has a line managera genuine interest in employee development\n Why is the above-mentioned is important?==The answer is quite simple: from day one you have an ally - your line manager==.\
Each line manager’s efficiency is based on the output of each person reporting to them: the faster you grow - the bigger your output - the better the line manager’s efficiency. Given all this, sooner or later, after you have joined your company, your line manager will approach you with the question: “Where do you see yourself after a certain time?” If it is not happening and you have regular one-to-ones, feel free to add this as a topic for discussion in the agenda.\
Voicing your intentions and setting a goal is just the first step of your way. The next step is to gather the list of requirements for the higher role and compile a list of achievements that can serve as evidence of your qualifications that you can use as a guide that you should follow to get from point A to point B. In companies with transparent promotion processes, this should be already in place.\
If this is not the case, you and your manager could compose one. Remember that this process is beneficial for both sides: you are getting an agreement that after certain achievements, you will be praised with the promotion and your line manager can get increased output from the team, so it’s a win-win case.\
Different companies may have different requirements for certain positions, and I won’t claim that the ones below are universal and will suit everyone. The main purpose is to give you an idea it might look like if you need one that can be further tailored to your needs.\n Guidelines for evidence can be used as a roadmap that brings you to the desired destination. The next steps for the common track might beCheck the team’s roadmap for suitable projects or change requests that might fit the purpose of the evidence.Voice up your intentions to the line manager so they can assist with the suitable project allocation and provide information about its priority, business value, and when it can be picked up for development.Spot any potential areas for improvement in code, observability, extensibility, and security perspectives and raise them as ownership tickets.Familiarize yourself with the current recruitment process in your company and ask for shadowing during recruitment sessions. Ask to switch roles where someone more senior will shadow you and ask for feedback. \n This is a short list of the roles that will be covered from requirements/guidelines for evidence perspectives:Junior Software Engineer RequirementsSoftware Engineer RequirementsSenior Software Engineer RequirementsLead Engineer RequirementsSenior Engineering Lead Requirements==Junior Software Engineer Requirements==|  |  |  |
|----|----|----|
|  | Delivers tasks \n · Clear requirements are needed (business and system) \n · Designs/implements limited-scope technical solutions \n · Limited guidance is required | 1. List of tasks completed \n o Tasks should be complex enough to mention them \n o Deadlines are met \n o No major quality issues \n o Tasks were completed with no handholding \n 2. Input from the line manager confirming that all the requirements are met. |
|  | Applies best practices \n · Learns and constantly applies best practices \n · Proficient with various dev tools \n · Investigates and fixes complicated problems/bugs | Feedback from the line manager and peers confirming that all the requirements are met. |\
==Software Engineer Requirements==|  |  |  |
|----|----|----|
|  | Delivers change requests (features) \n · Takes business requirements as input \n · Breaks work into tasks with a sufficient level of detail on the solution (what needs to be done and when it’s done) and the implementation (how it should be done) \n · Provides accurate estimates on a task/user story level \n · Pairs with other engineers to deliver faster | List of change requests delivered, conforming to the following requirements: \n 1. The change request has been fully delivered and the deadline was met. \n 2. The discovery part was completed by the employee (tickets, estimates). \n 3. The change request is complex enough from a technical perspective (more than 2 man-weeks for 1 engineer to implement it). \n 4. The change request provides a meaningful impact on the business. \n 5. The change request is signed off by the business and is running in production. \n 6. The employee has demonstrated a sufficient level of autonomy and quality (based on the feedback from the tech lead and the engineering manager). |
|  | Designs services \n · Designs and implements smaller services while taking into account all of the non-functional aspects (extensibility, security, observability, etc) \n · Writes high-quality code with full adoption of engineering practices and methodologies \n · Participates in code reviews to enforce best practices \n · Fixes the root causes behind bugs and problems encountered | At least two services designed conforming to the following requirements: \n 1. It can be a new service or a complete redesign of the existing service. \n 2. It can be a standalone service, a library, or a component consumed by other services. \n 3. The service shouldn’t be trivial from a design perspective. \n 4. The engineer should have followed the formal design process: \n · Obtain business and system requirements \n · Identify the bounded context \n · Identify non-functional requirements \n · Break down context into services \n · Get feedback on the solution \n · Implement it \n 5. Service is implemented and is running in production. |\
==Senior Software Engineer==|  |  |  |
|----|----|----|
|  | Delivers project phases (epics) \n · Takes requirements and high-level system design as input \n · Creates system design for the service or the component, decides on the technologies and engineering practices to be used \n · Breaks work into tasks or user stories with a sufficient level of detail on the solution (what needs to be done and when it’s done) and the implementation (how it should be done) \n · Provides accurate estimates on task/user story level \n · Leads a small team to deliver the scope \n · Unblocks their team, resolves issues, and removes impediments | List of project phases/epics delivered, conforming to the following requirements: \n 1. The epic/project phase has been fully delivered and the deadline was met. \n 2. The discovery part was completed by the employee (tickets, estimates). \n 3. The epic/project phase is complex enough from a technical perspective (requires at least 2 engineers for >= 2 weeks). \n 4. The epic/project phase provides a meaningful impact on the business. \n 5. The functionality is signed off by the business and is running in production. \n 6. The employee has demonstrated a sufficient level of autonomy and quality (based on the feedback from the tech lead and engineering manager). \n 7. The engineer participated in the implementation as a technical lead. |
|  | Designs subsystems \n · It is the same as for a Software Engineer but focuses on more complex services or subsystems \n · Proficient in the cloud and distributed systems design and implementation | At least 3 services designed conforming to the following requirements: \n 1. It can be a new service or a complete redesign of the existing service. \n 2. It can be a standalone service, a library, or a component consumed by other services. \n 3. The service shouldn’t be trivial from a design perspective. \n 4. The engineer should have followed the formal design process: \n a. Obtain business and system requirements \n b. Identify bounded context \n c. Identify non-functional requirements \n d. Break down context into services \n e. Get feedback on the solution \n f. Implement it \n 5. Service is implemented and is running in production. |
|  | Proposes changes \n · Challenges the status quo and the assumptions made \n · Find ways to improve the platform, processes, working environment, and the tech team in general | At least three significant changes were proposed, which can be any of the following: \n 1. Functionality: proposed a change request that was prioritized and implemented (change request should be substantial enough to be considered as a change, not a cosmetic change). \n 2. People: interviewed an engineer who was hired and passed probation (junior software engineer or higher, considered as a change to the team). \n 3. Ownership: proposed an ownership project (included in the ownership roadmap, approved by CTO). |\
\
==Lead Engineer Requirements==|  |  |  |
|----|----|----|
|  | Tech lead for projects (project proposals) \n · Takes business requirements as input \n · Find the most effective solution for the business problem (research alternatives, validate solutions using no-code/low-code approaches) \n · Creates system design for the new service or subsystem, decides on the technologies and engineering practices to be used \n · Breaks work into epics with a sufficient level of detail on the solution (what needs to be done and when it’s done) and the implementation (how it should be done) \n · Provides accurate estimates on the project level, commits to dates \n · Acts as a tech lead for the entire project \n · Unblocks their team, resolves issues, and removes impediments \n · Manages technology, implementation, and operational risks | List of projects delivered, conforming to the following requirements: \n 1. The solution for the problem was proposed by the employee and it is considered to be effective. I.e. multiple alternatives were evaluated, and the best alternative was chosen based on the low-code/no-code validation. \n 2. The discovery part was completed by the employee (tickets, estimates). \n 3. The solution was architected by the employee. \n 4. The project needs to be a “feature” project initiated through a project proposal. \n 5. The engineer participated in the implementation as a technical lead (see requirements column for more details). |
|  | Drives technical changes (squad) \n · Proposes and implements initiatives to improve system quality and reduce technical debt \n · Proposes and implements changes to improve developer experience and productivity \n · Advocates and enforces clean code and clean architecture | List of major changes introduced (usually at least four), conforming to the following requirements: \n 1. The change provides meaningful improvement to system quality (e.g. platform improvements), developer experience, or developer productivity. The change affects the entire squad. \n 2. The engineer doesn’t have to be the one who proposed the change. The engineer should be the primary driving force behind the change (e.g. designed, acted as a tech lead, participated in the implementation). The change can be delivered by an engineer or as a team effort. \n 3. The change should be fully implemented and used by the squad/platform (the change should be “sticky” and provide enough value to keep it). \n 4. The change should be significant enough to mention. |
|  | Mentor \n · Mentors and supports less experienced engineers \n · Conducts technical interviews effectively \n · Acts as a “magnet” for great engineers during hiring (be a decisive factor where we are in competition for good talent vs. another company) | Possible evidence: \n 1. Engineers interviewed, who were hired and passed probation. \n 2. Feedback from upskilled engineers. \n 3. Training sessions are organized/delivered for the entire tech team (e.g. Tech Sync, Engineering Dojo). \n 4. When leading a working group a list of changes proposed/implemented in the scope of the working group can be used as evidence. |\
==Senior Engineering Lead==|  |  |  |
|----|----|----|
|  | Tech Lead for complex projects (project proposals) \n Same as Lead Engineer, but focuses on problems that are complex from technical, organizational, or business perspectives \n · The project requires coordination across multiple squads \n · The project involves 3rd party technology provider or stakeholder (e.g. partnership) \n · a new product build while the product is in the discovery mode \n · high priority/urgency project with fixed deadlines and many unknown | List of projects delivered, conforming to the following requirements: \n 1. The project is considered to be complex (see examples on the left). \n 2. The project has been fully delivered (all deliverables + DoD) and the deadline was met. \n 3. The solution for the problem was proposed by the employee and it is considered to be effective (i.e. multiple alternatives were evaluated, and the best alternative was selected based on the low-code/no-code validation). \n 4. The discovery part was completed by the employee (system requirements, tickets, estimates). \n 5. The solution was architected by the employee. The project has a high complexity from a system design perspective. \n 6. An engineer participated in the implementation as a technical lead. |
|  | Drives technical changes (tech) \n · Same as E5 but on the tech level \n · System owner for at least one non-functional aspect (e.g. security, observability, etc). | List of major changes introduced (usually at least 4), conforming to the following requirements: \n 1. The change provides meaningful improvement to system quality (e.g. platform improvements), developer experience, or developer productivity. The change affects multiple squads (e.g. technology adoption). \n 2. The engineer doesn’t have to be the one who proposed the change. The engineer should be the primary driving force behind the change (e.g. designed, acted as a tech lead, participated in the implementation). The change itself can be delivered by an engineer or as a team effort. \n 3. The change should be fully implemented and used by multiple squads (changes should be “sticky” and provide enough value to keep it). \n 4. The change should be significant enough to mention. It should be tracked on the “upcoming projects” page as an ownership project (ownership in this context means changes to the platform, tooling, processes, etc, not just platform-related changes). \n 5. At least 2 changes should be related to the non-functional aspect owned by the individual. |
|  | Recognized expert \n · Recognized expert within a given area of expertise on a company level, acts as a technical point of contact in tech within their area of expertise \n · Monitors trends/technologies within the area of expertise and communicates updates and findings \n · Actively and regularly shares expertise with other engineers (workshops, tech talks, training) \n · Facilitates collaboration to find solutions for complex problems (working groups, etc) \n · Conducts technical interviews effectively \n · Mentors and supports less experienced engineers, guide their career from a professional development perspective \n · Acts as a “magnet” for great engineers during hiring (be a decisive factor where we are in competition for good talent vs. another company) | Possible evidence: \n 1. Interviewed engineers, who were hired and passed probation. \n 2. Feedback from upskilled engineers. \n 3. Training sessions are organized/delivered for the entire tech team (e.g. Tech Sync, Engineering Dojo). \n 4. Leading a working group, a list of changes proposed/implemented in the scope of the working group can be used as evidence. ||  |  |  |
|----|----|----|
|  | Delivers squad roadmap \n · Leads a squad of 3-6 engineers \n · Acts as a project manager for multiple concurrent initiatives \n · Able to deliver results having only business requirements as input (able to create and sign off system requirements) \n · Focuses on business impact, driven by business value \n · Communicates commitments, status, and risks to business stakeholders \n · Ensures that all squad members have all the information they need \n · Communicates to 3rd parties within the scope of initiatives/ownership \n · Finds the right balance between feature delivery and system quality \n · All requirements for Senior Software Engineer | New projects delivered by the squad conforming to the following requirements: \n 1. Project initiated through a project proposal. \n 2. The project has met its impact metrics, and the public commitment was met. \n 3. Projects reported in the previous promotion cycle can’t be included in the list. |
|  | Drives managerial changes (squad) \n · Measures and continuously improves squad performance \n · Identifies and establishes best practices within the squad with a focus on productivity \n · Maintains high quality of delivery \n · Ensures transparency on progress, risks, results | 1. Squad productivity (performance) metric values. \n 2. Major changes (at least 4) introduced, conforming to the following requirements: \n a. It solves a problem related to the owned squad or tribe, the problem needs to be included in the TOP 5 problems and agreed upon with the line manager. \n b. The change should be fully implemented and used by the squad (change should be “sticky” and provide enough value to keep it). \n c. The change should provide meaningful improvement to productivity, engagement, or quality of delivery. \n d. The manager doesn’t have to be the one who proposed the change. The EM should be the primary driving force behind the change. The change can be delivered by an engineer or as a team effort. |
|  | Line manager (>=3 direct reports) \n · Manages 3-6 direct reports \n · Coaches and supports engineers \n · Supports and guides career progressions \n · Reconciles differences of opinion and helps manage and resolve conflicts \n · Encourages a positive team culture and collaboration | 1. Squad engagement metric values. \n 2. List of engineers, who were hired and passed probation (can be skipped if we are not hiring, EM should be a hiring manager). |\
|  |  |  |
|----|----|----|
|  | Delivers roadmap for multiple squads \n · Ensures delivery across 2-3 squads \n · Fulfils Engineering Manager role in one of the squads \n · Owns partnerships with 3rd parties \n · All requirements from the Engineering Manager | New projects delivered by the squads conforming to the following requirements: \n 1. Project initiated through a project proposal (not a BAU activity). \n 2. The project has met its impact metrics and the public commitment was met. \n 3. Project results were presented as a Tech Feature session. \n 4. Projects reported in the previous promotion cycle can’t be included in the list. \n 5. At least 2 projects should be recognized as key projects on a company level (e.g. a new product, etc, can be confirmed with CTO). |
|  | Drives managerial changes (multiple squads/tech) \n · All requirements from Engineering but across multiple squads \n · System owner for at least one process (e.g. support, etc) | 1. Squads’ productivity (performance) metric values across multiple squads. \n 2. Major changes (at least 6) introduced, conforming to the following requirements: \n a. It solves a problem related to the squads or tribe, a problem needs to be included in the TOP 5 problems and agreed upon with the line manager. \n b. The change should be fully implemented and used by the squads (change should be “sticky” and provide enough value to keep it). \n c. The change should provide meaningful improvement to productivity, engagement, or quality of delivery. \n d. The manager doesn’t have to be the one who proposed the change. The Engineering Director should be the primary driving force behind the change. The change can be delivered by an engineer or as a team effort. \n e. At least 2 changes should be related to the process owned by the director. |
|  | Line manager (>=10 reports, including indirect reports) \n · All requirements for Engineering Manager \n · Coaches and supports engineers \n · Supports and guides career progressions \n · Manages churn, reduces “regrettable churn” | 1. Squads’ engagement metric values across multiple squads. \n 2. List of engineers, who were hired and passed probation (can be skipped if we are not hiring). \n 3. List of engineers promoted (can be skipped if there is no business need for promotions). |]]></content:encoded></item><item><title>How a Soft Robot Arm Moves Using Air, Not Motors</title><link>https://hackernoon.com/how-a-soft-robot-arm-moves-using-air-not-motors?source=rss</link><author>EScholar: Electronic Academic Papers for Scholars</author><category>tech</category><pubDate>Sat, 15 Feb 2025 19:00:19 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[(1) Jorge Francisco Garcia-Samartın, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain (jorge.gsamartin@upm.es);(2) Adrian Rieker, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain;(3) Antonio Barrientos, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain.3 PAUL: Design and Manufacturing4 Data Acquisition and Open-Loop Control\
Although the layout of the pneumatic bench allows working with up to 4 segments, it was thought that using 3 would allow the different problems linked to redundancy to be tackled without increasing the weight of the robot too much or requiring the tubes –which pass through the interior of the segments – to have an excessive amount of space.\
It is true that the tubes of the other three could pass through the first module, nevertheless, it was thought that the stiffness they would introduce by being so compressed could make it difficult to bend the initial segment. Since it is also the segment that has to exert the most force, as it is the one that supports the weight of the other segments, the risk of punctures could be increased.\
Therefore, a robot consisting of three identical modules was assembled, standing at a total height of 390 mm (with each segment measuring 100 mm, intersegment connections 20 mm each, and the vision trihedron rod 30 mm). Under these configurations, the estimated weight of PAUL’s arm is around 600 g. The structure protecting the manipulator is a cube with a side of 500 mm. Pressure of the pneumatic line was established in 1.2 bar.\
Examples of PAUL reaching different positions are depicted in Figure 13.The analysis of the workspace has been carried out experimentally, based on the data taken to generate the dataset. Figure 14 shows the workspace of a segment.\
As can be seen, this is a surface, as the segment has two degrees of freedom if the condition that at least one valve should remain deflated is imposed. The surface can be considered as the union of three surfaces intersecting at the central point, which corresponds to the configuration of all deflated bladders. The three surfaces are roughly spherical in shape. If the PCC model were completely valid for the robot, these would be perfect spheres, as the ends of a set of equal-length arcs of circumference with a common origin engrench a circle. Since this is not exactly the case, the generated surfaces only resemble the sphericity predicted by the constant curvature model.\
The addition of a second segment already generates a 4-D workspace that is difficult to represent. The generation of this is a consequence of the fact that, from each point on the surface of the workspace of a segment, another similar surface is generated. The\
\
union of all of these surfaces, which arise from the points on the surface of the first segment, results in the two-segment workspace. This is a volume in which, in addition, each point can be reached from two different orientations, thus leaving latent the four degrees of freedom that PAUL would have with only two modules.]]></content:encoded></item><item><title>Multiple Russian Threat Actors Targeting Microsoft Device Code Authentication</title><link>https://www.volexity.com/blog/2025/02/13/multiple-russian-threat-actors-targeting-microsoft-device-code-authentication/</link><author>ChrisArchitect</author><category>hn</category><pubDate>Sat, 15 Feb 2025 18:59:39 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[Multiple Russian Threat Actors Targeting Microsoft Device Code Authenticationby Charlie Gardner, Steven Adair, Tom LancasterVolexity has observed multiple Russian threat actors conducting social-engineering and spear-phishing campaigns targeting organizations with the ultimate goal of compromising Microsoft 365 accounts via Device Code Authentication phishing.Device Code Authentication phishing follows an atypical workflow to that expected by users, meaning users may not recognize it as phishing.Recent campaigns observed have been politically themed, particularly around the new administration in the United States and the changes this might mean for nations around the world.Starting in mid-January 2025, Volexity identified several social-engineering and spear-phishing campaigns by Russian threat actors aimed at compromising Microsoft 365 (M365) accounts. These attack campaigns were highly targeted and carried out in a variety of ways. The majority of these attacks originated via spear-phishing emails with different themes. In one case, the eventual breach began with highly tailored outreach via Signal.Through its investigations, Volexity discovered that Russian threat actors were impersonating a variety of individuals in order to socially engineer targets, including impersonating individuals from the following:United States Department of StateUkrainian Ministry of DefenceEuropean Union ParliamentProminent research institutionsCommunications carried a variety of different themes and messages, but they all ultimately resulted in the attacker inviting the targeted user to one of the following:Microsoft Teams Meeting / Video ConferenceAccess to applications and data as an external M365 userJoin a chatroom on a secure chat applicationWhen these attacks were successful and the attackers gained access to accounts, the post-exploitation phase often had unique characteristics in each case:The way the attackers accessed material from compromised organizations (scripts versus native applications)The infrastructure used to access stolen accountsDespite the differences, Volexity found the attacks had one thing in common: they were all Device Code Authentication attacks. While this attack method is not new, it is one that is definitely lesser known and not commonly leveraged by nation-state actors. Details on the social-engineering and spear-phishing campaigns, along with how Device Code Authentication attacks work, will be covered further in this blog post. What Volexity has observed is that this method has been more effective at successfully compromising accounts than most other targeted spear-phishing campaigns.Volexity assesses with high confidence that the series of attacks described in this blog post are from Russia-based threat actors. At this time, Volexity is tracking this activity under three different threat actors and assesses with medium confidence that at least one of them is  (overlapping with DarkHalo, APT29, Midnight Blizzard, CozyDuke). Volexity is tracking the remaining activity under  and . It is possible that all the activity described in this blog post is a single threat actor, but despite the similar targeting, timing, and attack method, other observed components of the operations are different enough to be tracked separately, for now.From Secure Chat to Insecure AuthenticationThe discovery of this threat activity started toward the end of January 2025, when Volexity uncovered a highly targeted attack that had successfully compromised the M365 account of one of its customers. This breach was discovered after Volexity identified suspicious sign-in activity to the account, which was followed by a rapid download of files from the user's OneDrive. All authentication and download events came from virtual private server (VPS) and Tor IP addresses, which is not the most subtle way to access an account. Volexity noted this activity was likely scripted, as the User-Agent string for later access and file downloads was the Python User-Agent string .Volexity then performed a detailed investigation into this incident, in an effort to identify how the account was compromised. A review of login activity showed the legitimate user had logged in and approved a multi-factor authentication (MFA) request. However, subsequent access was not from the legitimate user's IP address. This caused Volexity to initially suspect a phishing attack involving an adversary-in-the-middle (AiTM) framework. As a result, Volexity reviewed emails to the user leading up the time of the authentication event. This review identified a suspicious email just moments before the login activity from an email address purporting to be from someone with the name of a high-ranking official from the Ukrainian Ministry of Defence. The email was structured to look like a meeting invite for a chatroom on the messaging application, Element. Element is another encrypted messaging application that offers the ability for users to self-host a server with functionality that includes group video chats. The “invitation” email sent is shown below .Microsoft describes the purpose of this workflow as allowing '"users to sign in to input-constrained devices such as a smart TV, IoT device, or a printer.” However, in this case, it means if an attacker can convince a user to enter a specific code into this dialogue (and log in), they are granted long-term access to the user’s account.After working with its customer more closely, Volexity learned that the victim had been contacted on Signal by an individual purporting to be from the Ukrainian Ministry of Defence. This individual then requested the victim move off Signal to another secure chat application called Element. The attacker then had the victim join an Element server they controlled under the domain . This allowed the attacker to further communicate with the victim in real time and inform them they needed to click a link from an email to join a secure chat room. This is where the email Volexity had discovered came into play. The message was a ploy to fool the user into thinking they were being invited into a secure chat, when in reality they were giving the attacker access to their account. The generated Device Codes are only valid for 15 minutes once they are created. As a result, the real-time communication with the victim, and having them expect the "invitation", served to ensure the phish would succeed through timely coordination.The diagram below sVolexity tracks the threat actor behind this campaign as . Through research conducted on the custom domain used by UTA0304 to operate its own Element server, Volexity was able to pivot and discover additional infrastructure it believes is likely operated by the group. The table below represents the list of infrastructure that Volexity has tied to this threat actor.chromeelevationservice[.]comSpoofing the United States Department of StateIn early February 2025, Volexity observed multiple spear-phishing campaigns targeting users with fake Microsoft invitations purporting to be from the United States (US) Department of State. These emails were themed as invitations to join the US Department of State’s Microsoft tenant as an external user, or as invitations to a Microsoft Teams chat named “Measuring Influence Operations".Similar to the campaign conducted by UTA0304, these fake US Department of State emails were targeting users with a Device Code OAuth phishing workflow. Each email was aimed at convincing the user to accept the invitation and enter a unique code provided in the phishing email. The link in the invitations would direct users to the Microsoft Device Code authentication page. If the user entered the code provided in the phishing email, the authentication page would subsequently authorize the threat actor to access to the user’s account. However, it is worth noting that this campaign was sent out of the blue, with no precursor or build up to the emails, so users would not be expecting these messages. Even if they were to fall for the campaign, they would have to have done it within 15 minutes of receiving the email. This dramatically decreased the likelihood that this attack would be successful.After reviewing various parts of the attack, Volexity assesses with medium confidence that the Russian threat actor CozyLarch (aka APT29 or Midnight Blizzard) was behind these US Department of State themed spear-phishing campaigns. Additional details on each campaign are described in the sections that follow.Campaign 1: M365 Tenant External User InvitationCozyLarch sent invitations to several users, inviting them to access applications within the M365 tenant for the US Department of State. The invitation email was designed to look like a real invitation that would be sent from Microsoft, as shown below.The redirect link takes the user to the Microsoft Device Code OAuth workflow, and it is the same URL that UTA0304 directly embedded in their phishing campaign. However, unlike UTA0304, CozyLarch opted to use the redirect URL rather than the final login URL, perhaps because it may look even more recognizable to a discerning user, given that it is hosted on the main Microsoft domain. If the user entered the code provided from the email and continued through the authentication process, the attacker was granted access to the user’s M365 account.Campaign 2: M365 Teams Chat InvitationCozyLarch launched a second campaign, in which they targeted users with a fake invitation to join a Microsoft Teams chat named “Measuring Influence Operations”. The email made it appear as though there were already 37 other members in the chat.  A screenshot of one of the observed spear-phishing messages is shown below.The “Sign in to Microsoft Teams” button in the email body is a hyperlink that leads to the same https://www.microsoft.com/devicelogin URL observed in the other campaign. The attack flow and end goal are the same, with only a small difference in the theme of the emails.The emails are designed to appear as though they come from Microsoft. The messages used mixed encoding in the “friendly” name that make the address difficult to discern. An example of the full “from” header used in one phishing email is given below:\"Mic\udb40\udc30\udb40\udc30\udb40\udc30\u200br\udb40\udc30\udb40\udc30o\udb40\udc30\udb40\udc30soft Invitations on behal f of US Dep\udb40\udc30\udb40\udc30\udb40\udc30artme\udb40\udc30\udb40\udc30\udb40\udc30nt of St\udb40\udc30\udb40\udc30\udb40\udc30 ate \uff1cinvites\uff20mic\udb40\udc30\udb40\udc30\udb40\udc30\u200br\udb40\udc30\udb40\udc30o\udb40\udc30\udb40\udc30soft.co m\uff1e\u180e\u3000\u180e\u3000\u180e \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e \u180e\u3000\u180e \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e \u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e  \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000\u180e\u3000 \u180e\u3000\u180e\u3000\u180e \u061c Cc:\" <[email protected]>The attacker attempted to make it appear as if the emails were from , and also set the  header as . However, the true address could be seen at the end of the  field; all messages were sent via Google Gmail accounts. Volexity observed the following Gmail accounts as the actual senders of the messages observed:kaylassammers@gmail[.]comkendisggibson@gmail[.]comleslytthomson@gmail[.]comThese addresses are believed to be controlled by CozyLarch and can be used to reliably detect phishing emails that may have been sent.Using Wireless Proxy Networks for Email DistributionVolexity also noted that the sending IP address associated with each spear-phishing email was recorded in the headers. Looking at the  header in the messages, it became apparent that the attacker was using Proxy IP addresses based in the US to send messages. Volexity observed nearly a dozen IP addresses belonging to mobile networks in the US (AT&T and Verizon Wireless).European Parliament and Donald TrumpStarting in late January through to the publication of this blog (February 13, 2025), Volexity has observed another campaign by a Russian threat actor it tracks as  targeting numerous organizations. UTA0307 created a fake email under the identity of a member of the European Parliament who is on the Committee on Foreign Affairs. The threat actor reached out to numerous individuals with personalized emails requesting a Microsoft Teams meeting to discuss Donald Trump and his impact on relations between the US and the European Union. Volexity also observed a smaller set of campaigns centered on discussing China's foreign policy and China-European Union relations.The email subject lines used in these various campaigns are listed below:Discussion on Eastern Europe and the CaucasusDiscussion about Donald Trump's new termDiscussion about Trump & US relations with EuropeCollaboration on China and East Asia ResearchThe image below shows an example spear phish that was sent by UTA0307.None of the initial emails contained any malicious content or links at the onset. The threat actor was leveraging a tactic that has become commonplace for numerous nation-state actors, where they wait until a conversation has started prior to sending anything malicious. This serves the purpose of knowing they have an engaged target, and that the target's guard is potentially down. In the specific cases of Device Code Authentication phishing, it is especially important to have a responsive target, as the threat actor has only 15 minutes to convince the target to enter the code that has been generated.A Different Device Code OAuth Phishing TechniqueVolexity actually discovered the operations of UTA0307 following a successful compromise. Similar to the initial discovery of UTA0304, Volexity worked backwards from detecting a breach to identifying the above spear-phishing emails. In this case, the victim had engaged from the initial email and had several messages back and forth with UTA0307 regarding a meeting being set up. They agreed to join a Microsoft Teams meeting, and a fake invitation email was sent. However, this time the link in the email did not go to Microsoft. The target received an email with the subject "", and the body of the email, shown below, was designed to look like a real invitation.The “Join the meeting now” hyperlink, however, linked to a website controlled by UTA0307 (). This page in turn was set up to automatically generate a new Microsoft Device Code each time it was visited. The website was designed to appear as an official Microsoft interstitial page before the user can join a Microsoft Teams meeting. The message that appears on the landing page (shown below) claims that the victim needs to pass a security check by copying a code and entering it on a subsequent pageWhen the user clicks the “Next” button, a new tab is opened with the real Microsoft Device Code Authentication interface that requests an authentication code. If the victim enters the code supplied by the phishing page, they grant UTA0307 access to their M365 account. Interestingly, in the background of the initial phishing page, Volexity noted that the website would continuously poll the domain . It appears this domain was set up to monitor successful Device Code Authentication and, if detected, would redirect the user to a real Microsoft Teams meeting URL in an effort to make the activity appear legitimate.The threat actor never joined this Microsoft Teams meeting. However, UTA0307 did add authorization for an authentication application under their control to enable multi-factor authentication when logging into the compromised account. Volexity assesses with medium confidence that this was a requirement of logging into the account, even with the stolen authentication token.One benefit of this attack workflow versus other previously observed DeviceID phishing workflows is that, when a DeviceID code is generated, it is only valid for 15 minutes. Having an interstitial page that automatically generates new codes means UTA0307 does not have to worry about their phishing content expiring.UTA0307 Post-compromise Activities, Targeting and AttributionVolexity observed UTA0307 exfiltrating documents from a compromised M365 account that would be of interest to a Russian threat actor. This was determined based on identification of FileDownloaded operations observed in M365 audit log data. Given this information about the threat actor’s objectives, their targeting, and their use of a highly similar technique to that used in recent days and weeks by CozyLarch and UTA0304, Volexity assesses with medium confidence that UTA0307 is also a Russian threat actor.However, the exact implementation of the DeviceID OAuth phishing technique used in this activity differs slightly from those previously documented by Volexity, which provides some evidence that this activity may have been conducted by a separate threat actor. For example, while the previously observed phishing campaigns saw the attacker use the client ID for Microsoft Office when handling Device Code Authentication, this activity instead used the client ID for Microsoft Teams, as shown below (note that Microsoft uses  and  interchangeably in their logs when referring to the ID for an application):"appDisplayName": "Microsoft Teams","appId": "1fec8e78-bce4-4aaf-ab1b-5451cc387264",Another difference between this and the UTA0304 campaign is that in this case, all subsequent access to the compromised account occurred via Mullad VPN exit nodes (versus the other observed VPS and Tor IP addresses). Based on these two factors, Volexity has chosen to track this activity under the UTA0307 alias, rather than CozyLarch or UTA0304.Detecting Device Code AuthenticationVolexity identified a way to reliably detect this attack through monitoring and analysis of Microsoft Entra ID sign-in logs. When a user enters a device code and subsequently authenticates, it results in a login to the application associated with the generated code. This can be a common application like Microsoft Office that is frequently accessed by users and would not be a reliable indicator. However, the good news is that Device Code Authentications result in the  field being set with the value .The line below is what will appear in the JSON data in the Entra ID sign-in logs when a Device Code Authentication occurs:“authenticationProtocol": "deviceCode",Volexity further noted that as authenticated sessions refresh and are kept alive, subsequent sign-ins that initially occurred via a  often do not have anything set for  but they contain the following entry: “originalTransferMethod": "deviceCodeFlow",These values can be searched and filtered on in the Entra Admin center by adding filters for "Authentications Protocol" and "Original Transfer Method". The latter can be filtered in both  and  sign-ins. The frequency and legitimacy of these values occurring in the sign-in logs for a particular organization may vary, as this is a legitimate Microsoft feature. An organization can evaluate their risk and usage of these workflows, and potentially use this information as a proactive detection mechanism.If an organization has the ability to monitor URLs that are being accessed by users or sent in email, there are additional detection opportunities to discover Device Code Authentication attacks. The following official URLs can be monitored for as related to Microsoft Device Code Authentication:https://login.microsoftonline.com/common/oauth2/deviceauthhttps://www.microsoft.com/deviceloginhttps://aka.ms/deviceloginOrganizations can monitor for access to these URLs or for their presence in various communication methods, such as email. Attackers can find other means to redirect users to these URLs, but one of the main advantages of using the list above in phishing attacks is that the URL displayed is hosted on a legitimate Microsoft domain.Preventing Device Code AuthenticationVolexity believes the most effective way to prevent this potential attack vector is through conditional access policies on an organization's M365 tenant. It is possible for organizations to create a conditional access policy that disallows device code authentication altogether. It is fairly trivial to set up, and Microsoft provides online guidance on exactly how to do this. Based on Volexity's own testing, blocking the "Device code flow" from "Authentications flows" prevents this attack from working.  The image below shows what a conditional access policy would look like once it's set up and in place to block this authentication flow.Prior to implementing such a policy, organizations should evaluate the use of Device Code Authentication in their environment. This feature is used legitimately, and blocking it could have a negative impact. Volexity's review of its own customers identified several instances of legitimate access to resources via these means. However, at the majority of Volexity's customers, there was either no recent Device Code Authentication activity or there was only activity tied to the attacks described in this blog post.Volexity continues to track multiple spear-phishing campaigns targeting Device Code Authentication. This blog post serves to cover a few of the larger and unique campaigns observed. Volexity has observed other similar spear-phishing campaigns in recent weeks targeting Device Code Authentication that it believes are the work of Russian threat actors. Further, it should be noted that it is possible this is the work of a single threat actor running multiple, different campaigns. However, at this time, Volexity believes this activity is sufficiently different enough to warrant tracking this activity under two different unknown threat actors and one it believes is likely CozyLarch.While Device Code Authentication attacks are not new, they appear to have been rarely leveraged by nation-state threat actors . Volexity's visibility into targeted attacks indicates this particular method has been far more effective than the combined effort of years of other social-engineering and spear-phishing attacks conducted by the same (or similar) threat actors. It appears that these Russian threat actors have made a concerted effort to launch several campaigns against organizations with a goal of simultaneously abusing this method before the targets catch on and implement countermeasures.The detection mechanisms and countermeasures to these attacks have been available for years. However, Volexity believes they are seldom implemented and that most organizations are not even aware of this authentication flow, let alone the means to detect its misuse. These attacks serve as a reminder that threat actors will constantly look for ways to abuse legitimate features, and organizations must continually evaluate and implement methods to detect and prevent such attacks.These attacks also serve as a good opportunity to engage with users and remind them to be on the lookout for anything out of the ordinary when it comes to accessing resources when they are asked for login credentials or authorization grants. This phishing workflow has proven useful for an attacker, as many traditional sources of evidence and detection, both for a user and network defenders, are not present. For example:There is no “malicious” link or attachment. The only link is to the provider’s infrastructure (in this case, Microsoft). This means users cannot easily identify the link as being suspicious, and automated solutions detecting malicious emails will likely fail to do so for the same reason.Users are generally less aware of attacks that leverage legitimate services, and may be even less aware when it comes to those that involve entering a device code rather than their username or password.After successful authentication, the logs will show the authenticating application as a legitimate or benign application, reducing signal that can be keyed off of in sign-in logs by detection teams.These are items that organizations should look to further train users on and implement technical countermeasures against where possible.Volexity GitHub.If you believe you have been targeted by a similar attack and want to share details with Volexity for informational purposes, additional investigation, or incident response, please contact us.]]></content:encoded></item><item><title>xAI’s “Colossus” supercomputer raises health questions in Memphis</title><link>https://techcrunch.com/2025/02/15/xais-colossus-supercomputer-raises-health-questions-in-memphis/</link><author>Connie Loizos</author><category>tech</category><pubDate>Sat, 15 Feb 2025 18:53:04 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Elon Musk’s AI startup xAI plans to continue using 15 gas turbines to power its “Colossus” supercomputer in Memphis, Tennessee, according to an operating permit with the Shelby County Health Department for non-stop turbine use from June 2025 to June 2030. Why does it matter? The Commercial Appeal, a news outlet that obtained the documents, […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Elevate Your Night Shift Productivity Levels: 8 Strategies for Thriving - Not Just Surviving</title><link>https://hackernoon.com/elevate-your-night-shift-productivity-levels-8-strategies-for-thriving-not-just-surviving?source=rss</link><author>Beth Rush</author><category>tech</category><pubDate>Sat, 15 Feb 2025 18:45:02 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Almost every worker will tell you how tough it is to keep productivity levels high at work. However, the struggle is doubled when you work nights. Thankfully, there are a few techniques that can help you survive and thrive in your field, even when working those late hours.The Challenges of Long Hours in the EveningThe regular nine-to-five shift is the norm across many industries, especially in the corporate world. However, there are a few outliers, such as the hospitality and manufacturing sectors. Health care, security, and firefighting departments also need hands on deck at all times in emergencies, which requires plenty of alertness.\
There are several benefits, like less competition between workers and extra pay. However, it takes some work to get used to it as you have to adjust your body clock. The night shift can spark plenty of employee turnover since most people can’t sacrifice their daytime hours.\
Those who decide to take on the night shift find themselves at a crossroads. The hours may seem much longer despite being the same eight hours that workers typically work. It can be hard to keep energy levels up or stay awake.Most Effective Night Shift TipsDealing with a night shift schedule requires several adjustments, including your sleep schedule, caffeine intake, physical activities and so much more. Here are tried-and-true strategies to help you out.Have a Routine Before the ShiftGood sleep should be the highest priority in your pre-work routine. It’s much easier to stay alert and concentrate on your tasks on the job when you’ve had enough shut-eye. Unfortunately, over one-third of Americans sleep less than seven hours. Heading to bed in the middle of the day can also seem foreign to your body.\
Thus, the first step is to have a consistent schedule. For example, people in health care may have to start their eight hours of work at 7 p.m. or so. Others might deal with extended hours, bringing the total closer to 12.\
Thus, the ideal night-shift nurse sleep schedule will start at 9 a.m. if you want to achieve eight hours and an extra two hours to prep and commute. The leeway can also be used as additional time to sleep ahead of those longer work times.\
If it’s your first time heading into the shift, give your body a week to gradually acclimate to the new sleep schedule. Complete and total sleep deprivation can be too exhausting for your body.\
Be mindful of your sleeping quarters during the adjustment period. Blackout curtains are ideal for completely darkening the room and tricking your body into thinking it’s nighttime. You should put your phone in silent mode to avoid calls that may disrupt your sleep.\
You can also experiment with other sleeping aids. For example, some people find aromatherapy relaxing, easing them into slumber during the daytime. White noise machines can also provide the best background sound as you fall asleep.\
After a long sleep, you should feel recharged. Awaken your senses by preparing a well-balanced dinner before your shift, and incorporate fruits and vegetables into your meals to get your nutrition fix. Afterward, wear your clothing of choice and head out to conquer the night shift.Design a Post-Work RitualNow that you know how to prepare for a 12-hour night shift, it’s time to move on to winding down. Ideally, the routine gives you something to look forward to, such as having a shower to feel clean. You can also move your skincare routine to this time.\
Try to give yourself a bit of leisure after work. Some use this time to watch shows, listen to music, or play video games. Social media is also a good outlet for entertainment. Just remember to use it in moderation to avoid doomscrolling.Exercise Caution Around CaffeineCaffeine is a helpful tool to keep your energy levels as high as possible. A cup of your favorite coffee or tea just before work can help you energize throughout the day. However, it’s best to avoid the temptation of getting a second or third drink in the middle of the shift. Too much caffeine will result in quite a crash afterward.\
It’s also best to schedule your intake. Prolonged caffeine ingestion can disrupt the circadian rhythm, disrupting your sleep routine. Meanwhile, short exposure boosts sleep fragmentation, increasing your awakenings while sleeping and ruining the quality of your shut-eye. Once a week is a good rule of thumb to follow.One thing most people forget to realize when moving into the night shift is that everyone else still maintains their day routines. Your family and friends will likely have lunch, run errands, and do their own jobs when you’re asleep. When you’re awake and working, they’ll likely be sleeping.\
Human interaction is essential to enduring the night shift. Try to find overlaps and make time to catch up. You can invite a friend over for dinner before you head to work or chat on the phone while you’re home.\
You can also turn to your fellow employees going through the night shift. Camaraderie helps to overcome a challenge. Get to know these people, and build strong working relationships. The bond can even help you increase energy levels and boost productivity.Maintain Physical ActivityNight shift workers have limited time and energy. However, it’s still important to maintain some form of physical movement. Exercise may lessen the likelihood of disorders like depression, cardiovascular conditions, and metabolic diseases in chronic shift workers.\
Try to find breaks to just take a walk. Aside from getting fresh air, you can move your muscles and wake yourself up. If you’re already a veteran for the evening hours, you may even consider heading to the gym right after work.Move Your ResponsibilitiesKeeping productivity levels high throughout the shift can take time and practice. However, one hack you can try is intentionally scheduling the most important responsibilities at the beginning of your shift. After all, you will likely have more energy at the start.\
Once you’ve completed the bulk of the most important work, the next goal is to stretch out your energy throughout the rest of the hours and stay awake. You can try to space out your duties and give yourself breaks when you’re faltering.Keep the Same Schedule on Off DaysIt's important to maintain your current schedule to get your body used to the night shift. This solution is best for working full time, allowing you to fully adjust your body clock and move your most productive times to match your work schedule.\
If you have obligations during your off days that need to be done during the daytime, try to reschedule. You can also proceed and readjust afterward with some intentionally planned naps. Minimize deviating and the changes in your productivity should follow suit.Manage Your Mindset and StressNight shift workers can experience stress throughout the adjustment period. Unfortunately, this pressure can alter the immune system and make you more vulnerable to illnesses. It can also build a negative mindset toward your schedule.\
Make sure to have stress management techniques under your belt. Meditation is a good way to come to terms with your thoughts, while breathing exercises can assist you in calming down systemic turmoil. Activities like journaling and yoga can also improve your mood.Thrive With an Unconventional ScheduleHaving a night shift schedule is a challenge worth conquering. You get to be present for the people who need aid and assistance, and it brings fulfillment to your long-term career development. You just have to adapt to the circumstances to reap the rewards.]]></content:encoded></item><item><title>Perplexity launches its own freemium ‘deep research’ product</title><link>https://techcrunch.com/2025/02/15/perplexity-launches-its-own-freemium-deep-research-product/</link><author>Anthony Ha</author><category>tech</category><pubDate>Sat, 15 Feb 2025 18:39:14 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Perplexity has become the latest AI company to release an in-depth research tool, with a new feature announced Friday. Google unveiled a similar feature for its Gemini AI platform in December. Then OpenAI launched its own research agent earlier this month. All three companies even have given the feature the same name: Deep Research. The […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Bored With Chess? Magnus Carlsen Wants to Remake the Game</title><link>https://games.slashdot.org/story/25/02/15/053254/bored-with-chess-magnus-carlsen-wants-to-remake-the-game?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 15 Feb 2025 18:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA["Magnus Carlsen, the world's top chess player, is bored of chess," the Washington Post wrote Friday:

Carlsen has spent much of the past year appearing to dismiss the game he has mastered: It was no longer exciting to play, he told a podcast in March. In December, he withdrew from defending a world championship because he was penalized for wearing jeans to the tournament. 
How would the world's best player spice up the game? Change the rules, and add a touch of reality TV. 

Ten of the world's top players gathered in a German villa on the Baltic coast this week to play in the first tournament of a new chess circuit, the Freestyle Chess Grand Slam Tour, that Carlsen co-founded. The twist: The tour randomizes the starting positions of the chess board's most important pieces, so each game begins with the queen, rooks and knights in a jumble. [It's sometimes called "Chess960" or Fischer random chess — with both players starting with the same arrangement of pieces.] Players have to adapt on the fly. Carlsen is backed by a cadre of investors who see a chance to dramatize chess with the theatrics of a television show. Players wear heart-rate monitors and give confession-booth interviews mid-match where they strategize and fret to the audience. Some purists are skeptical. So is the International Chess Federation, which sent a barrage of legal threats to Freestyle Chess before it launched this week's event. 
At stake is a lucrative global market of hundreds of millions of chess players that has only continued to grow since the coronavirus pandemic launched a startling chess renaissance — and, perhaps, the authority to decide if and how a centuries-old game should evolve... The format is an antidote to the classical game, where patterns and strategies have been so rigorously studied that it's hard to innovate, Carlsen said. "It's still possible to get a [competitive] game, but you have to sort of dig deeper and deeper," Carlsen said. "I just find that there's too little scope for creativity." 

The article also includes this quote from American grand master Hikaru Nakamura who runs a chess YouTube channel with 2.7 million subscribers). "An integral part of regular chess is that when you play, you spend hours preparing your opening strategy before the game. But with Fischer Random ... it's a little bit looser and more enjoyable." And German entrepreneur Jan Henric Buettner (one of the investors) says they hope to bring the drama of Formula One racecars. ("Cameras mounted at table level peer up at each player during games," the article notes at one point.) 

The first Freestyle Chess Grand Slam Tour (with a $750,000 prize pool) concluded Friday, according to the article, but "Carlsen did not play in it," the Post points out. "He was upset in the semifinals by German grand master Vincent Keymer." Carlsen's reaction? "I definitely find Freestyle harder." 

But Chess.com reports that Carlsen will be back to playing regular chess very soon:

Global esports powerhouse Team Liquid has announced the signings of not just one, but two superstars of chess. Five-time World Champion and world number-one Magnus Carlsen and the 2018 challenger, world number-two Fabiano Caruana will represent the club ahead of the 2025 Esports World Cup (EWC)... Carlsen and Caruana, fresh from competing in the Weissenhaus Freestyle Chess Grand Slam, will first represent Team Liquid in the $150,000 Chessable Masters, which begins on February 16 and serves as the first of two qualifying events in the 2025 Champions Chess Tour. The top-12 players from the tour qualify for the EWC. 

In an announcement video Carlsen reportedly trolls the FIDE, according to Indian Express. "The announcement video sees Carlsen wear a Team Liquid jersey along with a jacket and jeans. He then asks: 'Do I have to change?' To this, someone responds: 'Don't worry, we're pretty chill in esports. Welcome to Team Liquid.'"]]></content:encoded></item><item><title>PAROL6: 3D-printed desktop robotic arm</title><link>https://source-robotics.github.io/PAROL-docs/</link><author>bo0tzz</author><category>hn</category><pubDate>Sat, 15 Feb 2025 18:26:49 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Basketball has evolved into a game of calculated decision-making</title><link>https://nabraj.com/blog/basketball-solved-sport/</link><author>nabaraz</author><category>hn</category><pubDate>Sat, 15 Feb 2025 18:21:10 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[Basketball has evolved from a game of unpredictability into a game of calculated decision-making with the use of data and analytics. From a game of points, assists, and rebounds, it has progressed into using thousands of data points to optimize every element of the game.All decisions are made based on numbers not intuition. Long-range shooting and layups are preferred over mid-range shooting. Players are no longer do-it-alls; they are now given specialized roles.In the last decade, long-range shooting has gone from a secondary option to a primary choice for building offense. Recently, teams have realized three-pointers have higher point value despite their lower scoring percentage. This has led to a revolution in structuring an offense around taking long-range shots. The Golden State Warriors, led by Stephen Curry, probably jump-started this trend with 34 three-pointer attempts per game in the 2018-19 season, twice as much from five years ago. Celtics, this season, have averaged almost 50 three-pointers attempt this season (2024-25 season).In the past, the team built its roster around a big name like Shaq. Most of the offense were from the center. This has now changed, with the primary strategy being to stretch the opposition and take long-range shots.The 3-and-D model refers to a player, usually a wing player, who is just above average at three-pointers and plays competent defense.  Forget about positions; just get a guy who can do some 3s and Ds.Danny Green is probably the father of this model, with his 40% career three-point field goal percentage and he also made into all-defensive team.In  recent years, every team has had at least one 3-and-D model player on the roster.Gone are the days of an all-around player. There is no longer a need for a player who does everything. Look at players like Kobe Bryant and Lebron James (early career); they not only scored but guarded defense, caught rebounds and played the role of playmakers.Now, it’s all about creating lineups with specialized players. A team typically consists of a three-point shooter, a defensive specialist, a playmaker, and rebounders. They all have specific roles assigned to them.A catch-all word for statistics, technology has played a pivotal role in shaping this game. In addition to data collection, biomechanics and motion cameras track every player’s movement. NBA even brought SportVU from football; it follows the ball and supposedly captures images 25 times per second. Coaches can now use this to analyze the speed, position, form, and motion of each player on the court. In the end, it’s all about optimizing every ball possession. Basketball might have lost its flair; every move is now predictable and measured. What is the future of basketball, is anyone’s guess? Maybe a rule change is around the corner?]]></content:encoded></item><item><title>OpenAI teases a ‘simplified’ GPT-5 model</title><link>https://techcrunch.com/2025/02/15/openai-teases-a-simplified-gpt-5-model/</link><author>Cody Corrall</author><category>tech</category><pubDate>Sat, 15 Feb 2025 18:05:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Welcome back to Week in Review. This week we’re looking at OpenAI canceling the release of o3; TikTok returning to U.S. app stores nearly a month after it was removed; more complications in Elon Musk’s bid to buy OpenAI for $97.4 billion; and more! Let’s do it. OpenAI effectively canceled the release of o3, which […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>Jill – a functional programming language for the Nand2Tetris platform</title><link>https://github.com/mpatajac/jillc</link><author>mailgolub</author><category>hn</category><pubDate>Sat, 15 Feb 2025 18:04:12 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Alzheimer&apos;s biomarkers now visible up to a decade ahead of symptoms</title><link>https://newatlas.com/brain/alzheimers-dementia/alzheimers-biomarkers-visible-decade-before-symptoms/</link><author>01-_-</author><category>hn</category><pubDate>Sat, 15 Feb 2025 18:02:17 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[Researchers at the University of Pittsburgh have devised a biomarker test that can spot small amounts of clumping tau protein in the brain and cerebrospinal fluid, which lead to Alzheimer's disease.Catching these clumps early while still in minute quantities can enable effective intervention. This test can help detect the tangled proteins years in advance of them appearing prominently in brain scans – as much as up to a decade.That's heartening because Alzheimer's disease not only has devastating impact on patients' lives long term, but is also currently incurable. It begins to show up as forgetfulness, and progresses to confusion and disorientation, delusions, hallucinations, and trouble sleeping. As the condition worsens, patients may experience difficulty eating, moving around, incontinence, loss of speech, and significant memory loss.“Early detection is key to more successful therapies for Alzheimer’s disease since trials show that patients with little-to-no quantifiable insoluble tau tangles are more likely to benefit from new treatments than those with a significant degree of tau brain deposits," explained Thomas Karikari, senior author of the paper published in  this week.Here's a quick bit of context on what's happening in and around the brain. Humans have some 86 billion nerve cells, and they're connected by what are called synapses. These synapses are supported by 'rail tracks' that enable the flow of essential nutrients and information, and they're called microtubules.Tau proteins (abbreviated from tubulin associated unit) stabilize these microtubules, and help keep the brain healthy. These proteins can malfunction, clump together and create tangles – preventing the microtubules from functioning properly.Here's where this new biomarker test comes in. The researchers have found an important section of the tau protein that causes it to form harmful tangles in the brain. This section is made up of 111 building blocks (amino acids). Within this section, they discovered two specific spots that, when modified, can tell doctors if tau proteins are starting to clump together. This is important because if doctors can detect these changes early enough, they might be able to treat the problem before it gets worse.The two specific spots they found (called p-tau-262 and p-tau-356) work like early warning signals, letting doctors know that tau proteins are beginning to malfunction. This could help identify Alzheimer's disease sooner, when treatments might be more effective.]]></content:encoded></item><item><title>How to Scale AI Infrastructure With Kubernetes and Docker</title><link>https://hackernoon.com/how-to-scale-ai-infrastructure-with-kubernetes-and-docker?source=rss</link><author>Natapong Sornprom</author><category>tech</category><pubDate>Sat, 15 Feb 2025 18:00:06 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Firms increasingly make use of artificial intelligence (AI) infrastructures to host and manage autonomous workloads. Consequently, as well as resilient infrastructures that will be able to meet heterogeneous application or cloud requirements. Organizations use and to meet such needs because firms realize that both are highly effective use cases that deliver scalable AI infrastructures.\
Deploying AI infrastructure typically provides adequate computation power to execute and process large datasets. These demands can translate into the need for scalable methods that enable AI models to run on large workloads without hurting performance., nonetheless, are also resource-intensive, normally demanding both high computing capacity and the ability to process high levels of data. As more advanced AI applications and a larger scale become required, scalability becomes more critical. Scalability ensures that AI systems can handle increasing workloads without any loss of performance.The growing amount of data is a concern for AI systems in many facets. Most AI models, especially those based on deep learning, heavily depend on large amounts of data during training and inference. However, without adequate scalable infrastructure, processing and interpreting such.Scalable AI hardware supports reliable and stable performance despite drastically overwhelming computational loads. With Kubernetes, horizontal scaling of AI jobs is a breeze, and the dynamic resizing of replica numbers can be done as a function of necessity. In contrast, Docker containers support lean, isolated environments for running AI models where resource conflict is not a performance bottleneck.Effective Resource ManagementEfficient use of resources is the key to cost-effective and sustainable AI deployment. Kubernetes' resource requests and limits allow for fine-grained CPU and memory resource management by avoiding underprovisioning and overprovisioning. Docker's resource management fills the gap by isolating container resources.Scaling AI Infrastructure With Kubernetes and DockerContainerization is one of the milestones in the evolution of scalable artificial intelligence infrastructure. Containerization of the AI application and its dependencies in a Docker container ensures consistency throughout the development, testing, and deployment environments.\
First, you must define a Dockerfile in order to install the environment. The Dockerfile is a series of instructions about how to build a Docker image. It declares a base image, the dependencies required, and the initial setup commands that apply to your app. The following is a basic Dockerfile for a Python machine-learning model:# Use an official Python runtime as a parent image
FROM python:3.9-slim

# Set the working directory in the container
WORKDIR /usr/src/app

# Copy the current directory contents into the container
COPY . .

# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Expose the port the app runs on
EXPOSE 5000

# Define environment variable
ENV NAME World

# Run the app
CMD ["python", "./app.py"]
\
If the Dockerfile is ready, then you can build the Docker image and run the container. Run the following commands: \n # Build the Docker image
docker build -t ml-model:latest .

# Run the container
docker run -p 5000:5000 ml-model:latest
Deploying the Dockerized AI Model to Kubernetes provides a wide range of orchestration features that enable efficient application management in the containerized infrastructure. Deployment of the Docker image on Kubernetes ensures that a specified number of application replicas is always running. The following is an example of deployment.yaml file that you can use to:apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-model-deployment
spec:
  replicas: 3  
  selector:
    matchLabels:
      app: ml-model
  template:
    metadata:
      labels:
        app: ml-model
    spec:
      containers:
      - name: ml-model-container
        image: ml-model:latest
        ports:
        - containerPort: 5000
\n The above code snippet shows how to deploy the AI model, but you also need to make the model externally accessible. You will need to expose it by defining a Kubernetes Service. The service.yaml below illustrates an example:apiVersion: v1
kind: Service
metadata:
  name: ml-model-service
spec:
  selector:
    app: ml-model
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
  type: LoadBalancer
\n Use the kubectl command-line tool to apply the deployment and service configurations:# Deploy the application
kubectl apply -f deployment.yaml

# Expose the service
kubectl apply -f service.yaml
Kubernetes provides excellent scaling capabilities to AI environments, maximizing resource utilization and performance. Horizontal scaling is done by adding additional containers, and vertical scaling involves adding additional resources like CPU or memory to a container.Horizontal scaling is used to scale up the number of replicas (Pods) of an AI system to handle a higher workload. The process requires enabling dynamic scaling depending on the number of replicas. The command used to enable such a process is `kubectl scale`. The particular command is used to set up the deployment to function up to a maximum of five replicas:\
`kubectl scale --replicas=5 deployment/ml-model-deployment`\
The command scales up the ml-model-deployment to use five replicas of the machine-learning model container. The system dynamically provisions more Pods to meet the required number afterward.Automatic Scaling using the Horizontal Pod Autoscaler (HPA)Kubernetes facilitates auto-scaling using the Horizontal Pod Autoscaler (HPA). The HPA dynamically adjusts the number of replicas based on resource use, i.e., CPU or memory, in relation to set limits. The YAML configuration shown below is a relevant example of an HPA that dynamically scales for ml-model-deployment in response to CPU use:apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: ml-model-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ml-model-deployment
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 50
\n In this setup, scaleTargetRef is used to define the Deployment to be scaled, i.e., ml-model-deployment. The minimum replica count is set using MinReplicas, while the maximum replica count is controlled using maxReplicas. In addition, the CPU utilization percentage is set using targetCPUUtilizationPercentage, i.e., to 50%. \
CPU utilization of more than 50% across all Pods results in scaling up the replica count to a maximum of 10 automatically. As soon as CPU utilization drops below the set percentage, Kubernetes automatically reduces the replica count in order to release resources.Horizontal scaling is mainly to cope with more traffic, whereas vertical scaling provides more resources (such as CPU or memory) to existing containers. The process is to scale up or down resource requests and limits in the Kubernetes Deployment. In order to scale up the CPU and memory limits of the ml-model-deployment, one would need to open the deployment.yaml file:apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-model-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ml-model
  template:
    metadata:
      labels:
        app: ml-model
    spec:
      containers:
      - name: ml-model-container
        image: ml-model:latest
        ports:
        - containerPort: 5000
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
          limits:
            cpu: "2"
            memory: "4Gi"
\
In this updated configuration:requests specify the minimum resources required for the container.limits define the maximum resources the container can use.]]></content:encoded></item><item><title>Rust and the Null Paradigm: Exploring Safety and Alternatives</title><link>https://dev.to/dedsecrattle/rust-and-the-null-paradigm-exploring-safety-and-alternatives-47b</link><author>Prabhat Kumar</author><category>dev</category><category>rust</category><pubDate>Sat, 15 Feb 2025 17:36:44 +0000</pubDate><source url="https://dev.to/t/rust">Dev.to Rust</source><content:encoded><![CDATA[Rust is a systems programming language known for its focus on memory safety, concurrency, and performance. One of the key decisions made by the Rust team is the choice to not support the null paradigm. While this design choice leads to safer, more reliable code, it raises an important question for developers: How do we handle the absence of a value?In many programming languages, the concept of  or  (depending on the language) is used to represent the absence of a value. This approach, however, introduces a number of issues:Null Pointer Dereferencing: Accessing a  pointer can lead to runtime errors that are often hard to debug. values can lead to subtle bugs when programmers forget to check for them, causing unexpected behaviors in applications.Rust decided to leave behind this problematic paradigm in favor of alternatives that promote safety at compile-time.
  
  
  Rust's Approach: Rust takes a unique approach to handling the absence of a value: it uses the  enum. This powerful construct allows developers to explicitly handle the presence or absence of a value.The  type is defined as: represents the presence of a value. represents the absence of a value.This makes  a much safer alternative to . The compiler forces you to explicitly handle both cases ( and ), reducing the risk of null pointer exceptions.Here's a simple example of how you might use  to handle optional values:In this example, instead of returning  when the user isn't found, we return , and the caller must handle the potential absence of a value.
  
  
  Why  Is Better Than  With , Rust ensures that you never have to deal with null values unless you explicitly decide to. This eliminates the common pitfalls of null pointer dereferencing. Rust’s borrow checker ensures that you handle all  cases correctly, even when dealing with complex ownership and lifetime semantics. Rust’s pattern matching syntax makes it easy to express the logic of handling  and  values, leading to clean and readable code.
  
  
  Other Alternatives:  for Error Handling
In addition to , Rust also offers the  enum for handling operations that might fail. The  type is especially useful when a function might produce either a valid result or an error, combining both success and failure cases into a single, explicit structure.Just like , the  type forces developers to handle both cases explicitly, improving robustness and error recovery in your programs.
  
  
  Conclusion: Embracing Safety and Clarity
Rust’s rejection of the  paradigm and adoption of types like  is a conscious choice to create safer, more reliable code. By forcing developers to handle the possibility of missing or invalid data explicitly, Rust eliminates the risks and headaches often associated with .While this approach might feel unfamiliar to developers coming from languages with , it quickly becomes a strength of the language. Embracing  (and ) in your code not only prevents bugs but also promotes a more clear, understandable way of thinking about data and operations in your applications.]]></content:encoded></item><item><title>Rust - Ownership Model</title><link>https://dev.to/dedsecrattle/rust-ownership-model-1l6j</link><author>Prabhat Kumar</author><category>dev</category><category>rust</category><pubDate>Sat, 15 Feb 2025 17:34:49 +0000</pubDate><source url="https://dev.to/t/rust">Dev.to Rust</source><content:encoded><![CDATA[Rust’s ownership model is one of its most powerful and defining features. It provides memory safety without needing a garbage collector, making Rust highly efficient and reliable. If you're coming from languages like C++, Java, or Python, understanding Rust’s ownership system might feel daunting at first. In this post, we'll break it down step by step.What is Ownership in Rust?Ownership is Rust’s unique way of managing memory. Instead of using garbage collection or manual memory management, Rust enforces strict ownership rules at compile time. These rules ensure memory safety and prevent data races in concurrent programs.The three key ownership rules are:Each value in Rust has a single owner.When the owner goes out of scope, Rust automatically deallocates the value.Ownership can be transferred (moved) or borrowed (immutably or mutably).
  
  
  Moving, Copying, and Cloning
When assigning a value from one variable to another, ownership is transferred. Consider this example:Since  is allocated on the heap, Rust prevents double-free errors by invalidating  when ownership moves to .Certain types implement the  trait, meaning they are duplicated instead of moved. Examples include:Primitive types (integers, floats, booleans, etc.) implement , so they don’t follow move semantics.If you need to duplicate heap-allocated data, use :Cloning explicitly creates a separate copy in memory, avoiding move-related issues.Rust allows borrowing instead of transferring ownership. Borrowing enables passing data without giving up ownership.A reference () allows read-only access to data without taking ownership:You can have multiple immutable borrows at the same time, but not if there’s a mutable borrow.A mutable reference () allows modification but enforces exclusivity:Rust ensures at compile time that you cannot have multiple mutable references or a mix of mutable and immutable references at the same time.
  
  
  Lifetimes: Ensuring Valid References
Rust’s  prevent dangling references. Consider this example:The  lifetime annotation ensures that the returned reference is valid as long as both input references are valid.
  
  
  Why Rust’s Ownership Model Matters
: No need for garbage collection, yet Rust prevents use-after-free and memory leaks.: Enforces thread safety at compile time.: Eliminates runtime overhead associated with memory management.: Code is predictable and free from subtle memory bugs.Rust’s ownership model might take some getting used to, but once you grasp it, you gain the power to write efficient and safe code without worrying about memory leaks. By understanding moves, copies, borrowing, and lifetimes, you can write highly performant Rust applications while maintaining safety guarantees.Are you currently learning Rust? Let me know what aspects of ownership you find the most challenging in the comments below!]]></content:encoded></item><item><title>&apos;Mass Theft&apos;: Thousands of Artists Call for AI Art Auction to be Cancelled</title><link>https://slashdot.org/story/25/02/15/0351257/mass-theft-thousands-of-artists-call-for-ai-art-auction-to-be-cancelled?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 15 Feb 2025 17:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[An anonymous reader shared this report from the Guardian:

Thousands of artists are urging the auction house Christie's to cancel a sale of art created with artificial intelligence, claiming the technology behind the works is committing "mass theft". The Augmented Intelligence auction has been described by Christie's as the first AI-dedicated sale by a major auctioneer and features 20 lots with prices ranging from $10,000 to $250,000... 
The British composer Ed Newton-Rex, a key figure in the campaign by creative professionals for protection of their work and a signatory to the letter, said at least nine of the works appearing in the auction appeared to have used models trained on artists' work. However, other pieces in the auction do not appear to have used such models. 
A spokesperson for Christie's said that "in most cases" the AI used to create art in the auction had been trained on the artists' "own inputs". 

More than 6,000 people have now signed the letter, which states point-blank that "Many of the artworks you plan to auction were created using AI models that are known to be trained on copyrighted work without a license."

These models, and the companies behind them, exploit human artists, using their work without permission or payment to build commercial AI products that compete with them. Your support of these models, and the people who use them, rewards and further incentivizes AI companies' mass theft of human artists' work. We ask that, if you have any respect for human artists, you cancel the auction. 

Last week ARTnews spoke to Nicole Sales Giles, Christie's vice-president and director of digital art sales (before the open letter was published). And Giles insisted one of the major themes of the auction is "that AI is not a replacement for human creativity."
"You can see a lot of human agency in all of these works," Giles said. "In every single work, you're seeing a collaboration between an AI model, a robot, or however the artist has chosen to incorporate AI. It is showing how AI is enhancing creativity and not becoming a substitute for it." 

One of the auction's headline lots is a 12-foot-tall robot made by Matr Labs that is guided by artist Alexander Reben's AI model. It will paint a new section of a canvas live during the sale every time the work receives a bid. Reben told ARTnews that he understands the frustrations of artists regarding the AI debate, but he sees "AI as an incredible tool... AI models which are trained on public data are done so under the idea of 'fair use,' just as search engines once faced scrutiny for organizing book data (which was ultimately found to fall under fair use)," he said.... "AI expands creative potential, offering new ways to explore, remix, and evolve artistic expression rather than replace it. The future of art isn't about AI versus artists — it's about how artists wield AI to push boundaries in ways we've never imagined before...." 

Digital artist Jack Butcher has used the open letter to create a minted digital artwork called Undersigned Artists. On X he wrote that the work "takes a collective act of dissent — an appeal to halt an AI art auction — and turns it into the very thing it resists: a minted piece of digital art. The letter, originally a condemnation of AI-generated works trained on unlicensed human labor, now becomes part of the system it critiques." 

Christie's will accept cryptocurrency payments for the majority of lots in the sale.
]]></content:encoded></item><item><title>A Programmer&apos;s Guide to Game Design: The Major Ingredients You Should Know</title><link>https://hackernoon.com/a-programmers-guide-to-game-design-the-major-ingredients-you-should-know?source=rss</link><author>Chenuli J.</author><category>tech</category><pubDate>Sat, 15 Feb 2025 17:00:05 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[Software developers spend their whole time with complicated problems, and they try to learn almost everything about algorithms, structures, frameworks, and blah-blah-blah. While playing games and coffee have become stress-busters in our lives, why can't building games be the best one?\
Even though some people find game development insane, it’s easy for software developers because they have almost every skill needed: math, Programming, UX/UI, and the usual stuff. If a normal person takes 6 months to learn a Game Engine, the Developer will take a maximum of 3 months or less.\
Many people don’t know this, but I started my tech career as a game developer, although I later turned my back on game development and became a Python developer. And no lies, they were a few of the best years in my life.\
This article is dedicated to any developer who wants to try something new or exciting (which is game development, yes). Scroll down!Software developers who are interested in game development have a remarkable head start. Programming skills are the core of game development. Even if you’re more comfortable with Swift or Ruby, which is not commonly used in game development, you can quickly pick up other Object-oriented programming languages that are much more commonly used for game development, like C# or C++, easier than anyone!\
If you're a Python lover, you will love to hear this: There are really good, AAA games made with Python such as Battlefield 2, EVE Online, Civilization IV, and more!Not only Python, but almost every commonly used Programming language has libraries that support making games. For example:Flutter has Flame, a game engine that supports Flutter language.Ruby has Gosu, a library that makes it easy to develop 2D games.Python has PyGame, a library that empowers you to create both 2D and 3D games.Phaser allows you to create games with JavaScript and HTML5.For every beginner, either a software engineer or a novice, I give one common piece of advice— Start as small as possible. It doesn't matter how small pieces of code it has or how messy it is, you've won the challenge!\
If you love simple 2D games, I would recommend that you make a Pong game. Pong features simple graphics (2 rectangles and a circle) you can create on your own, minimal sounds, and a game loop. If you want to learn about making multiplayer games, allow matches to occur between two human players over a network. If you want to learn about AI, allow the player to challenge the computer.\
And if you love 3D games like me, start with Cube Run. I haven't made it without a Game engine because, 3D becomes a bit harder with Python or others but with Unity, it's the best game I recommend to take a start.Major Ingredients of A GameIf you make a cake without Sugar, no one will eat it. Except for diabetic people, of course, like my mom.\
The same goes for video games. It’s full of ingredients, some of which are required for every game and some of which are optional. I’ll introduce them briefly.In many games, the level itself is a challenge, trickier than the smartest AI enemies. Series like Tomb Raider also emphasize complex and challenging level design.\
While the advent of open-world games like GTA may make the level design seem less important than in bygone times, it’s worth noting that even open-world games have ‘levels’, such as a particular building, structure, or map area you must enter to achieve a goal.\
To reduce player feelings of being railroaded, levels will ideally have multiple possible paths through them.In games, you can’t really rely on natural light sources to illuminate your video game.\
(You don’t think there’s a sun inside a game engine, do you?)\
Every light source in a video game must be added by hand and light manipulation is incredibly important. Light can be used for all of the following:Controlling the player’s ability . In horror and survival games, light is a resource that must be carefully managed.Controlling a player’s ability . In games with an element of stealth, dark areas can provide cover while well-lit areas represent a difficult challenge.Setting the mood. The quality of light can be used to set the mood, with sunny and bright lighting associated with happy times and brooding light associated with dark times.Lighting the way. Light can be used to direct the player’s attention. The best-designed levels in video games often make clever use of light to guide the player in the right direction when they might otherwise be lost.Game art is the medium through which the game world is presented to the player. In a sense, all the programming effort that goes into making video games is an attempt to turn game art into something that feels responsive and alive. Game art is an umbrella term that includes textures, 3D models, sprites, particle effects, and lighting.\
And yes, it’s a broad area, best to not cover it in this article.Unlike in the real world, video game sounds cannot be made by accident. Every sound in the game universe must be added by hand, and it is through layering these sounds that the game world starts to feel lifelike. You also need to be mindful of sounds triggered by the player, by other characters, and ambient sounds that create the game world environment.\
As an example, the player accidentally hits a metal object; if it doesn't emit a sound, it doesn't feel natural, or the scientist who claimed that metals have sonorous properties got it wrong.\
Another ever-present fact of video games is music, used to create an emotional response in the player or removed entirely to leave behind an eerie silence. Unlike most compositions, video game music must loop seamlessly. It must also transition smoothly to new compositions based on in-game events, such as being spotted by an enemy.\
Here are some of my favorite places to find sound:You have made graphics, levels, and everything but the whole game feels like a dead body. If you want your game to be alive, you need some lines of code.\
Most of my readers are probably a developer already, so you probably know the importance of programming anywhere. I'm not going to give a lecture on "what is programming", but here’s a bit about programming in game design.\
First of all, you need to decide one thing: Are you making a game by using a Game Engine + Language or building a game from scratch with Python or something? It's your choice but let me help you: If you're going to build games for fun, choose the first option because it's easier. \
As I said in the beginning, programmers always juggle complex problems so you probably shouldn't take more stress with that too.\
(Game Engines are the software used to create video games.)\
There are many of them, but the most popular ones are:Unity (Great for beginners, recommended)Next, choose a language to get started. Mostly, C# and C are used. Don't worry, you already got a headstart in knowing at least one programming language; most people start even before they know what the word “programming“stands for.\
And that’s about it. Well, of course, there are many other optional ingredients that video games consist of but in general, the above are basically the starter pack.Starting game development is easier for software developers than anyone. As someone with programming skills, you have a massive head-start on the average video game hobbyist who wants to learn how to make a game. If I scroll to the top of the article, I can list the below points as key takeaways.It's a lot easier to find a game dev library in your comfortable programming language to get started.Start with a small game, maybe a clone of an existing game.Game Engines make your life a lot easier.If you want to make a big, impressive game but don’t have a lot of time to spare, consider teaming up with others or joining a modding community.And that's all for now, Happy Designing! 🏎\
If you loved this article, make sure to subscribe using your email, so you can read all my content inside your inbox without missing any!It’s totally free of charge and I don’t even have time to send spam emails.]]></content:encoded></item><item><title>Marc Andreessen dreams of making a16z a lasting company, beyond partnerships</title><link>https://techcrunch.com/2025/02/15/marc-andreessen-dreams-of-making-a16z-a-lasting-company-beyond-partnerships/</link><author>Marina Temkin</author><category>tech</category><pubDate>Sat, 15 Feb 2025 17:00:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Many venture industry observers have wondered whether Andreessen Horowitz, a firm that manages $45 billion, has its sights on eventually becoming a publicly traded company. Co-founder Marc Andreessen said he isn’t “chomping at the bit to take the firm public,” on this week’s Invest Like the Best podcast. But he discussed his goal of building […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item><item><title>More Solar and Battery Storage Added to TX Grid Than Other Power Src Last Year</title><link>https://insideclimatenews.org/news/10022025/solar-battery-storage-texas-grid/</link><author>indigodaddy</author><category>hn</category><pubDate>Sat, 15 Feb 2025 16:37:04 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[As the market for renewables in Texas continues to strengthen and innovate, the power makeup of the state’s electric grid is slated to keep shifting toward adding more renewables. Last year, solar and battery storage installation led capacity growth within Texas’ electric grid, according to research from the Federal Reserve Bank of Dallas published in January. Texas added nearly 1,500 megawatts of battery storage to the grid’s summer rated capacities in 2023. That figure almost tripled to 4,374 megawatts added in 2024, according to the report. Capacity from solar power added to the grid enjoyed a similar trajectory. In 2023, 4,570 megawatts were added to the grid, while in 2024, nearly 9,700 megawatts were added. Given that Texas has its own isolated energy grid, the Electricity Reliability Council of Texas (ERCOT) is responsible for managing the majority of energy for its residents. Please take a look at the new openings in our newsroom.See jobsHistorically, ERCOT, which manages 90 percent of the state’s power load, has primarily relied on natural gas. But other energy sources, like wind and solar, have played a critical role in offsetting high demand. ERCOT added 3,400 megawatts from natural gas power plants in 2024. That’s after more than 1,000 megawatts of natural gas power were inactive within the grid from 2021 to 2023, according to Dallas Fed data. The capacity growth from solar and battery storage allowed the grid to manage another hot Texas summer in 2024, reported Garret Golding, an assistant vice president for energy program at the Dallas Fed. Battery storage is relatively new to ERCOT. One of the first battery power storage plants to be connected to ERCOT was in 2021, southeast of Dallas in Kaufman County. The 50-megawatt plant run by Enel, one of the largest renewable energy owners and operators in the country, was the first of Enel’s 14 battery projects it has since developed across the state. The forecasted power demand in Texas from population growth and heavy load users like data centers, cryptocurrency mining and artificial intelligence, alongside the competitive market for batteries, is dictating the rising use of storage within ERCOT, said Randald Bartlett, a senior director of operations and management for battery energy storage systems at Enel North America.Texas’ permitting processes and ability to develop has made it easier to add and build new capacity in comparison to other states with more laborious entryways, Bartlett said. Before, there wasn’t really adequate criteria and evidence to forecast what batteries would contribute to the grid, ERCOT CEO Pablo Vegas said during a board of directors meeting on Tuesday. Now, the grid operator added battery contribution to its report forecasting future capacity, demand and reserves. Battery storage in the ERCOT grid has nearly doubled every year since 2021, Vegas said. At the end of 2024, there were nearly 10,000 megawatts from batteries within ERCOT.Vegas said the capacity from batteries made a significant difference in ERCOT during bridge hours, or the winter morning hours when the sun has yet to rise and in the evenings after the sun sets. “Batteries made a meaningful contribution to what those shoulder periods look like and how much scarcity we get into during these peak events,” Vegas said when analyzing the grid’s performance during recent winter storms. In the spring of 2024, Texas’ installation of utility scale solar outpaced California’s, and jumped from 1,900 megawatts in 2019 to over 20,000 megawatts in 2024. As a result, solar met nearly 50 percent of the state’s peak power demand on some days. The state’s quick deployment of utility scale solar didn’t happen overnight. It started in 2005, when the legislature instructed the Public Utility Commission of Texas to create competitive renewable energy zones, where the state planned transmission lines to connect cities to renewable energy sources in west Texas.Initially, it was intended to capture wind power but was able to quickly include solar because of the existing infrastructure, said Dustin Mulvaney, an environmental studies professor at San Jose State University and an author of Planning to Build Faster: A Solar Energy Case Study, published in October by the Roosevelt Institute. That forward-looking plan is often held up as a model renewable energy advocates and developers say the Federal Energy Regulatory Commission could implement across other regional transmission organizations, by requiring proactive planning and by creating rules of how to pay for transmission systems. As the state’s grid continues to experience a rapid shift in the type of generation available to serve demand, the state’s grid operator is looking to build a higher voltage transmission system, upgrading from 345-kilovolt lines to 765-kilovolt lines. In 2024, nearly 78 gigawatts of transmission-connected wind, solar and battery energy storage capacity was installed to the grid. And more than 102 gigawatts of transmission-connected renewable capacity is expected to be installed by the end of 2025, according to a December ERCOT report.It’s that growth of both demand and renewables connected to the grid that’s led ERCOT to ask the Public Utility Commission to consider upgrading the state’s transmission system rather than expanding its existing one. The 765-kV lines would provide significant economic and reliability benefits to the ERCOT system, wrote Kristi Hobbs, ERCOT’s vice president of system planning and weatherization, in the grid operator’s submission of its regional transmission plans to the commission in late January.Regardless of which transmission plan is chosen, Hobbs wrote, the explosive growth projected throughout the next six years and beyond will require major public investment. Perhaps you noticed: This story, like all the news we publish, is free to read. That’s because Inside Climate News is a 501c3 nonprofit organization. We do not charge a subscription fee, lock our news behind a paywall, or clutter our website with ads. We make our news on climate and the environment freely available to you and anyone who wants it.That’s not all. We also share our news for free with scores of other media organizations around the country. Many of them can’t afford to do environmental journalism of their own. We’ve built bureaus from coast to coast to report local stories, collaborate with local newsrooms and co-publish articles so that this vital work is shared as widely as possible.Two of us launched ICN in 2007. Six years later we earned a Pulitzer Prize for National Reporting, and now we run the oldest and largest dedicated climate newsroom in the nation. We tell the story in all its complexity. We hold polluters accountable. We expose environmental injustice. We debunk misinformation. We scrutinize solutions and inspire action.Donations from readers like you fund every aspect of what we do. If you don’t already, will you support our ongoing work, our reporting on the biggest crisis facing our planet, and help us reach even more readers in more places? Please take a moment to make a tax-deductible donation. Every one of them makes a difference.Reporter, Texas RenewablesArcelia Martin is an award-winning journalist at Inside Climate News. She covers renewable energy in Texas from her base in Dallas. Before joining ICN in 2025, Arcelia was a staff writer at The Dallas Morning News and at The Tennessean. Originally from San Diego, California, she’s a graduate of Gonzaga University and Columbia University Graduate School of Journalism.]]></content:encoded></item><item><title>ISS Astronauts Give Space-to-Earth Interview Weeks Before Finally Returning to Earth</title><link>https://science.slashdot.org/story/25/02/15/033223/iss-astronauts-give-space-to-earth-interview-weeks-before-finally-returning-to-earth?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 15 Feb 2025 16:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Last June two NASA astronauts flew to the International Space Station on the first crewed test flight of Boeing's Starliner. But they aren't stranded there, and they weren't abandoned, the astronauts reminded CNN this week in a rare space-to-earth interview:

"That's been the rhetoric. That's been the narrative from day one: stranded, abandoned, stuck — and I get it. We both get it," [NASA astronaut Butch] Wilmore said. "But that is, again, not what our human spaceflight program is about. We don't feel abandoned, we don't feel stuck, we don't feel stranded." Wilmore added a request: "If you'll help us change the rhetoric, help us change the narrative. Let's change it to 'prepared and committed.' 

"That's what we prefer," he said... 
[NASA astronaut Suni] Williams also reiterated a sentiment she has expressed on several occasions, including in interviews conducted before she left Earth. "Butch and I knew this was a test flight," she told CNN's Cooper, acknowledging the pair has been prepared for contingencies and understood that the stay in space might be extended. "We knew that we would probably find some things (wrong with Starliner) and we found some stuff, and so that was not a surprise," she said. 
When Cooper opened the interview by asking the astronauts how they're doing, Williams answers "We're doing pretty darn good, actually," pointing out they had plenty of food and great crew members. And Wilmore added that crews come to the space station on a careful cycle, and "to alter that cycle sends ripple effects all the way down the chain. We would never expect to come back just special for us or anyone unless it was a medical issue or something really out of the circumstances along those lines. So we need to come back and keep the normal cycle going..." 

CNN's article notes a new announcement from NASA Tuesday that the astronauts might return a couple weeks early "after opting to change the SpaceX Crew Dragon capsule it will use." That mission's targeted launch date is now March 12. 

In the meantime, Williams says in the interview, "We do have some internet connection up here, so we can get some internet live. We've gotten football. It's been this crew's go-to this past fall. Also YouTube or something like that. It's not continuous — it has chunks of time that we get it. And we use that same system also to make phone calls home, so we can talk to our families, and do videoconferences even on the weekends as well. This place is a pretty nice place to live, for the most part." 

And they're also "working on with folks on the ground" to test the NASA's cube-shaped, free-flying robotic Astrobees.]]></content:encoded></item><item><title>Deepseek R1 Distill 8B Q40 on 4 x Raspberry Pi 5</title><link>https://github.com/b4rtaz/distributed-llama/discussions/162</link><author>b4rtazz</author><category>hn</category><pubDate>Sat, 15 Feb 2025 16:11:29 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>NTSYNC Driver Fix Being Worked On For Proper User Permissions</title><link>https://www.phoronix.com/news/Linux-NTSYNC-Permissions-Issue</link><author>Michael Larabel</author><category>tech</category><pubDate>Sat, 15 Feb 2025 16:05:32 +0000</pubDate><source url="https://www.phoronix.com/">Phoronix</source><content:encoded><![CDATA[One of the great new features of Linux 6.14 is the NTSYNC driver being completed for better emulating the Microsoft Windows NT synchronization primitives so that software like Wine and Proton (Steam Play) can provide for better performance when running Windows games on Linux. But it turns out an oversight up to now has meant that in practice it's not really too usable out-of-the-box...]]></content:encoded></item><item><title>The HackerNoon Newsletter: No Startup Has Ever Failed Because it Didn’t Have a Blog (2/15/2025)</title><link>https://hackernoon.com/2-15-2025-newsletter?source=rss</link><author>Noonification</author><category>tech</category><pubDate>Sat, 15 Feb 2025 16:04:17 +0000</pubDate><source url="https://hackernoon.com/">Tech - HackerNoon</source><content:encoded><![CDATA[🪐 What’s happening in tech today, February 15, 2025?By @realgpp [ 9 Min read ] Learn how to read thread dumps and take control of your application’s runtime behaviour.
 Read More.By @bigmao [ 6 Min read ] The case against content marketing, and how to do inbound marketing in the post-content age.  Read More.By @loadbalancer [ 5 Min read ] Researchers have optimized Layer-7 load balancing using programmable SmartNICs to improve efficiency, cost, and energy use in cloud data centers. Read More.🧑‍💻 What happened in your world this week?We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, 
 The HackerNoon Team ✌️]]></content:encoded></item><item><title>Jeep Claims &apos;Software Glitch&apos; Disabled Opting-Out of In-Vehicle Pop-Up Ads in &apos;a Few&apos; Cases</title><link>https://tech.slashdot.org/story/25/02/15/0149202/jeep-claims-software-glitch-disabled-opting-out-of-in-vehicle-pop-up-ads-in-a-few-cases?utm_source=rss1.0mainlinkanon&amp;utm_medium=feed</link><author>EditorDavid</author><category>tech</category><pubDate>Sat, 15 Feb 2025 15:34:00 +0000</pubDate><source url="https://slashdot.org/">Slashdot</source><content:encoded><![CDATA[Remember Jeep's new in-dash pop-up ads which reportedly appeared every time you stopped? 
"Since I'm a journalist, or at least close enough, I decided that I should at least get Stellantis/Jeep's side of things," writes car-culture site The Autopian:


Would Stellantis do something so woefully misguided and annoying? I reached out to our Stellantis/Jeep contact to ask and was initially told that they were "investigating" on their end, which to me felt like a stalling tactic while the proper ass-covering plans were conceived. I eventually got this response from a Stellantis spokesperson: 

 "This was an in-vehicle message designed to inform Jeep customers about Mopar extended vehicle care options. A temporary software glitch affected the ability to instantly opt out in a few isolated cases, though instant opt-out is the standard for all our in-vehicle messages. Our team had already identified and corrected the error, and we are following up directly with the customer to ensure the matter is fully resolved..." 

I suppose a glitch is possible, though I've not seen any examples of this ad popping up with the instant opt-out option available, but I guess it must exist, since not all Jeep owners seem to have had to deal with these ads. I suspect if this was happening to more people than these "few isolated cases" we'd still be cleaning up from the aftermath of the riots and uprisings. 

Because, as they write, "Really, I can't think of a quicker way to incur the wrath of nearly every human..."]]></content:encoded></item><item><title>Carbon capture more costly than switching to renewables, researchers find</title><link>https://techxplore.com/news/2025-02-carbon-capture-renewables.html</link><author>Brajeshwar</author><category>hn</category><pubDate>Sat, 15 Feb 2025 15:06:30 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Dust from car brakes more harmful than exhaust, study finds</title><link>https://e360.yale.edu/digest/brake-pads-lung-damage-study</link><author>Brajeshwar</author><category>hn</category><pubDate>Sat, 15 Feb 2025 15:06:15 +0000</pubDate><source url="https://news.ycombinator.com/">HN</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Rust - Ownership Model</title><link>https://dev.to/dedsecrattle/rust-ownership-model-2bak</link><author>Prabhat Kumar</author><category>dev</category><category>rust</category><pubDate>Sat, 15 Feb 2025 15:05:14 +0000</pubDate><source url="https://dev.to/t/rust">Dev.to Rust</source><content:encoded><![CDATA[Rust’s ownership model is one of its most powerful and defining features. It provides memory safety without needing a garbage collector, making Rust highly efficient and reliable. If you're coming from languages like C++, Java, or Python, understanding Rust’s ownership system might feel daunting at first. In this post, we'll break it down step by step.What is Ownership in Rust?Ownership is Rust’s unique way of managing memory. Instead of using garbage collection or manual memory management, Rust enforces strict ownership rules at compile time. These rules ensure memory safety and prevent data races in concurrent programs.The three key ownership rules are:Each value in Rust has a single owner.When the owner goes out of scope, Rust automatically deallocates the value.Ownership can be transferred (moved) or borrowed (immutably or mutably).
  
  
  Moving, Copying, and Cloning
When assigning a value from one variable to another, ownership is transferred. Consider this example:Since  is allocated on the heap, Rust prevents double-free errors by invalidating  when ownership moves to .Certain types implement the  trait, meaning they are duplicated instead of moved. Examples include:Primitive types (integers, floats, booleans, etc.) implement , so they don’t follow move semantics.If you need to duplicate heap-allocated data, use :Cloning explicitly creates a separate copy in memory, avoiding move-related issues.Rust allows borrowing instead of transferring ownership. Borrowing enables passing data without giving up ownership.A reference () allows read-only access to data without taking ownership:You can have multiple immutable borrows at the same time, but not if there’s a mutable borrow.A mutable reference () allows modification but enforces exclusivity:Rust ensures at compile time that you cannot have multiple mutable references or a mix of mutable and immutable references at the same time.
  
  
  Lifetimes: Ensuring Valid References
Rust’s  prevent dangling references. Consider this example:The  lifetime annotation ensures that the returned reference is valid as long as both input references are valid.
  
  
  Why Rust’s Ownership Model Matters
: No need for garbage collection, yet Rust prevents use-after-free and memory leaks.: Enforces thread safety at compile time.: Eliminates runtime overhead associated with memory management.: Code is predictable and free from subtle memory bugs.Rust’s ownership model might take some getting used to, but once you grasp it, you gain the power to write efficient and safe code without worrying about memory leaks. By understanding moves, copies, borrowing, and lifetimes, you can write highly performant Rust applications while maintaining safety guarantees.Are you currently learning Rust? Let me know what aspects of ownership you find the most challenging in the comments below!]]></content:encoded></item><item><title>What is an encryption backdoor?</title><link>https://techcrunch.com/2025/02/15/what-is-an-encryption-backdoor/</link><author>Natasha Lomas</author><category>tech</category><pubDate>Sat, 15 Feb 2025 15:00:00 +0000</pubDate><source url="https://techcrunch.com/">TechCrunch</source><content:encoded><![CDATA[Talk of backdoors in encrypted services is once again doing the rounds after reports emerged that the U.K. government is seeking to force Apple to open up iCloud’s end-to-end encrypted (E2EE) device backup offering. Officials were said to be leaning on Apple to create a “backdoor” in the service that would allow state actors to […]© 2024 TechCrunch. All rights reserved. For personal use only.]]></content:encoded></item></channel></rss>