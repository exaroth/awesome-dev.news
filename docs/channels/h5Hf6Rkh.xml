<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Python</title><link>https://www.awesome-dev.news</link><description></description><item><title>RandomInvert in PyTorch</title><link>https://dev.to/hyperkai/randominvert-in-pytorch-5eb0</link><author>Super Kai (Kazuya Ito)</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 13:07:51 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[The 1st argument for initialization is (Optional-Default:-Type: or ):
*Memos:

It's the probability of whether an image is inverted or not.The 1st argument is (Required-Type: or ()):
*Memos:

A tensor must be 2D or 3D.]]></content:encoded></item><item><title>GaussianBlur in PyTorch (3)</title><link>https://dev.to/hyperkai/gaussianblur-in-pytorch-3-56do</link><author>Super Kai (Kazuya Ito)</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 11:20:32 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>just a silly game</title><link>https://dev.to/bankai2054/just-a-silly-game-29kl</link><author>anas barkallah</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 10:02:04 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Migrating from AWS CDK v1 to CDK v2</title><link>https://dev.to/sami_jaballah/migrating-from-aws-cdk-v1-to-cdk-v2-21nd</link><author>Sami Jaballah</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 09:40:02 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[If you’re currently using CDK v1 in your daily work, you’ve probably hit a roadblock trying to implement new AWS features. AWS isn’t adding those to CDK v1 anymore—so to keep up with the latest and greatest, you’ll need to migrate to CDK v2. It might sound like a hassle, but don’t worry—I’ve got your back. Let’s go through this step-by-step and get you up to speed, Python style.
  
  
  Why Should You Care About CDK v2?
Alright, let’s address the big question: why even bother migrating to CDK v2? Well, here are three solid reasons:Simplified Dependencies: No more pulling in tons of packages for different AWS services. CDK v2 bundles everything into a single package: aws-cdk-lib. How awesome is that?Stay Updated: CDK v1 isn’t getting any love anymore. If you want to keep up with the latest AWS features and updates, v2 is where it’s at.Better Developer Experience: AWS has introduced some stability guarantees and cleaned up APIs, making it easier for us to write and maintain our infrastructure code.1. Consolidated Package Structure
Remember the days of importing a separate package for each AWS service? That’s history now. CDK v2 unifies everything into aws-cdk-lib.from aws_cdk import core
from aws_cdk.aws_s3 import Bucket
from aws_cdk import Stack
from aws_cdk.aws_s3 import Bucket
2. Goodbye to Deprecated APIsSome APIs and constructs from v1 didn’t make the cut in v2. For instance, core.Construct has been replaced by constructs.Construct. A little cleanup never hurts, right?There are some great new features, like improved stability guarantees for low-level (L1) constructs and better testing capabilities with assertions.
  
  
  Let’s Get Migrating: Step-by-Step Guide
Ready to dive in? Follow these steps to upgrade your Python CDK project to v2.1. Update Your DependenciesStart by upgrading your project dependencies to use CDK v2. Open your requirements.txt or Pipfile and update them:aws-cdk-lib>=2.0.0
constructs>=10.0.0
Then, install the new dependencies:pip install -r requirements.txt
This is where the magic happens. Go through your code and replace aws_cdk.core with aws_cdk.Stack, and adjust other imports to use aws-cdk-lib.from aws_cdk import core
from aws_cdk.aws_s3 import Bucket
from aws_cdk import Stack
from aws_cdk.aws_s3 import Bucket
3. Refactor Deprecated ConstructsSome constructs have been replaced or removed. For example, core.Construct is now constructs.Construct. Update your code accordingly.class MyBucket(core.Construct):
    def __init__(self, scope: core.Construct, id: str):
        super().__init__(scope, id)
        Bucket(self, "MyBucket")
from constructs import Construct

class MyBucket(Construct):
    def __init__(self, scope: Construct, id: str):
        super().__init__(scope, id)
        Bucket(self, "MyBucket")
4. Remove Unnecessary Feature FlagsCDK v2 has removed or integrated several feature flags that were necessary in v1. To clean up your cdk.json file, remove any obsolete flags.{
  "app": "python3 app.py",
  "context": {
    "@aws-cdk/core:newStyleStackSynthesis": true,
    "@aws-cdk/aws-ec2:uniqueImds": true,
    "@aws-cdk/core:stackRelativeExports": true,
    "@aws-cdk/aws-secretsmanager:parseOwnedSecretName": true,
    "@aws-cdk/aws-kms:defaultKeyPolicies": true,
    "@aws-cdk/core:enableStackNameDuplicates": true,
    "aws-cdk:enableDiffNoFail": true,
    "@aws-cdk/aws-ecr-assets:dockerIgnoreSupport": true,
    "@aws-cdk/aws-s3:grantWriteWithoutAcl": true,
    "@aws-cdk/aws-efs:defaultEncryptionAtRest": true
  }
}
{
  "app": "python3 app.py"
}
Removing these flags ensures your project stays aligned with CDK v2 best practices.Finally, make sure everything works as expected. Run these commands:Fix any issues that pop up, and you’re good to go!
  
  
  Migration Verification Checklist
 All imports updated to aws-cdk-lib Construct imports moved to constructs package cdk diff shows expected changesAnd there you have it! Migrating from CDK v1 to v2 isn’t as scary as it might seem. With unified dependencies, better APIs, and future-proofing, this upgrade is worth the effort. Take it one step at a time, and don’t hesitate to ask for help if you hit a roadblock.Have you already migrated to CDK v2? Or are you planning to? Share your experience (or any questions) in the comments below!
  
  
  Useful links to help you along the way:
]]></content:encoded></item><item><title>My take on the Agentic Object Detection</title><link>https://dev.to/mayank_laddha_21ef3e061ff/my-take-on-the-agentic-object-detection-4612</link><author>Mayank Laddha</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 08:42:09 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[Segmenting Everything with SAM : We detect everything and worry about filtering later.Filtering with CLIP: Once we have all the segmented objects, we don’t want all of them. We need to filter out the noise and keep only the relevant objects.Adding Reasoning with a model like GPT-4o: Okay, so we’ve segmented and filtered. But what about finalising, understanding? That’s where a strong LLM like GPT-4o comes in.]]></content:encoded></item><item><title>Streamline Document Processing Pipelines with FalkorDB’s String Loader</title><link>https://dev.to/falkordb/streamline-document-processing-pipelines-with-falkordbs-string-loader-1f9g</link><author>Dan Shalev</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 08:17:53 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[ You decide how your data is chunked and processed, ensuring that the graph structure aligns perfectly with your RAG requirements. By working with runtime memory data, the string loader avoids the overhead of writing and reading intermediate files, reducing latency and simplifying the workflow.Integration with GraphRAG SDK: The string loader is designed to work seamlessly with the GraphRAG SDK, allowing you to build advanced graph-based RAG systems with greater ease and precision. The string loader is open-source, providing transparency and the ability to customize the feature to meet specific needs.]]></content:encoded></item><item><title>Building a RAG-Powered Support Chatbot in 24 Hours of Hackathon</title><link>https://dev.to/akshay_gupta/building-a-rag-powered-support-chatbot-in-24-hours-of-hackathon-5f7c</link><author>Akshay Gupta</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 07:18:48 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[Coffee? ✅ Chai? ✅ Determination to automate admin support? Double ✅In a recent 24-hour hackathon at annual PeopleGrove offsite, my team tackled an ambitious challenge: building an AI-powered support chatbot that could think and respond like a season platform administrator.Armed with Large Language Models (LLMs) and fueled by caffeine, we created a Retrieval-Augmented Generation (RAG) system that turned out to be surprisingly capable!: Our support heroes (admins and agents) spending their days 😅:Answering the same questions from different institutions 🏫

Repetitive SSO, analytics, and user management queriesSame solutions, different institutionsContext-switching between multiple support channels 🔄

Support tickets piling upTime-Consuming Routine Tasks ⏰

Manual ticket search and response formattingComplex Problem-Solving Getting Delayed 🎯

Too much time on routine questionsLimited bandwidth for critical platform improvementsOur support team needed a solution that could:Handle common queries intelligently 🤖Provide consistent, accurate responses 📚Free up time for complex problem-solving 💡Scale support without scaling the team 📈Maintain the human touch while automating routine tasks 🤝We built ChatterMind 🤖 - an AI chatbot that combines the power of LLMs with a RAG system. Think of it as a super-smart intern who:Never sleeps (unlike us during the hackathon) 😴Has photographic memory of all support tickets 🧠Knows the PeopleGrove documentation better than its authors 📚Knows when to call for backup (aka create a ticket) 🆘Remembers conversations (thanks to Redis - our MVP choice for the hackathon) 💾Keeps secrets better than a vault 🔒Here's a high-level overview of how ChatterMind processes and responds to queries:Let's geek out about our tech choices for a minute! 🤓Our initial choice was the DeepSeek model (1.5B parameters) because, well, it was lightweight and fast. But we quickly discovered it had a tendency to... let's say, get creative with the truth. After some frantic testing and a few more cups of chai, we switched to Gemini 2.0 Flash (experimental) which proved to be our goldilocks model:Better context understandingStronger reasoning capabilitiesThe secret sauce behind ChatterMind's human-like responses? Carefully crafted prompts! Our prompt engineering approach focused on:Role Definition 🎭

Defined as "Senior Product Support Specialist"Given a friendly personality and nameEstablished clear boundaries of authorityContext Management 🧩

User's current location in platformPrevious conversation historyResponse Structuring 📝

Natural, conversational flowMarkdown formatting for readabilityLength limits (100-300 words)Clear action items when neededSafety Guidelines 🛡️

Strict PII protection rulesDynamic Adaptation 🔄

First-time vs follow-up questionsTechnical vs non-technical usersSimple queries vs complex issuesError scenarios vs success pathsExample Prompt Template 📝System Context:
You are ChatterMind, a Senior Product Support Specialist at PeopleGrove.
Primary Goal: Provide clear, accurate, and helpful support while maintaining security.

Behavioral Guidelines:
- Be professional yet friendly
- Start with a warm greeting for new conversations
- For follow-ups, continue naturally without greeting
- Keep responses under 300 words
- Use markdown only when needed
- Never share PII or sensitive data
- If unsure, ask for clarification
- For complex issues, guide towards ticket creation

Current Context:
- User Location: {current_path}
- Required Permissions: {path_permissions}
- User Role: {user_role}

Previous Conversation:
{chat_history}

Reference Knowledge:
{relevant_articles}
{similar_tickets}
{route_context}

Current Question: {user_query}

Response Format:
1. [If new conversation] Brief greeting
2. Acknowledge context/location
3. Provide clear solution/steps
4. Add relevant warnings/notes
5. Offer follow-up assistance
Natural conversation flow 💬Helpful, actionable responses ✅
  
  
  Data Processing & Embeddings
We built our knowledge base from three main sources:Platform Routes & Permissions:For embeddings, we chose the  model from  because:384-dimensional embeddings (good balance of size vs. accuracy)Fast inference time (crucial for real-time chat)Great at capturing semantic meaningWorks well with technical contentWe stored these in ElasticSeach with cosine similarity search, which gave us:
  
  
  Edge Cases & Safety Features
ChatterMind turned out to be quite the responsible assistant. Some of our favourite edge case handles:Personal Data Protection:User: "What's John Smith's email address?"
ChatterMind: "I apologize, but I cannot share personal information such as email addresses, phone numbers, or other private details about users. This is to protect user privacy and comply with data protection regulations. If you need to contact someone, I recommend using the platform's built-in messaging system."
User: "Can you update my database permissions?"
ChatterMind: "I'm not able to directly modify system permissions or make database changes. This requires admin intervention for security reasons. Would you like me to help you create a ticket for this request?"
Handling Requests not related to Platform:User: "What is 5 + 2 + 7?"
ChatterMind: "I apologise, but performing mathematical calculations is beyond my scope as a platform support assistant. I'm designed to help with PeopleGrove platform-related questions and issues. If you need a calculator, I'd recommend using your device's built-in calculator app or a dedicated math tool."
User: "It's not working"
ChatterMind: "I notice you're on the messaging page, but I'll need more details to help you effectively. Could you please:
1. Describe what specific feature isn't working
2. What you were trying to do
3. What error message (if any) you're seeing

This will help me provide the most relevant solution."
Our implementation was heavily inspired by the excellent guide on building RAG systems with DeepSeek R1 by Asif Razzaq at MarkTechPost. While we ultimately chose Gemini 2.0 Flash for our use case, the fundamental RAG architecture outlined in the guide formed the backbone of our system.Key learnings we adapted from the guide:Document processing pipeline structureVector store implementation with FAISSEfficient retrieval mechanismsWe modified these concepts to fit our specific needs:The guide's emphasis on proper document chunking and context relevance directly influenced our implementation of the knowledge base processing:
  
  
  Real-time Communication with WebSockets
Why WebSockets? Because nobody likes waiting! We needed real-time, bi-directional communication between the frontend and our RAG system. RESTful APIs would've meant:No server-initiated messagesMore complex state managementChatbot responses getting suck "in transit"Here's how we implemented it:The WebSocket connection allows us to:Stream responses in real-timeMaintain conversation stateImplement retry mechanism
  
  
  ElasticSearch as Our Knowledge Base
While FAISS was suggested in the DeepSeek guide, we chose ElasticSearch for our vector store because:Built-in text search capabilitiesEfficient vector similarity searchHere's our ElasticSearch setup:
  
  
  Cool Features We're Proud Of
Context-Aware Responses

The bot doesn't just search - it understands where the user is in the platform and what they've been talking about. It's like having a GPS for user context!Privacy First

We trained our bot to be as tight-lipped as a secret agent about sensitive data. Try asking for someone's email - it'll give you the "I cannot share that information" speech faster than you can say "GDPR"!Beyond the Knowledge Base

The real magic happens when users ask questions that aren't in any document. By combining context with LLM capabilities, ChatterMind can reason about platform behaviour and suggest solutions, like a true admin would.
ChatterMind: "Hi Akshay, my name is ChatterMind! 👋 Welcome to XYZ Support. I'm here to help with any questions you have about mentoring, connecting with alumni, or using the platform. How can I assist you today?"
User: "Why is the page not working?"
ChatterMind: "It sounds like you're having trouble accessing the admin dashboard. To help me figure out why the page isn't working, could you tell me if you have correct access? This page requires admin-level permissions to function correctly. Also, please note that this page is not available on native mobile apps, so if you are using a mobile app, that could be the reason why it's not working.

If you do have the correct permissions and are not using a mobile app, could you describe what you're seeing on the page? Any details you can provide will help me troubleshoot the issue.

Please let me know if you have any other questions."

  
  
  Hackathon Compromises (aka Technical Debt)
Let's be real - in 24 hours, we had to cut some corners:Redis for chat history

Would use a proper database for productionNo backup/persistence configurationSecurity shortcuts

Basic token authenticationPerformance trade-offs

Single-node ElasticSearchIf we had more time (and less caffeine), we'd love to add:Proper infrastructure

Distributed chat history storageCool features

Voice interface (for those too tired to type)Multi-language support (because admins speak many languages)Predictive issue detection (stop problems before they happen!)This project wouldn't have been possible (let alone won the hackathon! 🏆 🎉) without my amazing team's diverse skills and relentless energy. Special thanks to:Our AI/ML engineer Suyash who became our guide at times and pointed us in right direction. 🧠Our Engineers Rajat & Rahul who made WebSockets work like magic, and did the end-to-end integration on my core idea. ⚡Our Engineers Manoj & Samrood who integrated ElasticSearch & became frontend ninjas who created a sleek chat-interface. 🎨And countless Chai & Coffee that fuelled our coding marathons. 🥤Winning the hackathon was the cherry on top of an incredible 24-hour journey. It proved that when passionate developers come together with a clear mission (and enough caffeine), we can create something truly impactful.Our hackathon project proved that with modern LLMs, good prompt engineering, and a solid RAG system, you can build a surprisingly capable admin support chatbot in just 24 hours.While not production-ready, it showed the potential for AI to transform admin support from a repetitive task to an intelligent service.No admins were harmed in the making of this chatbot, though several cups of Chai and Coffee were consumed! 🚀 ☕ 🎉]]></content:encoded></item><item><title>Python for Web Developers: A Fast-Paced Guide to the Language</title><link>https://dev.to/austinwdigital/python-for-web-developers-a-fast-paced-guide-to-the-language-38f7</link><author>Austin W</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 06:24:00 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[👋  Follow me on GitHub for new projects.Python is a powerful, high-level programming language widely used in web development, automation, data science, and scripting. If you're already a  familiar with JavaScript, TypeScript, Node.js, and frameworks like React or Next.js, learning Python can open doors to backend development with Django, Flask, and FastAPI, as well as automation, data analysis, and AI.This guide is a  of Python, focusing on concepts that web developers need to know. If you’re comfortable with JavaScript, you’ll find Python’s syntax clean and easy to pick up.1. Python Syntax & BasicsHello World (No Semicolons, No Braces)✔ No semicolons ().—uses indentation., just .  Variables & Dynamic Typing✔ No need to declare , , or .
✔ Types are inferred dynamically.  
  
  
  How Does const Work in Python?
Python does not have const like JavaScript, but you can define constants by using all-uppercase variable names as a convention.However, this does not enforce immutability. If you need true immutability, use a dataclass or a frozen set.Data Types (Compared to JavaScript)let obj = {key: "value"};2. Control Flow (Loops & Conditionals)✔ No parentheses  needed for conditions. instead of .  ✔  loops iterate directly over lists/arrays. loops work like JavaScript.  3. Functions & Lambda Expressions✔  replaces ., just indentation.  Lambda (Arrow Function Equivalent)✔ Equivalent to JavaScript’s arrow function:4. Python Collections (Lists, Dicts, Sets)let obj = { key: "value" };obj = {"key": "value"}  # Dictionaryconst unique = new Set([1, 2, 3]);unique = {1, 2, 3}  # SetDictionaries (Like Objects)5. Object-Oriented Programming (OOP) in Python✔  is the  (like  in JS). is like .  6. Python for Web DevelopmentDjango (Full-Stack Framework)pip django
django-admin startproject myproject
✔  is a batteries-included backend framework.
✔ Built-in ORM, authentication, and templating.  Flask (Lightweight API Framework)✔  is minimal and great for APIs.  FastAPI (High-Performance API)✔  is async-native and perfect for microservices.  SQLite Example (Django & Flask Compatible)✔  is built-in, no installation needed.  8. Asynchronous Programming in PythonAsync/Await (Similar to JavaScript)✔ Uses / like JavaScript. is the  equivalent of Node.js.  9. Python Package ManagementCreate Virtual Environment✔  for package management. () isolate dependencies.   10. Best Practices for Python DevelopmentWriting clean, efficient, and maintainable Python code is essential for long-term scalability. Here are the key best practices that every Python developer should follow:Follow PEP 8 (Python Style Guide)Python has an official style guide called , which provides conventions for writing Python code.4 spaces per indentation level (not tabs)..meaningful variable and function names. for variable and function names, and  for class names.Python’s  isolate dependencies for different projects, preventing conflicts.Creating a Virtual EnvironmentActivating the Virtual EnvironmentDeactivating the Virtual EnvironmentUse Type Hinting for Readable CodePython is dynamically typed, but you can use  to improve code clarity.✔ This makes the code . catch type errors.Write Readable DocstringsAlways document your functions and classes using  ().✔ Use triple quotes for multi-line docstrings.parameters, return values, and purpose.  Python uses  for  and triple quotes () for .✔ Use comments only where necessary—good code should be self-explanatory.Docstrings are not comments—they are for documentation and can be accessed with .  12. Common Python Imports for Web DevelopmentHere are some of the most common Python imports used in web development:13. Setting Up a  FileA  file is similar to  in Node.js—it lists dependencies for a Python project.Creating a  Filepip freeze  requirements.txt
Installing Dependencies from pip  requirements.txt
✔ This ensures that all team members and deployment environments have the .  14. Writing & Running Tests in PythonPython has built-in testing with , but  is another option - one that aims for simplicity.✔ Use  to check expected results.✔ —just use . test files named .  15. Fetching Data with API Calls in PythonPython uses  to fetch data, similar to  in JavaScript.✔  is like  in JavaScript. works the same way in both languages.Sending Data (POST Request)✔ Use  instead of  to send JSON.Logging is essential for debugging and monitoring applications.✔ Works like  but supports different log levels.  ✔ Saves logs for later analysis.17. Raising & Handling Errors in Python LoggingWhen an error occurs, Python lets you  or .✔ Use  to manually trigger an error.  Instead of crashing, log errors with a traceback:✔  logs the full error traceback.Python is a useful language for web developers, expanding your stack beyond JavaScript. Whether you’re building APIs with FastAPI, full-stack apps with Django, or automating tasks, Python makes it .🚀  Try building a small Flask or FastAPI project today!Python #WebDev #Django #Flask #FastAPI  A fast-paced guide to Python for web developers! Learn how to use Python for full-stack development, APIs, databases, async programming, and more. 🚀  
  
  
  TLDR – Highlights for Skimmers
Python syntax is simpler than JavaScript—no semicolons, indentation replaces {}.const does not exist in Python; uppercase variables are used for constants.Lists ([]) are like arrays, but dictionaries ({}) are not JavaScript objects.Classes & objects are similar, but Python uses self instead of this.Python async/await requires asyncio, unlike JavaScript’s built-in event loop.Django, Flask, and FastAPI are top backend frameworks for Python web dev.💬 Do you use Python in web dev? Share your experience in the comments! ]]></content:encoded></item><item><title>Code Optimization Strategies for Game Development 🔥</title><link>https://dev.to/codewithshahan/code-optimization-strategies-for-game-development-2n0e</link><author>Programming with Shahan</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 05:46:59 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[Game development is a battlefield. Either you optimize, or you lose. Period.I don’t care if you’re an experienced developer with 10 years of experience or 1 year of experience. If you want to make games that WORK, games people respect—you need to understand . Players demand smooth gameplay, high-quality visuals, and a flawless experience across every device. If your game stutters, crashes, or loads slower than a snail? You’re done. Optimization isn’t magic. It’s the foundation of smooth gameplay, fast loading, and stable performance. Without it, your game will lag, crash, and be forgotten faster than you can say “game over.”  But don’t worry. In this article, I will share four effective strategies to help you with that. 
  
  
  Effective Strategies for Performance Optimization
🤸‍♂️ What Is Optimization? Optimization means making your game run as fast and smooth as possible. SIMPLE.When you optimize your game, you:  🖥️ Make the game work on weaker computers or phones.💉 Prevent lag and crashes.Rule 1: Memory ManagementWhen you’re developing a game, memory is your most valuable resource.Every player movement, every enemy on the screen, every explosion needs a little piece of memory to function. Unfortunately, If you don’t manage memory properly, your game can get slow, laggy, or even crash. That’s why memory management is a critical skill every game developer needs. Let’s break it down step by step, with detailed examples in Python.Strategy #1: Memory PoolingThis strategy is simple: reuse Objects Instead of Creating New Ones** Memory pooling is like recycling for your game. Instead of creating new objects every time you need one, you reuse objects you’ve already created.  Creating and destroying objects repeatedly takes up time and memory. Let's say you are building a shooting game where the player fires 10 bullets per second. If you create a new bullet for each shot, your game could quickly slow down.  Here’s how you can implement memory pooling for bullets in a shooting game:The  Class: Defines what a bullet does and keeps track of whether it’s active (in use) or not.
The : A list of 10 reusable bullets.
The  Function: Finds an inactive bullet, reuses it, and sets its position.
Recycling Bullets: When you’re done with a bullet, you reset it so it can be reused.
Strategy #2. Data Structure OptimizationThe way you store your data can make or break your game’s performance. Choosing the wrong data structure is like trying to carry water in a leaky bucket—it’s inefficient and messy.  Let’s say you’re making a game for four players, and you want to keep track of their scores. You could use a list, but a fixed-size array is more efficient because it uses less memory. Creates a fixed-size array of integers ().
 You can’t accidentally add or remove elements, which prevents bugs and saves memory.
 Updating scores is quick and uses minimal resources.
Strategy #3. Memory ProfilingEven if your code seems perfect, hidden memory problems can still exist. Memory profiling helps you monitor how much memory your game is using and find issues like memory leaks.  Python has a built-in tool called  that tracks memory usage. Here’s how to use it: begins monitoring memory usage.
 Create a large list to use up memory.
 Get the current and peak memory usage, converting it to megabytes for readability.
 ends the tracking session.
Now it’s your turn to practice these strategies and take your game development skills to the next level!Rule 2: Asset Streaming (Load Only What You Need)If you load the entire world at once, your game will choke and die. You don’t need that drama. Instead, stream assets as the player needs them. This is called asset streaming. For instance, inside your game, you may have a huge open-world with forests, deserts, and cities. Why load all those levels at once when the player is only in the forest? Makes no sense, right? Load  and keep your game lean, fast, and smooth.Strategy #1: Segment and PrioritizeLet’s break this down with an example. Your player is exploring different levels: Forest, Desert, and City. We’ll only load a level when the player enters it.Here’s how to make it work in Python: Each level has a name (e.g., Forest) and a “loaded” status. If it’s loaded, it doesn’t load again.
 The  function finds the level the player wants to enter and loads it only if it hasn’t been loaded yet.
 Levels not visited don’t waste memory. The game runs smoothly because it only focuses on what the player needs.This is efficiency at its finest. No wasted memory, no wasted time. Your player moves; your game adapts. That’s how you dominate.  Strategy #2: Asynchronous Loading (No Waiting Allowed)Nobody likes waiting. Freezing screens? Laggy loading? It’s amateur hour. You need —this loads assets in the background while your player keeps playing.  Imagine downloading a huge map while still exploring the current one. Your game keeps moving, the player stays happy.Here’s how to simulate asynchronous loading in Python: The  module creates a new thread to load assets without freezing the main game.
 The  function fakes the loading time to mimic how it works in a real game.
 The player can continue playing while the new level or asset loads in the background.
With asynchronous loading, your player stays in the zone, and your game feels seamless. Pro-level stuff.Strategy 3: Level of Detail (LOD) Systems – Be Smart About QualityNot everything in your game needs to look like it’s been rendered by a Hollywood studio. If an object is far away, lower its quality. It’s called , and it’s how you keep your game’s performance sharp.  Example: Using LOD for a TreeHere’s a Python simulation of switching between high and low detail: The  property determines how far the tree is from the player.
 If the tree is close, render it in high detail. If it’s far, use low detail to save memory and processing power.
 The player doesn’t notice the difference, but your game runs smoother and faster.
This is how you keep the balance between beauty and performance. Your game looks stunning up close but doesn’t waste resources on faraway objects. Only load what you need, when you need it. No wasted memory.
 Smooth gameplay keeps players engaged and avoids frustration.
 These techniques are how AAA games stay fast and responsive.
 Go apply these strategies, keep your game lean, and make sure your players never even think about lag.Rule 3: Frame Rate StabilizationThe frame rate is how many pictures (frames) your game shows per second. If it’s unstable, your game will stutter and feel broken.  The secret? Keep the workload for each frame consistent.  🚦Here’s how you can control the timing in a game loop:⚖️ The game updates at a steady rate (60 times per second).
🪂 This make smooth gameplay, no matter how slow or fast the computer is.
Optimize Rendering Paths: Fewer draw calls. Smarter culling. Simplicity wins.Dynamic Resolution Scaling: When the pressure’s on, scale down resolution to maintain the frame rate. Players won’t even notice.Fixed Time Step: Keep your physics and logic consistent. Frame rate fluctuations shouldn’t mean chaos.Rule 4: GPU and CPU OptimizationYour computer has two main processors:   Handles logic, like moving a character or calculating scores.
 Handles graphics, like drawing your game world.
👇 Here's what you have to do for GPU/CPU optimization:Profile Everything: Use tools to pinpoint bottlenecks and strike hard where it hurts.
Shader Optimization: Shaders are resource hogs. Simplify them, streamline them, and cut the fat.
Multithreading: Spread tasks across CPU cores. Don’t overload one and leave the others idle.If one is working too hard while the other is idle, your game will lag.  Solution? Multithreading.
Let’s split tasks between two threads:🎰 One thread handles logic.
🛣️ Another thread handles graphics.
⚖️ This balances the workload and prevents bottlenecks.
Optimization isn’t just for “smart” people. It’s simple if you take it step by step:  Manage memory like a pro. Don’t waste it.
 Load only what you need.
Keep the frame rate stable. No stuttering.
 Use the CPU and GPU wisely.
Start optimizing NOW. Your future self will thank you.  ]]></content:encoded></item><item><title>Automating Daily arXiv Paper Summaries with Slack Notifications</title><link>https://dev.to/m_sea_bass/automating-daily-arxiv-paper-summaries-with-slack-notifications-1kp8</link><author>M Sea Bass</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 05:26:47 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[This post is a follow-up to the previous article. It turns out there’s a slight delay before the latest papers show up in the arXiv API. Because of this delay, the same paper can sometimes appear the next day.To fix this, we’re going to record the timestamp of the last retrieved paper and then only fetch new papers each day.We’ll store the timestamp of the latest paper in Amazon S3 so we can both update and retrieve it later. For this, you’ll need to install . In the  folder we created previously, run:Next, zip the folder again and upload it as a new version of your Lambda layer:zip  ./upload.zip ./python/Then, update your Lambda function to use this new layer version.You’ll also need an S3 bucket ready in advance. In this example, we simply created one with the default settings.Below is the fully revised code in English, including the new functions to update and retrieve the timestamp from S3. Note that we set  as an environment variable.By saving the timestamp in S3, your script won’t process the same paper entries each day, and if no new papers appear, the script will skip generating summaries. This helps reduce unnecessary API usage and costs.]]></content:encoded></item><item><title>GaussianBlur in PyTorch (2)</title><link>https://dev.to/hyperkai/gaussianblur-in-pytorch-2-1bj2</link><author>Super Kai (Kazuya Ito)</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 04:47:39 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>GaussianBlur in PyTorch (1)</title><link>https://dev.to/hyperkai/gaussianblur-in-pytorch-1-3ndn</link><author>Super Kai (Kazuya Ito)</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 04:35:52 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[The 1st argument for initialization is (Optional-Type: or /()):
*Memos:

A tuple/list must be the 1D with 1 or 2 elements.A single value( or ()) means [kernel_size, kernel_size].The 2nd argument for initialization is (Optional-Default:-Type:,  or /( or )):
*Memos:

It's  so it must be .A tuple/list must be the 1D with 1 or 2 elements.A single value(,  or ( or )) means .The 1st argument is (Required-Type: or ()):
*Memos:

A tensor must be 2D or 3D.]]></content:encoded></item><item><title>Weekly Challenge: Counting the XOR</title><link>https://dev.to/simongreennet/weekly-challenge-counting-the-xor-4hhc</link><author>Simon Green</author><category>dev</category><category>python</category><pubDate>Sun, 16 Feb 2025 04:23:00 +0000</pubDate><source url="https://dev.to/t/python">Dev.to Python</source><content:encoded><![CDATA[Each week Mohammad S. Anwar sends out The Weekly Challenge, a chance for all of us to come up with solutions to two weekly tasks. My solutions are written in Python first, and then converted to Perl. It's a great way for us all to practice some coding.You are given two array of strings,  and .Write a script to return the count of common strings in both arrays.The tasks and examples don't mention what to do if a string appears more than once in both arrays. I've made the assumption that we only need to return it once.For the command line input, I take two strings that are space separated as shown in the example.In Python this is a one liner. I turn the lists into sets (which only has unique values) and take the length of the intersection of these two sets.Perl does not have sets or intersections built in. For the Perl solution, I turn both strings into a hash with the key being the strings. I then iterate through the keys of the first hash to see if they appear in the second hash. If they do, I increment the  variable../ch-1.py 
2

./ch-1.py 
1

./ch-1.py 
0
You are given an encoded array and an initial integer.Write a script to find the original array that produced the given encoded array. It was encoded such that encoded[i] = orig[i] XOR orig[i + 1].This is relatively straight forward. For the command line input, I take the last value as the  integer, and the rest as the  integers.For this task, I create the  list (array in Perl) with the  value. I then iterate over each item in the  list and takes the exclusive-or of it and the last value in the  list../ch-2.py 1 2 3 1
1, 0, 2, 1]

./ch-2.py 6 2 7 3 4
4, 2, 0, 7, 4]
]]></content:encoded></item><item><title>Kay Hayen: Nuitka this week #16</title><link>https://nuitka.net/posts/nuitka-this-week-16.html</link><author></author><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 23:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Hey Nuitka users! This started out as an idea of a weekly update, but
that hasn’t happened, and so we will switch it over to just writing up
when something interesting happens and then push it out relatively
immediately when it happens.Nuitka Onefile Gets More Flexible:  and We’ve got a couple of exciting updates to Nuitka’s onefile mode that
give you more control and flexibility in how you deploy your
applications. These enhancements stem from real-world needs and
demonstrate Nuitka’s commitment to providing powerful and adaptable
solutions.Taking Control of Onefile Unpacking: Onefile mode is fantastic for creating single-file executables, but the
management of the unpacking directory where the application expands has
sometimes been a bit… opaque. Previously, Nuitka would decide whether
to clean up this directory based on whether the path used
runtime-dependent variables. This made sense in theory, but in practice,
it could lead to unexpected behavior and made debugging onefile issues
harder.Now, you have complete control! The new  option
lets you explicitly specify what happens to the unpacking directory:: This is the default behavior. Nuitka
will remove the unpacking directory unless runtime-dependent values
were used in the path specification. This is the same behavior as
previous versions.: The unpacking directory is 
removed and becomes a persistent, cached directory. This is useful
for debugging, inspecting the unpacked files, or if you have a use
case that benefits from persistent caching of the unpacked data. The
files will remain available for subsequent runs.: The unpacking directory 
removed after the program exits.This gives you the power to choose the behavior that best suits your
needs. No more guessing!Relative Paths with Another common request, particularly from users deploying applications
in more restricted environments, was the ability to specify the onefile
unpacking directory  to the executable itself. Previously, you
were limited to absolute paths or paths relative to the user’s temporary
directory space.We’ve introduced a new variable, , that you can use in
the  option. This variable is dynamically
replaced at runtime with the full path to the directory containing the
onefile executable.This would create a directory named  the same
directory as the  (or  on Linux/macOS)
and unpack the application there. This is perfect for creating truly
self-contained applications where all data and temporary files reside
alongside the executable.Nuitka Commercial and Open SourceThese features, like many enhancements to Nuitka, originated from a
request by a Nuitka commercial customer. This highlights the close
relationship between the commercial offerings and the open-source core.
While commercial support helps drive development and ensures the
long-term sustainability of Nuitka, the vast majority of features are
made freely available to all users.This change will be in 2.7 and is currentlyWe encourage you to try out these new features and let us know what you
think! As always, bug reports, feature requests, and contributions are
welcome on GitHub.]]></content:encoded></item><item><title>Django Weblog: DjangoCongress JP 2025 Announcement and Live Streaming!</title><link>https://www.djangoproject.com/weblog/2025/feb/14/djangocongress-jp-2025-announcement-and-livestream/</link><author></author><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 22:12:10 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[It will be streamed on the following YouTube Live channels:This year there will be talks not only about Django, but also about FastAPI and other asynchronous web topics. There will also be talks on Django core development, Django Software Foundation (DSF) governance, and other topics from around the world. Simultaneous translation will be provided in both English and Japanese.The Async Django ORM: Where Is it?Speed at Scale for Django Web ApplicationsImplementing Agentic AI Solutions in Django from scratchDiving into DSF governance: past, present and futureGetting Knowledge from Django Hits: Using Grafana and PrometheusCulture Eats Strategy for Breakfast: Why Psychological Safety Matters in Open SourceµDjango. The next step in the evolution of asynchronous microservices technology.A public viewing of the event will also be held in Tokyo. A reception will also be held, so please check the following connpass page if you plan to attend.]]></content:encoded></item><item><title>Eli Bendersky: Decorator JITs - Python as a DSL</title><link>https://eli.thegreenplace.net/2025/decorator-jits-python-as-a-dsl/</link><author></author><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 21:49:31 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Spend enough time looking at Python programs and packages for machine learning,
and you'll notice that the "JIT decorator" pattern is pretty popular. For
example, this JAX snippet:In both cases, the function decorated with  doesn't get executed by the
Python interpreter in the normal sense. Instead, the code inside is more like
a DSL (Domain Specific Language) processed by a special purpose compiler built
into the library (JAX or Triton). Another way to think about it is that Python
is used as a  to describe computations.In this post I will describe some implementation strategies used by libraries to
make this possible.Preface - where we're goingThe goal is to explain how different kinds of  decorators work by using
a simplified, educational example that implements several approaches from
scratch. All the approaches featured in this post will be using this flow: Expr IR --> LLVM IR --> Execution" /> Expr IR --> LLVM IR --> Execution" class="align-center" src="https://eli.thegreenplace.net/images/2025/decjit-python.png" />
These are the steps that happen when a Python function wrapped with
our educational  decorator is called:The function is translated to an "expression IR" - .This expression IR is converted to LLVM IR.Finally, the LLVM IR is JIT-executed.First, let's look at the  IR. Here we'll make a big simplification -
only supporting functions that define a single expression, e.g.:Naturally, this can be easily generalized - after all, LLVM IR can be used to
express fully general computations.Here are the  data structures:To convert an  into LLVM IR and JIT-execute it, we'll use this function:It uses the  class to actually generate LLVM IR from .
This process is straightforward and covered extensively in the resources I
linked to earlier; take a look at the full code here.My goal with this architecture is to make things simple, but .
On one hand - there are several simplifications: only single expressions are
supported, very limited set of operators, etc. It's very easy to extend this!
On the other hand, we could have just trivially evaluated the 
without resorting to LLVM IR; I do want to show a more complete compilation
pipeline, though, to demonstrate that an arbitrary amount of complexity can
be hidden behind these simple interfaces.With these building blocks in hand, we can review the strategies used by
 decorators to convert Python functions into s.Python comes with powerful code reflection and introspection capabilities out
of the box. Here's the  decorator:This is a standard Python decorator. It takes a function and returns another
function that will be used in its place ( ensures that
function attributes like the name and docstring of the wrapper match the
wrapped function).After  is applied to , what  holds is the
wrapper. When  is called, the wrapper is invoked with
.The wrapper obtains the AST of the wrapped function, and then uses
 to convert this AST into an :When  finishes visiting the AST it's given, its
 field will contain the  representing the function's
return value. The wrapper then invokes  with this .Note how our decorator interjects into the regular Python execution process.
When  is called, instead of the standard Python compilation and
execution process (code is compiled into bytecode, which is then executed
by the VM), we translate its code to our own representation and emit LLVM from
it, and then JIT execute the LLVM IR. While it seems kinda pointless in this
artificial example, in reality this means we can execute the function's code
in any way we like.AST JIT case study: TritonThis approach is almost exactly how the Triton language works. The body of a
function decorated with  gets parsed to a Python AST, which then
- through a series of internal IRs - ends up in LLVM IR; this in turn is lowered
to PTX by the
NVPTX LLVM backend.
Then, the code runs on a GPU using a standard CUDA pipeline.Naturally, the subset of Python that can be compiled down to a GPU is limited;
but it's sufficient to run performant kernels, in a language that's much
friendlier than CUDA and - more importantly - lives in the same file with the
"host" part written in regular Python. For example, if you want testing and
debugging, you can run Triton in "interpreter mode" which will just run the
same kernels locally on a CPU.Note that Triton lets us import names from the  package
and use them inside kernels; these serve as the  for the language
- special calls the compiler handles directly.Python is a fairly complicated language with  of features. Therefore,
if our JIT has to support some large portion of Python semantics, it may make
sense to leverage more of Python's own compiler. Concretely, we can have it
compile the wrapped function all the way to bytecode,
and start our translation from there.Here's the  decorator that does just this :The Python VM is a stack machine; so we emulate a stack to convert the
function's bytecode to  IR (a bit like an RPN evaluator).
As before, we then use our  utility function to lower
 to LLVM IR and JIT execute it.Using this JIT is as simple as the previous one - just swap 
for :Bytecode JIT case study: NumbaNumba is a compiler for Python itself. The idea
is that you can speed up specific functions in your code by slapping a
 decorator on them. What happens next is similar in spirit to
our simple , but of course much more complicated because it
supports a very large portion of Python semantics.Numba uses the Python compiler to emit bytecode, just as we did; it then
converts it into its own IR, and then to LLVM using .By starting with the bytecode, Numba makes its life easier (no need to rewrite
the entire Python compiler). On the other hand, it also makes some analyses
, because by the time we're in bytecode, a lot of semantic information
existing in higher-level representations is lost. For example, Numba has to
sweat a bit to recover control flow information from the bytecode (by
running it through a special interpreter first).The two approaches we've seen so far are similar in many ways - both rely on
Python's introspection capabilities to compile the source code of the JIT-ed
function to some extent (one to AST, the other all the way to bytecode), and
then work on this lowered representation.The tracing strategy is very different. It doesn't analyze the source code of
the wrapped function at all - instead, it  its execution by means of
specially-boxed arguments, leveraging overloaded operators and functions, and
then works on the generated trace.The code implementing this for our smile demo is surprisingly compact:Each runtime argument of the wrapped function is assigned a , and
that is placed in a , a placeholder class which lets us
do operator overloading:The remaining key function is :To understand how this works, consider this trivial example:After the decorated function is defined,  holds the wrapper function
defined inside . When  is called, the wrapper runs:For each argument of  itself (that is  and ), it creates
a new  holding a . This denotes a named variable in
the  IR.It then calls the wrapped function, passing it the boxes as runtime
parameters.When (the wrapped)  runs, it invokes . This is caught by the overloaded
 operator of , and it creates a new  with
the s representing  and  as children. This
 is then returned .The wrapper unboxes the returned  and passes it to
 to emit LLVM IR from it and JIT execute it with the
actual runtime arguments of the call: .This might be a little mind-bending at first, because there are two different
executions that happen:The first is calling the wrapped  function itself, letting the Python
interpreter run it as usual, but with special arguments that build up the IR
instead of doing any computations. This is the .The second is lowering this IR our tracing step built into LLVM IR and then
JIT executing it with the actual runtime argument values ; this is
the .This tracing approach has some interesting characteristics. Since we don't
have to analyze the source of the wrapped functions but only trace through
the execution, we can "magically" support a much richer set of programs, e.g.:This  with our basic . Since Python variables are
placeholders (references) for values, our tracing step is oblivious to them - it
follows the flow of values. Another example:This also just works! The created  will be a long chain of 
additions of 's runtime values through the loop, added to the 
for .This last example also leads us to a limitation of the tracing approach; the
loop cannot be  - it cannot depend on the function's arguments,
because the tracing step has no concept of runtime values and wouldn't know
how many iterations to run through; or at least, it doesn't know this unless
we want to perform the tracing run for every runtime execution .Tracing JIT case study: JAXThe JAX ML framework uses a tracing
approach very similar to the one described here. The first code sample in this
post shows the JAX notation. JAX cleverly wraps Numpy with its own version which
is traced (similar to our , but JAX calls these boxes "tracers"),
letting you write regular-feeling Numpy code that can be JIT optimized and
executed on accelerators like GPUs and TPUs via XLA. JAX's tracer builds up an underlying IR (called
jaxpr) which can then be
emitted to XLA ops and passed to XLA for further lowering and execution.For a fairly deep overview of how JAX works, I recommend reading the
autodidax doc.As mentioned earlier, JAX has some limitations
with things like data-dependent control flow in native Python. This won't work,
because there's control flow
that depends on a runtime value ():When  is executed, JAX will throw an exception, saying something
like:
This concrete value was not available in Python because it depends on the
value of the argument count.As a remedy, JAX has its
own built-in intrinsics from the jax.lax package.
Here's the example rewritten in a way that actually works: (and many other built-ins in the  package) is something JAX
can trace through, generating a corresponding XLA operation (XLA has support for
While loops, to which this
 can be lowered).The tracing approach has clear benefits for JAX as well; because it only cares
about the flow of values, it can handle arbitrarily complicated Python code,
as long as the flow of values can be traced. Just like the local variables and
data-independent loops shown earlier, but also things like closures. This makes
meta-programming and templating easy .The full code for this post is available on GitHub.]]></content:encoded></item><item><title>Hugo van Kemenade: Improving licence metadata</title><link>https://hugovk.dev/blog/2025/improving-licence-metadata/</link><author></author><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 15:11:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[PEP 639 defines a spec on how to document licences
used in Python projects.Change  as follows.I usually use Hatchling as a build backend, and support was added in 1.27:Replace the freeform  field with a valid SPDX license expression, and add
 which points to the licence files in the repo. There’s often only one,
but if you have more than one, list them all:Optionally delete the deprecated licence classifier:Then make sure to use a PyPI uploader that supports this.pip can also show you the metadata:A lot of work went into this. Thank you to PEP authors
Philippe Ombredanne for creating the first draft in
2019, to C.A.M. Gerlach for the second draft in 2021,
and especially to Karolina Surma for getting the third
draft finish line and helping with the implementation.And many projects were updated to support this, thanks to the maintainers and
contributors of at least:]]></content:encoded></item><item><title>Real Python: The Real Python Podcast – Episode #239: Behavior-Driven vs Test-Driven Development &amp;amp; Using Regex in Python</title><link>https://realpython.com/podcasts/rpp/239/</link><author></author><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 12:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[What is behavior-driven development, and how does it work alongside test-driven development? How do you communicate requirements between teams in an organization? Christopher Trudeau is back on the show this week, bringing another batch of PyCoder's Weekly articles and projects.]]></content:encoded></item><item><title>Daniel Roy Greenfeld: Building a playing card deck</title><link>https://daniel.feldroy.com/posts/2025-02-deck-of-cards</link><author></author><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 09:50:04 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Today is Valentine's Day. That makes it the perfect day to write a blog post about showing how to not just build a deck of cards, but show off cards from the heart suite.]]></content:encoded></item><item><title>Bojan Mihelac: Prefixed Parameters for Django querystring tag</title><link>http://code.informatikamihelac.com/en/query-string-with-prefixed-parameters/</link><author></author><category>dev</category><category>python</category><pubDate>Thu, 13 Feb 2025 21:37:18 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[An overview of Django 5.1's new querystring tag and how to add support for prefixed parameters.]]></content:encoded></item><item><title>Peter Bengtsson: get in JavaScript is the same as property in Python</title><link>http://www.peterbe.com/plog/get-in-javascript-is-the-same-as-property-in-python</link><author></author><category>dev</category><category>python</category><pubDate>Thu, 13 Feb 2025 12:41:56 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Prefix a function, in an object or class, with `get` and then that acts as a function call without brackets. Just like Python's `property` decorator.]]></content:encoded></item><item><title>EuroPython: EuroPython February 2025 Newsletter</title><link>https://blog.europython.eu/europython-february-2025-newsletter/</link><author></author><category>dev</category><category>python</category><pubDate>Thu, 13 Feb 2025 08:36:11 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Hope you&aposre all having a fantastic February. We sure have been busy and got some exciting updates for you as we gear up for EuroPython 2025, which is taking place once again in the beautiful city of Prague. So let&aposs dive right in!EuroPython 2025 is right around the corner and our programme team is hard at work putting together an amazing lineup. But we need your help to shape the conference! We received over 572 fantastic proposals, and now it’s time for Community Voting! 🎉 If you&aposve attended EuroPython before or submitted a proposal this year, you’re eligible to vote.📢 More votes = a stronger, more diverse programme! Spread the word and get your EuroPython friends to cast their votes too.🏃The deadline is , so don’t miss your chance!Want to play a key role in building an incredible conference? Join our review team and help select the best talks for EuroPython 2025! Whether you&aposre a Python expert or an enthusiastic community member, your insights matter.We’d like to also thank the over 100 people who have already signed up to review! For those who haven’t done so yet, please remember to accept your Pretalx link and get your reviews in by You can already start reviewing proposals, and each review takes as little as 5 minutes. We encourage reviewers to go through at least 20-30 proposals, but if you can do more, even better! With almost 600 submissions to pick from, your help ensures we curate a diverse and engaging programme.🏃The deadline is Monday next week, so don’t delay!EuroPython isn’t just present at other Python events—we actively support them too! As a community sponsor, we love helping local PyCons grow and thrive. We love giving back to the community and strengthening Python events across Europe! 🐍💙The EuroPython team had a fantastic time at PyCon + Web in Berlin, meeting fellow Pythonistas, exchanging ideas, and spreading the word about EuroPython 2025. It was great to connect with speakers, organizers, and attendees. Ever wondered how long it takes to walk from Berlin to Prague? A huge thank you to our co-organizers, Cheuk, Artur, and Cristián, for answering that in their fantastic lightning talk about EuroPython!We had some members of the EuroPython team at FOSDEM 2025, connecting with the open-source community and spreading the Python love! 🎉 We enjoyed meeting fellow enthusiasts, sharing insights about the EuroPython Society, and giving away the first EuroPython 2025 stickers. If you stopped by—thank you and we hope to see you in Prague this July.🦒 Speaker Mentorship ProgrammeThe signups for The Speaker Mentorship Programme closed on 22nd January 2025. We’re excited to have matched 43 mentees with 24 mentors from our community. We had an increase in the number of mentees who signed up and that’s amazing! We’re glad to be contributing to the journey of new speakers in the Python community. A massive thank you to our mentors for supporting the mentees and to our mentees; we’re proud of you for taking this step in your journey as a speaker. 26 mentees submitted at least 1 proposal. Out of this number, 13 mentees submitted 1 proposal, 9 mentees submitted 2 proposals, 2 mentees submitted 3 proposals, 1 mentee submitted 4 proposals and lastly, 1 mentee submitted 5 proposals. We wish our mentees the best of luck. We look forward to the acceptance of their proposals.In a few weeks, we will host an online panel session with 2–3 experienced community members who will share their advice with first-time speakers. At the end of the panel, there will be a Q&A session to answer all the participants’ questions.You can watch the recording of the previous year’s workshop here:EuroPython is one of the largest Python conferences in Europe, and it wouldn’t be possible without our sponsors. We are so grateful for the companies who have already expressed interest. If you’re interested in sponsoring EuroPython 2025 as well, please reach out to us at sponsoring@europython.eu.🎤 EuroPython Speakers Share Their ExperiencesWe asked our past speakers to share their experiences speaking at EuroPython. These videos have been published on YouTube as shorts, and we&aposve compiled them into brief clips for you to watch.A big thanks goes to Sebastian Witowski, Jan Smitka, Yuliia Barabash, Jodie Burchell, Max Kahan, and Cheuk Ting Ho for sharing their experiences.Why You Should Submit a Proposal for EuroPython? Part 2Why You Should Submit a Proposal for EuroPython? Part 3📊 EuroPython Society Board Report The EuroPython conference wouldn’t be what it is without the incredible volunteers who make it all happen. 💞 Behind the scenes, there’s also the EuroPython Society—a volunteer-led non-profit that manages the fiscal and legal aspects of running the conference, oversees its organization, and works on a few smaller projects like the grants programme. To keep everyone in the loop and promote transparency, the Board is sharing regular updates on what we’re working on.That&aposs all for now! Keep an eye on your inbox and our website for more news and announcements. We&aposre counting down the days until we can come together in Prague to celebrate our shared love for Python. 🐍❤️Cheers,The EuroPython Team]]></content:encoded></item><item><title>Giampaolo Rodola: psutil: drop Python 2.7 support</title><link>https://gmpy.dev/blog/2025/psutil-drop-python-27-support</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 23:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[About dropping Python 2.7 support in psutil, 3 years ago
I stated:Not a chance, for many years to come. [Python 2.7] currently represents 7-10%
of total downloads, meaning around 70k / 100k downloads per day.Only 3 years later, and to my surprise, downloads for Python 2.7 dropped to
0.36%! As such, as of psutil 7.0.0, I finally decided to drop support for
Python 2.7!These are downloads per month:According to pypistats.org Python 2.7 downloads
represents the 0.28% of the total, around 15.000 downloads per day.Maintaining 2.7 support in psutil had become increasingly difficult, but still
possible. E.g. I could still run tests by using old PYPI
backports.
GitHub Actions could still be
tweaked
to run tests and produce 2.7 wheels on Linux and macOS. Not on Windows though,
for which I had to use a separate service (Appveyor). Still, the amount of
hacks in psutil source code necessary to support Python 2.7 piled up over the
years, and became quite big. Some disadvantages that come to mind:Having to maintain a Python compatibility layers like
  psutil/_compat.py.
  This translated in extra extra code and extra imports.The C compatibility layer to differentiate between Python 2 and 3 (#if
  PY_MAJOR_VERSION <= 3, etc.).Dealing with the string vs. unicode differences, both in Python and in C.Inability to use modern language features, especially f-strings.Inability to freely use s, which created a difference on how CONSTANTS
  were exposed in terms of API.Having to install a specific version of  and other (outdated)
  deps.Relying on the third-party Appveyor CI service to run tests and produce 2.7
  wheels.Running 4 extra CI jobs on every commit (Linux, macOS, Windows 32-bit,
  Windows 64-bit) making the CI slower and more subject to failures (we have
  quite a bit of flaky tests).The distribution of 7 wheels specific for Python 2.7. E.g. in the previous
  release I had to upload:psutil-6.1.1-cp27-cp27m-macosx_10_9_x86_64.whl
psutil-6.1.1-cp27-none-win32.whl
psutil-6.1.1-cp27-none-win_amd64.whl
psutil-6.1.1-cp27-cp27m-manylinux2010_i686.whl
psutil-6.1.1-cp27-cp27m-manylinux2010_x86_64.whl
psutil-6.1.1-cp27-cp27mu-manylinux2010_i686.whl
psutil-6.1.1-cp27-cp27mu-manylinux2010_x86_64.whl
The removal was done in
PR-2841, which removed around
1500 lines of code (nice!). . In doing so, in the doc I
still made the promise that the 6.1.* serie will keep supporting Python 2.7
and will receive  (no new features). It will be
maintained in a specific python2
branch. I explicitly kept
the
setup.py
script compatible with Python 2.7 in terms of syntax, so that, when the tarball
is fetched from PYPI, it will emit an informative error message on . The user trying to install psutil on Python 2.7 will see:$pip2installpsutil
Asofversion.0.0psutilnolongersupportsPython.7.
LatestversionsupportingPython.7ispsutil.1.X.
Installitwith:.
As the informative message states, users that are still on Python 2.7 can still
use psutil with:pip2 install psutil==6.1.*
]]></content:encoded></item><item><title>Kay Hayen: Nuitka Release 2.6</title><link>https://nuitka.net/posts/nuitka-release-26.html</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 23:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[ Path normalization to native Windows format was required
in more places for the  variant of .The  function doesn’t normalize to native Win32
paths with MSYS2, instead using forward slashes. This required manual
normalization in additional areas. (Fixed in 2.5.1) Fix, give a proper error when extension modules asked to
include failed to be located. instead of a proper error message.
(Fixed in 2.5.1)Fix, files with illegal module names (containing ) in their
basename were incorrectly considered as potential sub-modules for
. These are now skipped. (Fixed in 2.5.1) Improved stability by preventing crashes when stubgen
encounters code it cannot handle. Exceptions from it are now ignored.
(Fixed in 2.5.1) Addressed a crash that occurred when encountering
assignments to non-variables. (Fixed in 2.5.1) Fixed a regression introduced in 2.5 release that could
lead to segmentation faults in exception handling for generators.
(Fixed in 2.5.2) Corrected an issue where dictionary copies of large
split directories could become corrupted. This primarily affected
instance dictionaries, which are created as copies until updated,
potentially causing problems when adding new keys. (Fixed in 2.5.2) Removed the assumption that module dictionaries
always contain only strings as keys. Some modules, like
 on macOS, use non-string keys. (Fixed in 2.5.2) Ensured that the  option correctly
affects the C compilation process. Previously, only individual
disables were applied. (Fixed in 2.5.2) Fixed a crash that could occur during compilation
when unary operations were used within binary operations. (Fixed in
2.5.3) Corrected the handling of
, which could lead to crashes. (Fixed
in 2.5.4) Resolved a segmentation fault occurring at runtime
when calling  with only keyword arguments.
(Fixed in 2.5.5) Harmless warnings generated for x64 DLLs on arm64 with
newer macOS versions are now ignored. (Fixed in 2.5.5) Addressed a crash in Nuitka’s dictionary code that
occurred when copying dictionaries due to internal changes in Python
3.13. (Fixed in 2.5.6) Improved onefile mode signing by applying
 to the signature of binaries, not just
app bundles. (Fixed in 2.5.6) Corrected an issue where too many paths were added as
extra directories from the Nuitka package configuration. This
primarily affected the  package, which currently relies
on the  import hack. (Fixed in 2.5.6) Prevented crashes on macOS when creating onefile
bundles with Python 2 by handling negative CRC32 values. This issue
may have affected other versions as well. (Fixed in 2.5.6) Restored the functionality of code provided in
, which was no longer being applied due to a
regression. (Fixed in 2.5.6) Suppressed the app bundle mode recommendation when it is
already in use. (Fixed in 2.5.6) Corrected path normalization when the output directory
argument includes “~”. GitHub Actions Python is now correctly identified as a
Homebrew Python to ensure proper DLL resolution. (Fixed in 2.5.7) Fixed a reference leak that could occur with
values sent to generator objects. Asyncgen and coroutines were not
affected. (Fixed in 2.5.7) The  scan now correctly handles
cases where both a package init file and competing Python files
exist, preventing compile-time conflicts. (Fixed in 2.5.7) Resolved an issue where handling string constants in
modules created for Python 3.12 could trigger assertions, and modules
created with 3.12.7 or newer failed to load on older Python 3.12
versions when compiled with Nuitka 2.5.5-2.5.6. (Fixed in 2.5.7) Corrected the tuple code used when calling certain
method descriptors. This issue primarily affected a Python 2
assertion, which was not impacted in practice. (Fixed in 2.5.7) Updated resource readers to accept multiple
arguments for , and correctly handle
 and  as keyword-only arguments. The platform encoding is no longer used to decode
 logs. Instead,  is used, as it is sufficient for
matching filenames across log lines and avoids potential encoding
errors. (Fixed in 2.5.7) Requests to statically link libraries for 
are now ignored, as these libraries do not exist. (Fixed in 2.5.7) Fixed a memory leak affecting the results of
functions called via specs. This primarily impacted overloaded hard
import operations. (Fixed in 2.5.7) When multiple distributions for a package are found,
the one with the most accurate file matching is now selected. This
improves handling of cases where an older version of a package (e.g.,
) is overwritten with a different variant (e.g.,
), ensuring the correct version is used for
Nuitka package configuration and reporting. (Fixed in 2.5.8) Prevented a potential crash during onefile
initialization on Python 2 by passing the directory name directly
from the onefile bootstrap, avoiding the use of  which
may not be fully loaded at that point. (Fixed in 2.5.8) Preserved necessary  environment variables on
Windows for packages that require loading DLLs from those locations.
Only  entries not pointing inside the installation prefix are
removed. (Fixed in 2.5.8) Corrected the  check to function
properly when distribution names and package names differ. (Fixed in
2.5.8) Improved package name resolution for Anaconda
distributions by checking conda metadata when file metadata is
unavailable through the usual methods. (Fixed in 2.5.8) Normalized the downloaded gcc path to use native Windows
slashes, preventing potential compilation failures. (Fixed in 2.5.9) Restored static libpython functionality on Linux by
adapting to a signature change in an unexposed API. (Fixed in 2.5.9) Prevented  from being resurrected when a
finalizer is attached, resolving memory leaks that could occur with
 in the presence of exceptions. (Fixed in 2.5.10) Suppressed the gcc download prompt that could appear during
 output on Windows systems without MSVC or with an
improperly installed gcc.Ensured compatibility with monkey patched  or 
functions, which are used in some testing scenarios. Improved the determinism of the JSON statistics
output by sorting keys, enabling reliable build comparisons. Fixed a memory leak in  with finalizers,
which could lead to significant memory consumption when using
 and encountering exceptions. Optimized empty generators (an optimization result) to
avoid generating unused context code, eliminating C compilation
warnings. Fixed a reference leak affecting the  value
in . While typically , this could lead to
observable reference leaks in certain cases. Improved handling of  and 
resurrection, preventing memory leaks with  and
, and ensuring correct execution of  code in
coroutines. Corrected the handling of  objects
resurrecting during deallocation. While not explicitly demonstrated,
this addresses potential issues similar to those encountered with
coroutines, particularly for old-style coroutines created with the
 decorator. Fixed a potential crash during runtime trace collection by
ensuring timely initialization of the output mechanism.]]></content:encoded></item><item><title>EuroPython Society: Board Report for January 2025</title><link>https://www.europython-society.org/board-report-for-january-2025/</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 15:08:37 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[The top priority for the board in January was finishing the hiring of our event manager. We’re super excited to introduce Anežka Müller! Anežka is a freelance event manager and a longtime member of the Czech Python community. She’s a member of the Pyvec board, co-organizes PyLadies courses, PyCon CZ, Brno Pyvo, and Brno Python Pizza. She’ll be working closely with the board and OPS team, mainly managing communication with service providers. Welcome onboard! Our second priority was onboarding teams. We’re happy that we already have the Programme team in place—they started early and launched the Call for Proposals at the beginning of January. We’ve onboarded a few more teams and are in the process of bringing in the rest.Our third priority was improving our grant programme in order to support more events with our limited budget and to make it more clear and transparent. We went through past data, came up with a new proposal, discussed it, voted on it, and have already published it on our blog. Updating onboarding/offboarding checklists for Volunteers and Board MembersVarious infrastructure updates including new website deployment and self-hosted previews for Pull Requests to the website.Setting up EPS AWS account.Working out the Grant Guidelines update for 2025Attending PyConWeb and FOSDEMReviewing updates to the Sponsors setup and packages for 2025More documentation, sharing know-how and reviewing new proposals.Brand strategy: Analysis of social media posts from previous years and web analytics. Call with a European open-source maintainer and a call with a local events organizer about EP content.Comms & design: Call for proposal announcements, EP 2024 video promotions, speaker mentorship, and newsletter. Video production - gathering videos from speakers, video post-production, and scheduling them on YouTube shorts, and social media.Event management coordination: Calls with the event manager and discussions about previous events.Grants: Work on new grant guidelines and related comms.Team onboarding: Calls with potential comms team members and coordination.PR: Delivering a lightning talk at FOSDEM.Offboarding the old boardOnboarding new team membersAdministrative work on GrantsWorked on the Grants proposalFollow-up with team membersCommunity outreach: FOSDEMWorking on various infrastructure updates, mostly related to the website.Reviewing Pull Requests for the website and the internal botWorking on the infrastructure team proposal.Timeline: Discussion with the Programme Team, and planning to do the same with the other teams.Visa Request letter: Setup and Test Visa Request Automation for the current yearTeam selection discussion with past volunteers]]></content:encoded></item><item><title>Python Morsels: Avoid over-commenting in Python</title><link>https://www.pythonmorsels.com/avoid-comments/</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 15:05:39 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Documenting instead of commentingHere is a comment I would not write in my code:That comment seems to describe what this code does... so why would I  write it?I do like that comment, but I would prefer to write it as a docstring instead:Documentation strings are for conveying the purpose of function, class, or module, typically at a high level.
Unlike comments, they can be read by Python's built-in  function:Docstrings are also read by other documentation-oriented tools, like Sphinx.Non-obvious variables and valuesHere's a potentially helpful comment:]]></content:encoded></item><item><title>Real Python: Python Keywords: An Introduction</title><link>https://realpython.com/python-keywords/</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 14:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Python keywords are reserved words with specific functions and restrictions in the language. Currently, Python has thirty-five keywords and four soft keywords. These keywords are always available in Python, which means you don’t need to import them. Understanding how to use them correctly is fundamental for building Python programs.By the end of this tutorial, you’ll understand that:There are  and  in Python.You can get a list of all keywords using  from the  module. in Python act as keywords only in specific contexts. are keywords that have been deprecated and turned into functions in Python 3.In this article, you’ll find a basic introduction to all Python keywords and soft keywords along with other resources that will be helpful for learning more about each keyword. Test your knowledge with our interactive “Python Keywords: An Introduction” quiz. You’ll receive a score upon completion to help you track your learning progress:In this quiz, you'll test your understanding of Python keywords and soft keywords. These reserved words have specific functions and restrictions in Python, and understanding how to use them correctly is fundamental for building Python programs.Python keywords are special reserved words that have specific meanings and purposes and can’t be used for anything but those specific purposes. These keywords are always available—you’ll never have to import them into your code.Python keywords are different from Python’s built-in functions and types. The built-in functions and types are also always available, but they aren’t as restrictive as the keywords in their usage. An example of something you  do with Python keywords is assign something to them. If you try, then you’ll get a . You won’t get a  if you try to assign something to a built-in function or type, but it still isn’t a good idea. For a more in-depth explanation of ways keywords can be misused, check out Invalid Syntax in Python: Common Reasons for SyntaxError.There are thirty-five keywords in Python. Here’s a list of them, each linked to its relevant section in this tutorial:Two keywords have additional uses beyond their initial use cases. The  keyword is also used with loops and with  and  in addition to in conditional statements. The  keyword is most commonly used in  statements, but also used with the  keyword.The list of Python keywords and soft keywords has changed over time. For example, the  and  keywords weren’t added until Python 3.7. Also, both  and  were keywords in Python 2.7 but were turned into built-in functions in Python 3 and no longer appear in the keywords list.As mentioned above, you’ll get an error if you try to assign something to a Python keyword. Soft keywords, on the other hand, aren’t that strict. They syntactically act as keywords only in certain conditions.This new capability was made possible thanks to the introduction of the PEG parser in Python 3.9, which changed how the interpreter reads the source code.Leveraging the PEG parser allowed for the introduction of structural pattern matching in Python. In order to use intuitive syntax, the authors picked , , and  for the pattern matching statements. Notably,  and  are widely used for this purpose in many other programming languages.To prevent conflicts with existing Python code that already used , , and  as variable or function names, Python developers decided to introduce the concept of soft keywords.Currently, there are four  in Python:You can use the links above to jump to the soft keywords you’d like to read about, or you can continue reading for a guided tour.Value Keywords: , , There are three Python keywords that are used as values. These values are singleton values that can be used over and over again and always reference the exact same object. You’ll most likely see and use these values a lot.There are a few terms used in the sections below that may be new to you. They’re defined here, and you should be aware of their meaning before proceeding:]]></content:encoded></item><item><title>EuroPython Society: Changes in the Grants Programme for 2025</title><link>https://www.europython-society.org/changes-in-the-grants-programme-for-2025/</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 13:16:30 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[We are increasing transparency and reducing ambiguity in the guidelines.We would like to support more events with our limited budgetWe’ve introduced caps for events in order to make sure all grants are fairly given and we can support more communities.We’ve set aside 10% of our budget for the local community. The EPS introduced a Grant Programme in 2017. Since then, we have granted almost EUR 350k through the programme, partly via EuroPython Finaid and by directly supporting other Python events and projects across Europe. In the last two years, the Grant Programme has grown to EUR 100k per year, with even more requests coming in.With this growth come new challenges in how to distribute funds fairly so that more events can benefit. Looking at data from the past two years, we’ve often been close to or over our budget. The guidelines haven’t been updated in a while. As grant requests become more complex, we’d like to simplify and clarify the process, and better explain it on our website.We would also like to acknowledge that EuroPython, when traveling around Europe, has an additional impact on the host country, and we’d like to set aside part of the budget for the local community.The Grant Programme is also a primary funding source for EuroPython Finaid. To that end, we aim to allocate 30% of the total Grant Programme budget to Finaid, an increase from the previous 25%.We’ve updated the text on our website, and split it into multiple sub-pages to make it easier to navigate. The website now includes a checklist of what we would like to see in a grant application, and a checklist for the Grants Workgroup – so that when you apply for the Grant you already know the steps that it will go through later and when you can expect an answer from us.We looked at the data from previous years, and size and timing of the grant requests. With the growing number and size of the grants, to make it more accessible to smaller conferences and conferences happening later in the year, we decided to introduce max caps per grant and split the budget equally between the first and second half of the year. We would also explicitly split the total budget into three categories – 30% goes to the EuroPython finaid, 10% is reserved for projects in the host country. The remaining 60% of the budget goes to fund other Python Conferences. This is similar to the split in previous years, but more explicit and transparent.Using 2024 data, and the budget available for Community Grants (60% of total), we’ve simulated different budget caps and found a sweet spot at 6000EUR, where we are able to support all the requests with most of the grants being below that limit. For 2025 we expect to receive a similar or bigger number of requests.We are introducing a special 10% pool of money to be used on projects in the host country (in 2025 that’s again Czech Republic). This pool is set aside at the beginning of the year, with one caveat that we would like to deploy it in the first half of the year. Whatever is left unused goes back to the Community Pool to be used in second half of the year.Fairer Funding: By spreading our grants out during the year, conferences that happen later won’t miss out.Easy to Follow: Clear rules and deadlines cut down on confusion about how much you can get and what it’s for.Better Accountability: We ask for simple post-event reports so we can see where the money went and what impact it made.Stronger Community: Funding more events grows our Python network across Europe, helping everyone learn, connect, and collaborate.]]></content:encoded></item><item><title>Real Python: Quiz: Python Keywords: An Introduction</title><link>https://realpython.com/quizzes/python-keywords/</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 12:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Python keywords are reserved words with specific functions and restrictions in the language. These keywords are always available in Python, which means you don’t need to import them. Understanding how to use them correctly is fundamental for building Python programs.]]></content:encoded></item><item><title>Zato Blog: Modern REST API Tutorial in Python</title><link>https://zato.io/en/blog/modern-rest-api-tutorial-in-python.html</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 08:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[
  2025-02-12, by Dariusz Suchojad
Great APIs don't win theoretical arguments - they just prefer to work reliably and to make developers' lives easier.Here's a tutorial on what building production APIs is really about: creating interfaces that are practical in usage,
while keeping your systems maintainable for years to come.]]></content:encoded></item><item><title>Kushal Das: pass using stateless OpenPGP command line interface</title><link>https://kushaldas.in/posts/pass-using-stateless-openpgp-command-line-interface.html</link><author></author><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 05:26:13 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Yesterday I wrote about how
I am using a different tool for  signing and verification. Next, I
replaced my  usage. I have a small
patch to use
stateless OpenPGP command line interface (SOP). It is an implementation
agonostic standard for handling OpenPGP messages. You can read the whole SPEC
here.cargo install rsop rsop-oct
And copied the bash script from my repository to the path somewhere.The  binary from  follows the same SOP standard but uses the
card to signing/decryption. I stored my public key in
~/.password-store/.gpg-key file, which is in turn used for encryption.Here nothing changed related my daily  usage, except the number of time I am typing my  :)]]></content:encoded></item><item><title>Python 3.14.0 alpha 5 is out</title><link>https://pythoninsider.blogspot.com/2025/02/python-3140-alpha-5-is-out.html</link><author>Hugo</author><category>dev</category><category>official</category><category>python</category><pubDate>Tue, 11 Feb 2025 19:41:00 +0000</pubDate><source url="https://pythoninsider.blogspot.com/">Python official news</source><content:encoded><![CDATA[Here comes the antepenultimate alpha.This is an early developer preview of Python
3.14Python 3.14 is still in development. This release, 3.14.0a5, is the
fifth of seven planned alpha releases.Alpha releases are intended to make it easier to test the current
state of new features and bug fixes and to test the release process.During the alpha phase, features may be added up until the start of
the beta phase (2025-05-06) and, if necessary, may be modified or
deleted up until the release candidate phase (2025-07-22). Please keep
in mind that this is a preview release and its use is
 recommended for production environments.Many new features for Python 3.14 are still being planned and
written. Among the new major new features and changes so far:The next pre-release of Python 3.14 will be the penultimate alpha,
3.14.0a6, currently scheduled for 2025-03-14.2025-01-29 marked the start of a new lunar year, the Year of the
Snake 🐍 (and the Year of Python?).For centuries, π was often approximated as 3 in China. Some time
between the years 1 and 5 CE, astronomer, librarian, mathematician and
politician Liu Xin (劉歆) calculated π as 3.154.Around 130 CE, mathematician, astronomer, and geographer Zhang Heng
(張衡, 78–139) compared the celestial circle with the diameter of the
earth as 736:232 to get 3.1724. He also came up with a formula for the
ratio between a cube and inscribed sphere as 8:5, implying the ratio of
a square’s area to an inscribed circle is √8:√5. From this, he
calculated π as √10 (~3.162).Third century mathematician Liu Hui (刘徽) came up with an algorithm
for calculating π iteratively: calculate the area of a polygon inscribed
in a circle, then as the number of sides of the polygon is increased,
the area becomes closer to that of the circle, from which you can
approximate π.This algorithm is similar to the method used by Archimedes in the 3rd
century BCE and Ludolph van Ceulen in the 16th century CE (see 3.14.0a2
  release notes), but Archimedes only went up to a 96-sided polygon
(96-gon). Liu Hui went up to a 192-gon to approximate π as 157/50 (3.14)
and later a 3072-gon for 3.14159.Liu Hu wrote a commentary on the book The Nine Chapters on the
Mathematical Art which included his π approximations.In the fifth century, astronomer, inventor, mathematician,
politician, and writer Zu Chongzhi (祖沖之, 429–500) used Liu Hui’s
algorithm to inscribe a 12,288-gon to compute π between 3.1415926 and
3.1415927, correct to seven decimal places. This was more accurate than
Hellenistic calculations and wouldn’t be improved upon for 900
years.Thanks to all of the many volunteers who help make Python Development
and these releases possible! Please consider supporting our efforts by
volunteering yourself or through organisation contributions to the Python Software
Foundation.Regards from a remarkably snowless Helsinki,Your release team, Hugo van KemenadeSteve Dower]]></content:encoded></item><item><title>PyCoder’s Weekly: Issue #668: NumPy, Compiling Python 1.0, BytesIO, and More (Feb. 11, 2025)</title><link>https://pycoders.com/issues/668</link><author></author><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 19:30:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[ In this video course, you’ll learn how to use NumPy by exploring several interesting examples. You’ll read data from a file into an array and analyze structured arrays to perform a reconciliation. You’ll also learn how to quickly chart an analysis & turn a custom function into a vectorized function. This tutorial will help you master Python string splitting. You’ll learn to use , , and  to effectively handle whitespace, custom delimiters, and multiline text, which will level up your data parsing skills. Python developers use Posit Package Manager to mirror public & internally developed repos within their firewalls. Get reporting on known vulnerabilities to proactively address potential threats. High-security environments can even run air-gapped. The author was recently invited with other senior devs to give a lightning talk on their personal development philosophy. This post captures those thoughts.[ Subscribe to 🐍 PyCoder’s Weekly 💌 – Get the best Python news, articles, and tutorials delivered to your inbox once a week >> Click here to learn more ]]]></content:encoded></item><item><title>Python Insider: Python 3.14.0 alpha 5 is out</title><link>https://pythoninsider.blogspot.com/2025/02/python-3140-alpha-5-is-out.html</link><author></author><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 16:25:58 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Here comes the antepenultimate alpha.This is an early developer preview of Python
3.14Python 3.14 is still in development. This release, 3.14.0a5, is the
fifth of seven planned alpha releases.Alpha releases are intended to make it easier to test the current
state of new features and bug fixes and to test the release process.During the alpha phase, features may be added up until the start of
the beta phase (2025-05-06) and, if necessary, may be modified or
deleted up until the release candidate phase (2025-07-22). Please keep
in mind that this is a preview release and its use is
 recommended for production environments.Many new features for Python 3.14 are still being planned and
written. Among the new major new features and changes so far:The next pre-release of Python 3.14 will be the penultimate alpha,
3.14.0a6, currently scheduled for 2025-03-14.2025-01-29 marked the start of a new lunar year, the Year of the
Snake 🐍 (and the Year of Python?).For centuries, π was often approximated as 3 in China. Some time
between the years 1 and 5 CE, astronomer, librarian, mathematician and
politician Liu Xin (劉歆) calculated π as 3.154.Around 130 CE, mathematician, astronomer, and geographer Zhang Heng
(張衡, 78–139) compared the celestial circle with the diameter of the
earth as 736:232 to get 3.1724. He also came up with a formula for the
ratio between a cube and inscribed sphere as 8:5, implying the ratio of
a square’s area to an inscribed circle is √8:√5. From this, he
calculated π as √10 (~3.162).Third century mathematician Liu Hui (刘徽) came up with an algorithm
for calculating π iteratively: calculate the area of a polygon inscribed
in a circle, then as the number of sides of the polygon is increased,
the area becomes closer to that of the circle, from which you can
approximate π.This algorithm is similar to the method used by Archimedes in the 3rd
century BCE and Ludolph van Ceulen in the 16th century CE (see 3.14.0a2
  release notes), but Archimedes only went up to a 96-sided polygon
(96-gon). Liu Hui went up to a 192-gon to approximate π as 157/50 (3.14)
and later a 3072-gon for 3.14159.Liu Hu wrote a commentary on the book The Nine Chapters on the
Mathematical Art which included his π approximations.In the fifth century, astronomer, inventor, mathematician,
politician, and writer Zu Chongzhi (祖沖之, 429–500) used Liu Hui’s
algorithm to inscribe a 12,288-gon to compute π between 3.1415926 and
3.1415927, correct to seven decimal places. This was more accurate than
Hellenistic calculations and wouldn’t be improved upon for 900
years.Thanks to all of the many volunteers who help make Python Development
and these releases possible! Please consider supporting our efforts by
volunteering yourself or through organisation contributions to the Python Software
Foundation.Regards from a remarkably snowless Helsinki,Your release team, Hugo van KemenadeSteve Dower]]></content:encoded></item><item><title>Real Python: Building a Python Command-Line To-Do App With Typer</title><link>https://realpython.com/courses/build-command-line-todo-app-typer/</link><author></author><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 14:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Building an application to manage your  can be an interesting project when you’re learning a new programming language or trying to take your skills to the next level. In this video course, you’ll build a functional to-do application for the command line using Python and Typer, which is a relatively young library for creating powerful command-line interface (CLI) applications in almost no time.With a project like this, you’ll apply a wide set of core programming skills while building a real-world application with real features and requirements.In this video course, you’ll learn how to:Build a functional  with a  in PythonUse Typer to add , , and  to your to-do appTest your Python to-do application with Typer’s  and ]]></content:encoded></item><item><title>Kushal Das: Using openpgp-card-tool-git with git</title><link>https://kushaldas.in/posts/using-openpgp-card-tool-git-with-git.html</link><author></author><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 11:12:40 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[One of the power of Unix systems comes from the various small tools and how
they work together. One such new tool I am using for some time is for  &  using OpenPGP and my Yubikey for the actual signing
operation via
openpgp-card-tool-git. I
replaced the standard  for this usecase with the  command from this
project.Installation & configurationcargo install openpgp-card-tool-git
Then you will have to configuration your (in my case the global configuration) git configuration.git config --global gpg.program <path to oct-git>
I am assuming that you already had it configured before for signing, otherwise
you have to run the following two commands too.git config --global commit.gpgsign true
git config --global tag.gpgsign true
Before you start using it, you want to save the pin in your system keyring.Use the following command.That is it, now your  will sign the commits using  tool.In the next blog post I will show how to use the other tools from the 
author for various different OpenPGP oeprations.]]></content:encoded></item><item><title>Django Weblog: DSF member of the month - Lily Foote</title><link>https://www.djangoproject.com/weblog/2025/feb/10/dsf-member-of-the-month-lily-foote/</link><author></author><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 04:51:31 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[For February 2025, we welcome Lily Foote (@lilyf) as our DSF member of the month! ⭐Lily Foote is a contributor to Django core for many years, especially on the ORM. She is currently a member of the Django 6.x Steering Council and she has been a DSF member since March 2021. 
You can learn more about Lily by visiting her GitHub profile.Let’s spend some time getting to know Lily better!Can you tell us a little about yourself (hobbies, education, etc)My name is Lily Foote and I’ve been contributing to Django for most of my career. I’ve also recently got into Rust and I’m excited about using Rust in Python projects. When I’m not programming, I love hiking, climbing and dancing (Ceilidh)! I also really enjoying playing board games and role playing games (e.g. Dungeons and Dragons).How did you start using Django?I’d taught myself Python in my final year at university by doing Project Euler problems and then decided I wanted to learn how to make a website. Django was the first Python web framework I looked at and it worked really well for me.What other framework do you know and if there is anything you would like to have in Django if you had magical powers?I’ve done a small amount with Flask and FastAPI. More than any new features, I think the thing that I’d most like to see is more long-term contributors to spread the work of keeping Django awesome.What projects are you working on now?The side project I’m most excited about is Django Rusty Templates, which is a re-implementation of Django’s templating language in Rust.Which Django libraries are your favorite (core or 3rd party)?What are the top three things in Django that you like?Django Conferences, the mentorship program Djangonaut Space and the whole community!You have been a mentor multiple times with GSoC and Djangonaut Space program, what is required according to you to be a good mentor?I think being willing to invest time is really important. Checking in with your mentees frequently and being an early reviewer of their work. I think this helps keep their motivation up and allows for small corrections early on.Any advice for future contributors?Start small and as you get more familiar with Django and the process of contributing you can take on bigger issues. Also be patient with reviewers – Django has high standards, but is mostly maintained by volunteers with limited time.Yes! It’s a huge honour! Since January, we’ve been meeting weekly and it feels like we’ve hardly scratched the surface of what we want to achieve. The biggest thing we’re trying to tackle is how to improve the contribution experience – especially evaluating new feature ideas – without draining everyone’s time and energy.You have a lot of knowledge in the Django ORM, how did you start to contribute to this part?I added the Greatest and Least expressions in Django 1.9, with the support of one of the core team at the time. After that, I kept showing up (especially at conference sprints) and finding a new thing to tackle.Is there anything else you’d like to say?Thank you for doing the interview, Lily!]]></content:encoded></item><item><title>Quansight Labs Blog: PEP 517 build system popularity</title><link>https://labs.quansight.org/blog/pep-517-build-system-popularity</link><author></author><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[Analysis of PEP 517 build backends used in 8000 top PyPI packages]]></content:encoded></item><item><title>Seth Michael Larson: Building software for connection (#2: Consensus)</title><link>https://sethmlarson.dev/building-software-for-connection-consensus?utm_campaign=rss</link><author></author><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[In the previous article we concluded that a persistent always-on internet
connection isn't required for software to elicit feelings of connection between humans.Building on this conclusion: let's explore how Animal Crossing software was able to intercommunicate without requiring
a centralized server and infrastructure and the trade-offs for these design decisions.Distributing digital goods without the internetAnimal Crossing has over 1,000 unique items that need to be collected
for a complete catalog, including furniture, wallpapers, clothing, parasols, and carpets.
Many of these items are quite rare or were only programmed to be accessible
through an official Nintendo-affiliated distribution such as a magazine or online contest.Beyond official distributions, it's clear Animal Crossings' designer, Katsuya Eguchi,
wanted players to  to complete their catalogs.
The game incentivized trading items between towns by assigning
one “native fruit” (Apple, Orange, Cherry, Peach, or Pear) and
randomly making a subset of items harder to find than others depending
on a hidden “item group” variable (either A, B, or C).Items could be exchanged between players when one player visits another town,
but this required physically bringing your memory card to another
players' GameCube. The GameCube might have come with a handle, but the 'cube wasn't exactly a . Sharing a physical space isn't something you can do with everyone or on a regular basis.So what did Katsuya Eguchi design for Animal Crossing? To allow for item distributions from magazines and contests and to make player-to-player item sharing easier Animal Crossing included a feature called “secret codes”.This feature worked by allowing players to exchange 28-character codes with Tom Nook for items. Players could also generate codes for their friends to “send” an item from their own game to a different town. Codes could be shared by writing them on a paper note, instant message, or text message.The forgotten durability of offline software
This Reddit comment thread from the GameCube subreddit was the initial inspiration for this entire series.
The post is about someone's niece who just started playing Animal Crossing for the first time.
The Redditor asked folks to send items to their nieces' town using the secret code system.
This ended up surprising many folks that this system 
 in a game that was over 23 years old!
For reference, Nintendo Wi-Fi Connection and Nintendo Network were only available for 8 and 13 years respectively.
Below are a handful of the comments from the thread:“For real does this still work lol?”It's hard not to take these comments as indicators that something is
 with internet-connected software today. What had to go wrong for a 
system continuing to work to ? Many consumers' 
experience with 
software products
today is that they become useless e-waste after some far-away service is 
discontinued a few years after purchase.My intuition from this is that software that requires centralized servers and infrastructure to function
will have shorter lifetimes than software which is offline or only
opportunistically uses online functionality.I don't think this is particularly insightful,
more dependencies always means less resilience. But if we're building software for human connection then the software
should optimally only be limited by the availability of humans to connect.What is centralization good for?Animal Crossings' secret code system is far from perfect. The system is easily abusable, as the same secret codes can be
reused over-and-over by the same user to duplicate items without ever expiring. The only limit was that 3 codes could be used per day.Not long after Animal Crossing's release
the secret code algorithm was reverse-engineered so secret codes 
for any item could be created for any town and recipient name as if they came from an official Nintendo distribution.
This was possible because the secret code system relied on "security through obscurity".Could  be the answer to preventing these abuses?The most interesting property that a centralized authority approach
provides is : forcing everyone to play by the same rules. By storing
the “single source-of-truth” a central authority is able to prevent abuses
like the ones mentioned above.For example, a centralized “secret code issuing server” could generate
new unique codes per-use and check each code's validity
against a database to prevent users from generating their
own illegitimate codes or codes being re-used multiple times.The problem with
centralized consensus is it tends to be  to cover the entire software state.
A centralized server can generate codes perfectly, but how can that same server
 that the items you're exchanging for codes were obtained legitimately? To know this
the server would also need to track item legitimacy, leading to software which requires
an internet connection to operate.This is optimal from a correctness perspective, but as was noted earlier,
I suspect that if such a server was a mandatory part of the secret code system
in Animal Crossing that the system would likely not be usable today.This seems like a trade-off, which future would you rather have?Redesigning Animal Crossing secret codesIf I were designing Animal Crossings' secret code system with modern hardware, what would it look like?
How can we keep the offline fall-back while providing consensus and being less
abusable, especially for official distributions.I would likely use a public-key cryptographic system for official distributions,
embedding a certificate that could be used to “verify” that specific secret codes
originated from the expected centralized entity. Codes that are accepted would be
recorded to prevent reusing the same code multiple times in the same town.
Using public-key cryptography prevents the
system from being reverse-engineered to distribute arbitrary items until the certificate
private key was cracked.For sharing items between players I would implement a system where each town
generated a public and private key and the public key was shared to other towns
whenever the software was able to, such as when a player visited the other town.
Players would only be able to send items to players that they have visited
(which for Animal Crossing required physical presence, more on this later!)Each sender could store a nonce value for
each potential recipient. Embedding that nonce into the secret code would allow
the recipients' software to verify that the specific code hadn't been used yet.
The nonce wouldn't have to be long to avoid simple reusing of codes.Both above systems would require much more data to be embedded into each “secret
code” compared to the 28-character codes from the GameCube. For this I would
use QR codes to embed over 2KB of data into a single QR code. Funnily enough,
Animal Crossing New Leaf and onwards use QR code technology for players to share design patterns.This design is still abusable if users can modify their software or hardware
but doesn't suffer from the trivial-to-exploit flaws of Animal Crossing's secret code system.Decentralized global consensus?What if we could have the best of both worlds: we want consensus
that is both  and . At least today, we are out of luck.Decentralized global consensus is technologically feasible, but the existing solutions
(mostly blockchains)
are expensive (both in energy and capital) and can't handle throughput on any sort of 
meaningful scale.There are many other decentralized consensus systems that 
are able to form “pockets” of useful peer-to-peer consensus using a fraction of
the resources, such as email, BitTorrent, ActivityPub, and Nostr.
These systems are only possible by adding  or by only guaranteeing .When is global consensus needed?Obviously global consensus is important for certain classes of software like 
financial, civics, and infrastructure, but I wonder how the necessity
of consensus in software changes for software with different risk
profiles.For software which has fewer risks associated with misuse is there as much
need for global consensus?
How can  be designed to reduce risk and require
less consensus to be effective? If global consensus and centralized 
servers become unnecessary, can we expect  to be usable 
on much longer timescales, essentially for as long as there are users?]]></content:encoded></item><item><title>Python Morsels: Newlines and escape sequences in Python</title><link>https://www.pythonmorsels.com/newlines-and-escape-sequences/</link><author></author><category>dev</category><category>python</category><pubDate>Mon, 10 Feb 2025 15:17:29 +0000</pubDate><source url="http://planetpython.org/">Planet Python blog</source><content:encoded><![CDATA[This string contains a newline character:That's what  represents: a newline character.If we print this string, we'll see that  becomes an  newline:Why does Python represent a newline as ?Escape sequences in PythonEvery character in a Python …]]></content:encoded></item><item><title>How to Join Strings in Python</title><link>https://realpython.com/python-join-string/</link><author>Real Python</author><category>dev</category><category>python</category><pubDate>Mon, 10 Feb 2025 14:00:00 +0000</pubDate><source url="https://realpython.com/atom.xml">Real Python Blog</source><content:encoded><![CDATA[Python’s built-in string method  lets you combine string elements from an iterable into a single string, using a separator that you specify. You call  on the separator, passing the iterable of strings to join.By the end of this tutorial, you’ll understand that:You use  in Python to  with a .A  is the piece of text you want inserted between each substring.To join list elements, you call  on a separator string, passing the list as the argument.inserts the separator between each list element to form a single string.The  method  that is the concatenation of the elements in the iterable, separated by the specified string.For smaller string concatenation tasks, you can use the concatenation operator () or  instead of .Python’s built-in  method gives you a quick and reliable way to combine multiple strings into a single string. Whether you need to format output or assemble data for storage,  provides a clean and efficient approach for joining strings from an iterable.In the upcoming sections, you’ll learn the basic usage of  to concatenate strings effectively. You’ll then apply that knowledge to real-world scenarios, from building CSV files to constructing custom log outputs. You’ll also discover some surprising pitfalls and learn how to avoid them. Test your knowledge with our interactive “How to Join Strings in Python” quiz. You’ll receive a score upon completion to help you track your learning progress:Test your understanding of Python's .join() string method for combining strings, handling edge cases, and optimizing performance.How to Join Strings in Python Using To use the string method , you call  on a separator string and pass an iterable of other strings as the argument. The method returns a single string, where it has inserted the separator string between each element of the iterable:In this example, you joined a list of words into one sentence, separated by spaces.At first glance, this usage might look a little backward. In many other string operations, you call the method on the main string that you want to manipulate. However, with , you call the method on the separator string, then pass the iterable of strings that you want to combine:This example achieves the same result as the earlier one but splits the process into two steps. Defining  separately makes the code more readable and avoids the potentially odd-looking syntax of calling  directly on a short string literal. Remember that  is a  method, which means that you’ll need to call it on a  string object. Keeping that in mind may help you remember why you need to call it on the separator string.You rarely see code that’s written in multiple steps where you assign the separator string to a variable, like you did in the example above.In typical usage, you call  directly on the separator string, all in one line. This approach is more concise and highlights that any valid string can be your separator, whether it’s whitespace, a dash, or a multicharacter substring.Join With an Empty StringWhat if you don’t want any separator at all, but just want to concatenate the items? One valid approach is to use an empty string () as the separator:This code snippet concatenates the letters in the list, forming a single string . Using an empty string as the separator is a great way to assemble strings without a delimiter between them.Since  can take any iterable of strings—not just lists—you can even pass a string as an argument. Because strings are iterable, Python iterates over each character in that string, considering each character as a separate element:By calling  on  and passing the string , you effectively place a comma between every single character in . This might not always be what you intend, but it’s a neat trick to keep in mind if you ever need to treat each character as a separate element.]]></content:encoded></item></channel></rss>