<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Python</title><link>https://www.awesome-dev.news</link><description></description><item><title>Django Weblog: DjangoCongress JP 2025 Announcement and Live Streaming!</title><link>https://www.djangoproject.com/weblog/2025/feb/14/djangocongress-jp-2025-announcement-and-livestream/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 22:12:10 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[It will be streamed on the following YouTube Live channels:This year there will be talks not only about Django, but also about FastAPI and other asynchronous web topics. There will also be talks on Django core development, Django Software Foundation (DSF) governance, and other topics from around the world. Simultaneous translation will be provided in both English and Japanese.The Async Django ORM: Where Is it?Speed at Scale for Django Web ApplicationsImplementing Agentic AI Solutions in Django from scratchDiving into DSF governance: past, present and futureGetting Knowledge from Django Hits: Using Grafana and PrometheusCulture Eats Strategy for Breakfast: Why Psychological Safety Matters in Open SourceÂµDjango. The next step in the evolution of asynchronous microservices technology.A public viewing of the event will also be held in Tokyo. A reception will also be held, so please check the following connpass page if you plan to attend.]]></content:encoded></item><item><title>Eli Bendersky: Decorator JITs - Python as a DSL</title><link>https://eli.thegreenplace.net/2025/decorator-jits-python-as-a-dsl/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 21:49:31 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Spend enough time looking at Python programs and packages for machine learning,
and you'll notice that the "JIT decorator" pattern is pretty popular. For
example, this JAX snippet:In both cases, the function decorated with  doesn't get executed by the
Python interpreter in the normal sense. Instead, the code inside is more like
a DSL (Domain Specific Language) processed by a special purpose compiler built
into the library (JAX or Triton). Another way to think about it is that Python
is used as a  to describe computations.In this post I will describe some implementation strategies used by libraries to
make this possible.Preface - where we're goingThe goal is to explain how different kinds of  decorators work by using
a simplified, educational example that implements several approaches from
scratch. All the approaches featured in this post will be using this flow: Expr IR --> LLVM IR --> Execution" /> Expr IR --> LLVM IR --> Execution" class="align-center" src="https://eli.thegreenplace.net/images/2025/decjit-python.png" />
These are the steps that happen when a Python function wrapped with
our educational  decorator is called:The function is translated to an "expression IR" - .This expression IR is converted to LLVM IR.Finally, the LLVM IR is JIT-executed.First, let's look at the  IR. Here we'll make a big simplification -
only supporting functions that define a single expression, e.g.:Naturally, this can be easily generalized - after all, LLVM IR can be used to
express fully general computations.Here are the  data structures:To convert an  into LLVM IR and JIT-execute it, we'll use this function:It uses the  class to actually generate LLVM IR from .
This process is straightforward and covered extensively in the resources I
linked to earlier; take a look at the full code here.My goal with this architecture is to make things simple, but .
On one hand - there are several simplifications: only single expressions are
supported, very limited set of operators, etc. It's very easy to extend this!
On the other hand, we could have just trivially evaluated the 
without resorting to LLVM IR; I do want to show a more complete compilation
pipeline, though, to demonstrate that an arbitrary amount of complexity can
be hidden behind these simple interfaces.With these building blocks in hand, we can review the strategies used by
 decorators to convert Python functions into s.Python comes with powerful code reflection and introspection capabilities out
of the box. Here's the  decorator:This is a standard Python decorator. It takes a function and returns another
function that will be used in its place ( ensures that
function attributes like the name and docstring of the wrapper match the
wrapped function).After  is applied to , what  holds is the
wrapper. When  is called, the wrapper is invoked with
.The wrapper obtains the AST of the wrapped function, and then uses
 to convert this AST into an :When  finishes visiting the AST it's given, its
 field will contain the  representing the function's
return value. The wrapper then invokes  with this .Note how our decorator interjects into the regular Python execution process.
When  is called, instead of the standard Python compilation and
execution process (code is compiled into bytecode, which is then executed
by the VM), we translate its code to our own representation and emit LLVM from
it, and then JIT execute the LLVM IR. While it seems kinda pointless in this
artificial example, in reality this means we can execute the function's code
in any way we like.AST JIT case study: TritonThis approach is almost exactly how the Triton language works. The body of a
function decorated with  gets parsed to a Python AST, which then
- through a series of internal IRs - ends up in LLVM IR; this in turn is lowered
to PTX by the
NVPTX LLVM backend.
Then, the code runs on a GPU using a standard CUDA pipeline.Naturally, the subset of Python that can be compiled down to a GPU is limited;
but it's sufficient to run performant kernels, in a language that's much
friendlier than CUDA and - more importantly - lives in the same file with the
"host" part written in regular Python. For example, if you want testing and
debugging, you can run Triton in "interpreter mode" which will just run the
same kernels locally on a CPU.Note that Triton lets us import names from the  package
and use them inside kernels; these serve as the  for the language
- special calls the compiler handles directly.Python is a fairly complicated language with  of features. Therefore,
if our JIT has to support some large portion of Python semantics, it may make
sense to leverage more of Python's own compiler. Concretely, we can have it
compile the wrapped function all the way to bytecode,
and start our translation from there.Here's the  decorator that does just this :The Python VM is a stack machine; so we emulate a stack to convert the
function's bytecode to  IR (a bit like an RPN evaluator).
As before, we then use our  utility function to lower
 to LLVM IR and JIT execute it.Using this JIT is as simple as the previous one - just swap 
for :Bytecode JIT case study: NumbaNumba is a compiler for Python itself. The idea
is that you can speed up specific functions in your code by slapping a
 decorator on them. What happens next is similar in spirit to
our simple , but of course much more complicated because it
supports a very large portion of Python semantics.Numba uses the Python compiler to emit bytecode, just as we did; it then
converts it into its own IR, and then to LLVM using .By starting with the bytecode, Numba makes its life easier (no need to rewrite
the entire Python compiler). On the other hand, it also makes some analyses
, because by the time we're in bytecode, a lot of semantic information
existing in higher-level representations is lost. For example, Numba has to
sweat a bit to recover control flow information from the bytecode (by
running it through a special interpreter first).The two approaches we've seen so far are similar in many ways - both rely on
Python's introspection capabilities to compile the source code of the JIT-ed
function to some extent (one to AST, the other all the way to bytecode), and
then work on this lowered representation.The tracing strategy is very different. It doesn't analyze the source code of
the wrapped function at all - instead, it  its execution by means of
specially-boxed arguments, leveraging overloaded operators and functions, and
then works on the generated trace.The code implementing this for our smile demo is surprisingly compact:Each runtime argument of the wrapped function is assigned a , and
that is placed in a , a placeholder class which lets us
do operator overloading:The remaining key function is :To understand how this works, consider this trivial example:After the decorated function is defined,  holds the wrapper function
defined inside . When  is called, the wrapper runs:For each argument of  itself (that is  and ), it creates
a new  holding a . This denotes a named variable in
the  IR.It then calls the wrapped function, passing it the boxes as runtime
parameters.When (the wrapped)  runs, it invokes . This is caught by the overloaded
 operator of , and it creates a new  with
the s representing  and  as children. This
 is then returned .The wrapper unboxes the returned  and passes it to
 to emit LLVM IR from it and JIT execute it with the
actual runtime arguments of the call: .This might be a little mind-bending at first, because there are two different
executions that happen:The first is calling the wrapped  function itself, letting the Python
interpreter run it as usual, but with special arguments that build up the IR
instead of doing any computations. This is the .The second is lowering this IR our tracing step built into LLVM IR and then
JIT executing it with the actual runtime argument values ; this is
the .This tracing approach has some interesting characteristics. Since we don't
have to analyze the source of the wrapped functions but only trace through
the execution, we can "magically" support a much richer set of programs, e.g.:This  with our basic . Since Python variables are
placeholders (references) for values, our tracing step is oblivious to them - it
follows the flow of values. Another example:This also just works! The created  will be a long chain of 
additions of 's runtime values through the loop, added to the 
for .This last example also leads us to a limitation of the tracing approach; the
loop cannot be  - it cannot depend on the function's arguments,
because the tracing step has no concept of runtime values and wouldn't know
how many iterations to run through; or at least, it doesn't know this unless
we want to perform the tracing run for every runtime execution .Tracing JIT case study: JAXThe JAX ML framework uses a tracing
approach very similar to the one described here. The first code sample in this
post shows the JAX notation. JAX cleverly wraps Numpy with its own version which
is traced (similar to our , but JAX calls these boxes "tracers"),
letting you write regular-feeling Numpy code that can be JIT optimized and
executed on accelerators like GPUs and TPUs via XLA. JAX's tracer builds up an underlying IR (called
jaxpr) which can then be
emitted to XLA ops and passed to XLA for further lowering and execution.For a fairly deep overview of how JAX works, I recommend reading the
autodidax doc.As mentioned earlier, JAX has some limitations
with things like data-dependent control flow in native Python. This won't work,
because there's control flow
that depends on a runtime value ():When  is executed, JAX will throw an exception, saying something
like:
This concrete value was not available in Python because it depends on the
value of the argument count.As a remedy, JAX has its
own built-in intrinsics from the jax.lax package.
Here's the example rewritten in a way that actually works: (and many other built-ins in the  package) is something JAX
can trace through, generating a corresponding XLA operation (XLA has support for
While loops, to which this
 can be lowered).The tracing approach has clear benefits for JAX as well; because it only cares
about the flow of values, it can handle arbitrarily complicated Python code,
as long as the flow of values can be traced. Just like the local variables and
data-independent loops shown earlier, but also things like closures. This makes
meta-programming and templating easy .The full code for this post is available on GitHub.]]></content:encoded></item><item><title>Hugo van Kemenade: Improving licence metadata</title><link>https://hugovk.dev/blog/2025/improving-licence-metadata/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 15:11:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[PEP 639 defines a spec on how to document licences
used in Python projects.Change  as follows.I usually use Hatchling as a build backend, and support was added in 1.27:Replace the freeform  field with a valid SPDX license expression, and add
 which points to the licence files in the repo. Thereâs often only one,
but if you have more than one, list them all:Optionally delete the deprecated licence classifier:Then make sure to use a PyPI uploader that supports this.pip can also show you the metadata:A lot of work went into this. Thank you to PEP authors
Philippe Ombredanne for creating the first draft in
2019, to C.A.M. Gerlach for the second draft in 2021,
and especially to Karolina Surma for getting the third
draft finish line and helping with the implementation.And many projects were updated to support this, thanks to the maintainers and
contributors of at least:]]></content:encoded></item><item><title>Real Python: The Real Python Podcast â Episode #239: Behavior-Driven vs Test-Driven Development &amp;amp; Using Regex in Python</title><link>https://realpython.com/podcasts/rpp/239/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 12:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[What is behavior-driven development, and how does it work alongside test-driven development? How do you communicate requirements between teams in an organization? Christopher Trudeau is back on the show this week, bringing another batch of PyCoder's Weekly articles and projects.]]></content:encoded></item><item><title>Daniel Roy Greenfeld: Building a playing card deck</title><link>https://daniel.feldroy.com/posts/2025-02-deck-of-cards</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Fri, 14 Feb 2025 09:50:04 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Today is Valentine's Day. That makes it the perfect day to write a blog post about showing how to not just build a deck of cards, but show off cards from the heart suite.]]></content:encoded></item><item><title>Bojan Mihelac: Prefixed Parameters for Django querystring tag</title><link>http://code.informatikamihelac.com/en/query-string-with-prefixed-parameters/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Thu, 13 Feb 2025 21:37:18 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[An overview of Django 5.1's new querystring tag and how to add support for prefixed parameters.]]></content:encoded></item><item><title>Peter Bengtsson: get in JavaScript is the same as property in Python</title><link>http://www.peterbe.com/plog/get-in-javascript-is-the-same-as-property-in-python</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Thu, 13 Feb 2025 12:41:56 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Prefix a function, in an object or class, with `get` and then that acts as a function call without brackets. Just like Python's `property` decorator.]]></content:encoded></item><item><title>EuroPython: EuroPython February 2025 Newsletter</title><link>https://blog.europython.eu/europython-february-2025-newsletter/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Thu, 13 Feb 2025 08:36:11 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Hope you&aposre all having a fantastic February. We sure have been busy and got some exciting updates for you as we gear up for EuroPython 2025, which is taking place once again in the beautiful city of Prague. So let&aposs dive right in!EuroPython 2025 is right around the corner and our programme team is hard at work putting together an amazing lineup. But we need your help to shape the conference! We received over 572 fantastic proposals, and now itâs time for Community Voting! ð If you&aposve attended EuroPython before or submitted a proposal this year, youâre eligible to vote.ð¢ More votes = a stronger, more diverse programme! Spread the word and get your EuroPython friends to cast their votes too.ðThe deadline is , so donât miss your chance!Want to play a key role in building an incredible conference? Join our review team and help select the best talks for EuroPython 2025! Whether you&aposre a Python expert or an enthusiastic community member, your insights matter.Weâd like to also thank the over 100 people who have already signed up to review! For those who havenât done so yet, please remember to accept your Pretalx link and get your reviews in by You can already start reviewing proposals, and each review takes as little as 5 minutes. We encourage reviewers to go through at least 20-30 proposals, but if you can do more, even better! With almost 600 submissions to pick from, your help ensures we curate a diverse and engaging programme.ðThe deadline is Monday next week, so donât delay!EuroPython isnât just present at other Python eventsâwe actively support them too! As a community sponsor, we love helping local PyCons grow and thrive. We love giving back to the community and strengthening Python events across Europe! ððThe EuroPython team had a fantastic time at PyCon + Web in Berlin, meeting fellow Pythonistas, exchanging ideas, and spreading the word about EuroPython 2025. It was great to connect with speakers, organizers, and attendees.Â Ever wondered how long it takes to walk from Berlin to Prague? A huge thank you to our co-organizers, Cheuk, Artur, and CristiÃ¡n, for answering that in their fantastic lightning talk about EuroPython!We had some members of the EuroPython team at FOSDEM 2025, connecting with the open-source community and spreading the Python love! ð We enjoyed meeting fellow enthusiasts, sharing insights about the EuroPython Society, and giving away the first EuroPython 2025 stickers. If you stopped byâthank you and we hope to see you in Prague this July.ð¦ Speaker Mentorship ProgrammeThe signups for The Speaker Mentorship Programme closed on 22nd January 2025. Weâre excited to have matched 43 mentees with 24 mentors from our community. We had an increase in the number of mentees who signed up and thatâs amazing! Weâre glad to be contributing to the journey of new speakers in the Python community. A massive thank you to our mentors for supporting the mentees and to our mentees; weâre proud of you for taking this step in your journey as a speaker.Â 26 mentees submitted at least 1 proposal. Out of this number, 13 mentees submitted 1 proposal, 9 mentees submitted 2 proposals, 2 mentees submitted 3 proposals, 1 mentee submitted 4 proposals and lastly, 1 mentee submitted 5 proposals. We wish our mentees the best of luck. We look forward to the acceptance of their proposals.In a few weeks, we will host an online panel session with 2â3 experienced community members who will share their advice with first-time speakers. At the end of the panel, there will be a Q&A session to answer all the participantsâ questions.You can watch the recording of the previous yearâs workshop here:EuroPython is one of the largest Python conferences in Europe, and it wouldnât be possible without our sponsors. We are so grateful for the companies who have already expressed interest. If youâre interested in sponsoring EuroPython 2025 as well, please reach out to us at sponsoring@europython.eu.ð¤ EuroPython Speakers Share Their ExperiencesWe asked our past speakers to share their experiences speaking at EuroPython. These videos have been published on YouTube as shorts, and we&aposve compiled them into brief clips for you to watch.A big thanks goes to Sebastian Witowski, Jan Smitka, Yuliia Barabash, Jodie Burchell, Max Kahan, and Cheuk Ting Ho for sharing their experiences.Why You Should Submit a Proposal for EuroPython? Part 2Why You Should Submit a Proposal for EuroPython? Part 3ð EuroPython Society Board ReportÂ The EuroPython conference wouldnât be what it is without the incredible volunteers who make it all happen. ð Behind the scenes, thereâs also the EuroPython Societyâa volunteer-led non-profit that manages the fiscal and legal aspects of running the conference, oversees its organization, and works on a few smaller projects like the grants programme. To keep everyone in the loop and promote transparency, the Board is sharing regular updates on what weâre working on.That&aposs all for now! Keep an eye on your inbox and our website for more news and announcements. We&aposre counting down the days until we can come together in Prague to celebrate our shared love for Python. ðâ¤ï¸Cheers,The EuroPython Team]]></content:encoded></item><item><title>Giampaolo Rodola: psutil: drop Python 2.7 support</title><link>https://gmpy.dev/blog/2025/psutil-drop-python-27-support</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 23:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[About dropping Python 2.7 support in psutil, 3 years ago
I stated:Not a chance, for many years to come. [Python 2.7] currently represents 7-10%
of total downloads, meaning around 70k / 100k downloads per day.Only 3 years later, and to my surprise, downloads for Python 2.7 dropped to
0.36%! As such, as of psutil 7.0.0, I finally decided to drop support for
Python 2.7!These are downloads per month:According to pypistats.org Python 2.7 downloads
represents the 0.28% of the total, around 15.000 downloads per day.Maintaining 2.7 support in psutil had become increasingly difficult, but still
possible. E.g. I could still run tests by using old PYPI
backports.
GitHub Actions could still be
tweaked
to run tests and produce 2.7 wheels on Linux and macOS. Not on Windows though,
for which I had to use a separate service (Appveyor). Still, the amount of
hacks in psutil source code necessary to support Python 2.7 piled up over the
years, and became quite big. Some disadvantages that come to mind:Having to maintain a Python compatibility layers like
  psutil/_compat.py.
  This translated in extra extra code and extra imports.The C compatibility layer to differentiate between Python 2 and 3 (#if
  PY_MAJOR_VERSION <= 3, etc.).Dealing with the string vs. unicode differences, both in Python and in C.Inability to use modern language features, especially f-strings.Inability to freely use s, which created a difference on how CONSTANTS
  were exposed in terms of API.Having to install a specific version of  and other (outdated)
  deps.Relying on the third-party Appveyor CI service to run tests and produce 2.7
  wheels.Running 4 extra CI jobs on every commit (Linux, macOS, Windows 32-bit,
  Windows 64-bit) making the CI slower and more subject to failures (we have
  quite a bit of flaky tests).The distribution of 7 wheels specific for Python 2.7. E.g. in the previous
  release I had to upload:psutil-6.1.1-cp27-cp27m-macosx_10_9_x86_64.whl
psutil-6.1.1-cp27-none-win32.whl
psutil-6.1.1-cp27-none-win_amd64.whl
psutil-6.1.1-cp27-cp27m-manylinux2010_i686.whl
psutil-6.1.1-cp27-cp27m-manylinux2010_x86_64.whl
psutil-6.1.1-cp27-cp27mu-manylinux2010_i686.whl
psutil-6.1.1-cp27-cp27mu-manylinux2010_x86_64.whl
The removal was done in
PR-2841, which removed around
1500 lines of code (nice!). . In doing so, in the doc I
still made the promise that the 6.1.* serie will keep supporting Python 2.7
and will receive  (no new features). It will be
maintained in a specific python2
branch. I explicitly kept
the
setup.py
script compatible with Python 2.7 in terms of syntax, so that, when the tarball
is fetched from PYPI, it will emit an informative error message on . The user trying to install psutil on Python 2.7 will see:$pip2installpsutil
Asofversion.0.0psutilnolongersupportsPython.7.
LatestversionsupportingPython.7ispsutil.1.X.
Installitwith:.
As the informative message states, users that are still on Python 2.7 can still
use psutil with:pip2 install psutil==6.1.*
]]></content:encoded></item><item><title>Kay Hayen: Nuitka Release 2.6</title><link>https://nuitka.net/posts/nuitka-release-26.html</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 23:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[ Path normalization to native Windows format was required
in more places for the  variant of .The  function doesnât normalize to native Win32
paths with MSYS2, instead using forward slashes. This required manual
normalization in additional areas. (Fixed in 2.5.1) Fix, give a proper error when extension modules asked to
include failed to be located. instead of a proper error message.
(Fixed in 2.5.1)Fix, files with illegal module names (containing ) in their
basename were incorrectly considered as potential sub-modules for
. These are now skipped. (Fixed in 2.5.1) Improved stability by preventing crashes when stubgen
encounters code it cannot handle. Exceptions from it are now ignored.
(Fixed in 2.5.1) Addressed a crash that occurred when encountering
assignments to non-variables. (Fixed in 2.5.1) Fixed a regression introduced in 2.5 release that could
lead to segmentation faults in exception handling for generators.
(Fixed in 2.5.2) Corrected an issue where dictionary copies of large
split directories could become corrupted. This primarily affected
instance dictionaries, which are created as copies until updated,
potentially causing problems when adding new keys. (Fixed in 2.5.2) Removed the assumption that module dictionaries
always contain only strings as keys. Some modules, like
 on macOS, use non-string keys. (Fixed in 2.5.2) Ensured that the  option correctly
affects the C compilation process. Previously, only individual
disables were applied. (Fixed in 2.5.2) Fixed a crash that could occur during compilation
when unary operations were used within binary operations. (Fixed in
2.5.3) Corrected the handling of
, which could lead to crashes. (Fixed
in 2.5.4) Resolved a segmentation fault occurring at runtime
when calling  with only keyword arguments.
(Fixed in 2.5.5) Harmless warnings generated for x64 DLLs on arm64 with
newer macOS versions are now ignored. (Fixed in 2.5.5) Addressed a crash in Nuitkaâs dictionary code that
occurred when copying dictionaries due to internal changes in Python
3.13. (Fixed in 2.5.6) Improved onefile mode signing by applying
 to the signature of binaries, not just
app bundles. (Fixed in 2.5.6) Corrected an issue where too many paths were added as
extra directories from the Nuitka package configuration. This
primarily affected the  package, which currently relies
on the  import hack. (Fixed in 2.5.6) Prevented crashes on macOS when creating onefile
bundles with Python 2 by handling negative CRC32 values. This issue
may have affected other versions as well. (Fixed in 2.5.6) Restored the functionality of code provided in
, which was no longer being applied due to a
regression. (Fixed in 2.5.6) Suppressed the app bundle mode recommendation when it is
already in use. (Fixed in 2.5.6) Corrected path normalization when the output directory
argument includes â~â. GitHub Actions Python is now correctly identified as a
Homebrew Python to ensure proper DLL resolution. (Fixed in 2.5.7) Fixed a reference leak that could occur with
values sent to generator objects. Asyncgen and coroutines were not
affected. (Fixed in 2.5.7) The  scan now correctly handles
cases where both a package init file and competing Python files
exist, preventing compile-time conflicts. (Fixed in 2.5.7) Resolved an issue where handling string constants in
modules created for Python 3.12 could trigger assertions, and modules
created with 3.12.7 or newer failed to load on older Python 3.12
versions when compiled with Nuitka 2.5.5-2.5.6. (Fixed in 2.5.7) Corrected the tuple code used when calling certain
method descriptors. This issue primarily affected a Python 2
assertion, which was not impacted in practice. (Fixed in 2.5.7) Updated resource readers to accept multiple
arguments for , and correctly handle
 and  as keyword-only arguments. The platform encoding is no longer used to decode
 logs. Instead,  is used, as it is sufficient for
matching filenames across log lines and avoids potential encoding
errors. (Fixed in 2.5.7) Requests to statically link libraries for 
are now ignored, as these libraries do not exist. (Fixed in 2.5.7) Fixed a memory leak affecting the results of
functions called via specs. This primarily impacted overloaded hard
import operations. (Fixed in 2.5.7) When multiple distributions for a package are found,
the one with the most accurate file matching is now selected. This
improves handling of cases where an older version of a package (e.g.,
) is overwritten with a different variant (e.g.,
), ensuring the correct version is used for
Nuitka package configuration and reporting. (Fixed in 2.5.8) Prevented a potential crash during onefile
initialization on Python 2 by passing the directory name directly
from the onefile bootstrap, avoiding the use of  which
may not be fully loaded at that point. (Fixed in 2.5.8) Preserved necessary  environment variables on
Windows for packages that require loading DLLs from those locations.
Only  entries not pointing inside the installation prefix are
removed. (Fixed in 2.5.8) Corrected the  check to function
properly when distribution names and package names differ. (Fixed in
2.5.8) Improved package name resolution for Anaconda
distributions by checking conda metadata when file metadata is
unavailable through the usual methods. (Fixed in 2.5.8) Normalized the downloaded gcc path to use native Windows
slashes, preventing potential compilation failures. (Fixed in 2.5.9) Restored static libpython functionality on Linux by
adapting to a signature change in an unexposed API. (Fixed in 2.5.9) Prevented  from being resurrected when a
finalizer is attached, resolving memory leaks that could occur with
 in the presence of exceptions. (Fixed in 2.5.10) Suppressed the gcc download prompt that could appear during
 output on Windows systems without MSVC or with an
improperly installed gcc.Ensured compatibility with monkey patched  or 
functions, which are used in some testing scenarios. Improved the determinism of the JSON statistics
output by sorting keys, enabling reliable build comparisons. Fixed a memory leak in  with finalizers,
which could lead to significant memory consumption when using
 and encountering exceptions. Optimized empty generators (an optimization result) to
avoid generating unused context code, eliminating C compilation
warnings. Fixed a reference leak affecting the  value
in . While typically , this could lead to
observable reference leaks in certain cases. Improved handling of  and 
resurrection, preventing memory leaks with  and
, and ensuring correct execution of  code in
coroutines. Corrected the handling of  objects
resurrecting during deallocation. While not explicitly demonstrated,
this addresses potential issues similar to those encountered with
coroutines, particularly for old-style coroutines created with the
 decorator. Fixed a potential crash during runtime trace collection by
ensuring timely initialization of the output mechanism.]]></content:encoded></item><item><title>EuroPython Society: Board Report for January 2025</title><link>https://www.europython-society.org/board-report-for-january-2025/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 15:08:37 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[The top priority for the board in January was finishing the hiring of our event manager. Weâre super excited to introduce AneÅ¾ka MÃ¼ller! AneÅ¾ka is a freelance event manager and a longtime member of the Czech Python community. Sheâs a member of the Pyvec board, co-organizes PyLadies courses, PyCon CZ, Brno Pyvo, and Brno Python Pizza. Sheâll be working closely with the board and OPS team, mainly managing communication with service providers. Welcome onboard! Our second priority was onboarding teams. Weâre happy that we already have the Programme team in placeâthey started early and launched the Call for Proposals at the beginning of January. Weâve onboarded a few more teams and are in the process of bringing in the rest.Our third priority was improving our grant programme in order to support more events with our limited budget and to make it more clear and transparent. We went through past data, came up with a new proposal, discussed it, voted on it, and have already published it on our blog. Updating onboarding/offboarding checklists for Volunteers and Board MembersVarious infrastructure updates including new website deployment and self-hosted previews for Pull Requests to the website.Setting up EPS AWS account.Working out the Grant Guidelines update for 2025Attending PyConWeb and FOSDEMReviewing updates to the Sponsors setup and packages for 2025More documentation, sharing know-how and reviewing new proposals.Brand strategy: Analysis of social media posts from previous years and web analytics. Call with a European open-source maintainer and a call with a local events organizer about EP content.Comms & design: Call for proposal announcements, EP 2024 video promotions, speaker mentorship, and newsletter. Video production - gathering videos from speakers, video post-production, and scheduling them on YouTube shorts, and social media.Event management coordination: Calls with the event manager and discussions about previous events.Grants: Work on new grant guidelines and related comms.Team onboarding: Calls with potential comms team members and coordination.PR: Delivering a lightning talk at FOSDEM.Offboarding the old boardOnboarding new team membersAdministrative work on GrantsWorked on the Grants proposalFollow-up with team membersCommunity outreach: FOSDEMWorking on various infrastructure updates, mostly related to the website.Reviewing Pull Requests for the website and the internal botWorking on the infrastructure team proposal.Timeline: Discussion with the Programme Team, and planning to do the same with the other teams.Visa Request letter: Setup and Test Visa Request Automation for the current yearTeam selection discussion with past volunteers]]></content:encoded></item><item><title>Python Morsels: Avoid over-commenting in Python</title><link>https://www.pythonmorsels.com/avoid-comments/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 15:05:39 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Documenting instead of commentingHere is a comment I would not write in my code:That comment seems to describe what this code does... so why would I  write it?I do like that comment, but I would prefer to write it as a docstring instead:Documentation strings are for conveying the purpose of function, class, or module, typically at a high level.
Unlike comments, they can be read by Python's built-in  function:Docstrings are also read by other documentation-oriented tools, like Sphinx.Non-obvious variables and valuesHere's a potentially helpful comment:]]></content:encoded></item><item><title>Real Python: Python Keywords: An Introduction</title><link>https://realpython.com/python-keywords/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 14:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Python keywords are reserved words with specific functions and restrictions in the language. Currently, Python has thirty-five keywords and four soft keywords. These keywords are always available in Python, which means you donât need to import them. Understanding how to use them correctly is fundamental for building Python programs.By the end of this tutorial, youâll understand that:There are  and  in Python.You can get a list of all keywords using  from the  module. in Python act as keywords only in specific contexts. are keywords that have been deprecated and turned into functions in Python 3.In this article, youâll find a basic introduction to all Python keywords and soft keywords along with other resources that will be helpful for learning more about each keyword. Test your knowledge with our interactive âPython Keywords: An Introductionâ quiz. Youâll receive a score upon completion to help you track your learning progress:In this quiz, you'll test your understanding of Python keywords and soft keywords. These reserved words have specific functions and restrictions in Python, and understanding how to use them correctly is fundamental for building Python programs.Python keywords are special reserved words that have specific meanings and purposes and canât be used for anything but those specific purposes. These keywords are always availableâyouâll never have to import them into your code.Python keywords are different from Pythonâs built-in functions and types. The built-in functions and types are also always available, but they arenât as restrictive as the keywords in their usage. An example of something you  do with Python keywords is assign something to them. If you try, then youâll get a . You wonât get a  if you try to assign something to a built-in function or type, but it still isnât a good idea. For a more in-depth explanation of ways keywords can be misused, check out Invalid Syntax in Python: Common Reasons for SyntaxError.There are thirty-five keywords in Python. Hereâs a list of them, each linked to its relevant section in this tutorial:Two keywords have additional uses beyond their initial use cases. The  keyword is also used with loops and with  and  in addition to in conditional statements. The  keyword is most commonly used in  statements, but also used with the  keyword.The list of Python keywords and soft keywords has changed over time. For example, the  and  keywords werenât added until Python 3.7. Also, both  and  were keywords in Python 2.7 but were turned into built-in functions in Python 3 and no longer appear in the keywords list.As mentioned above, youâll get an error if you try to assign something to a Python keyword. Soft keywords, on the other hand, arenât that strict. They syntactically act as keywords only in certain conditions.This new capability was made possible thanks to the introduction of the PEG parser in Python 3.9, which changed how the interpreter reads the source code.Leveraging the PEG parser allowed for the introduction of structural pattern matching in Python. In order to use intuitive syntax, the authors picked , , and  for the pattern matching statements. Notably,  and  are widely used for this purpose in many other programming languages.To prevent conflicts with existing Python code that already used , , and  as variable or function names, Python developers decided to introduce the concept of soft keywords.Currently, there are four  in Python:You can use the links above to jump to the soft keywords youâd like to read about, or you can continue reading for a guided tour.Value Keywords: , , There are three Python keywords that are used as values. These values are singleton values that can be used over and over again and always reference the exact same object. Youâll most likely see and use these values a lot.There are a few terms used in the sections below that may be new to you. Theyâre defined here, and you should be aware of their meaning before proceeding:]]></content:encoded></item><item><title>EuroPython Society: Changes in the Grants Programme for 2025</title><link>https://www.europython-society.org/changes-in-the-grants-programme-for-2025/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 13:16:30 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[We are increasing transparency and reducing ambiguity in the guidelines.We would like to support more events with our limited budgetWeâve introduced caps for events in order to make sure all grants are fairly given and we can support more communities.Weâve set aside 10% of our budget for the local community. The EPS introduced a Grant Programme in 2017. Since then, we have granted almost EUR 350k through the programme, partly via EuroPython Finaid and by directly supporting other Python events and projects across Europe. In the last two years, the Grant Programme has grown to EUR 100k per year, with even more requests coming in.With this growth come new challenges in how to distribute funds fairly so that more events can benefit. Looking at data from the past two years, weâve often been close to or over our budget. The guidelines havenât been updated in a while. As grant requests become more complex, weâd like to simplify and clarify the process, and better explain it on our website.We would also like to acknowledge that EuroPython, when traveling around Europe, has an additional impact on the host country, and weâd like to set aside part of the budget for the local community.The Grant Programme is also a primary funding source for EuroPython Finaid. To that end, we aim to allocate 30% of the total Grant Programme budget to Finaid, an increase from the previous 25%.Weâve updated the text on our website, and split it into multiple sub-pages to make it easier to navigate. The website now includes a checklist of what we would like to see in a grant application, and a checklist for the Grants Workgroup â so that when you apply for the Grant you already know the steps that it will go through later and when you can expect an answer from us.We looked at the data from previous years, and size and timing of the grant requests. With the growing number and size of the grants, to make it more accessible to smaller conferences and conferences happening later in the year, we decided to introduce max caps per grant and split the budget equally between the first and second half of the year. We would also explicitly split the total budget into three categories â 30% goes to the EuroPython finaid, 10% is reserved for projects in the host country. The remaining 60% of the budget goes to fund other Python Conferences. This is similar to the split in previous years, but more explicit and transparent.Using 2024 data, and the budget available for Community Grants (60% of total), weâve simulated different budget caps and found a sweet spot at 6000EUR, where we are able to support all the requests with most of the grants being below that limit. For 2025 we expect to receive a similar or bigger number of requests.We are introducing a special 10% pool of money to be used on projects in the host country (in 2025 thatâs again Czech Republic). This pool is set aside at the beginning of the year, with one caveat that we would like to deploy it in the first half of the year. Whatever is left unused goes back to the Community Pool to be used in second half of the year.Fairer Funding: By spreading our grants out during the year, conferences that happen later wonât miss out.Easy to Follow: Clear rules and deadlines cut down on confusion about how much you can get and what itâs for.Better Accountability: We ask for simple post-event reports so we can see where the money went and what impact it made.Stronger Community: Funding more events grows our Python network across Europe, helping everyone learn, connect, and collaborate.]]></content:encoded></item><item><title>Real Python: Quiz: Python Keywords: An Introduction</title><link>https://realpython.com/quizzes/python-keywords/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 12:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Python keywords are reserved words with specific functions and restrictions in the language. These keywords are always available in Python, which means you donât need to import them. Understanding how to use them correctly is fundamental for building Python programs.]]></content:encoded></item><item><title>Zato Blog: Modern REST API Tutorial in Python</title><link>https://zato.io/en/blog/modern-rest-api-tutorial-in-python.html</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 08:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[
  2025-02-12, by Dariusz Suchojad
Great APIs don't win theoretical arguments - they just prefer to work reliably and to make developers' lives easier.Here's a tutorial on what building production APIs is really about: creating interfaces that are practical in usage,
while keeping your systems maintainable for years to come.]]></content:encoded></item><item><title>Kushal Das: pass using stateless OpenPGP command line interface</title><link>https://kushaldas.in/posts/pass-using-stateless-openpgp-command-line-interface.html</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Wed, 12 Feb 2025 05:26:13 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Yesterday I wrote about how
I am using a different tool for  signing and verification. Next, I
replaced my  usage. I have a small
patch to use
stateless OpenPGP command line interface (SOP). It is an implementation
agonostic standard for handling OpenPGP messages. You can read the whole SPEC
here.cargo install rsop rsop-oct
And copied the bash script from my repository to the path somewhere.The  binary from  follows the same SOP standard but uses the
card to signing/decryption. I stored my public key in
~/.password-store/.gpg-key file, which is in turn used for encryption.Here nothing changed related my daily  usage, except the number of time I am typing my  :)]]></content:encoded></item><item><title>Python 3.14.0 alpha 5 is out</title><link>https://pythoninsider.blogspot.com/2025/02/python-3140-alpha-5-is-out.html</link><author>Hugo</author><category>Python official news</category><category>dev</category><category>official</category><category>python</category><pubDate>Tue, 11 Feb 2025 19:41:00 +0000</pubDate><source url="https://pythoninsider.blogspot.com/">Python Insider</source><content:encoded><![CDATA[Here comes the antepenultimate alpha.This is an early developer preview of Python
3.14Python 3.14 is still in development. This release, 3.14.0a5, is the
fifth of seven planned alpha releases.Alpha releases are intended to make it easier to test the current
state of new features and bug fixes and to test the release process.During the alpha phase, features may be added up until the start of
the beta phase (2025-05-06) and, if necessary, may be modified or
deleted up until the release candidate phase (2025-07-22). Please keep
in mind that this is a preview release and its use is
 recommended for production environments.Many new features for Python 3.14 are still being planned and
written. Among the new major new features and changes so far:The next pre-release of Python 3.14 will be the penultimate alpha,
3.14.0a6, currently scheduled for 2025-03-14.2025-01-29 marked the start of a new lunar year, the Year of the
Snake ð (and the Year of Python?).For centuries, Ï was often approximated as 3 in China. Some time
between the years 1 and 5 CE, astronomer, librarian, mathematician and
politician Liu Xin (åæ­) calculated Ï as 3.154.Around 130 CE, mathematician, astronomer, and geographer Zhang Heng
(å¼µè¡¡, 78â139) compared the celestial circle with the diameter of the
earth as 736:232 to get 3.1724. He also came up with a formula for the
ratio between a cube and inscribed sphere as 8:5, implying the ratio of
a squareâs area to an inscribed circle is â8:â5. From this, he
calculated Ï as â10 (~3.162).Third century mathematician Liu Hui (åå¾½) came up with an algorithm
for calculating Ï iteratively: calculate the area of a polygon inscribed
in a circle, then as the number of sides of the polygon is increased,
the area becomes closer to that of the circle, from which you can
approximate Ï.This algorithm is similar to the method used by Archimedes in the 3rd
century BCE and Ludolph van Ceulen in the 16th century CE (see 3.14.0a2
  release notes), but Archimedes only went up to a 96-sided polygon
(96-gon). Liu Hui went up to a 192-gon to approximate Ï as 157/50 (3.14)
and later a 3072-gon for 3.14159.Liu Hu wrote a commentary on the book The Nine Chapters on the
Mathematical Art which included his Ï approximations.In the fifth century, astronomer, inventor, mathematician,
politician, and writer Zu Chongzhi (ç¥æ²ä¹, 429â500) used Liu Huiâs
algorithm to inscribe a 12,288-gon to compute Ï between 3.1415926 and
3.1415927, correct to seven decimal places. This was more accurate than
Hellenistic calculations and wouldnât be improved upon for 900
years.Thanks to all of the many volunteers who help make Python Development
and these releases possible! Please consider supporting our efforts by
volunteering yourself or through organisation contributions to the Python Software
Foundation.Regards from a remarkably snowless Helsinki,Your release team, Hugo van KemenadeSteve Dower]]></content:encoded></item><item><title>PyCoderâs Weekly: Issue #668: NumPy, Compiling Python 1.0, BytesIO, and More (Feb. 11, 2025)</title><link>https://pycoders.com/issues/668</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 19:30:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[ In this video course, youâll learn how to use NumPy by exploring several interesting examples. Youâll read data from a file into an array and analyze structured arrays to perform a reconciliation. Youâll also learn how to quickly chart an analysis & turn a custom function into a vectorized function. This tutorial will help you master Python string splitting. Youâll learn to use , , and  to effectively handle whitespace, custom delimiters, and multiline text, which will level up your data parsing skills. Python developers use Posit Package Manager to mirror public & internally developed repos within their firewalls. Get reporting on known vulnerabilities to proactively address potential threats. High-security environments can even run air-gapped. The author was recently invited with other senior devs to give a lightning talk on their personal development philosophy. This post captures those thoughts.[ Subscribe to ð PyCoderâs Weekly ð â Get the best Python news, articles, and tutorials delivered to your inbox once a week >> Click here to learn more ]]]></content:encoded></item><item><title>Python Insider: Python 3.14.0 alpha 5 is out</title><link>https://pythoninsider.blogspot.com/2025/02/python-3140-alpha-5-is-out.html</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 16:25:58 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Here comes the antepenultimate alpha.This is an early developer preview of Python
3.14Python 3.14 is still in development. This release, 3.14.0a5, is the
fifth of seven planned alpha releases.Alpha releases are intended to make it easier to test the current
state of new features and bug fixes and to test the release process.During the alpha phase, features may be added up until the start of
the beta phase (2025-05-06) and, if necessary, may be modified or
deleted up until the release candidate phase (2025-07-22). Please keep
in mind that this is a preview release and its use is
 recommended for production environments.Many new features for Python 3.14 are still being planned and
written. Among the new major new features and changes so far:The next pre-release of Python 3.14 will be the penultimate alpha,
3.14.0a6, currently scheduled for 2025-03-14.2025-01-29 marked the start of a new lunar year, the Year of the
Snake ð (and the Year of Python?).For centuries, Ï was often approximated as 3 in China. Some time
between the years 1 and 5 CE, astronomer, librarian, mathematician and
politician Liu Xin (åæ­) calculated Ï as 3.154.Around 130 CE, mathematician, astronomer, and geographer Zhang Heng
(å¼µè¡¡, 78â139) compared the celestial circle with the diameter of the
earth as 736:232 to get 3.1724. He also came up with a formula for the
ratio between a cube and inscribed sphere as 8:5, implying the ratio of
a squareâs area to an inscribed circle is â8:â5. From this, he
calculated Ï as â10 (~3.162).Third century mathematician Liu Hui (åå¾½) came up with an algorithm
for calculating Ï iteratively: calculate the area of a polygon inscribed
in a circle, then as the number of sides of the polygon is increased,
the area becomes closer to that of the circle, from which you can
approximate Ï.This algorithm is similar to the method used by Archimedes in the 3rd
century BCE and Ludolph van Ceulen in the 16th century CE (see 3.14.0a2
  release notes), but Archimedes only went up to a 96-sided polygon
(96-gon). Liu Hui went up to a 192-gon to approximate Ï as 157/50 (3.14)
and later a 3072-gon for 3.14159.Liu Hu wrote a commentary on the book The Nine Chapters on the
Mathematical Art which included his Ï approximations.In the fifth century, astronomer, inventor, mathematician,
politician, and writer Zu Chongzhi (ç¥æ²ä¹, 429â500) used Liu Huiâs
algorithm to inscribe a 12,288-gon to compute Ï between 3.1415926 and
3.1415927, correct to seven decimal places. This was more accurate than
Hellenistic calculations and wouldnât be improved upon for 900
years.Thanks to all of the many volunteers who help make Python Development
and these releases possible! Please consider supporting our efforts by
volunteering yourself or through organisation contributions to the Python Software
Foundation.Regards from a remarkably snowless Helsinki,Your release team, Hugo van KemenadeSteve Dower]]></content:encoded></item><item><title>Real Python: Building a Python Command-Line To-Do App With Typer</title><link>https://realpython.com/courses/build-command-line-todo-app-typer/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 14:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Building an application to manage your  can be an interesting project when youâre learning a new programming language or trying to take your skills to the next level. In this video course, youâll build a functional to-do application for the command line using Python and Typer, which is a relatively young library for creating powerful command-line interface (CLI) applications in almost no time.With a project like this, youâll apply a wide set of core programming skills while building a real-world application with real features and requirements.In this video course, youâll learn how to:Build a functional  with a  in PythonUse Typer to add , , and  to your to-do appTest your Python to-do application with Typerâs  and ]]></content:encoded></item><item><title>Kushal Das: Using openpgp-card-tool-git with git</title><link>https://kushaldas.in/posts/using-openpgp-card-tool-git-with-git.html</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 11:12:40 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[One of the power of Unix systems comes from the various small tools and how
they work together. One such new tool I am using for some time is for  &  using OpenPGP and my Yubikey for the actual signing
operation via
openpgp-card-tool-git. I
replaced the standard  for this usecase with the  command from this
project.Installation & configurationcargo install openpgp-card-tool-git
Then you will have to configuration your (in my case the global configuration) git configuration.git config --global gpg.program <path to oct-git>
I am assuming that you already had it configured before for signing, otherwise
you have to run the following two commands too.git config --global commit.gpgsign true
git config --global tag.gpgsign true
Before you start using it, you want to save the pin in your system keyring.Use the following command.That is it, now your  will sign the commits using  tool.In the next blog post I will show how to use the other tools from the 
author for various different OpenPGP oeprations.]]></content:encoded></item><item><title>Django Weblog: DSF member of the month - Lily Foote</title><link>https://www.djangoproject.com/weblog/2025/feb/10/dsf-member-of-the-month-lily-foote/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 04:51:31 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[For February 2025, we welcome Lily Foote (@lilyf) as our DSF member of the month! â­Lily Foote is a contributor to Django core for many years, especially on the ORM. She is currently a member of the Django 6.x Steering Council and she has been a DSF member since March 2021. 
You can learn more about Lily by visiting her GitHub profile.Letâs spend some time getting to know Lily better!Can you tell us a little about yourself (hobbies, education, etc)My name is Lily Foote and Iâve been contributing to Django for most of my career. Iâve also recently got into Rust and Iâm excited about using Rust in Python projects. When Iâm not programming, I love hiking, climbing and dancing (Ceilidh)! I also really enjoying playing board games and role playing games (e.g. Dungeons and Dragons).How did you start using Django?Iâd taught myself Python in my final year at university by doing Project Euler problems and then decided I wanted to learn how to make a website. Django was the first Python web framework I looked at and it worked really well for me.What other framework do you know and if there is anything you would like to have in Django if you had magical powers?Iâve done a small amount with Flask and FastAPI. More than any new features, I think the thing that Iâd most like to see is more long-term contributors to spread the work of keeping Django awesome.What projects are you working on now?The side project Iâm most excited about is Django Rusty Templates, which is a re-implementation of Djangoâs templating language in Rust.Which Django libraries are your favorite (core or 3rd party)?What are the top three things in Django that you like?Django Conferences, the mentorship program Djangonaut Space and the whole community!You have been a mentor multiple times with GSoC and Djangonaut Space program, what is required according to you to be a good mentor?I think being willing to invest time is really important. Checking in with your mentees frequently and being an early reviewer of their work. I think this helps keep their motivation up and allows for small corrections early on.Any advice for future contributors?Start small and as you get more familiar with Django and the process of contributing you can take on bigger issues. Also be patient with reviewers â Django has high standards, but is mostly maintained by volunteers with limited time.Yes! Itâs a huge honour! Since January, weâve been meeting weekly and it feels like weâve hardly scratched the surface of what we want to achieve. The biggest thing weâre trying to tackle is how to improve the contribution experience â especially evaluating new feature ideas â without draining everyoneâs time and energy.You have a lot of knowledge in the Django ORM, how did you start to contribute to this part?I added the Greatest and Least expressions in Django 1.9, with the support of one of the core team at the time. After that, I kept showing up (especially at conference sprints) and finding a new thing to tackle.Is there anything else youâd like to say?Thank you for doing the interview, Lily!]]></content:encoded></item><item><title>Quansight Labs Blog: PEP 517 build system popularity</title><link>https://labs.quansight.org/blog/pep-517-build-system-popularity</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[Analysis of PEP 517 build backends used in 8000 top PyPI packages]]></content:encoded></item><item><title>Seth Michael Larson: Building software for connection (#2: Consensus)</title><link>https://sethmlarson.dev/building-software-for-connection-consensus?utm_campaign=rss</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Tue, 11 Feb 2025 00:00:00 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[In the previous article we concluded that a persistent always-on internet
connection isn't required for software to elicit feelings of connection between humans.Building on this conclusion: let's explore how Animal Crossing software was able to intercommunicate without requiring
a centralized server and infrastructure and the trade-offs for these design decisions.Distributing digital goods without the internetAnimal Crossing has over 1,000 unique items that need to be collected
for a complete catalog, including furniture, wallpapers, clothing, parasols, and carpets.
Many of these items are quite rare or were only programmed to be accessible
through an official Nintendo-affiliated distribution such as a magazine or online contest.Beyond official distributions, it's clear Animal Crossings' designer, Katsuya Eguchi,
wanted players to  to complete their catalogs.
The game incentivized trading items between towns by assigning
one ânative fruitâ (Apple, Orange, Cherry, Peach, or Pear) and
randomly making a subset of items harder to find than others depending
on a hidden âitem groupâ variable (either A, B, or C).Items could be exchanged between players when one player visits another town,
but this required physically bringing your memory card to another
players' GameCube. The GameCube might have come with a handle, but the 'cube wasn't exactly a . Sharing a physical space isn't something you can do with everyone or on a regular basis.So what did Katsuya Eguchi design for Animal Crossing? To allow for item distributions from magazines and contests and to make player-to-player item sharing easier Animal Crossing included a feature called âsecret codesâ.This feature worked by allowing players to exchange 28-character codes with Tom Nook for items. Players could also generate codes for their friends to âsendâ an item from their own game to a different town. Codes could be shared by writing them on a paper note, instant message, or text message.The forgotten durability of offline software
This Reddit comment thread from the GameCube subreddit was the initial inspiration for this entire series.
The post is about someone's niece who just started playing Animal Crossing for the first time.
The Redditor asked folks to send items to their nieces' town using the secret code system.
This ended up surprising many folks that this system 
 in a game that was over 23 years old!
For reference, Nintendo Wi-Fi Connection and Nintendo Network were only available for 8 and 13 years respectively.
Below are a handful of the comments from the thread:âFor real does this still work lol?âIt's hard not to take these comments as indicators that something is
 with internet-connected software today. What had to go wrong for a 
system continuing to work to ? Many consumers' 
experience with 
software products
today is that they become useless e-waste after some far-away service is 
discontinued a few years after purchase.My intuition from this is that software that requires centralized servers and infrastructure to function
will have shorter lifetimes than software which is offline or only
opportunistically uses online functionality.I don't think this is particularly insightful,
more dependencies always means less resilience. But if we're building software for human connection then the software
should optimally only be limited by the availability of humans to connect.What is centralization good for?Animal Crossings' secret code system is far from perfect. The system is easily abusable, as the same secret codes can be
reused over-and-over by the same user to duplicate items without ever expiring. The only limit was that 3 codes could be used per day.Not long after Animal Crossing's release
the secret code algorithm was reverse-engineered so secret codes 
for any item could be created for any town and recipient name as if they came from an official Nintendo distribution.
This was possible because the secret code system relied on "security through obscurity".Could  be the answer to preventing these abuses?The most interesting property that a centralized authority approach
provides is : forcing everyone to play by the same rules. By storing
the âsingle source-of-truthâ a central authority is able to prevent abuses
like the ones mentioned above.For example, a centralized âsecret code issuing serverâ could generate
new unique codes per-use and check each code's validity
against a database to prevent users from generating their
own illegitimate codes or codes being re-used multiple times.The problem with
centralized consensus is it tends to be  to cover the entire software state.
A centralized server can generate codes perfectly, but how can that same server
 that the items you're exchanging for codes were obtained legitimately? To know this
the server would also need to track item legitimacy, leading to software which requires
an internet connection to operate.This is optimal from a correctness perspective, but as was noted earlier,
I suspect that if such a server was a mandatory part of the secret code system
in Animal Crossing that the system would likely not be usable today.This seems like a trade-off, which future would you rather have?Redesigning Animal Crossing secret codesIf I were designing Animal Crossings' secret code system with modern hardware, what would it look like?
How can we keep the offline fall-back while providing consensus and being less
abusable, especially for official distributions.I would likely use a public-key cryptographic system for official distributions,
embedding a certificate that could be used to âverifyâ that specific secret codes
originated from the expected centralized entity. Codes that are accepted would be
recorded to prevent reusing the same code multiple times in the same town.
Using public-key cryptography prevents the
system from being reverse-engineered to distribute arbitrary items until the certificate
private key was cracked.For sharing items between players I would implement a system where each town
generated a public and private key and the public key was shared to other towns
whenever the software was able to, such as when a player visited the other town.
Players would only be able to send items to players that they have visited
(which for Animal Crossing required physical presence, more on this later!)Each sender could store a nonce value for
each potential recipient. Embedding that nonce into the secret code would allow
the recipients' software to verify that the specific code hadn't been used yet.
The nonce wouldn't have to be long to avoid simple reusing of codes.Both above systems would require much more data to be embedded into each âsecret
codeâ compared to the 28-character codes from the GameCube. For this I would
use QR codes to embed over 2KB of data into a single QR code. Funnily enough,
Animal Crossing New Leaf and onwards use QR code technology for players to share design patterns.This design is still abusable if users can modify their software or hardware
but doesn't suffer from the trivial-to-exploit flaws of Animal Crossing's secret code system.Decentralized global consensus?What if we could have the best of both worlds: we want consensus
that is both  and . At least today, we are out of luck.Decentralized global consensus is technologically feasible, but the existing solutions
(mostly blockchains)
are expensive (both in energy and capital) and can't handle throughput on any sort of 
meaningful scale.There are many other decentralized consensus systems that 
are able to form âpocketsâ of useful peer-to-peer consensus using a fraction of
the resources, such as email, BitTorrent, ActivityPub, and Nostr.
These systems are only possible by adding  or by only guaranteeing .When is global consensus needed?Obviously global consensus is important for certain classes of software like 
financial, civics, and infrastructure, but I wonder how the necessity
of consensus in software changes for software with different risk
profiles.For software which has fewer risks associated with misuse is there as much
need for global consensus?
How can  be designed to reduce risk and require
less consensus to be effective? If global consensus and centralized 
servers become unnecessary, can we expect  to be usable 
on much longer timescales, essentially for as long as there are users?]]></content:encoded></item><item><title>Python Morsels: Newlines and escape sequences in Python</title><link>https://www.pythonmorsels.com/newlines-and-escape-sequences/</link><author></author><category>Planet Python blog</category><category>dev</category><category>python</category><pubDate>Mon, 10 Feb 2025 15:17:29 +0000</pubDate><source url="http://planetpython.org/">Planet Python</source><content:encoded><![CDATA[This string contains a newline character:That's what  represents: a newline character.If we print this string, we'll see that  becomes an  newline:Why does Python represent a newline as ?Escape sequences in PythonEvery character in a Python â¦]]></content:encoded></item><item><title>How to Join Strings in Python</title><link>https://realpython.com/python-join-string/</link><author>Real Python</author><category>Real Python Blog</category><category>dev</category><category>python</category><pubDate>Mon, 10 Feb 2025 14:00:00 +0000</pubDate><source url="https://realpython.com/atom.xml">Real Python</source><content:encoded><![CDATA[Pythonâs built-in string method  lets you combine string elements from an iterable into a single string, using a separator that you specify. You call  on the separator, passing the iterable of strings to join.By the end of this tutorial, youâll understand that:You use  in Python to  with a .A  is the piece of text you want inserted between each substring.To join list elements, you call  on a separator string, passing the list as the argument.inserts the separator between each list element to form a single string.The  method  that is the concatenation of the elements in the iterable, separated by the specified string.For smaller string concatenation tasks, you can use the concatenation operator () or  instead of .Pythonâs built-in  method gives you a quick and reliable way to combine multiple strings into a single string. Whether you need to format output or assemble data for storage,  provides a clean and efficient approach for joining strings from an iterable.In the upcoming sections, youâll learn the basic usage of  to concatenate strings effectively. Youâll then apply that knowledge to real-world scenarios, from building CSV files to constructing custom log outputs. Youâll also discover some surprising pitfalls and learn how to avoid them. Test your knowledge with our interactive âHow to Join Strings in Pythonâ quiz. Youâll receive a score upon completion to help you track your learning progress:Test your understanding of Python's .join() string method for combining strings, handling edge cases, and optimizing performance.How to Join Strings in Python Using To use the string method , you call  on a separator string and pass an iterable of other strings as the argument. The method returns a single string, where it has inserted the separator string between each element of the iterable:In this example, you joined a list of words into one sentence, separated by spaces.At first glance, this usage might look a little backward. In many other string operations, you call the method on the main string that you want to manipulate. However, with , you call the method on the separator string, then pass the iterable of strings that you want to combine:This example achieves the same result as the earlier one but splits the process into two steps. Defining  separately makes the code more readable and avoids the potentially odd-looking syntax of calling  directly on a short string literal. Remember that  is a  method, which means that youâll need to call it on a  string object. Keeping that in mind may help you remember why you need to call it on the separator string.You rarely see code thatâs written in multiple steps where you assign the separator string to a variable, like you did in the example above.In typical usage, you call  directly on the separator string, all in one line. This approach is more concise and highlights that any valid string can be your separator, whether itâs whitespace, a dash, or a multicharacter substring.Join With an Empty StringWhat if you donât want any separator at all, but just want to concatenate the items? One valid approach is to use an empty string () as the separator:This code snippet concatenates the letters in the list, forming a single string . Using an empty string as the separator is a great way to assemble strings without a delimiter between them.Since  can take any iterable of stringsânot just listsâyou can even pass a string as an argument. Because strings are iterable, Python iterates over each character in that string, considering each character as a separate element:By calling  on  and passing the string , you effectively place a comma between every single character in . This might not always be what you intend, but itâs a neat trick to keep in mind if you ever need to treat each character as a separate element.]]></content:encoded></item><item><title>#493: Quarto: Open-source technical publishing</title><link>https://talkpython.fm/episodes/show/493/quarto-open-source-technical-publishing</link><author></author><category>Talk Python</category><category>dev</category><category>python</category><category>podcast</category><enclosure url="https://talkpython.fm/episodes/download/493/quarto-open-source-technical-publishing.mp3" length="" type=""/><pubDate>Sun, 9 Feb 2025 08:00:00 +0000</pubDate><source url="https://talkpython.fm/">Talk Python To Me</source><content:encoded><![CDATA[]]></content:encoded></item></channel></rss>