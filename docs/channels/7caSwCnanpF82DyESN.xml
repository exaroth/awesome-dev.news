<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Official News</title><link>https://www.awesome-dev.news</link><description></description><item><title>GitHub Copilot Spaces: Bring the right context to every suggestion</title><link>https://github.blog/ai-and-ml/github-copilot/github-copilot-spaces-bring-the-right-context-to-every-suggestion/</link><author>Andrea Griffiths</author><category>official</category><pubDate>Wed, 18 Jun 2025 16:00:00 +0000</pubDate><source url="https://github.blog/">Github Blog</source><content:encoded><![CDATA[When generative AI tools guess what you need, the magic only lasts as long as the guesses are right. Add an unfamiliar codebase, a security checklist your team keeps in a wiki, or a one‑off Slack thread that explains  something matters, and even the most and even the most powerful model may fill in gaps with assumptions rather than having access to your specific context and knowledge.GitHub Copilot Spaces fixes that problem by letting you bundle the exact context Copilot should read—code, docs, transcripts, sample queries, you name it—into a reusable “space.” Once a space is created, every Copilot chat, completion, or command is grounded in that curated knowledge, producing answers that feel like they came from your organization’s resident expert instead of a generic model.In this article, we’ll walk through:A 5‑minute quick‑start guide to creating your first spaceTips for personalizing Copilot’s tone, style, and conventions with custom instructionsReal‑world recipes for accessibility, data queries, and onboardingCollaboration, security, and what’s next on the roadmap (spoiler: IDE integration and Issues/PR support)Why context is the new bottleneck for AI‑assisted developmentLarge language models (LLMs) thrive on patterns, but day‑to‑day engineering work is full of patterned edge cases, including:A monorepo that mixes modern React with legacy jQueryOrganizational wisdom buried in Slack threads or internal wikisOrganization‑specific security guidelines that differ from upstream OSS docsWithout that context, an AI assistant can only guess. But with Copilot Spaces, you choose which files, documents, or free‑text snippets matter, drop them into a space, and let Copilot use that context to answer questions or write code. As Kelly Henckel, PM for GitHub Spaces, said in our GitHub Checkout episode, “Spaces make it easy to organize and share context, so Copilot acts like a subject matter expert.” The result? Fewer wrong guesses, less copy-pasting, and code that’s commit-ready.What exactly  a Copilot Space?Think of a space as a secure, shareable  plus :Code files, entire folders, Markdown docs, transcripts, or any plain text you addGives Copilot the ground truth for answersShort system prompts to set tone, coding style, or reviewer expectationsLets Copilot match your house rulesFollows the same role/visibility model you already use on GitHubNo new access control lists to manageFiles stay in sync with the branch you referencedYour space stays up to date with your codebaseSpaces are available to anyone with a Copilot license (Free, Individual, Business, or Enterprise) while the feature is in public preview. Admins can enable it under Settings  > Copilot > Preview features.: A space is like pinning your team’s  to the Copilot sidebar and letting everyone query it in plain language.Quick-start guide: How to build your first space in 5 minutes. For example, . so teammates know when——to use it.From repos: Pull in folders like  or individual files such as .Free‑text hack: Paste a Slack thread, video transcript, onboarding checklist, or even a JSON schema into the  tab. Copilot treats it like any other attachment.Write custom instructions. A sentence or two is enough:“Respond as a senior React reviewer. Enforce our ESLint rules and tailwind class naming conventions.”. You’re done. Ask Copilot a question in the Space chat—e.g., “Refactor this  component to match our accessibility checklist”—and watch it cite files you just attached.Personalize Copilot’s coding style (and voice, too) Custom instructions are the “personality layer” of a space and where spaces shine because they live  the attachments. This allows you to do powerful things with a single sentence, including: “Always prefer Vue 3  syntax and Composition API for examples.”“Answer concisely. Include a one‑line summary before code blocks.”Teach Copilot project‑specific vocabulary “Call it ‘scenario ID’ (SCID), not test case ID.”During the GitHub Checkout interview, Kelly shared how she built a personal space for a nonprofit side project: She attached only the Vue front‑end folder  instructions on her preferred conventions, and Copilot delivered commit‑ready code snippets that matched her style guide on the first try.Automate your workflow: three real‑world recipesMarkdown docs on WCAG criteria and GitHub’s internal “Definition of Done”Custom instruction: “When answering, cite the doc section and provide a code diff if changes are required.”: Instead of pinging the accessibility lead on Slack, you can use Spaces to ask questions like “What steps are needed for MAS‑C compliance on this new modal?” Copilot summarizes the relevant checkpoints, references the doc anchor, and even suggests ARIA attributes or color‑contrast fixes. GitHub’s own accessibility SME, Katherine, pinned this space in Slack so anyone filing a review gets instant, self‑service guidance.YAML schema files for 40+ event tablesExample KQL snippets saved as  filesInstruction: “Generate KQL only, no prose explanations unless asked.”Product managers and support engineers who  know your database structures can ask, “Average PR review time last 7 days?” Copilot autocompletes a valid KQL query with correct joins and lets them iterate. Result: lets PMs and support self-serve without bugging data science teams.3. Onboarding Hub and knowledge base in one linkKey architecture diagrams exported as SVG textADRs and design docs from multiple reposCustom instruction: “Answer like a mentor during onboarding; link to deeper docs.”New hires type “How does our auth flow handle SAML?” and get a structured answer with links and diagrams, all without leaving GitHub. Because spaces stay in sync with , updates to ADRs propagate automatically—no stale wikis.Collaboration that feels native to GitHubSpaces respect the same permission model you already use:: visible only to you unless sharedOrganization‑owned spaces: use repo or team permissions to gate accessRead‑only vs. edit‑capable: let SMEs maintain the canon while everyone else consumesSharing is as simple as sending the space URL or pinning it to a repo README. Anyone with access and a Copilot license can start chatting instantly.What’s next for Copilot Spaces?We’re working to bring Copilot Spaces to more of your workflows, and are currently developing:Issues and PR attachments to bring inline discussions and review notes into the same context bundle.: Query Spaces in VS Code for tasks like writing tests to match your team’s patterns. to help you browse spaces like you browse repos today, so new engineers can search “Payments SME” and start chatting.Head to github.com/copilot/spaces, spin up your first space, and let us know how it streamlines your workflow. Here’s how to get it fully set up on your end: : Settings > Copilot  >  Preview features > Enable Copilot Spaces.Create one small, high‑impact space—maybe your team’s code‑review checklist or a set of common data queries. in Slack or a README and watch the pings to subject‑matter experts drop.: prune unused attachments, refine instructions, or split a giant space into smaller ones.Copilot Spaces is free during the public preview and doesn’t count against your Copilot seat entitlements when you use the base model. We can’t wait to see what you build when Copilot has the  context at its fingertips.]]></content:encoded></item><item><title>Python 3.14.0 beta 3 is here!</title><link>https://pythoninsider.blogspot.com/2025/06/python-3140-beta-3-is-here.html</link><author>Hugo</author><category>dev</category><category>official</category><category>python</category><pubDate>Tue, 17 Jun 2025 18:43:00 +0000</pubDate><source url="https://pythoninsider.blogspot.com/">Python official news</source><content:encoded><![CDATA[This is a beta preview of Python 3.14Python 3.14 is still in development. This release, 3.14.0b3, is the
third of four planned beta releases.Beta release previews are intended to give the wider community the
opportunity to test new features and bug fixes and to prepare their
projects to support the new feature release.We  maintainers of
third-party Python projects to 
during the beta phase and report issues found to the Python bug
tracker as soon as possible. While the release is planned to be
feature-complete entering the beta phase, it is possible that features
may be modified or, in rare cases, deleted up until the start of the
release candidate phase (Tuesday 2025-07-22). Our goal is to have
 after beta 4 and as few code
changes as possible after the first release candidate. To achieve that,
it will be  to get as much
exposure for 3.14 as possible during the beta phase.This includes creating pre-release wheels for 3.14, as it helps other
projects to do their own testing. However, we recommend that your
regular production releases wait until 3.14.0rc1, to avoid the risk of
ABI breaks.Please keep in mind that this is a preview release and its use is
 recommended for production
environments.Some of the major new features and changes in Python 3.14 are:Note that PEPs 734
and 779
are exceptionally new in beta 3!(Hey,  if a feature you
find important is missing from this list, let Hugo know.)For more details on the changes to Python 3.14, see What’s new in
Python 3.14. The next pre-release of Python 3.14 will be the final
beta, 3.14.0b4, scheduled for 2025-07-08.PEP
761: Python 3.14 and onwards no longer provides PGP signatures for
release artifacts. Instead, Sigstore is recommended for verifiers.The installer we offer for Windows is being replaced by our new
install manager, which can be installed from the Windows
Store or our
FTP page. See our
documentation for more information. The JSON file available for
download below contains the list of all the installable packages
available as part of this release, including file URLs and hashes, but
is not required to install the latest release. The traditional installer
will remain available throughout the 3.14 and 3.15 releases.Thanks to all of the many volunteers who help make Python Development
and these releases possible! Please consider supporting our efforts by
volunteering yourself or through organisation contributions to the Python Software
Foundation.Regards from sunny Helsinki with 19 hours of daylight,Your release team, 
  Hugo van Kemenade
  Steve Dower
  ]]></content:encoded></item><item><title>5 tips for using GitHub Copilot with issues to boost your productivity</title><link>https://github.blog/ai-and-ml/github-copilot/5-tips-for-using-github-copilot-with-issues-to-boost-your-productivity/</link><author>Klint Finley</author><category>official</category><pubDate>Tue, 17 Jun 2025 16:00:00 +0000</pubDate><source url="https://github.blog/">Github Blog</source><content:encoded><![CDATA[Managing issues in software development can be tedious and time-consuming. But what if your AI peer programmer could streamline this process for you? GitHub Copilot‘s latest issue management features can help developers create, organize, and even solve issues. Below, we’ll dig into these features and how they can save time, reduce friction, and maintain consistency across your projects.1. Image to issue: Turn screenshots into instant bug reportsWriting detailed bug reports is often repetitive and frustrating, leading to inconsistent documentation. Copilot’s image to issue feature significantly reduces this friction.Simply paste a screenshot of the bug into Copilot chat with a brief description prompt Copilot to create an issue for you, then Copilot will analyze the image and generate a comprehensive bug report for you. No more struggling to describe visual glitches or UI problems—the image will speak for itself, and Copilot will handle the documentation.For example, if you encounter a UI alignment issue or a visual glitch that’s hard to describe, just capture a screenshot, paste it into Copilot, and briefly mention the problem. In the animation above, the user’s prompt was “create me a bug issue because markdown tables are not rendering properly in the comments.” Copilot then automatically drafted a report, including steps to reproduce the bug.To get the most out of this feature, consider annotating your screenshots clearly—highlighting or circling the problematic area—to help Copilot generate even more precise issue descriptions.Projects quickly become disorganized when team members skip adding proper metadata. Incorrect templates, missing labels, or wrong issue types make tracking and prioritization difficult.Copilot solves this by automatically inferring the best template based on your prompt. It also adds appropriate labels and issue types without requiring you to navigate multiple dropdown menus or memorize tagging conventions.Need something specific? Simply ask Copilot to add particular labels or switch templates. If you change templates after drafting, Copilot will automatically reformat your content—no manual copying required.3. Stay organized with versioning and milestonesKeeping issues updated and properly categorized is crucial for clear communication, maintaining project velocity, and ensuring visibility into progress. But with so much else to do, it’s easy to let this work fall by the wayside.With Copilot, adding projects and milestones is as simple as typing a prompt. You can also specify exactly how you want issues organized. For example, ask Copilot to use the “Bug Report” or “Feature Request” template, add labels like , , or , or set the issue type to “Task” or “Epic.” Copilot will apply these details automatically, ensuring your issues are consistently categorized.Additionally, Copilot tracks all changes, making them easily referenceable. You can review issue history and revert changes if needed, ensuring nothing important gets lost.4. Batch create multiple issues at onceSometimes you need to log several issues after a customer meeting, user testing session, or bug bash. Traditionally, this means repeating the same creation process multiple times.Copilot supports multi-issue drafting, allowing you to create multiple issues in a single conversation. Whether logging feature requests or documenting bugs, batch creation saves significant time.Simply prompt Copilot to create the issues, describe each one, and Copilot will draft them all. For example, you could give the following prompt to create two issues at once:Create me issues for the following features:
- Line breaks ignored in rendered Markdown despite double-space
- Bold and italic Markdown styles not applied when combinedYou will still need to review and finalize each one, but the drafting process is streamlined into a single workflow.5. Let AI help fix your bugs with Copilot coding agentCreating issues is only half the battle—fixing them is where the real work begins. You can now assign issues directly to Copilot. Just ask Copilot coding agent to take ownership of the issue, and your AI coding assistant will start analyzing the bug. Copilot can even suggest draft pull requests with potential fixes.This seamless handoff reduces context-switching and accelerates resolution times, allowing your team to focus on more complex challenges.Beyond Copilot: Issues enhancements on GitHubWhile Copilot is already revolutionizing issue management, we at GitHub are always looking for ways to enhance the overall issues experience. For example, you can now:Standardize issue types across repositories for consistent tracking and reporting.Break down complex tasks into sub-issues for better progress management.Use advanced search capabilities with logical operators to quickly find exactly what you need.Manage larger projects with expanded limits supporting up to 50,000 items.Kickstart enhanced issue management todayReady to transform your issue management workflow with GitHub Copilot? Head to github.com/copilot and try prompts like:“Create me an issue for…”Or simply upload a screenshot and mention you want to file a bug.Experience firsthand how Copilot makes issue management feel less like administrative overhead and more like a conversation with your AI pair programmer.]]></content:encoded></item><item><title>Python 201 – All About the TypedDict</title><link>https://www.blog.pythonlibrary.org/2025/06/17/python-201-all-about-the-typeddict/</link><author>Mike</author><category>dev</category><category>official</category><category>python</category><pubDate>Tue, 17 Jun 2025 13:25:53 +0000</pubDate><source url="https://www.blog.pythonlibrary.org/">Python Blog</source><content:encoded><![CDATA[Python has supported the concept of type hinting for quite a while now. However, unlike other programming languages, Python does not enforce type hints. You must use an external tool, such as Mypy, for that.In this tutorial, you will learn all about , a special way of adding type hinting to Heterogeneous dictionaries. A heterogeneous dictionary is a dictionary that has values that are not all the same type.But before you learn how to use the TypedDict, you should review how to type hint a regular dictionary.Type Hinting a Regular DictionaryA regular Python dictionary is defined as follows:my_dictionary = {"some_key": "some_value"}You can use any hashable type for the key, such as a string or an integer. The value of a dictionary can be any type whatsoever.When you want to type hint a dictionary, you would use the following: dict[key_type, value_type]Now let’s apply that to the example above:my_dictionary: dict[str, str] = {"some_key": "some_value"}If you are using a version of Python before 3.9, you will need to do the following instead:from typing import Dict

my_dictionary: Dict[str, str] = {"some_key": "some_value"}Fortunately, modern Python no longer requires that extra import.Now you’re ready to learn about how and why you might want to use the TypedDictThe TypedDict was introduced to Python in 3.8. You can read the full details about it in PEP 589. The reason you would use a TypedDict over a regular dictionary is when you have a dictionary with values of different types.my_dictionary = {"names": ["Mike", "Andrea", "John"],
                 "type": "employee",
                 "code": 123456
                }Type hinting this type of dictionary is more complex. You can do something like this, though:my_dictionary: dict[str, list | str | int] = {"names": ["Mike", "Andrea", "John"], "otype": "employee", "code": 123456 }Depending on how your type checker is configured, this might work. However, if you write code that modifies the list, your type checker may complain that a string doesn’t have an append method or vice versa.To make the type checker happier, you should use a .Here’s how you would use one with this example:from typing import TypedDict

class MultiTypeDict(TypedDict):
    names: list
    otype: str
    code: int

my_dictionary: MultiTypeDict = {"names": ["Mike", "Andrea", "John"], "otype": "employee", "code": 123456 }Isn’t that great? There’s just one problem. What if your dictionary’s keys have spaces in them? You cannot create class attributes with spaces!There’s a workaround for that. Check it out in the next section.Creating a TypedDict with Keys that Have SpacesFor this example, you will create a new dictionary with four keys, three of which contain spaces.To make a TypedDict for this type of dictionary, you need to call the TypedDict constructor instead of subclassing it:from typing import TypedDict

Results = TypedDict("Results",{"Animal Habitats": list,
                               "Tested": bool,
                               "Animal Name": str,
                               "Animal Location": str})

actual_results: Results = {
    "Animal Habitats": ["Asia", "N. America"],
    "Tested": False,
    "Animal Name": "Tigris",
    "Animal Location": "North Bay",
}When you call TypedDict, you pass in the typename (what you would have named the class) and the fields the dictionary should have. You’ll note that the fields are a dictionary. This is where you will put the keys that contain spaces and those without spaces.Give it a try and you’ll find it works great! is a handy tool for storing a complex dictionary. You will find that sometimes you even have these complex dictionaries inside of lists, tuples or even other dictionaries. Using the TypedDict can make type-hinting these data structures easier and prevent hard-to-detect defects from creeping in.]]></content:encoded></item><item><title>Highlights from Git 2.50</title><link>https://github.blog/open-source/git/highlights-from-git-2-50/</link><author>Taylor Blau</author><category>official</category><pubDate>Mon, 16 Jun 2025 17:12:27 +0000</pubDate><source url="https://github.blog/">Github Blog</source><content:encoded><![CDATA[The open source Git project just released Git 2.50 with features and bug fixes from 98 contributors, 35 of them new. We last caught up with you on the latest in Git back when 2.49 was released.💡 Before we get into the details of this latest release, we wanted to remind you that Git Merge, the conference for Git users and developers is back this year on September 29-30, in San Francisco. Git Merge will feature talks from developers working on Git, and in the Git ecosystem. Tickets are on sale now; check out the website to learn more.With that out of the way, let’s take a look at some of the most interesting features and changes from Git 2.50.Improvements for multiple cruft packsWhen we covered Git 2.43, we talked about newly added support for multiple cruft packs. Git 2.50 improves on that with better command-line ergonomics, and some important bugfixes. In case you’re new to the series, need a refresher, or aren’t familiar with cruft packs, here’s a brief overview:Git objects may be either reachable or unreachable. The set of reachable objects is everything you can walk to starting from one of your repository’s references: traversing from commits to their parent(s), trees to their sub-tree(s), and so on. Any object that you didn’t visit by repeating that process over all of your references is unreachable.In Git 2.37, Git introduced cruft packs, a new way to store your repository’s unreachable objects. A cruft pack looks like an ordinary packfile with the addition of an  file, which is used to keep track of when each object was most recently written in order to determine when it is safe to discard it.However, updating the cruft pack could be cumbersome–particularly in repositories with many unreachable objects–since a repository’s cruft pack must be rewritten in order to add new objects. Git 2.43 began to address this through a new command-line option: git repack --max-cruft-size. This option was designed to split unreachable objects across multiple packs, each no larger than the value specified by . But there were a couple of problems:If you’re familiar with ’s  option, ’s behavior is quite confusing. The former option specifies the maximum size an individual pack can be, while the latter involves how and when to move objects between multiple packs.The feature was broken to begin with! Since  imposes on cruft packs the same pack-size constraints as  does on non-cruft packs, it is often impossible to get the behavior you want.For example, suppose you had two 100 MiB cruft packs and ran git repack --max-cruft-size=200M. You might expect Git to merge them into a single 200 MiB pack. But since  also dictates the maximum size of the output pack, Git will refuse to combine them, or worse: rewrite the same pack repeatedly.Git 2.50 addresses both of these issues with a new option: --combine-cruft-below-size. Instead of specifying the maximum size of the output pack, it determines which existing cruft pack(s) are eligible to be combined. This is particularly helpful for repositories that have accumulated many unreachable objects spread across multiple cruft packs. With this new option, you can gradually reduce the number of cruft packs in your repository over time by combining existing ones together.With the introduction of --combine-cruft-below-size, Git 2.50 repurposed  to behave as a cruft pack-specific override for . Now  only determines the size of the outgoing pack, not which packs get combined into it.Along the way, a bug was uncovered that prevented objects stored in multiple cruft packs from being “freshened” in certain circumstances. In other words, some unreachable objects don’t have their modification times updated when they are rewritten, leading to them being removed from the repository earlier than they otherwise would have been. Git 2.50 squashes this bug, meaning that you can now efficiently manage multiple cruft packs and freshen their objects to your heart’s content.Incremental multi-pack reachability bitmapsMulti-pack indexes are extremely useful to accelerate object lookup performance in large repositories by binary searching through a single index containing most of your repository’s contents, rather than repeatedly searching through each individual packfile. But multi-pack indexes aren’t just useful for accelerating object lookups. They’re also the basis for multi-pack reachability bitmaps, the MIDX-specific analogue of classic single-pack reachability bitmaps. If neither of those are familiar to you, don’t worry; here’s a brief refresher. Single-pack reachability bitmaps store a collection of bitmaps corresponding to a selection of commits. Each bit position in a pack bitmap refers to one object in that pack. In each individual commit’s bitmap, the set bits correspond to objects that are reachable from that commit, and the unset bits represent those that are not.Multi-pack bitmaps were introduced to take advantage of the substantial performance increase afforded to us by reachability bitmaps. Instead of having bitmaps whose bit positions correspond to the set of objects in a single pack, a multi-pack bitmap’s bit positions correspond to the set of objects in a multi-pack index, which may include objects from arbitrarily many individual packs. If you’re curious to learn more about how multi-pack bitmaps work, you can read our earlier post Scaling monorepo maintenance.However, like cruft packs above, multi-pack indexes can be cumbersome to update as your repository grows larger, since each update requires rewriting the entire multi-pack index and its corresponding bitmap, regardless of how many objects or packs are being added. In Git 2.47, the file format for multi-pack indexes became incremental, allowing multiple multi-pack index layers to be layered on top of one another forming a chain of MIDXs. This made it much easier to add objects to your repository’s MIDX, but the incremental MIDX format at the time did not yet have support for multi-pack bitmaps.Git 2.50 brings support for the multi-pack reachability format to incremental MIDX chains, with each MIDX layer having its own  file. These bitmap layers can be used in conjunction with one another to provide reachability information about selected commits at any layer of the MIDX chain. In effect, this allows extremely large repositories to quickly and efficiently add new reachability bitmaps as new commits are pushed to the repository, regardless of how large the repository is.This feature is still considered highly experimental, and support for repacking objects into incremental multi-pack indexes and bitmaps is still fairly bare-bones. This is an active area of development, so we’ll make sure to cover any notable developments to incremental multi-pack reachability bitmaps in this series in the future.The  merge engine replaces This release also saw some exciting updates related to merging. Way back when Git 2.33 was released, we talked about a new merge engine called “ORT” (standing for “Ostensibly Recursive’s Twin”).ORT is a from-scratch rewrite of Git’s old merging engine, called “recursive.” ORT is significantly faster, more maintainable, and has many new features that were difficult to implement on top of its predecessor.One of those features is the ability for Git to determine whether or not two things are mergeable without actually persisting any new objects necessary to construct the merge in the repository. Previously, the only way to tell whether two things are mergeable was to run git merge-tree --write-tree on them. That works, but in this example  wrote any new objects generated by the merge into the repository. Over time, these can accumulate and cause performance issues. In Git 2.50, you can make the same determination without writing any new objects by using ’s new  mode and relying on its exit code.Most excitingly in this release is that ORT has entirely superseded recursive, and recursive is no longer part of Git’s source code. When ORT was first introduced, it was only accessible through ’s  option to select a strategy. In Git 2.34, ORT became the default choice over , though the latter was still available in case there were bugs or behavior differences between the two. Now, 16 versions and two and a half years later, recursive has been completely removed from Git, with its author, Elijah Newren, writing:As a wise man once told me, “Deleted code is debugged code!”As of Git 2.50, recursive has been completely  deleted. For more about ORT’s internals and its development, check out this five part series from Elijah here, here, here, here, and here.If you’ve ever scripted around your repository’s objects, you are likely familiar with , Git’s purpose-built tool to list objects and print their contents.  has many modes, like  (for printing out the contents of objects), or  (for printing out certain information about objects without printing their contents).Oftentimes it is useful to dump the set of all objects of a certain type in your repository. For commits,  can easily enumerate a set of commits. But what about, say, trees? In the past, to filter down to just the tree objects from a list of objects, you might have written something like:$ git cat-file --batch-check='%(objecttype) %(objectname)' \    --buffer <in | perl -ne 'print "$1\n" if /^tree ([0-9a-f]+)/'Git 2.50 brings Git’s object filtering mechanism used in partial clones to , so the above can be rewritten a little more concisely like:$ git cat-file --batch-check='%(objectname)' --filter='object:type=tree' <inWhile we’re on the topic, let’s discuss a little-known  command-line option: . This arcane option was used with objects that have a type other than , , , or . This is a quirk dating back a little more than a decade ago that allows  to write objects with arbitrary types. In the time since, this feature has gotten very little use. In fact, git cat-file -p --allow-unknown-type can’t even print out the contents of one of these objects!

$ oid="$(git hash-object -w -t notatype --literally /dev/null)"
$ git cat-file -p $oid
fatal: invalid object type
This release makes the  option silently do nothing, and removes support from git hash-object to write objects with unknown types in the first place.The  command learned a number of new tricks this release as well. It can now perform a few new different kinds of tasks, like , , and .  mirrors ’s functionality to remove stale or broken Git worktrees.  also mirrors existing functionality exposed via  to expire old  entries from previously recorded merge conflict resolutions. Finally,  can be used to remove stale unreachable objects from out of the reflog. also ships with new configuration for the existing  task. This task removes lingering loose objects that have since been packed away, and then makes new pack(s) for any loose objects that remain. The size of those packs was previously fixed at a maximum of 50,000, and can now be configured by the maintenance.loose-objects.batchSize configuration.If you’ve ever needed to recover some work you lost, you may be familiar with Git’s reflog feature, which allows you to track changes to a reference over time. For example, you can go back and revisit earlier versions of your repository’s main branch by doing  (to show  prior to the two most recent updates) or  (to show where your copy of the branch was at a week ago).Reflog entries can accumulate over time, and you can reach for  in the event you need to clean them up. But how do you delete the entirety of a branch’s reflog? If you’re not yet running Git 2.50 and thought “surely it’s ”, you’d be wrong! Prior to Git 2.50, the only way to delete a branch’s entire reflog was to do git reflog expire $BRANCH --expire=all.In Git 2.50, a new  sub-command was introduced, so you can accomplish the same as above with the much more natural git reflog delete $BRANCH.Speaking of references, Git 2.50 also received some attention to how references are processed and used throughout its codebase. When using the low-level  command, Git used to spend time checking whether or not the proposed refname could also be a valid object ID, making its lookups ambiguous. Since  is such a low-level command, this check is no longer done, delivering some performance benefits to higher-level commands that rely on  for their functionality.Git 2.50 also learned how to cache whether or not any prefix of a proposed reference name already exists (for example, you can’t create a reference  if either  or  already exists).Finally, in order to make those checks, Git used to create a new reference iterator for each individual prefix. Git 2.50’s reference backends learned how to “seek” existing iterators, saving time by being able to reuse the same iterator when checking each possible prefix.If you’ve ever had to tinker with Git’s low-level curl configuration, you may be familiar with Git’s configuration options for tuning HTTP connections, like  and  which are used to terminate an HTTP connection that is transferring data too slowly.These options can be useful when fine-tuning Git to work in complex networking environments. But what if you want to tweak Git’s TCP Keepalive behavior? This can be useful to control when and how often to send keepalive probes, as well as how many to send, before terminating a connection that hasn’t sent data recently.Prior to Git 2.50, this wasn’t possible, but this version introduces three new configuration options: , , and  which can be used to control the fine-grained behavior of curl’s TCP probing (provided your operating system supports it).Git is famously portable and runs on a wide variety of operating systems and environments with very few dependencies. Over the years, various parts of Git have been written in Perl, including some commands like the original implementation of  . These days, very few remaining Git commands are written in Perl.This version reduces Git’s usage of Perl by removing it as a dependency of the test suite and documentation toolchain. Many Perl one-liners from Git’s test suite were rewritten to use other Shell functions or builtins, and some were rewritten as tiny C programs. For the handful of remaining hard dependencies on Perl, those tests will be skipped on systems that don’t have a working Perl.This release also shipped a minor cosmetic update to . When starting a rebase, your  might appear with contents that look something like:
pick c108101daa foo
pick d2a0730acf bar
pick e5291f9231 baz
You can edit that list to , , or  (among many others), and Git will happily execute your rebase. But if you change the commit message in your rebase’s TODO script, they won’t actually change!That’s because the commit messages shown in the TODO script are just meant to help you identify which commits you’re rebasing. (If you want to rewrite any commit messages along the way, you can use the  command instead). To clarify that these messages are cosmetic, Git will now prefix them with a  comment character like so:
pick c108101daa # foo
pick d2a0730acf # bar
pick e5291f9231 # baz
Long time readers of this series will recall our coverage of Git’s feature (when Git added support for partial bundles), though we haven’t covered Git’s feature. Git bundles are a way to package your repositories contents: both its objects and the references that point at them into a single  file.While Git has had support for bundles since as early as v1.5.1 (nearly 18 years ago!), its  feature is much newer. In short, the  feature allows a server to serve part of a clone by first directing the client to download a  file. After the client does so, it will try to perform a fill-in fetch to gather any missing data advertised by the server but not part of the bundle.To speed up this fill-in fetch, your Git client will advertise any references that it picked up from the  itself. But in previous versions of Git, this could sometimes result in  clones overall! That’s because up until Git 2.50, Git would only advertise the branches in  when asking the server to send the remaining set of objects.Git 2.50 now includes advertises all references it knows about from the  when doing a fill-in fetch on the server, making -enabled clones much faster.For more details about these changes, you can check out this blog post from Scott Chacon.Last but not least,  (and ) now work much more smoothly in sparse checkouts by no longer having to expand the sparse index. This follows in a long line of work that has been gradually adding sparse-index compatibility to Git commands that interact with the index.Now you can interactively stage parts of your changes before committing in a sparse checkout without having to wait for Git to populate the sparsified parts of your repository’s index. Give it a whirl on your local sparse checkout today!]]></content:encoded></item><item><title>Rust compiler performance survey 2025</title><link>https://blog.rust-lang.org/2025/06/16/rust-compiler-performance-survey-2025/</link><author>Jakub Beránek</author><category>dev</category><category>official</category><category>rust</category><pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate><source url="https://blog.rust-lang.org/">Rust Blog</source><content:encoded><![CDATA[Long compile times of Rust code are frequently being cited as one of the biggest challenges limiting the productivity of Rust developers. Rust compiler contributors are of course aware of that, and they are continuously working to improve the situation, by finding new ways of speeding up the compiler, triaging performance regressions and measuring our long-term performance improvements. Recently, we also made progress on some large changes that have been in the making for a long time, which could significantly improve compiler performance by default.When we talk about compilation performance, it is important to note that it is not always so simple as determining how long does it take  to compile a crate. There are many diverse development workflows that might have competing trade-offs, and that can be bottlenecked by various factors, such as the integration of the compiler with the used build system.In order to better understand these workflows, we have prepared a Rust Compiler Performance Survey. This survey is focused specifically on compilation performance, which allows us to get more detailed data than what we usually get from the annual State of Rust survey. The data from this survey will help us find areas where we should focus our efforts on improving the productivity of Rust developers.You can fill out the survey here.Filling the survey should take you approximately 10 minutes, and the survey is fully anonymous. We will accept submissions until Monday, July 7th, 2025. After the survey ends, we will evaluate the results and post key insights on this blog.We invite you to fill the survey, as your responses will help us improve Rust compilation performance. Thank you!]]></content:encoded></item><item><title>Changes to Kubernetes Slack</title><link>https://kubernetes.io/blog/2025/06/16/changes-to-kubernetes-slack/</link><author></author><category>official</category><category>k8s</category><category>devops</category><pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate><source url="https://kubernetes.io/">Kubernetes Blog</source><content:encoded><![CDATA[: We’ve received notice from Salesforce that our Slack workspace  on June 20th. Stand by for more details, but for now, there is no urgency to back up private channels or direct messages.. Sometime later this year, our community may move to a new platform. If you are responsible for a channel or private channel, or a member of a User Group, you will need to take some actions as soon as you can.For the last decade, Slack has supported our project with a free customized enterprise account. They have let us know that they can no longer do so, particularly since our Slack is one of the largest and more active ones on the platform. As such, they will be downgrading it to a standard free Slack while we decide on, and implement, other options.On Friday, June 20, we will be subject to the feature limitations of free Slack. The primary ones which will affect us will be only retaining 90 days of history, and having to disable several apps and workflows which we are currently using. The Slack Admin team will do their best to manage these limitations.Responsible channel owners, members of private channels, and members of User Groups should take some actions to prepare for the upgrade and preserve information as soon as possible.The CNCF Projects Staff have proposed that our community look at migrating to Discord. Because of existing issues where we have been pushing the limits of Slack, they have already explored what a Kubernetes Discord would look like. Discord would allow us to implement new tools and integrations which would help the community, such as GitHub group membership synchronization. The Steering Committee will discuss and decide on our future platform.]]></content:encoded></item></channel></rss>