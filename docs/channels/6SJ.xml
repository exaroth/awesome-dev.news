<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Go</title><link>https://www.awesome-dev.news</link><description></description><item><title>Scaling multi-tenant Go applications: Choosing the right database partitioning approach</title><link>https://dev.to/abhirockzz/scaling-multi-tenant-go-applications-choosing-the-right-database-partitioning-approach-2amd</link><author>Abhishek Gupta</author><category>dev</category><category>go</category><category>devto</category><pubDate>Thu, 3 Jul 2025 13:01:29 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Multi-tenant applications face a fundamental challenge: how to efficiently store and query data for tenants of vastly different sizes? Consider the typical scenario where your platform serves both enterprise clients with hundreds of thousands of users, as well as small businesses with just a handful. With traditional database partitioning strategies you are likely to run into these common issues:: Large tenants create oversized partitions while small tenants waste allocated resources: High-activity tenants overwhelm individual database partitions, creating performance bottlenecks: User-specific lookups require scanning entire tenant datasets: Mixed workloads compete for the same database resourcesAzure Cosmos DB has been a go-to solution for multi-tenant applications due to its global distribution, automatic scaling, and flexible data models. Its partition-based architecture naturally aligns with tenant isolation requirements, making it attractive for SaaS platforms, IoT applications, and content management systems.However, even with these capabilities, the fundamental multi-tenant partitioning challenges persist. Let's examine how these issues manifest specifically in a Cosmos DB context.This blog post explores an approach to solving multi-tenant scaling challenges in Go applications using Azure Cosmos DB. You'll learn how to implement this using the Go SDK for Azure Cosmos DB, focusing on how to achieve efficient data distribution and query performance.
  
  
  Challenges with a multi-tenant SaaS solution
Imagine you're building a multi-tenant SaaS platform that manages user sessions and activities across different organizations using Cosmos DB. In such a setup, tenant variability is a significant challenge. Enterprise clients may have over 50,000 users generating millions of session events, while small businesses might only have 10 to 50 users with minimal activity. Mid-market companies typically fall in between, with 500 to 5,000 users and moderate usage. This wide range of tenant sizes and activity levels creates unique challenges for data partitioning and resource allocation in the database.This is how you might define your user session data model using a single partition key:This approach has several challenges. First, partition size imbalance occurs as enterprise tenants generate massive 20GB+ partitions, while small tenants use minimal storage, resulting in uneven resource utilization across physical partitions. Second, hot partition bottlenecks can develop when large tenants reach the 10,000 RU/s physical partition limit during peak usage periods. Third, user queries become inefficient because looking up individual user sessions requires scanning entire tenant partitions, which consumes unnecessary Request Units. Cross-tenant analytics also suffer, as queries spanning multiple tenants become expensive cross-partition operations.
  
  
  Hierarchical Partition Keys to the rescue
Hierarchical partition keys (HPKs) help implement subpartitioning that allows you to define up to three levels of partition key hierarchy. This leads to better data distribution and query routing compared to traditional single-level partitioning. Instead of forcing all tenant data into a single partition boundary, you are able to create logical subdivisions that align with your actual access patterns.Mapping this to the the multi-tenant solution challenges, hierarchical partition keys allow you to define a three-level partitioning scheme:: Primary partition key (e.g., ) - provides tenant isolation: Secondary partition key (e.g., ) - distributes data within tenants
: Tertiary partition key (e.g., ) - provides fine-grained distributionThis creates a logical partition path like instead of just . Large tenants can be subdivided by user and session, eliminating hot partitions. Instead of one massive "Enterprise-Corp" partition, you get manageable partitions like: ["Enterprise-Corp", "user-1001", "session-abc123"], ["Enterprise-Corp", "user-1002", "session-def456"], etc.Now, we can refactor the user session data model as such:Your queries can now be efficiently routed to only the subset of physical partitions that contain the relevant data. Specifying the full or partial subpartitioned partition key path effectively avoids a cross-partition query across all the parititions, which is a common problem with single partition keys.: WHERE tenantId = 'Enterprise-Corp' AND userId = 'user-1001' AND sessionId = 'session-abc123' provides single-partition access: WHERE tenantId = 'Enterprise-Corp' AND userId = 'user-1001' pinpoints exact data location: WHERE tenantId = 'Enterprise-Corp' only targets relevant partitionsEach logical partition (tenant-user-session combination) can scale independently, allowing tenant data to exceed the traditional 20GB limit and maintain optimal performance. Targeted queries consume fewer Request Units by avoiding unnecessary cross-partition scans, directly reducing operational expenses.
  
  
  Hierarchical Partition Keys in action with the Go SDK for Azure Cosmos DB
To explore the concepts, we will use a Go application that loads sample user session data into Azure Cosmos DB and queries it using the hierarchical partition keys.Run the loader to populate the database with sample data that uses hierarchical partition keys. Its a CLI application that generates user session data for users in different tenant types (Enterprise, Mid-market, Small business) and inserts it into the Cosmos DB container.Clone the repository and change into the  directory:git clone https://github.com/abhirockzz/cosmosdb-go-hierarchical-partition-keys
cosmosdb-go-hierarchical-partition-keys/load
Build the data loader application and run it. The database and container will be created automatically if they do not exist.go build  data-loader main.go

./data-loader  100  <insert database name>  <insert container name> Here is how the container is created with hierarchical partition keys:... and this is how sample data is added:Lets dive into the queries that demonstrate how to retrieve data using hierarchical partition keys.Let's examine how different query patterns perform with hierarchical partition keys. To execute these examples, you can comment out the relevant sections in the  function of the query/main.go file, set the required environment variables, and run the application.https://your-account.documents.azure.com:443/
<insert database name>
<insert container name>

cosmosdb-go-hierarchical-partition-keys/query
go run main.go

  
  
  1. Point Read (Most Efficient)
This is the most efficient query type, where you retrieve a single item using its unique ID and full partition key path. This avoids any cross-partition overhead.Take a look at the  function that performs a point read operation:This is routed to the single logical and physical partition that contains the data for the specified values of , , and .
  
  
  3. User-Specific Data (Targeted Cross-Partition)
This query is a targeted cross-partition query that returns data for a specific user in the tenant and routed to specific subset of logical and physical partition(s) that contain data for the specified values of  and .
  
  
  4. Tenant-Wide Data (Efficient Cross-Partition)
This query is a targeted cross-partition query that returns data for all users in a tenant and routed to a specific subset of logical and physical partition(s) that contain data for the specified value of .The queryWithSinglePKParameter is a function that lets you query with a single partition key parameter - this can be either , , or .
  
  
  5. User or Session Across All Tenants (Fan-Out)
Both types of queries will be routed to all physical partitions, resulting in a fan-out cross-partition query.This type of query is not efficient and should be avoided in production scenarios. It is included here for completeness, but you should design your application to avoid such queries whenever possible.Multi-tenant applications face inherent scaling challenges with traditional single-level partitioning: tenant size variability, hot partitions, and inefficient query patterns that impact both performance and cost. Hierarchical partition keys in Azure Cosmos DB address these issues by enabling intelligent data distribution across multiple partition levels, maintaining tenant isolation while achieving better resource utilization. By aligning your partition strategy with actual access patterns, you can build applications that scale naturally with tenant growth while maintaining predictable performance characteristics.]]></content:encoded></item><item><title>Domain Driven Design Microservice</title><link>https://dev.to/subpxl/domain-driven-design-microservice-pd4</link><author>shubham panchal</author><category>dev</category><category>go</category><category>devto</category><pubDate>Thu, 3 Jul 2025 10:38:33 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[What is Domain Driven Design
A microservice is a independent compoent of a
business logic. mostly is a breakdown of a
monolith application into individual componetns
that can scale and make the service fault tolerant
There are many advantages of microservces
and they cater to different business needs as per
design an architecture.
Event driven
with webworkerWhat is Domain Driven Design
Domain Drivern Design is a software design pattern that saperates businesss logic from language infrastruture and other technical components. it has businss logic domain at its core and all other things
that changes are wrapped like onion onto it.
It is important as the core business logic never changes but the outlying technologies changes but doesnot affect the business logic, It is like a port and adapter pattern where technologies like databases or message queues can be replaced easily without affecting anything.
The main business layer of the application that contains business models , methods, events and their working.
These are independent of any database or message queue or router and they mostly dont change.They have classes or structs that defines objects
or models and their methods and their interface signatures.
Application Layer is the layer that connects interface layer to the domain layer.Here there are many usecases of business present that may use more that one domain method for its working.Along with that it is responsible for authentication and transaction processing . sending notifications or
triggering events. when interface later recieves a resuqest it sends to
appropriate usecase method in application layer that may contain multiple domain methods and triggers events accordingly.
Interface layer is the outer layer from where the applicaiton is accessed.
It can be a cli , a rest api or a grpc endpoint. even all three in one application. This takes the appropriate input and sends to the application layer usecase for further processing and sends response back.
Infrastructure layer is where all interfaces are implemented concrete. It has all the technologies in it such as database, message queue, external apis and other relevent external things that are required by the
application. It should implements domain interface methods to work and this infra related technologies are injected into the repository
or other related objects in the main setup. This process is called wiring.]]></content:encoded></item><item><title>Smoke Alarm Batteries: Hogwarts’ Silent Protectors Against Fiendfyre &amp; Forgotten Spells</title><link>https://dev.to/ersajay/smoke-alarm-batteries-hogwarts-silent-protectors-against-fiendfyre-forgotten-spells-3iae</link><author>ersajay</author><category>dev</category><category>go</category><category>devto</category><pubDate>Thu, 3 Jul 2025 06:32:30 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[The Leaky Cauldron’s Safety Secret
On a rainy afternoon in Hogsmeade, I ducked into Zonko’s Joke Shop—not for Weasley’s Wizard Wheezes, but for a chat with Mr. Filch, the Hogwarts caretaker (and accidental safety guru).
“You’re here for the batteries, aren’t you?” he grumbled, polishing a Duster 3000. “Not as fun as Pygmy Puffs, but just as vital. Ever seen a smoke alarm fail? It’s worse than a Descendo charm gone wrong—chaos, and no one to blame but a lousy battery.”
Intrigued, I leaned in. This wasn’t just about magic—it was about smoke alarm batteries—the unsung heroes of wizarding (and muggle) safety. Let’s unmask their magic.What Powers Your Smoke Alarm? (Spells, or Just… Batteries?)
Smoke alarms rely on batteries that are more than metal and chemicals—they’re life-or-death spells in a case. Here’s the lineup:9V Lithium: A 10-year marvel, built to survive -40°C (Arctic attics) to +85°C (kitchen ceilings). Think of it as a Fidelius Charm for your home—secret, sturdy, and unbreakable.CR123A Lithium: Slim, coin-shaped cells for detectors like the First Alert SCO500. Imagine a Pocket Sneakoscope—small enough to fit anywhere, but never misses a threat.
Alkaline 9V: A $2 budget trap. They leak acid yearly, corroding circuits and causing 27% of alarm failures (NFPA 2024 report). Worse than a Dungbomb—smelly, messy, and best avoided.Key Insight: Lithium powers NASA lunar habitats; alkalines expire faster than Cauldron Cakes at a Quidditch match.Why Lithium Reigns Supreme (No, Not Just for Wizards)
Lithium batteries aren’t just “better”—they’re Hogwarts-level superior. Let’s break it down:Lifespan: Lithium lasts a decade with zero fuss—no midnight “chirp-chirp” curses. Alkalines? They die in a year, nagging you like a Boggart in your ceiling.
Leak Risk: Lithium’s laser-welded seal acts like a Protego charm, locking out acid forever. Alkalines? Their flimsy cases leak acid that eats circuits—like Evanesco for your alarm.
Temperature Toughness: Lithium thrives in extremes, from Arctic cold to kitchen heat. Alkalines? They crumble below 0°C, weaker than a Glacius charm in a snowstorm.Real-World Magic: 92% of EU smart homes use lithium. Alkalines? They’re relics of a bygone era—best left in the Room of Requirement (unseen, and forgotten).Changing Batteries: A Spellbook for Muggles & Wizards
Replacing a smoke alarm battery is like casting Reparo—simple, but precision matters. Here’s how:
For Kidde Models (e.g., KN-COSM-BA)Twist Off: Rotate the alarm counterclockwise, like unlocking a Gringotts vault. Detach it from the mount—no yanking, or you’ll trigger a Colloportus (stuck) situation.
Open Cover: Slide the battery compartment tab gently (no prying—force breaks it, like a Riddikulus charm gone wrong).
Replace: Insert a 9V lithium (Energizer L522, preferred). Match the +/- symbols—mix them up, and your alarm becomes a Pyrotechnics show (smoke, sparks, and regret).
Test: Hold the test button for 5 seconds. Silence = failure (call Dumbledore, or your local electrician). A loud beep? You’ve cast the Perfecto charm—well done.For First Alert (e.g., SA320CN)Locate Latch: Press the side release button, like whispering the Marauder’s Map’s secret phrase. The cover pops open, revealing the CR123A battery.
Swap CR123A: Remove the old cell, insert the new one (arrow up—polarity is very important, like mixing Veritaserum).
Reset: Press the test button twice. A double beep confirms success—cheer like you just caught the Golden Snitch.⚠️ Sealed Units (e.g., Kidde i12010S): No battery access! Replace the entire unit after 10 years (like retiring a Phoenix—sad, but necessary)."Battery-Free" Alarms: The Great Deception
Ever heard of a “battery-free” smoke alarm? It’s like a Bogey—a trick, not reality.Hardwired Alarms (e.g., First Alert SC9120B): ⚡ They’re plugged in, but still need a 9V lithium backup for outages (even magic needs a Portkey to safety).
Sealed 10-Year Models: 🔒 Tamper-proof? Yes. Battery-free? No. They’re just wizard-sealed—no user access, but still powered by lithium.Critical Truth: No alarm is truly battery-free. Alkaline backups void warranties (and your safety—don’t be a Gilderoy Lockhart).2025’s Top Batteries: Trusted by the Ministry of Magic
Not all batteries are created equal. Here’s the Ministry-approved list:9V Lithium: Stick to Panasonic CR-V3 or Energizer L522. They’re UL/CE/UN38.3 certified—approved by the Ministry of Magic (and NASA). Price: $6-$9.
CR123A: Duracell 123 or Panasonic CR123A. UL/CE certified—no Dark Arts here. Price: $4-$6.
USB-C 9V: Shui Mu Nian’s USB-C lithium (Amazon ASIN B0CZ2YJQJS). CE/UN38.3 certified—recharge like a Wand-Lighting Charm. Price: $2.45.No UN38.3 cert? Fire hazard (e.g., eBay “10 for $5” deals—Aguamenti won’t save you).
“Heavy-duty” labels? Alkaline in disguise (like Polyjuice Potion—deceptive, and dangerous).Global Innovations: Magic Meets Modern Safety
The future of smoke alarm batteries is pure wizardry:Smart Batteries: 🔌 Shui Mu Nian’s USB-C lithium (1,000 cycles). Recharge like your phone—no more Expelliarmus for dead alarms.
AI Integration: 📱 Alerts your phone before low battery (“Replace now, or sleep in smoke!”—Morsmordre vibes, but helpful).
Regulatory Revolutions: 🏛️ EU bans alkaline detectors by 2027; Japan mandates lithium in rentals (finally, common sense—Obliviate to alkalines).Beyond Homes: Where Batteries Rule the Wizarding World
Smoke alarm batteries aren’t just for kitchens. They’re everywhere—like Hogwarts’ ghosts:Hotels: Sealed lithium prevents 3 AM mass evacuations (no more Riddikulus for guests).
Industrial: CR123A survives chemical fumes & vibrations (like a Shield Charm for factories).
Space Tech: Panasonic CR123A powers fire detection in NASA moon bases (even Luna Lovegood would approve).Conclusion: The Unseen Protectors
Smoke alarm batteries aren’t flashy. They don’t cast Expecto Patronum or brew Felix Felicis. But they’re the reason your home stays safe, your hotel doesn’t burn, and moon bases don’t become Fiendfyre traps.
Next time you replace one, whisper, “Thanks, little hero.” It’s the least you can do for a battery that keeps the magic of life alive.Written by a witch who once ignored a chirping alarm. (Spoiler: It was an alkaline. Never again.)
🔋 Some magic isn’t in wands—it’s in the tools that keep the world from burning.]]></content:encoded></item><item><title>How to Use Worker: Secure Linux Process Execution Made Simple</title><link>https://dev.to/ehsaniara/how-to-use-worker-secure-job-execution-made-simple-559h</link><author>Jay Ehsaniara</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 20:57:38 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[This guide is designed for: setting up CI/CD pipelines with secure linux process execution building platforms that need to run user code safely looking for lightweight alternatives to Docker for process isolation creating internal developer tools and automationBasic Linux command-line experienceUnderstanding of processes, memory, and CPU conceptsFamiliarity with systemd services (helpful but not required)📚 What This Article Is NOT:A deep dive into Linux namespaces or cgroups internalsA comparison of container orchestration platformsA tutorial on building distributed systemsAn explanation of Worker's source code architectureWorker is a lightweight job isolation platform that lets you run commands and scripts in secure, resource-controlled
environments. Think of it as a simpler alternative to Docker for job execution - no containers needed, just a single using Linux namespaces for CPU, memory, and I/O and log streaming with authentication for easy interactionWhether you're building a CI/CD system, running user code safely, or need isolated task execution, Worker provides a
clean, production-ready solution.
  
  
  Why Use Worker? Before vs After Scenarios
Let's see how Worker transforms common development and operations challenges with real examples:
  
  
  🔍 System Call Isolation in Action❌ Without Worker: Direct Host Execution (Dangerous)ps aux
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root           1  0.0  0.3 167744 13132 ?        Ss   Jun26   0:11 /sbin/init
root           2  0.0  0.0      0     0 ?        S    Jun26   0:00 kthreadd]
systemd+     564  0.0  0.2  90096  5392 ?        Ss   Jun26   0:00 /lib/systemd/systemd-resolved
messagebus   565  0.0  0.1   8808  3840 ?        Ss   Jun26   0:02 /usr/bin/dbus-daemon 
worker      1234  0.1  0.5 123456 10240 ?        Sl   Jun26   1:23 /opt/worker/worker
postgres    2345  0.0  1.2 456789 25600 ?        S    Jun26   0:45 postgres: main process
mysql       3456  0.2  2.1 789012 43520 ?        Sl   Jun26   2:10 mysqld /var/lib/mysql
apache2     4567  0.0  0.8 234567 16384 ?        S    Jun26   0:30 /usr/sbin/apache2 
...
user        9999  0.0  0.0  10072  1608 pts/2    R+   17:37   0:00 ps aux
Process can see ALL system processes (including sensitive services)Has access to process details, PIDs, and resource usageCan potentially interact with or signal other processesNo isolation from host system resources✅ With Worker: Isolated Job Execution (Secure)worker-cli run ps aux
Job started:
ID: 120
Command: ps aux
Status: RUNNING
StartTime: 2025-01-15T17:34:33Z

worker-cli log 120   
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
0              1  0.0  0.0  10044  1580 ?        R    17:34   0:00 ps aux
Job sees ONLY its own process (PID 1 in isolated namespace)Cannot discover or interact with host processesComplete process isolation from host systemProtected from interference by other jobs
  
  
  🗂️ Filesystem Isolation Example❌ Without Worker (Host Access): /
bin   dev  home  lib64  mnt  proc  run   srv  tmp  var
boot  etc  lib   media  opt  root  sbin  sys  usr

 /etc/passwd  
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
✅ With Worker (Isolated Filesystem):worker-cli run  /
bin  lib  lib64  proc  sys  tmp  usr  work

worker-cli run  /etc/passwd
: /etc/passwd: No such file or directory

worker-cli run  /proc
1  cpuinfo  meminfo  mounts  version  : Each job gets its own  directory: Only essential directories are available: Each job has its own temporary space: Process information limited to the job's namespaceRead-only System Binaries: Access to , , etc. but cannot modify
  
  
  💾 Resource Protection Example❌ Without Worker (Unrestricted):python3 ✅ With Worker (Resource Protected):worker-cli run 512 python3 worker-cli log <job-id>
Allocated 1 MB
Allocated 2 MB
...
Allocated 500 MB
Allocated 512 MB
Killed  : Jobs cannot exceed allocated memory: Prevents CPU starvation of host system: Controls disk bandwidth usage: Restricts number of processes per job
  
  
  🏗️ 
npm 
python tests.py            
./build.sh                 
make integration-tests     
ps aux | pgrep Tests can crash the CI serverResource leaks between jobsNo job monitoring or log collectionSecurity risks from untrusted codeDifficult to enforce resource limitsManual process management
worker-cli run 512 100 npm worker-cli run 256 python tests.py  
worker-cli run 200 ./build.sh
worker-cli run 1024 make integration-tests


worker-cli list                 
worker-cli log <job-id>        
worker-cli stop <job-id>       ✅ Complete isolation prevents system crashes✅ Automatic resource cleanup✅ Real-time monitoring and logging✅ Failed jobs don't affect the system✅ Easy to track and debug build issues
  
  
  🎓 Online Code Execution PlatformUsers can access your filesystemInfinite loops can crash your serverNo resource limits (memory bombs)No way to safely kill runaway processesNo concurrent user support✅ Complete filesystem isolation✅ Resource limits prevent abuse✅ Automatic job termination✅ Real-time output streaming✅ Multiple users can run code simultaneously
  
  
  🔄 Data Processing Workflows
./process_batch1.py &

./process_batch2.py &  

./process_batch3.py &

ps aux | process_batch
top | python

pgrep Difficult to monitor progressNo way to limit resource usage
worker-cli run 1024 100 ./process_batch1.py
worker-cli run 1024 100 ./process_batch2.py  
worker-cli run 1024 100 ./process_batch3.py


worker-cli list                    
worker-cli log 1 & worker-cli log 2 & worker-cli log 3  ✅ Predictable resource usage✅ Easy progress monitoring
  
  
  Quick Start: Your First Job
Let's get Worker running in under 5 minutes.
wget https://github.com/ehsaniara/worker/releases/latest/download/worker_1.0.0_amd64.deb

dpkg  worker_1.0.0_amd64.deb

systemctl start worker
systemctl worker
That's it! Worker is now running as a system service with auto-generated SSL certificates.
worker-cli run Congratulations! You just ran your first isolated job.The  command is your main interface for job execution:
worker-cli run 
worker-cli run python3 
worker-cli run 50 256 stress-ng  1  30s


worker-cli run bash Resource Limits Explained: - CPU percentage (50 = 50% of one core) - Memory limit in MB - I/O operations per second limit
worker-cli list


worker-cli status 2

One of Worker's killer features is real-time log streaming:
worker-cli log 2

The log command automatically follows the output until the job completes or you press Ctrl+C.
worker-cli stop 2


  
  
  Example 1: Running a Data Processing Script
 process_data.py 
worker-cli run 128 python3 process_data.py &

worker-cli log 
  
  
  Example 2: Building a Project

worker-cli run 200 bash 
  
  
  Example 3: Testing with Network Access

worker-cli run curl  https://api.github.com/repos/ehsaniara/worker | jq 
worker-cli run python3  http.server 8080

  
  
  Configuration and Customization
Worker's behavior can be customized via configuration file at /opt/worker/config/config.yml:After changing configuration:systemctl restart worker
Point the CLI to a different server:
worker-cli  192.168.1.100:50051 run 192.168.1.100:50051
worker-cli run 
  
  
  Security and Authentication
Worker uses mutual TLS (mTLS) for security. Certificates are auto-generated during installation, but you can regenerate
them: /usr/local/bin/certs_gen.sh

Worker supports two roles via certificate organizational units:The role is determined by the  field in the client certificate.
  
  
  Monitoring and Troubleshooting
systemctl status worker

journalctl  worker systemctl show worker CPUUsageNSec,MemoryCurrent

worker status <job-id>
worker log <job-id>


worker list | 
watch  2 Issue: "Connection refused"systemctl status worker

netstat  | 50051

systemctl restart worker
Issue: "Certificate errors" /usr/local/bin/certs_gen.sh

 /opt/worker/certs/
Issue: "Job stuck in RUNNING"
worker-cli stop <job-id>


top
Worker provides a gRPC API for integration with other systems. Here's a simple Go client example:file .txt
    worker-cli run 128 python3 process_file.py  &
: Always set appropriate limits to prevent runaway jobs: Monitor system resources when running many parallel jobs: Long-running jobs can generate large logs - consider log rotation: Worker automatically cleans up completed jobs, but monitor disk space
  
  
  Comparison with Alternatives
: Report bugs and feature requests on GitHub: Always check sudo journalctl -u worker for service issues: Join discussions in the project's GitHub issuesWorker provides a clean, simple way to run isolated jobs without the complexity of container orchestration. Whether
you're processing data, running tests, or executing user code, Worker's combination of security, simplicity, and
real-time monitoring makes it an excellent choice for job execution.: One package, automatic configuration: Familiar command-line interface: Namespace isolation and mTLS authentication: Stream logs and monitor resource usageIntegration is straightforward: gRPC API for programmatic access]]></content:encoded></item><item><title>Hey you! Deploying the application can you hear me?</title><link>https://dev.to/pcmagas/hey-you-deploying-the-application-can-you-hear-me-57pk</link><author>Dimitrios Desyllas</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 19:32:13 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Hey you! Setting secrets upon  file via a CI/CD pipeline, can you hear me?Recently I am making a small utility tool named mkdotenv. Its goal simple: manipulate values upon .env files in a CI/CD pipeline. It is designed to run inside a pipeline during deployment and modify and set values upon  files.It is shipped in #fedora, #ubuntu, #linux, #windows and #mac. Available on Fedora #corpr, Ubuntu/Mint #ppa and #homebrew (for M-Series mac). Also, building from source is easy-peasy-lemon-sqeezy it just needs #go and #make and no other external dependencies.Please have a strong look as I develop it into a stable version.]]></content:encoded></item><item><title>A terminal UI for Apple Containers</title><link>https://dev.to/andreybleme/a-terminal-ui-for-apple-containers-2d4n</link><author>Lucas Bleme</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 16:22:27 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Apple finally released native support for containers, but it is missing a compatible GUI. I built lazycontainer, a terminal UI to make it easy to manage Apple containers. It is written in Go, and uses bubbletea🧋I have been trying the native apple containers on my Mac for the last weeks, and it looks .  Docker is one of the few things that makes my M1 feel slow, so I've been experimenting with replacing it with apple containers on my local environment for simple stuff like Postgres and Redis.It still has significant limitations in terms of networking and memory. It does not support routing traffic from container-managed applications to host applications. To workaround this, we need a port forwarding tool like  or  to establish a TCP connection between the host and the container and redirect the traffic. Not cool.socat TCP-LISTEN:8000,fork,bind=192.168.64.1 TCP:127.0.0.1:8000 There is no CLI support for managing volumes. Even though it allows running a container with a volume , we can't list or remove mounted volumes as we are used to doing with Docker. Same for networks.The first release also didn't come with support for compose. We are used to relying on docker_compose.yaml files to provision multiple containers, but that is not supported for now. This is one of the most requested features, and would definitely drive more adoption if added in the next release.It is great to see native containers come to Mac, but lima and colima already enable decent performance for containers running on Mac, and most importantly, being Docker compatible. It is hard to see this announcement as groundbreaking if they don't provide support for most things we are used to having in the Docker ecosystem.In the meantime, the open source community is hacking to make it compatible with Docker-like tools. Let me know what your thoughts are on it! Are you using it or planning to?]]></content:encoded></item><item><title>How OOP works in Golang</title><link>https://dev.to/hrrydgls/how-oop-works-in-golang-1o45</link><author>Harry Douglas</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 15:37:37 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[I'm quite beginner here in GO but I wanna share what I've learnt about it today! Lets start without losing time. If you are coming from another OOP friendly language, you already know what is a class. 
In Go we have the same thing but a bit different:This is the most basic class we have. Then we can add methods to it:The syntax seems a bit complicate to me as someone from PHP world but not too bad!Share your comments with me to feel that I am not alone here with this new stuff :)]]></content:encoded></item><item><title>Build a Local Image File Uploader from Scratch in Go</title><link>https://dev.to/vinitjpl/build-a-local-image-file-uploader-from-scratch-in-go-4caf</link><author>Vinit Jogi</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 12:53:24 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[🚀Getting Started with File Uploads in Go (for Beginners)Ever wondered how to build your own image uploader without relying on third-party services or complex libraries? In this tutorial, I’ll walk you through creating a simple, beginner-friendly local image file uploader using Go, HTML, CSS, and a bit of JavaScript. This project is perfect for developers just starting with Go who want to understand how file handling works behind the scenes. By the end, you'll have a fully functional uploader that stores images on your local filesystem — and a solid foundation to build more advanced features on top of it.Frontend: HTML, CSS and JS, To create a basic form for uploading files.Backend: Go (net/http), to handle file upload and server logic.Storage: Local filesystem, to save uploaded images in a local directory.Here's how the project is organized:file-uploader/
├── cmd/
│   └── file-uploader/
│       └── main.go              # Entry point of the application
├── internal/
│   ├── handlers/
│   │   └── upload.go            # Upload handler logic
│   ├── utilities/
│   │   └── utilities.go         # Utility/helper functions
│   └── web/
│       ├── index.html           # Frontend upload form
│       └── main.js              # Frontend JS logic (optional)
├── uploads/                     # Folder to store uploaded images
├── .gitignore                   # Git ignore rules
└── go.mod                       # Go module file
Alright, now that we’ve covered the basics — let’s roll up our sleeves and start building this image uploader step by step! 💪🛠️Step 1: 🧱Generating a go.mod file
First things first — open your favorite terminal, cd into your project directory, and run the following command to initialize a Go module:go mod init <your_module_name>
Replace  with the name or path you want for your project (e.g., github.com/yourusername/file-uploader or just go-file-uploader for local projects).This creates a go.mod file, which helps Go manage dependencies and track your module.Step 2: 🚀Building a file upload endpoint
Now let’s create a simple Go server that can handle file uploads and serve static files (like your HTML form and JavaScript).Here is what the  file inside  looks like:package main

import (
    "fmt"
    "go-file-uploader/internal/handlers"
    "log"
    "net/http"
)

func main() {
    http.HandleFunc("/upload", handlers.FileUploadHandler)

    // Serve static files (HTML, JS, CSS)
    fs := http.FileServer(http.Dir("internal/web"))
    http.Handle("/", fs)

    fmt.Println("Server running on port: 8080")
    log.Fatal(http.ListenAndServe(":8080", nil))
}

We define a  endpoint and link it to (which we'll define next).The root path  serves static frontend files from the  directory.The server runs on .Step 3: 📤Writing the File Upload LogicLet’s move on to the actual file upload handling. This logic lives in internal/handlers/upload.go.package handlers

import (
    "fmt"
    "go-file-uploader/internal/utilities"
    "io"
    "net/http"
    "strings"
)

// Validate the file type; currently only allowing image uploads
func isValidFileType(file []byte) bool {
    fileType := http.DetectContentType(file)
    return strings.HasPrefix(fileType, "image/")
}

func FileUploadHandler(w http.ResponseWriter, r *http.Request) {
    /*
        limiting the file size to 10 mb
        left shift operator. Shift the bits of 10, 20 times to the left
        effectively it is 10 * 2^20.
    */
    r.ParseMultipartForm(10 << 20)

    // Retrieve the uploaded file from the form

    file, handler, err := r.FormFile("myFile")

    if err != nil {
        http.Error(w, "Error retrieving the file", http.StatusBadRequest)
        return
    }

    defer file.Close()

    fileBytes, err := io.ReadAll(file)
    if err != nil {
        http.Error(w, "Invalid file", http.StatusBadRequest)
        return
    }

    if !isValidFileType(fileBytes) {
        http.Error(w, "Invalid file type", http.StatusUnsupportedMediaType)
        return
    }

    // Save the file locally to the uploads directory

    dst, err := utilities.CreateFile(handler.Filename)

    if err != nil {
        http.Error(w, "Error in saving the file", http.StatusInternalServerError)
        return
    }

    defer dst.Close()

    // Write the uploaded file bytes to the destination file

    if _, err := dst.Write(fileBytes); err != nil {
        http.Error(w, "Error saving the file", http.StatusInternalServerError)
    }

    fmt.Fprintf(w, "Uploaded file: %s\n", handler.Filename)
    fmt.Fprintf(w, "File Size: %.2f KB\n", float64(handler.Size)/(1024))
    // fmt.Fprintf(w, "MIME Header: %v\n", handler.Header)
    fmt.Fprintf(w, "File uploaded successfully: %s\n", handler.Filename)
}

We limit file size to 10MB using ParseMultipartForm(10 << 20).We retrieve the uploaded file via . Make sure the name "myFile" matches the name attribute of the input field in your HTML form — otherwise, Go won’t be able to read the file correctly.We read and validate the file type using Go's  (only allowing image types).We save the uploaded file using a utility function (), which we’ll define in the next step.Finally, we print out some details as a response after a successful upload.This approach is simple yet safe, ensuring only valid image files get saved on your system.Step 4: 🛠️Creating the CreateFile() Utility FunctionNow let’s define a utility function to save uploaded files inside a local  directory. This function lives in internal/utilities/utilities.go.package utilities

import (
    "os"
    "path/filepath"
)

func CreateFile(filename string) (*os.File, error) {
    // Create the uploads directory if it doesn't exist
    if _, err := os.Stat("uploads"); os.IsNotExist(err) {
        os.Mkdir("uploads", 0755)
    }

    // Build the full file path and create the file
    dst, err := os.Create(filepath.Join("uploads", filename))
    if err != nil {
        return nil, err
    }

    return dst, nil
}

We check whether the  folder exists using .If it doesn’t exist, we create it with permission  using .We then build the full path for the file using  — this ensures proper path formatting across OSes.Finally, we create the file and return it so the handler can write to it.This utility abstracts away the file creation logic, keeping your upload handler clean and focused.With the backend ready to handle image uploads, it’s time to move on to the fun part — building a simple user interface to test our uploader. Let’s jump into the HTML form next! 🧑‍💻📤Step 5: 🎨Building the Frontend UITo test our upload logic, we need a simple and clean user interface. The HTML file below creates a styled upload form with a file input, a submit button, and a placeholder to show the upload status.Save this as  in your  directory:<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Upload file locally using Go-Lang</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f9f9f9;
            padding: 40px;
        }

        .container {
            max-width: 500px;
            margin: auto;
            padding: 30px;
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            text-align: center;
        }

        input[type="file"] {
            margin-bottom: 20px;
        }

        button {
            padding: 10px 20px;
            font-size: 16px;
            background-color: #0077cc;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }

        button:hover {
            background-color: #005fa3;
        }

        #status {
            margin-top: 20px;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Upload a File</h1>
        <form id="uploadForm" enctype="multipart/form-data">
            <input type="file" name="myFile" id="fileInput" required />
            <button type="submit">Upload</button>
        </form>
        <div id="status"></div>
    </div>
    <script src="/main.js"></script>
</body>
</html>

The form uses enctype="multipart/form-data" — which is essential for file uploads.The input field has  to match the backend’s expected form key.There's an  script (we’ll write next) that can handle form submission using JavaScript.CSS is included within the  block for a nice, clean layout — no external files needed.Step 6: ⚙️ Adding JavaScript to Handle the Uploaddocument.getElementById("uploadForm").addEventListener("submit", async function (e) {
    e.preventDefault();

    const fileInput = document.getElementById("fileInput");
    const formData = new FormData();
    formData.append("myFile", fileInput.files[0]);

    const response = await fetch("/upload", {
        method: "POST",
        body: formData,
    });

    const status = document.getElementById("status");
    if (response.ok) {
        const text = await response.text();
        status.innerText = `Success: \n ${text}`;
    } else {
        status.innerText = `Failed to upload file. The file should be of type image and should be less than 10MB.`;
    }
});

We attach a submit event listener to the form.When the form is submitted, we prevent the default page reload using .We collect the selected file from the input field and append it to a  object.We then send a POST request to the  endpoint using .Based on the response, we update the page with a success or error message.This makes your uploader more dynamic and user-friendly — no page reloads needed!🧪 Final Step: Run and Test Your Uploader▶️ Run the Go Server
In your terminal, navigate to the root of your project and run:go run cmd/file-uploader/main.go
Server running on port: 8080

Open your browser and go to:You should see a clean UI with a file input and upload button.Choose an image file (e.g., , ) and click Upload.If successful, you’ll see something like:And that’s it! 🎉 You’ve just built a fully functional local image file uploader using Go, HTML, CSS, and JavaScript — without relying on any external libraries or cloud services.This project is a great starting point for understanding:How to handle file uploads in GoHow to validate file types and manage uploads securelyHow to connect a simple frontend with a backendFrom here, you can take it further by:Preventing file overwritesDisplaying uploaded images on the pageAdding drag-and-drop supportSaving file metadata in a databaseEventually integrating cloud storage like AWS S3Thanks for following along — and happy coding! 👨‍💻✨]]></content:encoded></item><item><title>Go Concurrency</title><link>https://dev.to/ajay-8192/go-concurrency-l6k</link><author>ajay-8192</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 10:31:26 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Go has a built-in feature to handle , which allows it to run multiple functions simultaneously and efficiently. Concurrency isn't parallelism. Parallelism refers to the simultaneous execution of multiple tasks, whereas concurrency refers to the ability to deal with multiple tasks at once. Go Concurrency is a common topic of discussion. Let's look at the mechanisms that support Go Concurrency. are functions or methods that run concurrently with other functions or methods. Goroutines are lightweight threads managed by the Go runtime. They're similar to threads, but they're much cheaper to create and manage. You can create thousands of goroutines without significant overhead.To create a goroutine, simply add the  keyword before the function call:In this example,  will run concurrently with the  function. The  is added to give the goroutine enough time to execute before the  function exits. Without , the  function might exit before the  goroutine has a chance to print its message. are the conduits through which goroutines communicate. They allow goroutines to send and receive values of a specified type. Channels are a fundamental part of Go's concurrency model, enabling safe and synchronized communication between concurrent processes.
  
  
  Declaring and Initializing Channels
You can declare a channel using the  keyword, followed by the type of data it will carry:To initialize a channel, you use the  function:
  
  
  Sending and Receiving Values
You send values into a channel using the  operator:You receive values from a channel using the same  operator, but this time it's on the left side of the assignment:Here's an example demonstrating channel communication:In this example,  sends a string to , and the  function receives that string and prints it.Channels can be , meaning they have a capacity to hold a certain number of values before blocking. When a channel is unbuffered (capacity 0), sending to it will block until another goroutine receives from it, and receiving from it will block until another goroutine sends to it.You can create a buffered channel by providing a capacity to the  function:Here's an example of a buffered channel:The  statement is used to wait on multiple channel operations. It allows a goroutine to block until one of multiple send/receive operations is ready. It's similar to a  statement but specifically for channels.In this example,  will wait for either  or  to send a message. Whichever message arrives first will be printed.
  
  
  Mutexes (Mutual Exclusion)
While channels are the preferred way to communicate and synchronize in Go, there are situations where you might need to protect shared resources from concurrent access. This is where  comes in. A  ensures that only one goroutine can access a critical section of code at a time, preventing .In this example,  ensures that only one goroutine can increment  at a time, preventing a race condition where the final  value might be incorrect without the mutex.  is used to wait for all goroutines to complete before printing the final counter.Go's concurrency model, built around  and , provides powerful and elegant ways to write concurrent programs. By understanding these core concepts, you can build highly performant and scalable applications in Go. While mutexes are available for shared memory access, the Go idiom often favors communication through channels to achieve concurrency safely and efficiently. Embrace goroutines and channels, and you'll unlock the true potential of Go for concurrent programming!]]></content:encoded></item><item><title>Is Real-Time Pushing in Go Too Hard? Try Sponge SSE and Get It Done in One Click!</title><link>https://dev.to/zhufuyi/is-real-time-pushing-in-go-too-hard-try-sponge-sse-and-get-it-done-in-one-click-3c94</link><author>zhuyasen</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 07:41:04 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Hey Gophers! Have you ever encountered scenarios like these:  You're developing a backend monitoring system and want to display real-time data like CPU usage and memory consumption on the frontend, but the only way is to have the frontend send a request every few seconds, exhausting the server?  You want to build an information feed similar to Facebook or Twitter, where new messages are instantly "dinged" and pushed to the user's page, instead of waiting for them to scratch their heads and manually refresh?  Or, you simply want to notify a user: "Your delivery has been picked up by [Handsome John Doe] and is speeding your way!", rather than having them stare anxiously at the order page?If you nodded to any of the questions above, then congratulations, you've probably been using the old method of "polling." It's like sending a subordinate to the kitchen every five seconds to ask, "Is the food ready yet?". Not only does the subordinate run their legs off, but the chef gets annoyed too.Isn't there a more elegant way? Of course, there is! Today's star is , and it's here to save the day! And the Go SSE library we're about to introduce will give you this superpower with "one click"!
  
  
  What is SSE? How is it different from WebSocket?
Before diving into the code, let's explain the principle in plain language., as the name suggests, are "events sent by the server." It's built on a standard HTTP connection, but this connection is a "long-lived" and  one.Think of it as a :  The  is the radio station that broadcasts 24/7.  The  is the radio.Once you tune your radio to the right channel (establish a connection), the station (server) can send you news and music (data) at any time, and you don't need to call every minute to ask, "Are there any new programs?".So, how is it different from WebSocket?: It's a . Only the server can push data to the client. It's simple, lightweight, based on standard HTTP, and natively supports auto-reconnect. It's perfect for scenarios that only require server-to-client information pushing.: It's a . The client and server can "shout" at each other at any time. It's more powerful, but the protocol is also more complex. It's suitable for scenarios like online chat and collaborative editing that require frequent two-way communication.In summary, if your requirement is one-way notification from "server -> client," then SSE is the simpler, more appropriate "wheel" for the job.
  
  
  What features does this Go library offer?
There are many SSE libraries on the market, but many only offer basic functionality. This  library, however, is incredibly thoughtful, like an all-in-one butler:: Excellent underlying design, capable of easily managing thousands of client connections.: Network jitter? User accidentally closed and reopened the page? No worries! The library has built-in mechanisms for automatic reconnection and event resending, ensuring no important messages are lost! (Requires persistent storage).: You can store historical events in Redis, MySQL, or anywhere you like. Mom no longer has to worry about losing messages after a server restart.: Automatically detects "zombie connections" and cleans them up in time, keeping the connection pool healthy.: You can "whisper" to one or more specific users, or "shout" a broadcast to all online users.Sounds cool, right? Just wait, seeing the code is even cooler!
  
  
  Get Started in Three Minutes: Build Your First SSE Service
Let's use a simple example to see how easy it is to quickly set up a service with the  library. Suppose we want to build a service that broadcasts "Hello World" to all clients every 5 seconds.
  
  
  1. Server-side Code ()
You'll need a Go environment and the Gin framework installed (this example uses Gin, but you can also use Go's native ).go get github.com/gin-gonic/gin
go get github.com/go-dev-frame/sponge/pkg/sse
Then, create a  file:See? It's super clear! Initialize Hub -> Create connection point -> Push message. Done!
  
  
  2. Client-side Code ()
Now, we need a "radio" to receive the messages. This library also provides a client implementation, which is very convenient.Now, first run , then open another terminal and run .You will see that the client prints a new message from the server every 5 seconds, without the client needing to do anything extra! That's the magic of SSE!Of course, you can also use other clients for testing.
  
  
  Advanced Usage: Make Your SSE Service More Powerful
The power of the  library goes far beyond this.
  
  
  Scenario 1: I don't want to lose a single message!
Imagine your service is pushing critical stock prices. If a client disconnects for 10 seconds due to network issues, they could miss out on a fortune!This is where  and  come into play.You just need to implement a simple  interface to tell the  library how to save and read events (e.g., using Redis).It's that simple! Now, when a client disconnects and reconnects, it will automatically include the ID of the last message it received. The server, upon seeing this, will fetch all the missed messages from your Redis and send them all at once. The fortune is saved!
  
  
  Scenario 2: I want to know if a message was successfully delivered.
Sometimes, you want to know if a message pushed to a specific user failed (for example, if that user has gone offline). You can set up a "failure callback function."This way, you can log, alert, or perform other compensatory actions for failed push events.Server-Sent Events (SSE) is a powerful tool for building modern real-time applications. Especially when dealing with one-way data streams from the server to the client, it is lighter and simpler than WebSocket.And this  library is like a well-equipped Swiss Army knife. It not only provides the core functionality of SSE but also thoughtfully prepares a series of "deluxe features" for you, such as persistence, auto-reconnection, failure handling, and performance monitoring. It frees developers from the tedious tasks of connection management and exception handling, allowing them to focus on implementing business logic.So, the next time your product manager comes up with a "real-time update" requirement, don't frown and write polling code anymore. Confidently puff out your chest and tell them, "No problem, I'll get it done in minutes!" Then, gracefully import "github.com/go-dev-frame/sponge/pkg/sse" and let the magic happen!]]></content:encoded></item><item><title>Building a Dynamic Reverse Proxy with Go: Hot Reload, Load Balancing &amp; CI/CD</title><link>https://dev.to/yusufbender/building-a-dynamic-reverse-proxy-with-go-hot-reload-load-balancing-cicd-4fgk</link><author>Yusuf Bender</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 06:41:12 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Have you ever wanted to build your own reverse proxy from scratch, with all the flexibility of dynamic configuration, hot reload, and load balancing—without relying on Nginx or Traefik?In this project, I built a fully working reverse proxy server in Go, supporting features like YAML-based configuration, basic authentication, path rewriting, round-robin routing, and live configuration reloads. It’s also fully containerized with Docker and tested using GitHub Actions.Let me walk you through the highlights of this project and why it’s more than just a toy proxy.
A reverse proxy is a server that sits between clients and backend services, forwarding client requests to the appropriate internal services. It's used for load balancing, authentication, caching, rewriting URLs, and more. Think of it as your system’s traffic controller.
Tools like Nginx and Caddy are excellent—but sometimes too abstract. I wanted to understand how things work under the hood: how a proxy handles routes, manages load balancing, or reloads configs without restarting. By building my own, I learned deeply about Go’s net/http, reverse proxying via httputil, and how to structure production-ready systems.
This proxy isn’t just functional—it’s production-aware. Here’s what it includes:Dynamic YAML configurationRound-robin load balancing between multiple targetsHealth checks via /health endpointsPath rewriting (e.g., /api -> /user)Basic Authentication for protected routesHot reload on config file changes (no need to restart the server)Logging and rate limiting middlewareUnit tested with Go's testing packageCI pipeline using GitHub Actions for test + Docker build**Project Structure
**Here’s how the project is organized:main.go: Entry point with middleware setup and hot reload logicrouter.go: Core reverse proxy logic, request handling, round-robin logicrouter_test.go: Unit tests for health checks, load balancing, and rewrite logicroutes.yaml: Defines dynamic routing rules, targets, auth credentialsapi-backend/: Sample API service for testing (written in Go, Dockerized).github/workflows/ci.yml: GitHub Actions config for CI pipeline**Example Configuration (routes.yaml)
**The YAML file defines how incoming paths are routed to target servers, including optional authentication and rewrite paths. For example:yaml
Kopyala
routes:path: /api
targets:

http://localhost:5003
auth:
username: admin
password: 1234
rewrite: /user
This means any request to /api will be routed in round-robin fashion to the targets, protected with basic auth, and the path will be rewritten to /user.**Hot Reload in Action
**One of the biggest challenges was implementing a hot reload system that watches the config file for changes. If routes.yaml is updated, the server reloads routes without restarting. This mimics how systems like Traefik work and adds flexibility in dynamic environments.**CI/CD Setup
**Every commit triggers the following steps via GitHub Actions:Builds the Docker image for the API backend(Optional) Could be extended to push to Docker Hub or deploy to a staging environmentThis ensures the proxy remains stable and buildable at all times.**Lessons Learned
**Go’s net/http and httputil.ReverseProxy provide great building blocks for low-level HTTP control.YAML makes dynamic configuration super clean for routing rules.Hot reload can be implemented simply with file watchers and mutex locking.Writing tests for a proxy server can be tricky, especially when simulating backend servers, but it's possible with httptest.**What’s Next?
**Adding a Web UI dashboard to visualize logs, active routes, and trafficSupport for JWT authenticationMetrics support with PrometheusRedis-backed caching layerLive reload via SIGHUP signal or WebSocket interfaceConclusion
This project was both a systems exercise and a backend engineering challenge. If you're learning Go or preparing for DevOps roles, building something like this sharpens your skills in concurrency, testing, and real-world infrastructure patterns.You can find the full code here:
GitHub Repo: github.com/yusufbender/bender-reverse-proxyIf you like the project, feel free to star it or fork and extend it!Let me know what you think—or even better, contribute and build together 🚀]]></content:encoded></item><item><title>ATMEGA328P-PU: The Little Prince of Microcontrollers in Circuits &amp; Stars</title><link>https://dev.to/ersajay/atmega328p-pu-the-little-prince-of-microcontrollers-in-circuits-stars-34ka</link><author>ersajay</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 06:38:01 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[A Meeting in the Desert of Circuits
The desert stretched endlessly, its sands glowing like gold under the sun. I was tracing the dunes, heading toward a distant oasis, when I spotted a glint in the sand—a small, rectangular shape, no bigger than a ladybug.
“You’re… very small,” I said, kneeling.
“And you’re a child who talks to microcontrollers,” it replied, voice soft as the wind. “But some keepers of light are smallest when they’re strongest. Ask the fox.”
It was an ATMEGA328P-PU—the heart of Arduino Uno, but to me, it felt like a secret. Let me tell you its story.What Is the ATMEGA328P-PU? (A Keeper of Code, Not Just Silicon)
This was no ordinary chip. It was a ATMEGA328P-PU, an 8-bit AVR microcontroller in a 28-pin DIP suit—smaller than a baobab seed, but tough as the roots of the rose’s planet. Here’s its secret:Clock Speed: 16-20MHz (overclockable to 24MHz for daredevils). Faster than the fox darting across the dunes.
Memory: 32KB Flash (stores code), 2KB SRAM (variables), 1KB EEPROM (your debugging tears). Like a Pensieve for electrons.
I/O Pins: 23 programmable pins (14 digital, 6 analog). Windows to the world—like the portholes on a spaceship.Fun Fact: Engineers call it the “Cockroach of MCUs.” Survives power surges, cosmic rays, and your “hold my beer” coding experiments. Even the baobabs can’t crush it.
“Why so quiet?” I asked.
“Keepers don’t shout,” it said. “They just keep.”ATMEGA328P-PU & Its Siblings: Stars in the Same Sky
In the desert of microcontrollers, ATMEGA328P-PU has siblings—some older, some louder, but none quite like it:ATMEGA328-PU: An older star. Higher power draw, like a planet that burns too bright. Avoid—like flip phones in 2025.
ATMEGA328PB-PU: A louder sibling. Extra peripherals (UART, timers), but bulkier. For complex projects, like a planet with too many volcanoes.
ATMEGA328P-PU: The steady one. Lower power (1.8V-5.5V), optimized code. Ideal for battery-powered projects—like a rose that blooms in the desert.Roast Alert:
ATMEGA328-PU (grumbling): “I’m vintage!”
ATMEGA328P-PU (calm, like the fox): “I’m in NASA prototypes. You’re in a landfill. Bye.”Why the Fox (and Engineers) Choose It
ATMEGA328P-PU isn’t flashy. It’s the kind of friend who shows up, fixes your code, and leaves without fanfare. Here’s why:Cost: $3/unit—cheaper than a morning espresso (and way more useful). Even the rose, who’s picky, approves.
Simplicity: No Wi-Fi tantrums or driver hell (looking at you, ESP32). Like a well-tended garden—no weeds.
Community Support: 10k+ Arduino tutorials. Google is your co-pilot, and the fox is your guide.Mars Rover Prototypes: Runs in -40°C labs (tested by NASA JPL). Even cosmic frost can’t stop it.
DIY COVID Ventilators: 2020’s MacGyver hero (MIT Open-Source Project). Saved lives, one byte at a time.“Why not be bigger?” I asked.
“Big things break,” it said. “Tiny things fit. In garage labs. In Mars rovers. In portable ECGs.”Programming the Little Prince: A Dance with Code
Want to wake the ATMEGA328P-PU? It’s like taming a fox—gentle, patient, and rewarding.
Option 1: Arduino IDE (The Friendly Path)Connect via USB-to-Serial (e.g., CH340G). Pray the drivers install (sometimes they don’t—blame AliExpress).
Select Board: Arduino Uno (even if you’re using a breadboard).
Upload Code: Watch the LED blink, like a star winking hello.Option 2: Bare-Metal with AVRDUDE (The Adventurer’s Path)Command: avrdude -c usbasp -p m328p -U flash:w:your_code.hex
Pro Tip: If smoke appears, take a breath. The fox says, “It’s not your fault—sometimes stars misbehave.”Burning the Bootloader: Tending the Rose
Burning a bootloader is like planting a rose—delicate, but necessary.
Tools Needed:Programmer: USBasp, Arduino as ISP, or a sacrificial Uno (no tears, it’ll forgive you).
Software: Arduino IDE or AVRDUDE (the gardener’s tools).Wire It Up: Connect MOSI, MISO, SCK, RESET, GND, VCC. Triple-check—no one likes a fried rose.
Arduino IDE: Tools > Programmer > USBasp (or your tool).
Burn: Tools > Burn Bootloader. Wait for the magic (or error messages—they’re just the rose’s thorns).]]></content:encoded></item><item><title>Telemetry Stack: System Monitoring with Go, FastAPI, InfluxDB and Grafana</title><link>https://dev.to/yusufbender/telemetry-stack-system-monitoring-with-go-fastapi-influxdb-and-grafana-1of5</link><author>Yusuf Bender</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 06:36:32 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[🚀 What is Telemetry Stack?
Telemetry Stack is a simple but powerful system monitoring solution. It consists of:📥 Agent (Go): Collects CPU, RAM, and Disk usage every 10 seconds🌐 API (FastAPI): Receives metrics and writes to InfluxDB🧠 InfluxDB: Time-series database to store metrics📊 Grafana: Beautiful dashboards for visualizing the data🐳 Docker Compose: All services containerized and orchestrated🧩 Project Structuretelemetry-stack/
├── agent/               # Golang system metrics collector
├── server/              # FastAPI metrics receiver
│   └── models.py
├── docker-compose.yml  # Full stack definition
└── README.md🔧 Technologies Used
Go (with gopsutil)
InfluxDB 2.7
Docker & Docker Compose🐙 GitHub Repository
🔗 View on GitHub ]]></content:encoded></item><item><title>Implementing Distributed Locks in Go: A Practical Guide for Backend Devs</title><link>https://dev.to/jones_charles_ad50858dbc0/implementing-distributed-locks-in-go-a-practical-guide-for-backend-devs-4iip</link><author>Jones Charles</author><category>dev</category><category>go</category><category>devto</category><pubDate>Wed, 2 Jul 2025 01:16:16 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[
  
  
  1. Hey, Let’s Talk Distributed Locks!
Hey there, fellow Go devs! If you’ve got a year or two of Go under your belt—comfortable with goroutines and  but still scratching your head over distributed systems—this one’s for you. Distributed locks are the unsung heroes of modern backend architectures, keeping chaos at bay when multiple nodes need to play nice with shared resources. Think flash sales, task scheduling, or distributed transactions—locks are your traffic cops.So, what’s a distributed lock? It’s a way to coordinate access to resources across machines. On a single machine,  does the trick. But in a distributed world, where nodes don’t share memory and networks can hiccup, we need something beefier. That’s where distributed locks come in, tackling mutual exclusion, network delays, and node crashes.I’ve been slinging code for 10 years—Java back in the day, Go for the last 7—and I’ve tripped over my share of distributed system traps. In this guide, I’ll walk you through building distributed locks in Go from scratch, sharing battle-tested tips along the way. Why Go? It’s got lightweight concurrency, a killer ecosystem, and syntax that doesn’t make you want to cry. Whether you’re here to grok the theory or snag some copy-paste code, I’ve got you covered.We’ll cover the basics, dive into Go implementations with Redis, ZooKeeper, and etcd, and wrap up with real-world examples and pitfalls to dodge. Let’s get rolling! What makes distributed locks tick, and why Go rocks for this.
  
  
  2. The Nuts and Bolts of Distributed Locks (and Why Go?)
Before we sling code, let’s get the lay of the land. Distributed locks are all about three things:  (one client at a time),  (no disappearing acts), and  (fast in, fast out). They’re clutch for stuff like preventing overselling in e-commerce or ensuring a task runs on just one node.So, why pick Go for this gig?: Goroutines are cheap and cheerful—think thousands of concurrent lock attempts without breaking a sweat. Channels make retry logic a breeze.: Libraries like , , and  are production-ready and waiting for you.: Go’s no-nonsense syntax means you can whip up a lock in a few lines and still get screaming performance.Compared to Java’s heavyweight setup or Python’s concurrency quirks (looking at you, GIL), Go hits the sweet spot. Here’s a quick cheat sheet: Go’s your trusty sidekick for distributed locks—light, fast, and drama-free. Next, we’ll get our hands dirty with code.
  
  
  3. Hands-On: Building Distributed Locks in Go
Enough talk—let’s code! We’ll implement distributed locks using Redis, ZooKeeper, and etcd, three heavy hitters in the game. Each has its flavor, and I’ll drop full Go snippets you can run or tweak. Let’s do this!
  
  
  3.1 Redis: Fast and Furious
 Redis uses  (set if not exists) to grab a lock, with a TTL to avoid deadlocks. It’s like snagging the last slice of pizza—if you’re first, it’s yours, but you’ve got a timer. The Lua script ensures only the lock owner can release it—avoids someone else swiping your pizza. High-speed scenarios like flash sales where consistency can flex a bit.
  
  
  3.2 ZooKeeper: Rock-Solid Consistency
 ZooKeeper uses temporary sequential nodes. You create a node, check if you’re the lowest number, and wait your turn if not—like a polite queue at the DMV. When you need bulletproof consistency, like financial systems or critical scheduling.
  
  
  3.3 etcd: The Cloud-Native Champ
 etcd uses leases and key competition. You grab a lease, set a key, and hold it ‘til the lease is up—like renting a coworking desk. Cloud-native apps or anything in the Kubernetes orbit—etcd’s a natural fit.
  
  
  4. Level Up: Best Practices and Pitfalls to Avoid
Code’s in the bag, but distributed locks are tricky beasts in the wild. Think of them as a relay baton—drop it, and your system’s toast. With a decade of backend scars, I’ve got some hard-won tips and traps to share. Let’s make your locks bulletproof. I once locked an entire e-commerce inventory with one key. Peak traffic hit, contention spiked, and QPS tanked to the hundreds. Oof. Lock by specific IDs (like product IDs) to keep things granular and contention low.
  
  
  Timeouts and Retries Done Right
 A task scheduler I built had a tiny TTL. One slow job later, the lock expired, another node jumped in, and chaos ensued—duplicate tasks everywhere. Use  for timeouts and exponential backoff for retries. Less fighting, more winning. Locks can bottleneck your app silently. Log acquire/release times and track contention with tools like Prometheus.
  
  
  The “Whoops, I Deleted Your Lock” Trap
 Client A’s lock expires, B grabs it, then A wipes it out by mistake. Concurrency goes poof. Use unique IDs and a Lua script (see Redis example) to ensure only the owner releases it.
  
  
  ZooKeeper’s Network Hiccups
 In a payment system, network jitter dropped ZooKeeper connections, killing locks and duplicating orders. Reconnect and double-check your lock:
  
  
  etcd’s High-Concurrency Lag
 Under heavy load, etcd’s lease requests piled up, slowing lock grabs to a crawl. Pre-allocate leases and reuse them: Locks need finesse—keep them tight, resilient, and visible.
  
  
  5. Locks in Action: Real-World Scenarios
Time to take our locks for a spin! We’ll tackle two classics: an e-commerce flash sale and a distributed task scheduler. Code’s ready, lessons are baked in—let’s roll.
  
  
  5.1 Flash Sale: No Overselling Allowed
 100 product units, 100,000 users, zero oversells. Redis to the rescue. Redis locks keep stock checks atomic. Pipeline it for even more speed.
  
  
  5.2 Task Scheduler: One Node, One Job
 Clean logs at midnight on one node only. etcd’s got this. etcd’s leases ensure one winner, and state sticks around for recovery. Cut lock time with async logging— showed ~5k QPS.
 Shard tasks by ID for scale.
  
  
  6. Wrapping Up: Key Takeaways and What’s Next
We’ve made it! From the nuts and bolts of distributed locks to Go-powered implementations and real-world wins, we’ve covered a lot of ground. Think of this as your crash course in taming distributed chaos. Let’s recap, drop some final tips, and peek at what’s ahead for Go in this space.Distributed locks boil down to mutual exclusion, reliability, and speed, and Go’s a champ at delivering them. Here’s the rundown:  : Your go-to for blazing-fast, high-concurrency gigs like flash sales.
: The rock-solid choice for consistency-first jobs like scheduling.
: The balanced, Go-native pick for cloud setups and Kubernetes fans.
We’ve coded them up, dodged pitfalls like lock misdeletion and network jitter, and seen them shine in e-commerce and task scheduling. The secret sauce? Fine-tune granularity, handle timeouts like a pro, and monitor everything.
  
  
  Practical Tips from the Trenches
After 10 years of backend battles, here’s my cheat sheet for rocking distributed locks:  : Kick off with Redis—it’s easy and fast. Scale to ZooKeeper or etcd when you need more.
: Keep lock hold times tiny—shard locks or go async for big wins.
: Network blips happen. Retry smartly and check lock state.
: No metrics, no clue. Log and track contention from day one.
Go’s star is rising in distributed systems, and it’s no fluke. With Kubernetes, Istio, and etcd all in its orbit, Go’s concurrency and simplicity are a perfect match for cloud-native chaos. What’s next? I’d bet on frameworks that bake in service discovery and auto-renewing leases—less boilerplate, more focus on your app. Distributed locks in Go feel like driving a tuned-up sports car: fast, stable, and fun to code.So, grab the snippets, tweak them for your projects, and let me know how it goes—I’d love to hear your war stories! Distributed locks don’t have to be a headache, and with Go, they’re downright approachable. Locks are tools, not magic. Pick the right one, wield it well, and your system will thank you. Happy coding!]]></content:encoded></item><item><title>1 million chess boards and 10,000+ Go binaries</title><link>https://golangweekly.com/issues/560</link><author></author><category>dev</category><category>go</category><pubDate>Wed, 2 Jul 2025 00:00:00 +0000</pubDate><source url="https://golangweekly.com/">Golang Weekly</source><content:encoded><![CDATA[ — AppSignal gives Go developers the tools they need to fix bugs, track performance issues, and ship with confidence. Easy to set up, a joy to use, and built for teams that care about their code.  Start your free trial today, no credit card required.]]></content:encoded></item><item><title>Advanced Golang Concurrency Patterns: Building Million-Events-Per-Second Data Pipelines with Intelligent Resource Management</title><link>https://dev.to/aaravjoshi/advanced-golang-concurrency-patterns-building-million-events-per-second-data-pipelines-with-2i02</link><author>Aarav Joshi</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 18:31:36 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[As a best-selling author, I invite you to explore my books on Amazon. Don't forget to follow me on Medium and show your support. Thank you! Your support means the world! 
  
  
  Advanced Concurrency Patterns for High-Throughput Data Pipelines in Golang
Building high-performance data pipelines requires moving beyond basic worker pools. I've spent years optimizing Go systems processing millions of events per second. The real challenge lies in balancing throughput with priority handling while preventing resource exhaustion. Let me share patterns that transformed our production systems.  Concurrency isn't just about goroutines. It's about intelligent resource management. Consider priority handling first. Dedicated channels for critical items prevent queue starvation. In our implementation, high-priority items bypass batching entirely:This simple separation reduced our P99 latency by 40%. Unexpectedly, it also improved regular throughput by eliminating head-of-line blocking.  Backpressure must be explicit. Many systems fail when queues overflow silently. We return submission statuses:In production, we couple this with exponential backoff and circuit breakers. Clients respect backpressure signals, preventing cascading failures.  Batching requires careful tuning. Fixed batch intervals cause latency spikes. Fixed sizes waste resources. Our solution combines both:This dual-trigger approach maintains consistent latency while adapting to load variations.  Work stealing solves imbalance problems. Traditional approaches introduce significant overhead. Our probabilistic stealing minimizes locks:We lock only during item transfer, not during queue inspection. This reduced steal overhead by 70% in benchmarks.  Telemetry is non-negotiable. We track:  Per-shard load distribution
Batch processing times (exponential moving average)
These metrics feed our auto-scaling systems. Sudden queue depth increases trigger horizontal scaling.  I learned hard lessons about resource exhaustion. Our pipeline now includes these safeguards:We maintain a strict priority queue ratio. When priority items exceed 10% of capacity, clients must throttle. This prevents priority floods from starving regular items.  Production enhancements matter. We added:  Circuit breakers that skip shards during downstream failures
A dead-letter queue for unprocessable items
Dynamic batch sizing based on queue depth
Prometheus metrics endpoint
These adjustments happen during maintenance windows. We avoid runtime mutations that could cause races.  Performance characteristics surprised us. On 8-core servers:  Sustained throughput: 780K ops/second
Priority latency: <2ms P99
Resource utilization: 70% CPU at peak
Zero drops at 10x load spikes
The key was minimizing synchronization. Our work stealing uses brief, targeted locks. Batch processing avoids shared state. Each shard maintains independent buffers.  Shutdown handling is often overlooked. We use context cancellation:This prevents data loss during deployments. In-flight items complete processing while new submissions stop immediately.  Through trial and error, I discovered critical insights. First, backpressure must propagate to clients. Second, metrics should drive scaling decisions. Third, priority systems need strict quotas. Most importantly, simplicity beats cleverness. Each component does one thing well.  
  
  
  These patterns now power our real-time analytics pipeline. They process 14 billion events daily with predictable performance. The system self-regulates during traffic spikes. Failures remain isolated. That reliability transformed how we design data systems.
📘 , , , and  to the channel! is an AI-driven publishing company co-founded by author . By leveraging advanced AI technology, we keep our publishing costs incredibly low—some books are priced as low as —making quality knowledge accessible to everyone.Stay tuned for updates and exciting news. When shopping for books, search for  to find more of our titles. Use the provided link to enjoy !Be sure to check out our creations:]]></content:encoded></item><item><title>Golang Context Package: A Guide to One of the Most Used Packages in Go</title><link>https://dev.to/pedro-silva-dev/golang-context-package-a-guide-to-one-of-the-most-used-packages-in-go-a3g</link><author>Pedro Silva</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 13:31:27 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[So, you're writing some Go code and you keep seeing context.Context pop up everywhere, right? Especially if you're building network servers or anything that juggles multiple tasks at once. This package was added way back in Go version 1.7, and it's super important for writing good, solid code. But what does it actually do? And why should you care? Let's dive in and figure it out!The "Why": The Problem Context Solves
Picture this: you have a web server that handles requests. For each request, your server might need to make a database query and a call to an external API. Now, think about two scenarios:The user cancels the request: The user just closes their browser tab. Your server, not knowing this, carries on with the database query and the API call, wasting CPU, memory, and network resources on a result that no one is ever going to see.An operation is too slow: The external API is taking forever to respond. You don't want your server to hang forever, tying up resources. You need a way to set a time limit.These scenarios show a classic challenge in concurrent programming: managing an operation's lifecycle. That's exactly the problem the context package was made to solve. It gives us a standard, super-powerful way to handle deadlines, timeouts, cancellation signals, and to carry request-specific data around.The Context Lifecycle: A Tree of Operations
The most important concept to get about context is that it creates a tree of operations. Each new request or background job kicks off a new tree.The Root: Every context tree starts with a root. You'll typically create this using . This base context is never canceled, has no values, and no deadline.Child Contexts: When you want to change a context—like adding a timeout or making it cancelable—you create a child context from a parent.
ctx, cancel := (parentCtx, 2*time.Second)Propagation: This parent-child relationship is the key to the context's power.Cancellation flows downwards: When a parent context is canceled, all of its children and their children's children are immediately canceled, too.Values are inherited: A child context inherits all the values from its parent.This tree structure lets you create a scope for a specific operation. If the main operation gets canceled (like the user's HTTP request is terminated), all the sub-operations (database queries, API calls) tied to its context automatically get the signal to stop.The "What": The  Interface
At its heart, the package gives us the context.Context interface, which is surprisingly simple:type Context interface {
    // Done returns a channel that's closed when work done on behalf of this
    // context should be canceled.
    Done() <-chan struct{}

    // Err returns a non-nil error if Done is closed.
    // It will be context.Canceled or context.DeadlineExceeded.
    Err() error

    // Deadline returns the time when work done on behalf of this
    // context should be canceled.
    Deadline() (deadline time.Time, ok bool)

    // Value returns the value associated with this context for a key,
    // or nil if no value is associated with the key.
    Value(key interface{}) interface{}
}

You'll rarely implement this interface yourself. Instead, you'll use the functions the context package already gives you to create and manage contexts.The "How": Creating and Using Contexts
Let's see how to build and use the context tree in practice. and context.TODO(): Like we said, this is your starting point—the root of your context tree. You'll usually use it in main() or at the top level of a request handler.: This function also returns an empty context. You should use it when you're not sure which context to use or when a function should be updated to accept a context but isn't yet. It works like a "to-do" note for the future.: Propagating Cancellation
This is the most direct way to make an operation cancelable. It returns a child context and a CancelFunc. It's basically a "stop" button!package main

import (
    "context"
    "fmt"
    "time"
)

func worker(ctx context.Context, id int) {
    for {
        select {
        case <-ctx.Done():
            // The context was canceled, so we stop working.
            fmt.Printf("Worker %d: stopping. Reason: %v\n", id, ctx.Err())
            return
        default:
            fmt.Printf("Worker %d: doing work.\n", id)
            time.Sleep(500 * time.Millisecond)
        }
    }
}

func main() {
    // Create a base context for our operation.
    // It's good practice to call the cancel function to free up resources,
    // so we use defer here.
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel() 

    // Start a few workers, all using the same cancelable context.
    go worker(ctx, 1)
    go worker(ctx, 2)

    // Let them run for a couple of seconds.
    time.Sleep(2 * time.Second)

    // Now, cancel the whole operation.
    fmt.Println("Main: canceling all workers.")
    cancel() // This closes the ctx.Done() channel for all workers.

    // Wait a moment to see the workers' shutdown messages.
    time.Sleep(1 * time.Second)
    fmt.Println("Main: finished.")
}
When  is called, the  channel of ctx is closed, and both goroutines get the signal to terminate.context.WithTimeout & context.WithDeadline: Time-based Cancellation
These are specialized and very common versions of WithCancel. It's like putting a stopwatch on your operation.WithTimeout: Cancels the context after a certain amount of time.WithDeadline: Cancels the context at a specific time.package main

import (
    "context"
    "fmt"
    "time"
)

func slowOperation(ctx context.Context) {
    fmt.Println("Starting slow operation...")
    select {
    case <-time.After(5 * time.Second):
        // This won't be reached if the context times out first.
        fmt.Println("Operation completed successfully.")
    case <-ctx.Done():
        // The context's deadline was exceeded.
        fmt.Println("The operation timed out:", ctx.Err())
    }
}

func main() {
    // Create a context that will be canceled after 3 seconds.
    ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
    // It's a good practice to always call cancel, even on a timeout context,
    // to release resources if the operation finishes early.
    defer cancel()

    slowOperation(ctx)
}

: Passing Request Data
WithValue lets you attach data to a context. This is great for passing info that's relevant to a whole request chain, like a tracing ID or an authenticated user's identity.Heads up: Use WithValue sparingly! Don't use it to pass essential parameters to functions; those should be explicit function arguments. Think of it more like a sticky note you attach to the request, not a suitcase.To avoid key conflicts, always define a custom, unexported type for your context keys.package main

import (
    "context"
    "fmt"
)

// Use a custom unexported type for the context key.
type key string

const traceIDKey key = "traceID"

func process(ctx context.Context) {
    // Retrieve the value.
    id, ok := ctx.Value(traceIDKey).(string)
    if ok {
        fmt.Println("Processing with Trace ID:", id)
    } else {
        fmt.Println("No Trace ID found.")
    }
}

func main() {
    // Create a context with a value.
    ctx := context.WithValue(context.Background(), traceIDKey, "abc-123-xyz")

    process(ctx)
}

Best Practices and Pitfalls
Always pass Context as the first argument to a function: func DoSomething(, ...). It's just good Go etiquette!Always call the cancel function returned by WithCancel, WithTimeout, and WithDeadline to clean up resources.  is your best friend.Never store a Context inside a struct. Pass it explicitly.Never pass a nil Context. If you're not sure, use .context.Background() should only be used at the highest level of a program (e.g., in main or at the start of a request handler) as the root of a context tree. Avoid passing it directly to other functions.A Context is immutable. Functions like WithCancel or WithValue return a new child context; they don't modify the one you pass in.Conclusion
And that's it! The context package isn't so scary after all, is it? It's a tool to keep your concurrent code from becoming a mess. By thinking in terms of these "context trees," you can handle timeouts and cancellations now. The next time you see context.Context in some code, you'll know it's the secret sauce that holds the whole operation together. Follow for more content!]]></content:encoded></item><item><title>TicTacToe. Go Duel. AI vs Fate.</title><link>https://dev.to/andrey_matveyev/tictactoe-go-duel-ai-vs-fate-5g9a</link><author>Andrey Matveyev</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 10:22:57 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[
  
  
  Neural Network vs Random Number Generator
"Knowledge itself is power" (с) -Francis BaconCreating a network is easy. Training it correctly is not an easy task. The result often does not match expectations. In reality, there is no magic here. The network does exactly what it is told to do. If the result is not what was intended, then the error is either in the training or in the interpretation of the results obtained. The creator's thoughts cannot yet be guessed by the network.In our previous article, we delved into the fundamentals of neural networks, building a simple model in Golang and successfully solving the classic XOR problem. Now it's time to move on to a more exciting and complex area — Reinforcement Learning — and apply this knowledge to create an intelligent agent capable of playing Tic-Tac-Toe.Unlike the XOR problem, where the network immediately received the "correct answer" and could adjust its weights, in games like Tic-Tac-Toe, a key difficulty arises: delayed reward. The agent makes moves, but the outcome of its actions (win, loss, or draw) is only known at the end of the game. This means we cannot immediately point out an "error" or "success" for each individual move to the network. The agent needs to learn to associate intermediate actions with future outcomes.It is precisely to solve such problems that the Deep Q-Learning (DQN) algorithm was developed, which we will discuss in detail in this article. We will describe the game logic, the DQN agent's architecture, and analyze its training process as both the first and second player. The article is written in an accessible, popular style and will not delve deeply into the mathematical foundations, as there are many excellent resources on this topic available online (e.g., mathematics of reinforcement learning (RL) or video about DeepLearning).Tic-Tac-Toe is a simple deterministic game for two players on a 3x3 board. Players take turns placing their symbols (X and O) into empty cells. The goal of the game is to be the first to get three of your symbols in a row horizontally, vertically, or diagonally. If all cells are filled and no winner is determined, the game ends in a draw.: Determined by the arrangement of X and O symbols on the board.: Choosing an empty cell to place your symbol.: A win for one of the players or a draw.: In Tic-Tac-Toe, the first player has a strategic advantage. With optimal play from both players, the game always ends in a draw or a win for the first player. According to my estimates, and confirmed by experiment (when the agent initially plays like a random opponent), the probability of winning for the player who makes the first move to the center is about 60% (600 out of 1000 games), a loss is about 30%, and a draw is 10%.Board Representation and State VectorThe game  is represented by a Board struct, and its state is converted into a numerical vector for the neural network using the  method.
  
  
  Deep Q-Learning Agent (DQN)
Our agent is based on the  architecture, which combines Q-learning with deep neural networks. This is evident in how the action for the next state is selected using the main Q-network, and then its Q-value is evaluated using the target network. This helps to reduce the overestimation of Q-values characteristic of classic DQN.The board state is converted into a numerical vector that is fed into the neural network. For each of the 9 board cells:, if the cell is occupied by the agent's symbol., if the cell is occupied by the opponent's symbol., if the cell is empty.Neural Network ArchitectureThe agent uses a fully connected neural network.: 9 neurons (corresponding to the 9 board cells).: One hidden layer with 27 (or 45/72) neurons with a Tanh activation function. The minimum number of neurons in the hidden layer that yielded satisfactory results was 9.: 9 neurons (corresponding to 9 possible actions/cells), also with a Tanh activation function.The agent learns by interacting with the environment (the Tic-Tac-Toe game) and receiving rewards.The  stores the agent's experiences, allowing for efficient training by sampling past interactions.DQNAgent Structure and Action SelectionThe  struct holds the Q-network, target network, replay buffer, and training parameters. The  method implements the epsilon-greedy strategy.The  method implements the core Double DQN update rule, using the replay buffer and target network.Note the Bellman equation:Using this mechanism, the "reward" gradually "propagates" from the end of the game to its beginning.The  function defines the reward structure for the agent:
  
  
  Training Process and Results
So, we are all set for testing.
Let's briefly summarize what we have:A  with a 9:27:9 architecture that knows nothing.A  and implementation of game logic (start, rule adherence, and end detector (win/loss/draw)).An  who can make moves into free cells randomly. And that's all.An  that, from the start, plays like its opponent but has the ability to learn. It knows when the game ends. And it knows whether it finished the game well or poorly.What can we observe and by what criteria can we determine the learning progress?Firstly, it's the agent's win percentage (expected to increase).Secondly, we can observe the decrease in Epsilon to understand what is happening – whether the agent is exploring (making random moves) or utilizing its accumulated experience.Thirdly, we can look at the weight vector on the output layer to understand how the agent decides to make its first move on an empty board (it is expected that the center will have the largest weight, then the corners, and then the sides as the least promising).And finally, we can track the maximum number of wins achieved throughout the entire experiment.Let's see what came of this and whether our agent will show growth in its competence.Training the Agent as the First PlayerIn this scenario, the agent (Player X) always makes the first move in the game. To accelerate convergence and ensure the learning of an optimal starting strategy, we can experimented with forcing the first move to the center of the board (default without this).These are the settings that can be changed when conducting an experiment.
'Knobs' that can be 'turned' for fine-tuning.
The network implemented here usually forgives even gross errors.
The most you risk is falling into a local minimum instead of a global one.
Feel free to try it yourself.PS D:\go\go-sample-tictactoe> go run .
Starting DQN agent training (X) against a random opponent (O) for Tic-Tac-Toe...
Episode: 1000, Wins X: 571 (571), Losses X: 307, Draws: 122, Epsilon X: 0.9876, Q(start): 0.4501|0.5164|0.4117  0.5863[0.5449]0.4485  0.3473|0.4411|0.4166
Episode: 2000, Wins X: 590 (590), Losses X: 284, Draws: 126, Epsilon X: 0.9715, Q(start): 0.3683|0.4917|0.3963  0.2354[0.6179]0.3571  0.2806|0.3732|0.3737
Episode: 3000, Wins X: 585 (590), Losses X: 294, Draws: 121, Epsilon X: 0.9558, Q(start): 0.2797|0.4310|0.3559  0.1067[0.4802]0.2719  0.1742|0.2720|0.2669
Episode: 4000, Wins X: 588 (590), Losses X: 285, Draws: 127, Epsilon X: 0.9402, Q(start): 0.2361|0.4065|0.3263  0.1037[0.3945]0.2356  0.1445|0.2771|0.2186
...
Episode: 297000, Wins X: 952 (969), Losses X: 43, Draws: 5, Epsilon X: 0.0156, Q(start): 0.5193|0.3906|0.2095  0.5050[0.3286]0.4332  0.1040|0.3630|0.2807
Episode: 298000, Wins X: 957 (969), Losses X: 40, Draws: 3, Epsilon X: 0.0154, Q(start): 0.5189|0.3942|0.1822  0.4883[0.3528]0.4347  0.1214|0.3698|0.2528
Episode: 299000, Wins X: 977 (977), Losses X: 20, Draws: 3, Epsilon X: 0.0152, Q(start): 0.5201|0.4159|0.1651  0.4708[0.3775]0.4352  0.1291|0.3870|0.2078
--- Target network updated at step 1050000 (Epsilon: 0.0151) ---
Episode: 300000, Wins X: 968 (977), Losses X: 23, Draws: 9, Epsilon X: 0.0150, Q(start): 0.4733|0.4222|0.1718  0.4519[0.4072]0.4743  0.1526|0.4102|0.1889
...
Episode: 497000, Wins X: 952 (990), Losses X: 43, Draws: 5, Epsilon X: 0.0011, Q(start): 0.3910|-0.3152|-0.2335  -0.2994[0.4932]0.0485  0.0135|-0.4090|-0.2174
--- Target network updated at step 1700000 (Epsilon: 0.0011) ---
Episode: 498000, Wins X: 942 (990), Losses X: 55, Draws: 3, Epsilon X: 0.0011, Q(start): 0.3798|-0.3127|-0.2245  -0.3118[0.4557]0.0439  0.0072|-0.4120|-0.2115
Episode: 499000, Wins X: 936 (990), Losses X: 56, Draws: 8, Epsilon X: 0.0011, Q(start): 0.3651|-0.3107|-0.2292  -0.3250[0.3711]0.0254  -0.0033|-0.4216|-0.1881
Episode: 500000, Wins X: 954 (990), Losses X: 41, Draws: 5, Epsilon X: 0.0011, Q(start): 0.3561|-0.3119|-0.2014  -0.3267[0.3711]0.0196  -0.0191|-0.4155|-0.1827

Training complete.
Testing the agent (X against random O)...

Test Results (1000 games, Agent X vs random O):
Agent X Wins: 956
Agent X Losses (Random O Wins): 39
Draws: 5
When the agent was to make the first move to the center, it demonstrated outstanding results, achieving up to 992 wins out of 1000 (in some cases) test games against a random opponent, with a minimal number of losses and draws. This confirms that the agent successfully learned an optimal strategy for the first player."Win Growth (agent moves first)" graph:Training the Agent as the Second PlayerIn this scenario, the opponent (Player O) always makes the first move randomly, and our agent (Player X) always responds second. This puts the agent in a less advantageous position, as the first move in Tic-Tac-Toe provides a strategic advantage. The goal of this experiment is to test how well the agent can adapt to the role of the second player and minimize the opponent's advantage.The same hyperparameters as for the first scenario were used.The only change is that the opponent always makes the first move.PS D:\go\go-sample-tictactoe> go run .
Starting DQN agent training (X) against a random opponent (O) for Tic-Tac-Toe...
Episode: 1000, Wins X: 296 (296), Losses X: 587, Draws: 117, Epsilon X: 0.9902, Q(start): 0.2536|0.3091|0.2323  0.3227[0.3963]0.3577  0.4702|0.4281|0.2465
Episode: 2000, Wins X: 298 (298), Losses X: 590, Draws: 112, Epsilon X: 0.9766, Q(start): 0.1909|0.3386|0.2124  0.3879[0.3856]0.3629  0.5409|0.4653|0.2537
Episode: 3000, Wins X: 295 (298), Losses X: 598, Draws: 107, Epsilon X: 0.9633, Q(start): 0.0990|0.3089|0.1477  0.3343[0.3218]0.2929  0.5055|0.4229|0.2093
Episode: 4000, Wins X: 261 (298), Losses X: 601, Draws: 138, Epsilon X: 0.9501, Q(start): 0.0718|0.2712|0.0945  0.3015[0.2998]0.2637  0.4218|0.3067|0.1649
...
Episode: 69000, Wins X: 610 (610), Losses X: 342, Draws: 48, Epsilon X: 0.3986, Q(start): 0.5987|0.5451|0.5798  0.5912[0.6872]0.5793  0.6331|0.5710|0.5508
Episode: 70000, Wins X: 610 (610), Losses X: 359, Draws: 31, Epsilon X: 0.3935, Q(start): 0.5962|0.5428|0.5695  0.5917[0.6848]0.5758  0.6282|0.5837|0.5531
Episode: 71000, Wins X: 606 (610), Losses X: 365, Draws: 29, Epsilon X: 0.3885, Q(start): 0.5914|0.5330|0.5650  0.5899[0.6844]0.5742  0.6268|0.5863|0.5423
Episode: 72000, Wins X: 570 (610), Losses X: 407, Draws: 23, Epsilon X: 0.3835, Q(start): 0.5867|0.5349|0.5650  0.5872[0.6871]0.5795  0.6202|0.5833|0.5385
Episode: 73000, Wins X: 564 (610), Losses X: 405, Draws: 31, Epsilon X: 0.3786, Q(start): 0.5912|0.5303|0.5606  0.5833[0.6815]0.5811  0.6198|0.5832|0.5418
Episode: 74000, Wins X: 612 (612), Losses X: 353, Draws: 35, Epsilon X: 0.3737, Q(start): 0.5958|0.5287|0.5575  0.5840[0.6816]0.5730  0.6146|0.5765|0.5359
--- Target network updated at step 250000 (Epsilon: 0.3694) ---
Episode: 75000, Wins X: 588 (612), Losses X: 373, Draws: 39, Epsilon X: 0.3689, Q(start): 0.6005|0.5305|0.5658  0.5903[0.6910]0.5730  0.6132|0.5845|0.5456
Episode: 76000, Wins X: 650 (650), Losses X: 311, Draws: 39, Epsilon X: 0.3642, Q(start): 0.6314|0.5703|0.5932  0.6218[0.7187]0.6036  0.6409|0.6085|0.5756
...
Episode: 497000, Wins X: 792 (822), Losses X: 185, Draws: 23, Epsilon X: 0.0020, Q(start): 0.5345|0.3504|0.2066  0.2787[0.5258]0.4991  0.1034|0.5461|0.5410
Episode: 498000, Wins X: 804 (822), Losses X: 168, Draws: 28, Epsilon X: 0.0020, Q(start): 0.5329|0.3472|0.2169  0.2769[0.5331]0.4969  0.1012|0.5451|0.5428
Episode: 499000, Wins X: 782 (822), Losses X: 180, Draws: 38, Epsilon X: 0.0019, Q(start): 0.5315|0.3456|0.2200  0.2724[0.5288]0.4962  0.1074|0.5430|0.5417
Episode: 500000, Wins X: 780 (822), Losses X: 188, Draws: 32, Epsilon X: 0.0019, Q(start): 0.5310|0.3443|0.2219  0.2718[0.5285]0.4971  0.1044|0.5442|0.5446

Training complete.
Testing the agent (X against random O)...

Test Results (1000 games, Agent X vs random O):
Agent X Wins: 783
Agent X Losses (Random O Wins): 191
Draws: 26
In the initial stages of training, the agent, as expected, showed a lower win percentage and a higher number of losses/draws due to the opponent's first-move advantage. However, as training progressed, the agent significantly improved its performance.Example game after training:Example game after training (X vs random O):
-------------
|   |   |   |
-------------
|   |   |   |
-------------
| O |   |   |
-------------
X's Turn:
-------------
|   |   |   |
-------------
|   |   | X |
-------------
| O |   |   |
-------------
O's Turn:
-------------
|   |   |   |
-------------
| O |   | X |
-------------
| O |   |   |
-------------
X's Turn:
-------------
|   |   |   |
-------------
| O |   | X |
-------------
| O |   | X |
-------------
O's Turn:
-------------
|   |   |   |
-------------
| O |   | X |
-------------
| O | O | X |
-------------
X's Turn:
-------------
|   |   | X |
-------------
| O |   | X |
-------------
| O | O | X |
-------------
Game Over! Player X won!
"Win Growth (agent moves second)" graph:These results show that the agent successfully learned to optimally respond to various first moves by the opponent, significantly increasing its win rate despite the strategic disadvantage of moving second. The "first move selection" problem for the agent disappeared, as it focused on reactive tactics.The project on training a DQN agent for Tic-Tac-Toe successfully demonstrated the effectiveness of deep reinforcement learning algorithms even for simple deterministic games. We saw how the agent can adapt to different roles (first/second player) and achieve near-optimal performance against a random opponent.The most guaranteed way to make the agent learn "human" optimality (center, corners) is to train it against a stronger, strategic opponent (e.g., Minimax AI) or in self-play mode. These opponents will punish any suboptimal move, forcing the agent towards true optimality.Write in the comments if you are interested, and I will arrange a battle (a real fight) between two agents. For now, my immediate plans include a final "move" to Linux and writing a small backend (e.g., a REST API) for a simple client to try playing with what has been developed.]]></content:encoded></item><item><title>Revisiting My Old Neural Network Project in Go</title><link>https://dev.to/harun_alrasyid_d6c9f599c/revisiting-my-old-neural-network-project-in-go-37ep</link><author>Harun Al Rasyid</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 08:17:15 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[It was messy, naïve, and mostly forgotten in my GitHub. The goal was to better understand the internals of forward and backpropagation by implementing everything manually, without relying on external ML libraries. The code worked, but it was very basic and lacked in performance.Now, I’m revisiting this project to refactor the code and improve the overall design. Here’s a summary of what I’ve improved:The codebase already had a good separation of concerns: activation functions, loss, optimizers, and network logic were neatly organized into their own modules. This made it relatively easy to extend the library with new features.
  
  
  The Improvement : Parallel Training
To improve training efficiency, I implemented . Training data is split into multiple batches, each processed in a separate goroutine using .I used  to safely collect training errors and weight deltas from all batches.After all batches are processed, the deltas are merged using a custom  function and applied once at the end of the epoch.. Initial versions caused data races when multiple goroutines accessed or modified shared weight structures.: Delay all updates until after parallel computation finishes.Locking Can Kill Parallelism. Putting locks around weight updates inside each batch makes the process sequential. It removes the benefit of parallelism.: Do all mutation  goroutines have joined.Unstable Training Without Averaging. Summing raw deltas led to unstable error gradient.: Add delta average in  to stabilize learning.Training speed increased (especially for datasets like Iris).]]></content:encoded></item><item><title>Make C++ a better place #4: Go as an alternative</title><link>https://dev.to/pikotutorial/make-c-a-better-place-4-go-as-an-alternative-57ip</link><author>pikoTutorial</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 07:58:00 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[The Go programming language brings simplicity and a clear design philosophy that make it attractive for developers who are tired of the complexity of C++. In this article, we will explore the most interesting features of the Go language that distinguish it from C++.
  
  
  Producer/consumer implementation with Go
If you didn't see the first article of this series, please read it because I explained there what are the things I want to check about each C++ alternative and how I'm going to do that.Below you case see the implementation of the reference producer/consumer application written in Go. I really wanted this implementation to be based on channels (more on them at the end of the article) because it's a very interesting feature of Go, but because channels are by design meant to be used for one-to-one communication, they are not suitable for this use case.So accordingly to the list of checks that I'm interested in, Go gives us the following statistics: - this code is 106 lines long (124 lines for C++) - it takes 91ms to build this application (2149ms for C++) with command:
/usr/local/go/bin/go build  producer_consumer.go
 - it takes 2172ms to run it (597ms for C++) - 1.4MB (105kB for C++)
  
  
  What I like about this code?
In Go you don't need to specify size of the fixed-size array if you provide its elements during initialization. This is a very nice feature because whenever you want to change the content of the array, you just add or remove an element from the initialization list, without having to additionally change the size of the array.I love the fact that Go doesn't force me to create a thread, specify its worker, start it, wait for every thread to join separately etc. - if you have a function that you want to run asynchronously, you just call  and that's it.Go fails to build the program if a certain variable is not used. It's not a warning or a suggestion - you just won't get any executable binary out of such source code.Go allows to provide all the imports in form of a list, so I didn't need to repeat "import..." for every required element.
  
  
  What I don't like about this code?

  
  
  Consts not applicable to all types
I was not able to create e.g. a constant array because Go doesn't allow for that.It's not visible directly in the example, but Go's encapsulation relies on the naming convention - if something starts with a upper-case letter, it's public (available outside of the package) and if something starts with a lower-case letter, it's private (not visible form outside of the package). Although it solves the problem of having special keywords like ,  etc., I think it can sometimes be a pain in the ass because I imagine a situation in which I want to just change the visibility of the function to private and suddenly I need to change the name of the function in all places where it has been already used within the package.In the Producer/Consumer example code I use a variadic template to provide the constructor's arguments to  function depending on what worker type I am currently creating (Producer vs Consumer). Unfortunately, Go doesn't have that. I thought that I'll workaround that just by making some arguments having default values, so that I can provide only the ones which are relevant during creation of a specific worker. To my surprise, it turned out that Go doesn't allow function's argument to have a default value.Moreover, there's not even a built-in enum type which forces user to define enums in a pretty weird way, not fitting into the general simplicity of the Go language.
  
  
  Using Go to write C++ code for the existing code bases
Go compiles directly to the machine code, so there's no out-of-the-box way to generate C++ code out of it.
  
  
  Using existing C++ code in Go
Go does not allow to use C++ code within Go programs. There is Cgo, but it requires to wrap all the C++ functions in a C interface, so effectively it does not allow for usage of all C++ features. For example, our our reference C++ library user uses templates which are not supported in C. So for me, the final conclusion is that I just can't use the existing C++ code writing programs in Go.
  
  
  Other interesting Go features

  
  
  Concurrency - Go's main achievement
Every programming language has something what its developers put at the center of its philosophy. For Go, concurrency may be considered as such thing. It has a very interesting approach to concurrency and thread-safety summarized by the sentence:Do not communicate by sharing memory; instead, share memory by communicating. Go implements it by usage of channels which are Go's attempt to assure thread-safety by design and not by usage of synchronization primitives like mutexes. Channels may be considered shared resources (a channel may be as simple as a single integer value) which can be accessed only by one goroutine at a time. If you're a C++ programmer, you can see the channel as a combination of ,  and . Below you can find the code showing channels in action (notice also how simple it is to spin up a new thread-like execution flow just by adding  before the function call):Channels have their own -like statement which is called  in Go. It allows to react upon incoming data from multiple channels:I wondered if this point shouldn’t actually be at the top of the list because the situation with implicit conversions in C++ is so bad and so confusing for the beginners that I recently started to consider it as one of the most important features of the programming language. It's mainly because C++ claims to be a strongly typed language, which lets your guard down, but in reality you come across multiple situations in which the language behaves as if it doesn't care about the types. Here is an (abstract, but vivid example - I don't want to repeat boring examples with assigning  to a ) example of what I mean - this is a valid and working code in C++:Someone will say "hey, just add an  before the constructor and the compilation will fail" and it's true, but then I can ask what if something like this slips through the review:It compiles again. Now I hear voice saying (because I already heard such argument) that "it is not a bug because you see  type name explicitly written on the left of the  which is being initialized with , so it is basically a language feature and no implicit conversion here". Ok, let's then add a simple function to this code and tell me where do you see the  type name during the function call:The answer is: you don't. And remember that  class from the example can be arbitrarily complex type or can start some resource management directly in the constructor, so maybe you've just constructed a heavy communication proxy or a database connection broker directly out of an integer literal.My point is that there's just so many ways in C++ to trigger an implicit conversion that you must never forget about it. In Go the situation is simple - if you have any custom type definition, even a type which is basically an alias, like below:you must convert everything explicitly to that type.
  
  
  Uniform formatting with Gofmt
One of Go's standout features is its commitment to uniformity of code formatting. The language comes with a built-in formatter  that imposes a consistent style across all Go codebases. Unlike C++, where formatting styles can vary greatly from one team to another, Go enforces a common standard. This means that Go developers spend less time debating style guidelines and more time focusing on solving real problems.However, Go's formatting solution isn't perfect. For instance, it doesn't care much about line length or whitespaces, which means that two developers using  may still produce different source code.Go has only one way to write scope curly brackets after ,  etc. The opening curly bracket must be placed in the same line because otherwise the Go lexer may insert a semicolon after the statement changing its meaning, for example:In fact, the latter version won't even compile because the compiler will complain about an unexpected newline.One of Go’s interesting features is named return values, which allow you to name return variables directly in the function signature:By doing so, you can use  directly inside the function without explicitly declaring it again. This reduces boilerplate code and helps the code to be self-documented. The downside is that these named return values are zero-initalized to their default values, so it also allows to return value which was not modified during the function flow (so was not explicitly initialized to any particular value).However, I admit that this may be a concern brought from other programming languages, a concern that is not applicable to Go. Go actually encourages to design types accordingly to  rule meaning that the memory initialized with zeros translates to some valid state of the object (for example, a zeroed mutex translates to an unlocked mutex). That brings us to the next interesting concept in Go.
  
  
  Memory allocation:  vs. In Go, there are two ways to allocate memory:  and . These functions differ significantly from their similarly-sounding counterparts in C++ (, , ).The  function allocates memory for an object, but does not initialize it. I must admit that at the beginning for me, as a person used to C++, it was pretty confusing because in C++ you can't write the following code if  doesn't have a default constructor :The behavior of Go's  behaves more like such code:allocate memory for the objectget a pointer to such an allocated and initialized objectyou use composite literals (Go's constructors) like on the code snippet bellow:The  function is a totally different story, starting with the fact that it doesn't even return a pointer. If you come from outside of C++ world, you could ask , but if you're a C++ insider you see that the connection is obvious. Its usage is also limited to slices, maps and channels. All these types happen to carry a reference to a data structure that must be initialized before use what  is responsible for.
  
  
  Resource management with defer
Go gives the ability to defer a statement until the end of functions scope (similar as the scope guard statements in D). The deferred statements are deferred in form of a stack, so their execution order is reversed. It's helpful and definitely better then writing the same functions at the end of the scope, but as I mentioned in the article about D, I'm not a big fan of defer-like mechanisms because although it helps to not forget about releasing certain resource (e.g. after adding a new path to the function), it still must be manually typed in by the programmer who is responsible for remembering it, so we can be sure that sooner or later someone will forget about it anyway.Go differentiates between two types of errors: recoverable and unrecoverable. Recoverable error handling relies on multivalue returns because a function may return 2 values - the actual returned value and the associated error which can be checked by the caller before using the value. In contrast, unrecoverable errors, such as accessing out-of-bounds slices, trigger a , which immediately stops normal execution and begins stack unwinding. However, Go provides the  function (in my opinion, not the best name choice for the "unrecoverable" type of error handling) to regain control during the unwinding process. Because the only code that is able to run during stack unwinding is inside the deferred functions,  must be used inside of a deferred function as well.If the section  panics, the control flow will be regained by the  and error will be printed.]]></content:encoded></item><item><title>🕵️‍♂️ Stop guessing why your Go service is slow.</title><link>https://dev.to/aleksei_aleinikov/stop-guessing-why-your-go-service-is-slow-514h</link><author>Aleksei Aleinikov</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 07:27:32 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>⚡ Upgrade Your Go APIs to HTTP/2 in 2025 — Why You’re (Probably) Late</title><link>https://dev.to/aleksei_aleinikov/upgrade-your-go-apis-to-http2-in-2025-why-youre-probably-late-5dgc</link><author>Aleksei Aleinikov</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 07:21:54 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Browsers switched years ago. Your CDN speaks h2. But… your Go backend? Still whispering HTTP/1.1 like it’s 2010.What you’re missing out on:
✅ Multiplexed requests — no more Head-of-Line blocking
✅ Fewer connections — lower TLS handshake and socket overhead
✅ Automatic header compression — smaller packets, faster responses
✅ Happier users and lower cloud bills🧑‍💻 The upgrade? Usually just one line plus TLS.
🚀 The gain? Snappier APIs, smoother streams, leaner infra.👉 Check out a minimal working Go example (and see why a single ]]></content:encoded></item><item><title>⏰🐹 Parallel Tasks in Go 2025: Tame Your Timeouts &amp; Tickers Like a Pro</title><link>https://dev.to/aleksei_aleinikov/parallel-tasks-in-go-2025-tame-your-timeouts-tickers-like-a-pro-17i2</link><author>Aleksei Aleinikov</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 07:16:22 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Spawning 1,000 goroutines is easy. Managing them without chaos?That’s mastery.
✅ Semaphore channels cap concurrency cleanly
✅ Back-pressure lets you fail fast (no more silent queue pileups)
✅ time.After() for one-liner timeouts — no stuck clients
✅ time.NewTicker() keeps heartbeats flowing safely
✅ Reuse timers to save GC and stay lean under loadProtect APIs from flooding in millisecondsStop ghost pings with smart cancelsRun watchdogs without memory leaks]]></content:encoded></item><item><title>⚡🐹 Optimizing Go in 2025: Slices, Strings &amp; sync.Pool Mastery</title><link>https://dev.to/aleksei_aleinikov/optimizing-go-in-2025-slices-strings-syncpool-mastery-3plj</link><author>Aleksei Aleinikov</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 07:15:29 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Slices and strings in Go look simple — until they eat your RAM and GC pauses.✅ Pre-allocate with make([]T, 0, N) to skip hidden copies
✅ Use strings.Builder for clean, fast string joins
✅ sync.Pool = free GC breaks during traffic spikes
✅ Reuse buffers, reset with care, avoid race bugsFilter slices in place: filtered := events[:0] — no new allocsOne static HTML builder instead of 20 tiny buffersReuse JSON encoders to slash latency under loadTakeaway:
Know how slices grow, pick the right string concat method, and treat pools like sharp knives — powerful but dangerous.]]></content:encoded></item><item><title>2N3904 Transistor: Hogwarts’ Unyielding Wand for Circuits &amp; Cosmic Spells</title><link>https://dev.to/ersajay/2n3904-transistor-hogwarts-unyielding-wand-for-circuits-cosmic-spells-12ck</link><author>ersajay</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 07:04:29 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[The Leaky Cauldron’s Hidden Tool
On a drizzly afternoon in Diagon Alley, I ducked into Quality Wands & Oddments—a shop that sold more than just wands. Behind the display of Felix Felicis and Pensieves, the owner, Mr. Fizzlewick, held up a small, cylindrical device, no bigger than a Bertie Bott’s Every Flavor Bean.
“That’s a 2N3904 transistor,” he said, grinning. “Not flashy like a Lumos charm, but it’s the Ollivander’s wand of electronics—trusted by hobbyists, engineers, even NASA. Powers everything from LED strips to Mars rovers. Unyielding. Ubiquitous. Wizarding.”
Intrigued, I leaned in. This wasn’t just metal and silicon—it was a 2N3904, the unsung hero of circuits. Let’s unmask its magic.What Is a 2N3904? (A Workhorse, Not a Show Pony)
The 2N3904 is Hogwarts’ “NPN bipolar junction transistor” 🔧—a TO-92 package (think: a tiny, cylindrical wand core) built for general-purpose amplification and switching. Here’s its spellbook (specs):Voltage: 40V collector-emitter (VCEO)—unfazed by voltage storms (unlike Tarantallegra—messy, and unwanted).
Current: 200mA collector current (IC)—sips power like a Butterbeer sip, not a Firewhiskey chug.
Speed: 300MHz transition frequency (fT)—faster than a Knight Bus in reverse.Real-World Magic: Survives garage lab mishaps and Martian simulations. It’s the Disillusionment Charm of transistors: invisible, but essential.2N3904 Pinout: The Three Spells of a Wand
The TO-92 package has three pins—think of them as the “spells” that make it work:Emitter (E): The exit for electrons—where magic leaves the wand.
Base (B): The control gate—a flick of your wrist (or a small current) to start the flow.
Collector (C): The entry for electrons—where magic begins.Pro Tip: Face the flat side, and pins are E-B-C left to right. Mix them up, and your circuit becomes a Pyrotechnics spell gone wrong (smoke, sparks, and a “Oops”).The Datasheet: The 2N3904’s Magic Manual
Every wizard needs a Advanced Potion-Making book—for 2N3904, it’s the datasheet (grabbed from ON Semiconductor or STMicroelectronics). Key takeaways:Absolute Max Ratings: 40V, 200mA—exceed these, and it’s Finite Incantatem (game over).
DC Current Gain (hFE): 100-300—amplifies signals like Sonorus for electrons.
Thermal Limits: 200°C/W—don’t let it cozy up to power resistors (they’re Furnunculus-hot).Fun Fact: The “Typical Applications” section is a Marauder’s Map for hobbyists—plots paths from LED strips to insulin pumps.Why Wizards (Engineers) Swear by 2N3904
2N3904 isn’t a Elder Wand—it’s the Hedwig of transistors: reliable, affordable, and everywhere.Cost: $0.02/unit—cheaper than a Pumpkin Pastie (and way more useful).
Availability: Sold at Digi-Key, Amazon, even your local electronics shop—like Fizzing Whizbees in a candy store.
Versatility: Powers LED strips (keeping your dorm lit), insulin pumps (saving lives), and Tesla key fobs (stopping parking-lot tantrums).NASA Rovers: Survives -55°C Mars simulations (Duracell? Expelliarmus).
Your Garage Lab: Handles your DIY “I’ll fix it!” projects (even when you fry it).Swapping Spells: Can You Replace It?
Not all transistors are Unforgivable Curses—some are just different. Here’s who plays well with 2N3904:2N2222/2N2222A: Upgraded wands. Higher current (600mA) or voltage (75V)—great for muscle.
BC547: Weaker cousin. Lower current (100mA)—like a Wingardium Leviosa that fizzles.
2N3906: PNP polarity—reverse magic. Like a wand that casts Muffliato when you want Lumos.
2N7000 (MOSFET): Different magic type. Not a BJT—like using a broom for Apparition.Golden Rule: Match polarity (NPN/PNP) first—like matching wand cores. Then check specs.Wielding 2N3904 Like a Pro (No Burned Fingers)
Want to cast 2N3904 spells without chaos? Follow these steps:
Step 1: Calculate the Base Resistor (RB)
Formula: RB = (VCC - VBE) / IB
Think of it as measuring Polyjuice Potion—precision matters.
Step 2: Solder Carefully
No third-degree burns allowed. Use a steady hand, like repairing a Time-Turner.
Step 3: Test (and Pray)
If smoke appears, blame the datasheet (or your shaky soldering).
Pro Tip: For SMD designs, use MMBT3904—its pocket-sized twin (perfect for tiny spells).Where to Buy (Avoid Knockturn Alley Fakes)
In 2025, shop like a Gryffindor—no dodgy Knockturn Alley fakes:Trusted Sources: Digi-Key, Ersaelectronics—reliable as Madam Pomfrey.
Red Flags: eBay listings with stock photos and “100% Genuine!!” claims—they’re Gilderoy Lockhart in disguise.Price Range: $0.02/unit retail; cheaper in bulk (AliExpress, but verify suppliers!).The Future: 2N3904 in 2030 & Beyond
What’s next for our tiny wand?AI Gadgets: Powers AR glasses that don’t melt your face (no Incendio mid-meeting).
Smart Home Tech: Keeps your coffee maker from burning breakfast (no Fiendfyre at 7 AM).
Mic Drop: Hoard these now. Future retro gamers will trade Golden Snitches for your stash.Conclusion: The Unseen Guardian of Magic
2N3904 isn’t flashy. It doesn’t cast Expecto Patronum or brew Polyjuice Potion. But it’s the reason your LED strips glow, your insulin pump works, and Mars rovers send back photos.
Next time you hold one, whisper, “Thanks, little wand.” It’s the least you can do for a transistor that keeps the magic of modern life alive.Written by a witch who once fried a 2N3904 trying to power a toy broom. (Spoiler: It worked. Eventually.)
🔧 Some magic isn’t in wands—it’s in the tools that keep the world turning.]]></content:encoded></item><item><title>Your Servers Deserve Better: Meet Minexus, a Smart Admin Agent System in Go</title><link>https://dev.to/arhuman/your-server-deserves-better-meet-minexus-a-smart-admin-agent-system-in-go-41gn</link><author>arhuman</author><category>dev</category><category>go</category><category>devto</category><pubDate>Tue, 1 Jul 2025 00:48:30 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[
  
  
  Meet Minexus — A Modular, Distributed Admin System in Go
I was tired of managing my servers with brittle scripts, ad hoc SSH sessions, and clunky monitoring tools. So I built Minexus, a modular platform to monitor and control servers via secure agents, with Go and gRPC under the hood.To send a command to 50 machines and get results back fastTo build your own admin plugins with GoTo manage your servers like a well-oiled, distributed systemThen this might be up your alley.Minexus is made of 3 main components: — the central server, connected to a PostgreSQL DB — lightweight agents running on your hosts, communicating with the Nexus via gRPC + mTLS — an admin UI and command interface, also talking to the NexusMinions register periodically. Commands go through the Nexus, and results are logged/stored. Want a new command? Just write a command.It’s simple, extensible, and built for sysadmins/devops/devs who want control without vendor lock-in.Remote command execution (with return capture)Service restarts across hostsHealth checks / monitoring pluginsSecurity scans (CVE lookup, etc.)Anything you can plug into a Go module...Want to send restart-service nginx to all your production servers and get clean results in seconds? Minexus can do that.It's early days, but it’s usable and growing. Contributors welcome — the command system (soon a plugin system) makes it a playground for Go devs.You're not a coder, it's not a problem: I’d love 🙏 Feedback on the architectureSuggestions for useful commands/pluginsHelp testing on non-Linux environmentsIdeas to make this your go-to internal admin framework
  
  
  Let’s Build This Together
I believe sysadmin/devops tooling should be:If you agree, give Minexus a spin, drop a comment, or open an issue.]]></content:encoded></item><item><title>Go for JavaScripters: Why You Should Learn Golang</title><link>https://dev.to/brailyguzman/go-for-javascripters-why-you-should-learn-golang-1poo</link><author>Braily Guzman</author><category>dev</category><category>go</category><category>devto</category><pubDate>Mon, 30 Jun 2025 22:27:42 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[
Go for JavaScripters: Why You Should Learn Golang

Go vs JavaScript: Quick Comparison
Data Types

Structs, Types, Methods, and Interfaces

Strings, Bytes, and Runes

Strings (Immutable UTF-8)Runes (Unicode Code Points)Quick Comparison: JavaScript vs Go

Functions and Control Flow

Returning Multiple ValuesWorking with the strings PackageConcurrency in Go: Goroutines, Channels, WaitGroups, and MutexesConcurrency vs ParallelismCommon Gotchas for JS DevsMini Project: Word Counter CLIGo Modules & Project StructureSimple HTTP Server ExampleJavaScript to Go: Quick Reference Cheat SheetAre you a JavaScript developer looking to expand your backend skills, or just curious about a language that powers Docker, Kubernetes, and much of the modern cloud? Meet  (aka Golang): a language created at Google by Ken Thompson, Rob Pike, and Robert Griesemer to make software development fast, fun, and scalable.Go is designed for simplicity, speed, and reliability. It compiles to a single binary, has a powerful standard library, and makes concurrency (doing many things at once) a breeze. If you love JavaScript's flexibility but crave more performance and predictability, Go is a perfect next step.How Go compares to JavaScript in syntax and philosophyGo's type system, variables, and data structuresHow to handle strings, bytes, and runes (Unicode!)Using Go's  package for text manipulationGo's powerful concurrency model (goroutines, channels, and more)Common pitfalls for JS devs switching to GoHow to build and run Go codeIf you're a JavaScript developer looking to level up with a fast, modern language built for performance and scalability, it's time to meet Go. is a middle-level programming language created at Google in 2007 by engineers who were tired of waiting around for their code to compile and dealing with overly complex systems. The result? A language that combines the performance of C (low-level) with the simplicity and readability of Python (high-level).
  
  
  Go vs JavaScript: Quick Comparison
APIs, infra, CLI, serversGo shines when it comes to building fast, scalable backend systems. It's a top choice for writing APIs, web servers, CLI tools, and infrastructure-level software. Tools like , , and  are all written in Go, which says a lot about its speed and reliability.One of Go's biggest superpowers is , the ability to run multiple tasks at the same time. In JavaScript, we use  and the event loop to handle asynchronous operations. In Go, we use goroutines, lightweight threads that are easy to spawn and manage.Go also makes deployment a breeze. While Node.js apps often require npm install, package.json, and a dozen dependencies, Go compiles everything into a single binary file you can just drop on a server and run.Front-end/browser-based developmentRapid prototyping with lots of UIProjects needing generics-heavy data structures (though Go 1.18+ now supports generics, it's not as flexible as TypeScript)Go might not be ideal for:Projects that require a lot of dynamic typing or runtime type changes (Go is statically typed and not as flexible as JavaScript or Python for dynamic data structures).Codebases that rely heavily on advanced generics or metaprogramming (Go's generics are intentionally simple and less expressive than those in TypeScript, Rust, or C++).Rapid prototyping where developer speed and a huge ecosystem of libraries (like npm for JS or PyPI for Python) are critical. Go's ecosystem is strong but not as broad for every domain.Projects where you need mature, specialized libraries for things like data science, machine learning, or scientific computing (Go's ecosystem is growing, but not as deep as Python's in these areas).Teams that require hot-reloading, scripting, or embedding code at runtime (Go is compiled and not designed for scripting or live code changes).Go is statically typed, so once a variable has a type, it can't be reassigned to something else, no switching  from a number to a string like in JS.Unlike JavaScript, which uses a single  type for all integers, Go provides several distinct integer types. Each type has its own range and memory usage, allowing you to choose the most appropriate one for your needs.-2.1 billion to 2.1 billion-9 quintillion to 9 quintillionplatform dependent (usually 32 or 64 bits)platform dependent (unsigned version of int)For example, if you need to store an RGB (Red, Green, Blue) value ranging from 0 to 255, the best choice is  (an unsigned 8-bit integer), since it efficiently covers exactly that range. If you need to store larger values, simply choose an integer type with a bigger bit size, such as , , or , depending on your requirements. will default to 32 or 64 bits depending on your system. types don't allow negative numbers but give you more room for positive values.Go will catch integer overflows at compile time, not at runtime.
This compiles but causes weird behavior:7 digits (single precision)15 digits (double precision — default)Warning: Precision loss can happen with  when dealing with very large or very small decimal values.In Go, arrays have  and contain elements of a single type.You can also let Go infer the length:Arrays are . Assigning or passing them copies the whole array.Their size is part of their type ( != )Slices are more flexible and commonly used than arrays.You can create a slice from an array:You can also use  to create a slice with a given length and capacity:Slices are , so modifying one will affect the original array:
  
  
  Structs, Types, Methods, and Interfaces
Go uses structs to group related data together, similar to objects in JavaScript. You can also define methods on types (including structs) to add behavior.Interfaces in Go define a set of method signatures (behavior) that a type must implement. Any type that provides those methods "satisfies" the interface, even if it doesn't explicitly declare that it does. This allows you to write flexible and decoupled code, because functions can accept interfaces rather than concrete types. Interfaces are a key part of Go's approach to polymorphism and code reuse.Duck typing is a concept where the type or class of an object is determined by its behavior (methods and properties), not by explicit inheritance or declaration. The phrase comes from "If it walks like a duck and quacks like a duck, it's a duck." In Go, any type that implements the methods required by an interface is considered to satisfy that interface, even if it doesn't explicitly declare it. This is similar to how JavaScript objects can be passed to functions as long as they have the expected methods or properties.Interfaces Example (Multiple Types):
JavaScript doesn't have interfaces, but you can use objects with the same method signatures (duck typing):
  
  
  Strings, Bytes, and Runes
In , strings are sequences of UTF-16 code units. This usually feels like characters but isn't always, especially with emojis or characters from other languages.In , strings are UTF-8 encoded immutable slices of bytes. That means:A string is a sequence of bytes.Characters can take up multiple bytes.Indexing directly gives you a , not a character.
  
  
  Strings (Immutable UTF-8)
Each character in  might take 1-3 bytes.Strings are immutable. You  change characters via indexing.Accessing bytes (not characters):A  is an alias for , just a number from 0-255. lets you inspect or manipulate the underlying raw data of a string.

  
  
  Runes (Unicode Code Points)
A  in Go is an  representing a full Unicode character, even emojis and symbols from non-Latin scripts.Useful when dealing with , not bytes.Can handle multi-byte characters like emoji properly.
Use a  to  properly:
  
  
  Quick Comparison: JavaScript vs Go
 → 4utf8.RuneCountInString(str)
  
  
  Functions and Control Flow
In Go, you must declare the type of each parameter and the return value. The function block is enclosed by  just like JS.
  
  
  Returning Multiple Values
Go functions can return more than one value, which is commonly used for returning a result and an error.In JavaScript, you might return an object or array to simulate multiple return values:Go uses familiar  logic but requires the conditions to evaluate to a , no more truthy/falsy magic like in JS.Go uses pointers to reference memory locations, similar to C, but without pointer arithmetic. Pointers are useful for modifying values in place and for efficient memory usage. means "pointer to an int". gets the address of . dereferences the pointer to access the value.
JavaScript does not have pointers, but objects and arrays are passed by reference:Go has only one loop keyword: .You can also use it like a  loop:The  keyword is used to iterate over elements in a variety of data structures, including arrays, slices, maps, and strings. When iterating over a string,  yields the index and the Unicode code point (rune) at each position.Example: Iterating over runes in a stringThis will print each Unicode character (rune) in the string, including multi-byte characters like emojis.
  
  
  Working with the strings Package
Go's standard library includes the powerful  package for manipulating text. Here are some common tasks:
  
  
  Concurrency in Go: Goroutines, Channels, WaitGroups, and Mutexes
Go's concurrency model is one of its superpowers. Unlike JavaScript's single-threaded event loop, Go lets you run multiple tasks at the same time using goroutines and channels.
  
  
  Concurrency vs Parallelism
 is about dealing with lots of things at once (structuring your program to handle multiple tasks that may not actually run at the same time). is about doing lots of things at the same time (actually running on multiple CPU cores).Go makes it easy to write concurrent code, and if your machine has multiple cores, Go can run goroutines in parallel too.A goroutine is a lightweight thread managed by the Go runtime. Just add  before a function call to run it concurrently:Channels let goroutines communicate safely: sends a value into the channel. receives a value from the channel.A  lets you wait for a group of goroutines to finish:A  is used to safely share data between goroutines: Without it, multiple goroutines could try to update  at the same time, causing race conditions.The  keyword in Go schedules a function call to run after the function completes, just before it returns. This is especially useful for cleanup tasks like closing files, unlocking mutexes, or printing final messages.If you use multiple  statements, they run in LIFO (last-in, first-out) order:Closing files or network connectionsLogging or printing final messages
JavaScript doesn't have a direct equivalent, but you might use  in a  block for similar cleanup:
  
  
  Common Gotchas for JS Devs
No implicit type coercion: Go won't convert types for you.  is an error, not . Uninitialized variables have a default value (e.g.,  for int,  for string,  for pointers/slices/maps). Go uses explicit error returns, not try/catch. All variables must be declared before use.No unused imports or variables: The compiler will error if you import a package or declare a variable and don't use it. Use structs and interfaces instead.No method overloading or default parameters.
  
  
  Mini Project: Word Counter CLI
Let's build a simple CLI tool that reads a line of text from the user, counts the number of words and unique words, and prints word frequencies. This demonstrates string manipulation, maps, and user input.Why not use  for user input? is best for simple, space-separated input (e.g., numbers or single words), but for names or sentences,  is preferred because it reads the whole line, including spaces.  will only read up to the first space.
  
  
  Go Modules & Project Structure
Go uses modules to manage dependencies. To start a new project:go mod init github.com/yourusername/yourproject
Typical Go project structure:myproject/
  go.mod
  main.go
  pkg/      # reusable packages
  internal/ # private packages
Go does not use exceptions. Instead, functions that can fail return an  as a second return value:
  
  
  Simple HTTP Server Example
Go makes it easy to spin up a web server:
  
  
  JavaScript to Go: Quick Reference Cheat Sheet
Multiple return values + Go is a modern, efficient, and fun language that empowers JavaScript developers to build fast, scalable, and reliable backend systems. With its simple syntax, powerful concurrency model, and robust standard library, Go is a fantastic next step for anyone looking to level up their programming skills.If you’re comfortable in JavaScript, you’re more ready for Go than you think. The syntax is different, but the logic and problem-solving skills you’ve built in JS will serve you well.Ready to try Go? Dive into the resources above, experiment with the examples, and start building something awesome. Happy coding! 🚀Have questions or feedback? Feel free to reach out or leave a comment!]]></content:encoded></item><item><title>You Don&apos;t Know iota</title><link>https://dev.to/leapcell/you-dont-know-iota-2c9b</link><author>Leapcell</author><category>dev</category><category>go</category><category>devto</category><pubDate>Mon, 30 Jun 2025 17:42:17 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[When you delve into official libraries, open-source libraries, or any Go project, you’ll find the magical identifier  everywhere. It plays an important role, making code more concise and clear, while improving readability and maintainability. Its applications are wide-ranging, from enumerated types to bit operations, and even complex constant expression calculations—it can do it all.In this article, I will take you on an in-depth exploration of the magical power of , including an introduction to , its use cases, practical tips, and important considerations.Within a constant declaration, the predeclared identifier iota represents successive untyped integer constants. Its value is the index of the respective ConstSpec in that constant declaration, starting at zero.The above quote is from the official documentation. In short, by using , we can automatically create a series of consecutive integers in constant declarations, starting from zero, without manually specifying the value for each constant.
  
  
  Automatically Generating Incrementing Constant Values
With , it’s easy to generate incrementing constant values. The first constant using  in a constant declaration is initialized to 0, and subsequent constants automatically increment, making it unnecessary to specify the value of each constant manually when defining a series of incrementing constants. This improves code readability and maintainability. For example:
  
  
  Defining Enumerated Type Constants
By using , you can easily define a series of related enumerated values without having to manually specify the number for each value. This makes the enumeration type definitions more concise and easier to extend or modify. For example:By using  within constant declarations, you can create complex expressions and adjust the value of  as needed in each constant declaration. This allows you to easily generate a set of constants that follow a specific pattern. For example:By combining the left shift operator () with , you can conveniently generate a set of constants for bitwise operations. For example:
  
  
  Tips and Considerations When Using iota
We can use the underscore () to ignore certain values, for example:
  
  
  iota Is Independent in Different Constant Blocks
The scope of  is the entire constant block. The  in different constant blocks is independent, and the value of the first  in each block is always 0.This article provided a detailed introduction to . By fully leveraging the features of  in your code, you can make your code more concise and clear, while also improving readability and maintainability.Leapcell is the Next-Gen Serverless Platform for Web Hosting, Async Tasks, and Redis:Develop with Node.js, Python, Go, or Rust.Deploy unlimited projects for freepay only for usage — no requests, no charges.Unbeatable Cost EfficiencyPay-as-you-go with no idle charges.Example: $25 supports 6.94M requests at a 60ms average response time.Streamlined Developer ExperienceIntuitive UI for effortless setup.Fully automated CI/CD pipelines and GitOps integration.Real-time metrics and logging for actionable insights.Effortless Scalability and High PerformanceAuto-scaling to handle high concurrency with ease.Zero operational overhead — just focus on building.]]></content:encoded></item><item><title>Golang</title><link>https://dev.to/weiming77/golang-2bli</link><author>weiming77</author><category>dev</category><category>go</category><category>devto</category><pubDate>Mon, 30 Jun 2025 12:33:20 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Go CLI Mastery: Crafting Developer Tools That Don&apos;t Suck</title><link>https://dev.to/tavernetech/go-cli-mastery-crafting-developer-tools-that-dont-suck-3p53</link><author>Taverne Tech</author><category>dev</category><category>go</category><category>devto</category><pubDate>Mon, 30 Jun 2025 10:37:31 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[The Foundation: Setting Up Your CLI ArchitectureBuilding Your CLI Masterpiece: Subcommands and Advanced FeaturesPro Tips & Distribution: Making Your CLI Tool Production-Ready
Picture this: You're a developer, and your terminal is your kingdom. You've got 47 different CLI tools installed, but somehow, half of them feel like they were designed by someone who's never actually used a command line. The flags make no sense, the help text is either non-existent or a novel, and don't even get me started on the error messages! 😤But here's the thing – Go has quietly become the undisputed champion of CLI tool development. Docker, Kubernetes kubectl, Hugo, and countless other tools that make our dev lives easier are all built with Go. Why? Because Go combines the performance of compiled languages with the simplicity that makes developers actually want to use your tools.Today, we're diving deep into the art and science of building CLI tools that developers will not only use but actually  using. Buckle up, gophers! 🐹
  
  
  1. 🏗️ The Foundation: Setting Up Your CLI Architecture
Let's start with a confession: building CLI tools used to be like assembling IKEA furniture blindfolded. You'd spend more time parsing flags than actually solving problems. Thankfully, the Go ecosystem has evolved, and we now have tools that make CLI development feel less like archaeology and more like actual engineering. – the dynamic duo of Go CLI development. Here's a lesser-known fact: Cobra was originally created by Steve Francia (spf13), the same genius behind Hugo. The framework powers some of the most popular CLI tools in existence, and there's a good reason for that.: Notice how we're using both short () and long () flags? This isn't just good practice – it's respecting your users' muscle memory. Some folks are  people, others prefer . Why force them to choose sides in the CLI wars?The beautiful thing about this setup is that Viper automatically handles environment variables, config files, and command flags in order of precedence. Your users can configure your tool however they want, and you don't have to write a single line of additional parsing code. It's like having a personal assistant for configuration management! 🎩
  
  
  2. 🛠️ Building Your CLI Masterpiece: Subcommands and Advanced Features
Now that we've got our foundation, let's build something that would make even the most jaded senior developer nod in approval. CLI tools are like Swiss Army knives – everyone needs one, but half the features remain mysterious unless you design them intuitively.Here's where most CLI tools fail: they treat subcommands like an afterthought. But in Go with Cobra, subcommands are first-class citizens. Let's build a practical example – a developer productivity tool:Here's a : The  package we're using was inspired by the realization that 68% of developers spend more time reading CLI output than writing code. Good visual feedback isn't just pretty – it's a productivity multiplier! in this example is the combination of: (Git is enabled by default because, come on, it's 2025) (no more cryptic "error: invalid input" nonsense) with colors and emojis that actually explains what went wrong
The magic here is  – your CLI starts simple but grows with your users' expertise. Beginners can use  and get something that works. Power users can dive into project create myapp --lang rust --ci --template microservice when they're ready.
  
  
  3. 🚀 Pro Tips & Distribution: Making Your CLI Tool Production-Ready
Alright, you've built an awesome CLI tool. It works on your machine (famous last words, right?). Now comes the real challenge: making it work everywhere and making it easy for people to actually get their hands on it.Here's a lesser-known fact that'll blow your mind: Go's static compilation means your CLI tool can run on systems where the user has never even heard of Go. This is huge! While Python developers are explaining virtual environments and Node.js folks are debugging npm conflicts, you just hand someone a binary and say "run this."Testing CLI apps is like teaching your pet to fetch – lots of repetition, but when it works, it's magical. The key is testing both the happy path and the "what happens when users inevitably do something unexpected" path.Now, let's talk about  – because the best CLI tool in the world is useless if nobody can install it:But here's the : Use GitHub Actions to automate this process and create releases automatically: Set up Homebrew distribution for macOS users:The irony? You'll spend more time setting up the distribution pipeline than building the actual CLI tool. But that's the price of making software that people can actually use without a PhD in dependency management! 😂We've journeyed from the basics of Cobra and Viper to building production-ready CLI tools that developers will actually want to use. The key takeaways? Respect your users' intelligence, provide sensible defaults, give helpful feedback, and make installation painless.The Go ecosystem has matured to the point where building professional CLI tools is no longer the domain of systems programming wizards. With the right frameworks and practices, you can create tools that feel as polished as the best commercial software.Here's the thing: every great developer tool started as someone's side project to solve their own problem. Docker began as a deployment tool for dotCloud. Kubernetes started as Google's internal orchestration system. Your next CLI tool might just be the one that changes how developers work.So, what CLI tool will you build next? Will it be the project generator that finally makes sense? The deployment tool that doesn't require a manual? The debugging assistant that actually assists? The terminal is your canvas, and Go is your brush 🎨Share your Go CLI creations in the comments – I'd love to see what the community builds with these techniques! And remember, the best CLI tool is the one that makes other developers' lives just a little bit easier.]]></content:encoded></item><item><title>Stop Wrestling with Config Files: A DevOps Guide to Sanity with Konfigo</title><link>https://dev.to/bogdan_bododumitrescu_/stop-wrestling-with-config-files-a-devops-guide-to-sanity-with-konfigo-1hh3</link><author>Bogdan “Bodo” Dumitrescu</author><category>dev</category><category>go</category><category>devto</category><pubDate>Mon, 30 Jun 2025 07:53:57 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[As a DevOps engineer, you've probably felt the pain of managing configuration files. You've got JSON, YAML, TOML,  files, and maybe even some custom formats you'd rather not talk about. You're juggling configs for different environments (dev, staging, prod), and trying to keep everything in sync is a nightmare. What if I told you there's a better way?Enter Konfigo, a powerful command-line tool that's about to become your new best friend.Konfigo is a versatile configuration management tool that helps you streamline your entire configuration workflow. It reads various configuration file formats, merges them intelligently, and processes the combined data against a user-defined schema for validation, transformation, and even batch output generation.Think of it as a Swiss Army knife for your configuration files. 🇨🇭Here are some of the key features that make Konfigo a game-changer for DevOps: JSON, YAML, TOML, and  files are all supported. No more converting files by hand! Intelligently merges multiple configuration sources, respecting order and immutability rules.Powerful Schema Processing: Inject dynamic values from environment variables, dedicated variable files, or schema defaults. Create new configuration values (e.g., , , , ). Modify keys and values (e.g., , , , , , , , ). Enforce rules (, , , , , , ). Use the  directive in a variables file to generate multiple tailored configuration outputs from a single schema and run.Environment Variable Integration: Override any configuration value directly using environment variables.
  
  
  Why Should a DevOps Person Care? 🤷‍♀️
Okay, so Konfigo has a lot of features. But how does it actually make your life easier?
  
  
  Tame the Multi-Headed Hydra of Configuration Formats
Let's say you have a base configuration in YAML, but your production environment requires some overrides from a  file. With Konfigo, you can merge them with a single command:konfigo  base.yaml,prod.env No more writing custom scripts to parse and merge different formats. Konfigo handles it all for you.
  
  
  Automate Your Configuration Workflow
You can integrate Konfigo into your CI/CD pipelines to generate environment-specific configurations on the fly. For example, you can have a base configuration and then apply environment-specific overrides from different files.Here's a conceptual example of how you might use Konfigo in a CI/CD pipeline:
  
  
  Prevent Configuration Drift
Configuration drift is a major source of headaches in any infrastructure. With Konfigo's schema validation, you can enforce a consistent structure and set of rules for your configurations.For example, you can create a schema that requires a specific key to be present, or that a value must be a number within a certain range. If a configuration doesn't match the schema, Konfigo will throw an error, and you can catch the problem before it ever reaches production.
  
  
  Dynamic Configurations are Your Friend
Stop hardcoding values in your configuration files! With Konfigo, you can use variables and data generation to create dynamic configurations.For example, you can use an environment variable to set the database host, or you can use the  generator to add a build timestamp to your configuration.konfigo  config.json  schema.yml  staging-vars.yml  staging_config.json
If you're managing configurations for a microservices architecture or a multi-tenant application, you know how complex it can get. Konfigo's batch processing feature can help you simplify this.You can create a template configuration and then use a variables file to generate multiple tailored configurations for each service or tenant.Let's look at a simple example of how Konfigo can be used to validate and transform a configuration file.konfigo  config.json  schema.yaml In this example, Konfigo does two things: the input to ensure that  is at least 1024. the input by adding the prefix  to the  key.
  
  
  Ready to Give it a Try? 🚀
I've only scratched the surface of what Konfigo can do. If you're tired of wrestling with configuration files, I highly recommend giving it a try.Let me know what you think in the comments below! 👇]]></content:encoded></item><item><title>BC847 Transistor: The Tiny Star-Keeper of Our Tech Planets</title><link>https://dev.to/ersajay/bc847-transistor-the-tiny-star-keeper-of-our-tech-planets-31p4</link><author>ersajay</author><category>dev</category><category>go</category><category>devto</category><pubDate>Mon, 30 Jun 2025 06:23:12 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[A Meeting in the Circuit Desert
The desert stretched endlessly, its sands glowing like gold under the sun. I was tracing the dunes, heading toward a distant oasis, when I spotted a glint in the sand—a small, silver shape, no bigger than a ladybug.
“You’re… very small,” I said, kneeling.
“And you’re a child who talks to transistors,” it replied, voice steady as the wind. “But some keepers of light are smallest when they’re strongest. Ask the fox.”
It was a BC847—an NPN bipolar junction transistor, but to me, it felt like a secret. Let me tell you its story.What Is a BC847? (Not Just Metal—A Keeper of Light)
This was no ordinary silicon. It was a BC847, a tiny hero in a SOT-23-3 suit—smaller than a ladybug, but tough as a baobab’s roots. Here’s its secret:Voltage: 45V collector-emitter (VCEO), 5V base-emitter (VBE). It’s like a windbreak for circuits—sturdy against storms of static.
Current: 100mA collector current (IC), 5mA base current (IB). Sips power like a hummingbird, not a thirsty camel.
Speed: 100MHz transition frequency (fT). Faster than the fox darting across the dunes.Real-World Magic: Powers LED drivers in Philips Hue bulbs (keeping your roses lit) and Tesla’s battery sensors (guiding spaceships on Earth).
“Why so quiet?” I asked.
“Keepers don’t shout,” it said. “They just keep.”BC847 & Its Neighbors: Brothers, Not Twins
In the desert of transistors, BC847 has cousins—some taller, some faster, but none quite like it:BC846: A stronger brother. Handles 65V (vs. BC847’s 45V) but same current. Like a cactus that grows taller, not wider.
BC547: An old friend. Cheaper, but bulkier (TO-92 vs. SOT-23). Like a postman with a big bag—reliable, but takes up space.
2N3904: A flashy neighbor. Faster, but panics at voltage spikes. Like a sprinter who trips at the finish line.Roast Alert:
2N3904 (boasting): “I’m cheaper!”
BC847 (calm, like the fox): “I’m in Tesla’s BMS. You’re in a kid’s science kit. Bye.”Why BC847 Shines Brighter Than Most
BC847 isn’t just a transistor—it’s a star in the circuit sky. Here’s why:Tiny, But Tenacious: SOT-23-3 fits wearables and IoT sensors, like a key in a tiny lock. Even the fox couldn’t squeeze into spaces this small.
Speed of Light: 100MHz fT processes signals faster than your Wi-Fi rage-quits. The fox? He’s impressed.
Cheap, But Charming: $0.02/unit—cheaper than your morning espresso. Even the rose, who’s picky, approves.“Why not be bigger?” I asked.
“Big things break,” it said. “Tiny things fit. In smartwatches. In Mars rovers. In insulin pumps.”BC847: Keeper of a Thousand Stars
From your wrist to the cosmos, BC847 guards:Medical (The Healer’s Planet):
Powers portable ECG monitors, amplifying weak heart signals (no “404 Error: Heartbeat”). Keeps insulin pumps precise—because roses (and diabetics) need gentle care.Automotive & Aerospace (The Cosmic Planets):
Monitors Tesla’s battery cells (no TikTok fire memes—phew!). Survives cosmic radiation in satellites (Earth drama is overrated, anyway).Consumer Tech (Your Daily Planet):
Powers smartwatch sensors, outlasting your gym motivation. Keeps wireless earbuds jamming—because even foxes need their Hotline Bling.“Do you get lonely?” I asked.
“No,” it said. “I’m everywhere. In your watch, in your car, in the stars. Loneliness is for roses that forget they’re loved.”Brand Battle: The Guardians of the Desert
Not all keepers are made equal. Let’s meet the ones worth trusting:Nexperia: The geographer of transistors. Makes high-speed BC847W variants—pricier ($0.05/unit), but worth it for precision.
ON Semiconductor: The cactus of the bunch. Works from -40°C (Arctic) to +150°C (Sahara). Bulk orders only, but tough as nails.
Guangzhou Guangxin: The friendly merchant. Budget-friendly ($0.02/unit), but skip if you need fancy datasheets.Pro Tip: For Mars rovers, stick to ON Semi’s BC847HR (-55°C rated). Even the stars trust it.How to Find Your BC847 (Avoid the Baobabs of Fakes)
In 2025, shop like a wanderer—no baobab-sized fakes:Retailers: Digi-Key, Ersaelectronic. Search “BC847 SOT-23”—they’ll guide you like the desert’s wind.
Bulk Orders: Alibaba, with verified suppliers like Guangzhou Guangxin. Bargain like a merchant, but check for laser-etched logos (stickers = baobabs).Price Range: $0.02–$0.10/unit retail; $0.015/unit for 1k+ (AliExpress).The Secret of the Tiny Keeper
BC847 isn’t flashy. It doesn’t need a name in lights or a viral meme. It’s the kind of friend you remember when your smartwatch works, your Tesla doesn’t catch fire, or a Mars rover sends back photos.
“What makes you special?” I asked, as I left.
It didn’t answer. It just sat there, quiet as the desert, as the stars, as time itself.
And I realized—some keepers don’t need to be big. They just need to shine.Written by a wanderer who once mistook a BC847 for a ladybug. (Spoiler: It didn’t fly, but it powered a toy robot. Close enough.)
🌵 You become responsible, forever, for the stars you once overlooked.]]></content:encoded></item><item><title>การสร้าง Docker Image สำหรับ Go ให้เหมาะกับ Production</title><link>https://dev.to/somprasongd/kaarsraang-docker-image-samhrab-go-aihehmaaakab-production-529b</link><author>Somprasong Damyos</author><category>dev</category><category>go</category><category>devto</category><pubDate>Mon, 30 Jun 2025 04:09:10 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[แนวทางสร้าง Go container image ที่ เล็ก ปลอดภัย deploy ง่าย และ maintain ได้ระยะยาวเมื่อพัฒนาแอปพลิเคชันด้วยภาษา Go หนึ่งในจุดเด่นที่สำคัญคือการสร้างไฟล์ไบนารีแบบ static ทำให้เหมาะอย่างยิ่งสำหรับนำไปบรรจุใน Docker container ที่มีขนาดเล็กและปลอดภัย ซึ่ง Alpine Linux เป็นฐานที่คนนิยมใช้เพราะขนาดเล็กและมีแพ็กเกจพื้นฐานเพียงพอสำหรับงานส่วนใหญ่แต่การจะทำให้ container ขนาดเล็กและพร้อมใช้จริงใน production ต้องเข้าใจประเด็นสำคัญทั้งในแง่ของ build, dependency, และการจัดการ image ให้มีความเสถียรและปลอดภัย
  
  
  ปิด cgo (CGO_ENABLED=0) เพื่อสร้าง static binary
โดยปกติ Go จะเปิดใช้ cgo เป็นค่าเริ่มต้นหากโค้ดมีการเรียกไลบรารี C หรือใช้ฟังก์ชันมาตรฐานบางส่วนที่อ้างอิง libc ซึ่งอาจทำให้ไฟล์ไบนารีต้องพึ่งพา shared library ภายนอก เช่น glibc หรือ muslเมื่อใช้ Alpine ซึ่งใช้ musl libc แทน glibc ปัญหาที่พบบ่อยคือไฟล์ไบนารีที่พึ่ง glibc จะรันไม่สำเร็จ หากต้องการความแน่นอนว่ารันได้ทุกที่บน Linux base image ควรตั้ง  เพื่อให้ Go สร้างไฟล์ไบนารีที่ลิงก์แบบ static ทั้งหมด ลดปัญหา dependency ภายนอก
  
  
  ลดขนาดไฟล์ด้วย ldflags "-s -w"
ตัวเลือก  เป็นอีกเทคนิคที่ใช้กันทั่วไปเพื่อลดขนาดไฟล์ที่ได้จาก  จะตัด symbol table ซึ่งไม่จำเป็นต่อการรันจริง จะตัดข้อมูลสำหรับการ debug (DWARF)ผลคือขนาดไฟล์จะลดลงได้หลาย MB แต่ข้อควรระวังคือ หากต้องใช้เครื่องมือ debug เช่น Delve ข้อมูลเหล่านี้จะหายไป ทำให้ debug ได้ลำบากขึ้น เทคนิคนี้จึงเหมาะสำหรับ build ไบนารีที่ใช้จริงใน production เท่านั้น
  
  
  ทำไมไม่ควรใช้ alpine:latest
หลายคนมักเขียน Dockerfile ว่า  เพราะง่าย แต่ในทางปฏิบัติ นี่เป็นสิ่งที่ควรหลีกเลี่ยง เนื่องจาก tag  ไม่ได้ผูกกับ version ใด ๆ แบบตายตัว ภายใน repository อาจอัปเดตเมื่อใดก็ได้โดยไม่ประกาศล่วงหน้า ซึ่งทำให้ build ครั้งถัดไปอาจได้ base image ที่ไม่เหมือนเดิมและอาจเกิดปัญหาใหม่โดยไม่รู้ตัวแนวทางที่ควรทำคือระบุเวอร์ชันให้ชัดเจน เช่น  เพื่อให้แน่ใจว่าผลลัพธ์ reproducible และ rollback ได้ง่ายหากเกิดปัญหา
  
  
  ใช้ Multi-Stage Build เพื่อลดขนาดและจัดการได้ง่าย
Dockerfile สำหรับ Go ที่ดีควรแยกขั้นตอน build ออกจากขั้นตอน runtime โดยใช้ multi-stage build ขั้นแรกใช้ image  สำหรับ compile โค้ด ขั้นถัดไปใช้  หรือแม้แต่  เพื่อลดขนาด imagego mod download
go build  /app/app ./cmd/api/main.go

apk add  ca-certificates tzdata  addgroup  appgroup  adduser  appuser  appgroup

อีกหนึ่งจุดที่หลายคนมองข้ามคือ user ที่ container ใช้รันโปรเซส เริ่มต้น container จะรันด้วย root ซึ่งถ้าเกิดช่องโหว่ ผู้โจมตีอาจใช้สิทธิ root ภายใน container เพื่อโจมตีต่อได้ง่ายวิธีแก้คือสร้าง user สิทธิจำกัด แล้วสั่งให้ container รันด้วย user นี้แทน การเพิ่มบรรทัด  และ  ใน Dockerfile เป็นวิธีปฏิบัติมาตรฐานที่ช่วยปิดความเสี่ยงนี้ได้ดีหลายคนสับสนระหว่าง  และ  ว่าควรใช้แบบไหน ต่างกันอย่างไร ใช้กำหนด  ที่ container ต้องรันเสมอ ไม่ว่าผู้ใช้จะสั่ง  พร้อม argument อะไร คำสั่งนี้จะถูกเรียกเสมอ โดย argument ที่ตามมาจะถูกต่อท้าย ใช้กำหนด  ถ้า  ไม่ได้ระบุ argument ใหม่ ระบบจะใช้ค่าใน  แทน แต่ถ้าผู้ใช้ระบุ argument ใหม่ทั้งหมด  จะถูกแทนที่ทันทีกรณีนี้ หากรัน  จะได้  ถ้ารัน  จะได้ การใช้  แบบ exec form () ยังช่วยให้โปรเซสของเราทำงานเป็น PID 1 โดยตรง ทำให้จัดการ signal ได้ถูกต้อง โดยเฉพาะ SIGTERM ซึ่งสำคัญต่อการทำ graceful shutdown ใน production
  
  
  สรุปแนวทาง Production Docker Image สำหรับ Go
ปิด cgo () เพื่อสร้างไฟล์ staticใช้  เพื่อลดขนาดไฟล์ระบุ base image version ชัดเจน เช่น  อย่าใช้ แยกขั้น build ออกจากขั้น runtime ด้วย multi-stage buildสร้าง non-root user เพื่อลดความเสี่ยงใช้  เพื่อกำหนด command หลัก และ  เพื่อกำหนด default argumentsแนวทางทั้งหมดนี้จะช่วยให้ได้ Docker Image ที่ขนาดเล็ก เสถียร ปลอดภัย และจัดการได้ง่ายจริงในงาน production]]></content:encoded></item><item><title>Mastering Timeout Control in Go with Goroutines</title><link>https://dev.to/jones_charles_ad50858dbc0/mastering-timeout-control-in-go-with-goroutines-27bh</link><author>Jones Charles</author><category>dev</category><category>go</category><category>devto</category><pubDate>Mon, 30 Jun 2025 00:48:02 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[
  
  
  Hey, Let’s Talk Timeouts!
If you’ve built backend systems, you’ve hit the timeout wall. External APIs, database queries, or distributed tasks—without a timeout, your app can hang like a sloth on a branch. Think of timeouts as your app’s "eject button"—they keep things moving and save resources when the chef’s taking too long with your metaphorical pizza.Go’s concurrency toolkit—goroutines and channels—is a game-changer here. Forget clunky threads or callback nightmares; Go’s approach is like snapping together LEGO bricks. This post is for devs with a year or two of Go under their belt—folks who’ve spun up goroutines but want to wield timeouts like a pro. We’ll go from basics to battle-tested designs, sprinkled with real-world wins and facepalms. Why goroutines? They’re light, fast, and pair perfectly with channels for clean timeout magic. Buckle up—we’re diving in!
  
  
  Timeout Control : Why Goroutines Shine

  
  
  What’s a Timeout, Anyway?
A timeout caps how long a task gets to run. Finish on time? Cool. Too slow? Sorry, you’re cut off. It’s everywhere in backend land—waiting on an API, querying a database, or juggling distributed jobs. No timeout means angry users or a crashed server.
  
  
  Goroutines: The Timeout Superpower
Goroutines aren’t just threads lite—they’re timeout ninjas. Here’s why:: Starting at 2KB, they scale to thousands without breaking a sweat—try that with Java threads!: Channels sync tasks and timeouts effortlessly, no lock juggling required.: With , timeouts snap into place like LEGO—no bloated configs needed.Compare that to Java’s thread pools or C++ timers—Go’s leaner and meaner.Plus, tricks like  and  make timeouts dynamic and leak-proof. Ready to code? Let’s roll!
  
  
  Getting Hands-On: Simple Timeout with Goroutines
Time to code! Let’s build a basic timeout setup with goroutines and channels. It’s like learning to ride a bike—start simple, then trick it out later. We’ll simulate an API call with a 5-second deadline. Here’s the game plan: launch a goroutine, use a channel for results, and race it against a timeout.: Runs the task async—main thread stays chill.:  grabs the output, buffered so the goroutine doesn’t block.: Listens for the result or —first one wins.Run it, and the 6-second "API" loses to the 5-second timeout. Boom—.Dead simple—under 20 lines!
Lightweight—goroutines sip resources.: Timeout triggers, but the goroutine keeps chugging. In this case, that  finishes anyway—wasted cycles.
: Fine for one task, messy for a dozen.This is your timeout starter kit—great for quick wins, but it’s not ready for the big leagues. Next, we’ll swap  for  to level up control and kill those leaks.
  
  
  Level Up: Timeout Control with Context
Our basic setup was cool, but it’s like a bike without brakes—leaky and hard to stop. Enter Go’s  package: the timeout boss that cancels tasks and cleans up messes. Let’s ditch  and make a database query that stops on a 1-second dime.Since Go 1.7,  has been the concurrency MVP. It’s not just timeouts—it’s cancellation, propagation, and resource smarts in one. Here’s the pitch:: Set deadlines or kill tasks manually.: Share control across functions—no repeat code.: Tell goroutines to quit via .: Spawns a context with a 1-second fuse.: Frees resources, timeout or not.: Signals the goroutine to quit—no lingering zombies.: Spills the beans on what went wrong.Run it, and the 2-second query gets axed at 1 second—clean and efficient.:  is your safety net.: Pass  as the first arg—it’s the Go way.: Chain contexts for deep call stacks.: I once skipped —goroutines piled up ‘til the server cried. Check  to spot stragglers.: A 500ms cap killed legit database calls. Use P95 latency (e.g., 1.5x) to set sane limits.This is timeout control with brains—scalable and leak-free. Next, we’ll hit real-world chaos with distributed systems and high-concurrency tricks!
  
  
  Real-World Timeout Kung Fu
Theory’s nice, but projects are where timeouts get real. With a decade of scars to prove it, I’ll walk you through two battle-tested scenarios—distributed task scheduling and high-concurrency APIs. Code, wins, and facepalms incoming!
  
  
  Scenario 1: Taming Distributed Systems
Picture an e-commerce order flow: inventory, payment, logistics—all separate services. One lags, and the whole chain stalls. We need per-task timeouts  a global kill switch, plus partial results if things go south.Nested  with goroutines, plus  for wrangling parallel calls. Here’s a 5-second timeout across three services:: Runs services in parallel, ties them to , and grabs errors.: "Payment" times out, but others succeed—user gets .: 5 seconds caps the chaos.: Track each service’s time—saved my bacon debugging timeouts.: Don’t ditch everything for one failure.
  
  
  Scenario 2: High-Concurrency API Chaos
An API gateway slamming downstream services with requests. Unchecked goroutines could spiral into a memory apocalypse. We need timeouts  a lid on concurrency.A worker pool with —three goroutines max, 3-second timeout:: Three workers keep goroutines in check.: 3 seconds cuts off laggards.: Tasks flow in, results flow out—smooth as butter.: Base it on load— is a solid start.: Add a token bucket to chill downstream pressure.: I’ve seen goroutines hog CPU post-timeout—check  religiously.: Task IDs + durations = debug gold.
  
  
  Wrapping Up: Timeout Mastery Unlocked
We’ve gone from timeout newbie to goroutine ninja! Goroutines + channels/context are your Go timeout dream team—light, fast, and slick. Whether it’s a quick API call or a sprawling distributed system, you’ve got the tools: basic  for simplicity,  for control, and  for chaos. Pitfalls? Sure—leaky goroutines and tight timeouts bit me hard—but now you know the fixes.
  
  
  Where It Shines (and Where It Doesn’t)
This stuff kills it for high-concurrency backends—think microservices or task queues. Need millisecond precision for trading apps?  might lag a hair—try  instead.: Go 1.23 buffs —finer cancellation’s coming. Dig in!: Pair timeouts with gRPC tracing or Kafka queues—it’s the future.:  is a task’s heartbeat—master it, and your code sings.: Spin up  to spy on goroutines, log timeout stats, and tweak away. This is your launchpad—go build something epic!]]></content:encoded></item><item><title>Working with Scheduled Tasks in Go: Timer and Ticker</title><link>https://dev.to/leapcell/working-with-scheduled-tasks-in-go-timer-and-ticker-8jb</link><author>Leapcell</author><category>dev</category><category>go</category><category>devto</category><pubDate>Sun, 29 Jun 2025 19:01:38 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[In daily development, we may encounter situations where we need to delay the execution of some tasks or execute them periodically. At this point, we need to use timers in Go.In Go, there are two types of timers:  (one-shot timer) and  (periodic timer). This article will introduce both types of timers.A Timer is a one-shot timer used to perform an operation once at a specific time in the future.There are two ways to create a Timer:NewTimer(d Duration) *Timer: This function accepts a parameter  of type  (the time interval), which indicates how long the timer should wait before expiring.  returns a new Timer, which internally maintains a channel . When the timer fires, the current time is sent to channel .AfterFunc(d Duration, f func()) *Timer: Accepts a specified time interval  and a callback function . This function returns a new Timer, and when the timer expires, it directly calls  instead of sending a signal through channel . Calling the Timer's  method can stop the timer and cancel the execution of .The following code demonstrates how to use  and  to create timers and their basic usage:The output of the above code is as follows:timer fired!
timer2 fired!
Here is a step-by-step explanation of the code:Use  to create a timer, then listen to its  property in a new goroutine to wait for the timer to fire.Use  to create another timer, specifying a callback function to handle the timer expiration event.The main goroutine waits long enough to ensure the timer's firing information can be printed.: This method is used to reset the expiration time of a Timer, essentially reactivating it. It accepts a parameter  of type , representing how long the timer should wait before expiring.In addition, this method returns a  value:If the timer is active, it returns .If the timer has already expired or been stopped, it returns  (note:  does not mean the reset failed, it only indicates the current state of the timer).The output of the code is as follows:Step-by-step explanation:Create a timer set to expire after 5 seconds.Call the  method immediately to set it to expire in 1 second. Since the timer is still active (not expired),  returns .The  statement waits for the timer to expire and prints the actual seconds passed (about 1 second).The timer is reset again, this time to expire in 2 seconds. Since the timer has already expired,  returns .The  statement again waits for the timer to expire and prints the seconds passed (about 2 seconds).: This method is used to stop the timer. If the timer is successfully stopped, it returns . If the timer has already expired or been stopped, it returns . Note: the  operation does not close channel .The output is as follows:Step-by-step explanation:Create a timer set to fire after 3 seconds.Immediately call the  method to stop the timer. Since the timer has not yet fired,  returns .Call  again to try to stop the same timer. Since it is already stopped, this time  returns .A Ticker is a periodic timer used to execute tasks repeatedly at fixed intervals. At every interval, it sends the current time to its channel.We can use the  function to create a new Ticker object. This function accepts a  parameter  (the interval).The output of the code is as follows:ticker fired!
ticker fired!
ticker fired!
ticker fired!
ticker fired!
Step-by-step explanation:Create a timer that fires every second. To ensure the timer is cleaned up at the end of the function, we use .Create a context that times out after 5 seconds.  is used to clean up the context before exiting.In a new goroutine, a  statement listens to two channels: the timer's channel () and the context's done channel (). When the timer fires each second, it prints a message. When the context times out (after 5 seconds), it prints a timeout message and returns, ending the goroutine.The main goroutine uses time.Sleep(time.Second * 7) to wait 7 seconds, ensuring that both the timer firing and timeout events can be observed.In addition to listening to  with , you can also use a  loop:Note: Even if you stop a Ticker with the  method, its channel  will not be closed. This means, whether you use  or  to listen to , you need another mechanism to exit the loop, such as using a context.The  method is used to stop the ticker and reset its period to the specified duration. The next tick will occur after the new period has elapsed. It accepts a parameter  of type , which represents the new interval. This parameter must be greater than zero; otherwise, the  method will panic internally.The output of the code is as follows:Step-by-step explanation:Create a time.Ticker that fires every 5 seconds.Use the  method to change the interval from 5 seconds to 1 second.In a single loop, print out the interval. The expected result is 1 second.The  method is used to stop the ticker. After calling , no more ticks will be sent to channel .  the  operation does not close the channel .The output is as follows:Ticker fired!
Ticker fired!
Ticker fired!
Goroutine stopped!
Ticker stopped!
Create a time.Ticker object that fires every second. At the same time, a quit channel of type  is introduced, which is used to send a stop signal to the running goroutine.Start a new goroutine. In this goroutine, a for-select loop listens to two events: ticker firing () and the quit signal (). Each time the ticker fires, it prints a message. If it receives the quit signal, it prints a message and exits the loop.In the main goroutine, time.Sleep(time.Second * 3) simulates a waiting time of 3 seconds, during which the ticker will fire a few times.The main goroutine stops the ticker by calling , then closes the quit channel. The goroutine receives the quit signal, prints a message, and exits the loop.The  method does  close channel , so we need to use other means (such as a quit signal) to clean up resources.
  
  
  Main Differences Between Timer and Ticker
 is used for tasks that are executed after a single delay. is used for tasks that need to be executed repeatedly.
  
  
  Behavioral Characteristics:
 fires once after the specified delay, sending a single time value to its channel. fires periodically at the specified interval, sending repeated time values to its channel. can be reset ( method) and stopped ( method).  is used to change the firing time of the Timer. can also be reset ( method) and stopped ( method).  is used to change the interval at which the Ticker fires.The  method of  is used to prevent the Timer from firing. If the Timer has already fired,  does not remove the time value that has already been sent to its channel.The  method of  is used to stop the periodic firing. Once stopped, no new values will be sent to its channel.For both Timer and Ticker, calling the  method  close their  channels. If there are other goroutines listening on this channel, to avoid potential memory leaks, you need to manually terminate those goroutines. Usually, such resource cleanup can be handled by using a  or by a quit signal (implemented with channels).After a Ticker has completed its task, you should call the  method to release the associated resources and prevent memory leaks. If you do not stop the Ticker in time, it may result in continuous resource occupation.This article has explored Go's Timer and Ticker in depth, introducing how to create them, their basic usage, and their related methods in detail. Additionally, the article summarizes the main differences between these two types of timers and emphasizes the considerations to keep in mind when using them.When writing Go code, you should choose the appropriate timer according to the application scenario. At the same time, it's important to follow best practices—especially to release resources promptly after finishing with a timer—which is crucial for avoiding potential memory leaks.Leapcell is the Next-Gen Serverless Platform for Web Hosting, Async Tasks, and Redis:Develop with Node.js, Python, Go, or Rust.Deploy unlimited projects for freepay only for usage — no requests, no charges.Unbeatable Cost EfficiencyPay-as-you-go with no idle charges.Example: $25 supports 6.94M requests at a 60ms average response time.Streamlined Developer ExperienceIntuitive UI for effortless setup.Fully automated CI/CD pipelines and GitOps integration.Real-time metrics and logging for actionable insights.Effortless Scalability and High PerformanceAuto-scaling to handle high concurrency with ease.Zero operational overhead — just focus on building.]]></content:encoded></item><item><title>From Migrations to Seed : Working with Fixtures in Nixopus</title><link>https://dev.to/raghavyuva/from-migrations-to-seed-working-with-fixtures-in-nixopus-2e95</link><author>Raghav</author><category>dev</category><category>go</category><category>devto</category><pubDate>Sun, 29 Jun 2025 18:41:52 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[Hey, we’re always up for exploring something cool at Nixopus, and this time, we’re diving into fixtures. Now, the word  might sound a bit too technical and not immediately clear to many of our fellow developers so let’s break it down, and you’ll see exactly what we mean. Let’s dive in.If you’ve worked with migrations before, you’ve probably come across the term  for databases. Even if you haven’t, let’s take a moment to understand what seeding data actually involves.Usually, during development, things can get tricky over time, especially when you have contributors and developers working together on the same project. Everyone wants everything to be quick and hassle-free so development doesn’t slow down. As a project maintainer, it’s your responsibility to enable this smooth contribution roadmap for any user who wants to help out. That’s exactly what we’re working towards at Nixopus.One major part of Contributing to Nixopus is that after getting everything set up, Contributor still needs to do the following tasks :You realize you need  to log in and test admin features.You also want to create  for that organization to test the role based access.You might even want to enable specific features inside nixopus, and disable some!This is time consuming and error-prone, especially when you or your teammates need to do it over and over again on fresh databases. That’s exactly where data seeding comes into the picture.The process of populating a database with an initial set of data. Simple, isn’t it?But how do we actually create one in Go using Bun ORM? This is what pushes us to explore how we can write a script to do exactly that.We’ve divided our seed files into a modular folder structure. This way, everything stays organized and it’s much easier to load schema specific data when you need it.  Below is an example of the file structure and the kind of data we’ll be loading into the database later in our Codebase:First things first, we need to get input from the user. Let’s assume the user runs a command like:go run internal/cmd/fixtures/main.goThen we want to accept some arguments along with this command to determine what exactly the user is trying to do, we will get into what each flag does later, for now let's go forwardNow that we know what the user is actually trying to do, let’s create a Bun DSN URL which stands for , which is a connection string used to configure and connect to databases or services.Here’s a raw example of what a Postgres DSN URL looks like: postgres://username:password@localhost:5432/database_name?sslmode=disableSince we don’t want to hardcode credentials, we need to load our secrets like passwords and other configs from environment variables. Here’s how we can do that in Go:Once we have our DSN ready, we can check if our connection string is properly formatted and can be parsed without errors. The function we use for this is :Now that we are ready to go, let's connect to our database and close the connection to database as our program endsNow we need to load all our fixtures from the YAML files in our  folder.  Here’s a simple flowchart that shows how the loading process works, Read The CodeAfter we have everything set up, we decide how we want to load the fixtures onto our database.  This block of code checks which option the user passed when they ran the command and performs the action accordingly:
  
  
  Explanation of the Flags We Considered Earlier
I know you must be waiting for the final touch, it's a lot of code to digest, right? So let’s take a moment to clearly understand the arguments we took earlier from the user:If you used , it , recreates them, and then loads your fixtures into fresh tables. This is helpful if you want to start from scratch every time.If you used , it  but keeps the tables themselves (the structure stays intact), then loads your fixtures.If you didn’t pass any of those flags, it simply inserts the fixture data as-is, without dropping or truncating anything.Do you think this could be done even better? Hmm that’s exactly why we’d love to have you join our Discord community!   Want to see what we’re building and what we’ve accomplished so far? Take a look at our CHANGELOG.md.  ]]></content:encoded></item><item><title>**Building a Concurrent Caching System in Go: 500K+ Operations Per Second Performance**</title><link>https://dev.to/aaravjoshi/building-a-concurrent-caching-system-in-go-500k-operations-per-second-performance-3gbl</link><author>Aarav Joshi</author><category>dev</category><category>go</category><category>devto</category><pubDate>Sun, 29 Jun 2025 18:16:49 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[As a best-selling author, I invite you to explore my books on Amazon. Don't forget to follow me on Medium and show your support. Thank you! Your support means the world! Building high-performance applications often feels like solving a complex puzzle. When systems struggle under heavy data loads, I've found that intelligent caching becomes essential. My journey with Go led me to design a concurrent caching system that handles millions of operations efficiently. Let me share how this works and why it matters.Caching isn't just about storing data. It's about making strategic decisions on what to keep and what to remove. In our implementation, we support three eviction strategies. Least Recently Used discards older items first. Least Frequently Used removes less-accessed entries. Adaptive Replacement Cache dynamically balances between recency and frequency patterns. Each approach serves different access scenarios.Sharding is our secret weapon against contention. By splitting data across partitions, we minimize lock collisions. Here's how we distribute keys:This FNV-1a hashing ensures even distribution across shards. Each shard operates independently, allowing concurrent access patterns that scale with CPU cores. Memory management requires careful design. We use atomic operations for access tracking to avoid excessive locking. Notice how we handle entry updates:These lightweight operations maintain accuracy without blocking other readers. For eviction, priority queues enable efficient removal. The LRU implementation uses a heap-based queue:Time-based expiration is handled through a background cleaner. This routine periodically scans for stale entries:Serialization demonstrates practical persistence. Our approach avoids marshaling expired entries:Performance testing reveals impressive results. On a 32-core system, we consistently achieve over 500,000 operations per second. The sharded architecture reduces contention dramatically compared to single-lock implementations. Memory overhead stays low—about 30% less than standard map-based caches.In production, I've applied this to several scenarios. Database query caching reduces backend load by 40% in read-heavy applications. Web session storage handles sudden traffic spikes gracefully. API response caching cuts latency from milliseconds to microseconds. For computational workflows, memoization reuse saves significant processing time.Consider these enhancements for enterprise use. Add Prometheus metrics to track hit ratios and eviction rates. Implement size-based eviction for memory-bound systems. For distributed environments, integrate cluster coordination using gossip protocols. Always include cache warming mechanisms for cold starts.The true value emerges in high-scale systems. When handling 50,000 operations across 100 goroutines, our implementation performs reliably:
  
  
  This outputs results like: Processed 50k ops in 92.4ms. The numbers prove our design—minimal locking, smart eviction, and memory efficiency create a responsive caching layer. Whether building microservices or data pipelines, such caching becomes infrastructure bedrock.
📘 , , , and  to the channel! is an AI-driven publishing company co-founded by author . By leveraging advanced AI technology, we keep our publishing costs incredibly low—some books are priced as low as —making quality knowledge accessible to everyone.Stay tuned for updates and exciting news. When shopping for books, search for  to find more of our titles. Use the provided link to enjoy !Be sure to check out our creations:]]></content:encoded></item><item><title>**Go Database Optimization: 5 Performance Patterns That Boost Application Speed by 700%**</title><link>https://dev.to/aaravjoshi/go-database-optimization-5-performance-patterns-that-boost-application-speed-by-700-4148</link><author>Aarav Joshi</author><category>dev</category><category>go</category><category>devto</category><pubDate>Sun, 29 Jun 2025 18:03:10 +0000</pubDate><source url="https://dev.to/t/go">Dev.to Go</source><content:encoded><![CDATA[As a best-selling author, I invite you to explore my books on Amazon. Don't forget to follow me on Medium and show your support. Thank you! Your support means the world! Building high-performance applications in Go requires thoughtful database interaction design. When systems face heavy loads, inefficient data access becomes the primary bottleneck. I've seen applications crumble under pressure due to poorly optimized database patterns, leading to frustrated users and costly scaling. Let's explore practical techniques to prevent these issues.Database connections are expensive resources. Creating new connections for every request wastes precious milliseconds. Connection pooling solves this by reusing existing connections. Here's how I configure it properly:These numbers aren't arbitrary. After load testing various configurations, I found this ratio balances memory usage and connection wait times. Exceeding your database's actual connection limit causes queues that cascade through your application.Batch processing revolutionized how I handle write operations. Instead of executing individual inserts, I group them:The batch processor collects operations until reaching 100 requests or waiting 100ms, whichever comes first. This reduced database round trips by 92% in my last benchmark. The transaction block ensures atomic execution:Caching requires careful strategy. I implement dual caching: prepared statements and query results. Statement caching avoids repeated SQL compilation:Result caching works best for read-heavy operations. Serializing to JSON handles struct variability:Context handling prevents resource leaks. Always propagate cancellation:For production systems, add observability. I instrument these key metrics:Batch flush latency distributionPool utilization percentageImplement circuit breakers to avoid overwhelming databases during outages. This simple pattern prevents cascading failures:Connection validation prevents stale pool issues. Before reuse, verify connectivity:Tuning requires understanding your workload. For write-heavy systems, increase batch sizes to 500-1000 operations. For read-heavy applications, allocate more memory to caching. Always test with production-like data volumes.These patterns delivered remarkable improvements in my projects. One API handling financial transactions increased throughput from 1,200 to 9,500 requests per second. Database CPU utilization dropped by 40% despite higher traffic. The implementation pays continuous dividends as systems scale.
  
  
  Remember optimization isn't premature engineering. It's building responsive foundations. Start with connection pooling, add batching when write volumes grow, and introduce caching for frequent queries. Each layer compounds performance gains while keeping complexity manageable.
📘 , , , and  to the channel! is an AI-driven publishing company co-founded by author . By leveraging advanced AI technology, we keep our publishing costs incredibly low—some books are priced as low as —making quality knowledge accessible to everyone.Stay tuned for updates and exciting news. When shopping for books, search for  to find more of our titles. Use the provided link to enjoy !Be sure to check out our creations:]]></content:encoded></item></channel></rss>