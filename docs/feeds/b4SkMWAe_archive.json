{"id":"b4SkMWAe","title":"DevOps","displayTitle":"DevOps","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":48,"items":[{"title":"Digest #172: Kubernetes 2.0, GCP Incident and AWS Lambda Hacks","url":"https://www.devopsbulletin.com/p/digest-172-kubernetes-20-gcp-incident","date":1750434842,"author":"Mohamed Labouardy","guid":163623,"unread":true,"content":"<p>Welcome to this week’s edition of the DevOps Bulletin!</p><p>This week, we explore what a hypothetical Kubernetes 2.0 might look like and whether it’s time to rethink core assumptions like controllers, CRDs, and YAML. We also broke down Google Cloud’s latest public incident write-up in plain terms and asked a tough question: Why are we building AI agents to answer things an SQL query could handle better? Plus, we dig into how NAT and packet mangling work in Linux, and how Pinterest handles EC2 network throttling at scale. One more thing: if you’ve ever spent an hour fighting with port forwarding to share a local app, ngrok’s no-config API sharing guide might save your next afternoon.</p><p>All this and more in this week’s DevOps Bulletin—don’t miss out!</p><p>If you've ever wasted an afternoon messing with port forwarding, firewalls, or cloud configs just to share an API, yeah, same.  makes it dead simple to expose your API to the internet, securely, in seconds. No config dumps. No infra overhead. Just your app, online.</p><ul><li><p> client for instant, schema-aware SQL exploration; runs locally so your data and credentials stay on your machine.</p></li><li><p>&nbsp;is a command-line tool that runs HTTP requests defined in a simple, plain-text format.</p></li><li><p> and SCP client with userspace Tailscale connectivity. Secure shell access and file transfers over Tailnet without requiring a full Tailscale daemon.</p></li><li><p> is an AI-powered CLI that restructures messy commit histories into clean, conventional commits.</p></li><li><p> is a lightweight container image registry that stores and serves images directly from your Docker daemon's storage.</p></li><li><p> is an anonymous, expiring Docker container registry using the official Docker Registry image.</p></li></ul><div><p> If you have feedback to share or are interested in <a href=\"https://www.passionfroot.me/devopsbulletin\">sponsoring</a> this newsletter, feel free to reach out via , or simply reply to this email.</p></div>","contentLength":1826,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceb050a9-cff6-4285-9a70-ef18a8d0caa7_6157x2760.png","enclosureMime":"","commentsUrl":null},{"title":"Blind & Visually Impaired Initiative (BVI) Meeting - 2025-06-17","url":"https://www.youtube.com/watch?v=pcVgyZVyUvc","date":1750429828,"author":"CNCF [Cloud Native Computing Foundation]","guid":163619,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io</article>","contentLength":381,"flags":null,"enclosureUrl":"https://www.youtube.com/v/pcVgyZVyUvc?version=3","enclosureMime":"","commentsUrl":null},{"title":"KeycloakCon: Welcome + Opening Remarks - Mana Takeda, Nomura Research Institute, Ltd.","url":"https://www.youtube.com/watch?v=spqU1exuKcE","date":1750427383,"author":"CNCF [Cloud Native Computing Foundation]","guid":163583,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nKeycloakCon: Welcome + Opening Remarks - Mana Takeda, Nomura Research Institute, Ltd.</article>","contentLength":468,"flags":null,"enclosureUrl":"https://www.youtube.com/v/spqU1exuKcE?version=3","enclosureMime":"","commentsUrl":null},{"title":"Standardizing Authentication Flows in Keycloak Environments – Efficient Authorization S... Yuta Kato","url":"https://www.youtube.com/watch?v=lTEgUizqTg4","date":1750427383,"author":"CNCF [Cloud Native Computing Foundation]","guid":163584,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nStandardizing Authentication Flows in Keycloak Environments – Efficient Authorization Strategies Using OPA - Yuta Kato, CyberAgent, Inc.\n\nIn this session, we will explain how we standardized and streamlined authentication flows to address the growing workload faced by engineers due to the rapid increase in authentication services.\n\nTo tackle the challenging task of building individual authentication flows for over 100 services, we adopted an implementation approach that defines authorization levels using role information and leverages attribute data stored in Keycloak.\n\nBy accurately linking user information with imported role data and standardizing authentication flows, we enabled faster updates to authorization systems. Additionally, we implemented centralized policy management for each client using OPA (Open Policy Agent) and policy language, significantly improving maintenance efficiency.\n\nThis session will provide practical and scalable design strategies and implementation methods for building robust systems that address authorization strategies using OPA.</article>","contentLength":1462,"flags":null,"enclosureUrl":"https://www.youtube.com/v/lTEgUizqTg4?version=3","enclosureMime":"","commentsUrl":null},{"title":"Sponsored Keynote: Hitachi’s Keycloak Journey - Evolution of Business and Community - Michito Okai","url":"https://www.youtube.com/watch?v=dUR9_gZZOfY","date":1750427381,"author":"CNCF [Cloud Native Computing Foundation]","guid":163580,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nSponsored Keynote: Hitachi’s Keycloak Journey - Evolution of Business and Community - Michito Okai, Software Engineer, Hitachi Ltd.\n\nIn this keynote session, Michito Okai will explain how Hitachi uses Keycloak for real business. Keycloak has a wide range of functions, complies with various standard specifications, and has good performance. Therefore, Keycloak can solve the requirements of various industries such as banking, insurance, and the public sector and so on. In fact, Hitachi has realized a variety of use cases in real business to solve customer requirements by making full utilization of Keycloak.\n\nAlso, to make full utilization of Keycloak in real business, Hitachi has been working on community activities. For example, based on requirements from customers, Hitachi added new functions and made Keycloak compliant with standard specifications.</article>","contentLength":1246,"flags":null,"enclosureUrl":"https://www.youtube.com/v/dUR9_gZZOfY?version=3","enclosureMime":"","commentsUrl":null},{"title":"Sponsored Keynote: Networking Reception Welcome, Presented by NRI - Hiroyuki Wada","url":"https://www.youtube.com/watch?v=BACroos63Rk","date":1750427381,"author":"CNCF [Cloud Native Computing Foundation]","guid":163581,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nSponsored Keynote: Networking Reception Welcome, Presented by NRI - Hiroyuki Wada, Nomura Research Institute, Ltd.\n\nJoin us as we kick off the Networking Reception with a warm welcome from NRI, proud sponsor of tonight’s gathering.</article>","contentLength":616,"flags":null,"enclosureUrl":"https://www.youtube.com/v/BACroos63Rk?version=3","enclosureMime":"","commentsUrl":null},{"title":"Keycloakify: A Practical Toolkit for Customizing Keycloak Interfaces - Joseph Garrone, Insee","url":"https://www.youtube.com/watch?v=0peJITq1WXU","date":1750427381,"author":"CNCF [Cloud Native Computing Foundation]","guid":163582,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nKeycloakify: A Practical Toolkit for Customizing Keycloak Interfaces - Joseph Garrone, Insee\n\nKeycloakify is an open-source tool that simplifies theming in Keycloak by enabling the use of modern frameworks like React, Angular, and Svelte.\n\nIt supports customization of login, account, admin, and email interfaces, with real-time previews and standard frontend tooling.\n\nIn this session, we’ll walk through how it works, how it’s used in production environments, and how it compares to Keycloak’s built-in theming system.</article>","contentLength":909,"flags":null,"enclosureUrl":"https://www.youtube.com/v/0peJITq1WXU?version=3","enclosureMime":"","commentsUrl":null},{"title":"Keynote: Keycloak Introduction and Demo - Marek Posolda, Keycloak Project Maintainer","url":"https://www.youtube.com/watch?v=hwmko7glE6I","date":1750427380,"author":"CNCF [Cloud Native Computing Foundation]","guid":163573,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nKeynote: Keycloak Introduction and Demo - Marek Posolda, Keycloak Project Maintainer\n\nIn this talk, Marek will introduce the Keycloak project. He will talk about the history of the Keycloak, use of Keycloak and how can be Keycloak used to secure your applications. Marek will show the simple demo how to secure your application with Keycloak.</article>","contentLength":725,"flags":null,"enclosureUrl":"https://www.youtube.com/v/hwmko7glE6I?version=3","enclosureMime":"","commentsUrl":null},{"title":"Fine-Grained Authorization & Beyond: Mastering Keycloak Patterns in AI-infused Apps - Daniel Oh","url":"https://www.youtube.com/watch?v=Ry5m_SOXKd4","date":1750427380,"author":"CNCF [Cloud Native Computing Foundation]","guid":163574,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nFine-Grained Authorization &amp; Beyond: Mastering Keycloak Patterns in AI-infused Apps - Daniel Oh, Red Hat\n\n\nSecuring a single application with Keycloak and OIDC/OAuth 2.0 is straightforward, but what about complex microservice architectures, especially those incorporating AI capabilities? This session explores advanced patterns and best practices for leveraging Keycloak within distributed systems built with a specific focus on securing AI applications. We'll go beyond basic authentication and RBAC to implement fine-grained authorization for accessing and utilizing AI models using Keycloak Authorization Services. Topics include efficient token propagation between services (including those hosting AI models), securing service-to-service communication, handling multi-tenancy considerations for AI services, and integrating custom Keycloak policies to control access to sensitive AI functionalities and data. Learn how to build scalable, maintainable, and highly secure microservice ecosystems, including those leveraging AI, powered by Quarkus, Langchain4j, and Keycloak.</article>","contentLength":1461,"flags":null,"enclosureUrl":"https://www.youtube.com/v/Ry5m_SOXKd4?version=3","enclosureMime":"","commentsUrl":null},{"title":"Don't Be Afraid to Operate Alone! The ABCs of Authentication Infrastructure Manag... Chotaro Iwasaki","url":"https://www.youtube.com/watch?v=LjvmutbHr6s","date":1750427380,"author":"CNCF [Cloud Native Computing Foundation]","guid":163575,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nDon't Be Afraid to Operate Alone! The ABCs of Authentication Infrastructure Management - Chotaro Iwasaki, Giftee, Inc.\n\nThere are many documents and books that explain the basic concepts and configuration methods for Keycloak. However, the current situation is that concrete know-how about operation is not shared much.\n\nOur company operates an authentication infrastructure centered on Keycloak for various services developed in-house. In this session, we will share the ideas and concrete efforts in introducing and operating a general-purpose authentication infrastructure.\n\nWe hope that this session will contribute to the revitalization of the Keycloak community in Japan by circulating the sharing of knowledge about Keycloak operation!</article>","contentLength":1125,"flags":null,"enclosureUrl":"https://www.youtube.com/v/LjvmutbHr6s?version=3","enclosureMime":"","commentsUrl":null},{"title":"How To Manage Keycloak Securely by Using Terraform on Google Cloud - Atsushi Kitano, Cloud Ace","url":"https://www.youtube.com/watch?v=HuHHKNRsOp8","date":1750427380,"author":"CNCF [Cloud Native Computing Foundation]","guid":163576,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nHow To Manage Keycloak Securely by Using Terraform on Google Cloud - Atsushi Kitano, Cloud Ace\n\nWe have launched a new service which monitors customers' systems.\nIt uses Keycloak to authenticate for customers and developers to use our service components, for instance, Grafana, ArgoCD, Backstage, Redmine, and so on.\n\nSo, Keycloak has personal information, and we have to manage it securely.\nWe're using Terraform to configure Keycloak, not for making mistakes due to creating by hand. And we don't want to encounter errors when running Terraform code from the developer's PC.\nSo we're running it from the CD agent. We use Cloud Build, a Google Cloud product, because it provides a private pool that allows us to use a specific IP address.\n\nWe'll introduce how to build this CD system and how to use Terraform in my session.</article>","contentLength":1207,"flags":null,"enclosureUrl":"https://www.youtube.com/v/HuHHKNRsOp8?version=3","enclosureMime":"","commentsUrl":null},{"title":"No More Configuration Confusion! Keycloak Mapper Basics for SEs – How to Work with... Takahiro Inoue","url":"https://www.youtube.com/watch?v=7j2TqT7EU10","date":1750427380,"author":"CNCF [Cloud Native Computing Foundation]","guid":163577,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nNo More Configuration Confusion! Keycloak Mapper Basics for SEs – How to Work with LDAP/External IdP Integration and OIDC Tokens - Takahiro Inoue, Red Hat\n\nWhen using Keycloak, configuring Mappers is essential for integrating with LDAP or external IdPs and for managing OIDC tokens.\n\nThis session will cover three key types of Mappers:\nUser Federation Mappers used for integration with LDAP or Active Directory,\nIdentity Provider Mappers for mapping attributes from external IdPs such as Google and GitHub, and\nProtocol Mappers for outputting information into tokens.\nWe'll explain the types and use cases for each Mapper to help you understand their roles.\n\nThis is the perfect session for anyone looking to quickly grasp the basics of Mappers and learn key configuration tips to avoid confusion in real-world environments.</article>","contentLength":1209,"flags":null,"enclosureUrl":"https://www.youtube.com/v/7j2TqT7EU10?version=3","enclosureMime":"","commentsUrl":null},{"title":"OpenID Federation Trust Chain on Keycloak for Highly Assured Use Cases of Digital I... Yutaka Obuchi","url":"https://www.youtube.com/watch?v=08Y40Au93w8","date":1750427380,"author":"CNCF [Cloud Native Computing Foundation]","guid":163578,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nOpenID Federation Trust Chain on Keycloak for Highly Assured Use Cases of Digital Identity Wallet - Yutaka Obuchi, Hitachi\n\nOpenID Federation 1.0 provides a framework to build trust between a Relying Party and an OpenID Provider that have no direct relationship so that the Relying Party can send OIDC/OAuth requests to the OpenID Provider without being previously registered.\n\nOne primary use case is the trust between an Issuer and a Holder (Wallet) on W3C’s Verifiable Credential Data Model, which is getting a lot of attentions as an approach to realize the Digital Identity Wallet ecosystem.\nEspecially when high assurance level is needed like EU Digital Identity Wallet, OpenID Federation can provide a strong solution.\n\nIn this session:\nFirstly I will explain OpenID Federation and the reason why it is important for Digital Identity Wallet ecosystem.\nThen I will explain what types of roles Keycloak can play with OpenID Federation Trust Chain.\nAlso I will show a simple demo of client registration with OpenID Federation Trust Chain on Keycloak.</article>","contentLength":1439,"flags":null,"enclosureUrl":"https://www.youtube.com/v/08Y40Au93w8?version=3","enclosureMime":"","commentsUrl":null},{"title":"Keynote: AI Agents with Keycloak in MCP - Takashi Norimatsu, Senior OSS Specialist, Hitachi Ltd.","url":"https://www.youtube.com/watch?v=-CsygNAJt-0","date":1750427380,"author":"CNCF [Cloud Native Computing Foundation]","guid":163579,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nKeynote: AI Agents with Keycloak in MCP - Takashi Norimatsu, Senior OSS Specialist, Hitachi Ltd.\n\nIn this talk, Takashi investigates the possibility of integrating Keycloak with AI agents.\nIn the field of AI agents, Model Context Protocol (MCP) becomes a hot topic, which makes it easy for an AI agent/tool to connect internal/external services.\n\nWhen an AI agent/tool implementing an MCP client accesses a remote external service implementing an MCP server, end user authentication and authorization is sometimes required. According to the MCP specification, OAuth 2.1 needs to be used for that, which implies that there is the possibility of using Keycloak for end user authentication and authorization because Keycloak supported OAuth 2.1.\n\nFirstly, Takashi talks about MCP briefly and describes end user authentication and authorization of MCP in more detail. After that, the speaker shows the possible system configuration that includes Keycloak as a part of the MCP server.</article>","contentLength":1362,"flags":null,"enclosureUrl":"https://www.youtube.com/v/-CsygNAJt-0?version=3","enclosureMime":"","commentsUrl":null},{"title":"Compliance in the Age of AI: Why Strong CI/CD Foundations Matter","url":"https://devops.com/compliance-in-the-age-of-ai-why-strong-ci-cd-foundations-matter/?utm_source=rss&utm_medium=rss&utm_campaign=compliance-in-the-age-of-ai-why-strong-ci-cd-foundations-matter","date":1750415471,"author":"Arpad Kun","guid":163447,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Streamline Operational Troubleshooting with Amazon Q Developer CLI","url":"https://aws.amazon.com/blogs/devops/streamline-operational-troubleshooting-with-amazon-q-developer-cli/","date":1750371119,"author":"Kirankumar Chandrashekar","guid":163163,"unread":true,"content":"<p><a href=\"https://aws.amazon.com/q/developer/\">Amazon Q Developer</a> is the most capable generative AI–powered assistant for software development, helping developers perform complex workflows. Amazon Q Developer <a href=\"https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line.html\">command-line interface (CLI)</a> combines conversational AI with direct access to AWS services, helping you understand, build, and operate applications more effectively. The <a href=\"https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-chat.html\">Amazon Q Developer CLI</a> executes commands, analyzes outputs, and provides contextual recommendations based on best practices for troubleshooting tools and platforms available on your local machine.</p><p>In today’s cloud-native environments, troubleshooting production issues often involves juggling multiple terminal windows, parsing through extensive log files, and navigating numerous AWS console pages. This constant context-switching delays problem resolution and adds cognitive burden to teams managing cloud infrastructure.</p><p>In this blog post, you will explore how Amazon Q Developer CLI transforms the troubleshooting experience by streamlining challenging scenarios through conversational interactions.</p><h2>The Traditional Troubleshooting Experience</h2><p>When issues arise, engineers typically spend hours manually examining infrastructure configurations, reviewing logs across services, and analyzing error patterns. The process requires switching between multiple interfaces, correlating information from various sources, and deep AWS knowledge. This complex workflow often extends problem resolution from hours into days and increase the burden on the infrastructure teams.</p><h2>Solution: Amazon Q Developer CLI</h2><p>Amazon Q Developer CLI streamlines the entire troubleshooting process, from initial investigation to problem resolution, making complex AWS troubleshooting accessible and efficient through simple conversations.</p><p>How Amazon Q Developer CLI works:</p><ul><li><strong>Natural Language Interface:</strong> Execute AWS CLI commands and interact with AWS services using conversational prompts</li><li> Map out infrastructure and analyze configurations</li><li><strong>Intelligent Log Analysis:</strong> Parse, correlate, and analyze logs across services</li><li><strong>Root Cause Identification:</strong> Pinpoint issues through AI-powered reasoning</li><li> Implement fixes with minimal human intervention</li><li> Test solutions and explain complex issues simply</li></ul><p>One of the <a href=\"https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-chat-tools.html\">built-in tools</a> within the Amazon Q Developer CLI, , enables natural language interaction with AWS services, as shown in Figure 1. This tool leverages the AWS CLI permissions configured on your local machine, allowing secure and authorized access to your AWS resources.</p><p><em>Figure 1: Tools selection in Amazon Q Developer CLI</em></p><h2>Real-World Troubleshooting Scenario</h2><h3>Demonstration Environment Setup</h3><p>This demonstration was performed with the following environment configuration:</p><p>The environment includes a local development machine with necessary tools, appropriate AWS account permissions, and terminal access. By starting Amazon Q Developer CLI in the project directory, it has immediate access to relevant code and configuration files.</p><h3>Scenario: Troubleshooting NGINX 5XX Errors</h3><p>The scenario demonstrates troubleshooting a multi-tier application architecture as shown in figure 2 deployed on Amazon ECS Fargate with:</p><ul><li><strong>Application Load Balancer (ALB)</strong> distributing traffic across availability zones</li><li><strong>NGINX reverse proxy service</strong> handling incoming requests</li><li> processing business logic</li><li> enabling internal communication</li><li> Logs providing centralized logging</li></ul><p><em>Figure 2: AWS Architecture diagram for the app used in this blog post</em></p><h3>Traditional Troubleshooting Steps</h3><p>For the architecture in figure 2, when 502 Gateway Timeout errors occur, traditional troubleshooting requires:</p><ol><li>Checking ALB target group health</li><li>Examining ECS service status across multiple consoles</li><li>Analyzing CloudWatch logs from different log groups</li><li>Correlating error patterns between services</li><li>Reviewing infrastructure code for configuration issues</li><li>Implementing and deploying fixes</li></ol><h3>Amazon Q Developer CLI Approach</h3><p>Instead, let’s see how Amazon Q Developer CLI handles this systematically, step by step:</p><p><strong>Step1: Initial Problem Report</strong></p><p>Amazon Q Developer CLI is provided with the initial prompt as a problem statement within the application project directory as shown in the following screenshot in figure 3. Amazon Q Developer responds back and says it is going investigate the 502 Gateway Timeout errors in the NGINX application.</p><pre><code>Our production NGINX application is experiencing 502 Gateway Timeout errors. \nI have checked out the application and infrastructure code locally and the AWS CLI \nprofile 'demo-profile' is configured with access to the AWS account where the \ninfrastructure and application is deployed to. Can you help investigate and diagnose the issue?\n</code></pre><p><em>Figure 3: Amazon Q Developer CLI with initial prompt and problem statement</em></p><p><strong>Step2: Systematic Infrastructure Discovery</strong></p><p>Amazon Q Developer CLI start to systematically discovering the infrastructure as shown in the following screenshot in figure 4. If you see the initial prompt did not include that the app is hosted on ECS, but Amazon Q Developer CLI understood the context and executes the AWS CLI calls to describe the Cluster and the services within it. It made sure that the ECS tasks are running for both the services within the Cluster. It is a key discovery that both services show healthy status (1/1 desired count), indicating the issue isn’t service availability.</p><p><em>Figure 4: AWS Infrastructure discovery by Amazon Q Developer CLI</em></p><p><strong>Step 3: Intelligent Log Analysis</strong></p><p>Amazon Q Developer CLI retrieves and analyzes recent CloudWatch logs from the NGINX container, immediately identifying the critical error pattern as shown in the following screenshot in figure 5, where Amazon Q Developer responds: “Perfect! I found the issue. The NGINX logs show clear 504 gateway timeout with upstream timeout messages.”</p><p><em>Figure 5: CloudWatch Log analysis by Amazon Q Developer CLI</em></p><p><strong>Step 4: Amazon Q Developer CLI Analysis and Root Cause Identification</strong></p><p>Amazon Q Developer examines backend service logs and discovers a mismatch between the backend service response time and NGINX timeout settings, as seen in the following screenshot in figure 6.</p><p><em>Figure 6: Root cause identification by Amazon Q Developer CLI</em></p><p><strong>Step 5: Amazon Q Developer CLI Root Cause Analysis</strong></p><p>Amazon Q Developer CLI examines the ECS task definitions to identify the exact configuration mismatch, as shown in the following screenshot in figure 7. Amazon Q Developer finds that:</p><ul><li>Backend service is configured with response_delay=15000 (15 secs)</li><li>NGINX proxy is configured with proxy_read_timeout 10s</li></ul><p>This mismatch causes 504 gateway timeout errors when the backend response exceeds NGINX’s timeout threshold.</p><p><em>Figure 7: Root cause analysis and issue detection by Amazon Q Developer CLI</em></p><p><strong>Step 6: Automated Code Fix</strong></p><p>Here’s where Amazon Q Developer CLI truly excels—it doesn’t just diagnose; it implements the fix. Since Amazon Q Developer CLI is started within the project where the CDK code for ECS task definition is defined, it identified the code configuration and also modified it, as shown in the following screenshot in figure 8.</p><p><em>Figure 8: CDK code fix by Amazon Q Developer CLI</em></p><p>Amazon Q Developer CLI builds and deploys the fix by executing  and  using the ‘‘ AWS CLI profile that was initially provided in the prompt, as shown in the following screenshot in figure 9.</p><p><em>Figure 9: CDK code build and deployment by Amazon Q Developer CLI</em></p><p>Amazon Q Developer CLI validates the solution by sending a curl request to the ALB endpoint after the successful deployment, as shown in the following screenshot in figure 10.</p><p><em>Figure 10: Fix validation by Amazon Q Developer CLI</em></p><p>In addition to that, Amazon Q Developer also sends a request to the health check endpoint and validates everything is working after the fix was deployed, as shown in the following screenshot in figure 11.</p><p><em>Figure 11: Health endpoint validation by Amazon Q Developer CLI</em></p><h2>What Amazon Q Developer CLI Accomplished</h2><p>Using just conversational commands, Amazon Q Developer CLI performed a complete troubleshooting cycle:</p><ul><li><strong>Infrastructure Discovery:</strong> Automatically mapped ECS clusters, services, and dependencies</li><li> Analyzed thousands of log entries across multiple services</li><li> Identified exact configuration mismatch between NGINX’s timeout (10s) and the backend’s response delay (15s)</li><li> Located problematic timeout setting in CDK infrastructure code</li><li><strong>Automated Implementation:</strong> Modified infrastructure code to increase the NGINX timeout</li><li> Built, deployed, and validated the complete solution</li><li> Verified both fix effectiveness and overall system health</li></ul><p>Amazon Q Developer CLI handles troubleshooting tasks through a single, conversational interface, eliminating the need for multiple tools or AWS CLI commands.</p><p>Amazon Q Developer CLI represents a significant evolution in how we troubleshoot cloud infrastructure issues. By combining natural language understanding with powerful command execution capabilities, it transforms complex troubleshooting workflows into efficient, action-oriented dialogues. Whether you’re dealing with NGINX 5XX errors or similar issues across other AWS services, Amazon Q Developer CLI can help you diagnose issues, implement fixes, and validate solutions—all through a conversational interface that feels natural and intuitive.</p><p>Give Amazon Q Developer CLI a try the next time you encounter a troubleshooting challenge, and experience the difference it can make in your operational workflow.</p><p>Kirankumar Chandrashekar is a Generative AI Specialist Solutions Architect at AWS, focusing on Amazon Q Developer. Bringing deep expertise in AWS cloud services, DevOps, modernization, and infrastructure as code, he helps customers accelerate their development cycles and elevate developer productivity through innovative AI-powered solutions. By leveraging Amazon Q Developer, he enables teams to build applications faster, automate routine tasks, and streamline development workflows. Kirankumar is dedicated to enhancing developer efficiency while solving complex customer challenges, and enjoys music, cooking, and traveling.</p>","contentLength":9913,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Announcing the new AWS CDK EKS v2 L2 Constructs","url":"https://aws.amazon.com/blogs/devops/announcing-the-new-aws-cdk-eks-v2-l2-constructs/","date":1750367221,"author":"Matteo Luigi Restelli","guid":163138,"unread":true,"content":"<p>Today, we’re announcing the release of  construct, a new alpha version of <a href=\"https://aws.amazon.com/cdk/\">AWS Cloud Development Kit (CDK)</a> L2 construct for <a href=\"https://aws.amazon.com/eks/\">Amazon Elastic Kubernetes Service (EKS)</a>. This construct represents a significant change in how developers can define and manage their EKS environments using infrastructure as code. While maintaining the powerful capabilities of its <a href=\"https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_eks-readme.html\">predecessor library</a> for creating and managing EKS clusters, this alpha release introduces key architectural improvements that enhance both flexibility and maintainability.</p><p>The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework that enables you to define your cloud infrastructure using familiar programming languages and deploy it through AWS CloudFormation. The CDK uses <a href=\"https://docs.aws.amazon.com/cdk/v2/guide/constructs.html\">constructs</a> – a layered abstraction concept where Layer 1 (L1) constructs map directly to CloudFormation resources, while Layer 2 (L2) constructs provide intuitive APIs, helper functions, best-practice defaults, and generate a lot of the boilerplate code and glue logic for you. This layered approach means you can seamlessly move between high-level abstractions for common use cases and low-level resource definitions when you need fine-grained control. The result is an Infrastructure as Code (IaC) experience that helps you maintain productivity while ensuring you have access to the full power of AWS services when you need it. You can read more about constructs and their benefits in the <a href=\"https://docs.aws.amazon.com/cdk/v2/guide/constructs.html\">CDK user guide</a>.</p><p>In this post we’ll explore:</p><ul><li>How to use the new EKS v2 construct</li></ul><p>Amazon EKS is a managed Kubernetes service that makes it easy to run Kubernetes on AWS without needing to manage the control plane or nodes. EKS automatically handles critical tasks like patching, node provisioning, and upgrades. You can run EKS using EC2 instances for worker nodes, <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/fargate.html\">AWS Fargate</a> for serverless containers, or a combination of both, providing the flexibility to choose the right compute option for your workloads.</p><p>While the <a href=\"https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_eks-readme.html\">existing EKS L2 construct</a> has served customers well, we identified opportunities to further enhance the developer experience and operational efficiency based on their feedback. The new  construct delivers significant improvements through native <a href=\"https://aws.amazon.com/it/cloudformation/\">AWS CloudFormation</a> resources, modern <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/access-entries.html\">Access Entry-based authentication</a>, and enhanced architectural flexibility. Key benefits include reduced deployment overhead, simplified cluster access management, support for multiple EKS clusters within a single stack, and granular control over resource creation with features like the optional  Lambda handler. These improvements help customers build and manage their EKS infrastructure more efficiently while maintaining the robust functionality they expect from AWS CDK constructs.</p><p>Given that this construct is in the alpha stage, you’ll need to install and import the construct using the <a href=\"https://aws.amazon.com/blogs/developer/experimental-construct-libraries-are-now-available-in-aws-cdk-v2/\">experimental construct libraries process</a>. During the alpha stage, the CDK team is actively gathering customer feedback and iterating on the implementation. Once the construct meets our bar for general availability, we’ll integrate it directly into the AWS CDK core library, making it as easily accessible as our other L1 and L2 constructs. This approach allows us to rapidly deliver new capabilities while ensuring they meet the high standards our customers expect.</p><h3>Deploying EKS Cluster with Default Configuration</h3><p>Let’s explore how to create an Amazon EKS cluster using AWS CDK  construct with minimal configuration requirements. The following example demonstrates the most straightforward way to define an EKS cluster, leveraging the power of CDK’s opinionated defaults. Creating a new cluster is done using the  construct. The only required property is the Kubernetes version.</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\n\n// Creating an EKS Cluster with default properties\nconst eksCluster = new eksv2.Cluster(this, 'EksCluster', {\n    version: eksv2.KubernetesVersion.V1_32\n});</code></pre><p>This translates in the following Architecture as shown in figure 1:</p><p><em>Figure 1 – L2 CDK construct v2 for EKS, Default Architecture</em></p><ul><li> – A logically isolated section of the AWS Cloud that spans across two Availability Zones, equipped with an Internet Gateway to enable secure communication with the internet. This multi-AZ design helps ensure your applications remain available even if an Availability Zone experiences issues.</li><li> – A fully managed Kubernetes control plane deployed in an AWS-managed VPC , providing high availability and automatic version management for the Kubernetes control plane components.</li><li><strong>Public Subnet Infrastructure</strong> – Two public subnets, each with its own <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html\">NAT Gateway</a> Instance, enabling your cluster components to securely access the internet for essential operations like pulling container images and downloading updates. These NAT Gateways provide a secure outbound path while protecting your workloads from direct internet exposure.</li><li><strong>Private Subnet Configuration</strong> – Two private subnets optimized for running your EKS worker nodes, offering enhanced security by isolating your workloads from direct internet access while maintaining the ability to communicate with AWS services and the internet through the NAT Gateways.</li><li> – A comprehensive set of <a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html\">IAM roles</a> and policies that implement the principle of least privilege: \n  <ul><li>Control plane service role that enables EKS to manage AWS resources on your behalf</li><li>Node IAM role that allows worker nodes to interact with other AWS services and join the EKS cluster</li></ul></li></ul><p>You can also use  to provision a cluster that uses only Fargate workers.</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\n\n// Creating an EKS Cluster with default properties and Fargate workers\nconst eksFargateCluster = new eksv2.FargateCluster(this, 'EksFargateCluster', {\n   version: eksv2.KubernetesVersion.V1_32,\n});</code></pre><p>To help our customers maintain better control over their cluster access patterns, the Kubectl Handler is not automatically deployed with the default configuration. You can easily enable this functionality by configuring the  property when you need kubectl access management as shown below.</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\nimport { KubectlV32Layer } from '@aws-cdk/lambda-layer-kubectl-v32'\n\n// Creating an EKS Cluster with default properties and kubectl handler\nconst eksCluster = new eksv2.Cluster(this, 'EksCluster', {\n   version: eksv2.KubernetesVersion.V1_32,\n   kubectlProviderOptions: {\n      kubectlLayer: new KubectlV32Layer(this, 'KubectlLayer')\n   },\n});</code></pre><h3>Deploying EKS Cluster with AutoMode</h3><p><a href=\"https://docs.aws.amazon.com/eks/latest/userguide/automode.html\">EKS Auto Mode</a> represents a significant advancement in how Amazon EKS manages compute capacity for Kubernetes clusters. This intelligent capacity management system automatically provisions and scales node groups based on workload demands, removing the need for manual capacity planning.</p><p>When you create a new cluster with the  construct, EKS Automode is activated by default, by means that <code>DefaultCapacityType.AUTOMODE</code> is automatically set as the default capacity type for the EKS Cluster. If you prefer, you can specify the  to AutoMode:</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\n\n// Creating an EKS Cluster with AutoMode\nconst eksCluster = new eksv2.Cluster(this, 'EksCluster', {\n   version: eksv2.KubernetesVersion.V1_32,\n   defaultCapacityType: eksv2.DefaultCapacityType.AUTOMODE, // default value\n});\n</code></pre><p>After deploying the Stack containing the construct instance, in the EKS Console you’ll be able to see that an EKS Cluster has been created with AutoMode enabled:</p><p><em>Figure 2 – EKS Cluster Deployed with Automode</em></p><p>Auto Mode enhances your Amazon EKS experience by automatically configuring two strategically designed node pools out of the box:</p><ul><li>A system node pool optimized for running critical cluster system components and add-ons, ensuring reliable cluster operations.</li><li>A general node pool specifically tuned for your application workloads, providing the flexibility needed for diverse containerized applications.</li></ul><p>You can configure which node pools to enable through the  property:</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\n\n// Creating an EKS Cluster with Automode and selecting nodePools\nconst eksCluster = new eksv2.Cluster(this, 'EksCluster', {\n   version: eksv2.KubernetesVersion.V1_32,\n   defaultCapacityType: eksv2.DefaultCapacityType.AUTOMODE,\n   compute: {\n      nodePools: ['system', 'general-purpose'],\n   },\n});</code></pre><h3>Deploying EKS Cluster with Managed Node Groups</h3><p><a href=\"https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html\">Amazon EKS Managed Node Groups</a> deliver a seamless compute management experience for your Kubernetes clusters. This powerful capability eliminates operational complexity by automating the end-to-end lifecycle of Amazon EC2 instances that power your containerized applications. Behind the scenes, Amazon EKS managed node groups intelligently orchestrate these changes, ensuring zero-disruption to your applications through graceful node draining. The service automatically leverages the latest Amazon EKS-optimized AMIs, providing a secure and optimized foundation for your workloads.</p><p>By setting  to , customers can leverage the traditional managed node group management approach:</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\n\n// Creating an EKS Cluster with Managed Node Groups and default instance types\nconst eksCluster = new eksv2.Cluster(this, 'EksCluster', {\n   version: eksv2.KubernetesVersion.V1_32,\n   defaultCapacityType: eksv2.DefaultCapacityType.NODEGROUP,\n});\n</code></pre><p>By default, when using <code>DefaultCapacityType.NODEGROUP</code>, this library will allocate a managed node group with two  instances. After deploying the above code, you can check the EKS Console to see that an EKS Cluster has been deployed as shown in figure 3:</p><p><em>Figure 3 – EKS Cluster Deployed with Managed Node Groups</em></p><p>You can also check the Compute tab and see the Managed Node Group Configuration as shown in figure 4:</p><p><em>Figure 4 – EKS Cluster Managed Node Group Default Configuration</em></p><p>If you want to have control over instance types of a Managed Node Group, you can specify the default EC2 type as property of the construct:</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\nimport * as ec2 from 'aws-cdk-lib/aws-ec2'\n\n// Creating an EKS Cluster with Managed Node Groups and specific instance types\nconst eksCluster = new eksv2.Cluster(this, 'EksCluster', {\n   version: eksv2.KubernetesVersion.V1_32,\n   defaultCapacityType: eksv2.DefaultCapacityType.NODEGROUP,\n   defaultCapacity: 5,\n   defaultCapacityInstance: ec2.InstanceType.of(ec2.InstanceClass.M5, ec2.InstanceSize.SMALL),\n});\n</code></pre><p>You can also specify additional customizations after the EKS cluster declaration, via the  method:</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\nimport * as ec2 from 'aws-cdk-lib/aws-ec2'\n\n// Creating an EKS Cluster with Managed Node Groups and specific instance types\nconst eksCluster = new eksv2.Cluster(this, 'EksCluster', {\n   version: eksv2.KubernetesVersion.V1_32,\n   defaultCapacityType: eksv2.DefaultCapacityType.NODEGROUP,\n   defaultCapacity: 0,\n});\n\neksCluster.addNodegroupCapacity('custom-node-group', {\n  instanceTypes: [new ec2.InstanceType('m5.large')],\n  minSize: 4,\n  diskSize: 100,\n});\n</code></pre><h3>Managing Permissions through Access Entries</h3><p>The new  construct transitions away from the previous ConfigMap-based authentication (which is deprecated in EKS) in favor of the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/access-entries.html\">Access Entries Authentication mode</a>. This change introduces Access Entry as the standardized method for managing cluster permissions, offering a more streamlined and secure approach to granting cluster access to IAM users and roles.</p><p>You can define Access Policies through the  construct and you can adjust the scope of the Access Policy to the entire EKS cluster or to specific EKS Namespaces:</p><pre><code>import * as eksv2 from '@aws-cdk/aws-eks-v2-alpha';\n\n// AmazonEKSClusterAdminPolicy with `cluster` scope\neks.AccessPolicy.fromAccessPolicyName('AmazonEKSClusterAdminPolicy', {\n   accessScopeType: eks.AccessScopeType.CLUSTER,\n});\n\n// AmazonEKSAdminPolicy with `namespace` scope\neks.AccessPolicy.fromAccessPolicyName('AmazonEKSAdminPolicy', {\n   accessScopeType: eks.AccessScopeType.NAMESPACE,\n   namespaces: ['foo', 'bar'] \n});</code></pre><p>You can then grant access to specific IAM Roles using the  method:</p><pre><code>import * as iam from 'aws-cdk-lib/aws-iam'\n\n// Defining a IAM Role\nconst clusterAdminRole = new iam.Role(this, 'ClusterAdminRole', {\n   assumedBy: new iam.ArnPrincipal('arn_for_trusted_principal'),\n});\n\n// Creating an EKS Cluster with AutoMode\nconst eksCluster = new eksv2.Cluster(this, 'EksCluster', {\n   version: eksv2.KubernetesVersion.V1_32,\n   defaultCapacityType: eksv2.DefaultCapacityType.AUTOMODE,\n});\n\n// Cluster Admin role for this cluster\neksCluster.grantAccess('clusterAdminAccess', clusterAdminRole.roleArn, [\n\teks.AccessPolicy.fromAccessPolicyName('AmazonEKSClusterAdminPolicy', {\n   \t    accessScopeType: eks.AccessScopeType.CLUSTER,\n    }),\n]);</code></pre><p>When the Principal assumes the , it receives seamless access to the EKS cluster through a carefully orchestrated permission chain. This access is governed by the <code>AmazonEKSClusterAdminPolicy</code>, which is automatically attached to the Access Policy linked to the IAM Role.</p><p>In this post, we introduced the new <a href=\"https://docs.aws.amazon.com/cdk/api/v2/docs/aws-eks-v2-alpha-readme.html\">AWS CDK L2 construct  for Amazon EKS</a>, demonstrating how it simplifies cluster deployment while offering enhanced flexibility and operational efficiency. Through practical examples, we showcased how customers can leverage the construct’s intelligent defaults and customization options to build production-ready Kubernetes environments on AWS</p><p>The new L2 construct for Amazon EKS delivers significant improvements that help customers accelerate their container adoption journey:</p><ul><li>: Eliminates dependency on Custom Resources and <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/welcome.html\">AWS Lambda</a> functions by utilizing native <a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html\">AWS CloudFormation</a> resources, resulting in faster and more reliable deployments.</li><li>: Implements Access Entry-based authentication, replacing the deprecated ConfigMap approach with a more secure and programmable solution.</li><li>: Removes the single-cluster-per-stack limitation and eliminates nested stacks, enabling more flexible architectural patterns.</li><li><strong>Optimized Resource Creation</strong>: Makes the kubectl Lambda handler optional, giving customers fine-grained control over their infrastructure components.</li><li>: Provides automated node group management with intelligent defaults while maintaining full customer control when needed.</li></ul><p>To get started with the new EKS L2 construct, visit the <a href=\"https://docs.aws.amazon.com/cdk/api/v2/docs/aws-eks-v2-alpha-readme.html\">AWS CDK documentation</a>. If you have specific features you’d like to see added, we encourage you to submit a feature request in the <a href=\"https://github.com/aws/aws-cdk\">aws-cdk GitHub repository</a>. Your feedback helps us continue innovating on your behalf.</p>","contentLength":14520,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Accelerate development with secure access to Amazon Q Developer using PingIdentity","url":"https://aws.amazon.com/blogs/devops/accelerate-development-with-secure-access-to-amazon-q-developer-using-pingidentity/","date":1750366994,"author":"Sid Vantair","guid":163116,"unread":true,"content":"<p>Customers adopting <a href=\"https://aws.amazon.com/q/developer/\">Amazon Q Developer</a>, a generative AI-powered coding companion, often need authentication through existing identity providers like PingIdentity. By leveraging <a href=\"https://aws.amazon.com/iam/identity-center/\">AWS IAM Identity Center</a>, organizations can enable their developers to access Amazon Q Developer with their existing PingIdentity credentials, streamlining authentication and removing the need for separate login procedures. Amazon Q Developer can chat about code, provide inline code completions, and generate new code. It also scans your code for security vulnerabilities and makes code improvements, including language updates, debugging, and optimizations. Amazon Q Developer comes in two tiers. The Free Tier is available at no cost for individual use. The Pro Tier is a paid version offering enterprise access controls, an analytics dashboard, customization, and higher usage limits. Organizations that enable the Pro tier of Amazon Q Developer for their developers typically authenticate with AWS IAM Identity Center. This approach is popular due to its ability to federate with external identity providers. In this blog, we will show you how to set up PingIdentity as an external IdP for IAM Identity Center and allow developers to access Amazon Q Developer using their existing PingIdentity login credentials.</p><div><img aria-describedby=\"caption-attachment-22919\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-1.png\" alt=\"AWS authentication flow diagram: Developers interact with Amazon Q Developer and AWS IAM Identity Center, integrating with Ping Identity for SAML-based access.\" width=\"977\" height=\"323\"><p>Figure 1 – Solution Overview</p></div><p>The authentication workflow is as follows:</p><ol><li>The developer initiates an access request to Amazon Q Developer.</li><li>IAM Identity center checks authentication status.</li><li>If not authenticated, redirects to PingIdentity login.</li><li>Developer provides PingIdentity Credentials.</li><li>PingIdentity validates credentials and sends SAML response.</li><li>IAM Identity Center verifies the SAML response.</li><li>Upon successful verification, grants Amazon Q Developer access.</li><li>Developer begins using Amazon Q Developer.</li></ol><ul><li>PingIdentity environment with users and groups already setup for Amazon Q Developer access</li><li>Pro Tier subscription of Amazon Q Developer</li></ul><p>In this section, we demonstrate how to create a SAML-based connection between PingIdentity and IAM Identity Center, enabling you to access Amazon Q Developer seamlessly using your PingIdentity credentials.</p><p>:&nbsp;You will need to switch between PingIdentity portal and IAM Identity Center in your browser. We recommend opening a new browser tab for each console.</p><h3>Step 1: Enable AWS Single Sign-On in PingIdentity</h3><p>This step involves enabling AWS Single Sign-On application within PingIdentity.</p><ol><li><ol><li>In the PingIdentity console, Navigate to the <strong>Applications Tab &gt; Application Catalog</strong></li><li>for AWS Single Sign-On and select to start the .</li></ol></li></ol><div><img aria-describedby=\"caption-attachment-22920\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-2.png\" alt=\"Screenshot of the PingIdentity Application Catalog interface. The search term &quot;aws&quot; is entered in the search bar, displaying three results: Amazon Web Services – AWS, AWS Gov-Cloud, and AWS Single Sign-On. The &quot;AWS Single Sign-On&quot; option is outlined with a red box and includes a plus button to add the application\" width=\"746\" height=\"329\"><p>Figure 2 – PingIdentity Application Catalog</p></div><p><em>Alt Text: Screenshot of the PingIdentity Application Catalog interface. The search term “aws” is entered in the search bar, displaying three results: Amazon Web Services – AWS, AWS Gov-Cloud, and AWS Single Sign-On. The “AWS Single Sign-On” option is outlined with a red box and includes a plus button to add the application</em></p><ol><li><ol start=\"3\"><li>Provide <strong>Name, SSO Region and SSO Tenant ID</strong> and choose <ul><li>Name – Input an appropriate name for the connection</li><li>SSO Region – Input the appropriate region</li><li>Tenant ID – Identity Store ID You can run the following CLI command to retrieve the value. It’s a 10-digit alphanumeric prefixed by “d-“.</li></ul></li></ol></li></ol><div><pre><code>aws sso-admin list-instances –query ‘Instances[0].IdentityStoreId’</code></pre></div><ol><li><ol start=\"4\"><li>Navigate to  and select  from the drop down.</li></ol></li></ol><div><img aria-describedby=\"caption-attachment-22921\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-3.png\" alt=\"Screenshot of the AWS Single Sign-On configuration in PingIdentity. The screen shows Step 2 of the setup process where the SAML attribute SAML_SUBJECT is mapped to the PingOne attribute &quot;Email Address&quot;. A red box highlights the mapping section under &quot;PingOne Mappings&quot;.\" width=\"811\" height=\"405\"><p>Figure 3 – AWS Single Sign-On attribute mapping</p></div><p><em>Alt Text: Screenshot of the AWS Single Sign-On configuration in PingIdentity. The screen shows Step 2 of the setup process where the SAML attribute SAML_SUBJECT is mapped to the PingOne attribute “Email Address”. A red box highlights the mapping section under “PingOne Mappings”.</em></p><ol><li><ol start=\"5\"><li>Search and select the group that you have created earlier for enabling access to Amazon Q Developer and select to add the group.</li></ol></li></ol><div><img aria-describedby=\"caption-attachment-22922\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/12/devops-16054-image-4.png\" alt=\"Screenshot of Step 3 in the AWS Single Sign-On setup process in PingIdentity. The screen shows the group selection interface where the &quot;Amazon Q&quot; group is listed. A plus icon is shown next to the group to add it, and a blue &quot;Save&quot; button is highlighted in the bottom-right corner to confirm the configuration.\" width=\"712\" height=\"545\"><p>Figure 4 – Select PingIdentity directory Groups for Amazon Q Developer access</p></div><p><em>Alt Text: Screenshot of Step 3 in the AWS Single Sign-On setup process in PingIdentity. The screen shows the group selection interface where the “Amazon Q” group is listed. A plus icon is shown next to the group to add it, and a blue “Save” button is highlighted in the bottom-right corner to confirm the configuration.</em></p><h3>Step 2: Connecting PingIdentity with IAM identity Center</h3><p>This step involves configuring PingIdentity with the AWS IAM Identity Center sign-on details to complete the authentication setup.</p><ol><li>In the PingIdentity console, Navigate to the <strong>Applications Tab &gt; Applications </strong>and select the application you created earlier in Step 1</li><li>Select <strong>Enable Advanced Configuration</strong> and choose .</li></ol><div><img aria-describedby=\"caption-attachment-22923\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-5.png\" alt=\"Screenshot of the PingIdentity Applications dashboard showing the AWS Single Sign-On application selected. The overview panel displays key configuration sections including protocol (SAML), mapped attributes, selected policies, and access group (Amazon Q). The option &quot;Enable Advanced Configuration&quot; is highlighted near the bottom of the panel.\" width=\"1528\" height=\"562\"><p>Figure 5 – Enable Advanced configuration for AWS single Sign-On application</p></div><p><em>Alt Text: Screenshot of the PingIdentity Applications dashboard showing the AWS Single Sign-On application selected. The overview panel displays key configuration sections including protocol (SAML), mapped attributes, selected policies, and access group (Amazon Q). The option “Enable Advanced Configuration” is highlighted near the bottom of the panel.</em></p><ol start=\"3\"><li>Scroll down and select This will save the Metadata file to your local computer, which you will use later during the configuration process.</li><li>Under , select  from the  drop-down menu.</li></ol><div><img aria-describedby=\"caption-attachment-22924\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-6.png\" alt=\"Screenshot of the IAM Identity Center settings page, focused on the &quot;Identity source&quot; tab. The page displays details such as identity source, authentication method, AWS access portal URL, issuer URL, and identity store ID. A dropdown menu labeled &quot;Actions&quot; is expanded in the top-right corner, showing options to &quot;Customize AWS access portal URL&quot; and &quot;Change identity source,&quot; highlighted with a red box.\" width=\"1537\" height=\"571\"><p>Figure 6 – Change identity source in IAM Identity Center Console</p></div><p><em>Alt Text: Screenshot of the IAM Identity Center settings page, focused on the “Identity source” tab. The page displays details such as identity source, authentication method, AWS access portal URL, issuer URL, and identity store ID. A dropdown menu labeled “Actions” is expanded in the top-right corner, showing options to “Customize AWS access portal URL” and “Change identity source,” highlighted with a red box.</em></p><ol start=\"6\"><li>On the next page, select <strong>External identity provider</strong> and choose .</li><li>Under <strong>Service provider metadata</strong> copy the <strong>IAM Identity Center Assertion Consumer Service (ACS) URL</strong>. <div><img aria-describedby=\"caption-attachment-22925\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-7.png\" alt=\"Screenshot of the &quot;Configure external identity provider&quot; step in the AWS IAM Identity Center setup process. The screen displays service provider metadata including the AWS access portal sign-in URL, IAM Identity Center Assertion Consumer Service (ACS) URL (highlighted with a red box), and IAM Identity Center issuer URL. A button labeled &quot;Download metadata file&quot; is shown in the upper right.\" width=\"1272\" height=\"505\"><p>Figure 7 – Copy IAM Identity Center ACS URL</p></div></li></ol><p><em> Alt Text: Screenshot of the “Configure external identity provider” step in the AWS IAM Identity Center setup process. The screen displays service provider metadata including the AWS access portal sign-in URL, IAM Identity Center Assertion Consumer Service (ACS) URL (highlighted with a red box), and IAM Identity Center issuer URL. A button labeled “Download metadata file” is shown in the upper right.</em></p><ol start=\"8 \"><li>Now go back to the PingIdentity browser tab and Navigate to the  tab and select to edit the details.</li><li>Paste the ACS URL you copied from the IAM identity center console and choose .</li></ol><div><img aria-describedby=\"caption-attachment-22986\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/12/devops-16054-image-26.png\" alt=\"Screenshots showing the configuration and editing of SAML settings for AWS Single Sign-On in PingIdentity. The first image displays the static configuration view, listing the ACS URL, signing key (&quot;PingOne SSO Certificate for Administrators environment&quot;), signing method (&quot;Response&quot;), and signing algorithm. The second image shows the editable configuration screen with the ACS URL input field highlighted in red, alongside dropdowns for selecting the signing key, options for signing method (Assertion, Response, or both), and the RSA_SHA256 signing algorithm. These screens guide users through setting up secure SAML integration with AWS SSO.\" width=\"1157\" height=\"332\"><p>Figure 8 – Configuring AWS Single Sign-On SAML Settings in PingIdentity console</p></div><p><em>Alt Text:&nbsp;Two screenshots showing the configuration and editing of SAML settings for AWS Single Sign-On in PingIdentity. The first image displays the static configuration view, listing the ACS URL, signing key (“PingOne SSO Certificate for Administrators environment”), signing method (“Response”), and signing algorithm. The second image shows the editable configuration screen with the ACS URL input field highlighted in red, alongside dropdowns for selecting the signing key, options for signing method (Assertion, Response, or both), and the RSA_SHA256 signing algorithm. These screens guide users through setting up secure SAML integration with AWS SSO.</em></p><h3>Step 3: Configure PingIdentity as external IdP in IAM identity Center</h3><p>This step involves setting up PingIdentity as an external IdP in IAM Identity Center to enable federated access.</p><ol><li>Navigate back to the previous browser tab where you had IAM Identity Center console open.</li><li>Upload the downloaded PingIdentity IdP SAML metadata file from step 3 of previous section and select </li></ol><div><img aria-describedby=\"caption-attachment-22928\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-10.png\" alt=\"Screenshot of the AWS Identity Center configuration screen where the user uploads the IdP SAML metadata XML file. The metadata file is shown as successfully selected. Below are empty fields for optional manual entry of IdP sign-in URL, IdP issuer URL, and IdP certificate. The &quot;Next&quot; button is highlighted in orange at the bottom right, indicating the next step in the setup process.\" width=\"952\" height=\"576\"><p>Figure 9 – AWS IAM Identity Center metadata</p></div><p><em>Alt Text: Screenshot of the AWS Identity Center configuration screen where the user uploads the IdP SAML metadata XML file. The metadata file is shown as successfully selected. Below are empty fields for optional manual entry of IdP sign-in URL, IdP issuer URL, and IdP certificate. The “Next” button is highlighted in orange at the bottom right, indicating the next step in the setup process.</em></p><ol start=\"3\"><li>Review the list of changes. Once you are ready to proceed, type then select .</li></ol><h3>Step 4: Enable provisioning and identity-aware sessions in IAM identity Center</h3><p>This step involves configuring user provisioning and enabling identity-aware sessions in AWS IAM Identity Center to support dynamic access control.</p><ol><li>On the  page, locate and enable <a href=\"https://docs.aws.amazon.com/singlesignon/latest/userguide/how-to-with-scim.html\" target=\"_blank\" rel=\"noopener noreferrer\">automatic provisioning</a>. This immediately enabled automatic provisioning in IAM Identity Center and displays the necessary SCIM endpoint and access token information.</li><li>In the&nbsp;Inbound automatic provisioning&nbsp;dialog box, copy each of the values for the following options. You will need to paste these later when you configure provisioning in PingIdentity. \n  <ul></ul></li></ol><div><img aria-describedby=\"caption-attachment-22929\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-11.png\" alt=\"Two options are displayed for further configuration: &quot;Enable identity-aware sessions&quot; and &quot;Automatic provisioning.&quot; Both options have an &quot;Enable&quot; button on the right-hand side, highlighted in red.\" width=\"1228\" height=\"378\"><p>Figure 10 – IAM Identity Center Settings for identity aware sessions and automatic provisioning</p></div><p><em>Alt Text: Two options are displayed for further configuration: “Enable identity-aware sessions” and “Automatic provisioning.” Both options have an “Enable” button on the right-hand side, highlighted in red.</em></p><h3>Step 5: Configure connections provisioning in PingIdentity</h3><p>This step involves setting up connection provisioning in PingIdentity to enable automatic user and group management.</p><ol><li>In the PingIdentity console, Navigate to the <strong>Integrations &gt; Provisioning.</strong></li><li>Select <strong>plus icon &gt; New Connection</strong></li><li>Under connection type Identity Store.</li></ol><div><img aria-describedby=\"caption-attachment-22930\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-12.png\" alt=\"PingIdentity Provisioning configuration screen. The left sidebar highlights the &quot;Provisioning&quot; tab. The main panel shows the &quot;Create a New Connection&quot; dialog with two connection type options: &quot;Identity Store&quot; and &quot;Gateway.&quot; The &quot;Identity Store&quot; option is selected using the &quot;Select&quot; button on the right. A plus (+) icon at the top indicates the option to add a new provisioning connection.\" width=\"1517\" height=\"646\"><p>Figure 11 – PingIdentity connection provisioning</p></div><p><em>Alt Text: PingIdentity Provisioning configuration screen. The left sidebar highlights the “Provisioning” tab. The main panel shows the “Create a New Connection” dialog with two connection type options: “Identity Store” and “Gateway.” The “Identity Store” option is selected using the “Select” button on the right. A plus (+) icon at the top indicates the option to add a new provisioning connection.</em></p><ol start=\"4\"><li>Select SCIM outbound from the list of options and select </li><li>Provide a name for the connection and select .</li><li>Paste the  into the  field.</li><li>Navigate to  and select .</li><li>Paste the into the Oauth Access Token field.</li><li>Select Test Connection to validate the connectivity and select .</li></ol><div><img aria-describedby=\"caption-attachment-22931\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-13.png\" alt=\"PingIdentity interface showing the &quot;Configure Authentication&quot; step in the &quot;Create a New Connection&quot; wizard. Key fields include the SCIM Base URL, SCIM Version (2.0), Authentication Method (OAuth 2 Bearer Token), OAuth Access Token (obscured), and resource paths for Users and Groups. The &quot;Test Connection&quot; and &quot;Next&quot; buttons are visible at the bottom.\" width=\"888\" height=\"707\"><p>Figure 12 – Configure authentication details</p></div><p><em>Alt Text: PingIdentity interface showing the “Configure Authentication” step in the “Create a New Connection” wizard. Key fields include the SCIM Base URL, SCIM Version (2.0), Authentication Method (OAuth 2 Bearer Token), OAuth Access Token (obscured), and resource paths for Users and Groups. The “Test Connection” and “Next” buttons are visible at the bottom.</em></p><ol start=\"10\"><li>Navigate to  and change to .</li><li>Choose . By default, the connection is created in a Disabled state.</li></ol><div><img aria-describedby=\"caption-attachment-22932\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-14.png\" alt=\"Final step in the PingIdentity &quot;Create a New Connection&quot; wizard showing the &quot;Configure Preferences&quot; screen. The highlighted fields include &quot;User Filter Expression&quot; with the value userName Eq &quot;%s&quot;, &quot;User Identifier&quot; set to userName, and group membership handling options (&quot;Merge&quot; and &quot;Overwrite&quot; with &quot;Overwrite&quot; selected). A &quot;Save&quot; button is highlighted at the bottom right.\" width=\"882\" height=\"705\"><p>Figure 13 – Edit UserFilter Expressions for the connection</p></div><p><em>Alt Text: Final step in the PingIdentity “Create a New Connection” wizard showing the “Configure Preferences” screen. The highlighted fields include “User Filter Expression” with the value userName Eq “%s”, “User Identifier” set to userName, and group membership handling options (“Merge” and “Overwrite” with “Overwrite” selected). A “Save” button is highlighted at the bottom right.</em></p><ol start=\"12\"><li>Select the connection you created and select the toggle switch to  the connection.</li></ol><div><img aria-describedby=\"caption-attachment-22933\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-15.png\" alt=\"PingIdentity configuration screen showing the IAM Identity Store integration. The page displays the identity store name, and tabs for &quot;Overview&quot; and &quot;Configuration.&quot; A toggle switch in the top-right corner is highlighted, indicating the integration is currently enabled.\" width=\"865\" height=\"242\"><p>Figure 14 – Enable the connection</p></div><p><em>Alt Text: PingIdentity configuration screen showing the IAM Identity Store integration. The page displays the identity store name, and tabs for “Overview” and “Configuration.” A toggle switch in the top-right corner is highlighted, indicating the integration is currently enabled.</em></p><h3>Step 6: Configure rules provisioning in PingIdentity</h3><p>This step involves setting up provisioning rules in PingIdentity to define how users and groups are synchronized.</p><ol><li>In the PingIdentity console, Navigate to the <strong>Integrations &gt; Provisioning.</strong></li><li>Select </li><li>Provide a Name and Description for the rule.</li><li>Select  to select the Connection you created in the previous step.</li></ol><div><img aria-describedby=\"caption-attachment-22990\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/12/devops-16054-image-27.png\" alt=\"Alt Text: Screenshots showing the final steps in connecting the IAM Identity Center to the IAM identity store using PingIdentity. The first image shows the IAM Identity Store connection listed under &quot;Available Connections&quot; with a plus (+) icon to initiate the link. The second image shows the selected connection from the PingOne Directory (P1) as the source and IAM identity store (SCIM) as the target, with the option to &quot;Save&quot; the configuration.\" width=\"1121\" height=\"341\"><p>Figure 15 – Add the IAM identity center connection to the rule</p></div><p><em>Alt Text: Screenshots showing the final steps in connecting the IAM Identity Center to the IAM identity store using PingIdentity. The first image shows the IAM Identity Store connection listed under “Available Connections” with a plus (+) icon to initiate the link. The second image shows the selected connection from the PingOne Directory (P1) as the source and IAM identity store (SCIM) as the target, with the option to “Save” the configuration.</em></p><ol start=\"7\"><li>If you want to sync users from your PingIdentity directory, create a user filter. To do so, navigate to  and select  to edit the settings.</li><li>Choose the appropriate filter from the drop down based on your use case and select . I have chosen Group Name which has been designated for Amazon Q Developer access.</li></ol><div><img aria-describedby=\"caption-attachment-22936\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-18.png\" alt=\"Screenshot of the &quot;Edit User Filter&quot; interface in IAM Identity Center. The user filter is configured to provision users who belong to a group with names that contain &quot;Amazon Q Developer.&quot; The condition logic is set to match if &quot;Any&quot; of the conditions are true.\" width=\"1521\" height=\"456\"><p>Figure 16 – PingIdentity user filter</p></div><p><em>Alt Text: Screenshot of the “Edit User Filter” interface in IAM Identity Center. The user filter is configured to provision users who belong to a group with names that contain “Amazon Q Developer.” The condition logic is set to match if “Any” of the conditions are true.</em></p><ol start=\"9\"><li>If you want to sync a group from your PingIdentity directory, create group provisioning. To do so, navigate to  and select  to edit the settings.</li><li>Select the appropriate group which has been designated for Amazon Q Developer access and choose .</li></ol><div><img aria-describedby=\"caption-attachment-22937\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-19.png\" alt=\"Screenshot of the &quot;Edit Group Provisioning&quot; screen in IAM Identity Center. The group &quot;Amazon Q Developer&quot; is selected for outbound provisioning. A &quot;Save&quot; button is highlighted in the bottom-left corner.\" width=\"882\" height=\"683\"><p>Figure 17 – PingIdentity Group Provisioning</p></div><p><em>Alt Text: Screenshot of the “Edit Group Provisioning” screen in IAM Identity Center. The group “Amazon Q Developer” is selected for outbound provisioning. A “Save” button is highlighted in the bottom-left corner.</em></p><ol start=\"11\"><li>Navigate to Attribute Mapping and select the pencil icon to edit the settings.</li><li>Delete the PingOne Directory attribute .</li><li>Add a new attribute and select Username as PingOne Directory and displayName as IAM identity Store.</li></ol><div><img aria-describedby=\"caption-attachment-22993\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/12/devops-16054-image-28.png\" alt=\"Two screenshots showing the editing of attribute mappings in IAM Identity Center. The first image displays default mappings such as 'Email Address' to 'workEmail' and 'Username' to 'userName', with an option to delete or update each field. The second image shows the addition of a new attribute mapping from 'Username' to 'displayName', along with highlighted 'Add' and 'Save' buttons.\" width=\"1281\" height=\"475\"><p>Figure 18 – PingIdentity attribute mapping</p></div><p><em>Alt Text: Two screenshots showing the editing of attribute mappings in IAM Identity Center. The first image displays default mappings such as ‘Email Address’ to ‘workEmail’ and ‘Username’ to ‘userName’, with an option to delete or update each field. The second image shows the addition of a new attribute mapping from ‘Username’ to ‘displayName’, along with highlighted ‘Add’ and ‘Save’ buttons.</em></p><ol start=\"15\"><li>Select the rule you created and select the toggle switch to enable the rule.</li><li>This automatically provisions the users/groups from PingIdentity to IAM identity Center using SCIM.</li></ol><div><img aria-describedby=\"caption-attachment-22994\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/12/devops-16054-image-29.png\" alt=\"IAM Identity Center sync summary showing successful user and group provisioning. The first image highlights two users impacted and successfully synced. The second image highlights one group impacted and successfully synced. Sync status is marked 'ACTIVE' in both views, confirming successful integration between PingOne and AWS IAM Identity Center.\" width=\"1266\" height=\"485\"><p>Figure 19 – PingIdentity Users and Groups Sync status using SCIM</p></div><p><em>Alt Text: IAM Identity Center sync summary showing successful user and group provisioning. The first image highlights two users impacted and successfully synced. The second image highlights one group impacted and successfully synced. Sync status is marked ‘ACTIVE’ in both views, confirming successful integration between PingOne and AWS IAM Identity Center.</em></p><h3>Step 7: Provide access to Amazon Q Developer</h3><p>This step involves locating and subscribing the groups that need permission to use Amazon Q Developer.</p><ol><li>In the <a href=\"https://us-east-1.console.aws.amazon.com/amazonq/developer/home\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Q Developer console</a>, under Subscriptions add the IAM identity center groups which require access to Amazon Q Developer.</li><li>Select and search for the group name.</li></ol><div><img aria-describedby=\"caption-attachment-22942\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-24.png\" alt=\"Screenshot of the Amazon Q Developer Subscriptions page in the AWS Management Console. The &quot;Groups&quot; tab is selected, displaying “Amazon Q Developer,” with a subscription status of “Subscribed.” The “Amazon Q Developer” group is highlighted with a red box.\" width=\"1543\" height=\"605\"><p>Figure 20 – Amazon Q Developer subscriptions page</p></div><p><em>Alt Text: Screenshot of the Amazon Q Developer Subscriptions page in the AWS Management Console. The “Groups” tab is selected, displaying “Amazon Q Developer,” with a subscription status of “Subscribed.” The “Amazon Q Developer” group is highlighted with a red box.</em></p><h2>Setup Amazon Q Developer with IAM Identity Center</h2><p>This section guides you through installing the Amazon Q Developer extension and setting up authentication with IAM Identity Center.</p><ol><li>To set up Amazon Q Developer extension in your integrated development environment (IDE), complete the steps in <a href=\"https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/q-in-IDE-setup.html#setup-vscode\" target=\"_blank\" rel=\"noopener noreferrer\">AWS documentation</a>.</li><li>Once extension is installed Choose Amazon Q icon in your IDE.</li><li>Select Use with Pro license and choose</li><li>Provide the Start URL. You can retrieve this AWS access portal URL from the IAM Identity Center Console.</li></ol><div><img aria-describedby=\"caption-attachment-22943\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-25.png\" alt=\"Screenshot of the IAM Identity Center settings page in the AWS Console, displaying the identity source configuration. It shows that the identity source is set to &quot;External identity provider&quot; with SAML 2.0 authentication and SCIM provisioning. The highlighted section includes the AWS access portal URL and the Identity Store ID. The &quot;Settings&quot; tab is selected in the left navigation pane.\" width=\"1510\" height=\"598\"><p>Figure 21 – IAM identity center access portal URL</p></div><p><em>Alt Text: Screenshot of the IAM Identity Center settings page in the AWS Console, displaying the identity source configuration. It shows that the identity source is set to “External identity provider” with SAML 2.0 authentication and SCIM provisioning. The highlighted section includes the AWS access portal URL and the Identity Store ID. The “Settings” tab is selected in the left navigation pane.</em></p><ol start=\"7\"><li>Provide the region that hosts the identity directory and choose </li><li>Select on the resulting pop up which redirects to your browser.</li><li>The browser redirects you to the Pingone URL where you enter your PingIdentity credentials and select .</li><li>Upon successful authentication, select on the resulting pop up to login successfully.</li></ol><div><img aria-describedby=\"caption-attachment-22959\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-26-3.gif\" alt=\"A screen recording of Visual Studio Code where the user selects the Amazon Q icon from the sidebar. The screen transitions to a login prompt indicating that the user must authenticate using their PingIdentity credentials via IAM Identity Center before accessing Amazon Q Developer features. The message highlights that authentication is required to continue.\" width=\"800\" height=\"413\"><p>Figure 22 – Setup Visual Studio Code Amazon Q Developer extension</p></div><p><em>Alt Text: A screen recording of Visual Studio Code where the user selects the Amazon Q icon from the sidebar. The screen transitions to a login prompt indicating that the user must authenticate using their PingIdentity credentials via IAM Identity Center before accessing Amazon Q Developer features. The message highlights that authentication is required to continue.</em></p><p>Upon successfully completing the previous step, you can now leverage the code suggestions by Amazon Q Developer.</p><div><img aria-describedby=\"caption-attachment-22944\" loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-27.gif\" alt=\"A screen recording of Visual Studio Code where Amazon Q Developer generates a sample code inline.\" width=\"1920\" height=\"1080\"><p>Figure 23 – Amazon Q Developer example</p></div><p><em>Alt Text: A screen recording of Visual Studio Code where Amazon Q Developer generates a sample code inline. </em></p><p>To avoid ongoing charges after testing this solution, follow these steps to remove all provisioned resources:1. Remove PingIdentity Application Configuration</p><ul><li>In the , navigate to .</li><li>Locate and delete the  application that was configured for IAM Identity Center integration.</li></ul><p>2. Reset IAM Identity Center Configuration</p><ul><li>In the  console: \n  <ul><li>Navigate to <strong>Settings &gt; Identity source</strong>.</li><li>Change the identity source back to the default <strong>IAM Identity Center directory</strong> if no longer using PingIdentity.</li><li>Remove any external metadata and configuration uploaded during the setup.</li></ul></li></ul><p>3. Revoke Subscriptions and Access</p><ul><li>In the <strong>Amazon Q Developer console</strong>: \n  <ul><li>Go to  and remove assigned groups such as  or .</li><li>This will deactivate access and prevent any future charges tied to those subscriptions.</li></ul></li></ul><p>4. Remove Amazon Q Developer Extension</p><ul><li>If desired, uninstall the <strong>Amazon Q Developer extension</strong> from Visual Studio Code to fully revert the development environment.</li></ul><p>In this post, we demonstrated how to use existing PingIdentity credentials to access Amazon Q Developer through integration with IAM Identity Center. We provided a step-by-step guide for configuring PingIdentity as an external identity provider (IdP) with IAM Identity Center. Lastly, we demonstrated how to connect Amazon Q Developer extension within your IDE to AWS using your PingIdentity credentials, allowing seamless access to Amazon Q Developer.If you have any comments or questions, share them in the comments section.</p><p><strong>To learn more about AWS Services</strong></p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/11/devops-16054-image-28.jpg\" alt=\"\" width=\"524\" height=\"133\"> is a Solutions Architect with AWS covering Strategic accounts. He thrives on resolving complex technical issues to overcome customer hurdles. Outside of work, he cherishes spending time with his family and fostering inquisitiveness in his children.</p>","contentLength":19145,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AWS Extends MCP Support in Amazon Q Developer to Multiple IDEs","url":"https://devops.com/aws-extends-mcp-support-in-amazon-q-developer-to-multiple-ides/?utm_source=rss&utm_medium=rss&utm_campaign=aws-extends-mcp-support-in-amazon-q-developer-to-multiple-ides","date":1750338593,"author":"Mike Vizard","guid":162849,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why AI-based Code Generation Falls Short","url":"https://devops.com/why-ai-based-code-generation-falls-short/?utm_source=rss&utm_medium=rss&utm_campaign=why-ai-based-code-generation-falls-short","date":1750332788,"author":"Joydip Kanjilal","guid":162806,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Top 5 AI Trends for Developers","url":"https://devops.com/the-top-5-ai-trends-for-developers/?utm_source=rss&utm_medium=rss&utm_campaign=the-top-5-ai-trends-for-developers","date":1750331127,"author":"Sam Basu","guid":162805,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dependabot Your Way to Zero CVEs with Copac","url":"https://www.youtube.com/watch?v=yNym_Ui18ZM","date":1750327304,"author":"CNCF [Cloud Native Computing Foundation]","guid":162799,"unread":true,"content":"<article>Rebuilding images to fix CVEs is challenging—missing build contexts, third-party base images, and resource-intensive approval processes create significant obstacles. This talk demonstrates effective solutions using Trivy for vulnerability scanning.</article>","contentLength":250,"flags":null,"enclosureUrl":"https://www.youtube.com/v/yNym_Ui18ZM?version=3","enclosureMime":"","commentsUrl":null},{"title":"Cut the Wait: Testing Cloud Apps Without Constantly Redeploying","url":"https://www.youtube.com/watch?v=6U8uS-8PClE","date":1750316406,"author":"CNCF [Cloud Native Computing Foundation]","guid":162646,"unread":true,"content":"<article>Constantly having to redeploy your cloud apps and wait for CI pipelines just to test small code changes? It’s slow, frustrating, and hampers developer productivity. But with mirrord, an open-source tool, developers can instantly test locally written code in a real cloud environment, without repeated redeployments.\n\nJoin this webinar to see how mirrord simplifies and accelerates developer workflows by securely mirroring traffic and resources from your cloud environment directly to your local machine. Learn how to shorten feedback loops, identify issues faster, and empower your dev team to ship faster.</article>","contentLength":609,"flags":null,"enclosureUrl":"https://www.youtube.com/v/6U8uS-8PClE?version=3","enclosureMime":"","commentsUrl":null},{"title":"Cloud Native Live: Taming the configuration beast with Pkl!","url":"https://www.youtube.com/watch?v=jJVs6-QmXDo","date":1750309550,"author":"CNCF [Cloud Native Computing Foundation]","guid":162576,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon events in Hong Kong, China (June 10-11); Tokyo, Japan (June 16-17); Hyderabad, India (August 6-7); Atlanta, US (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io</article>","contentLength":405,"flags":null,"enclosureUrl":"https://www.youtube.com/v/jJVs6-QmXDo?version=3","enclosureMime":"","commentsUrl":null},{"title":"CNL: Integrating MCP metadata in your internal developer platform","url":"https://www.youtube.com/watch?v=MhyMLykUMUc","date":1750300995,"author":"CNCF [Cloud Native Computing Foundation]","guid":161762,"unread":true,"content":"<article>MCP, Model Context Protocol, is clearly the hot topic of 2025 and while we are seeing more and more interesting use cases around this, no one has really yet focused on all the metadata that MCP brings to the table: Tools description, Tool parameters description, prompt description. All of this is really useful information that can be used by the developer building AI Infused applications.\n\nIt’s also totally aligned with the Platform Engineering vision which tries to streamline the service catalogs to its platform user.\n\nJoin me in the mainly live coding session to see how to integrate MCP Metadata into your Platform Engineering strategy.</article>","contentLength":647,"flags":null,"enclosureUrl":"https://www.youtube.com/v/MhyMLykUMUc?version=3","enclosureMime":"","commentsUrl":null},{"title":"Atlassian Adds CLI Option to AI Agent for Building Software","url":"https://devops.com/atlassian-adds-cli-option-to-ai-agent-for-building-software/?utm_source=rss&utm_medium=rss&utm_campaign=atlassian-adds-cli-option-to-ai-agent-for-building-software","date":1750276864,"author":"Mike Vizard","guid":161485,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AWS Extends Cloud Security Reach to Include DevSecOps Tools to Scan Code","url":"https://devops.com/aws-extends-cloud-security-reach-to-include-devsecops-tools-to-scan-code/?utm_source=rss&utm_medium=rss&utm_campaign=aws-extends-cloud-security-reach-to-include-devsecops-tools-to-scan-code","date":1750271959,"author":"Mike Vizard","guid":161450,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Docker State of App Dev: Security","url":"https://www.docker.com/blog/docker-state-of-app-dev-security/","date":1750261918,"author":"Rebecca Floyd","guid":161290,"unread":true,"content":"<p><strong>Security is a team sport: why everyone owns it now</strong></p><p><em>Six security takeaways from</em><em>Docker’s 2025 State of Application Development Report.</em></p><p>In the evolving world of software development, one thing is clear — <strong>security is no longer a siloed specialty</strong>. It’s a team sport, especially when vulnerabilities strike. That’s one of several key security findings in the 2025 Docker State of Application Development Survey.</p><p>Here’s what else we learned about security from our second annual report, which was based on an online survey of over 4,500 industry professionals.</p><p><strong>1. Security isn’t someone else’s problem</strong></p><p>Forget the myth that only “security people” handle security. Across orgs big and small, roles are blending. If you’re writing code, you’re in the security game. As one respondent put it, “We don’t have dedicated teams — we all do it.” According to the survey, just <strong>1 in 5 organizations outsource security</strong>. And it’s top of mind at most others: only <strong>1% of respondents say security is not a concern </strong>at their organization.</p><p>One exception to this trend: In larger organizations (50 or more employees), software security is more likely to be the exclusive domain of security engineers, with other types of engineers playing less of a role.</p><p><strong>2. Everyone thinks they’re in charge of security</strong></p><p>Team leads from multiple corners report that <strong>they’re the ones focused on security</strong>. Seasoned developers are as likely to zero in on it as are mid-career security engineers. And they’re both right. Security has become woven into every function — devs, leads, and ops alike.</p><p><strong>3. When vulnerabilities hit, it’s all hands on deck</strong></p><p>No turf wars here. When scan alerts go off,  — whether it’s security engineers helping experienced devs to decode scan results, engineering managers overseeing the incident, or DevOps engineers filling in where needed.</p><p>Fixing vulnerabilities is also a major time suck. Among security-related tasks that respondents routinely deal with, it was the most selected option across all roles. Worth noting: Last year’s State of Application Development Survey identified security/vulnerability remediation tools as a key area where better tools were needed in the development process.</p><p><strong>4. Security isn’t the bottleneck — planning and execution are</strong></p><p>Surprisingly, security doesn’t crack the top 10 issues holding teams back. <strong>Planning and execution-type activities are bigger sticking points</strong>. Translation? Security is better integrated into the workflow than many give it credit for.&nbsp;</p><p><strong>5. Shift-left is yesterday’s news</strong></p><p>The once-pervasive mantra of “shift security left” is now only the . Has the shift left already happened? Is AI and cloud complexity drowning it out? Or is this further evidence that security is, by necessity, shifting everywhere?</p><p>Again, perhaps security tools have gotten better, making it easier to shift left. (Our 2024 survey identified the shift-left approach as a possible source of frustration for developers and an area where more effective tools could make a difference.) Or perhaps there’s simply broader acceptance of the shift-left trend.</p><p><strong>6. Shifting security left may not be the buzziest trend, but it’s still influential</strong></p><p>The impact of shifting security left pales beside more dominant trends such as Generative AI and infrastructure as code. But it’s still a strong influence for developers in leadership roles.&nbsp;</p><p> Security is no longer a roadblock; it’s a reflex. Teams aren’t asking, “Who owns security?” — they’re asking, “How can we all do it better?”</p>","contentLength":3541,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CloudBees Adds MCP Server to Unify Platform for Integrating DevOps Workflows","url":"https://devops.com/cloudbees-adds-mcp-server-to-unify-platform-for-integrating-devops-workflows/?utm_source=rss&utm_medium=rss&utm_campaign=cloudbees-adds-mcp-server-to-unify-platform-for-integrating-devops-workflows","date":1750260622,"author":"Mike Vizard","guid":161297,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Docker Chose OCI Artifacts for AI Model Packaging","url":"https://www.docker.com/blog/oci-artifacts-for-ai-model-packaging/","date":1750253533,"author":"Emily Casey","guid":161214,"unread":true,"content":"<p>As <a href=\"https://www.docker.com/products/ai-ml-development/\">AI development accelerates</a>, developers need tools that let them move fast without having to reinvent their workflows. <a href=\"https://www.docker.com/blog/introducing-docker-model-runner/\">Docker Model Runner</a> introduces a <a href=\"https://github.com/docker/model-spec\" rel=\"nofollow noopener\" target=\"_blank\">new specification</a> for packaging large language models (LLMs) as OCI artifacts — a format developers already know and trust. It brings <a href=\"https://github.com/docker/model-distribution\" rel=\"nofollow noopener\" target=\"_blank\">model sharing</a> into the same workflows used for containers, with support for OCI registries like Docker Hub.</p><p>By using OCI artifacts, teams can skip custom toolchains and work with models the same way they do with container images. In this post, we’ll share why we chose OCI artifacts, how the format works, and what it unlocks for GenAI developers.</p><p>One of Docker’s goals is to make genAI application development accessible to a larger community of developers. We can do this by helping models become first-class citizens within the cloud native ecosystem.&nbsp;</p><p>When models are packaged as OCI artifacts, developers can get started with AI development without the need to learn, vet, and adopt a new distribution toolchain. Instead, developers can discover new models on Hub and distribute variants publicly or privately via existing OCI registries, just like they do with container images today! For teams using Docker Hub, enterprise features like Registry Access Management (RAM) provide policy-based controls and guardrails to help enforce secure, consistent access.</p><p>Packaging models as OCI artifacts also paves the way for deeper integration between inference runners like Docker Model Runner and existing tools like containerd and Kubernetes.</p><h2>Understanding OCI images and artifacts</h2><p>Many of these advantages apply equally to OCI images and OCI artifacts. To understand why images can be a less optimal fit for LLMs and why a custom artifact specification conveys additional advantages, it helps to first revisit the components of an OCI image and its generic cousin, the OCI artifact.</p><p>OCI images are a standardized format for container images, defined by the<a href=\"https://opencontainers.org/\" rel=\"nofollow noopener\" target=\"_blank\"> Open Container Initiative (OCI)</a>. They package everything needed to run a container: metadata, configuration, and filesystem layers.</p><p>An OCI image is composed of three main components:</p><ul><li>An  – a JSON file containing references to an and a set of filesystem .</li><li>An  – a JSON file containing the layer ordering and OCI runtime configuration.</li><li>One or more  – TAR archives (typically compressed), containing filesystem changesets that, applied in order, produce a container root filesystem.</li></ul><p>Below is an example manifest from the busybox image:</p><div><pre>{\n  \"schemaVersion\": 2,\n  \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\n  \"config\": {\n    \"mediaType\": \"application/vnd.oci.image.config.v1+json\",\n    \"digest\": \"sha256:7b4721e214600044496305a20ca3902677e572127d4d976ed0e54da0137c243a\",\n    \"size\": 477\n  },\n  \"layers\": [\n    {\n      \"mediaType\": \"application/vnd.oci.image.layer.v1.tar+gzip\",\n      \"digest\": \"sha256:189fdd1508372905e80cc3edcdb56cdc4fa216aebef6f332dd3cba6e300238ea\",\n      \"size\": 1844697\n    }\n  ],\n  \"annotations\": {\n    \"org.opencontainers.image.url\": \"https://github.com/docker-library/busybox\",\n    \"org.opencontainers.image.version\": \"1.37.0-glibc\"\n  }\n}\n\n</pre></div><p>Because the image manifest contains content-addressable references to all image components, the hash of the manifest file, otherwise known as the image digest, can be used to uniquely identify an image.</p><p>OCI artifacts offer a way to extend the OCI image format to support distributing content beyond container images. They follow the same structure: a manifest, a config file, and one or more layers.&nbsp;</p><p>The <a href=\"https://github.com/opencontainers/image-spec/blob/main/artifacts-guidance.md\" rel=\"nofollow noopener\" target=\"_blank\">artifact guidance</a> in the OCI image specifications describes how this same basic structure (manifest + config + layers) can be used to distribute other types of content.<p>The artifact type is designated by the config file’s media type. For example, in the manifest below config.mediaType is set to application/vnd.cncf.helm.config.v1+json. This indicates to registries and other tooling that the artifact is a Helm chart and should be parsed accordingly.</p></p><div><pre>{\n  \"schemaVersion\": 2,\n  \"config\": {\n    \"mediaType\": \"application/vnd.cncf.helm.config.v1+json\",\n    \"digest\": \"sha256:8ec7c0f2f6860037c19b54c3cfbab48d9b4b21b485a93d87b64690fdb68c2111\",\n    \"size\": 117\n  },\n  \"layers\": [\n    {\n      \"mediaType\": \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\",\n      \"digest\": \"sha256:1b251d38cfe948dfc0a5745b7af5ca574ecb61e52aed10b19039db39af6e1617\",\n      \"size\": 2487\n    }\n  ]\n}\n\n</pre></div><p>In an OCI artifact, layers may be of any media type and are not restricted to filesystem changesets. Whoever defines the artifact type defines the supported layer types and determines how the contents should be used and interpreted.</p><h2>Using container images vs. custom artifact types</h2><p>With this background in mind, while we could have packaged LLMs as container images, defining a custom type has some important advantages:</p><ol><li>A custom artifact type allows us to define a domain-specific config schema. Programmatic access to key metadata provides a support structure for an ecosystem of useful tools specifically tailored to AI use-cases.</li><li>A custom artifact type allows us to package content in formats other than compressed TAR archives, thus avoiding performance issues that arise when LLMs are packaged as image layers. For more details on how model layers are different and why it matters, see the <a href=\"https://docs.google.com/document/d/14-TEPoE7zgAsNWnRXjgv7OYlENCZRC0hrYYXl5rOukI/edit?tab=t.0\" rel=\"nofollow noopener\" target=\"_blank\">Layers</a> section below.</li><li>A custom type ensures that models are packaged and distributed separately from inference engines. This separation is important because it allows users to consume the variant of the inference engine optimized for their system without requiring every model to be packaged in combination with every engine.</li><li>A custom artifact type frees us from the expectations that typically accompany a container image. Standalone models are not executable without an inference engine. Packaging as a custom type makes clear that they are not independently runnable, thus avoiding confusion and unexpected errors.</li></ol><p>Now that we understand the high-level goals, let’s dig deeper into the details of the format.</p><p>The model specification defines the following media types:</p><ul><li>application/vnd.docker.ai.model.config.v0.1+json – identifies a model config JSON file. This value in config.mediaType in a manifest identifies an artifact as a Docker model with config file adhering to v0.1 of the specification.</li><li>application/vnd.docker.ai.gguf.v3 – indicates that a layer contains a model packaged as a GGUF file.</li><li>application/vnd.docker.ai.license – indicates that a layer contains a plain text software license file.</li></ul><p>Expect more media types to be defined in the future as we add runtime configuration, add support for new features like projectors and LoRA adaptors, and expand the supported packaging formats for model files.</p><p>A model manifest is formatted like an image manifest and distinguished by the config.MediaType. The following example manifest, taken from the ai/gemma3, references a model config JSON and two layers, one containing a GGUF file and the other containing the model’s license.</p><div><pre>{\n  \"schemaVersion\": 2,\n  \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\n  \"config\": {\n    \"mediaType\": \"application/vnd.docker.ai.model.config.v0.1+json\",\n    \"size\": 372,\n    \"digest\": \"sha256:22273fd2f4e6dbaf5b5dae5c5e1064ca7d0ff8877d308eb0faf0e6569be41539\"\n  },\n  \"layers\": [\n    {\n      \"mediaType\": \"application/vnd.docker.ai.gguf.v3\",\n      \"size\": 2489757856,\n      \"digest\": \"sha256:09b370de51ad3bde8c3aea3559a769a59e7772e813667ddbafc96ab2dc1adaa7\"\n    },\n    {\n      \"mediaType\": \"application/vnd.docker.ai.license\",\n      \"size\": 8346,\n      \"digest\": \"sha256:a4b03d96571f0ad98b1253bb134944e508a4e9b9de328909bdc90e3f960823e5\"\n    }\n  ]\n}\n\n\n</pre></div><p>The manifest digest uniquely identifies the model and is used by Docker Model Runner as the model ID.</p><p>The model configuration is a JSON file that surfaces important metadata about the model, such as size, parameter count, quantization, as well as metadata about the artifact provenance (like the creation timestamp).The following example comes from the ai/gemma model on Dockerhub:</p><div><pre>{\n  \"config\": {\n    \"format\": \"gguf\",\n    \"quantization\": \"IQ2_XXS/Q4_K_M\",\n    \"parameters\": \"3.88 B\",\n    \"architecture\": \"gemma3\",\n    \"size\": \"2.31 GiB\"\n  },\n  \"descriptor\": {\n    \"created\": \"2025-03-26T09:57:32.086694+01:00\"\n  },\n  \"rootfs\": {\n    \"type\": \"rootfs\",\n    \"diff_ids\": [\n      \"sha256:09b370de51ad3bde8c3aea3559a769a59e7772e813667ddbafc96ab2dc1adaa7\",\n      \"sha256:a4b03d96571f0ad98b1253bb134944e508a4e9b9de328909bdc90e3f960823e5\"\n    ]\n  }\n}\n\n</pre></div><p>By defining a domain-specific configuration schema, we allow tools to access and use model metadata cheaply — by fetching and parsing a small JSON file — only fetching the model itself when needed.<p>For example, a registry frontend like Docker Hub can directly surface this data to users who can, in turn, use it to compare models or select based on system capabilities and requirements. Tooling might use this data to estimate memory requirements for a given model. It could then assist in the selection process by suggesting the best variant that is compatible with the available resources.</p></p><p>Layers in a model artifact differ from layers within an OCI image in two important respects.</p><p>Unlike an image layer, where compression is recommended, model layers are . Because models are large, high-entropy files, compressing them provides a negligible reduction in size, while (un)compressing is time and compute-intensive.</p><p>In contrast to a layer in an OCI image, which contains multiple files in an archive, each “layer” in a model artifact must contain a . This allows runtimes like Docker Model Runner to reduce disk usage on the client machine by storing a single uncompressed copy of the model. This file can then be directly memory mapped by the inference engine at runtime.</p><p>The lack of file names, hierarchy, and metadata (e.g. modification time) ensures that identical model files always result in identical reusable layer blobs. This prevents unnecessary duplication, which is particularly important when working with LLMs, given the file size.</p><p>You may have noticed that these “layers” are not really filesystem layers at all. They are files, but they do not specify a filesystem. So, how does this work at runtime? When Docker Model runner runs a model, instead of finding the GGUF file by name in a model filesystem, the desired file is identified by its media type (application/vnd.docker.ai.gguf.v3) and fetched from the model store. For more information on the Model Runner architecture, please see the architecture overview in this accompanying <a href=\"https://www.docker.com/blog/how-we-designed-model-runner-and-whats-next/\">blog post</a>.</p><p>Like OCI images and other OCI artifacts, Docker model artifacts are distributed via registries like Dockerhub, Artifactory, or Azure Container Registry that comply with the <a href=\"https://github.com/opencontainers/distribution-spec\" rel=\"nofollow noopener\" target=\"_blank\">OCI distribution specification</a>.</p><p>The Docker Hub Gen AI catalog aids in the discovery of<a href=\"https://hub.docker.com/catalogs/gen-ai\" rel=\"nofollow noopener\" target=\"_blank\"> popular models</a>. These models are packaged in the format described here and are compatible with Docker Model Runner and any other runtime that supports the OCI specification.</p><p>If you are accustomed to exploring models on Hugging Face, there’s good news! Hugging Face now supports on-demand conversion to the Docker Model Artifact format when you <a href=\"https://docs.docker.com/reference/cli/docker/model/pull/#pulling-from-huggingface\" rel=\"nofollow noopener\" target=\"_blank\">pull from Hugging Face</a> with docker model pull.</p><p>Hopefully, you now have a better understanding of the Docker OCI Model format and how it supports our goal of making AI app development more accessible to developers via familiar workflows and commands. But this version of the artifact format is just the beginning! In the future, you can expect the enhancements to the packaging format to bring this level of accessibility and flexibility to a broader range of use cases. Future versions will support:</p><ul><li><strong>Additional runtime configuration options</strong> like templates, context size, and default parameters. This will allow users to configure models for specific use cases and distribute that config alongside the model, as a single immutable artifact.</li><li>allowing users to extend existing model artifacts with use-case-specific fine-tuning.</li><li>, enabling users to package multi-modal such as language-and-vision models using LLaVA-style projectors.</li><li> that provide a set of models with different parameter count and quantizations, allowing runtimes the best option for the available resources.</li></ul><p>In addition to adding features, we are committed to fostering an open ecosystem. Expect:</p><ul><li>Deeper integrations into containerd for a more native runtime experience.</li><li>Efforts to harmonize with <a href=\"https://github.com/cncf/sandbox/issues/358\" rel=\"nofollow noopener\" target=\"_blank\">ModelPack</a> and other model packaging standards to improve interoperability.</li></ul><p>These advancements show our ongoing commitment to making the OCI artifact a versatile and flexible way to package and run AI models, delivering the same ease and reliability developers already expect from Docker.</p>","contentLength":12706,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Behind the scenes: How we designed Docker Model Runner and what’s next","url":"https://www.docker.com/blog/how-we-designed-model-runner-and-whats-next/","date":1750253429,"author":"Jacob Howard","guid":161213,"unread":true,"content":"<p>The last few years have made it clear that AI models will continue to be a fundamental component of many applications. The catch is that they’re also a fundamentally  type of component, with complex software and hardware requirements that don’t (yet) fit neatly into the constraints of container-oriented development lifecycles and architectures. To help address this problem, Docker launched the <a href=\"https://docs.docker.com/model-runner/\" rel=\"nofollow noopener\" target=\"_blank\">Docker Model Runner</a> with Docker Desktop 4.40. Since then, we’ve been working aggressively to expand Docker Model Runner with additional OS and hardware support, deeper integration with popular Docker tools, and improvements to both performance and usability.For those interested in Docker Model Runner and its future, we offer a behind-the-scenes look at its design, development, and roadmap. </p><div><p> Docker Model Runner is really  components: the model runner and the model distribution specification. In this article, we’ll be covering the former, but be sure to check out the <a href=\"https://www.docker.com/blog/oci-artifacts-for-ai-model-packaging/\">companion blog post</a> by Emily Casey for the equally important distribution side of the story.</p></div><p>Docker Model Runner’s primary design goal was to allow users to <a href=\"https://www.docker.com/blog/run-llms-locally/\">run AI models locally</a> and to access them from both containers and host processes. While that’s simple enough to articulate, it still leaves an enormous design space in which to find a solution. Fortunately, we had some additional constraints: we were a small engineering team, and we had some ambitious timelines. Most importantly, we didn’t want to compromise on UX, even if we couldn’t deliver it all at once. In the end, this motivated design decisions that have so far allowed us to deliver a viable solution while leaving plenty of room for future improvement.</p><p>One thing we knew early on was that we weren’t going to write our own inference engine (Docker’s wheelhouse is containerized development, not low-level inference engines). We’re also big proponents of open-source, and there were just so many great existing solutions! There’s <a href=\"https://github.com/ggml-org/llama.cpp\" rel=\"nofollow noopener\" target=\"_blank\">llama.cpp</a>, <a href=\"https://github.com/vllm-project/vllm\" rel=\"nofollow noopener\" target=\"_blank\">vLLM</a>, <a href=\"https://github.com/ml-explore/mlx\" rel=\"nofollow noopener\" target=\"_blank\">MLX</a>, <a href=\"https://onnx.ai/\" rel=\"nofollow noopener\" target=\"_blank\">ONNX</a>, and <a href=\"https://pytorch.org/\" rel=\"nofollow noopener\" target=\"_blank\">PyTorch</a>, just to name a few.</p><p>Of course, being spoiled for choice can also be a curse — which to choose? The obvious answer was: as many as possible, but not all at once.</p><p>We decided to go with llama.cpp for our initial implementation, but we intentionally designed our APIs with an additional, optional path component (the  in ) to allow users to take advantage of multiple future backends. We also designed interfaces and stubbed out implementations for other backends to enforce good development hygiene and to avoid becoming tethered to one “initial” implementation.</p><p>The second design choice we had to make was how to expose inference to consumers in containers. While there was also a fair amount of choice in the inference API space, we found that the OpenAI API standard seemed to offer the best initial tooling compatibility. We were also motivated by the fact that several teams inside Docker were already using this API for various real-world products. While we may support additional APIs in the future, we’ve so far found that this API surface is sufficient for most applications. One gap that we know exists is  compatibility with this API surface, which is something we’re working on iteratively.</p><p>This decision also drove our choice of llama.cpp as our initial backend. The llama.cpp project already offered a turnkey option for OpenAI API compatibility through its <a href=\"https://github.com/ggml-org/llama.cpp/tree/master/tools/server\" rel=\"nofollow noopener\" target=\"_blank\">server</a> implementation. While we had to make some small modifications (e.g. Unix domain socket support), this offered us the fastest path to a solution. We’ve also started contributing these small patches upstream, and we hope to expand our contributions to these projects in the future.</p><h3><strong>First-class citizenship for models in the Docker API</strong></h3><p>While the OpenAI API standard was the most ubiquitous option amongst existing tooling, we also knew that we wanted models to be first-class citizens in the <a href=\"https://docs.docker.com/reference/api/engine/version/v1.50/\" rel=\"nofollow noopener\" target=\"_blank\">Docker Engine API</a>. Models have a fundamentally different execution lifecycle than the processes that typically make up the s of containers, and thus, they don’t fit well under the standard  endpoints of the Docker Engine API. However, much like containers, images, networks, and volumes, models are such a fundamental component that they really deserve their own API resource type. This motivated the addition of a set of  endpoints, closely modeled after the  endpoints, but separate for reasons that are best discussed in the distribution blog post.</p><p>Another critical design goal was support for GPU acceleration of inference operations. Even the smallest useful models are extremely computationally demanding, while more sophisticated models (such as those with tool-calling capabilities) would be a stretch to fit onto local hardware at all. GPU support was going to be non-negotiable for a useful experience.</p><p>Unfortunately, passing GPUs across the VM boundary in Docker Desktop, especially in a way that would be reliable across platforms and offer a usable computation API inside containers, was going to be either impossible or very flaky.</p><p>As a compromise, we decided to run inference operations outside of the Docker Desktop VM and simply proxy API calls from the VM to the host. While there are some risks with this approach, we are working on initiatives to mitigate these with containerd-hosted sandboxing on macOS and Windows. Moreover, with Docker-provided models and application-provided prompts, the risk is somewhat lower, especially given that inference consists primarily of numerical operations. We assess the risk in Docker Desktop to be about on par with accessing host-side services via  (something already enabled by default).</p><p>However, agents that drive tool usage with model output can cause more significant side effects, and that’s something we needed to address. Fortunately, using the <a href=\"https://www.docker.com/blog/announcing-docker-mcp-catalog-and-toolkit-beta/\">Docker MCP Toolkit</a>, we’re able to perform tool invocation inside ephemeral containers, offering reliable encapsulation of the side effects that models might drive. This hybrid approach allows us to offer the best possible local performance with relative peace of mind when using tools.</p><p>Outside the context of Docker Desktop, for example, in Docker CE, we’re in a significantly better position due to the lack of a VM boundary (or at least a very transparent VM boundary in the case of a hypervisor) between the host hardware and containers. When running in standalone mode in Docker CE, the Docker Model Runner will have direct access to host hardware (e.g. via the <a href=\"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/index.html\" rel=\"nofollow noopener\" target=\"_blank\">NVIDIA Container Toolkit</a>) and will run inference operations within a container.</p><h3><strong>Modularity, iteration, and open-sourcing</strong></h3><p>As previously mentioned, the Docker Model Runner team is relatively small, which meant that we couldn’t rely on a monolithic architecture if we wanted to effectively parallelize the development work for Docker Model Runner. Moreover, we had an early and overarching directive: open-source as much as possible.</p><p>Breaking up these components allowed us to divide work more effectively, iterate faster, and define clean API boundaries between different concerns. While there have been some tricky dependency hurdles (in particular when integrating with closed-source components), we’ve found that the modular approach has facilitated faster incremental changes and support for new platforms.</p><h2><strong>The High-Level Architecture</strong></h2><p>At a high level, the Docker Model Runner architecture is composed of the three components mentioned above (the runner, the distribution code, and the CLI), but there are also some interesting sub-components within each:</p><p><strong>Figure 1: Docker Model Runner high-level architecture</strong></p><p>How these components are packaged and hosted (and how they interact) also depends on the platform where they’re deployed. In each case it looks slightly different. Sometimes they run on the host, sometimes they run in a VM, sometimes they run in a container, but the overall architecture looks the same.</p><p>The core architectural component is the . This component, provided by the model distribution code, is where the actual model tensor files are stored. These files are stored differently (and separately) from images because (1) they’re high-entropy and not particularly compressible and (2) the inference engine needs direct access to the files so that it can do things like mapping them into its virtual address space via . For more information, see the accompanying model distribution blog post.</p><p>The model distribution code also provides the <strong>model distribution client</strong>. This component performs operations (such as pulling models) using the model distribution protocol against OCI registries.</p><p>Built on top of the model store is the . The model runner maps inbound inference API requests (e.g.  or  requests) to processes hosting pairs of inference engines and models. It includes scheduler, loader, and runner components that coordinate the loading of models in and out of memory so that concurrent requests can be serviced, even if models can’t be loaded simultaneously (e.g. due to resource constraints). This makes the execution lifecycle of models different from that of containers, with engines and models operating as ephemeral processes (mostly hidden from users) that can be terminated and unloaded from memory as necessary (or when idle). A different backend process is run for each combination of engine (e.g. ) and model (e.g. ) as required by inference API requests (though multiple requests targeting the same pair will reuse the same runner and backend processes if possible).</p><p>The runner also includes an installer service that can dynamically download backend binaries and libraries, allowing users to selectively enable features (such as CUDA support) that might require downloading hundreds of MBs of dependencies.</p><p>Finally, the model runner serves as the central server for all Docker Model Runner APIs, including the  APIs (which it routes to the model distribution code) and the  APIs (which it routes to its scheduler). This API server will always opt to hold in-flight requests until the resources (primarily RAM or VRAM) are available to service them, rather than returning something like a  response. This is critical for a number of usage patterns, such multiple agents running with different models or concurrent requests for both embedding and completion.</p><p>The primary user-facing component of the Docker Model Runner architecture is the . This component is a standard <a href=\"https://pkg.go.dev/github.com/docker/cli/cli-plugins\" rel=\"nofollow noopener\" target=\"_blank\">Docker CLI plugin</a> that offers an interface very similar to the  command. While the lifecycle of model execution is different from that of containers, the concepts (such as pushing, pulling, and running) should be familiar enough to existing Docker users.</p><p>The model CLI communicates with the model runner’s APIs to perform almost all of its operations (though the transport for that communication varies by platform). The model CLI is context-aware, allowing it to determine if it’s talking to a Docker Desktop model runner, Docker CE model runner, or a model runner on some custom platform. Because we’re using the standard Docker CLI plugin framework, we get all of the standard <a href=\"https://docs.docker.com/engine/manage-resources/contexts/\" rel=\"nofollow noopener\" target=\"_blank\">Docker Context</a> functionality for free, making this detection much easier.</p><p>As previously mentioned, the Docker Model Runner comprises two sets of APIs: the Docker-style APIs and the OpenAI-compatible APIs. The Docker-style APIs (modeled after the  APIs) include the following endpoints:</p><ul><li> (Model pulling)</li><li> (Model listing)</li><li><strong>GET /models/{namespace}/{name}</strong> (Model metadata)</li><li><strong>DELETE /models/{namespace}/{name}</strong> (Model deletion)</li></ul><p>The bodies for these requests look very similar to their image analogs. There’s no documentation at the moment, but you can get a glimpse of the format by looking at their <a href=\"https://github.com/docker/model-runner/blob/main/pkg/inference/models/api.go\" rel=\"nofollow noopener\" target=\"_blank\">corresponding Go types</a>.</p><p>In contrast, the OpenAI endpoints follow a different but still RESTful convention:</p><ul><li><strong>GET /engines/{engine}/v1/models</strong> (OpenAI-format model listing)</li><li><strong>GET /engines/{engine}/v1/models/{namespace}/{name}</strong> (OpenAI-format model metadata)</li><li><strong>POST /engines/{engine}/v1/chat/completions</strong> (Chat completions)</li><li><strong>POST /engines/{engine}/v1/completions</strong> (Chat completions (legacy endpoint))</li><li><strong>POST /engines/{engine}/v1/embeddings</strong> (Create embeddings)</li></ul><p>At this point in time, only one  value is supported (), and it can also be omitted to use the default () engine.</p><p>We make these APIs available on several different endpoints:</p><p>First, in Docker Desktop, they’re available on the Docker socket (), both inside and outside containers. This is in service of our design goal of having models as a first-class citizen in the Docker Engine API. At the moment, these endpoints are prefixed with a  path (to avoid dependencies on APIs that may evolve during development), but we’ll likely remove this prefix in the next few releases since these APIs have now mostly stabilized and will evolve in a backward-compatible way.</p><p>Second, also in Docker Desktop, we make the APIs available on a special <strong>model-runner.docker.internal</strong> endpoint that’s accessible just from containers (though not currently from <a href=\"https://docs.docker.com/security/for-admins/hardened-desktop/enhanced-container-isolation/\" rel=\"nofollow noopener\" target=\"_blank\">ECI</a> containers, because we want to have inference sandboxing implemented first). This TCP-based endpoint exposes just the  and  API endpoints (not the whole Docker API) and is designed to serve existing tooling (which likely can’t access APIs via a Unix domain socket). No  prefix is used in this case.</p><p>Finally, in both Docker Desktop and Docker CE, we make the  and  API endpoints available on a host TCP endpoint (, by default, again without any  prefix). In Docker Desktop this is optional and not enabled by default. In Docker CE, it’s a critical component of how the API endpoints are accessed, because we currently lack the integration to add endpoints to Docker CE’s  or to inject a custom <strong>model-runner.docker.internal</strong> hostname, so we advise using the standard  host gateway address to access this localhost-exposed port (e.g. setting your OpenAI API base URL to <strong>http://172.17.0.1:12434/engines/v1</strong>). Hopefully we’ll be able to unify this across Docker platforms in the near future (see our roadmap below).</p><p>The natural first step for Docker Model Runner was integration into Docker Desktop. In Docker Desktop, we have more direct control over integration with the Docker Engine, as well as existing processes that we can use to host the model runner components. In this case, the model runner and model distribution components live in the Docker Desktop host backend process (the  process you may have seen running) and we use special middleware and networking magic to route requests on  and <strong>model-runner.docker.internal</strong> to the model runner’s API server. Since the individual inference backend processes run as subprocesses of , there’s no risk of a crash in Docker Desktop if, for example, an inference backend is killed by an Out Of Memory (OOM) error.</p><p>We started initially with support for macOS on Apple Silicon, because it provided the most uniform platform for developing the model runner functionality, but we implemented most of the functionality along the way to build and test for all Docker Desktop platforms. This made it significantly easier to port to Windows on AMD64 and ARM64 platforms, as well as the GPU variations that we found there.</p><p>The one complexity with Windows was the larger size of the supporting library dependencies for the GPU-based backends. It wouldn’t have been feasible (or tolerated) if we added another 500 MB – 1 GB to the Docker Desktop for Windows installer, so we decided to default to a CPU-based backend in Docker Desktop for Windows with optional support for the GPU backend. This was the primary motivating factor for the dynamic installer component of the model runner (in addition to our desire for incremental updates to different backends).</p><p>This all sounds like a very well-planned exercise, and we did indeed start with a three-component design and strictly enforced API boundaries, but in truth we started with the model runner service code as a sub-package of the Docker Desktop source code. This made it much easier to iterate quickly, especially as we were exploring the architecture for the different services. Fortunately, by sticking to a relatively strict isolation policy for the code, and enforcing clean dependencies through APIs and interfaces, we were able to easily extract the code (kudos to the excellent <a href=\"https://github.com/newren/git-filter-repo\" rel=\"nofollow noopener\" target=\"_blank\">git-filter-repo</a> tool) into a separate repository for the purposes of open-sourcing.</p><p>Aside from Docker’s penchant for open-sourcing, one of the main reasons that we wanted to make the Docker Model Runner source code publicly available was to support integration into Docker CE. Our goal was to package the  command in the same way as  and .</p><p>The trick with Docker CE is that we wanted to ship Docker Model Runner as a “vanilla” Docker CLI plugin (i.e. without any special privileges or API access), which meant that we didn’t have a backend process that could host the model runner service. However, in the Docker CE case, the boundary between host hardware and container processes is much less disruptive, meaning that we could actually run Docker Model Runner in a container and simply make any accelerator hardware available to it directly. So, much like a standalone BuildKit builder container, we run the Docker Model Runner as a standalone container in Docker CE, with a special named volume for model storage (meaning you can uninstall the runner without having to re-pull models). This “installation” is performed by the model CLI automatically (and when necessary) by pulling the  image and starting a container. Explicit configuration for the runner can also be specified using the <strong>docker model install-runner</strong> command. If you want, you can also remove the model runner (and optionally the model storage) using <strong>docker model uninstall-runner</strong>.</p><p>This unfortunately leads to one small compromise with the UX: we don’t currently support the model runner APIs on  or on the special <strong>model-runner.docker.internal</strong> URL. Instead, the model runner API server listens on the host system’s loopback interface at  (by default), which is available inside most containers at . If desired, users can also make this available on <strong>model-runner.docker.internal:12434</strong> by utilizing something like <strong>–add-host=model-runner.docker.internal:host-gateway</strong> when running  or  commands. This can also be achieved by using the  key in a Compose YAML file. We have plans to make this more ergonomic in future releases.</p><p>The status quo is Docker Model Runner support in Docker Desktop on macOS and Windows and support for Docker CE on Linux (including WSL2), but that’s definitely not the end of the story. Over the next few months, we have a number of initiatives planned that we think will reshape the user experience, performance, and security of Docker Model Runner.</p><h3><strong>Additional GUI and CLI functionality</strong></h3><p>The most visible functionality coming out over the next few months will be in the model CLI and the “Models” tab in the Docker Desktop dashboard. Expect to see new commands (such as , , and ) that will provide more direct support for monitoring and controlling model execution. Also, expect to see new and expanded layouts and functionality in the Models tab.</p><h3><strong>Expanded OpenAI API support</strong></h3><p>A less-visible but equally important aspect of the Docker Model Runner user experience is our compatibility with the OpenAI API. There are dozens of endpoints and parameters to support (and we already support many), so we will work to expand API surface compatibility with a focus on practical use cases and prioritization of compatibility with existing tools.</p><h3><strong>containerd and Moby integration</strong></h3><p>One of the longer-term initiatives that we’re looking at is integration with . containerd already provides a modular runtime system that allows for task execution coordinated with storage. We believe this is the right way forward and that it will allow us to better codify the relationship between model storage, model execution, and model execution sandboxing.</p><p>In combination with the containerd work, we would also like tighter integration with the Moby project. While our existing Docker CE integration offers a viable and performant solution, we believe that better ergonomics could be achieved with more direct integration. In particular, niceties like support for <strong>model-runner.docker.internal</strong> DNS resolution in Docker CE are on our radar. Perhaps the biggest win from this tighter integration would be to expose Docker Model Runner APIs on the Docker socket and to include the API endpoints (e.g. ) in the official <a href=\"https://docs.docker.com/reference/api/engine/version/v1.50/\" rel=\"nofollow noopener\" target=\"_blank\">Docker Engine API documentation</a>.</p><p>One of the product goals for Docker Model Runner was a consistent experience from development inner loop to production, and Kubernetes is inarguably a part of that path. The existing Docker Model Runner images that we’re using for Docker CE will also work within a Kubernetes cluster, and we’re currently developing instructions to set up a Docker Model Runner instance in a Kubernetes cluster. The big difference with Kubernetes is the variety of cluster and application architectures in use, so we’ll likely end up with different “recipes” for how to configure the Docker Model Runner in different scenarios.</p><p>One of the things we’ve heard from a number of customers is that vLLM forms a core component of their production stack. This was also the first alternate backend that we stubbed out in the model runner repository, and the time has come to start poking at an implementation.</p><p>Finally, there are some bits that we just can’t talk about yet, but they will fundamentally shift the way that developers interact with models. Be sure to tune-in to Docker’s sessions at <a href=\"https://www.wearedevelopers.com/world-congress\" rel=\"nofollow noopener\" target=\"_blank\">WeAreDevelopers</a> from July 9–11 for some exciting announcements around AI-related initiatives at Docker.</p>","contentLength":21642,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ChatLoopBackOff: Episode 62 (OpenTofu)","url":"https://www.youtube.com/watch?v=bUlv2JLNEt0","date":1750231515,"author":"CNCF [Cloud Native Computing Foundation]","guid":161062,"unread":true,"content":"<article>Get to know OpenTofu with CNCF Ambassador, Sandipan Panda. This is a vibrant CNCF project delivering an open, community-driven alternative to Terraform. Born from the need for a truly open infrastructure-as-code (IaC) tool, OpenTofu is fully backward-compatible with Terraform, empowering users to manage cloud and on-prem infrastructure with the flexibility, transparency, and governance of open source. Whether you're orchestrating complex multi-cloud environments or looking for a vendor-neutral approach to IaC, OpenTofu offers a familiar syntax with a fresh commitment to openness and collaboration. Join us as we explore how OpenTofu is building momentum in the cloud native ecosystem—and why it’s quickly becoming a key choice for infrastructure automation.</article>","contentLength":768,"flags":null,"enclosureUrl":"https://www.youtube.com/v/bUlv2JLNEt0?version=3","enclosureMime":"","commentsUrl":null},{"title":"ChatLoopBackOff: Episode 61 (Kairos)","url":"https://www.youtube.com/watch?v=GehQj_WYUTQ","date":1750231123,"author":"CNCF [Cloud Native Computing Foundation]","guid":161061,"unread":true,"content":"<article>Join us for an introduction to Kairos with CNCF Ambassador, Sergio Mendez. This is a powerful CNCF project designed to simplify and secure Kubernetes deployments at the edge. Kairos enables the creation of immutable, declarative Linux-based OS images that come bundled with Kubernetes—perfect for edge environments, bare-metal clusters, and IoT applications. With features like over-the-air updates, rollback support, and secure boot, Kairos brings modern DevOps principles to edge computing. Whether you're deploying in low-connectivity scenarios or need a consistent, reproducible operating system for Kubernetes nodes, Kairos offers a flexible and resilient solution. Don’t miss this session to explore how Kairos is transforming cloud native infrastructure at the edge.</article>","contentLength":777,"flags":null,"enclosureUrl":"https://www.youtube.com/v/GehQj_WYUTQ?version=3","enclosureMime":"","commentsUrl":null},{"title":"AI, the New Hero of Software Development … or Anti-Hero?","url":"https://devops.com/ai-the-new-hero-of-software-development-or-anti-hero/?utm_source=rss&utm_medium=rss&utm_campaign=ai-the-new-hero-of-software-development-or-anti-hero","date":1750186131,"author":"Guy Currier","guid":159836,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AWS re:Inforce roundup 2025: top announcements","url":"https://aws.amazon.com/blogs/aws/aws-reinforce-roundup-2025-top-announcements/","date":1750180223,"author":"AWS News Blog Team","guid":159803,"unread":true,"content":"<p>At AWS re:Inforce 2025 (June 16-18, Philadelphia), AWS Vice President and Chief Information Security Officer Amy Herzog delivered the keynote address, announcing new security innovations. Throughout the event, AWS announced additional security capabilities focused on simplifying security at scale and enabling organizations to build more resilient applications in the cloud. Below is a comprehensive roundup of the major security launches and updates announced at this year’s conference.</p><p><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/06/aws-iam-mfa-root-users-across-all-account-types/\">AWS IAM now enforces MFA for root users across all account types</a> The new Multi-Factor Authentication enforcement prevents over 99% of password-related attacks. You can use a range of supported IAM MFA methods, including FIDO-certified security keys to harden access to your AWS accounts. AWS supports FIDO2 passkeys for a user-friendly MFA implementation and allows you to register up to 8 MFA devices per root and IAM user.</p><p><a href=\"https://aws.amazon.com/blogs/security/improve-your-security-posture-using-amazon-threat-intelligence-on-aws-network-firewall/\">Improve your security posture using Amazon threat intelligence on AWS Network Firewall</a> This new Network Firewall managed rule group offers protection against active threats relevant to workloads in AWS. The feature uses the Amazon threat intelligence system <a href=\"https://www.aboutamazon.com/news/aws/amazon-madpot-stops-cybersecurity-crime\">MadPot</a>&nbsp;to continuously track attack infrastructure, including malware hosting URLs, botnet command and control servers, and crypto mining pools, identifying indicators of compromise (IOCs) for active threats.</p><p><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/06/aws-waf-web-application-security-configuration-steps-expert-level-protection/\">AWS WAF simplified console experience</a> The new AWS WAF console experience reduces security configuration steps by up to 80% through pre-configured protection packs. Security teams can quickly implement comprehensive protection for specific application types, with consolidated security metrics and customizable controls through an intuitive interface.</p><p><a href=\"https://aws.amazon.com/blogs/aws/amazon-guardduty-expands-extended-threat-detection-coverage-to-amazon-eks-clusters/\">Amazon GuardDuty expands Extended Threat Detection coverage to Amazon EKS clusters</a> Amazon GuardDuty Extended Threat Detection now supports Amazon EKS clusters, helping you detect sophisticated multistage attacks by correlating security signals across Kubernetes audit logs, runtime behaviors, and AWS API activities. This enhancement automatically identifies critical attack sequences that might otherwise go unnoticed, enabling faster response to threats.</p><p><a href=\"https://aws.amazon.com/blogs/apn/updates-to-the-aws-mssp-competency-deliver-turnkey-security-solutions-for-customers/\">New categories for the AWS MSSP Competency</a> The AWS MSSP Competency (previously AWS Level 1 MSSP Competency) now includes new categories covering infrastructure security, workload security, application security, data protection, identity and access management, incident response, and cyber recovery. Partners provide 24/7 monitoring and incident response through dedicated Security Operations Centers.</p>","contentLength":2587,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Amazon GuardDuty expands Extended Threat Detection coverage to Amazon EKS clusters","url":"https://aws.amazon.com/blogs/aws/amazon-guardduty-expands-extended-threat-detection-coverage-to-amazon-eks-clusters/","date":1750177564,"author":"Esra Kayabali","guid":159766,"unread":true,"content":"<p>Security teams managing Kubernetes workloads often struggle to detect sophisticated multistage attacks that target containerized applications. These attacks can involve container exploitation, privilege escalation, and unauthorized movement within Amazon EKS clusters. Traditional monitoring approaches might detect individual suspicious events, but often miss the broader attack pattern that spans across these different data sources and time periods.</p><p>GuardDuty Extended Threat Detection introduces a new critical severity finding type, which automatically correlates security signals across Amazon EKS audit logs, runtime behaviors of processes associated with EKS clusters,&nbsp;malware execution in EKS clusters, and AWS API activity to identify sophisticated attack patterns that might otherwise go unnoticed. For example, GuardDuty can now detect attack sequences in which a threat actor exploits a container application, obtains privileged service account tokens, and then uses these elevated privileges to access sensitive Kubernetes secrets or AWS resources.</p><p>This new capability uses GuardDuty correlation algorithms to observe and identify sequences of actions that indicate potential compromise. It evaluates findings across <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html#features-of-guardduty\">protection plans</a> and other signal sources to identify common and emerging attack patterns. For each attack sequence detected, GuardDuty provides comprehensive details, including potentially impacted resources, timeline of events, actors involved, and indicators used to detect the sequence. The findings also map observed activities to MITRE ATT&amp;CK® tactics and techniques and remediation recommendations based on AWS best practices, helping security teams understand the nature of the threat.</p><p>To enable Extended Threat Detection for EKS, you need at least one of these features enabled: <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/kubernetes-protection.html\">EKS Protection</a> or <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/runtime-monitoring-configuration.html\">Runtime Monitoring</a>. For maximum detection coverage, we recommend enabling both to enhance detection capabilities. EKS Protection monitors control plane activities through audit logs, and Runtime Monitoring observes behaviors within containers. Together, they create a complete view of your EKS clusters, enabling GuardDuty to detect complex attack patterns.</p><p>To use the new Amazon GuardDuty Extended Threat Detection for EKS clusters, go to the <a href=\"https://console.aws.amazon.com/guardduty/home?#/summary\">GuardDuty console</a> to enable EKS Protection in your account. From the Region selector in the upper-right corner, select the Region where you want to enable EKS Protection. In the navigation pane, choose . On the  page, review the current status and choose . Select&nbsp; to save your selection.</p><p>After it’s enabled, GuardDuty immediately starts monitoring EKS audit logs from your EKS clusters without requiring any additional configuration. GuardDuty consumes these audit logs directly from the EKS control plane through an independent stream, which doesn’t affect any existing logging configurations. <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/eks-protection-enable-multiple-accounts.html\">For multi-account environments</a>, only the delegated GuardDuty administrator account can enable or disable EKS Protection for member accounts and configure auto-enable settings for new accounts joining the organization.</p><p>To enable , choose  in the navigation pane. Under the&nbsp;&nbsp;tab, choose&nbsp;&nbsp;to enable Runtime Monitoring for your account.</p><p>Now, you can view from the  dashboard the attack sequences and critical findings specifically related to Kubernetes cluster compromise. You can observe that GuardDuty identifies complex attack patterns in Kubernetes environments, such as credential compromise events and suspicious activities within EKS clusters. The visual representation of findings by severity, resource impact, and attack types gives you a holistic view of your Amazon EKS security posture. This means you can prioritize the most critical threats to your containerized workloads.</p><p>The  page provides visibility into complex attack sequences targeting EKS clusters, helping you understand the full scope of potential compromises. GuardDuty correlates signals into a timeline, mapping observed behaviors to MITRE ATT&amp;CK® tactics and techniques such as account manipulation, resource hijacking, and privilege escalation. This granular level of insight reveals exactly how attackers progress through your Amazon EKS environment. It identifies affected resources like EKS workloads and service accounts. The detailed breakdown of indicators, actors, and endpoints provides you with actionable context to understand attack patterns, determine impact, and prioritize remediation efforts. By consolidating these security insights into a cohesive view, you can quickly assess the severity of Amazon EKS security incidents, reduce investigation time, and implement targeted countermeasures to protect your containerized applications.</p><p>The  section of the  page shows context about the specific assets affected during an attack sequence. This unified resource list provides you with visibility into the exact scope of the compromise—from the initial access to the targeted Kubernetes components. Because GuardDuty includes detailed attributes such as resource types, identifiers, creation dates, and namespace information, you can rapidly assess which components of your containerized infrastructure require immediate attention. This focused approach eliminates guesswork during incident response, so you can prioritize remediation efforts on the most critical affected resources and minimize the potential blast radius of Amazon EKS targeted attacks.</p><p>Amazon GuardDuty Extended Threat Detection with expanded coverage for Amazon EKS clusters provides comprehensive security monitoring across your Kubernetes environment. You can use this capability to detect sophisticated multistage attacks by correlating events across different data sources, identifying attack sequences that traditional monitoring might miss.</p><p>For more information about this new capability, refer to the <a href=\"https://docs.aws.amazon.com/guardduty/\">Amazon GuardDuty</a> Documentation.</p><a href=\"https://www.linkedin.com/in/esrakayabali/\">— Esra</a>","contentLength":5885,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Unify your security with the new AWS Security Hub for risk prioritization and response at scale (Preview)","url":"https://aws.amazon.com/blogs/aws/unify-your-security-with-the-new-aws-security-hub-for-risk-prioritization-and-response-at-scale-preview/","date":1750175877,"author":"Donnie Prakoso","guid":159704,"unread":true,"content":"<p>AWS Security Hub has been a central place for you to view and aggregate security alerts and compliance status across Amazon Web Services (AWS) accounts. Today, we are announcing the preview release of the new AWS Security Hub which&nbsp;offers additional correlation, contextualization, and visualization capabilities. This helps you prioritize critical security issues, respond at scale to reduce risks, improve team productivity, and better protect your cloud environment.</p><p>Here’s a quick look at the new AWS Security Hub.</p><p>Let me walk you through how to get started with AWS Security Hub.</p><p>If you’re a new customer to AWS Security Hub, you need to navigate to the AWS Security Hub console to enable AWS security capabilities and capabilities and start assessing risk across your organization. You can learn more on the <a href=\"https://docs.aws.amazon.com/securityhub/latest/userguide/security-hub-adv-getting-started-enable.html?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Documentation page</a>.</p><p>After you have AWS Security Hub enabled, it will automatically consume data from supporting security capabilities you’ve enabled, such as Amazon GuardDuty, Amazon Inspector, Amazon Macie, and AWS Security Hub CSPM. You can navigate to the AWS Security Hub console to view these findings and benefit from insights created through correlation of findings across these capabilities.</p><p>As security risks are uncovered, they’re presented in a redesigned Security Hub summary dashboard. The new Security Hub summary dashboard provides a comprehensive, unified view of your AWS security posture. The dashboard organizes security findings into distinct categories, making it easier to identify and prioritize risks.</p><p>The new  widget helps you identify and prioritize security exposures by analyzing resource relationships and signals from Amazon Inspector, AWS Security Hub CSPM, and Amazon Macie. These exposure findings are automatically generated and are a key part of the new solution, highlighting where your critical security exposures are located. You can learn more about exposure on the <a href=\"https://docs.aws.amazon.com/securityhub/latest/userguide/exposure-fidnings-adv.html?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Documentation page</a>.</p><p>AWS Security Hub now provides a  widget designed to help you identify potential coverage gaps. You can use this widget to identify where you’re missing coverage by the security capabilities that power Security Hub. This visibility helps you identify which capabilities, accounts, and features you need to address to improve your security coverage.</p><p>As you can see on the navigation menu, AWS Security Hub is organized into five key areas to streamline security management:</p><ul><li>: Provides visibility into all exposure findings, a security vulnerability or misconfiguration that could potentially expose an AWS resource or system to unauthorized access or compromise, generated by Security Hub, helping you identify resources that might be accessible from outside your environment</li><li>: Consolidates all threat findings generated by Amazon GuardDuty, showing potential malicious activities and intrusion attempts</li><li>: Displays all vulnerabilities detected by Amazon Inspector, highlighting software flaws and configuration issues</li><li>: Shows all posture management findings from AWS Security Hub Cloud Security Posture Management (CSPM), helping provide compliance with security best practices</li><li>: Presents all sensitive data findings identified by Amazon Macie, helping you track and protect your sensitive information</li></ul><p>When you navigate to the <a href=\"https://console.aws.amazon.com/securityhub/v2/home#/exposure?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\"></a> page, you’ll see findings grouped by title, with severity levels clearly indicated to help you focus on critical issues first.</p><p>To explore specific exposures, you can select any finding to see affected resources. The panel includes key information about the implicated resource, account, Region, and when the issue was detected.</p><p>In this panel, you’ll also find an attack path visualization that is particularly useful for understanding complex security relationships. For network exposure paths, you can see all components involved in the path—including virtual private clouds (VPCs), subnets, security groups, network access control lists (ACLs), and load balancers—helping you identify exactly where to implement security controls. The visualization also highlights Identity and Access Management (IAM) relationships, showing how permission configurations might allow privilege escalation or data access. Resources with multiple contributing traits are clearly marked so you can quickly identify which components represent the greatest risk.</p><p>The <a href=\"https://console.aws.amazon.com/securityhub/v2/home#/threats?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\"></a> dashboard provides actionable insights into potential malicious activities detected by Amazon GuardDuty, organizing findings by severity so you can quickly identify critical issues like unusual API calls, suspicious network traffic, or potential credential compromises. The dashboard includes <a href=\"https://aws.amazon.com/blogs/aws/introducing-amazon-guardduty-extended-threat-detection-aiml-attack-sequence-identification-for-enhanced-cloud-security/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">GuardDuty Extended Threat Detection</a> findings, with all “Critical” severity threats representing these Extended Threat Detections that require immediate attention.</p><p>Similarly, the <a href=\"https://console.aws.amazon.com/securityhub/v2/home#/vulnerabilities?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\"></a> dashboard from Amazon Inspector provides a comprehensive view of software vulnerabilities and network exposure risks. The dashboard highlights vulnerabilities with known exploits, packages requiring urgent updates, and resources with the highest numbers of vulnerabilities.</p><p>Another valuable new feature is the <a href=\"https://console.aws.amazon.com/securityhub/v2/home#/resources?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\"></a> view, which provides an inventory of all resources deployed in your organization covered by AWS Security Hub. You can use this view to quickly identify which resources have findings against them and filter by resource type or finding severity. Selecting any resource provides detailed configuration information without needing to pivot to other consoles, streamlining your investigation workflow.</p><p>The new Security Hub also offers integration capabilities to help you comprehensively monitor your cloud environments and connect with third-party security solutions. This gives you the flexibility to create a unified security solution tailored to your organization’s specific needs.</p><p>For example, with integration capability, when viewing a security finding, you can select the  option and choose your preferred ticketing integration.</p><p>Here are a couple of things to note:</p><ul><li> – During this preview period, the new AWS Security Hub is available in following AWS Regions: US East (N. Virginia, Ohio), US West (N. California, Oregon), Africa (Cape Town), Asia Pacific (Hong Kong, Jakarta, Mumbai, Osaka, Seoul, Singapore, Sydney, Tokyo), Canada (Central), Europe (Frankfurt, Ireland, London, Milan, Paris, Stockholm), Middle East (Bahrain), and South America (São Paulo).</li><li> – The new AWS Security Hub is available at no additional charge during the preview period. However, you will still incur costs for the integrated capabilities including Amazon GuardDuty, Amazon Inspector, Amazon Macie, and AWS Security Hub CSPM.</li><li><strong>Integration with existing AWS security capabilities</strong> – Security Hub integrates with Amazon GuardDuty, Amazon Inspector, AWS Security Hub CSPM, and Amazon Macie, providing a comprehensive security posture without additional operational overhead.</li></ul><p>To learn more about the enhanced AWS Security Hub and join the preview, visit the <a href=\"https://aws.amazon.com/security-hub/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">AWS Security Hub</a> product page.</p>","contentLength":6968,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AWS Backup adds new Multi-party approval for logically air-gapped vaults","url":"https://aws.amazon.com/blogs/aws/aws-backup-adds-new-multi-party-approval-for-logically-air-gapped-vaults/","date":1750175414,"author":"Veliswa Boya","guid":159703,"unread":true,"content":"<p>Today, we’re announcing the general availability of a new capability that integrates <a href=\"https://docs.aws.amazon.com/aws-backup/latest/devguide/logicallyairgappedvault.html\">AWS Backup logically air-gapped vaults</a> with <a href=\"https://docs.aws.amazon.com/mpa/latest/userguide/what-is.html\">Multi-party approval</a> to provide access to your backups even when your AWS account is inaccessible due to inadvertent or malicious events. AWS Backup is a fully managed service that centralizes and automates data protection across AWS services and hybrid workloads. It provides core data protection features, ransomware recovery capabilities, and compliance insights and analytics for data protection policies and operations.</p><p>As a backup administrator, you use AWS Backup logically air-gapped vaults to securely share backups across accounts and organizations, logically isolate your backup storage, and support direct restore to help reduce recovery time following an inadvertent or malicious event. However, if a bad or unintended actor gains root access to your backup account or the management account of your organization, your backups suddenly become inaccessible, even though they’re still safely stored in the logically air-gapped vault. While traditional account recovery involved working through support channels, AWS Backup with Multi-party approval delivers immediate access to recovery tools, empowering you with faster resolution times and greater control over your recovery timeline.</p><p>Multi-party approval for AWS Backup logically air-gapped vaults adds an additional layer of protection for you to recover your application data even when your AWS account becomes completely inaccessible. Using Multi-party approval, you can create approval teams which consist of highly trusted individuals in your organization, then associate them with your logically air-gapped vault. If you get locked out of your AWS accounts due to inadvertent or malicious actions, you can request your own approval team to authorize sharing of your vault from any account, even those outside your <a href=\"https://aws.amazon.com/organizations/\">AWS Organizations</a> account. Once approved, you gain authorized access to your backups and can begin your recovery process.</p><p> Multi-party approval for AWS Backup logically air-gapped vaults combines the security of logically air-gapped vaults with the governance of Multi-party approval to create a recovery mechanism that works even when your AWS account is compromised. Here’s how it works:</p><p><strong>1. Approval team creation</strong> First, you create an approval team in your AWS Organizations management account. If the management account is new, first <a href=\"https://docs.aws.amazon.com/singlesignon/latest/userguide/identity-center-instances.html\">create an AWS Identity and Access Management (IAM) Identity Center instance</a> before creating the approval team. The approval team consists of trusted individuals (IAM Identity Center users) who will be authorized to approve vault sharing requests. Each approver receives an invitation to join the approval team through a new Approval portal.<a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa1.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa1-1024x458.png\" alt=\"\" width=\"1024\" height=\"458\"></a></p><p> When your approval team is active, you share it with accounts that own logically air-gapped vaults using <a href=\"https://aws.amazon.com/ram/\">AWS Resource Access Manager (AWS RAM)</a> to safeguard against requests for approval from arbitrary accounts. Backup administrators can then associate this approval team with new or existing logically air-gapped vaults.</p><p><strong>3. Protection against compromise</strong> If your AWS account becomes compromised or inaccessible, you can request access to your backups from a different account (a clean recovery account). This request includes the <a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-resource-backup-logicallyairgappedbackupvault.html\">Amazon Resource Name (ARN) of the logically air-gapped vault</a> in the format <code>arn:aws:backup:&lt;region&gt;:&lt;account&gt;:backup-vault:&lt;name&gt;</code> and an optional vault name and comment.</p><p> The request is sent to the approval team, who review it through the approval portal. When the minimum required number of approvers authorize the request, the vault is automatically shared with the requesting account. All requests and approvals are comprehensively logged in <a href=\"https://aws.amazon.com/cloudtrail/\">AWS CloudTrail</a>.</p><p> With access granted, you can immediately start restoring or copying your data in the new recovery account without waiting for your compromised account to be remediated.</p><p>This approach provides an entirely separate authentication path to access and recover your backups, completely independent of your AWS account credentials. Even if the bad actor has root access to your account, they can’t prevent the approval team-based recovery process.</p><p><strong>1. Create a new logically air-gapped vault</strong> To create a new logically air-gapped vault, provide a ,  (optional), and .<a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa2-5.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa2-5-1024x405.png\" alt=\"\" width=\"1024\" height=\"405\"></a><strong>2. Assign an approval team</strong> When the vault has been created, choose  to assign it with an existing approval team.<a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa3.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa3-1024x193.png\" alt=\"\" width=\"1024\" height=\"193\"></a></p><p>Choose an existing approval team from the drop-down menu then select  to finalize the assignment.<a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa4.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa4-1024x202.png\" alt=\"\" width=\"1024\" height=\"202\"></a></p><p>Now your approval team is assigned to your logically air-gapped vault.<a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa5.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/06/05/newmpa5-1024x135.png\" alt=\"\" width=\"1024\" height=\"135\"></a></p><p> It’s essential to test your recovery process before an actual emergency:</p><ol><li>From a different AWS account, use the AWS Backup console or API to request sharing of your logically air-gapped vault by providing the vault ID and ARN.</li><li>Request approval of your request from the approval team.</li><li>Once approved, verify that you can access and restore backups from the vault in your testing account.</li></ol><p>, monitor the health of your approval team regularly using <a href=\"https://docs.aws.amazon.com/aws-backup/latest/devguide/aws-backup-audit-manager.html\">AWS Backup Audit Manager</a> to ensure they have sufficient active participants to meet your approval threshold.</p><p> Today, we’re also announcing the general availability of a new capability that AWS account administrators can use to add Multi-party approval to their product offerings. As highlighted in this post, AWS Backup is the first service to integrate this capability. With Multi-party approval, administrators can enable application owners to guard sensitive service operations with a distributed review process.</p><p> Multi-party approval provides several significant security advantages:</p><ul><li>Distributed decision-making, eliminating single points of failure</li><li>Full auditability through AWS CloudTrail integration</li><li>Protection against compromised credentials</li><li>Formal governance for compliance-sensitive operations</li><li>Consistent approval experience across integrated services</li></ul><p>Multi-party approval is available today in all <a href=\"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_tag-policies-supported-regions.html\">AWS Regions</a> where AWS Organizations is available. Multi-party approval for AWS Backup logically air-gapped vaults is available in all AWS Regions where <a href=\"https://aws.amazon.com/backup/\">AWS Backup</a> is available.</p>","contentLength":6139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"New AWS Shield feature discovers network security issues before they can be exploited (Preview)","url":"https://aws.amazon.com/blogs/aws/new-aws-shield-feature-discovers-network-security-issues-before-they-can-be-exploited-preview/","date":1750173869,"author":"Esra Kayabali","guid":159702,"unread":true,"content":"<p>Today, I’m happy to announce <a href=\"https://aws.amazon.com/shield/\">AWS Shield</a> network security director (preview), a capability that simplifies identification of configuration issues related to threats such as SQL injections and distributed denial of service (DDoS) events, and proposes remediations. This feature identifies and analyzes network resources, connections, and configurations. It compares them against AWS best practices to create a network topology that highlights resources requiring protection.</p><p>Organizations today face significant challenges in maintaining a robust network security posture. Security teams often struggle to efficiently discover all resources in their environments, understand how these resources are interconnected, and identify which security services are currently configured. Additionally, they find determining how well resources are configured relative to AWS best practices requires considerable expertise and effort. Many teams find it difficult to identify which network security services and rule sets would best protect their applications from common and emerging threats.</p><p>AWS Shield network security director addresses these challenges through three key capabilities. First, it performs comprehensive analysis to discover resources across your AWS accounts, identify connectivity between resources, and determine which network security services and configurations are currently in place. Second, it prioritizes resources by severity level based on AWS network security best practices and threat intelligence. Finally, it provides specific remediation recommendations such as step-by-step instructions for implementing the right AWS security services, including <a href=\"https://aws.amazon.com/waf\">AWS WAF</a>, <a href=\"https://aws.amazon.com/vpc/\">Amazon Virtual Private Cloud (Amazon VPC)</a><a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-groups.html\">security groups</a>, and Amazon VPC <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html\">network access control lists (ACLs)</a> to protect your resources.</p><p>The service supports critical network security use cases, including protecting applications against internet-born threats and controlling human access to resources based on port, protocol, or IP address range. It provides network analysis to discover assets and delivers analysis that eliminates time-consuming manual processes for identifying resources that need protection. The service offers resource prioritization by assigning security findings a severity level based on network context and adherence to AWS best practices, helping you focus on what matters most. Additionally, it supplies actionable recommendations with specific guidance on which services and configurations will address each security gap. You can also get answers, in natural language, from AWS Shield network security director from within <a href=\"https://aws.amazon.com/q/developer/\">Amazon Q Developer</a> in the <a href=\"https://console.aws.amazon.com/\">AWS Management Console</a> and chat applications.</p><p>To use AWS Shield network security director, I need to initiate a network analysis of my AWS resources. I go to the <a href=\"http://console.aws.amazon.com/wafv2/homev2\">AWS WAF &amp; Shield console</a> and choose  under <strong>AWS Shield network security director</strong> in the navigation pane. I choose , which takes me to the configuration page. On this page, I can choose how to perform my first network analysis: I can assess findings from across all supported Regions or from my current Region only. I select .</p><p>After the analysis is completed, the dashboard page shows a breakdown of resource types by severity level and the most common categories of network security findings associated with their resources. Resources are categorized by type and severity level (critical, high, medium, low, informational), making it easy to identify which areas need immediate attention.</p><p>Next, I explore the  section to understand the distribution of my assets and filter by severity level in my environment. I can use  to review a specific severity level, which will redirect me to the  under <strong>Network security director </strong>with the associated severity level filter. I choose the resources that have  severity level.</p><p>I choose a specific resource to view its network topology map showing how it connects to other resources and associated findings. This visualization helps me understand the potential impact of security configurations and identify exposed paths. I review detailed findings such as “Allows unrestricted inbound access (0.0.0.0/0) on all ports” with severity ratings.</p><p>Next, I go to  under <strong>Network security director</strong>, which shows common configuration issues. For each finding, I receive detailed information and recommended remediation steps. The service rates the severity of findings (high, medium, low) to help me prioritize my response. Critical-severity findings such as “CloudFront origin is also internet accessible without CloudFront protections” or high-severity findings such as “Allows unrestricted inbound access (0.0.0.0/0) on all ports” are presented first, followed by medium- and low-severity issues.</p><p>You can analyze your network security configurations, in natural language, with AWS Shield network security director within Amazon Q Developer in the AWS Management Console and chat applications. For example, you can say “Do I have any network security issues on my CloudFront distributions?” or “Are any of my resources vulnerable to bots and scrapers?” This integration helps security teams quickly understand their security posture and receive guidance on implementing best practices without having to navigate through extensive documentation.</p><p>To explore this capability, I ask “What are my most critical network security issues?”&nbsp;in the section. Amazon Q analyzes my network security configuration and generates a response based on the security assessment of my AWS environment.</p><p>With this comprehensive view of your network security, you can now make data-driven decisions to strengthen your defenses against emerging threats.</p><p>AWS Shield network security director is available in the US East (N. Virginia) and Europe (Stockholm) Regions. The Amazon Q Developer capability to analyze network security configurations is available in preview in US East (N. Virginia). To begin strengthening your network security, visit the <a href=\"https://console.aws.amazon.com/wafv2/network-security-director\">AWS Shield network security director console</a> and initiate your first network security analysis.</p>","contentLength":6077,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Amazon CloudFront simplifies web application delivery and security with new user-friendly interface","url":"https://aws.amazon.com/blogs/aws/amazon-cloudfront-simplifies-web-application-delivery-and-security-with-new-user-friendly-interface/","date":1750171935,"author":"Micah Walter","guid":159655,"unread":true,"content":"<p>Today, we’re announcing a new simplified onboarding experience for <a href=\"https://aws.amazon.com/cloudfront/\">Amazon CloudFront</a> that developers can use to accelerate and secure their web applications in seconds. This new experience, along with improvements to the <a href=\"https://aws.amazon.com/waf/\">AWS WAF</a> console experience, makes it easier than ever for developers to configure content delivery and security services without requiring deep technical expertise.</p><p>Setting up content delivery and security for web applications traditionally required navigating multiple <a href=\"https://aws.amazon.com/\">Amazon Web Services (AWS)</a> services and making numerous configuration decisions. With this new CloudFront onboarding experience, developers can now create a fully configured distribution with DNS and a TLS certificate in just a few clicks.</p><p>Amazon CloudFront offers compelling benefits for organizations of all sizes looking to deliver content and applications globally. As a content delivery network (CDN), CloudFront significantly improves application performance by serving content from edge locations closest to your users, reducing latency and improving user experience. Beyond performance, CloudFront provides built-in security features that protect your applications from distributed denial of service (DDoS) attacks and other threats at the edge, preventing malicious traffic from reaching your origin infrastructure. The service automatically scales with your traffic demands without requiring any manual intervention, handling both planned and unexpected traffic spikes with ease. Whether you’re running a small website or a large-scale application, the CloudFront integration with other AWS services and the new simplified console experience makes it easier than ever to implement these essential capabilities for your web applications.</p><p>The new CloudFront console experience guides developers through a simplified workflow that starts with the domain name they want to use for their distribution. When using <a href=\"https://aws.amazon.com/route53/\">Amazon Route 53</a>, the experience automatically handles TLS certificate provisioning and DNS record configuration, while incorporating security best practices by default. This unified approach eliminates the need to switch between multiple services like <a href=\"https://aws.amazon.com/certificate-manager/\">AWS Certificate Manager</a>, Route 53, and AWS WAF, and offers developers a faster time to production without the need to dive deep on the nuanced configuration options of each service.</p><p>For example, a developer can now create a secure CloudFront distribution for their applications fronted by a load balancer by entering their domain name and selecting their load balancer as the origin. The console automatically recommends optimal CDN and security configurations based on the application type and requirements, and developers can deploy with confidence knowing they’re following AWS best practices.</p><p>For developers who wish to host a static website on <a href=\"https://aws.amazon.com/s3\">Amazon Simple Storage Service (Amazon S3)</a>, CloudFront provides several important benefits. First, it improves your website’s performance by caching content at edge locations closer to your users, reducing latency and improving page load times. Second, it helps protect your S3 bucket by acting as a security layer—CloudFront can be configured to be the only way to access your content, preventing direct access to your S3 bucket. The new experience automatically configures these security best practices for you.</p><p>Complementing the new CloudFront experience, we’re also introducing an improved AWS WAF console that features intelligent Rule Packs—curated sets of security rules based on application type and security requirements. These Rule Packs enable developers to implement comprehensive security controls without needing to be security experts.</p><p>When creating a CloudFront distribution, developers can now enable AWS WAF protection through an integrated experience that uses these new Rule Packs. The console provides clear recommendations for security configurations that developers can use to preview and validate their settings before deployment.</p><p>Web applications face numerous security threats today, including SQL injection attacks, cross-site scripting (XSS), and other <a href=\"https://owasp.org/www-project-top-ten/\">OWASP Top 10</a> vulnerabilities. With the new AWS WAF integration, you automatically get protection against these common attack vectors. The recommended Rule Packs provide immediate protection against malicious bot traffic, common web exploits, and known bad actors while preventing direct-to-origin attacks that could overwhelm your infrastructure.</p><p>If you’ve ever created an Amazon CloudFront distribution, you’ll immediately notice that things have changed. The new experience is straightforward to follow and understand. For my example, I chose to create a distribution for a static website using Amazon S3 as my origin.</p><p>In , I give my distribution a name and select from  or the new <strong>Multi-tenant architecture</strong> option, which I can use to configure distributions that use multiple domains but share a common configuration. I choose  and enter an optional domain name. With the new experience, I can use the  button to verify I have my domain as a Route 53 zone file.</p><p>Next, I select the origin for the distribution, which is where CloudFront will fetch the content to serve and cache. For my , I select Amazon S3. As the preceding screenshot shows, there are several additional options to choose from. Each of the options is designed to make configuration as straightforward as possible for the most popular use cases. Next, I select my S3 bucket, either by typing in the bucket name or using the  button.</p><p>Next, I have several settings related to using Amazon S3 as my origin. The <strong>Grant CloudFront access to origin</strong> option is an important one. This option (selected by default) will update my S3 bucket policy to allow CloudFront to access my bucket and will configure my bucket for . This way, I can use a completely private bucket and know that assets in my bucket can only be accessed through CloudFront. This is a critical step to keeping my bucket and assets secure.</p><p>In the next step, I’m presented with the option to configure AWS WAF. With AWS WAF enabled, my web servers are better protected because it inspects each incoming request for potential threats before allowing them to make their way to my web servers. There is a cost to enabling AWS WAF, and as you can see in the following screenshot, there is a calculator to help estimate additional charges.</p><p>The new CloudFront onboarding experience and enhanced AWS WAF console are available today in all <a href=\"https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#region\">AWS Regions</a> where these services are offered. You can start using these new features through the <a href=\"https://aws.amazon.com/console/\">AWS Management Console</a>. There are no additional charges for using these new experiences—you pay only for the CloudFront and AWS WAF resources you use, based on their respective pricing models.</p>","contentLength":6745,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AWS Certificate Manager introduces exportable public SSL/TLS certificates to use anywhere","url":"https://aws.amazon.com/blogs/aws/aws-certificate-manager-introduces-exportable-public-ssl-tls-certificates-to-use-anywhere/","date":1750171580,"author":"Channy Yun (윤석찬)","guid":159654,"unread":true,"content":"<p>Now you can export public certificates from ACM, get access to the private keys, and use them on any workloads running on <a href=\"https://aws.amazon.com/ec2/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\">Amazon Elastic Compute Cloud (Amazon EC2)</a> instances, containers, or on-premises hosts. The exportable public certificate are valid for 395 days. There is a charge at time of issuance, and again at time of renewal.&nbsp;Public certificates exported from ACM are issued by <a href=\"https://www.amazontrust.com/repository/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\">Amazon Trust Services</a> and are widely trusted by commonly used platforms such as Apple and Microsoft and popular web browsers such as Google Chrome and Mozilla Firefox.</p><p><strong><u>ACM exportable public certificates in action</u></strong> To export a public certificate, you first request a new exportable public certificate. You cannot export previously created public certificates.</p><p>To get started, choose  in the <a href=\"https://console.aws.amazon.com/acm/home?#/certificates/request&amp;trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\">ACM console</a> and choose  in the  section. If you select , the private key for this certificate will be disallowed for exporting from ACM and this cannot be changed after certificate issuance.</p><pre><code>aws acm request-certificate \\\n--domain-name mydomain.com \\\n--key-algorithm EC_Prime256v1 \\\n--validation-method DNS \\\n--idempotency-token &lt;token&gt; \\\n--options \\\nCertificateTransparencyLoggingPreference=DISABLED \\\nExport=ENABLED</code></pre><p>After you request the public certificate, you must validate your domain name to prove that you own or control the domain for which you are requesting the certificate. The certificate is typically issued within seconds after successful domain validation.</p><p>When the certificate enters status , you can export your issued public certificate by choosing .</p><p>Enter a passphrase for encrypting the private key. You will need the passphrase later to decrypt the private key. To get the public key, Choose .</p><p>You can copy the PEM encoded certificate, certificate chain, and private key or download each to a separate file.</p><p>You can use the  command to export a public certificate and private key. For added security, use a file editor to store your passphrase and output keys to a file to prevent being stored in the command history.</p><pre><code>aws acm export-certificate \\\n     --certificate-arn arn:aws:acm:us-east-1:&lt;accountID&gt;:certificate/&lt;certificateID&gt; \\\n     --passphrase fileb://path-to-passphrase-file \\\n     | jq -r '\"\\(.Certificate)\\(.CertificateChain)\\(.PrivateKey)\"' \\\n     &gt; /tmp/export.txt</code></pre><p>You can now use the exported public certificates for any workload that requires SSL/TLS communication such as Amazon EC2 instances. To learn more, visit <a href=\"https://docs.aws.amazon.com/linux/al2/ug/SSL-on-amazon-linux-2.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\">Configure SSL/TLS on Amazon Linux</a> in your EC2 instances.</p><p> Here are a couple of things to know about exportable public certificates:</p><ul><li> – An administrator of your organization can set AWS IAM policies to authorize roles and users who can request exportable public certificates. ACM users who have current rights to issue a certificate will automatically get rights to issue an exportable certificate. ACM admins can also manage the certificates and take actions such as revoking or deleting the certificates. You should protect exported private keys using secure storage and access controls.</li><li> – You may need to revoke exportable public certificates to comply with your organization’s policies or mitigate key compromise. You can only revoke the certificates that were previously exported. The certificate revocation process is global and permanent. Once revoked, you can’t retrieve revoked certificates to reuse. To learn more, visit <a href=\"http://docs.aws.amazon.com/acm/latest/userguide/revoke-certificate.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\">Revoke a public certificate</a> in the AWS documentation.</li><li> – You can configure automatic renewal events for exportable public certificates by <a href=\"https://aws.amazon.com/eventbridge/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\">Amazon EventBridge</a> to monitor certificate renewals and create automation to handle certificate deployment when renewals occur. To learn more, visit <a href=\"https://docs.aws.amazon.com/acm/latest/userguide/cloudwatch-events.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\">Using Amazon EventBridge</a> in the AWS documentation. You can also renew these certificates on-demand. When you renew the certificates, you’re charged for a new certificate issuance. To learn more, visit <a href=\"http://docs.aws.amazon.com/acm/latest/userguide/force-certificate-renewal.html?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\">Force certificate renewal</a> in the AWS documentation.</li></ul><p> You can now issue exportable public certificates from ACM and export the certificate with the private keys to use other compute workloads as well as ELB, Amazon CloudFront, and Amazon API Gateway.</p><p>You are subject to additional charges for an exportable public certificate when you create it with ACM. It costs $15 per fully qualified domain name and $149 per wildcard domain name. You only pay once during the lifetime of the certificate and will be charged again only when the certificate renews. To learn more, visit the <a href=\"https://aws.amazon.com/certificate-manager/pricing/?trk=769a1a2b-8c19-4976-9c45-b6b1226c7d20&amp;sc_channel=el\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Certificate Manager Service Pricing</a> page.</p>","contentLength":4464,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Verify internal access to critical AWS resources with new IAM Access Analyzer capabilities","url":"https://aws.amazon.com/blogs/aws/verify-internal-access-to-critical-aws-resources-with-new-iam-access-analyzer-capabilities/","date":1750169348,"author":"Micah Walter","guid":159653,"unread":true,"content":"<p>Security teams in regulated industries, such as financial services and healthcare, need to verify access to sensitive data stores like <a href=\"https://aws.amazon.com/s3\">Amazon Simple Storage Service (Amazon S3)</a> buckets containing credit card information or healthcare records. Previously, teams had to invest considerable time and resources conducting manual reviews of AWS Identity and Access Management (IAM) policies or rely on pattern-matching tools to understand internal access patterns.</p><p>The new IAM Access Analyzer internal access findings identify who within your AWS organization has access to your critical AWS resources. It uses automated reasoning to collectively evaluate multiple policies, including service control policies (SCPs), resource control policies (RCPs), and identity-based policies, and generates findings when a user or role has access to your S3 buckets, <a href=\"https://aws.amazon.com/dynamodb/\">Amazon DynamoDB</a> tables, or <a href=\"https://aws.amazon.com/rds/\">Amazon Relational Database Service (Amazon RDS)</a> snapshots. The findings are aggregated in a unified dashboard, simplifying access review and management. You can use <a href=\"https://aws.amazon.com/eventbridge/\">Amazon EventBridge</a> to automatically notify development teams of new findings to remove unintended access. Internal access findings provide security teams with the visibility to strengthen access controls on their critical resources and help compliance teams demonstrate access control audit requirements.</p><p>To begin using this new capability, you can enable IAM Access Analyzer to monitor specific resources using the <a href=\"https://aws.amazon.com/console/\">AWS Management Console</a>. Navigate to IAM and select  under the  section of the left-hand navigation menu. From here, select .</p><p>From the  page, select the option of <strong>Resource analysis – Internal access</strong>. Under , you can customize your analyzer’s name to whatever you prefer or use the automatically generated name. Next, you need to select your . If your account is the management account for an AWS organization, you can choose to monitor resources across all accounts within your organization or the current account you’re logged in to. If your account is a member account of an AWS organization or a standalone account, then you can monitor resources within your account.</p><p>The zone of trust also determines which IAM roles and users are considered in scope for analysis. An organization zone of trust analyzer evaluates all IAM roles and users in the organization for potential access to a resource, whereas an account zone of trust only evaluates the IAM roles and users in that account.</p><p>For this first example, we assume our account is the management account and create an analyzer with the organization as the zone of trust.</p><p>Next, we need to select the resources we wish to analyze. Selecting  gives us three options. Let’s first examine how we can select resources by identifying the account and resource type for analysis.</p><p>You can use dialog to choose resource types through a new interface. Here, we select <strong>All supported resource types</strong> and select the accounts we wish to monitor. This will create an analyzer that monitors all supported resource types. You can either select accounts through the organization structure (shown in the following screenshot) or paste in account IDs using the  option.</p><p>You can also choose to use the <strong>Define specific resource types</strong> dialog, which you can use to pick from a list of supported resource types (as shown in the following screenshot). By creating an analyzer with this configuration, IAM Access Analyzer will continually monitor both existing and new resources of the selected type within the account, checking for internal access.</p><p>After you’ve completed your selections, choose .</p><p>Alternatively, you can use the <strong>Add resources by resource ARN</strong> option.</p><p>Or you can use the <strong>Add resources by uploading a CSV file</strong> option to configure monitoring a list of specific resources at scale.</p><p>After you’ve completed the creation of your analyzer, IAM Access Analyzer will analyze policies daily and generate findings that show access granted to IAM roles and users within your organization. The updated IAM Access Analyzer dashboard now provides a resource-centric view. The  section summarizes access into three distinct categories: public access, external access outside of the organization (requires creation of a separate external access analyzer), and access within the organization. The  section highlights the top resources with active findings across the three categories. You can see a list of all analyzed resources by selecting  or  on the left-hand navigation menu.</p><p>On the  page, you can filter the list of all analyzed resources for further analysis.</p><p>When you select a specific resource, any available external access and internal access findings are listed on the  page. Use this feature to evaluate all possible access to your selected resource. For each finding, IAM Access Analyzer provides you with detailed information about allowed IAM actions and their conditions, including the impact of any applicable SCPs and RCPs. This means you can verify that access is appropriately restricted and meets least-privilege requirements.</p><p>This new IAM Access Analyzer capability is available today in all commercial Regions. <a href=\"https://aws.amazon.com/iam/access-analyzer/pricing/\">Pricing</a> is based on the number of critical AWS resources monitored per month. External access analysis remains available at no additional charge. Pricing for EventBridge applies separately.</p>","contentLength":5302,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Merging Business Logic and DevOps","url":"https://devops.com/merging-business-logic-and-devops/?utm_source=rss&utm_medium=rss&utm_campaign=merging-business-logic-and-devops","date":1750146815,"author":"Chris Brill","guid":159429,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Embed Security Into Enterprise DevOps Pipelines","url":"https://devops.com/how-to-embed-security-into-enterprise-devops-pipelines/?utm_source=rss&utm_medium=rss&utm_campaign=how-to-embed-security-into-enterprise-devops-pipelines","date":1750144819,"author":"Gaurav Belani","guid":159428,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AWS Weekly Roundup: AWS re:Inforce 2025, AWS WAF, AWS Control Tower, and more (June 16, 2025)","url":"https://aws.amazon.com/blogs/aws/aws-weekly-roundup-aws-reinforce-2025-aws-waf-aws-control-tower-and-more-june-16-2025/","date":1750092997,"author":"Esra Kayabali","guid":157442,"unread":true,"content":"<p>Today marks the start of <a href=\"https://reinforce.awsevents.com/\">AWS re:Inforce 2025</a>, where security professionals are gathering for three days of technical learning sessions, workshops, and demonstrations. This security-focused conference brings together AWS security specialists who build and maintain the services that organizations rely on for their cloud security needs.</p><p>AWS Chief Information Security Officer (CISO) Amy Herzog will deliver the conference keynote along with guest speakers who will share new security capabilities and implementation insights. The event offers multiple learning paths with sessions designed for various technical roles and expertise levels. Many of my colleagues from across AWS are leading hands-on workshops, demonstrating new security features, and facilitating community discussions. For those unable to join us in Philadelphia, the keynote and innovation talks will be viewable by livestream during the event, and available to watch on demand after the event. Look out for the key announcements and technical insights from the conference in upcoming posts!</p><p>Let’s look at last week’s new announcements.</p><p> Here are the launches that got my attention.</p><p> – <a href=\"https://aws.amazon.com/q/developer/\">Amazon Q Developer</a> now supports Model Context Protocol (MCP) in its integrated development environment (IDE) plugins, helping developers integrate external tools for enhanced contextual development workflows. You can now augment the built-in tools with any MCP server that supports the stdio transport layer. These servers can be managed within the Amazon Q Developer user interface. This makes it easy to add, remove, and modify tool permissions. The integration enables more customized responses by orchestrating tasks across both native and MCP server-based tools. MCP support is available in Visual Studio Code and JetBrains IDE plugins, as well as in the Amazon Q Developer command line interface (CLI), with detailed documentation and implementation guides available in the <a href=\"https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-ide-configuration.html\">Amazon Q Developer documentation</a>.</p><p><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/06/aws-waf-automatic-application-layer-ddos-protection/\"><strong>AWS WAF now supports automatic application layer DDoS protection</strong></a> – AWS has enhanced its application layer (L7) distributed denial of service (DDoS) protection capabilities with faster automatic detection and mitigation that responds to events within seconds. This AWS Managed Rules group automatically detects and mitigates DDoS attacks of any duration to keep applications running on Amazon CloudFront, Application Load Balancer, and other AWS WAF supported services available to users. The system establishes a baseline within minutes of activation using machine learning (ML) models to detect traffic anomalies, then automatically applies rules to address suspicious requests. Configuration options help you customize responses such as presenting challenges or blocking requests. The feature is available to all AWS WAF and AWS Shield Advanced subscribers in all supported AWS Regions, except Asia Pacific (Thailand), Mexico (Central), and China (Beijing and Ningxia). To learn more about AWS WAF application layer (L7) DDoS protection, visit the <a href=\"https://docs.aws.amazon.com/waf/latest/developerguide/waf-anti-ddos.html\">AWS WAF documentation</a>&nbsp;or the&nbsp;<a href=\"https://console.aws.amazon.com/wafv2/homev2/home\">AWS WAF console</a>.</p><p><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/06/aws-control-tower-service-linked-aws-config-managed-rules/\"><strong>AWS Control Tower now supports service-linked AWS Config managed AWS Config rules</strong></a> – <a href=\"https://aws.amazon.com/controltower/\">AWS Control Tower</a> now deploys service-linked AWS Config rules directly in managed accounts, replacing the previous CloudFormation StackSets deployment method. This change improves deployment speed when enabling service-linked AWS Config rules across multiple AWS Control Tower managed accounts and Regions. These service-linked rules are managed entirely by AWS services and can’t be edited or deleted by users. This helps maintain consistency and prevent configuration drift. AWS Control Tower Config rules detect resource noncompliance within accounts and provide alerts through the dashboard. You can deploy these controls using the <a href=\"https://console.aws.amazon.com/controltower/home/landing\">AWS Control Tower console</a> or <a href=\"https://docs.aws.amazon.com/controltower/latest/APIReference/Welcome.html\">AWS Control Tower control APIs</a>.</p><p><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/06/powertools-lambda-bedrock-agents-function-utility/\"><strong>Powertools for AWS Lambda introduces Bedrock Agents Function utility</strong></a> – The new Amazon Bedrock Agents Function utility in Powertools for AWS Lambda simplifies building serverless applications integrated with Amazon Bedrock Agents. This utility helps developers create AWS Lambda functions that respond to Amazon Bedrock Agents action requests with built-in parameter injection and response formatting, eliminating boilerplate code. The utility seamlessly integrates with other Powertools features like Logger and Metrics, making it easier to build production-ready AI applications. This integration improves the developer experience when building agent-based solutions that use AWS Lambda functions to process actions requested by Amazon Bedrock Agents. The utility is available in Python, TypeScript, and .NET versions of Powertools.</p><p><a href=\"https://aws.amazon.com/about-aws/whats-new/2025/06/open-sourcing-pgactive-active-active-replication-extension-postgresql/\"><strong>Announcing open sourcing pgactive: active-active replication extension for PostgreSQL</strong></a> – Pgactive is a PostgreSQL extension that enables asynchronous active-active replication for streaming data between database instances, and AWS has made it open source. This extension provides additional resiliency and flexibility for moving data between instances, including writers located in different Regions. It helps maintain availability during operations like switching write traffic. Building on PostgreSQL’s logical replication features, pgactive adds capabilities that simplify managing active-active replication scenarios. The open source approach encourages collaboration on developing PostgreSQL’s active-active capabilities while offering features that streamline using PostgreSQL in multi-active instance environments. For more information and implementation guidance, visit the <a href=\"https://github.com/aws/pgactive\">GitHub repository</a>.</p><p>We launched existing services and instance types in additional Regions:</p><p> Check your calendar and sign up for upcoming AWS events.</p><p><a href=\"https://aws.amazon.com/startups/lp/aws-gen-ai-lofts\">AWS GenAI Lofts</a>&nbsp;are collaborative spaces and immersive experiences that showcase AWS expertise in cloud computing and AI. They provide startups and developers with hands-on access to AI products and services, exclusive sessions with industry leaders, and valuable networking opportunities with investors and peers.&nbsp;<a href=\"https://aws.amazon.com/startups/lp/aws-gen-ai-lofts#locations\">Find a GenAI Loft location near you</a>&nbsp;and don’t forget to register.</p><p><a href=\"https://aws.amazon.com/events/summits/\">AWS Summits</a> are free online and in-person events that bring the cloud computing community together to connect, collaborate, and learn about AWS. Register in your nearest city: <a href=\"https://aws.amazon.com/it/events/summits/milano/\">Milano</a> (June 18), <a href=\"https://aws.amazon.com/cn/events/summits/shanghai/\">Shanghai</a> (June 19 – 20), <a href=\"https://aws.amazon.com/events/summits/mumbai/\">Mumbai</a> (June 19) and <a href=\"https://aws.amazon.com/jp/summits/japan/\">Japan</a> (June 25 – 26).</p><p>That’s all for this week. Check back next Monday for another Weekly Roundup!</p><p><em>This post is part of our&nbsp;<a href=\"https://aws.amazon.com/blogs/aws/tag/week-in-review/\">Weekly Roundup</a>&nbsp;series. Check back each week for a quick roundup of interesting news and announcements from AWS!</em></p>","contentLength":6586,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Five Great DevOps Job Opportunities","url":"https://devops.com/five-great-devops-job-opportunities-143/?utm_source=rss&utm_medium=rss&utm_campaign=five-great-devops-job-opportunities-143","date":1750060399,"author":"Mike Vizard","guid":157059,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Changes to Kubernetes Slack","url":"https://kubernetes.io/blog/2025/06/16/changes-to-kubernetes-slack/","date":1750032000,"author":"","guid":157132,"unread":true,"content":"<p>: We’ve received notice from Salesforce that our Slack workspace  on June 20th. Stand by for more details, but for now, there is no urgency to back up private channels or direct messages.</p><p>. Sometime later this year, our community may move to a new platform. If you are responsible for a channel or private channel, or a member of a User Group, you will need to take some actions as soon as you can.</p><p>For the last decade, Slack has supported our project with a free customized enterprise account. They have let us know that they can no longer do so, particularly since our Slack is one of the largest and more active ones on the platform. As such, they will be downgrading it to a standard free Slack while we decide on, and implement, other options.</p><p>On Friday, June 20, we will be subject to the <a href=\"https://slack.com/help/articles/27204752526611-Feature-limitations-on-the-free-version-of-Slack\">feature limitations of free Slack</a>. The primary ones which will affect us will be only retaining 90 days of history, and having to disable several apps and workflows which we are currently using. The Slack Admin team will do their best to manage these limitations.</p><p>Responsible channel owners, members of private channels, and members of User Groups should <a href=\"https://github.com/kubernetes/community/blob/master/communication/slack-migration-faq.md#what-actions-do-channel-owners-and-user-group-members-need-to-take-soon\">take some actions</a> to prepare for the upgrade and preserve information as soon as possible.</p><p>The CNCF Projects Staff have proposed that our community look at migrating to Discord. Because of existing issues where we have been pushing the limits of Slack, they have already explored what a Kubernetes Discord would look like. Discord would allow us to implement new tools and integrations which would help the community, such as GitHub group membership synchronization. The Steering Committee will discuss and decide on our future platform.</p>","contentLength":1684,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cloud Native Live: From cloud to code - managing growth with infrastructure as code","url":"https://www.youtube.com/watch?v=E-c6QZXOjs4","date":1750031633,"author":"CNCF [Cloud Native Computing Foundation]","guid":155921,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"https://www.youtube.com/v/E-c6QZXOjs4?version=3","enclosureMime":"","commentsUrl":null}],"tags":["devops"]}