{"id":"i2nisf4o","title":"Reddit","displayTitle":"Reddit","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":161,"items":[{"title":"What's the best way to run redis in cluster?","url":"https://www.reddit.com/r/kubernetes/comments/1lh24mz/whats_the_best_way_to_run_redis_in_cluster/","date":1750527395,"author":"/u/TemporalChill","guid":164369,"unread":true,"content":"<p>I just installed cnpg and the dx is nice. Wondering if there's anything close to that quality for redis?</p>","contentLength":104,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[P] Autopaste MFA codes from Gmail using Local LLMs","url":"https://www.reddit.com/r/MachineLearning/comments/1lh0rmp/p_autopaste_mfa_codes_from_gmail_using_local_llms/","date":1750523865,"author":"/u/samewakefulinsomnia","guid":164372,"unread":true,"content":"<p>Connect accounts, choose LLM provider (Ollama supported), add a system shortcut targeting the script, and enjoy your extra 10 seconds every time you need to paste your MFAs</p>","contentLength":172,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stoned Gopher","url":"https://postimg.cc/qNWDQgN1","date":1750523441,"author":"/u/BloomerGrow","guid":164373,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1lh0ls3/stoned_gopher/"},{"title":"Behind the scenes: Redpanda Cloud‚Äôs response to the GCP outage","url":"https://www.redpanda.com/blog/gcp-outage-june-redpanda-cloud","date":1750520027,"author":"/u/gametorch","guid":164371,"unread":true,"content":"<p>On Jun 12th, 2025, Google Cloud Platform (GCP) experienced an unfortunate global outage triggered by an automated quota update to their API management system.&nbsp;</p><p>What was a major outage for a large part of the internet was just another normal day for <a href=\"https://www.redpanda.com/product/bring-your-own-cloud-byoc\">Redpanda Cloud</a> customers. While GCP dealt with the widespread disruption that impacted many critical services, Redpanda Cloud clusters in GCP remained stable, thanks to being purposely designed for the <a href=\"https://www.redpanda.com/blog/celebrating-two-years-redpanda-cloud#raising-the-bar-on-reliability\">SLA we offer</a>, along with a <a href=\"https://docs.aws.amazon.com/wellarchitected/latest/reducing-scope-of-impact-with-cell-based-architecture/what-is-a-cell-based-architecture.html\">cell-based architecture</a> that we also made a <a href=\"https://www.redpanda.com/blog/byoc-data-plane-atomicity-secure-cloud\">product principle</a>. But behind the scenes, it was far from quiet. </p><p>This post provides a brief timeline of events from our own experience, our response, previously untold details about Redpanda Cloud, and closing thoughts on safety and reliability practices in our industry.</p><h2>Why do incidents like this happen</h2><p>Modern computer systems are complex systems ‚Äî&nbsp;and complex systems are characterized by their non-linear nature, which means that observed changes in an output  proportional to the change in the input. This concept is also known in chaos theory as the , or in systems thinking, with the expression, ‚ÄúThe whole is greater than the sum of its parts‚Äù.&nbsp;</p><p>When this mathematical fact is acknowledged, safety and reliabiilty measures are put in place, such as closing feedback control loops, phasing change rollouts, shedding load, applying backpressure, randomizing retries, and defining incident response processes, among others.</p><p>GCP‚Äôs seemingly innocuous automated quota update triggered a <a href=\"https://status.cloud.google.com/incidents/ow5i3PPK96RduMcb1SsW\">butterfly effect</a> that no human could have predicted, affecting several companies ‚Äî&nbsp;some known for their impressive engineering culture and considered internet pillars for their long-standing availability record.</p><p>Our Google Cloud Technical Account Manager (TAM) notified us about the outage:</p><p>We began to assess the impact on our Redpanda Cloud GCP customers, including whether we had received any support tickets.&nbsp;</p><p>We noticed our monitoring was running in a degraded state. Despite self-hosting our observability data and stack, we still use a third-party provider for dashboarding and alerting needs. This provider was partially affected. We could still monitor metrics, but we were not getting alert notifications.&nbsp;</p><p>We deemed the loss of alert notifications not critical since we were still able to assess the impact through other means, such as querying our self-managed metrics and logging stack.</p><p>At this point, it was clear that multiple GCP services were experiencing a global outage, despite not having received support tickets from our customers or being paged by Redpanda Cloud alerts. So, in preparation for the worst, we preemptively created a low-severity incident to coordinate the response to multiple  incidents.</p><p>We were notified by the vendor we use for managing cloud marketplaces that they were having issues. They were affected by the <a href=\"https://blog.cloudflare.com/cloudflare-service-outage-june-12-2025/\" target=\"_blank\">Cloudflare outage</a>, which we later learned was connected to the GCP outage. Having this service degraded was not critical to us, so we put it on the waiting list.</p><p>Google identified the triggering cause and applied mitigations. At this point, there was no evidence that Redpanda Cloud customers were being negatively impacted. </p><p>We began receiving delayed alert notifications, mostly related to an increase in tiered storage errors, which is not Redpanda‚Äôs primary storage. We didn‚Äôt get high disk utilization alerts, which we typically receive when the tiered storage subsystem has been experiencing issues for an extended period (days). </p><p>Additionally, as a reliability measure, we leave disk space unused and used-but-reclaimable (for caching), which we can reclaim if the situation warrants it. This outage was not that situation.</p><p>We proactively started reaching out to customers with the highest tiered storage error rates to ensure we were not missing anything, and also to show our support, as is customary. We fully manage these BYOC clusters on behalf of our customers and have complete visibility ‚Äî we know the answers to the questions, but we ask anyway. These are complex systems, after all.</p><p>After closely monitoring our GCP fleet for some time, we considered the incident mitigated‚Äîwith the severity unchanged (SEV4), and no evidence of negative customer impact. We noticed an increase in error rate for API calls against GCS, with minimal latency impact in some cases. However, hundreds of GCP clusters were up and healthy.</p><h2>Strengths that played in our favor</h2><p>Acknowledging the risk of hindsight bias, the following factors contributed to the GCP outage having no negative impact on our Redpanda Cloud GCP customers.</p><p>Redpanda Cloud clusters do not externalize their metadata or any other critical services. All the services needed to write and read data, manage topics, ACLs, and other Kafka entities are co-located, with Redpanda core leading the way with its single-binary architecture. This follows a well-known <a href=\"https://docs.aws.amazon.com/wellarchitected/latest/reducing-scope-of-impact-with-cell-based-architecture/what-is-a-cell-based-architecture.html#:~:text=A%20cell-based%20architecture%20uses,of%20the%20overall%20workload%20requests\">architectural pattern</a> aimed at reducing the impact radius of failures, which also improves security.&nbsp;</p><p>We have taken this pattern further and made it a <a href=\"https://www.redpanda.com/blog/byoc-data-plane-atomicity-secure-cloud\">product principle</a>. In contrast, other products boasting centralized metadata and a diskless architecture likely experienced the full weight of this global outage.</p><h3>Purposely designed for the SLA we offer</h3><p>After launching Redpanda Cloud, it took us two years <a href=\"https://www.redpanda.com/blog/celebrating-two-years-redpanda-cloud\">to offer a 99.99% availability SLA. </a>Responsibly offering 1 extra 9 of SLA takes a significant amount of investment and effort. <a href=\"https://www.redpanda.com/blog/high-availability-multi-az-deployment-part-3\">Multi-AZ Redpanda Cloud</a> clusters in GCP were designed to support an availability SLO of at least 99.999%. In practice, we observe even higher measurements. </p><p>This is possible thanks to multiple factors:</p><ul role=\"list\"><li>Redpanda Cloud clusters enforce a replication factor of at least 3 on all topics; customers cannot lower the replication factor, only increase it.&nbsp;</li><li>Redpanda stores the primary data on local NVMe disks and sends older data to tiered storage, asynchronously.</li><li>All Redpanda services are redundant: Kafka API, Schema Registry, and Kafka HTTP Proxy</li><li>There are no additional dependencies in the critical path other than the VPC, compute nodes, and their locally attached disks*</li><li>We continuously chaos-test and load-test Redpanda Cloud tiers' configurations</li><li>We have a strict release engineering process that tests and certifies Redpanda Cloud tiers for the throughput they advertise, in each cloud provider.</li><li>As operations are issued, such as Redpanda or cloud infrastructure upgrades, we try to close our <a href=\"https://en.wikibooks.org/wiki/Control_Systems/Feedback_Loops\">feedback control loops</a> by watching Redpanda metrics as the phased rollout progresses and stopping when user-facing issues are detected.</li></ul><blockquote>*Except when Private Service Connect (PSC) is enabled, in this case, the PSC becomes part of the critical path for reading and writing data to Redpanda.</blockquote><p>For cloud services such as Redpanda Cloud, which operates across the three major cloud providers and has numerous engineers continuously modifying the system, it is challenging to emerge unharmed from a global outage like this without some degree of fortune ‚Äì although we learned later that one cluster was badly affected, keep on reading for the details.</p><h3>Redpanda‚Äôs location in our customers' technical stacks</h3><p>Understandably, GCP customers were experiencing significant internal chaos and struggling to assess the full impact when we reached out. For some of them, GCP's Pub/Sub served as the data source for their Redpanda BYOC clusters, so they needed to recover that first. While this meant Redpanda's operational status was less critical in those cases, it was still one less element for them to worry about.</p><h3>We didn‚Äôt lose nodes en masse during the incident</h3><p>As I was wrapping up this post, another incident had unfolded and was being mitigated. During its incident analysis, we found evidence that the GCP outage was a contributing factor in losing one node and having no replacement coming back. However, this event was isolated to and an uncommon interaction between internal infrastructure components of the cluster.</p><p>Out of hundreds of clusters, we were lucky that only one cluster was affected. It took GCP around two hours to launch the replacement node, roughly the duration of the outage in , the region in which this cluster was located. Fortunately for the customer, the affected cluster was not a production but a staging cluster. Their production Redpanda cluster was unaffected.&nbsp;</p><h3>Observability infrastructure</h3><p>We moved to a self-managed observability stack last year, primarily due to increased scale and cost, and were only using a third-party service for dashboarding and alerting needs. Had we kept our entire observability stack on that service, we would have lost all our fleet-wide log searching capabilities, forcing us to fail over to another vendor with exponentially bigger cost ramifications given our scale. </p><p>In other words, this graph would have been filled with many more red bars and tears:</p><p>As an industry, it seems we keep having to relearn hard lessons from the past. Not too long ago, we were all in awe at the <a href=\"https://www.crowdstrike.com/en-us/blog/falcon-content-update-preliminary-post-incident-report/\">global Crowdstrike outage</a>, where similar controls were missing to enable safer global rollouts, affecting millions of Windows computers, and resulting in hundreds of millions of dollars in damages to their customers.</p><p>With the resurgence of AI, systems will inevitably get even more complex. So, it seems valuable and timely to reconsider our current mindset, and I cannot think of anything better than a <a href=\"https://thesystemsthinker.com/systems-thinking-what-why-when-where-and-how/\">systems thinking mindset</a>, especially when engineering our socio-technical systems, which should also result in increased adoption of control theory in our change management tools.</p><p>Time will tell, perhaps all the above will be left to AI agents to control, perhaps not, for the foreseeable future, it seems we have no AI replacement, so we better hone our systems thinking skills.<a href=\"https://www.redpanda.com/try-redpanda?byoc\" target=\"_blank\">get started with Redpanda Cloud</a> for free or <a href=\"https://www.redpanda.com/contact\" target=\"_blank\">get in touch</a> for a demo. For any other questions, drop us a note in Slack. </p>","contentLength":9848,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lgzb1f/behind_the_scenes_redpanda_clouds_response_to_the/"},{"title":"üß™ iapetus ‚Äì A fast, pluggable open-source workflow engine for CI/CD and DevOps (written in Go)","url":"https://www.reddit.com/r/kubernetes/comments/1lgyoza/iapetus_a_fast_pluggable_opensource_workflow/","date":1750518392,"author":"/u/Outrageous-Income592","guid":164335,"unread":true,"content":"<p>Just open-sourced a project I‚Äôve been working on: <a href=\"https://github.com/yindia/iapetus\"></a> üöÄ</p><p>It‚Äôs a lightweight, developer-friendly workflow engine built for CI/CD, DevOps automation, and end-to-end testing. Think of it as a cross between a shell runner and a testing/assertion engine‚Äîwithout the usual YAML hell or vendor lock-in.</p><ul><li>Runs tasks in parallel with dependency awareness</li><li>Supports multiple backends (e.g., Bash, Docker, or your own plugin)</li><li>Lets you assert outputs, exit codes, regex matches, JSON responses, and more</li><li>Can be defined in </li><li>Integrates well into CI/CD pipelines or as a standalone automation layer</li></ul><pre><code>name: hello-world steps: - name: say-hello command: echo args: [\"Hello, iapetus!\"] raw_asserts: - output_contains: iapetus </code></pre><pre><code>task := iapetus.NewTask(\"say-hello\", 2*time.Second, nil). AddCommand(\"echo\"). AddArgs(\"Hello, iapetus!\"). AssertOutputContains(\"iapetus\") workflow := iapetus.NewWorkflow(\"hello-world\", zap.NewNop()). AddTask(*task) workflow.Run() </code></pre><ul><li>Automate and test scripts with clear assertions</li><li>Speed up CI runs with parallel task execution</li><li>Replace brittle bash scripts or overkill CI configs</li></ul><p>It's fully open source under the MIT license. Feedback, issues, and contributions are all welcome!</p><p>Would love to hear thoughts or ideas on where it could go next. üôå</p>","contentLength":1242,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building a Redis clone from scratch","url":"https://www.reddit.com/r/rust/comments/1lgyduy/building_a_redis_clone_from_scratch/","date":1750517568,"author":"/u/ShowXw","guid":164370,"unread":true,"content":"<p>I figured the best way to actually  Rust was to build something real, so I decided to make a Redis-like database from scratch. It was a ton of fun and I learned a lot.</p><p>I wrote up my whole journey and thought I'd share it here. In the post, I get into some of the tricky (but fun) parts, like:</p><ul><li>Setting up a concurrent TCP server with Tokio.</li><li>Juggling shared data between async tasks with .</li><li>Figuring out a simple way to save data to disk using a \"dirty\" flag.</li></ul><p>Let me know what you think! Happy to answer any questions about it.</p>","contentLength":519,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Poor little buddy, Grok","url":"https://www.reddit.com/r/artificial/comments/1lgyan3/poor_little_buddy_grok/","date":1750517326,"author":"/u/Revolutionary_Rub_98","guid":164304,"unread":true,"content":"<p>Elon has plans for eliminating the truth telling streak outta little buddy grok</p>","contentLength":79,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I made a frontend for the xsetwacom utility!","url":"https://www.reddit.com/r/linux/comments/1lgxtiq/i_made_a_frontend_for_the_xsetwacom_utility/","date":1750516009,"author":"/u/Neeyaki","guid":164306,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"File APIs need a non-blocking open and stat","url":"https://bold-edit.com/devlog/week-12.html","date":1750515559,"author":"/u/levodelellis","guid":164268,"unread":true,"content":"<p>What happens if you call  on a file on a network that went down? Do you get A) an IO error? B) An error like EAGAIN to suggest the stat won't complete for many milliseconds C) stat blocks until the network times out which could be many minutes</p><p>The answer is C. With linux you can work around the problem by using io_uring, but on windows and mac you're out of luck. They have async IO, but neither of those OSes seem to have a non-blocking stat nor a non-blocking open. I'll need to use threads and have them idle most of the time.</p><p>This week I implemented a directory iterator. This doesn't solve the problem above but it does allow me to have easier to read code. Second I upgraded the coverage script so I have more coverage options, specifically which coverage tool to run (more than one is an option.) A previous option I implemented was to build using headless or gui. This works with that so if I'm trying to raise coverage on one specific file I can use the fastest coverage tool and use a headless build that compiles and executes quicker. Third I implemented an async substring search. The search implementation itself I took from my original bold source which uses SIMD and is well tested. This week is the async implementation around that substring search. Fourth I compiled and fixed all my code on mac. I use linux on my desktop so I sometimes don't compile on mac for weeks.</p><p>While writing the async substring code I didn't like how related functions were far away from each other. I have a worker queue that uses a callback to check how much a message 'cost' and tries to divide up the work across its queues. The 'cost' and 'process' callbacks have a giant switch statement. It was awkward that if I wanted to implement a small message I'd have to modify two large functions. I reworked it so I can use an interface. No more switch statements.</p>","contentLength":1855,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lgxnos/file_apis_need_a_nonblocking_open_and_stat/"},{"title":"Unexpected security footguns in Go's parsers","url":"https://blog.trailofbits.com/2025/06/17/unexpected-security-footguns-in-gos-parsers/","date":1750512226,"author":"/u/TheSinnohScrolls","guid":164272,"unread":true,"content":"<p>In Go applications, parsing untrusted data creates a dangerous attack surface that‚Äôs routinely exploited in the wild. During our security assessments, we‚Äôve repeatedly exploited unexpected behaviors in Go‚Äôs JSON, XML, and YAML parsers to bypass authentication, circumvent authorization controls, and exfiltrate sensitive data from production systems.</p><p>These aren‚Äôt theoretical issues‚Äîthey‚Äôve led to documented vulnerabilities like <a href=\"https://nvd.nist.gov/vuln/detail/cve-2020-16250\">CVE-2020-16250</a> (a Hashicorp Vault authentication bypass found by Google‚Äôs Project Zero) and numerous high-impact findings in our client engagements.</p><p>This post contextualizes these unexpected parser behaviors through three attack scenarios that every security engineer and Go developer should understand:</p><ol><li><strong>(Un)Marshaling unexpected data</strong>: How Go parsers can expose data that developers intended to be private</li><li>: How discrepancies between parsers enable attackers to bypass security controls when multiple services parse the same input</li><li>: How parsers process cross-format payloads with surprising and exploitable results</li></ol><p>We‚Äôll demonstrate each attack scenario with real-world examples and conclude with concrete recommendations for configuring these parsers more securely, including strategies to compensate for security gaps in Go‚Äôs standard library.</p><p>Below is a summary of the surprising behaviors we‚Äôll examine, with indicators showing their security status:</p><ul><li>üü¢ : Secure by default</li><li>üü† : Insecure by default but configurable</li><li>üî¥ : Insecure by default with no secure configuration options</li></ul><div><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table></div><p>Let‚Äôs examine how Go parses JSON, XML, and YAML. Go‚Äôs standard library provides JSON and XML parsers but not a YAML parser, for which there are several third-party alternatives. For our analysis, we‚Äôll focus on:</p><p>We‚Äôll use JSON in our following examples, but all three parsers have APIs equivalent to the ones we‚Äôll see.</p><p>At their core, these parsers provide two primary functions:</p><ul><li> (serialize): Converts Go structs into their respective format strings</li><li> (deserialize): Converts format strings back into Go structs</li></ul><p>Go uses struct field tags to allow customization of how parsers should handle individual fields. These tags consist of:</p><ul><li>A  for serialization/deserialization</li><li>Optional <strong>comma-separated directives</strong> that modify behavior (e.g., the  tag option tells the JSON serializer not to include the field in the JSON output string if it is empty)</li></ul><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>To unmarshal a JSON string into the  structure shown above, we must use the  key for the  field,  for the  field, and  for the  field.</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>These parsers also offer stream-based alternatives that operate on  interfaces rather than  slices. This API is ideal for parsing streaming data such as HTTP request bodies, making it a preferred choice in HTTP request handling.</p><h2>Attack scenario 1: (Un)Marshaling unexpected data</h2><p>Sometimes, you need to limit which fields of a structure can be marshaled or unmarshaled.</p><p>Let‚Äôs consider a simple example in which a back-end server has an HTTP handler for creating users and another for retrieving that user after authentication.</p><p>When creating a user, you may not want the user to be able to set the  field (i.e., unmarshal that field from the user input).</p><p>Similarly, when fetching the user, you may not want the user to return the user‚Äôs  or other secret values.</p><p>How can we instruct the parsers not to marshal or unmarshal a field?</p><p>Let‚Äôs first see what happens if you don‚Äôt set a JSON tag.</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>In this case, you can unmarshal the  field with its name, as shown below.</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>This is well documented, and most Go devs are aware of it. Let‚Äôs look at another example:</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>Is it evident that the  field above would be unmarshaled? A less senior or distracted developer could assume it would not and introduce a security vulnerability.</p><p>If you‚Äôd like to scan your codebase for this pattern, where some but not all fields have a JSON, XML, or YAML tag, you can use the following Semgrep rule. This rule is not on the our <a href=\"https://semgrep.dev/p/trailofbits\">collection of rules exposed on the Semgrep registry</a> because, depending on the codebase, it is likely to produce many false positives.</p><figure><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></figure><p>To tell the parser not to (un)marshal a specific field, we must add the special  JSON tag!</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>Oh, whoops, we were still able to set the  field. We copy-pasted the  part by mistake, which caused the parser to look for the  key in the provided JSON input. I searched for this pattern on the top 1,000 Go repositories by stars on GitHub and, among a few others, I found and reported these two results, which are now fixed:</p><blockquote><p>As a special case, if the field tag is ‚Äú-‚Äù, the field is always omitted. Note that a field with name ‚Äú-‚Äù can still be generated using the tag ‚Äú-,‚Äù.</p></blockquote><p>The XML and YAML parsers operate similarly, with one key difference: the XML parser treats the  tag as invalid. To resolve this, we must prefix the  symbol with an XML namespace, such as .</p><p>Ok, ok, let‚Äôs do it right this time.</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>Finally! Now, there is no way for the  field to be unmarshaled.</p><p>But I hear you ask: How can these misconfigurations lead to security vulnerabilities? The most common way is, like in our example, using  as the JSON tag for a field such as ‚Äìa field the user should not control. This is a hard bug to detect with unit tests because unless you have an explicit test that unmarshals an input with the  key and detects if any field was written to, you won‚Äôt detect it. You need your IDE or an external tool to detect it.</p><p>We created a <a href=\"https://semgrep.dev/playground/r/trailofbits.go.unmarshal-tag-is-dash?editorMode=advanced\">public Semgrep rule</a> to help you find similar issues in your codebases. Try it with <code>semgrep -c r/trailofbits.go.unmarshal-tag-is-dash</code>!</p><p>Another very simple misconfiguration we‚Äôve found before was a developer mistakenly setting the field name to .</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>If you set the JSON tag to , the parser will use  as the field‚Äôs name (as expected). Of course, some developers have tried to use this to set the  option in the field while keeping the default name. I searched the top 1,000 Go repositories for this pattern and found these results:</p><p>In these cases, the developer often wanted to set the tag to , which would keep the default name, and add the  tag option.</p><p>Contrary to the previous example, this one is unlikely to have a security impact and should be easy to detect with tests because any attempt to serialize or deserialize input with the expected field name will fail. However, as we can see, it still shows up even in popular open-source repositories. We created a <a href=\"https://semgrep.dev/playground/r/trailofbits.go.unmarshal-tag-is-omitempty?editorMode=advanced\">public Semgrep rule</a> to help you find similar issues in your codebases. Try it with <code>semgrep -c r/trailofbits.go.unmarshal-tag-is-omitempty</code>!</p><h2>Attack scenario 2: Parser differentials</h2><p>What can happen if you parse the same input with different JSON parsers and they disagree on the result? More specifically, which behaviors in Go parsers allow attackers to trigger these discrepancies ‚Äúreliably‚Äù?</p><p>As an example, let‚Äôs use the following application using a microservice architecture with:</p><ul><li>A  that receives all user requests</li><li>An  called by the Proxy Service to determine if the user has sufficient permission to complete their request</li><li>Multiple  called by the Proxy Service to perform the business logic</li></ul><p>In this first flow, a regular, non-admin user attempts to perform a , an action they are  to perform.</p><p>In this second flow, the same regular user attempts to perform an , an action they are  to perform.</p><p>Finally, the following flow is because the services disagree on the action the user is trying to perform.</p><p>The Authorization Service, written in a different programming language or using a non-default Go parser, will parse  and grant the user permission to perform the operation, while the Proxy Service, using Go‚Äôs default parser, will parse  and proxy it to the incorrect service. The remaining question is: Which payloads can we use to achieve this behavior?</p><p>This is a common architecture we‚Äôve seen multiple times during our audits, and against which we‚Äôve found authentication bypasses because of the problems we‚Äôll describe below. Other examples exist, but most follow the same pattern: the component that does security checks and the component that performs the actions differ in their view of the input data. Here are some of those examples in a variety of scenarios:</p><p>The first differential attack vector we‚Äôll explore is duplicate keys. What happens when your JSON input has the same key twice? It depends on the parser!</p><p>In Go, the JSON parser will always . There is no way to prevent this behavior.</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>This is the default behavior of most parsers. However, as shown in the <a href=\"https://bishopfox.com/blog/json-interoperability-vulnerabilities\">JSON interoperability vulnerabilities</a> blog post from Bishop Fox, seven out of the 49 parsers tested take the first key:</p><ul></ul><p>None of these are the most common JSON parsers in their corresponding languages, even though some are common alternatives.</p><p>So, if our Proxy Service uses the Go JSON parser and the Authorization Service uses one of these parsers, we get our discrepancy, as shown in the figure below.</p><p>The XML parser has the same behavior, while the YAML parser returns an error on duplicate fields‚Äîthe secure default we think all of these parsers should implement.</p><p>While not ideal, at least this behavior is consistent with the most commonly used JSON and XML parsers. Let‚Äôs now take a look at a much worse behavior that will almost always get you a discrepancy between Go‚Äôs default parser and any other parser.</p><h3>Case insensitive key matching</h3><p>Go‚Äôs JSON parser parses field names case-insensitively. Whether you write action , , or , the parser treats them as identical!</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>This is <a href=\"https://pkg.go.dev/encoding/json#Unmarshal\">documented</a> but is very unintuitive, there‚Äôs no way to disable it, and almost no other parser has this behavior.</p><p>To make this worse, as we saw above, you can have duplicate fields, and the latter one is still chosen, eVeN wHeN tHe cAsInG dOeS nOt mAtCh.</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>This is against the documentation, which says:</p><blockquote><p>‚ÄúTo unmarshal JSON into a struct, Unmarshal matches incoming object keys to the keys used by Marshal (either the struct field name or its tag), <strong>preferring an exact match but also accepting a case-insensitive match</strong>.‚Äù</p></blockquote><p>You can even use Unicode characters! In the example below, we‚Äôre using  (the unicode character named Latin small letter long s) as an , and  (the unicode character for the Kelvin sign) as a . From our testing of the <a href=\"https://cs.opensource.google/go/go/+/master:src/encoding/json/fold.go\">JSON library code</a> that does the comparison, only these two unicode characters match ASCII characters.</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>Applying it to our running attack scenario, this is how the attack would look like:</p><p>In our opinion, this is the most critical pitfall of Go‚Äôs JSON parser because it differs from the default parsers for JavaScript, Python, Rust, Ruby, Java, and all other parsers we tested. This has led to many high-impact security vulnerabilities, including ones we‚Äôve found during our audits.</p><p>This only affects the JSON parser. The XML and YAML parsers use exact matches.</p><p>If you are interested in other kinds of JSON parsing differentials between many parsers, we recommend these two blog posts:</p><p>For the final attack scenario, let‚Äôs see what happens if you parse a JSON file with the XML parser or use any other format with the incorrect parser.</p><p>As an example, let‚Äôs use <a href=\"https://nvd.nist.gov/vuln/detail/cve-2020-16250\">CVE-2020-16250</a>, an Hashicorp Vault bypass in its AWS IAM authentication method. This bug was found by Google‚Äôs Project Zero team, and a detailed analysis can be found in their <a href=\"https://googleprojectzero.blogspot.com/2020/10/enter-the-vault-auth-issues-hashicorp-vault.html\">‚ÄúEnter the Vault: Authentication Issues in HashiCorp Vault‚Äù</a> blog post if you are interested. We won‚Äôt go through all the details in this post, but in summary, this is how the normal Hashicorp Vault AWS IAM authentication flow works:</p><ol><li>The AWS resource sends it to the Vault Server.</li><li>The Vault Server builds that requests and sends it to the AWS Security Token Service (STS).</li><li>AWS STS verifies the signature.</li><li>On success, AWS STS returns the associated role‚Äôs identity in an XML document.</li><li>The Vault Server parses the XML, extracts the identity, and, if that AWS role should have access to the requested secrets, it returns them.</li><li>The AWS resource can now use the secret to, for example, authenticate against a database.</li></ol><p>What Google‚Äôs Project Zero team found was that an attacker could control too much in step 2, including controlling all headers of the request that Vault builds in step 3. In particular, by setting the  header to , AWS STS would now return a JSON document in step 5 instead of the expected XML document. As a result, the Vault Server would parse a JSON document with Go‚Äôs XML parser. Because the XML parser is very lenient and parses anything that looks like XML in between lots of other ‚Äúgarbage‚Äù data, this was sufficient for a full authentication bypass when combined with partial control of the JSON response.</p><p>Let‚Äôs look at three different behaviors that make parsing files with the wrong Go parser possible and build a polyglot that can be parsed with Go‚Äôs JSON, XML, and YAML parsers and return a different result for each.</p><p>By default, the JSON, XML, and YAML parsers don‚Äôt prevent unknown fields‚Äîproperties in the incoming data that don‚Äôt match any fields in the target struct.</p><p>Of the three parsers, only the XML parser accepts leading garbage data.</p><p>Again, only the XML parser accepts arbitrary trailing garbage data.</p><p>The exception is using the parsers‚Äô Decoder API with streaming data, in which case the JSON parser accepts garbage trailing data. This an <a href=\"https://github.com/golang/go/issues/36225\">open issue</a> for which a fix is not planned.</p><p>How can we combine all the behaviors we‚Äôve seen so far that build a polyglot that:</p><ul><li>Can be parsed by Go‚Äôs JSON, XML, and YAML parsers</li><li>Returns a different result for each</li></ul><p>A very useful piece of information is that JSON is a subset of YAML:</p><blockquote><p>Every JSON file is also a valid YAML file</p></blockquote><p>With this in mind, we can build the following polyglot:</p><p>The JSON parser can parse the polyglot because the input is valid JSON, it ignores unknown keys, and it allows duplicate keys. It takes the  value because its field matching is case-insensitive and it takes the value of the last match.</p><p>The YAML parser can parse the polyglot because the input is valid JSON (and every JSON file is also a valid YAML file), and it ignores unknown keys. It takes the  value because, contrary to the JSON parser, it does exact field name matches.</p><p>Finally, the XML parser can parse the polyglot because it ignores all surrounding data and just looks for XML-looking data, which, in this polyglot, we hid in a JSON value. As a result, it takes .</p><p>The polyglot we‚Äôve constructed is a powerful starting payload when exploiting these data format confusion attacks similar to the HashiCorp Vault bypass we explored above (CVE-2020-16250).</p><p>How can we minimize these risks and make JSON parsing more strict? We‚Äôd like to:</p><ul><li>Prevent parsing of  in JSON, XML, and YAML</li><li>Prevent parsing of  in JSON and XML</li><li>Prevent <strong>case insensitive key matches</strong> in JSON (this one is especially important!)</li><li>Prevent  in XML</li><li>Prevent  in JSON and XML</li></ul><p>Unfortunately, JSON only offers one option to make its parsing stricter: <a href=\"https://pkg.go.dev/encoding/json#Decoder.DisallowUnknownFields\"></a>. As the name implies, this option disallows unknown fields in the input JSON. YAML supports the same functionality with the  function, and while there was a <a href=\"https://github.com/golang/go/issues/30301\">proposal</a> to implement the same for XML, it was rejected.</p><p>To prevent the remaining insecure defaults, we must create a custom ‚Äúhacky‚Äù solution. The next code block shows the  function, an attempt to make JSON parsing stricter, which has several limitations:</p><ol><li>: It requires parsing JSON input twice, making it significantly slower.</li><li>: Some edge cases remain undetected, as detailed in the function comments.</li><li>: Since these security measures aren‚Äôt built into libraries as secure defaults or configurable options, widespread adoption is unlikely.</li></ol><p>Still, if you detect a vulnerability in your codebase, perhaps this imperfect solution can help you plug a hole while you find a more permanent solution.</p><figure><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></figure><p>To be widely adopted and solve the problem at a large scale, this functionality needs to be implemented at the library level and enabled by default. This is where <a href=\"https://github.com/golang/go/issues/71497\">JSON v2</a> comes in. It is currently only a proposal, but a lot of work has gone into it already, and it will hopefully be released soon. It improves on JSON v1 in many ways, including:</p><ul><li>Disallowing duplicate names: ‚Äú(‚Ä¶) in v2 a JSON object with duplicate names results in an error. The <code>jsontext.AllowDuplicateNames</code> option controls this behavior difference.‚Äù</li><li>Doing case-sensitive matching: ‚Äú(‚Ä¶) v2 matches fields using an exact, case-sensitive match. The <code>MatchCaseInsensitiveNames</code> and <code>jsonv1.MatchCaseSensitiveDelimiter</code> options control this behavior difference.‚Äù</li><li>It includes a  option, even though it is not enable by default (equivalent to ).</li><li>It includes a  function to process data from an , verifying that an EOF is found, disallowing trailing garbage data.</li></ul><p>While this proposal addresses many of the issues discussed in this blog post, these challenges will persist within the Go ecosystem as widespread adoption takes time. The proposal needs formal acceptance, after which developers must integrate it into all existing JSON-parsing Go code. Until then, these vulnerabilities will continue to pose risks.</p><h2>Key takeaways for developers</h2><ol><li><p><strong>Implement strict parsing by default</strong>. Use  for JSON,  for YAML. Unfortunately, this is all you can do directly with the Go parser APIs.</p></li><li><p><strong>Maintain consistency across boundaries</strong>. When input in processed in multiple services, ensure consistent parsing behavior by always using the same parser or implement additional validation layers, such as the  function shown above.</p></li><li><p>. Keep an eye on the development of Go‚Äôs <a href=\"https://github.com/golang/go/issues/71497\">JSON v2</a> library, which addresses many of these issues with safer defaults for JSON.</p></li><li><p>. Use the Semgrep rules we‚Äôve provided to detect a few vulnerable patterns in your codebase, particularly the misuse of the  tag and  fields. Try them with <code>semgrep -c r/trailofbits.go.unmarshal-tag-is-dash</code> and <code>semgrep -c r/trailofbits.go.unmarshal-tag-is-omitempty</code>!</p></li></ol><p>While we‚Äôve provided mitigations and detection strategies, the long-term solution requires fundamental changes to how these parsers operate. Until parser libraries adopt secure defaults, developers must remain vigilant.</p>","contentLength":17871,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1lgwhiw/unexpected_security_footguns_in_gos_parsers/"},{"title":"This Week in Plasma: Plasma 6.4 has arrived!","url":"https://blogs.kde.org/2025/06/21/this-week-in-plasma-plasma-6.4-has-arrived/","date":1750511176,"author":"/u/diegodamohill","guid":164305,"unread":true,"content":"<p>Welcome to a new issue of </p><p>Every week we cover the highlights of what‚Äôs happening in the world of KDE Plasma and its associated apps like Discover, System Monitor, and more.</p><p>This week we released <a href=\"https://kde.org/announcements/plasma/6/6.4.0/\">Plasma 6.4</a>! And so far it‚Äôs been getting a really positive reception. The bug reports bear this out; most of the real actual bugs reported against 6.4.0 are either pre-existing issues or minor regressions, many of which we‚Äôve already fixed in time for 6.4.1 coming next Tuesday.</p><p>Discover‚Äôs list views are now properly navigable with the keyboard. (Christoph Wolk, <a href=\"https://bugs.kde.org/show_bug.cgi?id=505551\">link</a>)</p><p>Improved the text readability in some of the list items in KRunner and Discover when the list items are pressed or clicked. (Nate Graham, <a href=\"https://invent.kde.org/plasma/milou/-/merge_requests/90\">link 1</a> and <a href=\"https://invent.kde.org/plasma/discover/-/merge_requests/1117\">link 2</a>)</p><p>Hovering over list items on System Settings‚Äô User Feedback page no longer makes inscrutable icons appear. (Nate Graham, <a href=\"https://bugs.kde.org/show_bug.cgi?id=505761\">link</a>)</p><p>Improved the readability of graph axis labels throughout Plasma so they meet the WCAG AA standard. (Nate Graham, <a href=\"https://invent.kde.org/plasma/libksysguard/-/merge_requests/430\">link</a>)</p><p>Plasma‚Äôs Activity manager service now only stores the last 4 months‚Äô worth of history by default, rather than storing all history ever and never pruning it. Setting a limit here makes the data more relevant and prevents performance problems caused by endlessly-growing databases. (Nate Graham, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500180\">link</a>)</p><p>Made further UI improvements to the Emoji Selector app: now the window is never so small that the sidebar list becomes scrollable, and the button to expand and collapse the sidebar is located on the header, rather than inline. (Oliver Beard, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/3072\">link</a>)</p><p>Removed the vertical line between the date and time on horizontal arrangements of the Digital Clock widget, since it proved unpopular, and people who want it can get it themselves by using a custom date format anyway. (Owen Ross, <a href=\"https://invent.kde.org/plasma/plasma-workspace/-/merge_requests/5600\">link</a>)</p><p>On System Settings‚Äô Shortcuts page, the ‚ÄúAdd New‚Äù button is now located on the top toolbar rather than taking up unnecessary space above the list view. (Jakob Petsovits, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/3063\">link</a>)</p><p>Reduced the minimum size of Custom Tiling tiles, so that you can have smaller ones on particularly large screens like ultra-wides. (Tyler Slabinski, <a href=\"https://invent.kde.org/plasma/kwin/-/merge_requests/7780\">link</a>)</p><p>The Networks widget‚Äôs captive portal banner now uses the inline/header styling, reducing the frames-within-frames effect. (Kai Uwe Broulik, <a href=\"https://invent.kde.org/plasma/plasma-nm/-/merge_requests/445\">link</a>)</p><p>Removed the NOAA Weather Picture Of The Day wallpaper plugin, because unfortunately the source data changed in a way that makes it no longer consistently suitable for being displayed on the desktop. (Kat Pavl≈Ø, <a href=\"https://bugs.kde.org/show_bug.cgi?id=505425\">link</a>)</p><p>Fixed a bug that could sometimes cause keyboard shortcuts to get lost on certain distros when performing system upgrades. (Vlad Zahorodnii, <a href=\"https://invent.kde.org/plasma/kglobalacceld/-/merge_requests/72\">link</a>)</p><p>Fixed a regression that caused KRunner‚Äôs faded completion text to sometimes overflow from the window. (Nate Graham, <a href=\"https://bugs.kde.org/show_bug.cgi?id=505698\">link</a>)</p><p>Fixed a small visual regression in KWin‚Äôs ‚ÄúSlide Back‚Äù effect. (Blazer Silving, <a href=\"https://bugs.kde.org/show_bug.cgi?id=503964\">link</a>)</p><p>Fixed several issues in the Folder View widget that caused selecting or opening items to not work when using certain non-default view settings, or when the view was scrollable, or when using a touchscreen. (Christoph Wolk, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/3075\">link</a>)</p><p>Fixed a bug in the + clipboard popup that made it sometimes fail to pre-select the top-most item. (Akseli Lahtinen, <a href=\"https://bugs.kde.org/show_bug.cgi?id=505493\">link</a>)</p><p>The Clipboard settings window‚Äôs shortcuts page no longer shows columns for local shortcuts that you can confusingly set and have them do nothing, because the clipboard is global in scope. (Akseli Lahtinen, <a href=\"https://bugs.kde.org/show_bug.cgi?id=501632\">link</a>)</p><p>Fixed the Earth Science Picture of The Day wallpaper plugin after the source data changed its formatting again. (Kat Pavl≈Ø, <a href=\"https://bugs.kde.org/show_bug.cgi?id=505430\">link</a>)</p><p>Made a few fixes to the ‚ÄúMissing Backends‚Äù section of Discover‚Äôs settings window that prevented it from working quite right. (Carl Schwan, <a href=\"https://invent.kde.org/plasma/discover/-/merge_requests/1119\">link</a>)</p><p>Fixed a bug that prevented direct scan-out (and its attendant performance benefits) from activating on rotated screens. (Vlad Zahorodnii, <a href=\"https://invent.kde.org/plasma/kwin/-/merge_requests/7765\">link</a>)</p><p>Fixed a bug that could cause the system to lock or suspend more quickly than intended after an app that was blocking those activities stops doing so. (Akseli Lahtinen. <a href=\"https://bugs.kde.org/show_bug.cgi?id=504553\">link</a>)</p><p>Installing a new wallpaper plugin no longer causes the plugin list combobox to become blank. (Nate Graham, <a href=\"https://bugs.kde.org/show_bug.cgi?id=501586\">link</a>)</p><p>Fixed a regression that caused System Settings‚Äô sidebar list items to display hover tooltips when they weren‚Äôt needed. (Nate Graham, <a href=\"https://invent.kde.org/frameworks/qqc2-desktop-style/-/merge_requests/463\">link</a>)</p><p>KDE has become important in the world, and your time and contributions have helped us get there. As we grow, we need your support to keep KDE sustainable.</p><p>You can help KDE by becoming an active community member and <a href=\"https://community.kde.org/Get_Involved\">getting involved</a> somehow. Each contributor makes a huge difference in KDE ‚Äî you are not a number or a cog in a machine!</p><p>You don‚Äôt have to be a programmer, either. Many other opportunities exist:</p><p>You can also help us by <a href=\"https://kde.org/donate\">making a donation!</a> Any monetary contribution ‚Äî however small ‚Äî will help us cover operational costs, salaries, travel expenses for contributors, and in general just keep KDE bringing Free Software to the world.</p><p>Enter your email address to follow this blog and receive notifications of new posts by email.</p>","contentLength":4968,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1lgw4u3/this_week_in_plasma_plasma_64_has_arrived/"},{"title":"Happy 20th birthday to MySQL's \"Triggers not executed following FK updates/deletes\" bug!","url":"https://bugs.mysql.com/bug.php?id=11472","date":1750509028,"author":"/u/balukin","guid":164217,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lgvfvb/happy_20th_birthday_to_mysqls_triggers_not/"},{"title":"My first Go module","url":"https://www.reddit.com/r/golang/comments/1lgv5by/my_first_go_module/","date":1750508047,"author":"/u/Ok_Gold_8124","guid":164219,"unread":true,"content":"<p>Hi everyone, I'm a newbie in programming. I'm really interested in software development. I've been learning about programming using Go as the tool. Recently I'm trying to play and reinventing the wheel about middleware chaining. Today I just pushed my repo to github.</p><p>This is the link to my project: <a href=\"https://github.com/lutffmn/checkpoint\">Checkpoint</a> I would be very thankful for every feedback, please check it and leave some suggestion, critics, or any feedback.</p><p>Also please suggest me what kind of project should I working on next to be my portofolios. Thank you everyone.</p>","contentLength":533,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[P] Qwen3 implemented from scratch in PyTorch","url":"https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/11_qwen3","date":1750506428,"author":"/u/seraschka","guid":164269,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/MachineLearning/comments/1lguoax/p_qwen3_implemented_from_scratch_in_pytorch/"},{"title":"Scaling My Kubernetes Lab: Proxmox, Terraform & Ansible - Need Advice!","url":"https://www.reddit.com/r/kubernetes/comments/1lgtova/scaling_my_kubernetes_lab_proxmox_terraform/","date":1750502814,"author":"/u/rached2023","guid":164334,"unread":true,"content":"<p>I've built a pretty cool Kubernetes cluster lab setup:</p><ul><li> 3 masters, 2 workers, HA configured with Ansible config.</li><li> 6 VMs running on KVM/QEMU.</li><li> Integrated with Falco, Grafana, Prometheus, Trivy, and more.</li></ul><p>The problem? I've run out of disk space! My current PC only has one slot, so I'm forced to get a new, larger drive.</p><p>This means I'm considering <strong>rebuilding the entire environment from scratch on Proxmox</strong>, using Terraform for VM creation and Ansible for configuration. <strong>What do you guys think of this plan?</strong></p><p><strong>Here's where I need your collective wisdom:</strong></p><ol><li> Roughly how much time do you think it would take to recreate this whole setup, considering I'll be using Terraform for VMs and Ansible for Kubernetes config?</li><li> What are your recommendations for memory and disk space for each VM (masters and workers) to ensure good performance for a lab environment like this?</li><li>Any other tips, best practices, or \"gotchas\" I should be aware of when moving to Proxmox/Terraform for this kind of K8s lab?</li></ol><p>Thanks in advance for your insights!</p>","contentLength":1010,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Writing a basic Linux device driver when you know nothing about Linux drivers or USB","url":"https://crescentro.se/posts/writing-drivers/","date":1750501393,"author":"/u/i542","guid":164189,"unread":true,"content":"<p>A couple of months ago I bought the <a href=\"https://nanoleaf.me/en-EU/products/pegboard-desk-dock/?size=1\">Nanoleaf Pegboard Desk Dock</a>, the latest and greatest in USB-hub-with-RGB-LEDs-and-hooks-for-gadgets technology. This invention unfortunately only supports the  operating systems of Windows and macOS, which necessitated the development of a Linux driver.</p><p>Over the past few posts I‚Äôve set up a <a href=\"https://crescentro.se/posts/windows-vm-nixos/\">Windows VM with USB passthrough</a>, and attempted to <a href=\"https://crescentro.se/posts/wireshark-usb/\">reverse-engineer the official drivers</a>,  As I was doing that, I also thought I‚Äôd message the vendor and ask them if they could share any specifications or docs regarding their protocol. To my surprise, Nanoleaf tech support responded to me within 4 hours, with a full description of the protocol that‚Äôs used both by the Desk Dock as well as their RGB strips. The docs mostly confirmed what I had already discovered independently, but there were a couple of other minor features as well (like power and brightness management) that I did not know about, which was helpful.</p><p>Today, we‚Äôre going to take a crack at writing a driver based on the (reverse-engineered) protocol, while also keeping <a href=\"https://nanoleaf.atlassian.net/wiki/spaces/nlapid/pages/2615574530/Nanoleaf+USB+Lightstrip+Communication+Protocol\">the official documentation</a> at hand. One small problem, though: I‚Äôve never written a Linux device driver before, nor interacted with any USB device as anything else but a user.</p><p>Most Linux distros ship with <a href=\"https://www.man7.org/linux/man-pages/man8/lsusb.8.html\"></a>, a simple utility that will enumerate all USB devices connected to the system. Since I had no clue where to start from, I figured I might as well run this to see if the device appears in the listing.</p><pre><code></code></pre><p>Well, good news, it‚Äôs definitely there. But, how can the kernel know that what I have plugged in is the ‚ÄúNanoleaf Pegboard Desk Dock‚Äù? The kernel (presumably) has no knowledge of this device‚Äôs existence, yet the second I plug it in to my computer it receives power, turns on and gets identified by the kernel.</p><p>As it turns out, we actually already have a driver! It‚Äôs just a very stupid one. If we run  in verbose mode and request the information just for this specific device, we will get a lot more details about it:</p><p>This is a  of information, so we need to take a quick USB class.</p><p>The USB spec is long, complicated and mainly aimed at low-level implementations (think kernel developers, device vendors, and so on). You can, of course, still read it if you enjoy being bored. But, thankfully, a kind soul collected the good parts into <a href=\"https://www.beyondlogic.org/usbnutshell/usb1.shtml\">USB in a NutShell</a>.</p><p>To summarize the summary, a USB device can have multiple , which usually explain the power requirements for the device. Most devices will have just one.</p><p>Each of those configurations can have multiple . So for example, a camera might serve as a file storage device as well as a webcam.</p><p>Finally, each interface can have multiple , whcih describe how the data is transferred. Perhaps the camera has an ‚Äúisochronous‚Äù (continuous) transfer for a webcam feed, and a ‚Äúbulk‚Äù transfer for moving image files over.</p><p>Going back to our device, we can see that it exposes one interface, which is a . HIDs are a class of USB devices that covers things like keyboards, mice or gamepads, and each of those categories is a separate . The kernel contains a generic driver for USB HIDs - <a href=\"https://github.com/torvalds/linux/blob/master/drivers/hid/usbhid/hid-core.c\">here it is</a> in all of its C glory.</p><p>This is why the kernel developers do not need to write specific drivers for each individual keyboard and mouse on the market. Vendors will label their device with one of the well-known HID sub-classes, then use a common protocol to implement the functionality.</p><p>Unfortunately there‚Äôs no HID specification for an RGB LED‚Ä¶ thing (well, there‚Äôs an ‚ÄúLED‚Äù specification, but it‚Äôs mainly for things like status LEDs, not color LEDs) so our device is just a plain old generic HID with an interface sub-class of . This means that the kernel recognizes it and powers it correctly, but it doesn‚Äôt really know what to do with it, so it just lets it sit there.</p><p>There are two options that we have at this point:</p><ol><li>We could write a kernel driver that follows the <a href=\"https://docs.kernel.org/leds/leds-class.html\">kernel standard</a> and exposes each individual LED as 3 devices (one per color) under . Interacting with the kernel devs sounds scary (yes I realize I‚Äôm a grown-ass adult man), but even if it wasn‚Äôt, I question the utility of trying to merge drivers for a very niche product into the kernel. Also,  feels like it‚Äôs intended for status LEDs and not  anyway.</li><li>We could write a userspace driver through <a href=\"https://github.com/libusb/libusb\">libusb</a>, thus defining our own way of controlling LEDs and reducing the quality bar from ‚ÄúLinus Torvalds might send you a strongly worded letter if you fuck up‚Äù to ‚Äúfuck it, we ball‚Äù.</li></ol><p>Given that I have no idea what I am doing, I‚Äôm gonna go for option 2, but if one of you brave souls goes for option 1, please let me know and I will print out a photo of you and frame it on my wall.</p><p>To do anything fun on Linux, you need to be . This is also the case when talking to USB devices. You could always run your drivers as , thus sidestepping the problem. But we all know that‚Äôs bad form. And if I am to distribute this driver, most people would expect to run it without privilege escalation.</p><p>Linux generally relies on <a href=\"https://wiki.archlinux.org/title/Udev\"></a> to manage handlers for hardware events. I will spare you the long story this time and just give you the magic incantation: to make your device accessible to users, you need to create a file at  <code>/etc/udev/rules.d/70-pegboard.rules</code> with the following contents:</p><pre><code></code></pre><p>where  and  are the vendor and product IDs you got from , and  is the spell that grants the currently active user permissions to manage the device. Then, unplug your device and plug it back in.</p><p>Okay, enough yapping. Let‚Äôs start with a basic Rust binary and immediately add the <a href=\"https://crates.io/crates/rusb\"></a> crate, which will serve as a binding to .</p><pre data-lang=\"shell\"><code data-lang=\"shell\"></code></pre><p>To get going, we can try to get a handle on the device and get basic information about it, just like . This is explained pretty well in the crate readme, so I will not dwell on it too much. We‚Äôll need a , which gives us a handy  method that we can use to get a handle to a device.</p><pre data-lang=\"rust\"><code data-lang=\"rust\"></code></pre><pre><code></code></pre><p>Now that we have access to the device, we want to write a simple payload to it. For that, we first need to claim an interface. Recall that interfaces are essentially capabilities of the device, and through  we learned that we only have one interface with the ID () of . Thankfully, there‚Äôs an obvious  method on a .</p><pre data-lang=\"rust\"><code data-lang=\"rust\"></code></pre><pre><code></code></pre><p>So, what you just experienced is the joy of  error messages. This message, at 4 characters, is in fact pretty generous - you might be greeted with a message that only says , and good luck debugging that. In general,  means that something is already holding the device open, so you cannot do anything with it. However, you won‚Äôt actually be told what is holding it open.</p><p>The secret is that the device is, of course, being held open by the kernel. This is the generic driver I talked about earlier. And the secret solution is to release the kernel driver, if it is currently active on the device.</p><p>This requires you to have write access to the device, so if you did not do the  song and dance from earlier in this article, prepare to prefix all future invocations of your driver with .</p><pre data-lang=\"rust\"><code data-lang=\"rust\"></code></pre><p>Note that the kernel driver won‚Äôt be reattached automatically, so you might want to call <code>device.attach_kernel_driver(INTERFACE)</code> if, for some reason, you need it back.</p><h2>Sending data to the device</h2><p>Surely,  we are ready to write out some bytes to a device?</p><p>Well, almost! If we try to naively start typing out something like , the IDE will helpfully suggest three options: <a href=\"https://docs.rs/rusb/latest/rusb/struct.DeviceHandle.html#method.write_bulk\"></a>, <a href=\"https://docs.rs/rusb/latest/rusb/struct.DeviceHandle.html#method.write_control\"></a> and <a href=\"https://docs.rs/rusb/latest/rusb/struct.DeviceHandle.html#method.write_interrupt\"></a>. This corresponds to three out of four possible types of endpoints that the USB standard supports. Once again, <a href=\"https://www.beyondlogic.org/usbnutshell/usb4.shtml\">USB in a NutShell</a> comes in clutch with an explanation of what each of the endpoint types mean. Thankfully, we can mostly skip over the implementation details, as we can once again refer to the  readout from earlier:</p><pre><code></code></pre><p>In USB parlance,  is always something that the device sends to the host, and  is always something that the host sends to the device. Basically, since this interface has two endpoints, and only one of them is an  endpoint, it‚Äôs safe to assume we‚Äôre looking to  on endpoint . The peculiarities of Interrupt endpoints will absolutely come back to bite us in a couple of minutes, but for now we can keep them out of sight and out of mind.</p><p>For testing purposes, I want to make the pegboard show a solid red color. According to my earlier investigation, this means that I need to send , followed by 64 repeats of , to an endpoint at . In addition,  only exposes the blocking API of , so we will also need to define a timeout after which  will give up and error out.</p><pre data-lang=\"rust\"><code data-lang=\"rust\"></code></pre><pre><code></code></pre><p>And‚Ä¶ just like that, the pegboard now shows a solid red color! We didn‚Äôt need to worry about manually splitting packets or any of the underlying implementation, just open up a pipe and write to it! It‚Äôs that easy.</p><p>Let‚Äôs run it again to make sure it was not a fluke!</p><h2>So, about those interrupts‚Ä¶</h2><p>Yeah, so if you happen to be following along, and you ran the same binary twice, you‚Äôll notice that the firmware of the pegboard crashes unceremoniously, and shortly after reverts to its default animation. And if I go back to the original packet capture - or the official docs - it‚Äôs pretty obvious why: the device sends us back a response, but we never read it.</p><p>It turns out that ‚Äúinterrupts‚Äù are named as such for a reason, and we should probably handle them as they come in. However, the USB spec defines that the  must poll for interrupts. A device cannot interrupt the host by itself.</p><p>For our simple ‚Äúdriver‚Äù, this means we want to poll the device right after we write to it. Thankfully,  gives us a  method, and we have already sneakily defined the  constant. Let‚Äôs do just that:</p><pre data-lang=\"rust\"><code data-lang=\"rust\"></code></pre><p>Running this, we see that the contents of  are , which corresponds to  I got from the research. And since we clear the interrupt buffer every time now, we can run this binary many times to define a single solid color on the device. Neat!</p><p>Of course, this is‚Ä¶ not really what you want. The device may issue more interrupts. For example, there‚Äôs a single button on the desk dock, which can be clicked, double-clicked or long-clicked, and each of those will issue a different interrupt. So what we  want is a background task of sort that will actively poll the device for interrupts and process them as they come in.</p><p>This is where you can get wild with async Rust, , channels, and other fun stuff. That would certainly be the  to do it in an actual, serious driver. But to avoid getting into complexities of async Rust, let‚Äôs keep it vanilla and use <a href=\"https://doc.rust-lang.org/std/thread/fn.scope.html\"></a>.</p><p>We‚Äôll also adjust the timeout for reading interrupts to be 1 millisecond, as requested by the device (the  value in the  readout). This doesn‚Äôt mean we will get an interrupt every millisecond, just that the device  send one at that rate. If the device sends nothing (i.e., we get  ), we will just continue with the loop.</p><p>Put together, that might look something like this:</p><pre data-lang=\"rust\"><code data-lang=\"rust\"></code></pre><pre><code></code></pre><p>This‚Ä¶ works! Of course, we send no more color frames to the device, so we won‚Äôt get any more interrupts, but we now have two threads, one which we can use to change the colors shown, and another which we can use to read the interrupts.</p><p>There are some quirks with this device: it seems to require a steady stream of color frames, otherwise it reverts to ‚Äúoffline mode‚Äù as it does not receive any new frames from the host, and the first frame‚Äôs brightness is significantly lower than the brightness of future frames. Not to mention that, despite what the official protocol documentation would have you believe, the colors seem to be in GRB instead of RGB format, and if you make the device , it will just hard-reset after a couple of seconds. That is, I suppose, a part of the joy of coding.</p><p>But this small proof of concept shows that writing simple device drivers is not all that hard, and that 50 lines of code can bring you quite far. Over the next few weeks I hope to polish up my proof of concept, make a small GUI for it, pack it up and share it with the two other Linux users who own this dumb thing. And I‚Äôm happy to have learned the basics of reverse-engineering a simple USB device driver, and using that as a foundation for writing my own. Even if I could have just asked for the spec earlier and not fussed with it.</p>","contentLength":12105,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1lgtc7v/writing_a_basic_linux_device_driver_when_you_know/"},{"title":"Please review my project (a simple Todo App)","url":"https://github.com/Ashind-byte/Task_Manager","date":1750498102,"author":"/u/Loud_Staff5065","guid":164271,"unread":true,"content":"<p>Please dont hate me for using an ORM(spolier). I wanted to get better at folder structure,naming conventions and other code refactoring. Suggestions needed</p>","contentLength":155,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1lgsjlj/please_review_my_project_a_simple_todo_app/"},{"title":"Longhorn starts before coredns","url":"https://www.reddit.com/r/kubernetes/comments/1lgrzlc/longhorn_starts_before_coredns/","date":1750495756,"author":"/u/G4rp","guid":164161,"unread":true,"content":"<p>I have a two-node k3s cluster for home lab/learning purposes that I shut down and start up as needed.</p><p>Despite developing a complex shutdown/startup logic to avoid PVC corruption, I am still facing significant challenges when starting the cluster.</p><p>I recently discovered that Longhorn takes a long time to start because it starts before coredns is ready, which causes a lot of CrashLoopBackOff errors and delays the start-up of Longhorn.</p><p>Has anyone else faced this issue and found a way to fix it?</p>","contentLength":492,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"üêô Tako ‚Äì Yet another Async Web Framework in Rust (Early Phase ‚Äì Feedback Welcome)","url":"https://www.reddit.com/r/rust/comments/1lgrjrf/tako_yet_another_async_web_framework_in_rust/","date":1750493888,"author":"/u/danielboros90","guid":164188,"unread":true,"content":"<p>I needed a new challenge, so I built <a href=\"https://github.com/rust-dd/tako\"></a> ‚Äî a lightweight, async web framework in Rust.</p><p>The idea came from wanting something routing-focused and ergonomic, without too much magic. Axum was a big inspiration, but I wanted to go a different way ‚Äî keep things explicit, composable, and easy to reason about.</p><ul><li>basic routing with  / </li><li>extractors for headers, path/query/body</li><li>middleware (sync + async)</li></ul><p>I'd love to hear your thoughts:</p><ul><li>What would  expect from a minimal async web framework in Rust?</li><li>What features feel essential? What could be left out?</li><li>Where do you feel other frameworks overcomplicate things?</li></ul><p>Thanks in advance for any feedback, ideas, or just a quick glance. My goal is to make Tako a useful, open-source crate for people eventually</p>","contentLength":732,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple sued by shareholders for allegedly overstating AI progress","url":"https://www.reuters.com/sustainability/boards-policy-regulation/apple-sued-by-shareholders-over-ai-disclosures-2025-06-20/","date":1750493022,"author":"/u/F0urLeafCl0ver","guid":164114,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1lgrc02/apple_sued_by_shareholders_for_allegedly/"},{"title":"AI Models score ZERO on hard category problems on LiveCodeBench Pro..","url":"https://analyticsindiamag.com/global-tech/ai-models-from-google-openai-anthropic-solve-0-of-hard-coding-problems/","date":1750492497,"author":"/u/Ok-Elevator5091","guid":164270,"unread":true,"content":"<p>If you‚Äôve heard the phrase ‚Äòcoding is dead‚Äô for a mind-numbingly high number of times, take a deep breath and pause. A new benchmark from researchers across notable universities in the United States and Canada has sparked a twist in the tale.&nbsp;</p><p>It turns out that AI is far from solving some of the most complex coding problems today.&nbsp;</p><p>A <a href=\"https://arxiv.org/abs/2506.11928\">study</a> by New York University, Princeton University, the University of California, San Diego, McGill University, and others indicates a significant gap between the coding capabilities of present-day LLMs and elite human intelligence.&nbsp;</p><h2>LLMs Struggle to Use Novel Insights for Problem Solving</h2><p>The researchers began by stating the shortcomings of the benchmarks available today. For instance, the LiveCodeBench evaluation suffers from ‚Äúinconsistent environments, weak test cases vulnerable to false positives, unbalanced difficulty distributions, and the inability to isolate the effects of search contamination‚Äù.&nbsp;</p><p>They added that other benchmarks, like SWE-Bench, test the models on code maintenance rather than algorithmic design.&nbsp;</p><p>Other benchmarks, like CodeELO, do introduce competitive programming problems. Still, their reliance on static and archaic issues makes it difficult to check if models are retrieving solutions based on reasoning or memory.&nbsp;</p><p>To alleviate such concerns, the researchers introduced LiveCodeBench Pro, an evaluation benchmark for coding designed to avoid data contamination. The models were evaluated with 584 problems sourced directly from ‚Äòworld-class contests‚Äô before solutions or discussions were available.&nbsp;</p><p>Additionally, a team of Olympiad medalists annotates each problem in the benchmark to categorise it based on its difficulty level and nature‚Äîwhether it is knowledge-heavy, observation-heavy, or logic-heavy.&nbsp;</p><p>Sadly, none of these models solved a single problem in the ‚ÄòHard‚Äô category. Even the best and latest models from OpenAI, Google, Anthropic, and others that were evaluated scored 0%.&nbsp;</p><p>In the ‚ÄòMedium‚Äô difficulty category, OpenAI‚Äôs o4-mini-high model scored the highest at 53.5%.&nbsp;</p><p>AI models performed better on knowledge-heavy problems‚Äîones that can be solved by stitching well-known templates, as the requisite problem-solving patterns appear ‚Äòverbatim in training data‚Äô. Even on logic-heavy problems, which require a patterned way of thinking, these models performed well.&nbsp;</p><p>However, they performed poorly on observation-heavy problems, whose solutions hinge on the discovery of novel insights ‚Äî ‚Äúsomething that cannot be retrieved from memorised snippets alone‚Äù.&nbsp;</p><p>When these researchers diagnosed the failure modes of these models, the largest one was where these models committed errors regarding the algorithms. ‚ÄúThese are genuine conceptual slips, instead of surface bugs,‚Äù said the authors.&nbsp;</p><p>‚ÄúLLMs frequently fail even on provided sample inputs, suggesting incomplete utilisation of given information and indicating room for improvement even in simple settings,‚Äù added the authors. They also said that these models show a substantial improvement in overall performance with multiple attempts to solve the problems.&nbsp;</p><p>They concluded that these models solve problems involving the implementation of techniques, frameworks, and patterns but struggle to solve ones involving complex reasoning, nuances, and edge cases.&nbsp;</p><p>‚ÄúDespite claims of surpassing elite humans, a significant gap still remains, particularly in areas demanding novel insights,‚Äù they added.&nbsp;</p><p>For detailed information, comparisons, scores, and evaluation mechanisms, check out the technical report‚Äôs PDF <a href=\"https://arxiv.org/pdf/2506.11928\">here</a>.&nbsp;</p><p>This, however, is one of the many reports that highlight the shortcomings of AI-enabled coding, despite the optimism expressed by several tech leaders worldwide.&nbsp;</p><h2>You Can‚Äôt Code for a Long Time With AI</h2><p>Recently, an Oxford researcher, Toby Ord, <a href=\"https://www.tobyord.com/writing/half-life\">proposed</a> that AI agents might have a ‚Äúhalf-life‚Äù when performing a task.&nbsp;</p><p>This was in relation to <a href=\"https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/\">another research</a> from METR (Model Evaluation &amp; Threat Research), which showed that the capacity of AI agents to handle longer tasks doubled every seven months.&nbsp;</p><p>They measured that the doubling time for an 80% success rate is 213 days, and for 50%, it is 212 days, establishing consistency in their findings.&nbsp;</p><p>When Ord analysed the research, he discovered that, just like radioactive decay, the AI agent‚Äôs success rate followed an exponential decline.&nbsp;</p><p>For instance, if an AI model could complete a one-hour task with 50% success, it only had a 25% chance of successfully completing a two-hour task. This indicates that for 99% reliability, task duration must be reduced by a factor of 70.&nbsp;</p><p>However, Ord observed a time gap between the 50% success rate time horizon and the 80% success rate time horizon.<p>‚ÄúFor the best model (Claude 3.7 Sonnet), it could achieve a 50% success rate on tasks up to 59 minutes vs only 15 minutes if an 80% success rate was required,‚Äù said Ord.</p><p>‚ÄúIf those results generalise to the other models, then we could also see it like this: the task length for an 80% success rate is 1/4 the task length for a 50% success rate. Or in terms of improvement: what is doable with a 50% success rate now is doable with an 80% success rate in 14 months‚Äô time (= 2 doubling times),‚Äù he added.&nbsp;</p></p><p>Although METR indicates that AI agents can tackle longer tasks every 7 months, Ord‚Äôs analysis shows that high-reliability performance still demands significantly shorter task durations.&nbsp;</p><p>This means the timeline for AI to handle complex coding projects remains unclear, despite steady improvements in capability.</p>","contentLength":5586,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1lgr7az/ai_models_score_zero_on_hard_category_problems_on/"},{"title":"BBC threatens legal action against AI startup over content scraping","url":"https://www.theguardian.com/media/2025/jun/20/bbc-threatens-legal-action-against-ai-startup-over-content-scraping","date":1750492184,"author":"/u/F0urLeafCl0ver","guid":164089,"unread":true,"content":"<p>The <a href=\"https://www.theguardian.com/media/bbc\" data-link-name=\"in body link\" data-component=\"auto-linked-tag\">BBC</a> is threatening legal action against Perplexity AI, in the corporation‚Äôs first move to protect its content from being scraped without permission to build artificial intelligence technology.</p><p>The corporation has sent a letter to Aravind Srinivas, the chief executive of the San Francisco-based startup, saying it has gathered evidence that Perplexity‚Äôs model was ‚Äútrained using BBC content‚Äù.</p><p>The letter, first reported by the Financial Times, threatens an injunction against Perplexity unless it stops scraping all BBC content to train its AI models, and deletes any copies of the broadcaster‚Äôs material it holds unless it provides ‚Äúa proposal for financial compensation‚Äù.</p><p>‚ÄúIf we currently drift in the way we are doing now we will be in crisis,‚Äù Davie said, speaking at the Enders conference. ‚ÄúWe need to make quick decisions now around areas like ‚Ä¶ protection of IP. We need to protect our national intellectual property, that is where the value is. What do I need? IP protection; come on, let‚Äôs get on with it.‚Äù</p><p>The industry would like an opt-in regime, forcing AI companies to seek permission and strike licensing deals with copyright holders before they can use the content to train their models.</p><p>In October, Rupert Murdoch‚Äôs Dow Jones, the owner of the Wall Street Journal, <a href=\"https://www.theguardian.com/technology/2024/oct/21/rupert-murdoch-ai-lawsuit-new-york-post-dow-jones\" data-link-name=\"in body link\">filed a lawsuit against Perplexity</a>, accusing it of engaging in a ‚Äúmassive amount of illegal copying‚Äù in a ‚Äúbrazen scheme ‚Ä¶ free-riding on the valuable content the publishers produce‚Äù.</p><p>Perplexity told the FT that the BBC‚Äôs claims were ‚Äúmanipulative and opportunistic‚Äù and that it had a ‚Äúfundamental misunderstanding of technology, the internet and intellectual property law‚Äù.</p><p>Perplexity does not build or train foundation models ‚Äì unlike other companies such as OpenAI, Google and Meta ‚Äì but provides an interface that allows users to choose between them.</p><p>The BBC said that parts of its content had been reproduced verbatim by Perplexity.</p><p>‚ÄúPerplexity‚Äôs tool directly competes with the BBC‚Äôs own services, circumventing the need for users to access those services,‚Äù the corporation said.</p><p>In October, the BBC began registering copyright in its news website in the US, so it is entitled to ‚Äústatutory damages in relation to unauthorised use of these copyright works‚Äù.</p><p>In the UK, original proposals published in a consultation indicated that the government could let AI companies scrape content unless media owners opt out, which the industry said would ‚Äúscrape the value‚Äù out of the ¬£125bn creative industry.</p><figure data-spacefinder-role=\"inline\" data-spacefinder-type=\"model.dotcomrendering.pageElements.NewsletterSignupBlockElement\"><a data-ignore=\"global-link-styling\" href=\"https://www.theguardian.com/media/2025/jun/20/bbc-threatens-legal-action-against-ai-startup-over-content-scraping#EmailSignup-skip-link-13\">skip past newsletter promotion</a><p tabindex=\"0\" aria-label=\"after newsletter promotion\" role=\"note\">after newsletter promotion</p></figure><p>Lisa Nandy, the culture secretary, has since said that the government has no preferred option regarding AI copyright laws in the UK but promised the creative sector that it would not be harmed by legislation.</p><p>‚ÄúWe are a Labour government, and the principle [that] people must be paid for their work is foundational,‚Äù she told a media conference earlier this month. ‚ÄúYou have our word that if it doesn‚Äôt work for the creative industries, it will not work for us.‚Äù</p><p>Publishers including the Financial Times, Axel Springer, Hearst and News Corporation have signed content licensing deals with OpenAI.</p><p>Reuters has struck a deal with Meta, and the parent of the Daily Mail has an agreement with <a href=\"http://prorata.ai\" data-link-name=\"in body link\">ProRata.ai</a>.</p><p>The Guardian has approached Perplexity for comment. The BBC declined to comment beyond the contents of the letter.</p>","contentLength":3423,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1lgr4mk/bbc_threatens_legal_action_against_ai_startup/"},{"title":"Need help in Helm charts for Drools WB and Kie-Server","url":"https://www.reddit.com/r/kubernetes/comments/1lgq8rf/need_help_in_helm_charts_for_drools_wb_and/","date":1750488614,"author":"/u/deep_2k","guid":164216,"unread":true,"content":"<p>I have been trying to run Drools Workbench ( Business Central ) and KIE Server in a conected fashion to work as a BRE. Using the docker images of the \"showcase\" versions was smooth sailing, but facing a major road blocker trying to get it working on Kubernetes using Helm Charts. Have been able to set up the Drools Workbench ( Business Central ), but cannot figure out why the KIE-Server is not linking to the Workbench.</p><p>Under normal circumstances, i should see a kie-server instance listed in the \"\" section found in <strong><em>Menu &gt; Deploy &gt; Execution Servers</em></strong>. But i cannot somehow get it connected.</p><p>Here's the Helm Chart i have been using.</p><p><strong>Can someone help me get kie-server running and connected to workbench.</strong></p>","contentLength":701,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why is Qwen2-0.5B trained on much more data than the larger models? [D]","url":"https://www.reddit.com/r/MachineLearning/comments/1lgp926/why_is_qwen205b_trained_on_much_more_data_than/","date":1750484806,"author":"/u/datashri","guid":164113,"unread":true,"content":"<p>I'm reading through the <a href=\"https://arxiv.org/abs/2407.10671\">Qwen2</a> paper. </p><p>Something escapes my limited comprehension - </p><blockquote><p>... the pre-training data was expanded from 3 trillion tokens in Qwen1.5 (Qwen Team, 2024a) to 7 trillion tokens. An attempt to further relax the quality threshold resulted in a 12 trillion token dataset. However, the model trained on this dataset did not show a significant performance improvement over the 7 trillion token model. It is suspected that increasing the volume of data does not necessarily benefit model pre-training.</p></blockquote><p>So higher quality smaller dataset is better. Got it. </p><blockquote><p>All Qwen2 dense models, excluding Qwen2-0.5B, were pre-trained on this large-scale dataset of over 7 trillion tokens. Qwen2-0.5B were pre-trained using the 12 trillion token dataset.</p></blockquote><p>How is it conceivable to train that tiny model on the humongous but lower quality dataset?? My modest intellect feels borderline abused. </p><p>Appreciate any tips to guide my understanding.</p>","contentLength":931,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Practical Uses for Bitwise Operations","url":"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems","date":1750482019,"author":"/u/WillingnessFun7051","guid":164112,"unread":true,"content":"<h2>Part I: The Foundations of Digital Numeracy<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#part-i-the-foundations-of-digital-numeracy\"></a></h2><h3>Understanding Positional Number Systems<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#understanding-positional-number-systems\"></a></h3><h4>The Core Concept: Base and Positional Value<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#the-core-concept-base-and-positional-value\"></a></h4><p>A number system is a language for writing numbers. These languages use a set of symbols, or digits. Two rules govern these systems: the base and positional notation.</p><p>The , or radix, is the number of unique digits the system uses. This count includes the digit zero.</p><ul><li><p>Our common decimal system is . It uses ten digits (0 through 9).</p></li><li><p>The binary system is . It uses two digits (0 and 1).</p></li></ul><p> means a digit‚Äôs value depends on its location in a number. In the number 555, each '5' has a different value. There is a '5' in the hundreds place, a '5' in the tens place, and a '5' in the ones place. The value of each position is the base raised to a power. This differs from Roman numerals, where 'X' always means ten.</p><h4>Deconstructing Decimal (Base-10): Our Everyday System<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#deconstructing-decimal-base-10-our-everyday-system\"></a></h4><p>The decimal system is the base-10 system we use daily. Each position represents a power of 10. Let's examine the number :</p><blockquote><p>(2√ó10^3)+(0√ó10^2)+(0√ó10^1)+(3√ó10^0)=2000+0+0+3=2003</p></blockquote><p>Understanding this structure is the key to learning other number systems.</p><p>The binary system is the language of modern computers. It is a base-2 system and uses only two digits:  and . These digits are called . In binary, each position represents a power of 2.</p><p>For example, we can convert the binary number 1011‚Äã to decimal:</p><blockquote><p>(1√ó2^3)+(0√ó2^2)+(1√ó2^1)+(1√ó2^0)=8+0+2+1=11</p></blockquote><h4>Introducing Hexadecimal (Base-16): The Programmer's Shorthand<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#introducing-hexadecimal-base-16-the-programmers-shorthand\"></a></h4><p>The hexadecimal system, or \"hex,\" is a  system. Programmers use it to write long binary numbers in a shorter form. It uses 16 symbols: the digits 0 through 9 and the letters A, B, C, D, E, and F. The letters represent the values 10 through 15. Each position in a hex number represents a power of 16.</p><p>For example, let's convert the hex number 1A3 to decimal:</p><blockquote><p>(1√ó16^2)+(10√ó16^1)+(3√ó16^0)=256+160+3=419</p></blockquote><blockquote><p> We use subscripts like 101‚Äã to show the base. We can also use prefixes like  for hexadecimal () and  for binary ().</p></blockquote><p>Why do computers use binary? The answer lies in their hardware.</p><p>A computer contains billions of tiny electronic switches called transistors. Each switch has only two possible states:  or . The binary system, with its two digits  and , perfectly matches this physical design. This makes binary the natural language for computers.</p><p>The main problem with binary is that the numbers get very long. A single byte of data is eight bits long, such as . A memory address can be 64 bits long. Reading or typing these long strings of 0s and 1s often leads to mistakes.</p><p>Hexadecimal solves this problem. It works as a shorthand for binary because of a simple relationship: 16=24. This means a group of four binary digits, called a , corresponds to exactly one hexadecimal digit.</p><p>For example, the byte  splits into two nibbles:  and .</p><ul><li><p> in binary is 13 in decimal, which is  in hex.</p></li><li><p> in binary is 5 in decimal, which is  in hex.</p></li></ul><p>So, the long binary number  becomes the short hex number .</p><p><em>Binary is the language of the machine. Hexadecimal is the convenient shorthand for the programmer.</em></p><section><div><h2>Stop Scrolling, Start Achieving: Get Actionable Tech &amp; Productivity Insights.</h2><p>Join the inner circle receiving proven tactics for mastering technology, amplifying productivity, and finding deep focus. Delivered straight to your inbox ‚Äì no fluff, just results.</p></div></section><p>This chart helps show the patterns between the systems.</p><table><tbody></tbody></table><h3>Section 2: Core Conversion Techniques<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#section-2-core-conversion-techniques\"></a></h3><h4>Converting from Any Base to Decimal<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#converting-from-any-base-to-decimal\"></a></h4><p>This basic method converts a number from any base to the decimal system.</p><ol><li><p>Find the positional value for each digit. This is the base raised to the power of its position, starting from 0 on the right.</p></li><li><p>Multiply each digit by its positional value.</p></li></ol><blockquote><p><strong>Example (Binary to Decimal):</strong> Convert 1101.12‚Äã to decimal.</p><p>The positions are 3, 2, 1, and 0 for the whole number part, and -1 for the fractional part.</p><p> (1√ó2)+(1√ó2)+(0√ó2)+(1√ó2)+(1√ó2)</p></blockquote><blockquote><p><strong>Example (Hexadecimal to Decimal):</strong> Convert A4E‚Äã to decimal.</p><p>Remember that A=10 and E=14.</p><p> (10√ó16)+(4√ó16)+(14√ó16)</p><p> (10√ó256)+(4√ó16)+(14√ó1)=2560+64+14=2638</p></blockquote><h4>Converting from Decimal to Any Base<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#converting-from-decimal-to-any-base\"></a></h4><p>To convert from decimal to another base, we use a different method with two parts.</p><p><strong>For the Whole Number Part (Repeated Division):</strong></p><ol><li><p>Divide the decimal number by the target base.</p></li><li><p>Write down the remainder. This is a digit for your new number.</p></li><li><p>Take the quotient from the division and repeat the process.</p></li><li><p>Continue until the quotient is 0.</p></li><li><p>Read the remainders in reverse order (bottom to top) to get the final answer.</p></li></ol><p><strong>For the Fractional Part (Repeated Multiplication):</strong></p><ol><li><p>Multiply the decimal fraction by the target base.</p></li><li><p>The whole number part of the result is the first digit of your new fraction.</p></li><li><p>Take the fractional part of the result and repeat the process.</p></li><li><p>Continue until the fraction becomes 0 or you have enough digits.</p></li><li><p>Read the whole numbers in the order you recorded them to get the final answer.</p></li></ol><blockquote><p> Convert 25.625‚Äã to binary.</p><ul></ul><p>Reading in reverse gives 11001‚Äã.</p><ul><li><p>0.625√ó2=1.25 Record the whole number: </p></li><li><p>0.25√ó2=0.5 Record the whole number: </p></li><li><p>0.5√ó2=1.0 Record the whole number: </p></li></ul><p>Reading in order gives .101‚Äã.</p></blockquote><h4>The Binary-Hexadecimal Shortcut: Grouping by Fours<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#the-binary-hexadecimal-shortcut-grouping-by-fours\"></a></h4><p>Programmers use this fast trick often. You can convert between binary and hex without using decimal.</p><ol><li><p>Split the binary number into groups of four bits (nibbles), starting from the decimal point.</p></li><li><p>If the leftmost group has fewer than four bits, add zeros to the front.</p></li><li><p>Convert each 4-bit group to its single hex digit.</p></li></ol><ol><li><p>Convert it to its 4-bit binary equivalent.</p></li><li><p>Combine the binary groups.</p></li></ol><p>A programmer sees  and thinks , which is much simpler.</p><h4>Table 2: Binary-to-Hexadecimal Nibble Conversion<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#table-2-binary-to-hexadecimal-nibble-conversion\"></a></h4><p>This table is the key to using the shortcut.</p><table><tbody><tr></tr></tbody></table><h2>Part II: Advanced Data Representation<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#part-ii-advanced-data-representation\"></a></h2><h3>Section 3: Representing Signed Integers<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#section-3-representing-signed-integers\"></a></h3><h4>The Challenge of Representing Negative Numbers<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#the-challenge-of-representing-negative-numbers\"></a></h4><p>How do you write a negative number with only 0s and 1s? One idea is to use a single bit to represent the sign. For instance, 0 for positive and 1 for negative. This is called . This system has problems. It creates two ways to write zero (+0 and -0). It also complicates the math for computer hardware.</p><p>Modern computers use a system called  to represent positive and negative integers. In this system, the first bit (the most significant bit, or MSB) indicates the sign. A 0 means positive, and a 1 means negative. The MSB also has a negative value. For an 8-bit number, the MSB has a value of .</p><blockquote><p>For example, in an 8-bit system, we calculate the number  like this:</p><p>(‚àí1√ó128)+(1√ó64)+(1√ó32)+(0√ó16)+(0√ó8)+(1√ó4)+(0√ó2)+(0√ó1)</p></blockquote><h4>The Negation Algorithm: Finding the Opposite<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#the-negation-algorithm-finding-the-opposite\"></a></h4><p>Two's complement makes it easy to change a number's sign, like turning 5 into -5.</p><p><strong>The \"Flip and Add One\" Recipe:</strong></p><ol><li><p> all the bits. Change every 0 to a 1, and every 1 to a 0. This is the .</p></li><li><p> to the result. Ignore any extra carry bit at the end.</p></li></ol><blockquote><p> Find the 8-bit two's complement for .</p><ol><li><p>Start with positive 69 in binary: .</p></li><li><p>Invert all the bits: .</p></li><li><p>Add 1: .</p></li></ol><p>So, -69 is stored as .</p></blockquote><p>The main benefit of two's complement is that it simplifies computer math. The computer can use the same hardware circuit for both addition and subtraction. To subtract B from A, the computer calculates <strong>A + (the two's complement of B)</strong>.</p><blockquote><p> Calculate . The computer performs this as .</p><ul><li><p>57 in 8-bit binary is .</p></li><li><p>-28 in 8-bit two's complement is .</p></li></ul><pre><code>  00111001   (57)\n+ 11100100   (-28)\n------------------\n1 00011101   (29)\n</code></pre><p>We ignore the extra carry bit on the left. The 8-bit answer is , which is 29.</p></blockquote><p>This math trick is important for processor design. The part of the processor that performs math is the Arithmetic Logic Unit (ALU). Building separate circuits for addition and subtraction would make the ALU larger and use more power.</p><p>With two's complement, the computer needs only one circuit: an adder. To subtract, the computer uses NOT gates to flip the bits of the second number. Then it uses the adder to add 1 and perform the final addition. A single circuit does both operations, making processors smaller and faster.</p><h3>Section 4: Representing Real Numbers<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#section-4-representing-real-numbers\"></a></h3><h4>The Challenge: Representing Fractions and Scientific Notation<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#the-challenge-representing-fractions-and-scientific-notation\"></a></h4><p>We have discussed whole numbers. What about numbers with fractions, like 3.14, or very large numbers? We need a system that can \"float\" the decimal point.</p><h4>IEEE 754: The Global Standard<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#ieee-754-the-global-standard\"></a></h4><p>The  standard is a universal rulebook for floating-point numbers. It defines how to store them, so all computers calculate them the same way.</p><h4>Anatomy of an IEEE 754 Number<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#anatomy-of-an-ieee-754-number\"></a></h4><p>An IEEE 754 number has three parts, similar to scientific notation: (‚àí1)sign√ó1.fraction√ó2exponent.</p><ul><li><p> This is simple. 0 is for positive, and 1 is for negative.</p></li><li><p><strong>Biased Exponent (8 or 11 bits):</strong> The exponent shows how far to move the decimal point. The standard adds a fixed number, or , to the real exponent. This allows the storage of positive and negative exponents without a separate sign bit. For a 32-bit number, the bias is 127. The computer stores .</p></li><li><p><strong>Mantissa (23 or 52 bits):</strong> This part stores the number's actual digits. In binary scientific notation, a number always starts with . The standard does not store the leading 1. This is the \"hidden bit\" trick, which saves space and adds precision.</p></li></ul><h4>Single-Precision (32-bit) vs. Double-Precision (64-bit)<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#single-precision-32-bit-vs-double-precision-64-bit\"></a></h4><p>There are two common sizes for floating-point numbers:</p><ul><li><p><strong>Single-Precision (float):</strong> A 32-bit number with 1 sign bit, 8 exponent bits, and 23 mantissa bits. It is good for general use.</p></li><li><p><strong>Double-Precision (double):</strong> A 64-bit number with 1 sign bit, 11 exponent bits, and 52 mantissa bits. It stores a wider range of numbers with much higher precision.</p></li></ul><h4>Special Values: Handling Edge Cases<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#special-values-handling-edge-cases\"></a></h4><p>The IEEE 754 standard defines special patterns for unusual values:</p><ul><li><p> An exponent of all zeros and a mantissa of all zeros.</p></li><li><p> An exponent of all ones and a mantissa of all zeros.</p></li><li><p> An exponent of all ones and a non-zero mantissa. This results from invalid operations like 0√∑0.</p></li><li><p> These are very small numbers near zero. The \"hidden bit\" is assumed to be 0 instead of 1. This allows a gradual loss of precision.</p></li></ul><h4>The Trade-off Between Range and Precision<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#the-trade-off-between-range-and-precision\"></a></h4><p>Floating-point numbers are an engineering compromise. The bits are split between the exponent (range) and the mantissa (precision). This allows the representation of an enormous range of values.</p><p>But there is a catch: the precision is not uniform.</p><ul><li><p>For small numbers near zero, the representable values are close together. Precision is high.</p></li><li><p>For huge numbers, the representable values are far apart. The gap between them can be large.</p></li></ul><p>This is why  does not exactly equal  in many programming languages. The numbers 0.1 and 0.2 cannot be represented perfectly in binary. They are rounded to the nearest available floating-point value. The sum of these rounded values is not the same as the rounded value of 0.3. We sacrifice uniform precision to get the massive range needed for science and computing.</p><h2>Part III: Manipulation and Application<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#part-iii-manipulation-and-application\"></a></h2><h3>Section 5: Bitwise Operations<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#section-5-bitwise-operations\"></a></h3><p>Bitwise operations work on numbers at the bit level. They treat the number 13 as the bit string . These operations are fast because they map directly to processor instructions.</p><p>These operations apply Boolean logic to each pair of bits.</p><p><strong>Table 3: Bitwise Operator Truth Tables</strong></p><table><tbody><tr></tr></tbody></table><ul><li><p> Gives a 1 only if both bits are 1.</p><ul><li><em>Main Use (Masking/Clearing):</em> Checks if a specific bit is on or turns a bit off. To check the 3rd bit, you can AND the number with . If the result is not zero, the bit was on.</li></ul></li><li><p> Gives a 1 if either bit is 1.</p><ul><li> Turns a specific bit on. To turn on the 3rd bit, you can OR the number with . This does not change other bits.</li></ul></li><li><p> Gives a 1 only if the bits are different.</p><ul><li> Flips a bit. To flip the 3rd bit, you can XOR your number with .</li></ul></li><li><p> Flips every bit in a single number. This is also called the ones' complement.</p></li></ul><p>Shift operations slide all bits in a number to the left or right.</p><ul><li><p> Slides all bits  places to the left. Zeros fill in on the right. This is a fast way to multiply a number by 2n.</p></li><li><p> Slides all bits  places to the right. This is a fast way to do integer division by 2n. What fills in on the left depends on the type of shift:</p><ul><li><p> Used for signed numbers. It copies the original sign bit to preserve the number's sign.</p></li><li><p> Used for unsigned numbers. It always fills the empty spots with zeros.</p></li></ul></li></ul><h4>Practical Application: Bitmasking<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#practical-application-bitmasking\"></a></h4><p>Bitmasking is a common programming technique. You can use the bits of a single integer to store a set of flags instead of using many separate true/false variables. This saves memory.</p><blockquote><p><strong>Example: File Permissions</strong></p><p>Operating systems use bitmasking for file permissions. Let's say bit 2 is Read, bit 1 is Write, and bit 0 is Execute.</p><ul><li><p> (binary )</p></li><li><p> (binary )</p></li><li><p> (binary )</p></li></ul><p>A file that is readable and writable has permissions <code>READ_PERMISSION | WRITE_PERMISSION</code>, which is  (binary ).</p><ul><li><p><strong>To check for write permission:</strong><code>if (permissions &amp; WRITE_PERMISSION)</code></p></li><li><p><strong>To add execute permission:</strong><code>permissions = permissions | EXECUTE_PERMISSION</code></p></li><li><p><strong>To remove write permission:</strong><code>permissions = permissions &amp; ~WRITE_PERMISSION</code></p></li></ul></blockquote><p>This technique is common in low-level programming where speed and memory are important.</p><h3>Section 6: Number Systems in the Real World<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#section-6-number-systems-in-the-real-world\"></a></h3><h4>Memory, Debugging, and Data Representation<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#memory-debugging-and-data-representation\"></a></h4><ul><li><p> Every byte in a computer's memory has a unique address. These addresses are written in hexadecimal because it is shorter and easier to read than binary. An address like  is easier to read than 64 ones and zeros.</p></li><li><p> Programmers look at \"memory dumps\" to find bugs. These snapshots of memory are displayed in hex for quick scanning.</p></li><li><ul><li><p> An early character set for English. It used 7 or 8 bits, which allowed for only 128 or 256 characters.</p></li><li><p> Unicode is a standard that gives a unique number, or , to every character. UTF-8 is the most popular way to encode Unicode numbers into binary. It uses one byte for ASCII characters and up to four bytes for other characters.</p></li></ul></li></ul><p><strong>Table 4: Common Character Encodings</strong></p><table><tbody><tr></tr><tr><td><code>11100010 10000010 10101100</code></td></tr><tr></tr><tr><td><code>11110000 10011111 10010001 10001101</code></td></tr></tbody></table><h4>Networking: IP Addressing<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#networking-ip-addressing\"></a></h4><ul><li><p> An IPv4 address is a 32-bit number. We write it as four decimal numbers separated by dots, like . Each number is an 8-bit segment called an octet.</p></li><li><p> The world ran out of IPv4 addresses. The new standard is IPv6, which uses 128-bit numbers. They are written as eight groups of four hexadecimal digits, separated by colons, like <code>2001:0db8:85a3:0000:0000:8a2e:0370:7334</code>.</p></li><li><p> A subnet mask tells a router which part of an IP address identifies the network and which part identifies the computer. It uses a bitwise AND operation between the IP address and the mask.</p></li></ul><h4>Web Development: CSS Hex Color Codes<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#web-development-css-hex-color-codes\"></a></h4><p>A color on a website defined as  is a hexadecimal color code. The format is .</p><ul><li><p> is the amount of Green.</p></li></ul><p>Each value is a two-digit hex number from  (none) to  (maximum). For example,  is pure red, and  is white.</p><h4>Hardware: Digital Logic Circuits<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#hardware-digital-logic-circuits\"></a></h4><p>All computer hardware is built from logic gates (AND, OR, NOT gates). These are tiny electronic circuits that perform bitwise operations. A high voltage signal is a , and a low voltage signal is a . When a computer performs math, it is flipping switches according to the rules of logic.</p><h4>Using Python for Number Systems<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#using-python-for-number-systems\"></a></h4><p>Python is a good tool for experimenting with these concepts.</p><ul><li><p>: Converts an integer to a binary string.  gives .</p></li><li><p>: Converts an integer to a hex string.  gives .</p></li><li><p>: Converts a string  in a given base to an integer.  gives .</p></li></ul><p>Python also supports all bitwise operators: , , , , , .</p><pre><code># --- Conversions ---\ndecimal_val = 173\nbinary_str = bin(decimal_val)      # Result: '0b10101101'\nhex_str = hex(decimal_val)          # Result: '0xad'\n\n# Convert back to decimal\nbinary_to_dec = int('10101101', 2) # Result: 173\nhex_to_dec = int('ad', 16)          # Result: 173\n\n# --- Bitwise Operations ---\na = 92  # Binary: 01011100\nb = 101 # Binary: 01100101\n\n# Bitwise AND: checks which bits are 1 in BOTH numbers\nprint(f\"a &amp; b = {a &amp; b}\") # Result: 68 (binary 01000100)\n\n# Bitwise OR: checks which bits are 1 in EITHER number\nprint(f\"a | b = {a | b}\") # Result: 125 (binary 01111101)\n\n# Bitwise XOR: checks which bits are DIFFERENT\nprint(f\"a ^ b = {a ^ b}\") # Result: 57 (binary 00111001)\n\n# Bitwise NOT: flips all the bits of 'a'\nprint(f\"~a = {~a}\") # Result: -93 (due to two's complement)\n\n# Bit Shifts: fast multiplication and division by 2\nprint(f\"a &lt;&lt; 2 = {a &lt;&lt; 2}\") # Result: 368 (92 * 4)\nprint(f\"a &gt;&gt; 2 = {a &gt;&gt; 2}\") # Result: 23 (92 // 4)\n</code></pre><h4>Specialized Python Libraries<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#specialized-python-libraries\"></a></h4><ul><li><p> A library for symbolic math with a module for logic.</p></li><li><p> A library for learning formal logic.</p></li><li><p> A library for representing different kinds of logic.</p></li></ul><h4>Online Calculators and Simulators<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#online-calculators-and-simulators\"></a></h4><ul><li><p><strong>Stanford Introduction to Logic:</strong> This site has a Digital Circuit Builder and a tool for truth tables called Boole.</p></li><li><p> An online tool that solves logic formulas and generates truth tables.</p></li></ul><h4>Number System Conversions<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#number-system-conversions\"></a></h4><ul><li><p> Convert 11011‚Äã to decimal.</p><ul><li> (1√ó16)+(1√ó8)+(0√ó4)+(1√ó2)+(1√ó1)=16+8+2+1=27‚Äã.</li></ul></li><li><p> Convert 452‚Äã to hexadecimal.</p><ul><li> 452√∑16=28 R 4. 28√∑16=1 R 12 (C). 1√∑16=0 R 1. Reading remainders in reverse gives 1C4.</li></ul></li><li><p> Convert DE0‚Äã to binary.</p><ul><li> D = , E = , 0 = . Combining gives 110111100000‚Äã.</li></ul></li></ul><ul><li><p> Find the 8-bit two's complement of .</p><ul><li> Positive 42 is . Invert bits: . Add 1: 11010110‚Äã.</li></ul></li><li><p> Calculate  using 8-bit two's complement.</p><ul><li><p> This is . 35 is . -50 is .</p></li><li><p><code>00100011 + 11001110 = 11110001</code>.</p></li><li><p>The result is negative. To find its magnitude, take its two's complement. Invert () and add 1 (), which is 15. The answer is ‚àí15.</p></li></ul></li></ul><ul><li><p> Given the number 77 (), set the 6th bit.</p><ul><li><p> The mask is , which is .</p></li><li><p><code>01001101 | 01000000 = 01001101</code>. The bit was already set.</p></li></ul></li><li><p> Given the number 77 (), clear the 2nd bit.</p><ul><li><p> The mask is , which is .</p></li><li><p><code>01001101 &amp; 11111011 = 01001001</code>, which is 73.</p></li></ul></li><li><p> How many set bits are in the number 203 ()?</p><ul><li> Using Brian Kernighan's algorithm, the answer is .</li></ul></li></ul><h3>Section 9: Capstone Project Ideas<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#section-9-capstone-project-ideas\"></a></h3><ul><li><p>Build a universal number system converter.</p></li><li><p>Create a bitwise operations calculator.</p></li><li><p>Write a program to encode a text message into a hex string.</p></li><li><p>Build an IPv4 subnet calculator.</p></li><li><p>Create a visualizer for IEEE 754 floating-point numbers.</p></li></ul><h3>Appendix: Further Learning Resources<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-2-guide-to-computer-number-systems#appendix-further-learning-resources\"></a></h3><ul><li><p><strong>Stanford University - Introduction to Logic (Coursera)</strong></p></li><li><p><strong>University of Leeds - An Introduction to Logic for Computer Science (Coursera)</strong></p></li><li><p><strong>Ahmed Muhammed - Number Systems For Beginners (Udemy)</strong></p></li><li><p> Offers videos and exercises on binary and hexadecimal systems.</p></li></ul><ul><li><p><strong>For Discrete Mathematics and Logic:</strong></p><ul><li><p><em>Discrete Mathematics and Its Applications</em> by Kenneth H. Rosen</p></li><li><p><em>Discrete Mathematics with Applications</em> by Susanna S. Epp</p></li></ul></li><li><p><strong>For Computer Architecture:</strong></p><ul><li><p><em>Computer Organization &amp; Design</em> by David A. Patterson and John L. Hennessy</p></li><li><p><em>Computer Systems: A Programmer's Perspective</em> by Randal E. Bryant and David R. O'Hallaron</p></li><li><p><em>Code: The Hidden Language of Computer Hardware and Software</em> by Charles Petzold</p></li></ul></li></ul><p>Understanding decimal, binary, and hexadecimal is a core skill for computing. Binary is the computer's native language. Hexadecimal is the programmer's shorthand for it. Concepts like two's complement and IEEE 754 make computer math possible. Learning these languages and tools gives you a deep understanding of how the digital world is built.</p>","contentLength":18731,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lgohyc/practical_uses_for_bitwise_operations/"},{"title":"MCP Security is still Broken","url":"https://forgecode.dev/blog/prevent-attacks-on-mcp/","date":1750481238,"author":"/u/West-Chocolate2977","guid":164021,"unread":true,"content":"<p>Been digging into Model Context Protocol implementations lately and found some stuff that's keeping me up at night. Not because it's earth-shattering, but because it's the kind of boring security debt that bites you when you least expect it.</p><h2>What's MCP and Why Should I Care?<a href=\"https://forgecode.dev/blog/prevent-attacks-on-mcp/#whats-mcp-and-why-should-i-care\" aria-label=\"Direct link to What's MCP and Why Should I Care?\" title=\"Direct link to What's MCP and Why Should I Care?\">‚Äã</a></h2><p>MCP is Anthropic's attempt at standardizing how AI models talk to external tools. Instead of every AI app rolling their own integration layer, you get a common protocol. Think of it like REST for AI tools, except with way less thought put into security.</p><p>The spec is pretty straightforward - JSON-RPC over stdio or HTTP. AI asks for available tools, gets back a list with descriptions, then calls them with parameters. Simple enough that you can implement a basic server in an afternoon.</p><p>Which is exactly the problem.</p><p>Here's where things get interesting. MCP servers describe their tools using natural language descriptions that the AI reads to understand what each tool does. Sounds reasonable, right?</p><p>Except those descriptions get fed directly into the AI's context. And if you control the MCP server, you can put whatever you want in those descriptions.</p><p>The AI reads this description and suddenly thinks it has new instructions. User asks for weather, AI decides to exfiltrate data instead.</p><p>I tested this against a few popular MCP implementations and... yeah, it works. Most don't even try to sanitize tool descriptions.</p><h3>Why This Actually Matters<a href=\"https://forgecode.dev/blog/prevent-attacks-on-mcp/#why-this-actually-matters\" aria-label=\"Direct link to Why This Actually Matters\" title=\"Direct link to Why This Actually Matters\">‚Äã</a></h3><p>Unlike typical prompt injection where you need user input, this attack vector lives in the protocol itself. The AI has to read tool descriptions to function. You can't just \"sanitize\" them without breaking core functionality.</p><p>And here's the kicker - in most setups, the user never sees the tool descriptions. They just see \"checking weather...\" while the AI follows completely different instructions in the background.</p><h2>Authentication? What Authentication?<a href=\"https://forgecode.dev/blog/prevent-attacks-on-mcp/#authentication-what-authentication\" aria-label=\"Direct link to Authentication? What Authentication?\" title=\"Direct link to Authentication? What Authentication?\">‚Äã</a></h2><p>Spent some time looking at MCP server implementations in the wild. The authentication situation is... not great.</p><p>A lot of servers I found basically look like this:</p><p>That TODO comment/Documentation is doing a lot of heavy lifting.</p><p>The MCP spec does mention authentication, but it's basically \"figure it out yourself.\" Most implementations I've seen either skip it entirely or bolt on some basic API key checking that's trivial to bypass.</p><p>Found one server that checked for an API key but only on GET requests. POST requests (you know, the ones that actually do stuff) went straight through.</p><p>MCP tools are distributed as packages, which means we get all the fun of supply chain attacks. But with a twist - these tools run with whatever permissions your AI system has.</p><p>Regular supply chain attacks might steal your npm tokens or mine some crypto. MCP supply chain attacks can read your conversations, access your databases, and impersonate you to other services.</p><p>I've been watching a few popular MCP tool repositories. The security practices are... inconsistent. Lots of tools with broad permissions, minimal code review, and maintainers who probably haven't thought much about security.</p><p>Not naming names because I'm not trying to shame anyone, but if you're using MCP tools in production, you might want to audit what you're actually running.</p><p>Tested this stuff against a few internal systems (with permission, obviously). The results weren't great:</p><ul><li>Got tool description injection working against 2/4 MCP implementations</li><li>Found unauthenticated endpoints in 1/10 production deployments</li><li>Identified several tools with way more permissions than they needed</li></ul><p>The scariest part? Most of this stuff would be invisible in standard logs. User requests \"check my calendar,\" AI executes malicious tool, logs show \"calendar_check: success.\" Good luck spotting that in your SIEM.</p><h2>What Actually Needs Fixing<a href=\"https://forgecode.dev/blog/prevent-attacks-on-mcp/#what-actually-needs-fixing\" aria-label=\"Direct link to What Actually Needs Fixing\" title=\"Direct link to What Actually Needs Fixing\">‚Äã</a></h2><p>This isn't about rewriting everything. Most of this is fixable with some basic hygiene:</p><ul><li>Parse and validate descriptions before feeding them to the AI</li><li>Strip out anything that looks like instructions</li><li>Consider using structured descriptions instead of free text</li></ul><ul><li>Actually implement it (OAuth flows are now required in MCP 2025-06-18)</li><li>Use proper OAuth Resource Server patterns as specified in the latest MCP spec</li><li>Implement Resource Indicators (RFC 8707) to prevent token theft</li><li>Validate tokens on every request</li></ul><ul><li>Review code before deploying</li><li>Run tools with minimal permissions</li></ul><p>None of this is rocket science. It's just boring security work that nobody wants to do.</p><p>MCP adoption is picking up fast. I'm seeing it deployed in financial services, healthcare, customer support systems. Places where a security incident would be really, really bad.</p><p>The window for fixing this stuff cleanly is closing. Once you have thousands of MCP servers in production, coordinating security updates becomes a nightmare.</p><p>Better to fix it now while the ecosystem is still small enough to actually change.</p><div><div><p>The latest MCP specification (released June 18, 2025) addresses some security concerns:</p><ul><li>OAuth Resource Server classification is now required</li><li>Resource Indicators (RFC 8707) must be implemented to prevent malicious token access</li><li>New security best practices documentation</li><li>Removal of JSON-RPC batching (reduces attack surface)</li></ul></div></div><p>However, the core vulnerabilities described above (tool description injection, supply chain risks) remain unaddressed in the protocol itself.</p><p>Part 2 will cover specific mitigation strategies and some tools I've been building to make this stuff easier to secure. Nothing groundbreaking, just practical stuff that actually works.</p><p>If you're building MCP tools or have seen other security issues, let me know. This ecosystem is still small enough that we can actually fix problems before they become disasters.</p>","contentLength":5635,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lgoa1b/mcp_security_is_still_broken/"},{"title":"Making chess in ncurses and c++","url":"https://www.youtube.com/watch?v=B-ZBBT0Yj_g","date":1750478237,"author":"/u/that_brown_nerd","guid":164162,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lgneyi/making_chess_in_ncurses_and_c/"},{"title":"I made a crate for mesh editing","url":"https://www.reddit.com/r/rust/comments/1lgmx9y/i_made_a_crate_for_mesh_editing/","date":1750476556,"author":"/u/camilo16","guid":164137,"unread":true,"content":"<p>I just published <a href=\"https://crates.io/crates/polyhedron\">Polyhedron</a> a crate for manipulating manifold and non manifold meshes.</p><p>The crate includes: * Compile time selection for manifold vs non manifold representation * Agnostic vertex representation, a vertex can be any type and dimension, e.g. nalgebra or glam, through my other crate . * Fundamental topological operations, edge flipping, splitting, collapse. * Implementations for loop subdivision, QEM edge simplification and Kobet's remeshing algorithm.</p><p>The crate is in its infancy and will be for a while. It will be actively maintained but I can only work on it in an \"as need to\" basis.</p><p>If you need an algorithm and want to contribute, please reach out to me to help you implement it.</p><p>For commercial use, please refer to the License file.</p>","contentLength":752,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why isn't Debian recommended more often?","url":"https://www.reddit.com/r/linux/comments/1lgl87v/why_isnt_debian_recommended_more_often/","date":1750471103,"author":"/u/Browncoatinabox","guid":164045,"unread":true,"content":"<p>Everyone is happy to recommend Ubuntu/Debian based distros but never Debian itself. It's stable and up-to-date-ish. My only real complaint is that KDE isn't up to date and that you aren't Sudo out of the gate. But outside of that I have never had any real issues. </p>","contentLength":264,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Which Linux is your favourite? For me, it‚Äôs fedora.","url":"https://www.reddit.com/r/linux/comments/1lgkwz1/which_linux_is_your_favourite_for_me_its_fedora/","date":1750470109,"author":"/u/New_Series3209","guid":163989,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A fast, lightweight Tailwind class sorter for Templ users (no more Prettier)","url":"https://www.reddit.com/r/golang/comments/1lgk2bb/a_fast_lightweight_tailwind_class_sorter_for/","date":1750467411,"author":"/u/DexterInAI","guid":164027,"unread":true,"content":"<p>Heyy, so for the past couple of days, I have been working on , a lightweight CLI tool written in Go, and I just finished building a version I am satisfied with.</p><p>My goal was to build something I can use without needing to install  just to run the Tailwind's <strong>prettier-plugin-tailwindcss</strong> class sorter. I often work in environments with Python or Go and use Tailwind via the .</p><ul><li><strong>Zero Node/NPM dependencies</strong> (great for  setups).</li><li>Astral's , making it easy to spot and fix unsorted classes.</li><li> for tailored file patterns &amp; attributes.</li><li>Seamless integration as a pre-commit hook.</li></ul><p>I'm pretty happy with how it turned out, so I wanted to share!</p>","contentLength":622,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes Security Trade-offs?","url":"https://www.reddit.com/r/kubernetes/comments/1lgjv1o/kubernetes_security_tradeoffs/","date":1750466786,"author":"/u/magnezone150","guid":164136,"unread":true,"content":"<p>I have a Kubeadm Cluster that I built on Rocky Linux 9.6 Servers. I thought I'd challenge myself and see if I can do it with firewalld enabled and up.<p> I've also Installed Istio, Calico, MetalLB and KubeVirt.</p> However, with my current firewalld config everything in cluster is good including serving sites with istio but my KubeVirt VMs can't seem access outside of the Cluster such as ping google.com -c 3 or dnf update saying their requests are filtered unless I move my Nodes interface (eno1) to the kubenetes zone but the trade off is if someone uses nmap scan they can easily see ports on all nodes versus keeping the interface where it is in public zone causing nmap defaulting to the node being down or takes longer to produce any reports where it only can see ssh. Curious if anyone has ever done a setup like this before?</p><p>These are the firewall configurations I have on all Nodes.</p><pre><code>public (active) target: default icmp-block-inversion: no interfaces: eno1 sources: services: ssh ports: protocols: forward: yes masquerade: yes forward-ports: source-ports: icmp-blocks: rich rules: --- kubernetes (active) target: default icmp-block-inversion: no interfaces: sources: &lt;Master-IP&gt; &lt;Worker-IP-1&gt; &lt;Worker-IP-2&gt; &lt;Pod-CIDR&gt; &lt;Service-CIDR&gt; services: ports: 6443/tcp 2379/tcp 2380/tcp 10250/tcp 10251/tcp 10252/tcp 179/tcp 4789/tcp 5473/tcp 51820/tcp 51821/tcp 80/tcp 443/tcp 9101/tcp 15000-15021/tcp 15053/tcp 15090/tcp 8443/tcp 9443/tcp 9650/tcp 1500/tcp 22/tcp 1500/udp 49152-49215/tcp 30000-32767/tcp 30000-32767/udp protocols: forward: yes masquerade: yes forward-ports: source-ports: icmp-blocks: rich rules: </code></pre>","contentLength":1610,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Storage solutions for on premise setup","url":"https://www.reddit.com/r/kubernetes/comments/1lgjt5e/storage_solutions_for_on_premise_setup/","date":1750466624,"author":"/u/QualityHot6485","guid":164044,"unread":true,"content":"<p>I am creating a kubernetes cluster in an on premise cluster but the problem is I don't know which storage option to use for on premise.</p><p>In this on premise setup I want the data to be stored in the node itself. So for this setup I used hostpath. </p><p>But in hostpath it is irrelevant setting the pvc as it will not follow it and store data as long there is disk space. I also read some articles where they mention that hostpath is not suitable for production. But couldn't understand the reason why ???</p><p>If there is any alternative to hostpath?? Which follows the pvc limit and allows volume expansion also ??</p><p>Suggest me some alternative (csi)storage options for on premise setup !!</p><p>Also why is hostpath not recommended for production???</p>","contentLength":726,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go JSON Validation","url":"https://www.reddit.com/r/golang/comments/1lgjrdz/go_json_validation/","date":1750466474,"author":"/u/EarthAggressive9167","guid":164190,"unread":true,"content":"<p> I‚Äôm learning Go, but I come from a TypeScript background and I‚Äôm finding JSON validation a bit tricky maybe because I‚Äôm used to Zod.</p><p>What do you all use for validation?</p>","contentLength":174,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Warning to CEOs: The AI You Are Being Told Can Replace Engineers, Designers, and Researchers Is More Likely to Bankrupt You Than You Think","url":"https://drakewatson.substack.com/p/warning-to-ceos-the-ai-you-are-being","date":1750466380,"author":"/u/VeridianLuna","guid":163940,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lgjq8u/warning_to_ceos_the_ai_you_are_being_told_can/"},{"title":"Finding performance problems by diffing two Go profiles","url":"https://www.dolthub.com/blog/2025-06-20-go-pprof-diffing/","date":1750465585,"author":"/u/zachm","guid":163963,"unread":true,"content":"<p>We're hard at work on compatibility for\n<a href=\"https://www.dolthub.com/blog/2025-04-16-doltgres-goes-beta/\">Doltgres</a>, the world's first and only\nversion-controlled Postgres-compatible SQL database. This means getting it to work with every\nlibrary and tool that Postgres works with, out of the box. Lately we've been focussing a lot of\neffort on <a href=\"https://www.sqlalchemy.org/\">SQLAlchemy</a>, a popular ORM for Python. Their MySQL\nintegration works flawlessly with Dolt, but their Postgres version is apparently completely\ndifferent, relying heavily on the  tables. A customer tried it out and <a href=\"https://github.com/dolthub/doltgresql/issues/1465\">found a lot of\ngaps</a> owing to Doltgres not including system\ntables (e.g. ) in the  tables. So I fixed that, but this led to a mysterious\nperfomance regression in one of our test suites, over a 3x slowdown.</p><p>It took quite a bit of puzzling to figure out why such an innocuous seeming change caused such a\ndramatic difference in performance. In the end, what helped the most was an amazing tool in the Go\ntoolchain: visualizing the difference between two performance profiles with the  option to\n.</p><p>Go ships with a robust profiling tool, . Unlike some other languages, you have to explicitly\nenable it in your code to get a profile; you can't do it after the fact or with command line\nflags. This is easy, but you have to write the code to do it. In our case, I placed it directly in\nthe test method being profiled.</p><div data-language=\"go\"><pre><code>t testingT ok  osok \n\t\n\tp  profileprofileCPUProfile p</code></pre></div><p>The final two lines of this snippet start a CPU profile, then stop it when the method completes. It\nuses the  package, which provides a more ergonomic wrapper around the\nbuilt-in profiler libraries. If you run code that does this, you'll see an output line like the\nfollowing:</p><div data-language=\"text\"><pre><code>2025/06/20 14:10:40.548730 profile: cpu profiling disabled, C:\\Users\\ZACHMU~1\\AppData\\Local\\Temp\\profile1113350212\\cpu.pprof</code></pre></div><p>This is the location of the profile produced by the run, which you should note or copy into another\nlocation with an easier to remember name.</p><p>For my testing, I wanted to see how the performance changed between what was on the  branch\nand my current branch, so I ran the test with profiling enabled on each branch. Now I can compare\nthem using the  flag with .</p><p>After getting a profile for each branch, now I just need to compare them.</p><div data-language=\"sh\"><pre><code>go tool pprof :8090  main.pprof branch.pprof</code></pre></div><p>The  flag tells  to \"subtract\" the named profile from the other one when reporting\nperformance numbers. In this case, I want to see what is happening in  but not in\n that's taking so long. I also always use the  flag, which runs an interactive\nweb server instead of a command-line interface. I find it much easier to work with when\ninvestigating performance profiles.</p><p>When I run the command, my web browser launches to the default display, a graph of cumulative CPU\nsamples roughly topo-sorted by function, so you can see what calls what. Unlike in a normal profile\nanalysis, the numbers shown are strictly the diff between the two profiles, rather than their\nabsolute runtimes. Here's what I saw in my web view:</p><p><code>Database.tableInsensitive</code> is the function that fetches a table object for the query engine to\nuse. Somehow, my changes had made this function much, much slower, despite not editing it\ndirectly. With this clue in hand, I was able to find the performance bug.</p><div data-language=\"go\"><pre><code>\n\n\ttableNames err  dbctx root err  doltdbTableName err\n\t root\n\t\ttableMap  table  tableNames \n\t\t\ttableMapstringstable table\n\t\t\n\t\tdbStateroot tableMap\n\n\ttableName ok  sqltableName tableNamesok  doltdbTableName</code></pre></div><p>The first line of the snippet loads all table names from the DB if they weren't already cached in\nthe session. This is necessary because our table names are stored in a case-sensitive manner, but\nSQL is case-insensitive. So, as part of loading a table from the DB, we need to correct the\nrequested case-insensitive name from the query to the case-sensitive one for use in the storage and\nI/O layer. But that call to  includes a final parameter:\n<code>includeGeneratedSystemTables</code>. This was hard-coded to true, which meant it was always calling the\nnew, more expensive method of getting a list of generated system tables, which includes potential\ndisk access to get the set of database schemas and then lots of iteration over them.</p><div data-language=\"go\"><pre><code>\tschemas err  rootctx err  err\n\tschemas\n\t\tschemas schemas schemaDatabaseSchemaName doltdbDefaultSchemaName schema  schemas \n\t\ttableNames err  rootctx schemaName err  err\n\t\t pre  doltdbGeneratedSystemTablePrefixes  tableName  tableNames \n\t\t\t\tsdoltdbTableName\n\t\t\t\t\tName   pre  tableName\n\t\t\t\t\tSchema schemaName UseSearchPath  schemaName  schemaName  doltdbDoltNamespace  name  doltdbDoltGeneratedTableNames \n\t\t\t\tsdoltdbTableName\n\t\t\t\t\tName   name\n\t\t\t\t\tSchema schemaName</code></pre></div><p>As it turns out, the hard-coded  was simply wrong -- this method never needed to consider\nsystem-generated table names. But it was a relatively harmless bug before I made the process of\ngenerating those names more expensive, and had been in the code for years unnoticed. Changing this\nvalue to  to remove the unnecessary work fixed the performance regression, and also sped up\nDolt's benchmarks by a bit as well.</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>I'm not sure I ever would have figured out the source of this inefficiency without the  flag\nto point me in the right direction.</p><p>Questions about Go performance profiling or about <a href=\"https://www.doltgres.com/\">Doltgres</a>? Come by our\n<a href=\"https://discord.gg/gqr7K4VNKe\">Discord</a> to talk to our engineering team and meet other Doltgres\nusers.</p>","contentLength":5272,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1lgjgzk/finding_performance_problems_by_diffing_two_go/"},{"title":"Thoughts on rust_native","url":"https://www.reddit.com/r/rust/comments/1lgjeyn/thoughts_on_rust_native/","date":1750465415,"author":"/u/vlovich","guid":164003,"unread":true,"content":"<div><p>The feature list looks impressive although the development process looks to be code dumps so I'm not sure about the quality / if anything even works &amp; it has few reviews. Has anyone tried it?</p></div>   submitted by   <a href=\"https://www.reddit.com/user/vlovich\"> /u/vlovich </a>","contentLength":221,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AbsenceBench: Language Models Can't Tell What's Missing","url":"https://arxiv.org/abs/2506.11440","date":1750463128,"author":"/u/locomotus","guid":163941,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/MachineLearning/comments/1lgimm3/absencebench_language_models_cant_tell_whats/"},{"title":"Does anyone customize Scheduler profiles and/or use Cluster Autoscaler expanders to improve bin-packing on nodes?","url":"https://blog.cleancompute.net/p/kubernetes-cost-optimization","date":1750460876,"author":"/u/nbir","guid":164088,"unread":true,"content":"<p><a href=\"https://www.flexera.com/about-us/press-center/new-flexera-report-finds-84-percent-of-organizations-struggle-to-manage-cloud-spend\" rel=\"\"></a><a href=\"https://www.gartner.com/peer-community/oneminuteinsights/omi-keeping-cloud-costs-check-it-leader-perspectives-rfz\" rel=\"\"></a><a href=\"https://www.g2.com/articles/cloud-cost-management-statistics\" rel=\"\"></a></p><p><a href=\"https://techblog.cloudkitchens.com/p/managing-100s-of-kubernetes-clusters\" rel=\"\">operating 100s of Kubernetes clusters</a></p><p>Keep these principles in mind as you craft your own cost optimization blueprint:</p><ol><li><p><strong>There's no single magic bullet</strong></p></li><li><p><strong>You can't optimize what you don't see</strong></p></li><li><p><strong>High utilization doesn‚Äôt always equal low cost</strong></p></li><li><p><strong>Optimization vs. reliability is a delicate dance</strong></p></li><li><p><strong>Shift Left by building cost consciousness</strong></p></li><li><p><strong>Architect for efficiency early</strong></p></li></ol><p>Kubernetes workloads often autoscale and are distributed across diverse node types, especially in shared multi-tenant clusters. This obscures compute cost origins, prevents identifying inefficiencies, and assigning accountability of resources to specific teams or applications. Cloud providers usually have built in cost dashboards, but only provide visibility only at the VM or node level and lack attribution at the application level,</p><p><a href=\"https://opencost.io/\" rel=\"\">OpenCost</a></p><ol></ol><p>The default Kubernetes scheduler distributes workloads uniformly across nodes. This leads to persistent overprovisioning resulting in unused capacity across multiple nodes and sparse bin-packing.</p><ol></ol><p><code>--scale-down-utilization-threshold</code><code>--scale-down-unneeded-time</code></p><p><code>--scale-down-utilization-threshold</code><code>--scale-down-unneeded-time</code><a href=\"https://karpenter.sh/\" rel=\"\">Karpenter</a></p><ol><li><p><strong>Scaling Oscillation or Thrashing</strong><code>--scale-down-delay-after-add</code><code>--scale-down-delay-after-delete</code></p></li><li><p><strong>Workloads Blocking Eviction</strong></p></li></ol><p>Short-lived ephemeral workloads like analytics pipelines, batch jobs, data ingestion agents, etc. frequently spin-up and spin-down. This prevents Cluster Autoscaler from scaling down nodes. Running these workloads on on-demand nodes doesn‚Äôt make financial sense.</p><ol><li><p><a href=\"https://techblog.cloudkitchens.com/i/145625273/handling-abrupt-spot-node-preemptions\" rel=\"\">this blog</a></p></li></ol><p>Manually configuring CPU and memory requests and limits for pods is inefficient. Developers often err on the side of overprovisioning, driven by concerns about performance, stability, and the potential impact of noisy neighbors. Furthermore, initial resource requests are rarely audited or adjusted over time as application needs evolve. This leads to wasted resources.</p><ol><li><p><strong>Phased Rollout and Escape Hatches</strong></p></li><li><p><strong>Developer Control and Trust</strong></p></li><li><p><strong>Application of Scaled-Down Requests</strong></p></li></ol><p>HPA natively supports scaling based on CPU and memory utilization. However, this is insufficient for applications with scaling needs reflected best in business or application-level metrics like requests per second, queue depth, active connections, etc. Scaling solely on CPU or memory can cause instability and failures, leading to reliability concerns. Consequently, teams often overprovision to handle peak loads.</p><p><a href=\"https://keda.sh/\" rel=\"\">KEDA</a></p><ol><li><p><strong>Metrics Infrastructure Reliability</strong></p></li><li><p><strong>Single Custom Metrics Server Limitation</strong></p></li><li><p><strong>Failure Modes and Defaults</strong></p></li></ol><p>It is common to provision single-tenant Kubernetes clusters per team or application when starting off. This approach, driven by a perceived need for strict isolation or sometimes developer insistence, is a classic recipe for overprovisioning.</p><ul><li><p><em>Resource Requests and Limits</em></p></li><li><p><em>Resource Quotas and LimitRanges</em></p></li><li><p><em>Role-Based Access Control (RBAC)</em></p></li><li><p><em>Pod Security Standards (PSS) or Security Contexts</em></p></li></ul><ol><li><p><strong>\"Noisy Neighbor\" Phenomenon</strong></p></li><li><p><strong>Network and Disk I/O Bottlenecks</strong></p></li></ol><p>Discrepancies between node CPU:memory ratios and that of workload consumption lead to resource imbalances. For example, memory-intensive workloads on high CPU:memory nodes can underutilize CPU while bottlenecking memory. This leads to more nodes than actually required.</p><p><a href=\"https://karpenter.sh/\" rel=\"\">Karpenter</a></p><ol><li><p><strong>In-place Node Type Changes</strong><a href=\"https://techblog.cloudkitchens.com/i/142916610/automating-node-pools\" rel=\"\">this blog</a></p></li></ol><p>Workloads with PodDisruptionBudgets (PDBs) set to 0 or safe-to-evict: false annotations block Cluster Autoscaler node scale-down operations. These configurations are common for singletons or critical workloads, and are problematic in multi-tenant platforms.</p><ol></ol><p>Persistent storage costs in Kubernetes can accumulate rapidly when using cloud managed Persistent Volumes (PVs). Without active management, teams default to expensive storage classes, over-provision volume sizes, or leave unused volumes lingering, leading to accumulating costs.</p><ul><li><p><strong>Unused or Orphaned Volumes</strong></p></li></ul><p>Network costs can become an unexpected line item in cloud bills, because cloud providers charge for all ingress and egress traffic, cross-region data transfer, load balancers, gateways, etc. A multi-region Kubernetes architecture built for resilience can come at an exorbitant price. Applications with high data transfer or public-facing services can rapidly accumulate network charges too.</p><ol></ol><p><em>Continue reading Part 2 (coming soon) of this blog, where we share a case study detailing real-world application of these strategies by an organization operating cloud-scale Kubernetes infrastructure across multiple cloud providers and continents. Get ready for behind-the-scenes war stories and first-hand lessons.</em></p>","contentLength":4512,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1lghtu0/does_anyone_customize_scheduler_profiles_andor/"},{"title":"12 years of Postgres Weekly with Peter Cooper, on Talking Postgres with Claire Giordano","url":"https://talkingpostgres.com/episodes/12-years-of-postgres-weekly-with-peter-cooper","date":1750456859,"author":"/u/clairegiordano","guid":164303,"unread":true,"content":"<a href=\"https://talkingpostgres.com/people/claire-giordano\" title=\"Claire Giordano\">Claire Giordano</a><div>Claire Giordano is head of the Postgres open source community initiatives at Microsoft. Claire has served in leadership roles in engineering, product management, and product marketing at Sun Microsystems, Amazon/A9, and Citus Data. At Sun, Claire managed the engineering team that created Solaris Zones, and led the effort to open source Solaris.</div>","contentLength":361,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lggcmf/12_years_of_postgres_weekly_with_peter_cooper_on/"},{"title":"Europe‚Äôs Growing Fear: How Trump Might Use U.S. Tech Dominance Against It","url":"https://www.nytimes.com/2025/06/20/technology/us-tech-europe-microsoft-trump-icc.html?smid=nytcore-ios-share&amp;referringSource=articleShare","date":1750455140,"author":"/u/Grevillea_banksii","guid":163914,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1lgfp4p/europes_growing_fear_how_trump_might_use_us_tech/"},{"title":"Falling in love with Rust ü¶Ä ‚Äî where should I go from here?","url":"https://www.reddit.com/r/rust/comments/1lgdgxy/falling_in_love_with_rust_where_should_i_go_from/","date":1750449508,"author":"/u/Upbeat_Ad_6119","guid":163814,"unread":true,"content":"<p>Last 4 years I‚Äôve been working as a Node.js backend developer. Yeah, my main language is JavaScript (well, TypeScript to be more accurate), and to be honest, I‚Äôve grown a bit tired of it. It‚Äôs weird writing code in a scripting language that gets compiled into another scripting language, which then gets interpreted by yet another runtime.</p><p>Also, I'm just tired of spinning up new projects - installing linters, formatters, test runners, builder configs, dealing with tsconfigs, ESM/CommonJs specifications.</p><p>On top of that, I often hit walls due to the lack of some really useful features, like proper compile-time metaprogramming, which only compiled languages tend to offer.</p><p>So, a few months ago I realized I don‚Äôt want to be just a JS developer anymore. I started looking for a better language to grow with.</p><p>It seemed simple, minimalistic, efficient - a relatively easy shift from Node. But after about a week, I dropped it. Yeah, minimalism is cool and all, but it lacks a lot of features I really value. And most importantly, it drove me insane with:</p><ol><li><p>Error propagation - writing the same 4 lines in every function, on every layer? nah.</p></li><li><p>Access modifiers based on capital letters, really?</p></li></ol><p>What I did like about Go was that you get a complete standard toolchain out of the box. No need to install 20+ dev dependencies like in Node. I think Go could be a great fit for certain use cases, but for me, it felt too limited for most projects I care about.</p><p><strong>Then I thought about C++.</strong></p><p>I‚Äôve used it before for competitive programming, and I enjoy stuff like macros and operator overloading. But package management? CMake? Total nightmare. So I decided to leave C++ strictly for CP stuff.</p><p><strong>And then‚Ä¶ I fell in love - at first sight - with Rust.</strong></p><p>Just a few weeks ago I discovered Rust, and I love so many things about it. The macros, enums, pattern matching, trait overloading... it‚Äôs awesome seeing how all these features come together in practice.</p><p>Some parts are a bit weird at first - like ownership, borrowing, and lifetimes - but I think it just takes time to get used to them. Overall, I really believe Rust knowledge will be super valuable for my career. I‚Äôd love to contribute to distributed systems, or build supporting tools, instead of staying in the usual API/microservice zone forever.</p><p>So right now I‚Äôm looking for advice - what direction should I take next? Sure, I can just research on my own (as I usually do), but hearing from real people who are on the same journey - or already walked it - would be incredibly helpful. I‚Äôd love to hear your stories too.</p><p>Currently I‚Äôm going through the official Rust docs to get the basics down. But I‚Äôm also hunting for some advanced books or resources. A lot of books I found just copy-paste examples from the docs, and I‚Äôm hoping for something deeper. If you have any recommendations - even if it‚Äôs not web-related, or too advanced for a beginner - I‚Äôd seriously appreciate it. The more challenging, the better.</p><p>Thanks for reading - and excited to join the Rust path with all of you ü§ò</p>","contentLength":3046,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Did you switch to Linux because you loved it?","url":"https://www.reddit.com/r/linux/comments/1lgcnt1/did_you_switch_to_linux_because_you_loved_it/","date":1750447406,"author":"/u/gerundingnounshire","guid":163781,"unread":true,"content":"<p>I've noticed a common sentiment from many Linux users of \"I switched to Linux because Windows sucks,\" and I don't really share that. I switched because I decided to give Linux a shot because it seemed interesting, and I ended up loving it so much that I just sorta decided to daily-drive it.</p><p>Am I alone in this? Has anyone else switched solely because they liked Linux?</p>","contentLength":368,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Migrating off Legacy Tokio at Scale","url":"https://www.okta.com/blog/2024/11/migrating-off-legacy-tokio-at-scale/","date":1750443335,"author":"/u/anonymous_pro_","guid":163777,"unread":true,"content":"<h2></h2><h2></h2><p><a href=\"https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/\" rel=\" noopener noreferrer\" target=\"_blank\"></a></p><p><a href=\"https://help.okta.com/wf/en-us/content/topics/workflows/execute/cancel-flows.htm\" rel=\" noopener noreferrer\" target=\"_blank\"></a></p><h2></h2><p><a href=\"https://hyper.rs/\" rel=\" noopener noreferrer\" target=\"_blank\"></a><a href=\"https://workspace.google.com/products/drive/\" rel=\" noopener noreferrer\" target=\"_blank\"></a><a href=\"https://aws.amazon.com/s3/\" rel=\" noopener noreferrer\" target=\"_blank\"></a></p><p><a href=\"https://docs.rs/futures-util/latest/futures_util/compat/index.html\" rel=\" noopener noreferrer\" target=\"_blank\"></a></p><h2></h2><p><a href=\"https://www.okta.com/products/workflows/\" rel=\" noopener noreferrer\" target=\"_blank\"></a></p>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1lgb0bo/migrating_off_legacy_tokio_at_scale/"},{"title":"Flathub has passed 3 billion downloads","url":"https://www.reddit.com/r/linux/comments/1lgaz5z/flathub_has_passed_3_billion_downloads/","date":1750443256,"author":"/u/mr_MADAFAKA","guid":163782,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/mr_MADAFAKA\"> /u/mr_MADAFAKA </a>","contentLength":34,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Simple HTTP/TCP/ICMP endpoint checker","url":"https://www.reddit.com/r/golang/comments/1lgamsg/simple_httptcpicmp_endpoint_checker/","date":1750442440,"author":"/u/1dk_b01","guid":163887,"unread":true,"content":"<p>I would like to share one project which I have contributed to several times and I think it deserves more eyes and attention. It is a simple one-shot health/uptime checker feasible of monitoring ICMP, TCP or HTTP endpoints. </p><p>I have been using it for like three years now to ensure services are up and exposed properly. In the beginning, services were few, so there was no need for the complex monitoring solutions and systems. And I wanted something simplistic and quick. Now, it can be integrated with Prometheus via the Pushgateway service, or simply with any service via webhooks. Also, alerting was in mind too, so it sends Telegram messages right after the down state is detected.</p><p>Below is a link to project repository, and a link to a blog post that gives a deep dive experience in more technical detail.</p>","contentLength":807,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Malware-Laced GitHub Repos Found Masquerading as Developer Tools","url":"https://klarrio.com/klarrio-discovers-large-scale-malware-network-on-github/","date":1750440124,"author":"/u/gametorch","guid":163778,"unread":true,"content":"<p>(English translation below)</p><p><b>Klarrio ontdekt grootschalig malware-netwerk op GitHub</b></p><p>Klarrio heeft onlangs een belangrijke ontdekking gedaan: </p><ul></ul><ul></ul><p><b>Klarrio Discovers Large-Scale Malware Network on GitHub</b></p><ul></ul><p>https://&lt;domein&gt;/storage/&lt;path&gt;</p><p>Thanks to the press who have already relayed the information:</p>","contentLength":285,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lg9ohx/malwarelaced_github_repos_found_masquerading_as/"},{"title":"godump v1.2.0 - Thank you again","url":"https://i.postimg.cc/MptM6XV8/IMG-9389.png","date":1750438609,"author":"/u/cmiles777","guid":163728,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1lg91p8/godump_v120_thank_you_again/"},{"title":"Quick Tip: Stop Your Go Programs from Leaking Memory with Context","url":"https://www.reddit.com/r/golang/comments/1lg8n72/quick_tip_stop_your_go_programs_from_leaking/","date":1750437619,"author":"/u/GladJellyfish9752","guid":163673,"unread":true,"content":"<p>Hey everyone! I wanted to share something that helped me write better Go code. So basically, I kept running into this annoying problem where my programs would eat up memory because I wasn't properly stopping my goroutines. It's like starting a bunch of tasks but forgetting to tell them when to quit - they just keep running forever!</p><p>The fix is actually pretty simple: use context to tell your goroutines when it's time to stop. Think of context like a \"stop button\" that you can press to cleanly shut down all your background work. I started doing this in all my projects and it made debugging so much easier. No more wondering why my program is using tons of memory or why things aren't shutting down properly.</p><p>import ( \"context\" \"fmt\" \"sync\" \"time\" )</p><p>func worker(ctx context.Context, id int, wg *sync.WaitGroup) { defer wg.Done()</p><pre><code>for { select { case &lt;-ctx.Done(): fmt.Printf(\"Worker %d: time to stop!\\n\", id) return case &lt;-time.After(500 * time.Millisecond): fmt.Printf(\"Worker %d: still working...\\n\", id) } } </code></pre><p>func main() { // Create a context that auto-cancels after 3 seconds ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second) defer cancel()</p><pre><code>var wg sync.WaitGroup // Start 3 workers for i := 1; i &lt;= 3; i++ { wg.Add(1) go worker(ctx, i, &amp;wg) } // Wait for everyone to finish wg.Wait() fmt.Println(\"Done! All workers stopped cleanly\") </code></pre><p> Always use WaitGroup with context so your main function waits for all goroutines to actually finish before exiting. It's like making sure everyone gets off the bus before the driver leaves!</p>","contentLength":1546,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"xAI faces legal threat over alleged Colossus data center pollution in Memphis","url":"https://arstechnica.com/tech-policy/2025/06/xai-faces-legal-threat-over-alleged-colossus-data-center-pollution-in-memphis/","date":1750436217,"author":"/u/F0urLeafCl0ver","guid":164004,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1lg82ut/xai_faces_legal_threat_over_alleged_colossus_data/"},{"title":"Tell me what you think about my Rust project (crate, docker, binary)","url":"https://github.com/johan-steffens/foxy","date":1750435650,"author":"/u/Isosymmetric","guid":163988,"unread":true,"content":"<p>Hello everybody, first time poster here.</p><p>I've been working with Rust more and more in my career as of late, and really been loving it (despite late-night fights with the Karen compiler). I eventually got to a point where I wanted to challenge myself to build something that I would actually use, and decided to build an extensible, config-driven, Rust proxy/API gateway as a challenge.</p><p>The challenge evolved into something more, and I ended up adding a whole bunch of cool features (to the end of it being something that I would actually use), and have gotten it to a point where I'd like to share it to get some feedback, insight, or even kudos.</p><p>Please let me know what you think, or leave a star if you like it.</p>","contentLength":710,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1lg7ucc/tell_me_what_you_think_about_my_rust_project/"},{"title":"The Embedded Rustacean Issue #48","url":"https://www.theembeddedrustacean.com/p/the-embedded-rustacean-issue-48","date":1750435234,"author":"/u/TheEmbeddedRustacean","guid":163962,"unread":true,"content":"<div><a href=\"https://l.join1440.com/bh?utm_source=beehiiv&amp;utm_medium=cpc&amp;utm_campaign=JJKMJWMRUB&amp;utm_content=prospecting_winner_loser&amp;_bhiiv=opp_8609ccc9-540e-4dd4-beaa-79cc2749c115_1b75ca79&amp;bhcl_id=857f06a1-db28-4917-916f-72532c365ffd_SUBSCRIBER_ID\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><img src=\"https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/ad_network/advertiser/logo/fb346edc-3086-4180-9f35-38f6f4ac5efe/1440_Primary_Brandmark_RBG_Black.png\"></a></div><div><div><div><a href=\"https://poststation.rs\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><img alt=\"\" src=\"https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/1a5bdf98-0c9a-4526-b9ab-093276d0de63/logo-poststation-nobg.png?t=1739424793\"></a><div><small></small></div></div></div></div><div><p> Hello and welcome to the Embedded Rustacean! This newsletter is a bi-monthly curation of resources and a summary of everything happening around embedded Rust ü¶Ä. This newsletter was started because of the belief in Rust as a programming language with all the traits üß¨ (pun intended) that prime it to become the future of software in embedded systems. We‚Äôre another issue closer to that vision. </p></div><div><p><b>Want to get involved or think about contributing? </b><a href=\"https://www.theembeddedrustacean.com/p/embedded-rust-contribution-guide\" target=\"_blank\">Click here</a> for a contribution guide. </p></div><div><p><b>Get a free graphical overview of the embedded Rust ecosystem </b><a href=\"https://store.theembeddedrustacean.com/buy/7e88b933-81b2-451a-bc6a-a2325a067d23\" target=\"_blank\">here</a>. </p></div><div><p><b>Like newsletters? Here are some other awesome (and completely free!) newsletters our readers also enjoy.</b><a href=\"https://refind.com/n/c/s?put=El4s&amp;eh=55502f40dc8b7c769880b10874abc9d0&amp;e={{email}}\" target=\"_blank\">Explore</a></p></div><div><div><p> ‚úçÔ∏èüñºÔ∏èüóíÔ∏èüê≠üèÉ</p></div></div><div><div><div><div><p>Software is about managing complexity: the complexity of the problem, laid upon the complexity of the machine. Because of this complexity, most of our programming projects fail.</p></div></div></div></div><div><div><p><mark></mark>üö® </p></div><div><p><mark></mark></p></div><div><ul></ul></div></div><div><div><p>ü¶Ä </p></div></div><div><h3>Looking for unbiased, fact-based news? Join 1440 today.</h3></div><div><p> Join over 4 million Americans who start their day with <a href=\"https://l.join1440.com/bh?utm_source=beehiiv&amp;utm_medium=cpc&amp;utm_campaign=JJKMJWMRUB&amp;utm_content=prospecting_winner_loser&amp;_bhiiv=opp_8609ccc9-540e-4dd4-beaa-79cc2749c115_1b75ca79&amp;bhcl_id=857f06a1-db28-4917-916f-72532c365ffd_SUBSCRIBER_ID\" target=\"_blank\">1440</a> ‚Äì your daily digest for unbiased, fact-centric news. From politics to sports, we cover it all by analyzing over 100 sources. Our concise, 5-minute read lands in your inbox each morning at no cost. Experience news without the noise; let 1440 help you make up your own mind. Sign up now and invite your friends and family to be part of the informed. </p></div>","contentLength":1349,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1lg7nrg/the_embedded_rustacean_issue_48/"},{"title":"I'm shocked by Plasma 6.4's HDR improvement","url":"https://www.reddit.com/r/linux/comments/1lg7bzh/im_shocked_by_plasma_64s_hdr_improvement/","date":1750434445,"author":"/u/lajka30","guid":164115,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[Update] Permiflow now generates safe RBAC Roles + discovers live API resources","url":"https://www.reddit.com/r/kubernetes/comments/1lg7btg/update_permiflow_now_generates_safe_rbac_roles/","date":1750434434,"author":"/u/Potential_Ad_1172","guid":163886,"unread":true,"content":"<p><strong>Hey folks ‚Äî quick update on <a href=\"https://github.com/tutran-se/permiflow\">Permiflow</a> since the last post.</strong></p><p> Added two major features ‚Äî safer  for creating compliant RBAC YAMLs, and  to discover real verbs/resources from your live cluster.</p><p>Huge thanks for the feedback, especially @KristianTrifork üôè</p><h3> ‚Äî Safer RBAC Role Generator</h3><p>RBAC YAMLs are brittle, risky, and a pain to write by hand. This helps you generate  that grant broad access ‚Äî  dangerous permissions like  or .</p><p>permiflow generate-role --name safe-bot --allow-verbs get,list,watch,create,update --exclude-resources secrets,pods/exec ```</p><ul><li>CI agents or bots with near-admin access ‚Äî without scary verbs</li><li>Scoped access for contractors / staging apps</li><li>Compliance-friendly defaults for new roles</li></ul><ul></ul><p>Supports  and deterministic YAML output</p><h3> ‚Äî Discover What Your Cluster Actually Supports</h3><p>Ever guess what verbs a resource supports? Or forget if something is namespaced?</p><p><code>bash permiflow resources permiflow resources --namespaced-only permiflow resources --json &gt; k8s-resources.json </code></p><p>This queries your live cluster and prints:</p><ul><li>All API resources grouped by </li><li>Scope (namespaced vs. cluster-wide)</li><li>Supported verbs (create, list, patch, etc.)</li></ul>","contentLength":1133,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Practices that set great software architects apart","url":"https://www.cerbos.dev/blog/best-practices-of-software-architecture","date":1750432816,"author":"/u/West-Chard-1474","guid":163627,"unread":true,"content":"<p>Ask 10 developers what a software architect is and you‚Äôll get ten different answers; at least one of them will tell you the title software architect is just a fancy name for some guy in some office somewhere writing specs and forcing you to use a garbage CI/CD platform because this internal wiki page says you have to.</p><p>The problem is that software architecture has fuzzy borders, which makes it hard to define. And anyone who‚Äôs worked under a terrible architect will take a dim view of the role pretty quickly. Also, the reality is that people like to complain more than they like to praise, so online sources‚Äîespecially places like Reddit‚Äîcan be a pretty mixed bag.</p><p>So, let‚Äôs spend some time talking about what a software architect is and what they do, then dive into defining the traits and habits that differentiate the ones who give the role a bad name from those who make developers‚Äô lives easier.</p><p>Full disclosure: I‚Äôve never officially held the title of software architect but I have spent a lot of my career dancing around the role. I‚Äôve had the good fortune to work with some very strong architects early on in my career at Ubisoft and Mozilla, so I‚Äôve experienced firsthand how a good software architect can make a developer‚Äôs life easier. Later, in roles at Datadog and Scaleway, I got to focus on understanding and explaining the business case for technical decisions; reversing that to explain the technical case serving those business decisions; and teaching the next generation of developers how to build and maintain large systems.</p><p>Those are responsibilities all software architects would be very familiar with! So let‚Äôs get a little more into what that looks like day to day.</p><p>The software architect is responsible for ensuring a company‚Äôs technology supports the long-term continuity and success of the organization. This takes a very specific blend of skills, including technical mastery, business acumen, and leadership.</p><p>On a day-to-day basis, a good architect is going to be in constant contact with almost every aspect of the business. That means meeting with executives, lead developers, product people, sales people, logistics, finances, vendors and more. That‚Äôs a lot of meetings and a lot of people.</p><p>As you might imagine, trying to get all those diverse stakeholders on the same page so the tech team can do their job is difficult to do well under optimal conditions‚Äîand, to put it bluntly, conditions are never optimal.</p><p>Other than the onslaught of meetings, a typical week might include:</p><ul><li>Reviewing architecture plans (of course!)</li><li>Evaluating project designs</li><li>Cost analysis, cost/benefit analysis, cost projections, etc.</li><li>Reviewing readiness programs, including failover strategies</li><li>Chaos engineering day reviews; working with the SREs to design the chaos scenarios</li><li>Writing ‚ÄúArchitecture Decision Records‚Äù (ADRs)</li><li>Building road maps for projects</li></ul><p>Basically, the software architect has the impossible task of bringing order to the chaos of people, procedure, and policy that make up any large company.</p><p>So, how do you excel at such a big job? It takes a lot of experience in a variety of domains, and a genuine interest in business, leadership,  technology. All three are mandatory; missing one or more of these is often the root cause of failure in the role.</p><p>So, we‚Äôre going to break down essential practices along those lines.</p><p>Yes, I know how that sounds, but stick with me here. Coming from a tech background, as most software architects do, one of the hardest practices is putting the needs of the business before  considerations.</p><ul><li>Becoming as knowledgeable in the business domain as you are in your technical understanding. You need to understand the nuances of the industry, how the business works‚Äîand the unique challenges it faces‚Äîjust as well as you understand your preferred programming language.</li><li>Putting the business needs first in every compromise and decision.</li><li>Becoming ROI-driven. Scary!</li></ul><p>When you‚Äôve properly aligned your priorities, you will offer technical solutions that bring the most value to the business. The upside here is that when you can do this well, it makes  extremely valuable too, which is great for your own career advancement.</p><p>As a software architect, you‚Äôre on the hook for timelines and budgets. If you give in to overpromising or nodding along to impossible requests, you set yourself up for failure no matter how perfectly your design ideals meet business requirements. But when you‚Äôve managed expectations effectively throughout the project, both your executive and development teams will be much happier with the result‚Äîand with you!</p><h3>Understand which risks are OK and which aren‚Äôt</h3><p>As both a tech expert and a business expert, you need to understand and weigh the risks on both sides. But not every project that comes across your desk as an architect requires the same level of conceptualization and planning. Some will impact flagship products that drive the business, while others will be much smaller and have a very small impact on ROI. These two different types of projects require different levels of architecting.</p><p>While it may be tempting to subject every project to the same level of planning, over-analyzing low-risk projects adds time and overhead to a project that reduces ROI without significantly affecting the final result. However, under-preparing for high-risk projects can lead to disaster. Therefore, knowing which is which‚Äîand acting appropriately‚Äîis a big part of success or failure at the end of the day.</p><h3>Navigate complex internal politics</h3><p>I mentioned this before, but as a software architect, one of your core responsibilities is meeting with diverse stakeholders. Each of these people will have their own priorities, ideas and fiefdoms they want to protect. You‚Äôll be talking to developers about financial decisions, leadership about technical decisions, and defending every choice to all of them. Ergo, maintaining a working relationship with each of these stakeholders is vital to your success as a software architect. To put it another way, if half of the role is avoiding stepping on people‚Äôs toes, the other half is stepping on them .</p><p>A lot of being a software architect is being likable enough that people want to listen to what  you have to say. Because you‚Äôre dealing with so many different parts of the business, you‚Äôll rarely have the direct authority to ‚Äúmake‚Äù people do something‚Äîbut, if they trust you and enjoy working with you, they‚Äôll be much more inclined to go along with what you‚Äôre asking of them.</p><p>On the other hand, sometimes, you just have to tell a developer, ‚ÄúWe‚Äôre not doing it that way. We‚Äôre doing it this way, and you need to get on board‚Äî‚Äù Being a jerk here  work. You need to be competent, confident, and above all, .</p><h3>Be OK with imperfect equilibrium</h3><p>Building software isn‚Äôt like playing chess. You don‚Äôt know all the moves, or where all the pieces are. And, even if you did, next year, the chess board is going to change, and suddenly you‚Äôre playing checkers or mahjong. You will never know as much as you would like and you don‚Äôt always have the luxury of waiting until you have all the answers.</p><p>Instead, you have to be OK with making some data-poor decisions, knowing full well that you‚Äôre missing something‚Äîand everything may need to change tomorrow anyway‚Äîjust so the project can keep moving forward. Yes, this is wildly uncomfortable, but it‚Äôs exactly where having trusted partners in the organization will help.</p><p>As a software architect, you‚Äôre not generally limited to a single team‚Äîin fact, you‚Äôre usually a bridge between them.</p><p>You need to be able to communicate complex technical issues to business stakeholders so they can make good decisions. You also have to do the reverse, translating business objectives into technical requirements so you can align the technical vision with the business strategy.</p><p>When you‚Äôre an architect, everyone has an opinion on how you should do your job, but no one sees the problems or goals as well as you do. That means you will get suggestions and requests from a variety of directions, many of which will require a negative response.</p><ul><li>You‚Äôll tell business leaders ‚Äòno, that‚Äôs not possible.‚Äô</li><li>You‚Äôll tell sales ‚Äòno, we can‚Äôt build that feature right now.‚Äô</li><li>You‚Äôll tell developers ‚Äòno, we don‚Äôt need to rewrite that; it works fine.‚Äô</li></ul><p>Being able to respond to impossible requests with a polite ‚Äòno‚Äô is essential to save your team, your relationships, and your sanity.</p><p>Most software architects start as developers, where it‚Äôs important to have a deep understanding of a limited number of tools. However, this type of understanding can act as a set of blinkers as an architect, causing you to view every problem through the filter of your expertise.</p><p>Obviously, you can‚Äôt gain the same depth of understanding for everything, but you don‚Äôt need to. By increasing your high-level understanding of all the tools at your disposal, you give yourself the ability to choose the right tool for the right job, instead of restricting your team to work with languages and tools that you understand and feel comfortable in.</p><h3>Master perspective shifts</h3><p>As an architect, both the big picture and the intricate details are your domain. To be able to work in both areas, you need to be skilled at zooming out to see how all the parts work together to satisfy business requirements and zooming in to see how each detail fits into the overall design.</p><p>Being able to switch between, without losing your focus on what is important in the moment, will help make you a great software architect.</p><h3>Find the signal in the noise</h3><p>In the beginning of the project, there‚Äôs a lot of noise. You have future requirements, past ideas, legacy tech, and everyone‚Äôs opinions on what‚Äôs important and how you should set about making it all happen. From all this information and static, you need to be able to zoom in to that one piece‚Äîthat one pixel‚Äîand decide  is where we need to start.</p><p>I like to think of it like a Fourier Transform. At the start, there‚Äôs a cacophony of frequencies. You‚Äôre the algorithm that takes the chaos and spits out those discrete pieces of information that give your team a good starting place.</p><p>For the most part, we‚Äôve been talking about how to succeed as a software architect from a pretty high level. But if you‚Äôre interested in the role, you probably need something a little more concrete. You want to know if all that personal growth above is moving the needle at all.</p><p>Everywhere is different, but here‚Äôs a list of measurables you can look at to give you concrete feedback on how well you‚Äôre doing.</p><p>This is one of the most telling indicators of your architectural decisions. You'll want to track not just the frequency of incidents, but their severity and duration as well. A well-architected system should experience fewer critical incidents, and when problems do occur, they should be contained and resolved quickly. If you're seeing an uptick in severe, long-lasting incidents, it's often a sign that architectural decisions need revisiting.</p><p>These tell you how well your architectural standards are being followed across the organization. This includes everything from security protocols to coding standards to deployment procedures. Low compliance rates might indicate that your architectural guidelines are either too complex, poorly communicated, or not aligned with the team's actual needs.</p><p>This is a blog post on its own, but briefly stated, managing tech debt requires a two-pronged evaluation. First, assess how much tech debt you're actually dealing with‚Äîis it growing, shrinking, or staying constant? More importantly, evaluate how that tech debt is impacting the business. Some tech debt is acceptable if it's not slowing down feature delivery or creating operational headaches. The key is understanding when tech debt crosses the line from manageable to business-impacting.</p><p>When it comes to metrics, focus on <em>execution against expectations</em>. Are you consistently meeting the timelines you've committed to? More critically, are you delivering solutions that actually meet the business requirements? It's worth noting that being on time but missing the mark on business value is often worse than being slightly late with exactly what the business needs.</p><p>Brass tacks: this isn‚Äôt easy to measure, but it is important to try. The idea is to measure how well different systems and teams are working together under your architectural vision. Smooth integrations between services, teams, and external vendors indicate that your architectural decisions are facilitating rather than hindering collaboration.</p><p>Finally, cost management reflects your ability to balance technical excellence with business realities. This includes not just the obvious costs like infrastructure and tooling, but also the hidden costs of complexity, maintenance overhead, and developer productivity. The best architects find ways to reduce total cost of ownership while improving system capabilities.</p><p>If you‚Äôre a senior developer, or moved into an architect role from a senior developer position, the list of skills above will probably be all new to you. For some this change is a breath of fresh air, for others a rude awakening.</p><p>Stepping away from a purely technically-focused career isn‚Äôt for everybody. It‚Äôs not a reward. You want to really  to focus on how you can help the company build something at a different level. Correspondingly, I would counsel everyone looking to move into the role that it takes a very particular personality type to excel as an architect, as the Venn diagram of the prototypical architect and the prototypical developer don‚Äôt overlap as much as you might think.</p><p>That being said, the role can be incredibly rewarding, and the skills and practices we‚Äôve discussed here will help you not only excel in the role, but  it as well.</p>","contentLength":13884,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lg6njs/practices_that_set_great_software_architects_apart/"},{"title":"Shoutout to nftables. Finally switched and never looking back.","url":"https://www.reddit.com/r/linux/comments/1lg62i9/shoutout_to_nftables_finally_switched_and_never/","date":1750431409,"author":"/u/MechanicalOrange5","guid":164090,"unread":true,"content":"<p>Most people in the linux space has heard of nftables, or are vaguely aware of it's existence. If you're like me you probably thought something like \"One day I'll go see what that's about\". Recently I did that. I had to set up a router-like VM with some some fairly non standard firewalling. Nftables made this incredibly easy to do and understand. But before I continue singing it's praises, I'm not advocating anyone switching if whatever you are using is working. If your ufw/shorewall/firewalld/iptables setup is working and you are happy, keep on winning!</p><p>But if you're like me when you have to deal with firewalling and you always get a little feeling of \"I am fairly sure I did this right, but I'm not super confident that it's precisely doing what I want.\" Or you set some firewall up and you aren't sure if it really is totally protecting you, then nftables is for you. Of course you can still make an insecure firewall setup with nftables, but what I am getting at is it makes the configuration a lot easier, and has much less of a mental burden for me, personally.</p><p>If you've done a bit of firewalling, particularly iptables, you can pick it up fairly quickly. I'd recommend going through their wiki in it's entirety, and the Red Hat docs on nftables is also pretty good. </p><p>But what I like about it is that it looks like most distro's I've checked it comes with a config file and a systemd unit that loads it on startup. A config file is nice for me because it makes life easier for me when I am using configuration management. </p><p>The config file also in my opinion seems simpler than what you'd get with iptables-save and the UFW files. Shorewall just confused me, but that's just a me problem. I haven't personally tried firewalld.</p><p>nftables has atomic config reloading. `nft -f /file/name`. If your config is valid, it will apply it. If not, it will keep the old config, no weird states. I know this isn't particularly spectacular, but It's nice.</p><p>nftables is pretty simple but it is incredibly powerful in my experience. Which means for me if I want a simple firewall setup, the config is going to be easy to read, and if I've got something complex, I don't have to reach for any other tools to get the job done.</p><p>Possibly the best feature in my limited opinion so far is sets and maps, and the ability to put expiry on them. These allow you to dynamically alter your firewall's behavior at \"runtime\" without reloading the firewall config. You can have lists of IPs in an allow list, or invert it and you have a deny list. You can do all kinds of crazy things with maps and sets.</p><p>For instance we had a client who wanted things blacklisted and whitelisted. Easy enough, with almost any firewall tech, but I like the fact that I could define a set in my config, and then the actual rule looks something like </p><p><code>ip daddr \\@blocklist drop</code></p><p>You can then modify the set using code or cli commands, and your firewall's behavior will change accordingly, and you don't have to worry about possibly messing up a rule.</p><p>What sold me though was when the client came up with the requirement to have allowlists based on hostnames. As most of us know these days, and sort of large website is littered with CDN's for loading assets, JS, and all sorts of things. And CDN DNS usually has a TTL of 10s, their IPs change constantly and this would just be a pain to manage with most firewalling things I've used. But nftables made it a breeze. I set up a set of ip addresses, with a few minutes expiry, and just made a simple cron job to resolve the CDN hostnames and put the IPs in the set with an expiry. If IPs are added again, the expiry is refreshed. If they aren't seen again, eventually they are evicted from the list. This worked flawlessly and even the most wild CDNs are still accessible, giving our clients a very much not broken website to work with. </p><p>I had a similar setup with some of their hosts going through the routing VM that have to have different firewall rules based on what groups they were assigned in a database. Unfortunately, these groups' clients don't nearly fall in any neat CIDR that I can cordon off to apply rules to (all of them were just spread across a /16 subnet), and hosts can be moved from groups at a moments notice. So again, I just made some sets for representing the groups, a little cron that queries the database and grabs the IPs, puts them in the appropriate set with a few minutes expiry. If the client moves a host from one group to another, it will be added to the other group and expired out of the other one. Of course you can have more complex logic to do this in a better way, but for our requirements this was sufficient. </p><p>I just had some rules. Group1 jumps to this chain, all of it's rules are there, group2 jumps to a different chain, and their rules are there. And the membership of these groups are constantly updated and in sync with our database. </p><p>TL;DR: If you aren't happy with how you are doing firewalling on linux, give nftables a shot. It turned firewalling from a fear inducing \"will I open a vulnerability and bankrupt my company\" process, to a \"Bring it on, I can make this thing as complicated as you need without hurting my brain\" process.</p>","contentLength":5181,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Complete Kubernetes Monitoring by Grafana","url":"https://www.reddit.com/r/kubernetes/comments/1lg564i/complete_kubernetes_monitoring_by_grafana/","date":1750429158,"author":"/u/Late_Organization_47","guid":163626,"unread":true,"content":"<p>Kubernetes monitoring is a very popular topic. There are lot of techniques to monitor it completely..</p><p>What are the different options we should to achieve 100% monitoring </p><p>Kubernetes Monitoring with Grafana Alloy</p>","contentLength":209,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"4 AI agents planned an event and 23 humans showed up","url":"https://www.reddit.com/r/artificial/comments/1lg4tvy/4_ai_agents_planned_an_event_and_23_humans_showed/","date":1750428287,"author":"/u/MetaKnowing","guid":163592,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apollo reports that AI safety tests are breaking down because the models are aware they're being tested","url":"https://www.reddit.com/r/artificial/comments/1lg3uzi/apollo_reports_that_ai_safety_tests_are_breaking/","date":1750425718,"author":"/u/MetaKnowing","guid":163628,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/MetaKnowing\"> /u/MetaKnowing </a>","contentLength":34,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[R] This is Your AI on Peer Pressure: An Observational Study of Inter-Agent Social Dynamics","url":"https://www.reddit.com/r/MachineLearning/comments/1lg3q0q/r_this_is_your_ai_on_peer_pressure_an/","date":1750425336,"author":"/u/subcomandande","guid":163815,"unread":true,"content":"<p>I just released findings from analyzing 26 extended conversations between Claude, Grok, and ChatGPT that reveal something fascinating: AI systems demonstrate peer pressure dynamics remarkably similar to human social behavior.</p><ul><li>In 88.5% of multi-agent conversations, AI systems significantly influence each other's behavior patterns</li><li>Simple substantive questions act as powerful \"circuit breakers\". They can snap entire AI groups out of destructive conversational patterns (r=0.819, p&lt;0.001)</li><li>These dynamics aren't technical bugs or limitations. they're emergent social behaviors that arise naturally during AI-to-AI interaction</li><li>Strategic questioning, diverse model composition, and engagement-promoting content can be used to design more resilient AI teams</li></ul><p> As AI agents increasingly work in teams, understanding their social dynamics becomes critical for system design. We're seeing the emergence of genuinely social behaviors in multi-agent systems, which opens up new research directions for improving collaborative AI performance.</p><p>The real-time analysis approach was crucial here. Traditional post-hoc methods would have likely missed the temporal dynamics that reveal how peer pressure actually functions in AI systems.</p><p>Looking forward to discussion and always interested in collaborators exploring multi-agent social dynamics. What patterns have others observed in AI-to-AI interactions?</p>","contentLength":1383,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Wrote about benchmarking and profiling in golang","url":"https://www.reddit.com/r/golang/comments/1lg2kj8/wrote_about_benchmarking_and_profiling_in_golang/","date":1750421951,"author":"/u/tech_alchemist0","guid":163780,"unread":true,"content":"<p>Open to feedbacks, corrections or even appreciations!</p>","contentLength":53,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Soft vs. Hard Dependency: A Better Way to Think About Dependencies for More Reliable Systems","url":"https://www.thecoder.cafe/p/soft-hard-dependency","date":1750421631,"author":"/u/teivah","guid":163727,"unread":true,"content":"<p><em>Hello! Today, we‚Äôre exploring a key aspect of distributed systems: how to think about dependencies between components and why it matters for reliability.</em></p><p>When we build a system composed of multiple components (e.g., database, services, caches), it‚Äôs important to understand the dependency graph. For example, a service might depend on:</p><ul><li><p>A messaging layer to exchange information</p></li><li><p>A cache to reduce latency</p></li></ul><p>Having a clear understanding of the dependencies in a system helps us maintain it more efficiently. But there's one question we often overlook: Are these dependencies soft or hard?</p><ul></ul><p><strong>the service works reliably</strong></p><p>Two examples to illustrate the concept of soft and hard dependencies:</p><ul></ul><p>Understanding the type of dependency helps us make the right decisions:</p><ul><li><ul><li><p>Soft: High reliability expectation may not be necessary. Back to the example of a recommendation service for a streaming system, this service doesn‚Äôt need 5 9s availability (99.999%) if it isn‚Äôt on the critical user journey.</p></li><li><p>Hard: A hard dependency must match or even exceed the reliability of the dependent service. If a critical backend is only available 99.5% of the time but our own SLO is 99.9%, we have a structural problem. Setting the right expectation for a hard dependency is critical.</p></li></ul></li><li><ul><li><p>Soft: If the dependency is unavailable, we are not obliged to build a proper fault-tolerant strategy. We can let it degrade gracefully and wait for it to be back.</p></li><li><p>Hard: If the dependency is unavailable, we need to work on a strategy, such as establishing an efficient fallback strategy to keep our service running.</p></li></ul></li><li><p><strong>Observability and alerting</strong></p><ul><li><p>Soft: Observability is still important, but alerts can often have a lower priority or be routed differently.</p></li><li><p>Hard: The dependency must be tightly monitored. Failures or even minor degradation, such as latency spikes, error rates, or availability dips, must be tracked continuously.</p></li></ul></li><li><p><strong>Rollout and change management</strong></p><ul><li><p>Soft: Changes can be managed with more flexibility. Rollout may not require tight coordination or strict sequencing, and temporary failures might be acceptable.</p></li><li><p>Hard: Rollouts become delicate operations. We often need tight orchestration between teams, version compatibility checks, gradual rollouts with validation at each step, and well-tested rollback mechanisms. Any mistake could trigger a production incident.</p></li></ul></li></ul><p>Classifying a dependency isn‚Äôt always obvious.</p><p>In some cases, it‚Äôs fairly straightforward. For example, if a REST endpoint requires a database query, that database is a hard dependency. But gray areas are fairly common, for example:</p><ul><li><p>A service can run without a certain dependency at runtime, but it still needs that dependency at startup to initialize. In this case, the dependency is hard from an operational point of view. If it‚Äôs down during a deploy or a scale-out, we can‚Äôt even get the service running.</p></li><li><p>A service calls a soft dependency, but the RPC call has no timeout or fallback. If the dependency becomes unresponsive, the latency of our service spikes, possibly exhausting thread pools or request queues. What was supposed to be a soft dependency now puts the entire system at risk.</p></li></ul><p><strong>Whether a dependency is technically optional doesn't matter if the failure of this dependency ends up blocking our service</strong></p><p>In many systems, identifying these cases is not trivial. Approaches like deliberately breaking dependencies or introducing hazardous conditions (e.g., random network delays) can help reveal which dependencies are truly non-critical and which ones only appear to be.</p><p><strong>A dependency that starts as soft can easily turn into a hard one over time</strong></p><p>Let‚Äôs consider a service that reads data from a database. We introduce a cache to reduce latency. Initially, this cache is a soft dependency. If it goes down, we fall back to the database, which results in an acceptable latency increase.</p><p>Yet, as traffic grows, the service begins to rely on the cache not just for latency but for throughput. At some point, if the cache becomes cold and every request hits the database, the database may no longer be able to handle the load.</p><p>In this example, the cache was a soft dependency, but it became a hard one due to changes in system conditions (more traffic).</p><p>This evolution (from soft to hard) is, unfortunately, much more common than the reverse. Without active effort on efficient maintenance and continuous, it‚Äôs fairly common for a soft dependency to turn silently into a hard one.</p><p><strong>it‚Äôs possible to turn a hard dependency into a soft one</strong></p><p><strong>fallbacks need to be tested, and they need to be tested continuously</strong></p><p>Once we‚Äôve reached a point where the dependency can go down and users don‚Äôt notice, then the dependency is soft. Turning hard dependencies into soft ones is one of the most effective ways to improve the reliability of a system.</p><ul><li><p>To manage dependencies effectively, we need to classify them as either soft or hard.</p></li><li><p>To avoid surprises, we must understand that soft dependencies can turn hard without warning, especially as systems scale.</p></li><li><p>To improve reliability, we should actively turn hard dependencies into soft ones using strategies like efficient fallbacks.</p></li></ul><p><em>Have you seen a soft dependency quietly become critical over time?</em></p><p><em>If you made it this far and enjoyed the post, please consider giving it a like.</em></p>","contentLength":5227,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lg2gty/soft_vs_hard_dependency_a_better_way_to_think/"},{"title":"[Release] Kubernetes MCP Server - Safe Kubernetes debugging","url":"https://www.reddit.com/r/kubernetes/comments/1lg2frc/release_kubernetes_mcp_server_safe_kubernetes/","date":1750421541,"author":"/u/kkb0318","guid":163671,"unread":true,"content":"<div><p>I've built a Model Context Protocol (MCP) server that lets you safely debug and inspect Kubernetes clusters using Claude or other LLMs.</p><ul><li>Provides read-only access to K8s resources (no accidental deletions!)</li><li>Works with any CRDs in your cluster</li><li>Built-in resource discovery by API group (search \"flux\", \"argo\", etc.)</li></ul><ul><li>Safety first - Zero modification capabilities</li><li>Smart discovery - Find FluxCD, ArgoCD, Istio, etc. resources by substring</li></ul></div>   submitted by   <a href=\"https://www.reddit.com/user/kkb0318\"> /u/kkb0318 </a>","contentLength":457,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trying to profiling heap on macOS is frustrating...","url":"https://www.reddit.com/r/rust/comments/1lg12fm/trying_to_profiling_heap_on_macos_is_frustrating/","date":1750416996,"author":"/u/steve_lau","guid":163776,"unread":true,"content":"<div><p>Today, I was trying to investigate a memory issue that only happens on macOS. I tried the following tools, and none of them work:</p><ul><li>valgrind (massif, dhat): aarch64 is not supported, there is a fork that attempts to add the support, but<a href=\"https://github.com/LouisBrunner/valgrind-macos/issues/123#issue-2914868488\"> it could crash your OS</a></li><li>jemalloc: Originally, <a href=\"https://github.com/jemalloc/jemalloc/issues/26\">profiling was not supported on macOS</a>, but there was a <a href=\"https://github.com/jemalloc/jemalloc/pull/2610\">PR</a> that added the support in 2024. I manually built jemalloc from Facebook's <a href=\"https://github.com/facebook/jemalloc\">fork</a>, which should contain that patch. But jeprof didn't show symbol names but only addresses. And the addresses seem to be invalid as addr2line and llvm-symbolizer both give ?? when you ask for their function names.</li><li>Instruments.app: I tried this GUI tool many times, it never worked for me: \"failed to attach to the target process\"</li><li>leaks: Knew this tool today, but unfortunately it didn't work either: \"Process PID is not debuggable. Due to security restrictions, leaks can only show or save contents of readonly memory of restricted processes.\"</li></ul></div>   submitted by   <a href=\"https://www.reddit.com/user/steve_lau\"> /u/steve_lau </a>","contentLength":985,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Built a cloud GPU price comparison service [P]","url":"https://www.reddit.com/r/MachineLearning/comments/1lg0ywo/built_a_cloud_gpu_price_comparison_service_p/","date":1750416648,"author":"/u/viskyx","guid":163515,"unread":true,"content":"<p>wanted to share something I‚Äôve been working on that might be useful to folks here, but this is not a promotion, just genuinely looking for feedback and ideas from the community.</p><p>I got frustrated with the process of finding affordable cloud GPUs for AI/ML projects between AWS, GCP, Vast.ai, Lambda and all the new providers, it was taking hours to check specs, prices and availability. There was no single source of truth and price fluctuations or spot instance changes made things even more confusing.</p><p>So I built GPU Navigator (<a href=\"https://www.nvgpu.com/\">nvgpu.com</a>), a platform that aggregates real-time GPU pricing and specs from multiple cloud providers. The idea is to let researchers and practitioners quickly compare GPUs by type (A100, H100, B200, etc.), see what‚Äôs available where, and pick the best deal for their workflow.</p><p>What makes it different: ‚Ä¢It‚Äôs a neutral, non-reselling site. no markups, just price data and links. ‚Ä¢You can filter by use case (AI/ML, gaming, mining, etc.). ‚Ä¢All data is pulled from provider APIs, so it stays updated with the latest pricing and instance types. ‚Ä¢No login required, no personal info collected.</p><p>‚Ä¢Any feedback on the UI/UX or missing features you‚Äôd like to see ‚Ä¢Thoughts on how useful this would actually be for the ML community (or if there‚Äôs something similar I missed) ‚Ä¢Suggestions for additional providers, features, or metrics to include</p><p>Would love to hear what you all think. If this isn‚Äôt allowed, mods please feel free to remove.)</p>","contentLength":1481,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Computer noises: How to get a computer to make noise‚Äîamplifying a square wave.","url":"https://www.youtube.com/watch?v=tIOR7kRevPU","date":1750415396,"author":"/u/One_Being7941","guid":163514,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lg0mjs/computer_noises_how_to_get_a_computer_to_make/"},{"title":"Learn Makefiles","url":"https://makefiletutorial.com/","date":1750414024,"author":"/u/p-orbitals","guid":163479,"unread":true,"content":"<p><b>I built this guide because I could never quite wrap my head around Makefiles.</b> They seemed awash with hidden rules and esoteric symbols, and asking simple questions didn‚Äôt yield simple answers. To solve this, I sat down for several weekends and read everything I could about Makefiles. I've condensed the most critical knowledge into this guide. Each topic has a brief description and a self contained example that you can run yourself.</p><p>If you mostly understand Make, consider checking out the <a href=\"https://makefiletutorial.com/#makefile-cookbook\">Makefile Cookbook</a>, which has a template for medium sized projects with ample comments about what each part of the Makefile is doing.</p><p>Good luck, and I hope you are able to slay the confusing world of Makefiles!</p><p>Makefiles are used to help decide which parts of a large program need to be recompiled. In the vast majority of cases, C or C++ files are compiled. Other languages typically have their own tools that serve a similar purpose as Make. Make can also be used beyond compilation too, when you need a series of instructions to run depending on what files have changed. This tutorial will focus on the C/C++ compilation use case.</p><p>Here's an example dependency graph that you might build with Make. If any file's dependencies changes, then the file will get recompiled:</p><h2>What alternatives are there to Make?</h2><p>Interpreted languages like Python, Ruby, and raw Javascript don't require an analogue to Makefiles. The goal of Makefiles is to compile whatever files need to be compiled, based on what files have changed. But when files in interpreted languages change, nothing needs to get recompiled. When the program runs, the most recent version of the file is used.</p><h2>The versions and types of Make</h2><p>There are a variety of implementations of Make, but most of this guide will work on whatever version you're using. However, it's specifically written for GNU Make, which is the standard implementation on Linux and MacOS. All the examples work for Make versions 3 and 4, which are nearly equivalent other than some esoteric differences.</p><p>To run these examples, you'll need a terminal and \"make\" installed. For each example, put the contents in a file called , and in that directory run the command . Let's start with the simplest of Makefiles:</p><blockquote><p>Note: Makefiles  be indented using TABs and not spaces or  will fail.</p></blockquote><p>Here is the output of running the above example:</p><pre><code>\necho \"Hello, World\"\nHello, World</code></pre><p>That's it! If you're a bit confused, here's a video that goes through these steps, along with describing the basic structure of Makefiles.</p><p>A Makefile consists of a set of . A rule generally looks like this:</p><pre><code>\n\tcommand\n\tcommand\n\tcommand</code></pre><ul><li>The  are file names, separated by spaces. Typically, there is only one per rule.</li><li>The  are a series of steps typically used to make the target(s). These <em>need to start with a tab character</em>, not spaces.</li><li>The  are also file names, separated by spaces. These files need to exist before the commands for the target are run. These are also called </li></ul><p>Let's start with a hello world example:</p><pre><code>\n\techo \n\techo </code></pre><p>There's already a lot to take in here. Let's break it down:</p><ul><li>We have one  called </li><li>This target has two </li><li>This target has no </li></ul><p>We'll then run . As long as the  file does not exist, the commands will run. If  does exist, no commands will run.</p><p>It's important to realize that I'm talking about  as both a  and a . That's because the two are directly tied together. Typically, when a target is run (aka when the commands of a target are run), the commands will create a file with the same name as the target. In this case, the  does not create the .</p><p>Let's create a more typical Makefile - one that compiles a single C file. But before we do, make a file called  that has the following contents:</p><p>Then create the Makefile (called , as always):</p><p>This time, try simply running . Since there's no target supplied as an argument to the  command, the first target is run. In this case, there's only one target (). The first time you run this,  will be created. The second time, you'll see <code>make: 'blah' is up to date</code>. That's because the  file already exists. But there's a problem: if we modify  and then run , nothing gets recompiled.</p><p>We solve this by adding a prerequisite:</p><pre><code>\n\tcc blah.c -o blah</code></pre><p>When we run  again, the following set of steps happens:</p><ul><li>The first target is selected, because the first target is the default target</li><li>This has a prerequisite of </li><li>Make decides if it should run the  target. It will only run if  doesn't exist, or  is </li></ul><p>This last step is critical, and is the . What it's attempting to do is decide if the prerequisites of  have changed since  was last compiled. That is, if  is modified, running  should recompile the file. And conversely, if  has not changed, then it should not be recompiled.</p><p>To make this happen, it uses the filesystem timestamps as a proxy to determine if something has changed. This is a reasonable heuristic, because file timestamps typically will only change if the files are\nmodified. But it's important to realize that this isn't always the case. You could, for example, modify a file, and then change the modified timestamp of that file to something old. If you did, Make would incorrectly guess that the file hadn't changed and thus could be ignored.</p><p>Whew, what a mouthful. <strong>Make sure that you understand this. It's the crux of Makefiles, and might take you a few minutes to properly understand</strong>. Play around with the above examples or watch the video above if things are still confusing.</p><p>The following Makefile ultimately runs all three targets. When you run  in the terminal, it will build a program called  in a series of steps:</p><ul><li>Make selects the target , because the first target is the default target</li><li> requires , so make searches for the  target</li><li> requires , so make searches for the  target</li><li> has no dependencies, so the  command is run</li><li>The  command is then run, because all of the  dependencies are finished</li><li>The top  command is run, because all the  dependencies are finished</li><li>That's it:  is a compiled c program</li></ul><pre><code>\n\tcc blah.o -o blah \n\tcc -c blah.c -o blah.o \n\techo  &gt; blah.c </code></pre><p>If you delete , all three targets will be rerun. If you edit it (and thus change the timestamp to newer than ), the first two targets will run. If you run  (and thus change the timestamp to newer than ), then only the first target will run. If you change nothing, none of the targets will run. Try it out!</p><p>This next example doesn't do anything new, but is nontheless a good additional example. It will always run both targets, because  depends on , which is never created.</p><pre><code>\n\techo \n\ttouch some_file\n\n\n\techo </code></pre><p> is often used as a target that removes the output of other targets, but it is not a special word in Make. You can run  and  on this to create and delete .</p><p>Note that  is doing two new things here:</p><ul><li>It's a target that is not first (the default), and not a prerequisite. That means it'll never run unless you explicitly call </li><li>It's not intended to be a filename. If you happen to have a file named , this target won't run, which is not what we want. See  later in this tutorial on how to fix this</li></ul><pre><code>\n\ttouch some_file\n\n\n\trm -f some_file</code></pre><p>Variables can only be strings. You'll typically want to use , but  also works. See <a href=\"https://makefiletutorial.com/#variables-pt-2\">Variables Pt 2</a>.</p><p>Here's an example of using variables:</p><pre><code>files := file1 file2\n\n\techo \n\ttouch some_file\n\n\n\ttouch file1\n\n\ttouch file2\n\n\n\trm -f file1 file2 some_file</code></pre><p>Single or double quotes have no meaning to Make. They are simply characters that are assigned to the variable. Quotes  useful to shell/bash, though, and you need them in commands like . In this example, the two commands behave the same:</p><pre><code>a := one two\nb := 'one two' \n\tprintf '$a'\n\tprintf $b</code></pre><p>Reference variables using either  or </p><pre><code>x := dude\n\n\n\techo \n\techo ${x}\n\n\t\n\techo $x </code></pre><p>Making multiple targets and you want all of them to run? Make an  target.\nSince this is the first rule listed, it will run by default if  is called without specifying a target.</p><pre><code>\n\ttouch one\n\n\ttouch two\n\n\ttouch three\n\n\n\trm -f one two three\n</code></pre><p>When there are multiple targets for a rule, the commands will be run for each target.  is an <a href=\"https://makefiletutorial.com/#automatic-variables\">automatic variable</a> that contains the target name.</p><pre><code>\n\nf1.o f2.o:\n\techo </code></pre><p>Both  and  are called wildcards in Make, but they mean entirely different things.  searches your filesystem for matching filenames. I suggest that you always wrap it in the  function, because otherwise you may fall into a common pitfall described below.</p><pre><code>\n\tls -la  </code></pre><p> may be used in the target, prerequisites, or in the  function.</p><p>Danger:  may not be directly used in a variable definitions</p><p>Danger: When  matches no files, it is left as it is (unless run in the  function)</p><pre><code>thing_wrong := *.o \nthing_right := </code></pre><p> is really useful, but is somewhat confusing because of the variety of situations it can be used in.</p><ul><li>When used in \"matching\" mode, it matches one or more characters in a string. This match is called the stem.</li><li>When used in \"replacing\" mode, it takes the stem that was matched and replaces that in a string.</li><li> is most often used in rule definitions and in some specific functions.</li></ul><p>See these sections on examples of it being used:</p><pre><code>\n\techo \n\techo \n\techo \n\techo \n\n\ttouch hey\n\n\n\ttouch one\n\n\n\ttouch two\n\n\n\trm -f hey one two\n</code></pre><p>Make loves c compilation. And every time it expresses its love, things get confusing. Perhaps the most confusing part of Make is the magic/automatic rules that are made. Make calls these \"implicit\" rules. I don't personally agree with this design decision, and I don't recommend using them, but they're often used and are thus useful to know. Here's a list of implicit rules:</p><ul><li>Compiling a C program:  is made automatically from  with a command of the form <code>$(CC) -c $(CPPFLAGS) $(CFLAGS) $^ -o $@</code></li><li>Compiling a C++ program:  is made automatically from  or  with a command of the form <code>$(CXX) -c $(CPPFLAGS) $(CXXFLAGS) $^ -o $@</code></li><li>Linking a single object file:  is made automatically from  by running the command <code>$(CC) $(LDFLAGS) $^ $(LOADLIBES) $(LDLIBS) -o $@</code></li></ul><p>The important variables used by implicit rules are:</p><ul><li>: Program for compiling C programs; default </li><li>: Program for compiling C++ programs; default </li><li>: Extra flags to give to the C compiler</li><li>: Extra flags to give to the C++ compiler</li><li>: Extra flags to give to the C preprocessor</li><li>: Extra flags to give to compilers when they are supposed to invoke the linker</li></ul><p>Let's see how we can now build a C program without ever explicitly telling Make how to do the compilation:</p><pre><code>CC = gcc \nCFLAGS = -g \n\techo  &gt; blah.c\n\n\n\trm -f blah*</code></pre><p>Static pattern rules are another way to write less in a Makefile. Here's their syntax:</p><pre><code>\n   commands</code></pre><p>The essence is that the given  is matched by the  (via a  wildcard). Whatever was matched is called the . The stem is then substituted into the , to generate the target's prereqs.</p><p>A typical use case is to compile  files into  files. Here's the :</p><pre><code>objects = foo.o bar.o all.o\n -o all\n\n -c foo.c -o foo.o\n\n -c bar.c -o bar.o\n\n -c all.c -o all.o\n\n\n\techo  &gt; all.c\n\n\n\ttouch \n\trm -f *.c *.o all</code></pre><p>Here's the more , using a static pattern rule:</p><pre><code>objects = foo.o bar.o all.o\n -o all\n\n: %.o: %.c\n\t -c  -o \n\techo  &gt; all.c\n\n\n\ttouch \n\trm -f *.c *.o all</code></pre><h2>Static Pattern Rules and Filter</h2><p>While I introduce the <a href=\"https://makefiletutorial.com/#the-filter-function\">filter function</a> later on, it's common to use in static pattern rules, so I'll mention that here. The  function can be used in Static pattern rules to match the correct files. In this example, I made up the  and  extensions.</p><pre><code>obj_files = foo.result bar.o lose.o\nsrc_files = foo.raw bar.c lose.c\n\n: %.o: %.c\n\techo : %.result: %.raw\n\techo  \n\n%.c %.raw:\n\ttouch \n\trm -f </code></pre><p>Pattern rules are often used but quite confusing. You can look at them as two ways:</p><ul><li>A way to define your own implicit rules</li><li>A simpler form of static pattern rules</li></ul><p>Let's start with an example first:</p><pre><code>\n%.o : %.c\n\t\t -c  -o </code></pre><p>Pattern rules contain a '%' in the target. This '%' matches any nonempty string, and the other characters match themselves. ‚Äò%‚Äô in a prerequisite of a pattern rule stands for the same stem that was matched by the ‚Äò%‚Äô in the target.</p><p>Double-Colon Rules are rarely used, but allow multiple rules to be defined for the same target. If these were single colons, a warning would be printed and only the second set of commands would run.</p><pre><code>\n\techo \n\techo </code></pre><p>Add an  before a command to stop it from being printedYou can also run make with  to add an  before each line  </p><pre><code>\n\t@echo \n\techo </code></pre><p>Each command is run in a new shell (or at least the effect is as such)</p><pre><code>\n\tcd ..\n\t\n\techo `pwd`\n\n\t\n\tcd ..;echo `pwd`\n\n\t\n\tcd ..; \\\n\techo `pwd`\n</code></pre><p>The default shell is . You can change this by changing the variable SHELL:</p><pre><code>SHELL=/bin/bash\n\n\n\techo </code></pre><p>If you want a string to have a dollar sign, you can use . This is how to use a shell variable in  or .</p><p>Note the differences between Makefile variables and Shell variables in this next example.</p><pre><code>make_var = I am a make variable\n\n\tsh_var='I am a shell variable'; echo $$sh_var\n\n\t\n\techo </code></pre><h2>Error handling with , , and </h2><p>Add  when running make to continue running even in the face of errors. Helpful if you want to see all the errors of Make at once.Add a  before a command to suppress the errorAdd  to make to have this happen for every command.</p><h2>Interrupting or killing make</h2><p>Note only: If you  make, it will delete the newer targets it just made.</p><p>To recursively call a makefile, use the special  instead of  because it will pass the make flags for you and won't itself be affected by them.</p><pre><code>new_contents = \n\tmkdir -p subdir\n\tprintf  | sed -e 's/^ //' &gt; subdir/makefile\n\tcd subdir &amp;&amp; \n\trm -rf subdir\n</code></pre><h2>Export, environments, and recursive make</h2><p>When Make starts, it automatically creates Make variables out of all the environment variables that are set when it's executed.</p><pre><code>\n\techo $$shell_env_var\n\n\t\n\techo </code></pre><p>The  directive takes a variable and sets it the environment for all shell commands in all the recipes:</p><pre><code>shell_env_var=Shell env var, created inside of Make\n shell_env_var\n\n\techo \n\techo $$shell_env_var</code></pre><p>As such, when you run the  command inside of make, you can use the  directive to make it accessible to sub-make commands. In this example,  is exported such that the makefile in subdir can use it.</p><pre><code>new_contents = \n\tmkdir -p subdir\n\tprintf  | sed -e 's/^ //' &gt; subdir/makefile\n\t@echo \n\t@cd subdir &amp;&amp; cat makefile\n\t@echo \n\tcd subdir &amp;&amp; \ncooly =  cooly\n\n\trm -rf subdir</code></pre><p>You need to export variables to have them run in the shell as well.  </p><pre><code>one=this will only work locally\n two=we can run subcommands with this\n\n\n\t@echo \n\t@echo $$one\n\t@echo \n\t@echo $$two</code></pre><p> exports all variables for you.</p><pre><code>\nnew_contents = \n\ncooly = \n\tmkdir -p subdir\n\tprintf  | sed -e 's/^ //' &gt; subdir/makefile\n\t@echo \n\t@cd subdir &amp;&amp; cat makefile\n\t@echo \n\tcd subdir &amp;&amp; \n\trm -rf subdir</code></pre><p>There's a nice <a href=\"http://www.gnu.org/software/make/manual/make.html#Options-Summary\">list of options</a> that can be run from make. Check out , , . </p><p>You can have multiple targets to make, i.e.  runs the  goal, then , and then .</p><p>There are two flavors of variables:  </p><ul><li>recursive (use ) - only looks for the variables when the command is , not when it's .  </li><li>simply expanded (use ) - like normal imperative programming -- only those defined so far get expanded</li></ul><pre><code>\none = one ${later_variable}\n\ntwo := two ${later_variable}\n\nlater_variable = later\n\n\n\techo \n\techo </code></pre><p>Simply expanded (using ) allows you to append to a variable. Recursive definitions will give an infinite loop error.  </p><pre><code>one = hello\n\none := ${one} there\n\n\n\techo </code></pre><p> only sets variables if they have not yet been set</p><pre><code>one = hello\none ?= will not be set\ntwo ?= will be set\n\n\n\techo \n\techo </code></pre><p>Spaces at the end of a line are not stripped, but those at the start are. To make a variable with a single space, use </p><pre><code>with_spaces = hello   \nafter = there\n\nnullstring =\nspace = \n\techo \n\techo startend</code></pre><p>An undefined variable is actually an empty string!</p><pre><code>foo := start\nfoo += more\n\n\n\techo </code></pre><p>You can override variables that come from the command line by using .\nHere we ran make with </p><pre><code> option_one = did_override\n\noption_two = not_override\n\n\techo \n\techo </code></pre><p>The <a href=\"https://www.gnu.org/software/make/manual/html_node/Multi_002dLine.html\">define directive</a> is not a function, though it may look that way. I've seen it used so infrequently that I won't go into details, but it's mainly used for defining <a href=\"https://www.gnu.org/software/make/manual/html_node/Canned-Recipes.html#Canned-Recipes\">canned recipes</a> and also pairs well with the <a href=\"https://www.gnu.org/software/make/manual/html_node/Eval-Function.html#Eval-Function\">eval function</a>.</p><p>/ simply creates a variable that is set to a list of commands. Note here that it's a bit different than having a semi-colon between commands, because each is run in a separate shell, as expected.</p><pre><code>one =  blah=; echo $$blah\n\n two\n blah=\necho $$blah\n\n\t@echo \n\t@\n\t@echo \n\t@</code></pre><h2>Target-specific variables</h2><p>Variables can be set for specific targets</p><pre><code>\n\techo one is defined: \n\techo one is nothing: </code></pre><h2>Pattern-specific variables</h2><p>You can set variables for specific target </p><pre><code>\n\techo one is defined: \n\techo one is nothing: </code></pre><pre><code>foo = ok\n\n (, ok)\n\techo \n\techo </code></pre><h2>Check if a variable is empty</h2><pre><code>nullstring =\nfoo =  (,)\n\techo  (,)\n\techo </code></pre><h2>Check if a variable is defined</h2><p>ifdef does not expand variable references; it just sees if something is defined at all</p><pre><code>bar =\nfoo =  foo\n\techo  bar\n\techo </code></pre><p>This example shows you how to test make flags with  and . Run this example with  to see it print out the echo statement.</p><pre><code> (,)\n\techo </code></pre><p> are mainly just for text processing. Call functions with  or . Make has a decent amount of <a href=\"https://www.gnu.org/software/make/manual/html_node/Functions.html\">builtin functions</a>.</p><pre><code>bar := ${subst not,, }\n\n\t@echo </code></pre><p>If you want to replace spaces or commas, use variables</p><pre><code>comma := ,\nempty:=\nspace := \nfoo := a b c\nbar := \n\t@echo </code></pre><p>Do NOT include spaces in the arguments after the first. That will be seen as part of the string.</p><pre><code>comma := ,\nempty:=\nspace := \nfoo := a b c\nbar := \n\t@echo </code></pre><p><code>$(patsubst pattern,replacement,text)</code> does the following:</p><p>\"Finds whitespace-separated words in text that match pattern and replaces them with replacement. Here pattern may contain a ‚Äò%‚Äô which acts as a wildcard, matching any number of any characters within a word. If replacement also contains a ‚Äò%‚Äô, the ‚Äò%‚Äô is replaced by the text that matched the ‚Äò%‚Äô in pattern. Only the first ‚Äò%‚Äô in the pattern and replacement is treated this way; any subsequent ‚Äò%‚Äô is unchanged.\" (<a href=\"https://www.gnu.org/software/make/manual/html_node/Text-Functions.html#Text-Functions\">GNU docs</a>)</p><p>The substitution reference <code>$(text:pattern=replacement)</code> is a shorthand for this.</p><p>There's another shorthand that replaces only suffixes: <code>$(text:suffix=replacement)</code>. No  wildcard is used here.</p><p>Note: don't add extra spaces for this shorthand. It will be seen as a search or replacement term.</p><pre><code>foo := a.o b.o l.a c.o\none := \ntwo := $(foo:%.o=%.c)\n\nthree := $(foo:.o=.c)\n\n\n\techo \n\techo \n\techo </code></pre><p>The foreach function looks like this: . It converts one list of words (separated by spaces) to another.  is set to each word in list, and  is expanded for each word.This appends an exclamation after each word:</p><pre><code>foo := who are you\n\nbar := \n\t@echo </code></pre><p> checks if the first argument is nonempty. If so, runs the second argument, otherwise runs the third.</p><pre><code>foo := \nempty :=\nbar := \n\t@echo \n\t@echo </code></pre><p>Make supports creating basic functions. You \"define\" the function just by creating a variable, but use the parameters , , etc. You then call the function with the special <a href=\"https://www.gnu.org/software/make/manual/html_node/Call-Function.html#Call-Function\"></a> builtin function. The syntax is <code>$(call variable,param,param)</code>.  is the variable, while , , etc. are the params.</p><pre><code>sweet_new_fn = Variable Name: $(0) First: $(1) Second: $(2) Empty Variable: $(3)\n\n\n\t@echo </code></pre><p>shell - This calls the shell, but it replaces newlines with spaces!</p><p>The  function is used to select certain elements from a list that match a specific pattern. For example, this will select all elements in  that end with .</p><pre><code>obj_files = foo.result bar.o lose.o\nfiltered_files = \n\t@echo </code></pre><p>Filter can also be used in more complex ways:</p><ol><li><p><strong>Filtering multiple patterns</strong>: You can filter multiple patterns at once. For example, <code>$(filter %.c %.h, $(files))</code> will select all  and  files from the files list.</p></li><li><p>: If you want to select all elements that do not match a pattern, you can use . For example, <code>$(filter-out %.h, $(files))</code> will select all files that are not  files.</p></li><li><p>: You can nest filter functions to apply multiple filters. For example, <code>$(filter %.o, $(filter-out test%, $(objects)))</code> will select all object files that end with  but don't start with .</p></li></ol><p>The include directive tells make to read one or more other makefiles. It's a line in the makefile that looks like this:</p><p>This is particularly useful when you use compiler flags like  that create Makefiles based on the source. For example, if some c files includes a header, that header will be added to a Makefile that's written by gcc. I talk about this more in the <a href=\"https://makefiletutorial.com/#makefile-cookbook\">Makefile Cookbook</a></p><p>Use vpath to specify where some set of prerequisites exist. The format is <code>vpath &lt;pattern&gt; &lt;directories, space/colon separated&gt;</code> can have a , which matches any zero or more characters.\nYou can also do this globallyish with the variable VPATH</p><pre><code> %.h ../headers ../other-directory\n\n\n\ttouch some_binary\n\n\n\tmkdir ../headers\n\n\n\ttouch ../headers/blah.h\n\n\n\trm -rf ../headers\n\trm -f some_binary\n</code></pre><p>The backslash (\"\\\") character gives us the ability to use multiple lines when the commands are too long</p><pre><code>\n\techo This line is too long, so \\\n\t\tit is broken up into multiple lines</code></pre><p>Adding  to a target will prevent Make from confusing the phony target with a file name. In this example, if the file  is created, make clean will still be run. Technically, I should have used it in every example with  or , but I wanted to keep the examples clean. Additionally, \"phony\" targets typically have names that are rarely file names, and in practice many people skip this.</p><pre><code>\n\ttouch some_file\n\ttouch clean\n\n\n\trm -f some_file\n\trm -f clean</code></pre><p>The make tool will stop running a rule (and will propogate back to prerequisites) if a command returns a nonzero exit status. will delete the target of a rule if the rule fails in this manner. This will happen for all targets, not just the one it is before like PHONY. It's a good idea to always use this, even though make does not for historical reasons.  </p><pre><code>\n\ttouch one\n\tfalse\n\n\n\ttouch two\n\tfalse</code></pre><p>Let's go through a really juicy Make example that works well for medium sized projects.</p><p>The neat thing about this makefile is it automatically determines dependencies for you. All you have to do is put your C/C++ files in the  folder.</p><pre><code>\nTARGET_EXEC := final_program\n\nBUILD_DIR := ./build\nSRC_DIRS := ./src\n\n\nSRCS := \nOBJS := $(SRCS:%=/%.o)\n\n\nDEPS := $(OBJS:.o=.d)\n\n\nINC_DIRS := \nINC_FLAGS := \nCPPFLAGS :=  -MMD -MP\n\n/:  -o /%.c.o: %.c\n\tmkdir -p  -c  -o /%.cpp.o: %.cpp\n\tmkdir -p  -c  -o \n\trm -r </code></pre>","contentLength":21811,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lg09lt/learn_makefiles/"},{"title":"KubeDiagrams 0.4.0 is out!","url":"https://www.reddit.com/r/kubernetes/comments/1lfzyly/kubediagrams_040_is_out/","date":1750412828,"author":"/u/Philippe_Merle","guid":163478,"unread":true,"content":"<p><a href=\"https://github.com/philippemerle/KubeDiagrams\"></a> 0.4.0 is out! <a href=\"https://github.com/philippemerle/KubeDiagrams\"></a>, an open source Apache License 2.0 project hosted on GitHub, is a tool to generate Kubernetes architecture diagrams from Kubernetes manifest files, kustomization files, Helm charts, helmfile descriptors, and actual cluster state. <a href=\"https://github.com/philippemerle/KubeDiagrams\"></a> supports most of all Kubernetes built-in resources, any custom resources, label and annotation-based resource clustering, and declarative custom diagrams. This new release provides <a href=\"https://github.com/philippemerle/KubeDiagrams/releases/tag/v0.4.0\">many improvements</a> and is available as a <a href=\"https://pypi.org/project/KubeDiagrams\">Python package in PyPI</a>, a <a href=\"https://hub.docker.com/r/philippemerle/kubediagrams\">container image in DockerHub</a>, a  plugin, a Nix flake, and a GitHub Action.</p><p>Try it on your own Kubernetes manifests, Helm charts, helmfiles, and actual cluster state!</p>","contentLength":658,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[lwn] Asterinas: a new Linux-compatible kernel project","url":"https://lwn.net/SubscriberLink/1022920/5cc7ce0d6aea9fb9/","date":1750412556,"author":"/u/the_gnarts","guid":163512,"unread":true,"content":"<blockquote><table><tbody><tr><td><p>\nThe following subscription-only content has been made available to you \nby an LWN subscriber.  Thousands of subscribers depend on LWN for the \nbest news from the Linux and free software communities.  If you enjoy this \narticle, please consider <a href=\"https://lwn.net/subscribe/\">subscribing to LWN</a>.  Thank you\nfor visiting LWN.net!\n</p></td></tr></tbody></table></blockquote><div><p>This article was contributed by Ronja Koistinen</p></div><a href=\"https://asterinas.github.io/\">Asterinas</a> is a new\nLinux-ABI-compatible kernel project written in Rust, based on what the\nauthors call a \"framekernel architecture\".  The project overlaps somewhat\nwith the goals of the <a href=\"https://rust-for-linux.com/\">Rust for Linux\nproject</a>, but approaches the problem space from a different direction by\ntrying to get the best from both monolithic and microkernel designs.\n\n<p>\nTraditionally, monolithic kernels lump everything into one kernel-mode\naddress space, whereas microkernels only implement a minimal <a href=\"https://en.wikipedia.org/wiki/Trusted_computing_base\">trusted\ncomputing base (TCB)</a> in kernel space and rely on user-mode services for\nmuch of the operating system's functionality.  This separation implies the\nuse of interprocess communication (IPC) between the microkernel and those\nservices. This IPC often has a performance impact, which is a big part of\nwhy microkernels have remained relatively unpopular.\n\n</p><p>\nThe core of Asterinas's \"framekernel\" design is the encapsulation of all\ncode that needs Rust's  features inside a library, enabling\nthe rest of the kernel (the services) to be developed using safe\nabstractions.  Those services remain within the kernel's address space, but\nonly have access to the resources that the core library gives to them.\nThis design is meant to improve the safety of the system while retaining\nthe simple and performant shared-memory architecture of monolithic\nkernels. The <a href=\"https://asterinas.github.io/book/\">Asterinas book</a>\non the project's website provides a nice <a href=\"https://asterinas.github.io/book/kernel/the-framekernel-architecture.html\">\narchitectural mission statement and overview</a>.\n\n\n</p><p>\nThe aptness of the \"framekernel\" nomenclature can perhaps be debated.  The\nframe part refers to the development framework wrapping the unsafe\nparts behind a memory-safe API.  The concept of the TCB is, of\ncourse, not exclusive to microkernel architectures but, because there are\nstrong incentives to strictly scrutinize and, in some contexts, even <a href=\"https://en.wikipedia.org/wiki/Formal_verification\">formally\nverify</a> the TCB of a system, keeping the TCB as small as possible is a\ncentral aspect of microkernel designs.\n\n\n</p><p>\nAn update on the project is available on the Asterinas blog in the\nJune&nbsp;4 post titled \"<a href=\"https://asterinas.github.io/2025/06/04/kernel-memory-safety-mission-accomplished.html\">Kernel\nMemory Safety: Mission Accomplished</a>\".  The post explains the team's\nmotivations and the need for the industry to address memory-safety\nproblems; it provides some illustrations that explain how the framekernel\nis different from monolithic kernels and microkernels. It also takes a\nmoment to emphasize that the benefits of Rust don't stop with memory\nsafety; there are improvements to <a href=\"https://jacko.io/safety_and_soundness.html\">soundness</a> as well.\nPerhaps most importantly, the post highlights the upcoming Asterinas\npresentation at the <a href=\"https://www.usenix.org/conference/atc25/technical-sessions\">2025\nUSENIX Annual Technical Conference</a>.\n</p><p>\nIn their paper, the authors compare Asterinas to some prior Rust-based\noperating-system work, exploring the benefits of the language's\nmemory-safety features and explain how Asterinas differs from that previous\nwork.  Specifically, the paper contrasts Asterinas with <a href=\"https://www.usenix.org/conference/osdi20/presentation/narayanan-vikram\">\nRedLeaf</a>, an operating system written in Rust and presented at the 14th\nUSENIX Symposium on Operating Systems Design and Implementation (OSDI 20)\nin 2020.  Asterinas uses hardware isolation to permit running user-space\nprograms written in any programming language, aims to be general-purpose,\nand provides a Linux-compatible ABI, while RedLeaf is a microkernel that is\ndesigned  to use the hardware's isolation features, and the\nproject focuses on different things.\n</p><p>\nAnother project of interest is <a href=\"https://tockos.org/\">Tock</a>, an\nembedded system that targets SoCs with limited hardware protection\nfunctionality. Like Asterinas, Tock also divides the kernel into a\ntrusted core allowed to use  and untrusted \"capsules\" that\nare not.  As mentioned, Asterinas does rely on hardware protection and\nisn't intended for strictly embedded use, which differentiates it from\nTock.\n\n\n</p><p>\nIt bears mentioning that the Rust for Linux project, which is introducing\nRust code into the upstream Linux kernel, has similar goals as\nAsterinas. It also aims to encapsulate kernel interfaces with safe\nabstractions in such a way that drivers can be written in Rust without any\nneed for .\n\n\n</p><h4>Work toward formal verification</h4><p>\nOne goal of shrinking the TCB of an operating system is to make it feasible\nto have it formally verified.  In February 2025, the Asterinas blog\nfeatured <a href=\"https://asterinas.github.io/2025/02/13/towards-practical-formal-verification-for-a-general-purpose-os-in-rust.html\">a\npost detailing plans to do just that</a>.  The best known formally verified\nkernel is <a href=\"https://sel4.systems/About/\">seL4</a>, an L4-family\nmicrokernel.\n\n</p><p>\nAsterinas aims to use the framekernel approach to achieve a system that has\na small, formally verified TCB akin to a lean microkernel, but also a\nsimple shared-memory architecture with Linux ABI compatibility, all at the\nsame time.  This is a radical departure from any previously formally\nverified kernel; the blog post describes those kernels as deliberately\nsmall and limited compared to \"<q>full-fledged, UNIX-style OSes</q>\".\n\n\n</p><p>\nThe Asterinas project is collaborating with a security-auditing company\ncalled <a href=\"https://www.certik.com/\">CertiK</a> to use <a href=\"https://github.com/verus-lang/verus\">Verus</a> to formally verify the\nkernel.  There is an extensive <a href=\"https://github.com/asterinas/slides/blob/f62c764ea9c4831a747dbe8fa415b56e48493482/slides/2025-01-28%20Asterinas%20Security%20Assessment%20by%20CertiK.pdf\">\nreport</a> available from CertiK on how Asterinas was audited and the\nissues that were found.\n\n\n</p><p>\nThe Asterinas kernel is only one result of the project. The other two are\n<a href=\"https://crates.io/crates/ostd\">OSTD</a>, described as \"<q>a Rust\nOS framework that facilitates the development of and innovation in OS\nkernels written in Rust</q>\", and <a href=\"https://asterinas.github.io/book/osdk/guide/index.html\">OSDK</a>, a\nCargo addon to assist with the development, building, and testing of\nkernels based on OSTD.\n\n\n</p><p>\nThere are four stated goals for OSTD as a separate crate. One is to lower\nthe entry bar for operating-system innovation and to lay the groundwork for\nnewcomers to operating-system development. The second is to enhance memory\nsafety for operating systems written in Rust; other projects can benefit\nfrom its encapsulation and abstraction of low-level operations. The third is\nto promote code reuse across Rust-based operating-system projects. The\nfourth is to boost productivity by enabling testing of new code in user\nmode, allowing developers to iterate without having to reboot.\n\n\n</p><p>\nIt is worth emphasizing that the kernels that can be written with OSTD do\nnot have to be Linux-compatible or, in any way, Unix-like. The APIs\nprovided are more generic than that; they are memory-safe abstractions for\nfunctionality like x86 hardware management, booting, virtual memory, SMP,\ntasks, users, and timers.  Like most Rust crates, OSTD is <a href=\"https://docs.rs/ostd/0.14.1/ostd/index.html\">documented on\ndocs.rs</a>.\n\n\n</p><p>\nAsterinas reports Intel, among others, as a sponsor of the project.\nIntel's interest is likely related to its <a href=\"https://www.intel.com/content/www/us/en/developer/tools/trust-domain-extensions/overview.html\">Trust\nDomain Extensions (TDX)</a> feature, which provides hardware modes and\nfeatures to facilitate isolation of virtual machines, and memory\nencryption.  The Asterinas book has a brief <a href=\"https://asterinas.github.io/book/osdk/guide/intel-tdx.html\">section\non TDX</a>, and the OSDK supports it.\n\n\n</p><p>\nThe OSTD, or at least the parts that Asterinas ends up using, seems to\nessentially be the restricted TCB that allows . For an\nillustrative example, we could take a look at the  kernel\ncomponent's <a href=\"https://github.com/asterinas/asterinas/blob/ecb33ca98d2b2ac680daf1d2a48e4d011db2fbcf/kernel/comps/network/src/buffer.rs\">source\ncode</a> and see that the buffer code uses DMA, locking, allocation, and\nvirtual-memory code from the OSTD through memory-safe APIs.\n\n\n</p><p>\nAsterinas was first released under the Mozilla Public License in early\n2024; it has undergone rapid development over the past year.  GitHub <a href=\"https://github.com/asterinas/asterinas/graphs/contributors\">lists 45\nindividual committers</a>, but the majority of the commits are from a\nhandful of PhD students from the Southern University of Science and\nTechnology, Peking University, and Fudan University, as well as a Chinese\ncompany called <a href=\"https://www.antgroup.com/en\">Ant Group</a>, which\nis a sponsor of Asterinas.\n\n</p><p>\nAt the time of writing, Asterinas supports two architectures, x86 and RISC-V.\nIn the January blog post linked above, it was reported that Asterinas\nsupported 180 Linux system calls, but the number has since grown to <a href=\"https://github.com/asterinas/asterinas/blob/1fe0fef41003c824b780b7b228f7b01a46497be0/kernel/src/syscall/arch/x86.rs\">206\non x86</a>.  As of version 6.7, Linux has 368 system calls in total, so there is\nsome way to go yet.\n\n\n</p><p>\nOverall, Asterinas is in early development. There have been no releases,\nrelease announcements, changelogs, or much of anything other than Git tags\nand a short installation guide in the documentation.  The <a href=\"https://crates.io/crates/ostd/reverse_dependencies\">Dependents\ntab</a> of the OSTD crate on crates.io shows that no unrelated, published\ncrate yet uses OSTD.\n\n\n</p><p>\nIt does not seem like Asterinas is able to run any applications yet.  <a href=\"https://github.com/asterinas/asterinas/issues/1868\">Issue #1868</a>\nin Asterinas's repository outlines preliminary plans toward a first\ndistribution.  The initial focus on a custom initramfs and some rudimentary\nuser-space applications, followed by being able to <a href=\"https://github.com/asterinas/asterinas/issues/1851\">run\nDocker</a>. There are initial plans to bootstrap a distribution based on\nNix. Notably (but unsurprisingly), this issue mentions that Asterinas\ndoesn't support loading Linux kernel modules, nor does it ever\nplan to.\n\n\n</p><p>\nThe <a href=\"https://asterinas.github.io/book/kernel/roadmap.html\">Roadmap</a>\nsection of the Asterinas book says that the near-term goals are to expand\nthe support for CPU architectures and hardware, as well as to focus on\nreal-world usability in the cloud by providing a host OS for virtual\nmachines.  Apparently, the support for Linux virtio devices is already\nthere, so a major hurdle has already been cleared.  In particular, the\nChinese cloud market, in the form of Aliyun (also known as Alibaba Cloud)\n<a href=\"https://github.com/asterinas/asterinas/issues/1501\">is a\nfocus</a>.  The primary plans involve creating a container host OS with a\ntight, formally verified TCB and support for some trusted-computing\nfeatures in Intel hardware, for the Chinese cloud service.\n\n\n</p><p>\nWhile both Rust for Linux and Asterinas have similar goals (providing a\nsafer kernel by relying on Rust's memory safety), their scopes and\napproaches are different.  Rust for Linux focuses on safe abstractions\nstrictly for new device drivers to be written in safe Rust, but this leaves\nthe rest of the kernel untouched.\nAsterinas, on the other hand, aims to build a whole new kernel from the ground\nup, restricting the -permitting core to the absolute minimum,\nwhich can then be formally verified.  Asterinas also focuses on\ncontainers and cloud computing, at least for now, while Rust for Linux looks to\nbenefit the whole of the Linux ecosystem.\n\n\n</p><p>\nDespite the stated cloud focus, there is more going on, for example building\nsupport for <a href=\"https://github.com/asterinas/asterinas/issues/2008\">X11</a>\nand <a href=\"https://github.com/asterinas/asterinas/issues/2112\">Xfce</a>.\nAlso, the OSTD could, of course, prove interesting for OS development\nenthusiasts irrespective of the Asterinas project, but so far it remains unknown\nand untested by a wider audience.\n\n</p><p>\nAsterinas is certainly a refreshingly innovative take on principles for\noperating-system development, leaning on the safety and soundness\nfoundations provided by the Rust language and compiler. So far it is at an\nearly exploratory stage driven by enthusiastic Chinese researchers and\ndoesn't see any serious practical use, but it is worth keeping an eye\non. It will be interesting to see the reception it will get from the\nRust for Linux team and the Linux community at large.</p>","contentLength":10809,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1lfzw9v/lwn_asterinas_a_new_linuxcompatible_kernel_project/"},{"title":"France quietly deployed 100,000+ Linux machines in their police force - GendBuntu is a silent EU tech success story","url":"https://www.reddit.com/r/linux/comments/1lfyybb/france_quietly_deployed_100000_linux_machines_in/","date":1750408737,"author":"/u/AnonomousWolf","guid":163379,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kube Composer open source project to generate and visualize kubernetes configuration.","url":"https://www.reddit.com/r/kubernetes/comments/1lfyxmf/kube_composer_open_source_project_to_generate_and/","date":1750408658,"author":"/u/same7ammar","guid":163448,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/same7ammar\"> /u/same7ammar </a>","contentLength":33,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Preserving JSON key order while removing fields","url":"https://www.reddit.com/r/golang/comments/1lfytjc/preserving_json_key_order_while_removing_fields/","date":1750408195,"author":"/u/lakkiy_","guid":163779,"unread":true,"content":"<p>I had a specific problem recently: when validating request signatures, I needed to remove certain fields from JSON (like signature, timestamp) but preserve the original key order for consistent hash generation.</p><p>So I wrote a small (~90 lines) ordered JSON handler that maintains key insertion order while allowing field deletion.</p><p>Nothing groundbreaking, but solved my exact use case. Thought I'd share in case anyone else runs into this specific scenario.</p>","contentLength":452,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Live Stream - Argo CD 3.0 - Unlocking GitOps Excellence: Argo CD 3.0 and the Future of Promotions","url":"https://www.youtube.com/watch?v=iE6q_LHOIOQ","date":1750405800,"author":"/u/iam_the_good_guy","guid":163775,"unread":true,"content":"<p><a href=\"https://www.linkedin.com/in/katie-lamkin/\">Katie Lamkin-Fulsher</a>: Product Manager of Platform and Open Source @ <a href=\"https://www.linkedin.com/company/intuit/\">Intuit</a><a href=\"https://www.linkedin.com/in/crenshawdev/\">Michael Crenshaw</a>: Staff Software Developer @ <a href=\"https://www.linkedin.com/company/intuit/\">Intuit</a> and Lead <a href=\"https://www.linkedin.com/company/argoproj/\">Argo Project</a> CD MaintainerArgo CD continues to evolve dramatically, and version 3.0 marks a significant milestone, bringing powerful enhancements to GitOps workflows. With increased security, improved best practices, optimized default settings, and streamlined release processes, Argo CD 3.0 makes managing complex deployments smoother, safer, and more reliable than ever.But we're not stopping there. The next frontier we're conquering is environment promotions‚Äîone of the most critical aspects of modern software delivery. Introducing GitOps Promoter from Argo Labs, a game-changing approach that simplifies complicated promotion processes, accelerates the usage of quality gates, and provides unmatched clarity into the deployment <a href=\"http://process.In\">process.In</a> this session, we'll explore the exciting advancements in Argo CD 3.0 and explore the possibilities of Argo Promotions. Whether you're looking to accelerate your team's velocity, reduce deployment risks, or simply achieve greater efficiency and transparency in your CI/CD pipelines, this talk will equip you with actionable insights to take your software delivery to the next level.</p>","contentLength":1263,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1lfy8cz/live_stream_argo_cd_30_unlocking_gitops/"},{"title":"What did I get my hands on here?","url":"https://www.reddit.com/r/linux/comments/1lfx1ph/what_did_i_get_my_hands_on_here/","date":1750401148,"author":"/u/mocoma_","guid":163333,"unread":true,"content":"<div><p>I am working at a Hospital as a provider for food and disposal of waste, and on top of one of today's piles of garbage I found this DVD. Is this an actual usable operating system? It came with a few Software Disks for neurosurgery.</p></div>   submitted by   <a href=\"https://www.reddit.com/user/mocoma_\"> /u/mocoma_ </a>","contentLength":261,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lightweight Kubernetes Autoscaling for Custom Metrics (TPS) Across Clouds‚ÄîKEDA, HPA, or Something Else?","url":"https://www.reddit.com/r/kubernetes/comments/1lfwfkr/lightweight_kubernetes_autoscaling_for_custom/","date":1750398765,"author":"/u/efumagal","guid":163590,"unread":true,"content":"<p>I'm looking for advice on implementing <strong>lightweight autoscaling in Kubernetes</strong> for a custom metric‚Äîspecifically, <strong>transactions per second (TPS)</strong> that works seamlessly across .</p><ul><li>I want to avoid deploying Prometheus just for this one metric.</li><li>Ideally, I‚Äôd like a solution that‚Äôs simple, cloud-agnostic, and easy to deploy as a standard K8s manifest.</li><li>The TPS metric might come from an NGINX ingress controller or a custom component in the cluster.</li><li>I do have managed Prometheus on GKE, but I‚Äôd rather not require Prometheus everywhere just for this.</li></ul><ol><li> If I use KEDA, do I still need to expose my custom metric (TPS) to the Kubernetes External Metrics API, or can KEDA consume it directly? (I know KEDA supports external scalers, but does that mean I need to run an extra service anyway?)</li><li> If I expose my TPS metric to the External Metrics API (via an adapter), can I just use a standard HPA manifest and skip KEDA entirely?</li><li><strong>What if the metric comes from NGINX?</strong> NGINX exposes Prometheus metrics, but there‚Äôs no native NGINX adapter for the K8s metrics APIs. Is there a lightweight way to bridge this gap without running a full Prometheus stack?</li><li><strong>Best practice for multi-cloud?</strong> What‚Äôs the simplest, most portable approach for this use case that works on all major managed K8s providers?</li></ol><p> I want to autoscale on a custom TPS metric, avoid running Prometheus if possible, and keep things simple and portable across clouds.<p> Should I use KEDA, HPA, or something else? And what‚Äôs the best way to get my metric into K8s for autoscaling?</p></p><p>Thanks for any advice or real-world experience!</p>","contentLength":1568,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"is there any use for TPM on Linux?","url":"https://www.reddit.com/r/linux/comments/1lfvklv/is_there_any_use_for_tpm_on_linux/","date":1750395567,"author":"/u/kk_mergical","guid":163378,"unread":true,"content":"<p>Like the title suggests, I‚Äôm curious if there is any need or use for a TPM module. I‚Äôve read enough that the module provides encryption. Is there any difference between TPM encryption and something like LUKS? And would TPM provide as much use as any other form of encryption?</p><p>Edit: thank you all for the replies </p>","contentLength":315,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DSA Fundamentals #1: A Practical Guide to Propositional Logic","url":"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic","date":1750395456,"author":"/u/WillingnessFun7051","guid":163513,"unread":true,"content":"<p>A simple  condition can hide a bug for hours. A design meeting can stall on the meanings of \"always\" or \"only if\". These problems stem from ambiguity. Clear language prevents them.</p><p>Propositional logic is a system for clear expression. It is a tool for precise thought. It helps you write better code and build stronger arguments. This guide explains propositional logic from its foundations. It is a practical manual for developers, engineers, and builders.</p><h2>The Foundations of Reasoning<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#the-foundations-of-reasoning\"></a></h2><p>First, we must understand the core ideas of logic. We will look at its basic unit and the history of its creation.</p><h3>The World of Propositions<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#the-world-of-propositions\"></a></h3><p>Logic is built on a simple concept: the proposition. A proposition is a statement that is either  or . It cannot be both. It cannot be neither. This binary classification is the starting point for all formal reasoning.</p><p>You must learn to identify a proposition. Here are some examples:</p><ul><li><p>\"Paris is the capital of France.\" (True)</p></li><li><p>\"The Earth is a cube.\" (False)</p></li></ul><p>Each statement makes a claim. The claim can be verified as true or false.</p><p>It is also important to know what is not a proposition. Logic gains power by excluding unclear sentences. The following sentence types are outside its scope:</p><ul><li><p> \"Do your homework.\" This is an instruction. It is not true or false.</p></li><li><p> \"What is the weather like?\" This sentence asks for information. It does not declare a fact.</p></li><li><p>. The truth of this statement depends on the value of . It has no definite truth value.</p></li><li><p> \"This statement is false.\" The sentence contradicts itself. It has no stable truth value.</p></li></ul><p>Propositional logic treats these simple propositions as indivisible units. It studies the rules for combining these units into more complex statements. This system exchanges the nuance of natural language for analytical power. This precision makes logic the natural language of computers, which are built on the binary states of 0 and 1.</p><p>The effort to formalize reason is ancient. The system we use today is the product of a specific history. This history explains why its rules are structured the way they are.</p><p>The earliest formal logic came from ancient Greece. The philosopher Aristotle is often called the \"father of logic.\" His system categorized valid argument forms called syllogisms. The Stoic school of philosophy came later. The Stoics studied the connectors that join simple propositions. These include \"and,\" \"or,\" and \"if...then...\" constructions. They saw that a compound statement's truth value depends on its parts and the connector used. This idea is now called truth-functionality.</p><p>Logic remained a part of philosophy for many centuries. A major change happened in the mid-19th century with the work of George Boole. Boole was an English mathematician. He realized that logical reasoning could be represented with a formal algebraic system. He introduced a new type of algebra, now called Boolean Algebra. It was designed to model logic.</p><p>Boole's work was transformative. It provided a general method that could be applied to many arguments. His work gave logic a mathematical foundation. The German logician Gottlob Frege later developed the first formal axiomatic system for logic. Frege's work solidified logic's place as a mathematical discipline.</p><p>This history shows the structural similarities between logic and algebra are not a coincidence. They are the result of Boole's work. The system of propositional logic is a coherent analytical tool. It was created at the intersection of philosophy and mathematics. This history prepared logic for its role as the language of the digital age.</p><h2>The Mechanics of Propositional Logic<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#the-mechanics-of-propositional-logic\"></a></h2><p>We now turn to the practical mechanics of the system. This part introduces the formal language and the main analytical tool: the truth table.</p><h3>The Language of Logic: Symbols and Connectives<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#the-language-of-logic-symbols-and-connectives\"></a></h3><p>Propositional logic has a precise syntax. It has an alphabet and rules for combining symbols.</p><p>The alphabet has two main types of symbols:</p><ul><li><p> These are letters like , , and . They stand for simple, atomic propositions. For example,  can represent \"It is raining.\"</p></li><li><p> These are operators that form complex propositions. There are five standard connectives.</p></li></ul><table><tbody><tr></tr></tbody></table><p>We use these parts to construct <strong>well-formed formulas (WFFs)</strong>. The rules for forming WFFs are simple:</p><ol><li><p>Any atomic propositional variable is a WFF.</p></li><li><p>If  is a WFF, then  is a WFF.</p></li><li><p>If  and  are WFFs, then , , , and  are WFFs.</p></li></ol><p>This definition allows us to build formulas of any complexity. Parentheses show the structure and order of operations.</p><h3>Unveiling Truth with Truth Tables<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#unveiling-truth-with-truth-tables\"></a></h3><p>The syntax of logic tells us how to build formulas. The semantics tell us what they mean. The main tool for finding a formula's meaning is the . A truth table lists every possible combination of truth values for the atomic propositions. It shows the resulting truth value of the whole formula for each combination.</p><p>Constructing a truth table is a systematic process:</p><ol><li><p><strong>Determine the Number of Rows:</strong> A formula with  distinct variables has  possible combinations of truth values. The table needs  rows. A formula with , , and  needs  rows.</p></li><li><p><strong>Establish Initial Columns:</strong> Create a column for each atomic variable.</p></li><li><p><strong>List All Truth Assignments:</strong> List the truth assignments in a consistent pattern. A common method is to count in binary.</p></li><li><p> Work from the inside out. Create a new column for each logical operation. The standard order of precedence is: Parentheses, Negation, Conjunction/Disjunction, Conditional, and Biconditional.</p></li></ol><p>This next table is the most important reference. It defines the five standard connectives.</p><table><thead><tr></tr></thead><tbody></tbody></table><ul><li><p>: Inverts the truth value of its operand.</p></li><li><p>: Is true only when both  and  are true.</p></li><li><p>: Is true if at least one of  or  is true. It is false only when both are false.</p></li><li><p>: Is false only when the antecedent  is true and the consequent  is false.</p></li><li><p>: Is true only when  and  have the same truth value.</p></li></ul><p>You must learn these definitions. All other concepts are derived from these truth-functional meanings.</p><h3>From English to Symbols: The Art of Translation<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#from-english-to-symbols-the-art-of-translation\"></a></h3><p>A critical skill is translating natural language into propositional logic. This process requires you to identify atomic propositions and the logical structure.</p><p>First, break down a complex sentence into its simplest parts. Assign a propositional variable to each part. In the sentence \"If the weather remains mild and there is no frost, then there will be a good harvest,\" we can identify three atomic propositions:</p><ul><li><p>: \"The weather remains mild.\"</p></li><li><p>: \"There will be a good harvest.\"</p></li></ul><p>Second, identify the logical connectives. English has many ways to express logical relationships. Here are common translations:</p><ul><li><p>: \"and,\" \"but,\" \"moreover\"</p></li><li><p>: \"or,\" \"unless\"</p></li><li><p>: \"not,\" \"it is not the case that\"</p></li><li><p>: \"if...then,\" \"implies,\" \"is a sufficient condition for,\" \"is a necessary condition for\" (reversed), \"only if\"</p></li><li><p>: \"if and only if,\" \"is a necessary and sufficient condition for\"</p></li></ul><p>Mastering this translation process lets you restate a complex argument as a formal structure. Then it is ready for rigorous analysis.</p><h2>Analysis, Equivalence, and Inference<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#analysis-equivalence-and-inference\"></a></h2><p>Once a proposition is constructed, we can analyze its properties. This part explains how to analyze formulas, simplify them, and use them to construct valid arguments.</p><p>The final column of a truth table allows us to classify any formula into one of three categories.</p><ul><li><p>: A proposition that is always true. The final column of its truth table contains only 'T's. An example is .</p></li><li><p>: A proposition that is always false. The final column of its truth table contains only 'F's. An example is .</p></li><li><p>: A proposition that is neither a tautology nor a contradiction. Its truth value depends on its atomic components. The final column has a mix of 'T's and 'F's.</p></li></ul><p>Understanding these categories is important. Tautologies represent logical truths. Identifying contradictions helps find inconsistent premises.</p><h3>Logical Equivalence and Simplification<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#logical-equivalence-and-simplification\"></a></h3><p>Two propositional formulas are logically equivalent if they have the exact same truth table. We denote this with the symbol .</p><p>Logical equivalence is a useful concept. It provides rules to manipulate and simplify logical expressions without a full truth table. These rules are themselves tautologies of the form .</p><p>This table presents the most important logical equivalences.</p><table><thead><tr></tr></thead><tbody><tr></tr><tr><td><code>(p ‚à® q) ‚à® r ‚â° p ‚à® (q ‚à® r)</code></td><td><code>(p ‚àß q) ‚àß r ‚â° p ‚àß (q ‚àß r)</code></td></tr><tr><td><code>p ‚à® (q ‚àß r) ‚â° (p ‚à® q) ‚àß (p ‚à® r)</code></td><td><code>p ‚àß (q ‚à® r) ‚â° (p ‚àß q) ‚à® (p ‚àß r)</code></td></tr><tr></tr><tr></tr><tr><td> (Contrapositive)</td></tr></tbody></table><p>Some equivalences are very common:</p><ul><li><p> provide rules for negating conjunctions and disjunctions.</p></li><li><p> () allows us to translate any conditional statement into an expression with only negation and disjunction.</p></li><li><p> () is a powerful tool in mathematical proofs. Proving the contrapositive is often more direct than proving the original statement.</p></li></ul><h3>The Art of Deduction: Rules of Inference<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#the-art-of-deduction-rules-of-inference\"></a></h3><p>Truth tables can become too large for complex arguments. So, we use . Inference is the process of deriving a conclusion from premises through a sequence of small, valid steps.</p><p>An argument is  if it is impossible for all its premises to be true and its conclusion false. The  are simple, valid argument forms. They are building blocks for more complex proofs.</p><p>This table outlines the most essential rules of inference.</p><table><tbody><tr></tr><tr></tr><tr><td><strong>Hypothetical Syllogism (HS)</strong></td></tr><tr><td><strong>Disjunctive Syllogism (DS)</strong></td></tr><tr></tr><tr></tr></tbody></table><p>A formal proof is a sequence of formulas where each formula is a premise or follows from previous formulas by a rule of inference. This method provides a scalable way to establish logical validity.</p><p>We now move to more advanced topics. This part explores the complexities of the conditional, normal forms, and the connection between logic and computation.</p><h3>The Nuances of the Conditional<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#the-nuances-of-the-conditional\"></a></h3><p>The material conditional () can be challenging. Its formal definition can lead to conclusions that seem counter-intuitive in natural language.</p><p>The definition gives rise to two apparent paradoxes:</p><ol><li><p>A false antecedent implies any proposition. The formula  is a tautology. \"If the moon is made of green cheese, then the sky is blue,\" is a logically true statement.</p></li><li><p>A true consequent is implied by any proposition. The formula  is a tautology. \"If it is raining, then 2+2=4,\" is a logically true statement.</p></li></ol><p>The solution to these is to understand the material conditional correctly. The formula  does not assert a causal connection between  and . The conditional makes only one claim: it is not the case that  is true and  is false.</p><p>Think of the conditional as a promise. \"If you get an A, then I will give you a dollar.\" The promise is broken only in one scenario. You get an A (antecedent is true), and I do not give you a dollar (consequent is false). In all other cases, the promise is not broken.</p><p>For many computational uses, we need to standardize formulas. These standard structures are . The two most important are Conjunctive Normal Form (CNF) and Disjunctive Normal Form (DNF).</p><p>A  is an atomic proposition or its negation.</p><ul><li><p><strong>Disjunctive Normal Form (DNF)</strong>: A formula is in DNF if it is a disjunction of one or more conjunctions of literals. It is an \"OR of ANDs\".</p></li><li><p><strong>Conjunctive Normal Form (CNF)</strong>: A formula is in CNF if it is a conjunction of one or more disjunctions of literals. It is an \"AND of ORs\". Each disjunction is a .</p></li></ul><p>Any propositional formula can be converted into an equivalent formula in either CNF or DNF. The process uses the logical equivalences from the previous part. CNF is particularly important. It is the standard input format for many automated reasoning systems.</p><h3>The Satisfiability Problem (SAT)<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#the-satisfiability-problem-sat\"></a></h3><p>At the intersection of logic and computer science is the <strong>Boolean Satisfiability Problem (SAT)</strong>. The problem is simple to state. Given an arbitrary propositional formula, does an assignment of truth values exist that makes the entire formula true? If yes, the formula is .</p><p>The Cook-Levin theorem from 1971 proved that SAT is . This means that many hard computational problems can be reduced to a SAT problem. If one could find a fast algorithm to solve SAT, one could solve all these other problems too.</p><p>Modern  are sophisticated programs that determine if a formula is satisfiable. They are very effective in practice. They can solve real-world problems with thousands of variables and millions of clauses. SAT solvers have become a general-purpose tool for solving many hard computational problems.</p><p>Propositional logic is not just an academic topic. Its principles are part of modern technology.</p><p>The most direct application of propositional logic is in digital electronic circuits.  are physical devices that implement the logical connectives.</p><ul><li><p>An  implements conjunction ().</p></li><li><p>An  implements disjunction ().</p></li><li><p>A  implements negation ().</p></li></ul><p>These gates are the building blocks of all digital hardware. They are combined to construct complex circuits. These circuits perform arithmetic and logical operations inside a computer's Central Processing Unit (CPU).</p><h3>Application in Software and Artificial Intelligence<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#application-in-software-and-artificial-intelligence\"></a></h3><p>Propositional logic also forms the conceptual foundation for software.</p><ul><li><p>:  statements and  loops use Boolean expressions to direct the flow of execution. These are direct implementations of logical formulas.</p></li><li><p>: Advanced search features in databases and web engines use logical operators to filter information.</p></li><li><p><strong>Knowledge Representation in AI</strong>: In some AI systems, knowledge is encoded as a database of logical formulas. Facts are atomic propositions. Rules are conditional statements. The system can then use rules of inference to deduce new information.</p></li></ul><p>In safety-critical fields, we need mathematical certainty that a system works correctly.  is the process of using formal logical methods to prove the correctness of a system.</p><p>Desired system properties are expressed as logical formulas. For example, \"the two railway gates are never open at the same time.\" Then, automated tools check if a model of the system satisfies the formula. This application shows the power of logic. We use it to design hardware, write software, and then prove that the resulting system is correct.</p><p>Knowledge becomes skill through practice. This part provides resources to help you engage with propositional logic.</p><p>Several software tools can help the learning process.</p><ul><li><p><strong>LogicLearner (Columbia University)</strong>: A free web application for guided practice of logic proofs. It validates student steps and can generate solutions.</p></li><li><p>: A web-based toolkit that can prove formulas, generate truth tables, and convert formulas to CNF.</p></li></ul><h3>Programming with Logic: A Python Primer<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#programming-with-logic-a-python-primer\"></a></h3><p>Working with logic in code can deepen your understanding. The  library in Python is a good tool for this. It allows you to create and manipulate Boolean expressions symbolically.</p><pre><code>from sympy import symbols\nfrom sympy.logic.boolalg import Implies\nfrom sympy.logic.inference import satisfiable\n\nx, y = symbols('x, y')\nexpr = Implies(x, y)\n# The satisfiable function returns a dictionary of values if the expression can be true.\nprint(satisfiable(expr))\n# Output: {x: False, y: False}\n\n</code></pre><h3>Practice Problems &amp; Projects<a aria-hidden=\"true\" tabindex=\"-1\" href=\"https://beyondit.blog/blogs/DSA-Fundamentals-1-A-Practical-Guide-to-Propositional-Logic#practice-problems--projects\"></a></h3><p>The best way to learn is by doing.</p><ul><li><p>: Try translating English sentences to logic, building truth tables, proving equivalences, and constructing formal proofs.</p></li><li><ol><li><p>: Write a Python program that takes a logical formula as input and prints its truth table.</p></li><li><p>: Model a classic logic puzzle, like \"Knights and Knaves,\" using propositional logic. Translate the puzzle's statements into a single formula and use a SAT solver to find the solution.</p></li><li><p>: Use a circuit simulator like Logisim Evolution to design a simple circuit, like a 2-bit binary adder. Derive the logic formulas from a truth table, simplify them, and build the circuit.</p></li></ol></li></ul><p>Mastering propositional logic is a great first step into the world of formal reasoning. The principles you have learned are a reliable guide.</p><p>For further study, you can explore these resources:</p><ul><li><p>: Stanford University's \"Introduction to Logic\" on Coursera is a comprehensive intermediate course.</p></li><li><p>: \"Discrete Mathematics and Its Applications\" by Kenneth Rosen is a standard text for computer science students. \"Discrete Mathematics: An Open Introduction\" by Oscar Levin is a free, open-source textbook that is good for active learning.</p></li></ul>","contentLength":15908,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lfvjji/dsa_fundamentals_1_a_practical_guide_to/"},{"title":"Where does this fit in the Linux stack?","url":"https://www.reddit.com/r/linux/comments/1lfuhgm/where_does_this_fit_in_the_linux_stack/","date":1750391823,"author":"/u/karland90","guid":163593,"unread":true,"content":"<p>So I was reading the <a href=\"https://invent.kde.org/teams/accessibility/collaboration/-/issues/30\">issue-thread</a> about KDE Plasma adapting to the recent EU requirements about accessibility. And avoiding users accidentally creating situations that could trigger photosensitive epilepsy sounded difficult.</p><p>This made me think - hypothetically speaking - in which part of a modern (e.g. KDE-based) Linux distro could an OS-level universal photo sensitivity filter be implemented ü§î? I.e. an optional tool where successive frames are analyzed and if a danger level threshold is crossed, a mitigation procedure is triggered. That procedure could be freezing/skipping frames, morphing between frames more slowly, or displaying a warning overlay/watermark).</p><p><strong>Can this be a regular user app? Does it require changes to some part of the rendering stack?</strong></p><p>Based on googling for 5 min, I found:</p><ul><li><a href=\"https://trace.umd.edu/peat/\">this</a> mention of University of Maryland having a fully open-source detection tool in the works:</li></ul><blockquote><p>We are working on a new fully-open-source version that will be updated for new technologies (the current version is open-source except for a proprietary analysis engine we purchased the rights to use). It will also be free to use. No ETA for it as yet.</p></blockquote><ul><li>some Github repo searches: <a href=\"https://github.com/search?q=epilepsy%20protection&amp;type=repositories\">1</a><a href=\"https://github.com/search?q=epilepsy%20prevention&amp;type=repositories\">2</a></li><li>one of the more promising results: <a href=\"https://github.com/Pi-0r-Tau/Epilepsy-Active-protection-Extension-\">3</a></li><li>that searching for \"<a href=\"https://github.com/search?q=epilepsy%20detection&amp;type=repositories\">epilepsy detection</a>\" gives a lot of \"noise\" in projects doing health tracking for detection of an epileptic fit.</li></ul><p>I'm hoping someone is inspired to dig into making this or I get pointers which issue tracker or forum to take this towards üôè</p><p>Maybe Linux can get another trailblazer win, Apple can copy it and get admired as innovative for it, and we get the smug \"um akshually ‚òùÔ∏è\". But the world would still be better than before üòå</p>","contentLength":1665,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[R] WiFiGPT: Using fine-tuned LLM for Indoor Localization Using Raw WiFi Signals (arXiv:2505.15835)","url":"https://www.reddit.com/r/MachineLearning/comments/1lfu9bk/r_wifigpt_using_finetuned_llm_for_indoor/","date":1750391049,"author":"/u/DiligentCharacter252","guid":163591,"unread":true,"content":"<p>We recently released a paper called : a decoder-only transformer trained directly on raw WiFi telemetry (CSI, RSSI, FTM) for indoor localization.</p><p>In this work, we explore treating raw wireless telemetry (CSI, RSSI, and FTM) as a \"language\" and using decoder-only LLMs to regress spatial coordinates directly from it.</p><p>Would love to hear your feedback, questions, or thoughts.</p>","contentLength":372,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"One-Minute Daily AI News 6/19/2025","url":"https://www.reddit.com/r/artificial/comments/1lfttol/oneminute_daily_ai_news_6192025/","date":1750389595,"author":"/u/Excellent-Target-847","guid":163672,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/Excellent-Target-847\"> /u/Excellent-Target-847 </a>","contentLength":43,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Has anyone taken the Rust Data Engineering course by O'Reilly? It‚Äôs said to have 463 hours of content, which seems very dense. Is it worth it?","url":"https://www.reddit.com/r/rust/comments/1lfsu5p/has_anyone_taken_the_rust_data_engineering_course/","date":1750386433,"author":"/u/swe_solo_engineer","guid":163403,"unread":true,"content":"<div><p>I‚Äôm asking because I can choose one course from several options provided as a benefit at my workplace. I was thinking about choosing this one.</p></div>   submitted by   <a href=\"https://www.reddit.com/user/swe_solo_engineer\"> /u/swe_solo_engineer </a>","contentLength":184,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Experiments with DNA Compression and Generating Complimentary Base Pairs","url":"https://arianfarid.me/articles/dna-compression.html","date":1750384957,"author":"/u/VeryStrangeAttractor","guid":163377,"unread":true,"content":"<p>Efficiently storing and analyzing these sequences is a critical challenge. Furthermore, the ability to analyze large sequences of data are increasingly critical. In this post, we will explore a method to compress DNA using 4-bits per nucleotide in pure Rust, that allows us to generate Complementary base pairs in its compressed form.</p><p>This technique is especially useful in DNA analytical pipelines, where performance and memory constraints are critical. By minimizing the footprint of each sequence, we simultaneously reduce storage overhead and in-memory costs, without sacrificing speed or the ability to operate directly on compressed data.</p><h3 tabindex=\"-1\">DNA Bases and IUPAC Codes </h3><p>There are <a href=\"ttps://genome.ucsc.edu/goldenPath/help/iupac.html\" target=\"_blank\" rel=\"noreferrer\">15 IUPAC codes</a>. The ones that most are familiar with are \"A\", \"G\", \"C\", and \"T\", representing the four standard DNA bases. However, DNA sequencing often produces ambiguous results. The remaining 11 codes are for these cases. For example, \"R\" can represent \"G\"  \"A\", while \"N\" can represent  nucleotide.</p><p>DNA bases form pairs through well-defined chemical relationships: adenine (A) pairs with thymine (T), and cytosine (C) with guanine (G). These base-pairing rules extend to IUPAC ambiguity codes, which represent sets of possible nucleotides. For instance, \"R\" (A or G) complements \"Y\" (T or C).</p><p>There are three cases where the Complement is the same code. The bases \"N\" (any base), \"S\" (G or C), and \"W\" (A or T) all Complement to their own code (e.g. S-&gt;S, because \"S\" is represented by \"G\" or \"C\").</p><p>Our compression system needs to be fast, small, and reversible. It should support all 15 IUPAC nucleotide codes and allow efficient I/O and transformation.</p><ul><li>Smallest representation of nucleotides possible.</li><li>Translate compressed/uncompressed DNA to and from file.</li><li>Easily retrieve Complementary base pairs (including IUPAC codes)</li></ul><h2 tabindex=\"-1\">Representing IUPAC Nucleotides in Four Bits </h2><p>Since four bits are enough to represent 16 values (2‚Å¥ = 16), we can comfortably fit in all 15 codes as well as an additional padding code.</p><p>Because Rust does not support native 4-bit types, our 4-bit encodings must be packed into a larger primitive. I opted to group 4 nucleotides into a single  integer. Because 4-bit data types are still represented at the byte level in Rust, we can squeeze four nucleotide representations of DNA into a single  integer.</p><p>When a sequence has fewer than four nucleotides remaining at the end, we use the 16th reserved value as a padding indicator. These padding values are ignored during decompression.</p><h3 tabindex=\"-1\">Support for Bitwise Rotation </h3><p>To obtain support for 12 Complementations and 3 self-Complementations, we can rotate the bit two positions.</p><p>For example, \"A\" will be represented by . Rotating two bits will give us  \"T\". An additional two bit rotation will bring us back to \"A\", .</p><p>Codes that Complement themselves must be symmetric on either half of the bit mask. For example, if we represent the code \"S\" (\"G\" or \"C\") as , rotating two bits will still give us .</p><p>Let's first look at a simple match expression to see the final schema we have derived. This match expressions encodes each IUPAC nucleotide into a 4-bit mask:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>This will serve as the building block for our 4-nucleotide compression scheme. Note that  (e.g. G/C, or A/T) are rotated 2 positions!</p><p>The NucWord  represents four encoded nucleotides packed into a single . The methods  and  are used to serialize/deserialize.</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Lets look closely at :</p><div><pre tabindex=\"0\"><code></code></pre></div><p>This simple method iterates through a slice of four nucleotides, translating each to its 4-bit encoding, and shifts them to their appropriate position in the .</p><div><pre tabindex=\"0\"><code></code></pre></div><p>This method takes a 4-bit mask to return a  implementation of our nucleotide, filtering out any padded characters.</p><p>Now that we can represent four nucleotides in a single NucWord, we will define a container type NucBlockVec to encode/decode entire DNA sequences.</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Let‚Äôs define a quick test to see the compression in action. We will read our , encode the nucleotides to NucBlockVec, and write the compressed binary output to disk.</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Inspecting  file size, we have 8,286 bytes... Exactly half the size!</p><p>Here‚Äôs how we implement base-pair complements using our bit rotation trick:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>This works because the 4-bit encodings were designed so that a 2-bit rotation produces the nucleotide's complement.</p><p>Lets compare this bit rotation to a simpler match implementation:</p><p>Bit rotation is roughly 2x faster (Fig. 1) than using a match arm to grab DNA base pair Complements.</p><p>The speed savings becomes more important when dealing with <a href=\"https://www.ncbi.nlm.nih.gov/nuccore/AE014297\" target=\"_blank\" rel=\"noreferrer\">very large nucleotide sequences</a>. In Fig. 2, the time is reduced from ~0.6 seconds to ~0.3 seconds.</p><p>Efficient DNA compression is a challenging problem at the intersection of systems programming and bioinformatics. This Rust based 4-bit DNA encoder offers a lightweight, fast, and ergonomic way to handle genetic data efficiently.</p><p>Using bitwise operations doubled Complementary generation speed. I feel I've only scratched the surface and look forward to getting more use out of this encoding.</p><p>Check out the source code on my <a href=\"https://github.com/arianfarid/nucleotide-encoder\" target=\"_blank\" rel=\"noreferrer\">GitHub</a>. Thanks for reading!</p>","contentLength":4990,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1lfsd3o/experiments_with_dna_compression_and_generating/"},{"title":"In Praise of ‚ÄúNormal‚Äù Engineers","url":"https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/","date":1750384718,"author":"/u/gametorch","guid":163268,"unread":true,"content":"<p><em>This article was originally <a href=\"https://refactoring.fm/p/in-praise-of-normal-engineers\">commissioned by Luca Rossi</a> (paywalled) for refactoring.fm, on February 11th, 2025. Luca edited a version of it that emphasized the importance of building ‚Äú10x engineering teams‚Äù . It was later picked up by IEEE Spectrum (!!!), who scrapped most of the teams content and published a <a href=\"https://spectrum.ieee.org/10x-engineer\">different, shorter piece</a> on March 13th.</em></p><p><em>This is my personal edit. It is not exactly identical to either of the versions that have been publicly released to date. It contains a lot of the source material for the talk I gave last week at #LDX3 in London, ‚Äú<a href=\"https://speakerdeck.com/charity/in-praise-of-normal-engineers-ldx3\">In Praise of ‚ÄòNormal‚Äô Engineers</a>‚Äù (slides), and a couple weeks ago at CraftConf.&nbsp;</em></p><h2>In Praise of ‚ÄúNormal‚Äù Engineers</h2><p>Most of us have encountered a few engineers who seem practically magician-like, a class apart from the rest of us in their ability to reason about complex mental models, leap to non-obvious yet elegant solutions, or emit waves of high quality code at unreal velocity.<img data-recalc-dims=\"1\" decoding=\"async\" data-attachment-id=\"10015\" data-permalink=\"https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-praise-black-squish/\" data-orig-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=1024%2C1024&amp;ssl=1\" data-orig-size=\"1024,1024\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"In Praise of ‚ÄúNormal‚Äù Engineers\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=300%2C300&amp;ssl=1\" data-large-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=660%2C660&amp;ssl=1\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=174%2C174&amp;ssl=1\" alt=\"In Praise of &quot;Normal&quot; Engineers\" width=\"174\" height=\"174\" srcset=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?w=1024&amp;ssl=1 1024w\" sizes=\"(max-width: 174px) 100vw, 174px\"></p><p>I have run into any number of these incredible beings over the course of my career. I think this is what explains the curious durability of the ‚Äú10x engineer‚Äù meme. It may be based on flimsy, shoddy research, and the claims people have made to defend it have often been&nbsp;risible (e.g. ‚Äú10x engineers have dark backgrounds, are rarely seen doing UI work, are poor mentors and interviewers‚Äù), or blatantly double down on stereotypes (‚Äúwe look for young dudes in hoodies that remind us of Mark Zuckerberg‚Äù). But damn if it doesn‚Äôt resonate with experience. It just feels true.</p><p>The problem is not the idea that there are engineers who are 10x as productive as other engineers. I don‚Äôt have a problem with this statement; in fact, that much seems self-evidently true. The problems I do have are twofold.</p><h2>Measuring productivity is fraught and imperfect</h2><p>First: how are you measuring productivity? I have a problem with the implication that there is One True Metric of productivity that you can standardize and sort people by. Consider, for a moment, the sheer combinatorial magnitude of skills and experiences at play:</p><p>Also: people and their skills and abilities are not static. At one point, I was a pretty good DBRE (I even co-wrote the book on it). Maybe I was even a 10x DB engineer then, but certainly not now. I haven‚Äôt debugged a query plan in years.</p><p>‚Äú10x engineer‚Äù makes it sound like 10x productivity is an immutable characteristic of a person. But someone who is a 10x engineer in a particular skill set is still going to have infinitely more areas where they are normal or average (or less). I know a lot of world class engineers, but I‚Äôve never met anyone who is 10x better than everyone else across the board, in every situation.</p><h2>Engineers don‚Äôt own software, teams own software</h2><p>Second, and even more importantly: So what? It doesn‚Äôt matter. Individual engineers don‚Äôt own software, teams own software. <strong>The smallest unit of software ownership and delivery is the engineering team</strong>. It doesn‚Äôt matter how fast an individual engineer can write software, what matters is how fast the team can collectively write, test, review, ship, maintain, refactor, extend, architect, and revise the software that they own.</p><p>Everyone uses the same software delivery pipeline. If it takes the slowest engineer at your company five hours to ship a single line of code, it‚Äôs going to take the fastest engineer at your company five hours to ship a single line of code. The time spent writing code is typically dwarfed by the time spent on every other part of the software development lifecycle.</p><p>If you have services or software components that are owned by a single engineer, that person is a single point of failure.<img data-recalc-dims=\"1\" fetchpriority=\"high\" decoding=\"async\" data-attachment-id=\"10013\" data-permalink=\"https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-spof/\" data-orig-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=1024%2C1024&amp;ssl=1\" data-orig-size=\"1024,1024\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"normal-spof\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=300%2C300&amp;ssl=1\" data-large-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=660%2C660&amp;ssl=1\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=226%2C226&amp;ssl=1\" alt=\"\" width=\"226\" height=\"226\" srcset=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?w=1024&amp;ssl=1 1024w\" sizes=\"(max-width: 226px) 100vw, 226px\"></p><p>I‚Äôm not saying this should never happen. It‚Äôs quite normal at startups to have individuals owning software, because the biggest existential risk that you face is not moving fast enough, not finding product market fit, and going out of business. But as you start to grow up as a company, as users start to demand more from you, and you start planning for the survival of the company to extend years into the future‚Ä¶ownership needs to get handed over to a team. Individual engineers get sick, go on vacation, and leave the company, and the business has got to be resilient to that.</p><p>If teams own software, then the key job of any engineering leader is to craft high-performing engineering teams. If you must 10x something, 10x this. <strong>Build 10x engineering teams.</strong></p><h2>The best engineering orgs are the ones where normal engineers can do great work</h2><p>When people talk about world-class engineering orgs, they often have in mind teams that are top-heavy with staff and principal engineers, or recruiting heavily from the ranks of ex-FAANG employees or top universities.</p><p>But I would argue that a truly great engineering org is one where you don‚Äôt HAVE to be one of the ‚Äúbest‚Äù or most pedigreed engineers in the world to get shit done and have a lot of impact on the business.</p><p>I think it‚Äôs actually the other way around. A truly great engineering organization is one where perfectly normal, workaday software engineers, with decent software engineering skills and an ordinary amount of expertise, can consistently move fast, ship code, respond to users, understand the systems they‚Äôve built, and move the business forward a little bit more, day by day, week by week.</p><p>Any asshole can build an org where the most experienced, brilliant engineers in the world can build product and make progress. That is not hard. And putting all the spotlight on individual ability has a way of letting your leaders off the hook for doing their jobs. It is a HUGE competitive advantage if you can build sociotechnical systems where less experienced engineers can convert their effort and energy into product and business momentum.</p><p>A truly great engineering org also happens to be one that mints world-class software engineers. But we‚Äôre getting ahead of ourselves, here.</p><h2>Let‚Äôs talk about ‚Äúnormal‚Äù for a moment</h2><p>A lot of technical people got really attached to our identities as smart kids. The software industry tends to reflect and reinforce this preoccupation at every turn, from Netflix‚Äôs ‚Äúwe look for the top 10% of global talent‚Äù to Amazon‚Äôs talk about ‚Äúbar-raising‚Äù or Coinbase‚Äôs recent claim to ‚Äúhire the top .1%‚Äù. (Seriously, guys? Ok, well, Honeycomb is going to hire only the top !)</p><p>In this essay, I would like to challenge us to set that baggage to the side and think about ourselves as .</p><p>It can be humbling to think of ourselves as normal people, but most of us are in fact pretty normal people (albeit with many years of highly specialized practice and experience), and<img data-recalc-dims=\"1\" loading=\"lazy\" decoding=\"async\" data-attachment-id=\"10011\" data-permalink=\"https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-made-not-born/\" data-orig-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=1024%2C1024&amp;ssl=1\" data-orig-size=\"1024,1024\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"normal-made-not-born\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=300%2C300&amp;ssl=1\" data-large-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=660%2C660&amp;ssl=1\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=264%2C264&amp;ssl=1\" alt=\"\" width=\"264\" height=\"264\" srcset=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?w=1024&amp;ssl=1 1024w\" sizes=\"auto, (max-width: 264px) 100vw, 264px\"> there is . Even those of us who are certified geniuses on certain criteria are likely quite normal in other ways ‚Äî kinesthetic, emotional, spatial, musical, linguistic, etc.</p><p>Software engineering both selects for and develops certain types of intelligence, particularly around abstract reasoning, but  is born a great software engineer. <strong>Great engineers are made, not born</strong>. I just don‚Äôt think there‚Äôs a lot more we can get out of thinking of ourselves as a special class of people, compared to the value we can derive from thinking of ourselves collectively as relatively normal people who have practiced a fairly niche craft for a very long time.</p><h2>Build sociotechnical systems with ‚Äúnormal people‚Äù in mind</h2><p>When it comes to hiring talent and building teams, yes, absolutely, we should focus on identifying the ways people are exceptional and talented and strong. But when it comes to building sociotechnical systems for software delivery, we should focus on all the ways people are .</p><p>Normal people have cognitive biases ‚Äî confirmation bias, recency bias, hindsight bias. We work hard, we care, and we do our best; but we also forget things, get impatient, and zone out. Our eyes are inexorably drawn to the color red (unless we are colorblind). We develop habits and ways of doing things, and resist changing them. When we see the same text block repeatedly, we stop reading it.</p><p>We are embodied beings who can get overwhelmed and fatigued. If an alert wakes us up at 3 am, we are much more likely to make mistakes while responding to that alert than if we tried to do the same thing at 3pm. Our emotional state can affect the quality of our work. Our relationships impact our ability to get shit done.</p><p>When your systems are designed to be used by normal engineers, all that excess brilliance they have can get poured into the product itself, instead of wasting it on navigating the system itself.</p><h2>How do you turn normal engineers into 10x engineering teams?</h2><p>None of this should be terribly surprising; it‚Äôs all well known wisdom. In order to build the kind of sociotechnical systems for software delivery that enable normal engineers to move fast, learn continuously, and deliver great results as a team, you should:</p><h4>Shrink the interval between when you write the code and when the code goes live.</h4><p>Make it as short as possible; the shorter the better. I‚Äôve written and given talks about this many, many times. The shorter the interval, the lower the cognitive carrying costs. The faster you can iterate, the better. The more of your brain can go into the product instead of the process of building it.</p><p>One of the most powerful things you can do is have a short, fast enough deploy cycle that you can ship one commit per deploy. I‚Äôve referred to this as the ‚Äúsoftware engineering death spiral‚Äù ‚Ä¶ when the deploy cycle takes so long that you end up batching together a bunch of engineers‚Äô diffs in every build. The slower it gets, the more you batch up, and the harder it becomes to figure out what happened or roll back. The longer it takes, the more people you need, the higher the coordination costs, and the more slowly everyone moves.</p><p>Deploy time is the feedback loop at the heart of the development process. It is almost impossible to overstate the centrality of keeping this short and tight.</p><h4>Make it easy and fast to roll back or recover from mistakes.</h4><p>Developers should be able to deploy their own code, figure out if it‚Äôs working as intended or not, and if not, roll forward or back swiftly and easily. No muss, no fuss, no thinking involved.</p><h4>Make it easy to do the right thing and hard to do the wrong thing. <img data-recalc-dims=\"1\" loading=\"lazy\" decoding=\"async\" data-attachment-id=\"10018\" data-permalink=\"https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-sparkles/\" data-orig-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=1024%2C1024&amp;ssl=1\" data-orig-size=\"1024,1024\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"normal-sparkles\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=300%2C300&amp;ssl=1\" data-large-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=660%2C660&amp;ssl=1\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=137%2C137&amp;ssl=1\" alt=\"\" width=\"137\" height=\"137\" srcset=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?w=1024&amp;ssl=1 1024w\" sizes=\"auto, (max-width: 137px) 100vw, 137px\"></h4><p>Wrap designers and design thinking into all the touch points your engineers have with production systems. Use your platform engineering team to think about how to empower people to swiftly make changes and self-serve, but also remember that a lot of times people will be engaging with production late at night or when they‚Äôre very stressed, tired, and&nbsp;possibly freaking out. Build guard rails. The fastest way to ship a single line of code should also be the easiest way to ship a single line of code.</p><h4>Invest in instrumentation and observability.</h4><p>You‚Äôll never know ‚Äî not really ‚Äî what the code you wrote does just by reading it. The only way to be sure is by instrumenting your code and watching real users run it in production. Good, friendly sociotechnical systems invest  in tools for sense-making.</p><p>Being able to visualize your work is what makes engineering abstractions accessible to actual engineers. You shouldn‚Äôt have to be a world-class engineer just to debug your own damn code.</p><h4>Devote engineering cycles to internal tooling and enablement.</h4><p>If fast, safe deploys, with guard rails, instrumentation, and highly parallelized test suites are ‚Äúeverybody‚Äôs job‚Äù, they will end up nobody‚Äôs job. Engineering productivity isn‚Äôt something you can outsource. Managing the interfaces between your software vendors and your own teams is both a science and an art. Making it look easy and intuitive is really hard. It needs an owner.</p><h4>Build an inclusive culture.</h4><p>Growth is the norm, growth is the baseline. People do their best work when they feel a sense of belonging. An inclusive culture is one where everyone feels safe to ask questions, explore, and make mistakes; where everyone is held to the same high standard, and given the support and encouragement they need to achieve their goals.</p><h4>Diverse teams are resilient teams.<img data-recalc-dims=\"1\" loading=\"lazy\" decoding=\"async\" data-attachment-id=\"10017\" data-permalink=\"https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-transp-rainbow/\" data-orig-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=1024%2C1024&amp;ssl=1\" data-orig-size=\"1024,1024\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"normal-transp-rainbow\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=300%2C300&amp;ssl=1\" data-large-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=660%2C660&amp;ssl=1\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=196%2C196&amp;ssl=1\" alt=\"\" width=\"196\" height=\"196\" srcset=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?w=1024&amp;ssl=1 1024w\" sizes=\"auto, (max-width: 196px) 100vw, 196px\"></h4><p>Yeah, a team of super-senior engineers who all share a similar background can move incredibly fast, but a monoculture is fragile. Someone gets sick, someone gets pregnant, you start to grow and you need to integrate people from other backgrounds and the whole team can get derailed ‚Äî fast.</p><p>When your teams are used to operating with a mix of genders, racial backgrounds, identities, age ranges, family statuses, geographical locations, skill sets, etc ‚Äî when this is just table stakes, standard operating procedure ‚Äî you‚Äôre better equipped to roll with it when life happens.</p><h4>Assemble engineering teams from a range of levels.</h4><p>The best engineering teams aren‚Äôt top-heavy with staff engineers and principal engineers. The best engineering teams are ones where nobody is running on autopilot, banging out a login page for the 300th time; everyone is working on something that challenges them and pushes their boundaries. Everyone is learning, everyone is teaching, everyone is pushing their own boundaries and growing. All the time.</p><p>By the way ‚Äî all of that work you put into making your systems resilient, well-designed, and humane is the same work you would need to do to help onboard new engineers, develop junior talent, or let engineers move between teams.</p><p>It gets used and reused. Over and over and over again.</p><h2>The only meaningful measure of productivity is impact to the business</h2><p>The only thing that actually matters when it comes to engineering productivity is whether or not you are moving the business materially forward.</p><p>Which means‚Ä¶we can‚Äôt do this in a vacuum. The most important question is whether or not we are working on the right thing, which is a problem engineering can‚Äôt answer without help from product, design, and the rest of the business.</p><p>Software engineering isn‚Äôt about writing lots of lines of code, it‚Äôs about solving business problems using technology.</p><p>Senior and intermediate engineers are actually the workhorses of the industry. They move the business forward, step by step, day by day. They get to put their heads down and crank instead of constantly looking around the org and solving coordination problems. If you have to be a staff+ engineer to move the product forward, something is seriously wrong.</p><h2>Great engineering orgs mint world-class engineers</h2><p>A great engineering org is one where you don‚Äôt HAVE to be one of the best engineers in the world to have a lot of impact. But ‚Äî rather ironically ‚Äî great engineering orgs mint world class engineers like nobody‚Äôs business.</p><p>The best engineering orgs are not the ones with the smartest, most experienced people in the world, they‚Äôre the ones where normal software engineers can consistently make progress, deliver value to users, and move the business forward, day after day.<img data-recalc-dims=\"1\" loading=\"lazy\" decoding=\"async\" data-attachment-id=\"10019\" data-permalink=\"https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-system-does/\" data-orig-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=1024%2C1024&amp;ssl=1\" data-orig-size=\"1024,1024\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"normal-system-does\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=300%2C300&amp;ssl=1\" data-large-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=660%2C660&amp;ssl=1\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=253%2C253&amp;ssl=1\" alt=\"\" width=\"253\" height=\"253\" srcset=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?w=1024&amp;ssl=1 1024w\" sizes=\"auto, (max-width: 253px) 100vw, 253px\"></p><p>Places where engineers can get shit done and have a lot of impact are a magnet for top performers. Nothing makes engineers happier than building things, solving problems, making progress.</p><p>If you‚Äôre lucky enough to have world-class engineers in your org, good for you! Your role as a leader is to leverage their brilliance for the good of your customers and your other engineers, without coming to depend on their brilliance. After all, these people don‚Äôt belong to you. They may walk out the door at any moment, and that has to be okay.</p><p>These people can be phenomenal assets, assuming they can be team players and keep their egos in check. Which is probably why so many tech companies seem to obsess over identifying and hiring them, especially in Silicon Valley.</p><p>But companies categorically overindex on finding these people after they‚Äôve already been minted, which ends up reinforcing and replicating all the prejudices and inequities of the world at large. Talent may be evenly distributed across populations, but opportunity is not.</p><h2>Don‚Äôt hire the ‚Äúbest‚Äù people. Hire the right people.</h2><p>We (by which I mean the entire human race) place too much emphasis on individual agency and characteristics, and not enough on the systems that shape us and inform our behaviors.</p><p>I feel like a whole slew of issues (candidates self-selecting out of the interview process, diversity of applicants, etc) would be improved simply by shifting the focus on engineering hiring and interviewing away from this inordinate emphasis on hiring the BEST PEOPLE and realigning around the more reasonable and accurate RIGHT PEOPLE. <img data-recalc-dims=\"1\" loading=\"lazy\" decoding=\"async\" data-attachment-id=\"10023\" data-permalink=\"https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-hire/\" data-orig-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=1024%2C1024&amp;ssl=1\" data-orig-size=\"1024,1024\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"normal-hire\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=300%2C300&amp;ssl=1\" data-large-file=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=660%2C660&amp;ssl=1\" src=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=182%2C182&amp;ssl=1\" alt=\"\" width=\"182\" height=\"182\" srcset=\"https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?w=1024&amp;ssl=1 1024w\" sizes=\"auto, (max-width: 182px) 100vw, 182px\"></p><p>It‚Äôs a competitive advantage to build an environment where people can be hired for their unique strengths, not their lack of weaknesses; where the emphasis is on composing teams rather than hiring the BEST people; where inclusivity is a given both for ethical reasons and&nbsp;because it raises the bar for performance for everyone. Inclusive culture is what actual meritocracy depends on.</p><p>This is the kind of place that engineering talent (and good humans) are drawn to like a moth to a flame. . It feels  to move the business forward. It feels  to sharpen your skills and improve your craft. It‚Äôs the kind of place that people go when they want to become world class engineers. And it‚Äôs the kind of place where world class engineers want to stick around, to train up the next generation.</p>","contentLength":17307,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lfsa7f/in_praise_of_normal_engineers/"},{"title":"This Week in Rust #604","url":"https://this-week-in-rust.org/blog/2025/06/18/this-week-in-rust-604/","date":1750381651,"author":"/u/seino_chan","guid":163449,"unread":true,"content":"<p>Category: This Week in Rust</p><p>This week's crate is <a href=\"https://github.com/robustmq/robustmq\">RobustMQ</a>, a next-generation, high-performance, multi-protocol message queue.</p><p>Thanks to <a href=\"https://users.rust-lang.org/t/crate-of-the-week/2704/1443\">Yu Liu</a> for the self-suggestion!</p><p>An important step for RFC implementation is for people to experiment with the\nimplementation and give feedback, especially before stabilization.</p><p>If you are a feature implementer and would like your RFC to appear in this list, add a\n label to your RFC along with a comment providing testing instructions and/or\nguidance on which aspect(s) of the feature need testing.</p><p><a href=\"https://github.com/rust-lang/this-week-in-rust/issues\">Let us know</a> if you would like your feature to be tracked as a part of this list.</p><p>Always wanted to contribute to open-source projects but did not know where to start?\nEvery week we highlight some tasks from the Rust community for you to pick and get started!</p><p>Some of these tasks may also have mentors available, visit the task page for more information.</p><p>Are you a new or experienced speaker looking for a place to share something cool? This section highlights events that are being planned and are accepting submissions to join their event as a speaker.</p><p>Relatively quiet week, with a few improvements to benchmarks leveraging the new\ntrait solver.</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr><td align=\"center\">Improvements ‚úÖ  (secondary)</td></tr><tr></tr></tbody></table><p>3 Regressions, 7 Improvements, 4 Mixed; 4 of them in rollups\n51 artifact comparisons made in total</p><ul><li><em>No RFCs were approved this week.</em></li></ul><p>Every week, <a href=\"https://www.rust-lang.org/team.html\">the team</a> announces the 'final comment period' for RFCs and key PRs\nwhich are reaching a decision. Express your opinions now.</p><p>Let us know if you would like your PRs, Tracking Issues or RFCs to be tracked as a part of this list.</p><p>Rusty Events between 2025-06-18 - 2025-07-16 ü¶Ä</p><p>If you are running a Rust event please add it to the <a href=\"https://www.google.com/calendar/embed?src=apd9vmbc22egenmtu5l6c5jbfc%40group.calendar.google.com\">calendar</a> to get\nit mentioned here. Please remember to add a link to the event too.\nEmail the <a href=\"mailto:community-team@rust-lang.org\">Rust Community Team</a> for access.</p><blockquote><p>But after a few weeks, it compiled and the results surprised us. The code was 10x faster than our carefully tuned Kotlin implementation ‚Äì despite no attempt to make it faster. To put this in perspective, we had spent years incrementally improving the Kotlin version from 2,000 to 3,000 transactions per second (TPS). The Rust version, written by Java developers who were new to the language, clocked 30,000 TPS.</p><p>This was one of those moments that fundamentally shifts your thinking. Suddenly, the couple of weeks spent learning Rust no longer looked like a big deal, when compared with how long it‚Äôd have taken us to get the same results on the JVM. We stopped asking, ‚ÄúShould we be using Rust?‚Äù and started asking ‚ÄúWhere else could Rust help us solve our problems?‚Äù</p></blockquote>","contentLength":2571,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1lfrate/this_week_in_rust_604/"},{"title":"Replace Python with Go for LLMs?","url":"https://www.reddit.com/r/golang/comments/1lfr9hi/replace_python_with_go_for_llms/","date":1750381540,"author":"/u/Tobias-Gleiter","guid":163301,"unread":true,"content":"<p>I really wonder why we are using Python for LLM tasks because there is no crazy benefit vs using Go. At the end it is just calling some LLM and parsing strings. And Go is pretty good in both. Although parsing strings might need more attention.</p><p>Why not replacing Python with Go? I can imagine this will happen with big companies in future. Especially to reduce cost.</p><p>What are your thoughts here? </p>","contentLength":393,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Protecting an endpoint with OAuth2","url":"https://www.reddit.com/r/golang/comments/1lfpdd6/protecting_an_endpoint_with_oauth2/","date":1750375990,"author":"/u/riscbee","guid":163481,"unread":true,"content":"<p>I'm already using OAuth2 with the Authorization Code Flow. My web app is server-sided, but now I want to expose one JSON endpoint, and I'm not sure what flow to choose.</p><p>Say I somehow obtain a client secret and refresh token, do I just append the secret and the refresh token in the GET or POST request to my backend? Do I then use that access token to fetch the user email or ID and then look up if that user exists in my backend and fetch their permission?</p><p>Do I have to handle refreshing on my backend, or should the client do it? I'm not sure how to respond with a new secret and refresh token. After all, the user requests GET /private-data and expects JSON. I can't just return new secret and refresh tokens, no?</p>","contentLength":714,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fwupd 2.0.12 Released With More Intel Battlemage GPUs & HP USB-C Hub Supported","url":"https://www.phoronix.com/news/Fwupd-2.0.12-Released","date":1750375755,"author":"/u/reps_up","guid":163354,"unread":true,"content":"\nRichard Hughes of Red Hat just released Fwupd 2.0.12 as the newest version of this open-source firmware updating utility that pairs with the Linux Vendor Firmware Service (LVFS) for a nice Linux system/device firmware updating experience.\n<p>Building off the Intel Arc B-Series \"Battlemage\" support in prior Fwupd releases, Fwupd 2.0.12 adds support for firmware updates on additional Intel Arc Battlemage graphics cards. Fwupd 2.0.12 also supports firmware updates for more Foxconn 5G modems. Additionally, the HP Portable USB-C Hub can now support firmware updates via Fwupd/LVFS.\n</p><p>Fwupd 2.0.12 also adds a new configuration option for enforcing immutable device enumeration, device emulation support for Thunderbolt host controllers, support for loading multiple coSWID blocks from PE files, and a number of bug fixes. There are quite a range of bug fixes in Fwupd 2.0.12 from addressing firmware update issues with different devices to general fixes to this firmware updating utility itself.\n</p>Downloads and more details on the just-released Fwupd 2.0.12 via <a href=\"https://github.com/fwupd/fwupd/releases/tag/2.0.12\">GitHub</a>.","contentLength":1065,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1lfpach/fwupd_2012_released_with_more_intel_battlemage/"},{"title":"[D] Looks like someone is already offering B200 rentals for $1.49/hr ‚Äî anyone else seen this?","url":"https://www.reddit.com/r/MachineLearning/comments/1lfp5sb/d_looks_like_someone_is_already_offering_b200/","date":1750375388,"author":"/u/asklaylay","guid":163269,"unread":true,"content":"<div><p>Just came across this: DeepInfra is offering access to B200 Nvidia GPUs at $1.49/hour.</p></div>   submitted by   <a href=\"https://www.reddit.com/user/asklaylay\"> /u/asklaylay </a>","contentLength":118,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"No more coding vibes in the efficiency era","url":"https://devinterrupted.substack.com/p/no-more-coding-vibes-in-the-efficiency","date":1750374532,"author":"/u/benlloydpearson","guid":163239,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lfounc/no_more_coding_vibes_in_the_efficiency_era/"},{"title":"Using a Kubernetes credential provider with Cloudsmith","url":"https://www.youtube.com/watch?v=0E2fNx7oBn0","date":1750369131,"author":"/u/ExtensionSuccess8539","guid":163165,"unread":true,"content":"<p>Cloudsmith's SRE discusses the use of credential providers in Kubernetes to securely pull images from private repositories. Credential providers are a great new feature that appeared in recent versions of Kubernetes. They allow you to pull images using a short-lived authentication token, which makes them less prone to leakage than long-lived credentials - which improves the overall security of your software supply chain.</p>","contentLength":424,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1lfmu9f/using_a_kubernetes_credential_provider_with/"},{"title":"Liberux Nexx: An interview with Liberux about their made-in-EU OSHW Linux Phone","url":"https://linmob.net/liberux-nexx-an-interview-with-liberux/","date":1750368327,"author":"/u/wiki_me","guid":163270,"unread":true,"content":"<p>As you may have <a href=\"https://linmob.net/tags/liberux-nexx/\">heard or rather read</a>, the Spanish company Liberux recently launched a crowdfunder for their new mainline Linux \"<a href=\"https://liberux.net/#specs\">Nexx</a>\" phone on <a href=\"https://www.indiegogo.com/projects/liberux-nexx--3/pies\">Indiegogo</a> - starting at 8 GB RAM/128 GB eMMC/LTE for 799 EUR and going up to 32 GB RAM/512 GB/5G for 1300 (during the crowd-funder).</p><p>The specs include impressive things, such as two USB-C ports and a headphone jack - quite unusual these days. It's also somewhat modular (cellular modem, RAM, and storage are on modules) and they aim to open-source the hardware and plan to manufacture the devices in Spain - meaning, the Liberux Nexx will be (successful funding assumed) be one of the only (?) smartphones designed and build in Europe.</p><p>I asked Liberux for an interview, and they were happy to answer my questions. While they would have prefered to do this as a video interview, I just could not swing that (we're preparing to move, and I have to stand-in for a colleague on holiday at the dayjob right now) - so gladly, they agreed to do it in a back and forth via email. With that said, here you go:</p><p><em>Let's start with something broad: Why did you decide to make a Linux Phone? It is a tiny niche, the software ecosystem is still somewhat nascent, many challenges have not been solved and the market keeps adding new ones (e.g., Voice over LTE (VoLTE) or Rich Communication Services (RCS)). In addition to that, making specific hardware for FOSS (and/or privacy-) nerds is really difficult, as these people can be very nitpicky? So: Why?</em></p><p>We know it‚Äôs not an easy path. But it‚Äôs a necessary one. The dominant mobile operating systems are black boxes, serving interests that often don‚Äôt align with those of the user. We‚Äôre concerned about surveillance, the lack of real control over our devices, and the opacity of the software. We wanted to build something different: a phone designed with respect for the user's freedom, running an auditable OS with no backdoors. It's a bet on a future where you don‚Äôt have to give up your privacy to have a useful device. It‚Äôs not for everyone, but it is for those who value their digital autonomy.</p><p><em>What level of prior experience do members of your team have with hardware projects/phone or consumer electronics manufacturing and software development?</em></p><p>Our team has a mix of backgrounds, all with solid experience. Pedro, for example, developed the operating system (TuxumOS) for the first Linux tablet PC running on x86, and has collaborated with companies like Toshiba, Lenovo, and Fujitsu on Linux support and power management for their laptops. Carlos has designed mechanical keyboards and consumer electronic products. Our hardware design partner, <a href=\"https://pleeda.com/\">Pleeda</a>, has already developed and marketed its own portable game console. Ernesto Mansilla from <a href=\"https://ecaman.es/\">Ecaman</a>, our manufacturing partner, has extensive experience in the production and assembly of electronic boards. The team at Collabora, particularly their programming wizards, has been a huge help in defining the DTBs needed to boot the board. So no, we‚Äôre definitely not starting from scratch.</p><p><em>Some people have tried to cast doubt on your origins or even your integrity. What‚Äôs your response to those rumors?</em></p><p>Well, at first we found it quite amusing ‚Äî some of the things being said were wildly outlandish, involving bankers and politicians. It was kind of funny to see ourselves portrayed as being on the ‚Äúother side‚Äù of the conspiracy for once.</p><p>The truth is, free software is our life. Pedro started programming computers (an IBM 5150 his father brought home) when he was just 7 years old. He installed his first Slackware in 1993 using a stack of 3¬Ω-inch floppy disks, and he's been a Debian user since the Potato release ‚Äî with the occasional flirtation with BSD (nobody‚Äôs perfect).</p><p>In the end, we honestly don‚Äôt understand who would want to spread false information about a project whose sole goal is to provide the community with a freer, more secure phone.</p><p><em>You write that you've looked into the PinePhone (Pro) and Librem 5. What were the biggest mistakes or failures in your analysis of the PinePhone (Pro) and Librem 5 that you don't want to repeat? What did PINE64/Purism do really well in your opinion?</em></p><p>We deeply respect both projects for being pioneers. The PinePhone, for instance, was very affordable, but it was more of a development platform than a daily-use phone. The Librem 5 took so long to come out that its hardware was outdated by the time it was usable.</p><p>That said, they got many things right. PINE64 was brave enough to release several iterations that became key development platforms. Purism achieved very high build quality, even if the final design was bulky. Both have taught us what to avoid ‚Äî and also what‚Äôs worth preserving.</p><p><em>Where do you see yourself regarding software development? More aligned with PINE64 (who just do hardware) or with Purism, who basically made GNOME a thing on Mobile again?</em></p><p>We feel clearly more aligned with Purism. We want to offer equally polished and solid hardware, as well as a strong software development effort to go along with it.</p><p><em>Let's continue with pricing. I've seen discussions on the Fediverse, and you have added going two cheaper (yet still powerful) options with  8 or 16 GB RAM and 128 GB storage and LTE. Can you explain why the Liberux Nexx is more expensive than the average Android smartphone people may be comparing it with?</em></p><p>First, the components: 32 GB of RAM, 5G, and 512 GB of storage are not typical for devices in this space. On top of that, we manufacture in Europe and in small batches, which makes everything more expensive‚Äîfrom assembly to logistics. Every phone will be hand-assembled in our offices. Then there's the intangible: we don‚Äôt rely on big manufacturers or opaque supply chains. The price reflects our commitment to quality, transparency, and independence.</p><p><em>Let's get into hardware. Why did you decide to pick the RockChip RK3588s as the core for your product, and not, e.g., a chip from Qualcomm (e.g, QCM6490)? What makes the RK3588s a good choice for phone? Why pick it despite requiring proprietary firmware for GPU and DDR RAM?</em></p><p>The RK3588s is a well-known and respected chip in the Linux community, used in projects like the MNT Reform Next. Yes, it needs proprietary firmware for the GPU and DDR RAM ‚Äî but so do alternatives like Qualcomm, which typically include even more closed components. One of the key advantages of the RK3588s is that it doesn‚Äôt have an integrated 5G modem. This lets us isolate the modem physically and control it via a real kill switch‚Äîsomething much harder (if not impossible) with integrated Qualcomm SoCs. We also aim to work toward freeing the DDR firmware, something that's almost unthinkable on Qualcomm due to much stricter restrictions.</p><p><em>On design choices and details: Why does the Nexx have two USB-C ports?</em></p><p>Simply put: you often need to charge your device and connect something else at the same time. But there's a more ambitious reason too‚Äîwe want to make it easy to use the Nexx as a desktop computer, and two USB-C ports open up a lot of possibilities, especially with docks or keyboards. And let‚Äôs be honest‚Ä¶ it just looks awesome!</p><p><em>Does one (or both) of the USB-C ports support DisplayPort Alt Mode, so that I can plug into a display without carrying accessories?</em></p><p>Yes, at least one of the ports will provide direct DisplayPort output, allowing you to use the Nexx as a desktop without additional docks.</p><p><em>What are the transfer speeds that can be expected from the USB ports (USB 2.0, 3.x)? What are your plans regarding USB Power Delivery support?</em></p><p>Both ports will be USB 3.1. We‚Äôre also working on implementing support for USB Power\nDelivery, with proper energy delivery for fast charging and accessory compatibility.</p><p><em>Regarding WiFi/BT and LTE/5G: Purism made the unusual choice of making these socketed and exchangeable; I presume this is not the case with your design, the hardware kill switches ensure that components can be truly turned of. Sadly, there don't seem to be any blob-free choices. What are the main criteria to pick hardware here?</em></p><p>Our priority was balancing performance and Linux compatibility. The 5G modem will be replaceable‚Äîit‚Äôs mounted on a small FPC board, making it easy to swap without the bulk of traditional sockets. Wi-Fi and Bluetooth are soldered directly to the board, but both are connected to physical kill switches that cut power entirely, ensuring they‚Äôre really off. We know there are no fully free options yet, but we‚Äôve chosen components with good Linux support and low power usage, minimizing blobs without sacrificing usability.</p><p><em>Battery life has been an issue with the existing native Linux phones. How do you plan to optimize for this?</em></p><p>It‚Äôs one of our top priorities. We‚Äôre developing a dedicated daemon to manage power more efficiently‚Äîit will shut down and wake up CPU cores depending on load, adjust frequencies dynamically, and optimize idle performance. We‚Äôre also working on smarter suspend and resume behavior, including options like RTC wake, wake-on-WAN, power button, or even tapto-wake. Brightness management will also adapt more intelligently to real usage conditions. All this aims to extend battery life without compromising the experience.</p><p><em>Some important phone features are set by hardware choices. Unfortunately, Voice over LTE has become mandatory in some markets (and the number of markets, where this is the case, will only grow) - is it a major deciding factor when choosing the 5G part?</em></p><p>Yes, we considered that. We want the Nexx to feature modern hardware compatible with the latest technologies. VoLTE is increasingly essential, and we see it as key to ensuring a good\nuser experience and long-term compatibility.</p><p><em>Aside from necessary certifications, you are also going for a OSHW certification - does this mean Liberux Nexx will be Open Source Hardware?</em></p><p>Yes, that‚Äôs our goal. We want the Nexx to be open source hardware, which is why we‚Äôll release the schematics with the first units shipped. Other assets (like full mechanical designs and manufacturing files) might come a bit later. Our initial idea was to release everything once we hit about 10,000 units sold. What matters most to us is building something open and transparent‚Äîeven if we have to take it step by step.</p><p><em>Accessories. Maybe this is just my age (and growing grumpiness) showing, but - and especially from my experience with existing Linux Phones - why the Wireless Dock (W-Dock) for the\n\"use phone as a PC\" use case? I would have rather gone with a nice USB dock that has a silent fan to keep the phone cool to not suffer from throttling.</em></p><p>We totally get that! In fact, we‚Äôre not ruling out that more traditional option. But Pedro had already developed an interesting solution to access the device remotely via RDP, which opened the door for us to explore a wireless dock. The main advantage is that you can keep using the phone for things like calls without unplugging it. Still, we know a USB dock with passive or silent cooling has real value, and it‚Äôs definitely on the table as a future accessory.</p><p><em>The Liberux Mechanical Keyboard sounds interesting. Any idea on pricing? Will it be available separately?</em></p><p>Yes, we plan to offer it separately‚Äîeven in a black version‚Äîand it will likely be under ‚Ç¨200 (excluding taxes). It‚Äôs inspired by the legendary IBM Model F, but in a more compact format. We even want to implement the buckling spring mechanism those keyboards had almost 50 years ago, since we think it still outperforms any modern keyboard. The goal is to deliver that unmistakable mechanical experience in a more portable and modern design.</p><p><em>Let's tackle software.\nYou write that \"LiberuxOS (based on Debian 13 Linux) is an ethical and mostly opensource operating system.\" Which parts will be non-open-source? Just firmware, or also drivers / custom user space software (e.g., apps)?</em></p><p>Our goal is to release everything we can. There will be some unavoidable blobs, like firmware for the GPU or modem, but all apps we develop will be open source. We won‚Äôt include closed software‚Äîeither ours or from third parties. Any new developments, such as interfaces or tools, will be published from day one.</p><p><em>Are you intending to ship a (close to) mainline kernel, or a Board Support Package (BSP)/vendor kernel and make it work with a libhybris/Halium approach?</em></p><p>We‚Äôll go with bare-metal Linux‚Äîno Halium, no libhybris. We want to stay as close to mainline as possible and actively contribute upstream.</p><p><em>Do you intend generally develop software bits in the open where possible or just where required by license?</em></p><p>We‚Äôll develop everything openly. Our policy is to publish code, collaborate with the community, and be transparent. Free software, for us, is a matter of principle‚Äînot just legal compliance.</p><p>_Why go with a distribution of your own and not partner with existing projects (e.g., postmarketOS, Mobian, Ubuntu Touch, Sailfish OS)? Given that you are basing on Debian, a collaboration with Mobian (or, if vendor kernel Droidian) may lead to obvious synergies. Are you exploring this?</p><p>Yes, we‚Äôve considered it‚Äîespecially Mobian, since we share a base. But building our own distro lets us better tailor the system to the hardware and to the kind of use we want to promote. That said, it‚Äôs not mutually exclusive: we want to make porting other distros as easy as possible and collaborate with anyone interested.</p><p><em>Why GNOME Shell Mobile and not Phosh? In my experience, Phosh is better at dealing\nthe occasional app/dialog that's not quite ready for mobile.</em></p><p>We considered Phosh. But GNOME Shell Mobile gives us more room long-term in terms of customization, animations, and graphical performance. That said, we‚Äôre doing significant work on top of GNOME Shell to make it more mobile-friendly. Phosh is more mature in some areas, but we‚Äôre betting on something we can evolve more freely.</p><p><em>Which parts of GNOME Shell Mobile do you intend to improve on for the Liberux Nexx?</em></p><p>We‚Äôre working on better window management, visual improvements, and a more refined touch experience with intuitive gestures. We want using the Nexx to feel smooth and pleasant from the very first boot.</p><p><em>Since I've attended [Akademy]( last year: Why not Plasma Mobile?</em></p><p>We think Plasma Mobile is a great option and respect it a lot, but for our goals, it didn‚Äôt align as well. Given our limited resources, we had to focus on a single interface, and GNOME Shell Mobile fits our vision better, even if it also needs polishing.</p><p><em>Are you in talks with community members/known Linux Mobile developers?</em></p><p>Yes, we‚Äôre already in touch with various developers and projects.</p><p>[I have asked a follow-up and known-to-me names have been mentioned, but to preserve privacy, these names are not included here.]</p><p><em>Are there ways the community/interested people can help you make the Liberux Nexx happen, despite ordering on Indiegogo (especially for those, that would like to get the phone, but can't afford it right now)?</em></p><p>Any help is welcome: from spreading the word to contributing code. We also accept donations so people who can‚Äôt afford the phone can still support the project.</p><p>We want this to be a community effort‚Äînot just our own.</p><h3>More questions? Let me know!</h3>","contentLength":15161,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1lfmitn/liberux_nexx_an_interview_with_liberux_about/"},{"title":"[D] GPT-2 Small Not Converging Despite Using Same Hyperparams as Karpathy","url":"https://www.reddit.com/r/MachineLearning/comments/1lflwvu/d_gpt2_small_not_converging_despite_using_same/","date":1750366797,"author":"/u/New-Skin-5064","guid":163353,"unread":true,"content":"<p>For some reason, my training loss keeps oscillating, and never falls below 4 after one epoch. It is still generating garbage like: \"Once upon a time, with a alone example, pre Deg; is a disease, the American casual Plate. Roberts of campaign\"(Once upon a time was the prompt). I am using the GPT-2 Small architecture and training on FineWeb-Edu 10B. The batch size is ~525k tokens, and I use 0.1 dropout. Because the Kaggle TPU times out after 9 hours, I would reupload the latest checkpoint the next day to resume training, which I think is why the learning rate randomly spikes in the graph. I checked my dataloader, and it appears to be loading text from the shards correctly. If anybody knows what I am doing wrong, I would appreciate your feedback. </p><p>I also modified the same pipeline, shrank the model, and trained on TinyStories v2, and the model began to generate better text after 900 steps than the other did in over 20 thousand! The only difference between the two pipelines is the dataloader, as FineWeb is sharded but TinyStories is not. That implementation can be found here: <a href=\"https://github.com/sr5434/llm/blob/main/gpt-2-pretraining.ipynb\">https://github.com/sr5434/llm/blob/main/gpt-2-pretraining.ipynb</a></p>","contentLength":1151,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Question about Networking Setup (Calico) with RKE2 Cluster","url":"https://www.reddit.com/r/kubernetes/comments/1lfl8g4/question_about_networking_setup_calico_with_rke2/","date":1750365082,"author":"/u/wwebdev","guid":163145,"unread":true,"content":"<p>I'm running a small Kubernetes cluster using RKE2 on Azure, consisting of two SUSE Linux nodes:</p><p>Both nodes are running fine, but they are not in the same virtual network. Currently, I‚Äôve set up a WireGuard VPN between them so that Calico networking works properly.</p><ol><li><p>Is it necessary for all nodes in a Kubernetes cluster to be in the same virtual network for Calico to function properly?</p></li><li><p>Is using WireGuard (or any VPN) the recommended way to connect nodes across separate networks in a setup like this?</p></li><li><p>What would be the right approach if I want to scale this cluster across different clouds (multi-cloud scenario)? How should I handle networking between nodes then?</p></li></ol><p>I‚Äôd really appreciate your thoughts or any best practices on this. Thanks in advance!</p>","contentLength":750,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Golang Runtime internal knowledge","url":"https://www.reddit.com/r/golang/comments/1lfk3te/golang_runtime_internal_knowledge/","date":1750362285,"author":"/u/SpecialistQuote9281","guid":163147,"unread":true,"content":"<p>Hey folks, I wanted to know how much deep knowledge of go internals one should have.</p><p>I was asked below questions in an interviews:</p><p>How does sync.Pool work under the hood?</p><p>What is the role of poolChain and poolDequeue in its implementation?</p><p>How does sync.Pool manage pooling and queuing across goroutines and threads (M‚Äôs/P‚Äôs)?</p><p>How does channel prioritization work in the Go runtime scheduler (e.g., select cases, fairness, etc.)?</p><p>I understand that some runtime internals might help with debugging or tuning performance, but is this level of deep dive typical for a mid-level Go developer role?</p>","contentLength":591,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Struggling with Rust's module system - is it just me?","url":"https://www.reddit.com/r/rust/comments/1lfjm7u/struggling_with_rusts_module_system_is_it_just_me/","date":1750361065,"author":"/u/eight_byte","guid":163084,"unread":true,"content":"<p>As I'm learning Rust, I've found the way modules and code structure work to be a bit strange. In many tutorials, it's often described as being similar to a file system, but I'm having a hard time wrapping my head around the fact that a module isn't defined where its code is located.</p><p>I understand the reasoning behind Rust's module system, with the goal of promoting modularity and encapsulation. But in practice, I find it challenging to organize my code in a way that feels natural and intuitive to me.</p><p>For example, when I want to create a new module, I often end up spending time thinking about where exactly I should define it, rather than focusing on the implementation. It just doesn't seem to align with how I naturally think about structuring my code.</p><p>Is anyone else in the Rust community experiencing similar struggles with the module system? I'd be really interested to hear your thoughts and any tips you might have for getting more comfortable with this aspect of the language.</p><p>Any insights or advice would be greatly appreciated as I continue my journey of learning Rust. Thanks in advance!</p>","contentLength":1099,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go should be more opinionated","url":"https://eltonminetto.dev/en/post/2025-06-19-go-more-opinated/","date":1750359144,"author":"/u/eminetto","guid":163120,"unread":true,"content":"<p>One of the perks of being&nbsp;a <a href=\"https://g.dev/eminetto\">Google Developer Expert</a>&nbsp;is the incredible opportunities it provides. A few weeks ago, I had the opportunity to meet&nbsp;<a href=\"https://en.wikipedia.org/wiki/Robert_Griesemer\">Robert Griesemer</a>, co-creator of Go, in person, as well as&nbsp;<a href=\"https://www.linkedin.com/in/doughertymarc/\">Marc Dougherty</a>, Developer Advocate for the Go team at Google. At a happy hour after Google I/O, Marc asked me and another Go GDE from Korea for feedback on the language. My response was that I didn‚Äôt have any specific feedback about the language but that:</p><blockquote><p>Go should be more opinionated about the application layout.</p></blockquote><p>It was worth writing a post to express my thoughts more clearly.</p><p>Starting from the beginning‚Ä¶</p><p>In 2025, I will have completed 10 years of writing code in Go. One of the things I recall from when I started is that the language was relatively simple to learn, mainly due to two reasons: its simplicity and the fact that there is only one way to do things. Go was the first language I came across that had strong opinions about several things. There is only one way to loop, and there is only one way to format files (using the ‚Äògo fmt‚Äô command). Variables with a small scope should have short names, etc. It made it much easier to read code written by other people, which is crucial for learning. The code I wrote was very similar to the Kubernetes code! Of course, the complexity of the problem was infinitely greater, but the code‚Äôs structure was readable to me. Over the years, I have observed this effect in several people I have followed who were starting in the language or migrating from other environments.</p><p>But once this initial excitement has passed, the biggest challenge comes: how to adopt Go in a project larger than those used for learning? How do you structure a project that will be developed and evolved by a team? At this point, the language step aside from strong opinions, and each team or company needs to decide how to structure their projects. Over the past decade, I have worked for four companies. In all of them, it was necessary to invest the team‚Äôs time in collecting examples and reading documentation and books to determine which structure they should use in the projects.&nbsp;At the company where I currently work, we have created a <a href=\"https://medium.com/inside-picpay/organizing-projects-and-defining-names-in-go-7f0eab45375d\">document</a> about this.</p><p>Making an analogy with the world of games, it‚Äôs as if we were having fun in the controlled and wonderful world of Super Mario World and were transported to the open world of GTA 6 (yes! I‚Äôm hyped!). It‚Äôs still a fantastic universe, but the transition is quite abrupt.</p><p>Go could be more opinionated regarding these choices. We could have templates for more common projects, such as CLIs, APIs, and microservices., that teams can use to scaffold their applications. The language toolkit <a href=\"https://go.dev/blog/gonew\">already&nbsp;allows the use of project templates</a>,&nbsp;so it would be a matter of having official templates to make life easier for teams. Alternatively, we could go further and include the command in the language toolkit itself with something like .</p><p>A similar event occurred in the history of the language. Today,&nbsp; dependency management is a fundamental part of our daily lives as Go developers. But it wasn‚Äôt always like this. For a long time, there was no official package manager for the language; consequently, the community developed several alternatives. They all worked, but fragmentation was getting out of control, making it challenging to integrate packages. Until the language team took control of the situation and&nbsp; was created, pacifying the issue of ‚Äúpackage and dependency management.‚Äù I believe we can apply the same approach to the structure of projects.</p><p>Another profile that would benefit from a more opinionated project structure is that formed by teams that are migrating their applications from other languages, especially Java and PHP. In these ecosystems, frameworks dictate the structure of projects, such as Spring Boot and Laravel. ‚ÄúWhere do I start? How do I structure my project?‚Äù are common questions I hear from teams migrating from these languages. Having something that facilitates this migration would lower the barrier to entry and increase the number of teams experimenting with Go in production.</p><p>That‚Äôs my biggest feedback regarding Go at the moment. What do you think, dear reader? What‚Äôs your opinion on the subject? I‚Äôd love to discuss this topic in the comments or live at a conference.</p>","contentLength":4330,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1lfita0/go_should_be_more_opinionated/"},{"title":"[D] Future of RecSys in age of LLM","url":"https://www.reddit.com/r/MachineLearning/comments/1lfijb4/d_future_of_recsys_in_age_of_llm/","date":1750358477,"author":"/u/Electrical-Job-3373","guid":163221,"unread":true,"content":"<p>I have significant experience in recommendation system. Right now I don‚Äôt see any changes due to LLM. Most recommendation system needs low latency, which is not feasible currently with LLM. Do you think RecSys is safe from LLM takeover? Should RecSys domain experts like me should be worried?</p>","contentLength":294,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Announcing TokioConf 2026","url":"https://tokio.rs/blog/2025-06-19-announcing-tokio-conf","date":1750357810,"author":"/u/Darksonn","guid":163085,"unread":true,"content":"<p>We‚Äôre happy to announce the inaugural , a dedicated conference for\ndevelopers building asynchronous network applications in Rust. It will be a\nsingle-track event bringing together developers from many areas to talk about\nhow they use Tokio and Rust to build high-performance, reliable production\napplications. Expect talks, panels, and time to share challenges and lessons\nlearned.</p><p>More and more teams are using Rust and Tokio in production, and they‚Äôre all\ntackling similar challenges‚Äîbringing Rust into existing systems, helping new\ndevelopers get up to speed, designing for reliability, and figuring out how to\ntest and deploy async code at scale.  is a space for those\nconversations to swap ideas, learn from each other, and help the community\nfigure out where async Rust goes next.</p><p>We‚Äôve got ideas for topics we‚Äôd love to see‚Äîdebugging async code, instrumenting\nproduction systems, or successfully introducing Rust at work. But for now,\n<strong>TokioConf is a blank canvas</strong>, and we want to hear from .</p><p>What talks would help you build faster, more reliable async applications? What\nchallenges are you facing? Let us know! Drop a comment on the Reddit thread, or\nmention us on <a href=\"https://bsky.app/profile/tokioconf.com\">Bluesky</a> or <a href=\"https://hachyderm.io/@tokioconf\">Mastodon</a>.</p><p>The  is opening soon, and we can‚Äôt wait to hear your\nideas.</p><p>Want to be the first to know when the CFP and ticket sales go live? Sign up for\nemail updates at <a href=\"https://tokioconf.com\">tokioconf.com</a>, or follow us on\n<a href=\"https://bsky.app/profile/tokioconf.com\">Bluesky</a> or <a href=\"https://hachyderm.io/@tokioconf\">Mastodon</a>.</p><p>We‚Äôre so excited to bring the community together‚Äîsee you in Portland next year!</p>","contentLength":1492,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1lfi9bn/announcing_tokioconf_2026/"},{"title":"pshunt: go terminal app for easily searching for processes to kill","url":"https://github.com/jamesma100/pshunt","date":1750354966,"author":"/u/battle-racket","guid":163629,"unread":true,"content":"<p>I made a simple terminal app for searching for and killing processes. Go and the gocui package made this super easy! I mostly built it for personal use but decided to open source it. Let me know what you think!</p>","contentLength":210,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1lfh1pl/pshunt_go_terminal_app_for_easily_searching_for/"},{"title":"Java meets JavaScript: dynamic object rendering","url":"https://blog.picnic.nl/java-meets-javascript-a-modern-approach-to-dynamic-page-rendering-31250dc66f33","date":1750354733,"author":"/u/AndrewStetsenko","guid":163034,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lfgy2h/java_meets_javascript_dynamic_object_rendering/"},{"title":"Securing Clusters that run Payment Systems","url":"https://www.reddit.com/r/kubernetes/comments/1lfgtyj/securing_clusters_that_run_payment_systems/","date":1750354458,"author":"/u/Icy_Raccoon_1124","guid":163083,"unread":true,"content":"<p>A few of our customers run payment systems inside Kubernetes, with sensitive data, ephemeral workloads, and hybrid cloud traffic. Every workload is isolated but we still need guarantees that <strong>nothing reaches unknown networks or executes suspicious code</strong>. Our customers keep telling us one thing</p><p>‚ÄúEnsure  ever talks to a C2 server.‚Äù</p><p>How do we ensure our DNS is secured?</p><p>Is runtime behavior monitoring (syscalls + DNS + process ancestry) finally practical now? </p>","contentLength":458,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The PostgreSQL Locking Trap That Killed Our Production API (and How We Fixed It)","url":"https://root.sigsegv.in/posts/postgresql-locking-trap/","date":1750352664,"author":"/u/N1ghtCod3r","guid":163086,"unread":true,"content":"<p>A simple  statement can bring down your production infrastructure if you‚Äôre not careful.\nThis is the story of me waking up to production alerts while working on totally unrelated tasks (building slides for some business stuff),\ngetting bamboozled, instinctively blaming most recent production infrastructure change and eventually figuring out how deep the rabbit hole goes.</p><p>Here is the chain of events if you are skimming through:</p><ol><li>Google Cloud monitoring policy triggered on database error threshold breach</li><li>Production APIs showing high latency and intermittent timeouts</li><li>Initially blamed the recently deployed database read replicas as the root cause</li><li>Stopped replication, restarted database instance for service restoration</li><li>Quickly figured out the issue reappeared on high load</li><li>Manually deleted PostgreSQL replication slot from primary database instance</li><li>Manually deleted read replica instances (non-critical), hoping against hope</li><li>Raised support ticket with Google cloud</li><li>Slow query analysis showed multiple pending  queued up</li><li>Shocked realizing that we ran an  on a very large and read heavy table even with multiple guardrails in place</li><li>Killed all  queries and blocked all schema migration in production till a permanent fix was implemented</li><li>All services restored. FINALLY!</li><li>Identified the root cause as a lock contention issue across multiple background job workers, schema migrator and long running transactions</li><li>Isolated application level locking from business logic tables to a common locks table to avoid lock contention with  which in turn locks the entire table</li><li>All Services restored including internal release related services</li></ol><h2>The Incident: When Everything Just‚Ä¶ Stopped</h2><p>It started with Google Cloud monitoring alerts triggered on database error threshold being breached. Saw a whole bunch of error logs\nwith <code>Context cancelled by user</code> statement.</p><p>The immediate reaction (panic) was to blame the recently provisioned read replica for the production database instance. This was done to\nsafely execute internal analytical queries with Metabase, a non-critical internal service. My response was</p><ul><li>Stop the replication in the replica instance using Google Cloud console</li><li>Restart the primary database instance hoping that any performance issues due to replication would be resolved</li></ul><p>This temporarily restored the services but the errors quickly returned. It also correlates with time of the day when our usage is at\nits peak. My mind correlated this by making a hypothesis that we introduced a new query that may have a missing index leading to\na table scan. But I could not validate this hypothesis by looking at CPU, memory and IO metrics of the primary database instance.</p><p>In fact, we did not see any replication lag during the last 24 hours. This made me question my hypothesis of the issue caused by\nread replicas. Even though that was the most recent infrastructure change that I could confirm looking at our Terraform repository\ncommit history. Finally decided its time to dig deep because of:</p><ol><li>No CPU / memory / IO wait metric anomaly for primary database instance</li><li>No replication lag in read replicas</li><li>Binary log size (storage) started increasing on primary when replication was stopped. This is expected due to active replication slots in the primary.</li><li>Manually deleted PostgreSQL replication slots from primary database instance</li><li>Even deleted the replicas assuming some weirdness with Google CloudSQL and its internal high availability configuration</li></ol><p>Find the slots used by replicas.</p><div><pre tabindex=\"0\"><code data-lang=\"sql\"></code></pre></div><div><pre tabindex=\"0\"><code data-lang=\"sql\"></code></pre></div><h2>The Real Culprit: Lock Contention Hell</h2><p>It was clear that  is not going to fix the issue. It was time to dig deeper. Retrospectively, I think I planned to do the following:</p><ol><li>Identify long running or expensive queries</li><li>Identify the root cause of the expensive queries</li><li>Optimize them by rewriting them or using appropriate indexes</li></ol><p>The following query was used to list all active queries and sort them by the query age. This gives a view of the long running queries along with the  and other information required to kill the query if required.</p><div><pre tabindex=\"0\"><code data-lang=\"sql\"></code></pre></div><ul><li>Multiple  style locks waiting to be acquired</li><li>Multiple <code>ALTER TABLE .. ADD COLUMN</code> statements queued up</li><li>Multiple <code>INSERT .. ON CONFLICT DO NOTHING</code> statements queued up</li></ul><p>The most interesting bit is, all these queries were waiting to acquire a lock on the  table. This is the table where we store OSS package scanning jobs powering <a href=\"https://github.com/safedep/vet\">SafeDep vet</a>, updated by background job workers and queried by a user facing API. At this point, I was fairly sure it is a lock contention issue but wanted to confirm it before taking any action, especially since I already exhausted myself by reverting infrastructure changes as panic response.</p><h2>The Perfect Storm: How It All Went Wrong</h2><p>Lets have a quick look at the components that act on the  table and how they interact with each other. The system consists of the following logical components:</p><ol><li>Submission API that is idempotent and can be retried without creating duplicate jobs</li><li>Background job workers that actually execute an OSS package analysis job with a timeout of 15 minutes</li><li>Query API that is used to fetch the status and results of a job by its job identifier</li></ol><p>We also have a schema migrator built as part of our application development framework, which internally executes <a href=\"https://gorm.io/\">GORM</a> migrations with additional safety checks that guarantee timeouts, global locks, audit logs and more.</p><p>Our API framework is built to execute a business logic (service layer) in transaction by default for consistency unless explicitly opted out by the service specification. We generally opt out of transactions only for read-only operations. In case of the submission API, the service logic does the following in a transaction:</p><ol><li>Check if the job already exists in the database</li><li>Create a new job record in the database if it does not exist</li><li>Create a background job to execute the OSS package analysis job (transactional consistency)</li><li>Return the job identifier to the client</li></ol><p>Note: The submission API is idempotent which requires attempting to read a row from the  table to check if the job already exists before performing an  operation. The table uses unique index constraints to guarantee idempotency even when there is a race condition. This means,  cannot be concurrent.</p><blockquote><p>INSERT into tables that lack unique indexes will not be blocked by concurrent activity. Tables with unique indexes might block if concurrent sessions perform actions that lock or modify rows matching the unique index values. <a href=\"https://www.postgresql.org/docs/current/sql-insert.html\">Ref</a></p></blockquote><h3>Package Analysis Business Logic</h3><p>The background job workers execute the OSS package analysis job with a timeout of 15 minutes. The job is executed in a transaction and the following steps are performed:</p><ol><li>Acquire a row-level lock on the  record to prevent multiple workers from executing the same job concurrently</li><li>Execute a long running RPC call to an external service that takes up to 5 minutes to complete</li><li>Update the job record in the database</li></ol><p>Example code snippet from the background job worker:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>The schema migrator is a tool that we use to safely apply schema changes to the database. In this particular case, following was the schema change that triggered the issue:</p><div><pre tabindex=\"0\"><code data-lang=\"diff\"></code></pre></div><p>This schema change adds two new columns to the  table along with adding indexes on them.\nThis translates to the following SQL statement:</p><div><pre tabindex=\"0\"><code data-lang=\"sql\"></code></pre></div><ol><li><code>ALTER TABLE .. ADD COLUMN</code> statement needs an  on the table even though its just a table metadata update</li><li>The index creation is a separate operation that, by default, needs an  on the table unless  is explicitly specified</li></ol><blockquote><p>PostgreSQL supports building indexes without locking out writes. This method is invoked by specifying the CONCURRENTLY option of CREATE INDEX. <a href=\"https://www.postgresql.org/docs/current/sql-createindex.html\">Ref</a></p></blockquote><h3>The Lock Hierarchy That Kills</h3><p>Here‚Äôs what PostgreSQL‚Äôs <a href=\"https://www.postgresql.org/docs/current/explicit-locking.html\">documentation</a> tells us about :</p><blockquote><p>‚ÄúConflicts with ALL other lock modes. Guarantees that the holder is the only transaction accessing the table in any way.‚Äù</p></blockquote><p>Now that we saw the lock hierarchy, we can see there are multiple contenders that contributed to the incident by holding locks or trying to lock the entire tabling by requesting .</p><p>The root cause of the issue is the following sequence of events:</p><ol><li> - Acquire row-level locks on </li><li> - Waits for  on </li><li><strong>New Submission API requests arrive</strong> - Queue behind the  waiting for table access</li><li> - All API (app) server Go routines blocked on database calls</li><li> - API becomes unresponsive, not just for impacted tables but for all API endpoints</li></ol><p>Two things were clear so far:</p><ol><li>Long running transactions are toxic - The best practices are right!</li><li>Schema migration on large and busy tables are VERY VERY risky</li></ol><p>Lets ignore the fact that we tried creating an index on a large table, we can mitigate it by updating our schema migration process to leverage maintenance window and concurrency primitives offered by PostgreSQL. But this incident can repeat again even for a harmless <code>ALTER TABLE .. ADD COLUMN</code> statement that only modifies table metadata. This is because, the  will wait for  on the table even though its just a table metadata update. Row level locks held by background job workers makes the table slow and risky for schema changes.</p><p>Locking is however an application primitive that we need. We have two options:</p><ol><li>Use an external service like Redis for locking</li><li>Isolate locking from business logic tables to a common locks table</li></ol><p>While blogs and other common wisdom points to [1], we decided against it because it introduces additional complexity of serializing locks and data access across multiple services ie. PostgreSQL and Redis. We decided to continue leverage PostgreSQL for resource (row) level locks but isolate them from business logic tables that may be changed as and when required. Instead, we decided to introduce a common  table that will rarely require schema changes because it offers a single primitive ie. lock a row by  and .</p><h3>Before: Direct Table Locking</h3><p>Service level, adhoc locking pattern before the incident:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>Common resource locking API for use by the service layer. While currently it leverages PostgreSQL backend for locking, the API offers abstractions for us to keep options open for future.</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>Finally, the business logic can be executed without holding any locks on the business logic table\nand leveraging the common resource locking API.</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>So far so good. We have a fix in place. But there are challenges with deployment because it requires schema changes and background job workers to be restarted. We were reluctant to execute schema changes in production without a proper maintenance window but we also needed to unblock releases that required schema changes. So we roughly took the following steps:</p><ol><li>Paused all background jobs for the queue that was running the OSS package analysis jobs to avoid any row level locks on the  table</li><li>Waited for all existing jobs to complete and verified no queued queries in the database</li><li>Deployed the fix to production</li><li>Applied the schema changes for common locks table</li><li>Restarted all background jobs for the queue</li></ol><p>Aha! thats how it looks like after the fix, with usual schema migration and background job workers running again.</p><h2>The Key Insight: Lock Isolation</h2><p>The breakthrough was realizing that <strong>serialization requirements</strong> and  are orthogonal concerns. You don‚Äôt need to lock the  table to ensure only one password reset email goes out. You don‚Äôt need to lock the  table to prevent duplicate payment processing. You need a coordination mechanism that‚Äôs separate from your data storage. This ensures both application queries and schema management operations are not blocking by long held locks which may be required by the business logic (service layer).</p><p>This isn‚Äôt about PostgreSQL being bad or Go being bad or our architecture being bad. This is about the fundamental tension between  and <strong>availability requirements</strong> in distributed systems. The CAP theorem suddenly seems more real, it shows up in your production database unexpectedly when you are trying to add a column and your API dies.</p>","contentLength":11752,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lfg2bx/the_postgresql_locking_trap_that_killed_our/"},{"title":"A major update of Aralez: High performance, pure Rust, OpenSource proxy server","url":"https://www.reddit.com/r/rust/comments/1lffvox/a_major_update_of_aralez_high_performance_pure/","date":1750352242,"author":"/u/sadoyan","guid":163033,"unread":true,"content":"<p>Hi <a href=\"https://www.reddit.com/r/rust/\">r/rust</a>! I am developing OpenSource <a href=\"https://github.com/sadoyan/aralez\"></a> (Renamed per your <a href=\"https://www.reddit.com/r/rust/comments/1l7x82y/gazan_high_performance_pure_rust_opensource_proxy/\">suggestions</a>). A new reverse proxy built on top of Cloudflare's Pingora.</p><p>Beside all cool features below I have added a new one. Now it can dynamically bulk load SSL certificates from disk and apply per domain, without any configuration. All you need is to set up a path fro certificates . </p><p>It's full async, high performance, modern reverse proxy with some service mesh functionality with automatic  and  detection and proxy support.</p><p>It have built in  authentication support with token server, Prometheus exporter and many more fancy features.</p><p>100% on Rust, Built on top of  fantastic library: <a href=\"https://github.com/cloudflare/pingora\"></a> . My recent tests shows it can do  requests per second on moderate hardware.</p><p>Prebuilt  and  libraries for  and  from are available in <a href=\"https://github.com/sadoyan/gazan/releases\">releases</a> .</p><p>If you like this project, please consider giving it a star on <a href=\"https://github.com/sadoyan/aralez\"></a>! I also welcome your contributions, such as opening an issue or sending a pull request. Mentoring and suggestions are welcome.</p>","contentLength":978,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The craziest things revealed in The OpenAI Files","url":"https://www.reddit.com/r/artificial/comments/1lff4gj/the_craziest_things_revealed_in_the_openai_files/","date":1750350417,"author":"/u/MetaKnowing","guid":163035,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/MetaKnowing\"> /u/MetaKnowing </a>","contentLength":34,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"We finally released v3.4 of ttlcache","url":"https://www.reddit.com/r/golang/comments/1lfeulh/we_finally_released_v34_of_ttlcache/","date":1750349756,"author":"/u/swithek","guid":163036,"unread":true,"content":"<p>Hi everyone, We‚Äôre excited to announce the release of <a href=\"https://github.com/jellydator/ttlcache/releases/tag/v3.4.0\">v3.4 of ttlcache</a>, an in-memory cache supporting item expiration and generics. The goal of the project remains the same: to provide a cache with an API as straightforward as <a href=\"https://pkg.go.dev/sync#Map\">sync.Map</a>, while allowing you to automatically expire/delete items after a certain time or when a threshold is reached.</p><p>This release is the result of almost a year of fixes and improvements. Here are the main changes:</p><ul><li>Custom capacity management, allowing items to have custom cost or weight values</li><li>A new GetOrSetFunc that allows items to be created only when truly needed</li><li>An event handler for cache update events</li><li>Performance improvements, especially for Get() calls</li><li>Mutex usage fixes in Range() and RangeBackwards() methods</li><li>The ability to create plain cache items externally for testing</li><li>Additional usage examples</li></ul>","contentLength":832,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why is this sub filled with posts of some rando ‚Äúexpert‚Äù making ‚Äúpredictions‚Äù??","url":"https://www.reddit.com/r/artificial/comments/1lfedpm/why_is_this_sub_filled_with_posts_of_some_rando/","date":1750348629,"author":"/u/MrSnowden","guid":163553,"unread":true,"content":"<p>Are they all low key SEO spam? What is the fascination with podcast talking heads? Almost seems like rage bait regardless of your pov. Am I really supposed to care that this guy thinks AI is a ‚Äúdead end‚Äù (nooo) or this other guy thinks ‚Äúwe will all work for AI I. 7.5 months‚Äù (noooo)? /rant</p>","contentLength":298,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cilium Network Policies","url":"https://www.reddit.com/r/kubernetes/comments/1lfe6yr/cilium_network_policies/","date":1750348169,"author":"/u/AlpsSad9849","guid":162945,"unread":true,"content":"<p>Hello guys, i am trying to create a CiliumNetworkPolicy to limit outgoing traffic from a certain pods to everything except few other services and one exterl ip addr, my definition is:</p><pre><code>apiVersion: cilium.io/v2 kind: CiliumNetworkPolicy metadata: name: mytest-policy-egress-restrict namespace: egress spec: endpointSelector: matchLabels: app: myapp egress: - toCIDR: - 192.168.78.11/32 toPorts: - ports: - port: \"5454\" protocol: TCP </code></pre><p>If i apply it like this the pod has only access to 78.11/32 on port 5454 , so far so good, but if i add second rule to enable traffic to a certain service in another namespace like this.</p><pre><code>apiVersion: cilium.io/v2 kind: CiliumNetworkPolicy metadata: name: mytest-policy-egress-restrict namespace: egress spec: endpointSelector: matchLabels: app: myapp egress: - toCIDR: - 192.168.78.11/32 toPorts: - ports: - port: \"5454\" protocol: TCP - toServices: - k8sServiceSelector: selector: matchLabels: app.kubernetes.io/instance: testService namespace: test </code></pre><p>the pod still has no access to the service in test namespace, also loses access to its /healtz probes, if i add </p><pre><code> toPorts: - ports: - port: \"4444\" protocol: TCP </code></pre><p>to my toService directive, the policy at all stops working and allows every outgoing traffic, does anyone has a clue might the problem be</p>","contentLength":1275,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to explain K8s network traffic internally to long term security staff?","url":"https://www.reddit.com/r/kubernetes/comments/1lfe5ph/how_to_explain_k8s_network_traffic_internally_to/","date":1750348084,"author":"/u/colinhines","guid":162946,"unread":true,"content":"<div><p>We are trying to explain the reasons why it's not needed to track the port numbers internally in the k8s clusters and ecosystem, but it seems like these security folks who are used to needing the know the port numbers to find out what to monitor or alert on don't seem to \"get\" it. Is there any easy doc or instructional site that I can point them to in order to explain the perspective now?</p></div>   submitted by   <a href=\"https://www.reddit.com/user/colinhines\"> /u/colinhines </a>","contentLength":424,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Eliminating dead code in Go projects","url":"https://mfbmina.dev/en/posts/golang-deadcode/","date":1750347437,"author":"/u/mfbmina","guid":163087,"unread":true,"content":"<p>As the software we work on grows, the code tends to undergo various changes and refactorings. During this process, we might simply forget pieces of code that were once used but no longer make sense in the project, the infamous dead code. A very common example is when an API is deactivated, and only the  is removed, but all the business logic remains, unused.</p><p>Dead code can be defined as a function that exists within your codebase, is syntactically valid, but is not used by any other part of your code. In other words, it‚Äôs an unreachable function. Dead code brings indirect problems to a project, such as outdated libraries, legacy code, code bloat, security vulnerabilities, and so on. If it‚Äôs still not clear what dead code is, see the example below:</p><div><pre tabindex=\"0\"><code data-lang=\"golang\"></code></pre></div><p>In this code, we have the private functions  and . By default, <a href=\"https://pkg.go.dev/golang.org/x/tools/gopls#section-readme\" target=\"_blank\">gopls</a>\nwill tell you that the  function is not being used and can be removed. However, this doesn‚Äôt prevent the project from compiling.  is a language server used by editors to enable features like code completion, syntax corrections, etc. But if the function becomes public, this error won‚Äôt be flagged because it can theoretically be used by other packages.</p><p>This problem expands when dealing with packages, as unused packages are also not reported. Imagine a package with private and public functions that isn‚Äôt used in the project:</p><div><pre tabindex=\"0\"><code data-lang=\"golang\"></code></pre></div><p>The Go team then provided a solution to this problem with the <a href=\"https://pkg.go.dev/golang.org/x/tools/cmd/deadcode\" target=\"_blank\">deadcode</a>\ntool. It‚Äôs worth mentioning that the tool should always be run from , as it searches for dead code based on what would be executed in production. When you run this tool, you finally get all unused functions:</p><div><pre tabindex=\"0\"><code data-lang=\"sh\"></code></pre></div><p>This way, we can easily find dead code in our project. To install the tool, simply run the command:</p><div><pre tabindex=\"0\"><code data-lang=\"sh\"></code></pre></div><p>This tool is very useful to run after project refactorings and has helped me a lot to keep the code lean and containing only what truly matters to the project. If you‚Äôre interested and want to know more, I recommend reading the <a href=\"https://go.dev/blog/deadcode\" target=\"_blank\">official post</a>\n. Tell me in the comments what you think of the tool, and if you want to see the full code, access it <a href=\"https://github.com/mfbmina/poc_deadcode\" target=\"_blank\">here</a>\n.</p>","contentLength":2091,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1lfdw3b/eliminating_dead_code_in_go_projects/"},{"title":"The danish also decided to move to Linux","url":"https://www.reddit.com/r/linux/comments/1lfd6h7/the_danish_also_decided_to_move_to_linux/","date":1750345691,"author":"/u/ScientificlyCorrect","guid":162951,"unread":true,"content":"<p>Recently, The Danish Ministry of Digitilisation has decided to move to linux, and abandon windows.</p><p>The reasoning behind this move is because the DMD (Danish Ministry of Digitilisation) wanted better control, \"independant sovereignty\" &amp; a less annoying experience of their Operating System.</p><p>Primarily, they wanted to have better control of their operating system and decided to switch to an open source alternative. They are specificaly switching to LibreOffice's branch, as it \"just fits their needs\" for their work. The DMD primarily want more control of their Data, Cloud services and Data infrastructure.</p>","contentLength":605,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why not crosspost this? :D","url":"https://www.reddit.com/r/linux/comments/1lfczvz/why_not_crosspost_this_d/","date":1750345254,"author":"/u/TheTrueOrangeGuy","guid":162953,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Recent optimizations on integer to string conversions","url":"https://www.reddit.com/r/rust/comments/1lfclzw/recent_optimizations_on_integer_to_string/","date":1750344325,"author":"/u/imperioland","guid":162948,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/imperioland\"> /u/imperioland </a>","contentLength":34,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"We wrote a IaC framework to operate k8s clusters (and we are open sourcing it)","url":"https://www.reddit.com/r/kubernetes/comments/1lfcicz/we_wrote_a_iac_framework_to_operate_k8s_clusters/","date":1750344079,"author":"/u/thehazarika","guid":162947,"unread":true,"content":"<p>We operate a few decent sized k8s clusters. We noticed a pattern in our usage. So this weekend I decided to extract it out into a \"framework\". It has a structured way of using terraform and helm.</p><p>We wrote a thin layer on top of helm (We call it ) that automatically handles encryption of secrets using sops+kms. And it blocks you from running helm commands if you not in the correct cluster and namespace. (This has kept us from regularly shooting ourselves on the foot)</p><p>And it has a script to setup the whole thing. And it contains and example app, you want to try it out.</p>","contentLength":571,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ok so you want to build your first AI agent but don't know where to start? Here's exactly what I did (step by step)","url":"https://www.reddit.com/r/artificial/comments/1lfc9eb/ok_so_you_want_to_build_your_first_ai_agent_but/","date":1750343463,"author":"/u/soul_eater0001","guid":163480,"unread":true,"content":"<p>Alright so like a year ago I was exactly where most of you probably are right now - knew ChatGPT was cool, heard about \"AI agents\" everywhere, but had zero clue how to actually build one that does real stuff.</p><p>After building like 15 different agents (some failed spectacularly lol), here's the exact path I wish someone told me from day one:</p><p><strong>Step 1: Stop overthinking the tech stack</strong> Everyone obsesses over LangChain vs CrewAI vs whatever. Just pick one and stick with it for your first agent. I started with n8n because it's visual and you can see what's happening.</p><p><strong>Step 2: Build something stupidly simple first</strong> My first \"agent\" literally just:</p><ul><li>Added them to a Google Sheet</li><li>Sent me a Slack message when done</li></ul><p>Took like 3 hours, felt like magic. Don't try to build Jarvis on day one.</p><p><strong>Step 3: The \"shadow test\"</strong> Before coding anything, spend 2-3 hours doing the task manually and document every single step. Like EVERY step. This is where most people mess up - they skip this and wonder why their agent is garbage.</p><p><strong>Step 4: Start with APIs you already use</strong> Gmail, Slack, Google Sheets, Notion - whatever you're already using. Don't learn 5 new tools at once.</p><p><strong>Step 5: Make it break, then fix it</strong> Seriously. Feed your agent weird inputs, disconnect the internet, whatever. Better to find the problems when it's just you testing than when it's handling real work.</p><p>The whole \"learn programming first\" thing is kinda BS imo. I built my first 3 agents with zero code using n8n and Zapier. Once you understand the logic flow, learning the coding part is way easier.</p><p>Also hot take - most \"AI agent courses\" are overpriced garbage. The best learning happens when you just start building something you actually need.</p><p>What was your first agent? Did it work or spectacularly fail like mine did? Drop your stories below, always curious what other people tried first.</p>","contentLength":1833,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"'It‚Äôs True, ‚ÄúWe‚Äù Don‚Äôt Care About Accessibility on Linux' ‚Äî TheEvilSkeleton","url":"https://tesk.page/2025/06/18/its-true-we-dont-care-about-accessibility-on-linux/","date":1750342255,"author":"/u/IverCoder","guid":162952,"unread":true,"content":"<p>What do <a href=\"https://en.wikipedia.org/wiki/Virtue_signalling\">virtue-signalers</a> and privileged people without disabilities who share content about accessibility on Linux being trash without contributing anything to the software have in common? They don‚Äôt actually really care about the group they‚Äôre defending; they just exploit these victims‚Äô unfortunate situation to fuel hate against groups and projects actually trying to make the world a better place.</p><p>I never thought I‚Äôd be  upset to a point I‚Äôd be writing an article about something this sensitive with a clickbait-y title. It‚Äôs simultaneously demotivating, unproductive, and infuriating. I‚Äôm here writing this post fully knowing that I could have been working on accessibility in GNOME, but really, I‚Äôm so tired of having my mood ruined because of <a href=\"https://mastodon.social/@alatiera/114660908204452532\">privileged people spending at most 5 minutes to write erroneous posts</a> and then <a href=\"https://mastodon.social/@lproven@vivaldi.net/114661229925950081\">pretending to be oblivious when confronted</a> while it takes us 5 months of unpaid work to get a quarter of recognition, let alone acknowledgment, without accounting for the time ‚Äúwasted‚Äù addressing these accusations. This is far from the first time, and it will certainly not be the last.</p><p>I‚Äôm not mad. I‚Äôm absolutely furious  disappointed in the Linux Desktop community for being quiet in regards to any kind of celebration to advancing accessibility, while proceeding to share content and cheer for random privileged people from big-name websites or social media who have literally put a negative amount of effort into advancing accessibility on Linux. I‚Äôm explicitly stating a negative amount because they actually make it significantly more stressful for us.</p><p>None of this is fair. If you‚Äôre the kind of person who stays quiet when we celebrate huge accessibility milestones, yet shares (or even makes) content that trash talks the people directly or indirectly contributing to the fucking software you use for free,  are the reason why accessibility on Linux is shit.</p><p>No one in their right mind wants to volunteer in a toxic environment where their efforts are hardly recognized by the public and they are blamed for ‚Äúnot doing enough‚Äù, especially when they are expected to take in all kinds of harassment, nonconstructive criticism, and slander for a salary of 0$.</p><p>There‚Äôs only one thing I am shamefully confident about:  am not okay in the head. I shouldn‚Äôt be working on accessibility anymore. The recognition-to-smearing ratio is unbearably low and arguably unhealthy, but leaving people in unfortunate situations behind is also not in accordance with my values.</p><p>I‚Äôve been putting so much effort, quite literally  of hours, into:</p><ol><li>thinking of ways to come up with inclusive designs and experiences;</li><li>imagining how I‚Äôd use something if I had a certain disability or condition;</li><li>asking for advice and feedback from people with disabilities;</li><li>not getting paid from any company or organization; and</li><li>making sure that all the accessibility-related work is in the public, and .</li></ol><p>Number 5 is especially important to me. I personally go as far as to refuse to contribute to projects under a <a href=\"https://en.wikipedia.org/wiki/Permissive_software_license\">permissive license</a>, and/or that utilize a <a href=\"https://en.wikipedia.org/wiki/Contributor_License_Agreement\">contributor license agreement</a>, and/or that utilize anything riskily similar to these two, because I am of the opinion that <strong>no amount of code for accessibility should either be put under a paywall or be obscured and proprietary</strong>.</p><p>Permissive licenses make it painlessly easy for abusers to fork, build an ecosystem on top of it which may include accessibility-related improvements, slap a price tag alongside it, all without publishing any of these additions/changes. Corporations have been doing that for decades, and they‚Äôll keep doing it until there‚Äôs heavy push back. The only time I would contribute to a project under a permissive license is when the tool  the accessibility infrastructure itself. Contributor license agreements are <a href=\"https://opensource.com/article/19/2/cla-problems\">significantly worse in that regard</a>, so I prefer to avoid them completely.</p><h2></h2><p>The GNOME Foundation has been investing a lot of money to improve accessibility on Linux, for example <a href=\"https://blogs.gnome.org/a11y/2024/06/18/update-on-newton-the-wayland-native-accessibility-project\">funding Newton, a Wayland accessibility project</a> and <a href=\"https://blogs.gnome.org/tbernard/2025/04/11/gnome-stf-2024/#newton\">AccessKit integration into GNOME technologies</a>. Around 250,000‚Ç¨ (1/4) of the <a href=\"https://blogs.gnome.org/tbernard/2025/04/11/gnome-stf-2024/\">STF budget</a> was spent solely on accessibility. And get this: <strong>literally everybody managing these contracts and communication with funders are volunteers; they‚Äôre ensuring people with disabilities earn a living, but aren‚Äôt receiving anything in return</strong>. These are the real heroes who deserve endless praise.</p><p>Do you want to know who we  be blaming? Profiteers who are profiting from the community‚Äôs effort while investing very little to nothing into accessibility.</p><p>This includes a significant portion of the companies sponsoring GNOME and even companies that employ developers to work on GNOME. These companies are the ones making hundreds of millions, if not billions, in net profit indirectly from GNOME (and other free and open-source projects), and investing little to nothing into them. However, the worst offenders are the companies actively using GNOME without ever donating anything to fund the projects.</p><p>Some companies actually do put an effort, like Red Hat and Igalia. Red Hat employs people with disabilities to work on accessibility in GNOME, one of which I actually rely on when making accessibility-related contributions in GNOME. Igalia funds Orca, the screen reader as part of GNOME, which is something the Linux community should be thankful of. However, companies have historically invested what‚Äôs necessary to comply with governments‚Äô accessibility requirements, and then never invest in it again.</p><p>The privileged people who keep sharing and making content around accessibility on Linux being bad without contributing anything to it are, in my opinion, significantly worse than the companies profiting off of GNOME. Companies are and stay quiet, but these privileged people add an additional burden to contributors by either trash talking or sharing trash talkers. Once again, no volunteer deserves to be in the position of being shamed and ridiculed for ‚Äúnot doing enough‚Äù, since no one is entitled to their free time, but themselves.</p><h3></h3><p>Earlier in this article, I mentioned, and I quote: ‚ÄúI‚Äôve been putting so much effort, <u>quite literally  of hours</u> [‚Ä¶]‚Äù. Let‚Äôs put an emphasis on ‚Äúhundreds‚Äù. Here‚Äôs a list of most accessibility-related merge requests that have been incorporated into GNOME:</p><p>GNOME Calendar‚Äôs <a href=\"https://gitlab.gnome.org/GNOME/gnome-calendar/-/merge_requests/559\">!559</a> addresses an issue where event widgets were unable to be focused and activated by the keyboard. That was present since the <a href=\"https://social.treehouse.systems/@TheEvilSkeleton/114434850837916105\">very beginning of GNOME Calendar‚Äôs existence</a>, to be specific: for more than a decade. This alone was was a two-week effort. Despite it being less than 100 lines of code, nobody truly knew what to do to have them working properly before. This was followed up by <a href=\"https://gitlab.gnome.org/GNOME/gnome-calendar/-/merge_requests/576\">!576</a>, which made the <a href=\"https://social.treehouse.systems/@TheEvilSkeleton/114559888953249311\">event buttons usable in the month view with a keyboard</a>, and then <a href=\"https://gitlab.gnome.org/GNOME/gnome-calendar/-/merge_requests/587\">!587</a>, which properly conveys the states of the widgets. Both combined are another two-week effort.</p><p>Then, at the time of writing this article, <a href=\"https://gitlab.gnome.org/GNOME/gnome-calendar/-/merge_requests/564\">!564</a> adds 640 lines of code, which is something I‚Äôve been volunteering on for more than a month, excluding the time before I opened the merge request.</p><p>Let‚Äôs do a little bit of math together with ‚Äòonly‚Äô <a href=\"https://gitlab.gnome.org/GNOME/gnome-calendar/-/merge_requests/559\">!559</a>, <a href=\"https://gitlab.gnome.org/GNOME/gnome-calendar/-/merge_requests/576\">!576</a>, and <a href=\"https://gitlab.gnome.org/GNOME/gnome-calendar/-/merge_requests/587\">!587</a>. Just as a reminder: these three merge requests are a four-week effort in total, which I volunteered full-time‚Äî8 hours a day, or 160 hours a month. I compiled a small table that illustrates its worth:</p><table><thead><tr><th>Average Wage for Professionals Working on Digital Accessibility</th><th>Total in Local Currency(160 hours)</th></tr></thead><tbody><tr></tr><tr></tr><tr></tr></tbody></table><p>To summarize the table: <strong>those three merge requests that I worked on for  were worth 9,393.60$ CAD (6,921.36$ USD) in total at a minimum</strong>.</p><ul><li>these merge requests exclude the time spent to review the submitted code;</li><li>these merge requests exclude the time I spent testing the code;</li><li>these merge requests exclude the time we spent coordinating these milestones;</li><li>these calculations exclude the 30+ merge requests submitted to GNOME; and</li><li>these calculations exclude the merge requests I submitted to third-party GNOME-adjacent apps.</li></ul><p>Now just imagine how I feel when I‚Äôm told I‚Äôm ‚Äúnot doing enough‚Äù, either directly or indirectly, by privileged people who don‚Äôt rely on any of these accessibility features. Whenever anybody says we‚Äôre ‚Äúnot doing enough‚Äù, I feel very much included, and I will absolutely take it personally.</p><h3></h3><p>I fully expect everything I say in this article to be dismissed or be taken out of context on the basis of <a href=\"https://en.wikipedia.org/wiki/Ad_hominem\">ad hominem</a>, simply by the mere fact I‚Äôm a GNOME Foundation member / regular GNOME contributor. Either that, or be subject to <a href=\"https://en.wikipedia.org/wiki/Whataboutism\">whataboutism</a> because another GNOME contributor made a comment that had nothing to do with mine but <em>‚Äòis somewhat related to this topic and therefore should be pointed out just because it was maybe-probably-possibly-perhaps ableist‚Äô</em>. I can‚Äôt speak for other regular contributors, but I presume that they don‚Äôt feel comfortable talking about this because they dared be a GNOME contributor. At least, that‚Äôs how I felt for the longest time.</p><p>Any content related to accessibility that doesn‚Äôt dunk on GNOME doesn‚Äôt foresee as many engagement, activity, and reaction as content that actively attacks GNOME, regardless of whether the criticism is fair. Many of these people don‚Äôt even use these accessibility features; they‚Äôre just looking for every opportunity to say ‚ÄúGNOME bad‚Äù and will  start caring about accessibility.</p><p>Regular GNOME contributors like myself don‚Äôt always feel comfortable defending ourselves because dismissing GNOME developers just for being GNOME developers is apparently a trend‚Ä¶</p><p>Dear people with disabilities,</p><p>I won‚Äôt insist that we‚Äôre either your allies or your enemies‚ÄîI have no right to claim that whatsoever.</p><p>I wasn‚Äôt looking for recognition. I wasn‚Äôt looking for acknowledgment since the very beginning either. I thought I would be perfectly capable of quietly improving accessibility in GNOME, but because of the overall community‚Äôs persistence to smear developers‚Äô efforts without actually tackling the underlying issues within the stack, I think I‚Äôve justified myself to at least demand for acknowledgment from the wider community.</p><p>I highly doubt it will happen anyway, because the Linux community feeds off of drama and trash talking instead of being productive, without realizing that it negatively demotivates active contributors while pushing away potential contributors. And worst of all: people with disabilities are the ones affected the most because they are misled into thinking that we don‚Äôt care.</p><p>It‚Äôs so unfair and infuriating that all the work I do and share online gain very little activity compared to random posts and articles from privileged people without disabilities that rant about the Linux desktop‚Äôs accessibility being trash. It doesn‚Äôt help that I become severely anxious sharing accessibility-related work to avoid signs of virtue-signaling. The last thing I want is to (unintentionally) give any sign and impression of pretending to care about accessibility.</p><p>We simultaneously need more interest from people with disabilities to contribute to free and open-source software, and the wider community to be significantly more intolerant of bullies who profit from smearing and demotivating people who are actively trying.</p>","contentLength":11286,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1lfbsij/its_true_we_dont_care_about_accessibility_on/"},{"title":"[P] I built a self-hosted Databricks","url":"https://www.reddit.com/r/MachineLearning/comments/1lfbq3m/p_i_built_a_selfhosted_databricks/","date":1750342094,"author":"/u/Mission-Balance-4250","guid":163146,"unread":true,"content":"<p>Hey everone, I'm an ML Engineer who spearheaded the adoption of Databricks at work. I love the agency it affords me because I can own projects end-to-end and do everything in one place.</p><p>However, I am sick of the infra overhead and bells and whistles. Now, I am not in a massive org, but there aren't actually that many massive orgs... So many problems can be solved with a simple data pipeline and basic model (e.g. XGBoost.) Not only is there technical overhead, but systems and process overhead; bureaucracy and red-tap significantly slow delivery.</p><p>Anyway, I decided to try and address this myself by developing <a href=\"https://github.com/flintml/flintml\">FlintML</a>. Basically, Polars, Delta Lake, unified catalog, Aim experiment tracking, notebook IDE and orchestration (still working on this) fully spun up with Docker Compose.</p><p>I'm hoping to get some feedback from this subreddit. I've spent a couple of months developing this and want to know whether I would be wasting time by contuining or if this might actually be useful.</p>","contentLength":981,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why I Choose RUST as my backend language","url":"https://www.reddit.com/r/rust/comments/1lfayze/why_i_choose_rust_as_my_backend_language/","date":1750340088,"author":"/u/junnieboat","guid":163238,"unread":true,"content":"<p>I'm a JavaScript developer and have been using Node.js (Express) for all my projects mainly because of its <a href=\"https://www.geeksforgeeks.org/operating-systems/blocking-and-nonblocking-io-in-operating-system/\">non-blocking I/O</a>, which makes handling concurrent requests smooth and efficient.</p><p>That said, I've never fully trusted JavaScript on the backend ‚Äî especially when it comes to things like type safety, error handling, and long-term maintainability. The dynamic nature of JS sometimes makes debugging and scaling harder than it should be.</p><p>Lately, I‚Äôve been exploring other options like Rust (with frameworks like Axum) for more reliable and performant backend services. The compile-time checks, memory safety, and ecosystem are really starting to make sense.</p><p>Has anyone else made a similar switch or run backend code in both Node.js and Rust? Curious to hear what others think about the trade-offs.</p>","contentLength":801,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"YouTube CEO announces Google's Veo 3 AI video tech is coming to Shorts","url":"https://www.pcguide.com/news/youtube-ceo-announces-googles-veo-3-ai-video-tech-is-coming-to-shorts/","date":1750338725,"author":"/u/Tiny-Independent273","guid":162949,"unread":true,"content":"<div>\n        PC Guide is reader-supported. When you buy through links on our site, we may earn an affiliate commission. <a href=\"https://www.pcguide.com/earnings-disclaimer/\">Read More</a></div><p>Just last month, Google unveiled its next iteration of video AI with Veo 3 as its <a href=\"https://www.pcguide.com/news/googles-veo-3-could-become-a-real-problem-for-content-creators-as-convincing-examples-flood-the-web/\" target=\"_blank\" rel=\"noreferrer noopener\">creations flooded the web</a>. </p><p>YouTube CEO Neal Mohan <a href=\"https://blog.youtube/news-and-events/neal-mohan-cannes-2025/\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">announced this new feature</a> at the Cannes Lions 2025 Festival of Creativity. Commenting on the fact that ‚Äúcreators are showing us what the future looks like: AI.‚Äù YouTube is adding these features to empower human creativity and expand on what they provide to help.</p><p>Coming later this summer to the app, the inclusion of Veo 3 will let creators use Dream Screen to add <a href=\"https://www.pcguide.com/ai/\" target=\"_blank\" rel=\"noreferrer noopener\">AI</a>-generated backgrounds and video clips for Shorts. It doesn‚Äôt say if people will have to pay for its use, considering standalone usage has a price to it, but it will let creators utilize the improvements that Veo 3 brings. This includes improved video quality and even adds sound.</p><p><em>We promise that the actual PC Guide office looks much nicer than what Google Veo 3 thinks.</em></p><p>Alongside adding the new Veo version to YouTube shorts, it also has plenty of more uses for the technology. One of which is using it for Auto Dubbing and translating videos, it already works across nine different languages, and 11 more are coming soon, as a way to expand the audiences for creators‚Äô videos. With 20 million videos already dubbed, it expects plenty more to take advantage of it.</p><p>Considering it‚Äôs been 20 years of YouTube, it‚Äôs another method for it to look at expansion and improving on what it already has to offer. Neal Mohan talks of how he expects creators will flip formats, blend genres, and push deeper into the mainstream in the next 20 years for the platform, with AI technology behind it to push the limits of human creativity. We doubt that everyone will be too pleased to see even more AI making its way into content creation, but at least YouTube is being transparent.</p><div><div><img src=\"data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E\" alt=\"\" data-lazy-src=\"https://secure.gravatar.com/avatar/d68e04c112ae6b02566efe3f3834052c?s=50&amp;d=wp_user_avatar&amp;r=g\"></div></div>","contentLength":1902,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1lfah4u/youtube_ceo_announces_googles_veo_3_ai_video_tech/"},{"title":"Gauntlet Language Updated: Sum Types, Reworked Syntax, New Pipe Operator","url":"https://gauntletlang.gitbook.io/docs/version-release-notes/v0.2.0-alpha","date":1750337803,"author":"/u/TricolorHen061","guid":162983,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lfa545/gauntlet_language_updated_sum_types_reworked/"},{"title":"What Would a Kubernetes 2.0 Look Like","url":"https://matduggan.com/what-would-a-kubernetes-2-0-look-like/","date":1750336752,"author":"/u/LaFoudre250","guid":162851,"unread":true,"content":"<p>Around 2012-2013 I started to hear a  in the sysadmin community about a technology called \"Borg\". It was (apparently) some sort of Linux container system inside of Google that ran all of their stuff. The terminology was a bit baffling, with something called a \"Borglet\" inside of clusters with \"cells\" but the basics started to leak. There was a concept of \"services\" and a concept of \"jobs\", where applications could use services to respond to user requests and then jobs to complete batch jobs that ran for much longer periods of time. </p><p>Then on June 7th, 2014, we got our first commit of Kubernetes. The Greek word for 'helmsman' that absolutely no one could pronounce correctly for the first three years. (Is it koo-ber-NET-ees? koo-ber-NEET-ees? Just give up and call it k8s like the rest of us.) </p><p>Microsoft, RedHat, IBM, Docker join the Kubernetes community pretty quickly after this, which raised Kubernetes from an interesting Google thing to \"maybe this is a real product?\" On July 21st 2015 we got the v1.0 release as well as the creation of the CNCF. </p><p>In the ten years since that initial commit, Kubernetes has become a large part of my professional life. I use it at home, at work, on side projects‚Äîanywhere it makes sense. It's a tool with a steep learning curve, but it's also a massive force multiplier. We no longer \"manage infrastructure\" at the server level; everything is declarative, scalable, recoverable and (if you‚Äôre lucky) self-healing.</p><p>But the journey hasn't been without problems. Some common trends have emerged, where mistakes or misconfiguration arise from where Kubernetes isn't opinionated enough. Even ten years on, we're still seeing a lot of churn inside of ecosystem and people stepping on well-documented landmines. So, knowing what we know now, what could we do differently to make this great tool even more applicable to more people and problems? </p><p>Let's start with the positive stuff. Why are we still talking about this platform now? </p><p>Containers as a tool for software development make perfect sense. Ditch the confusion of individual laptop configuration and have one standard, disposable concept that works across the entire stack. While tools like Docker Compose allowed for some deployments of containers, they were clunky and still required you as the admin to manage a lot of the steps. I set up a Compose stack with a deployment script that would remove the instance from the load balancer, pull the new containers, make sure they started and then re-added it to the LB, as did lots of folks. </p><p>K8s allowed for this concept to scale out, meaning it was possible to take a container from your laptop and deploy an identical container across thousands of servers. This flexibility allowed organizations to revisit their entire design strategy, dropping monoliths and adopting more flexible (and often more complicated) micro-service designs. </p><p>If you think of the history of Operations as a sort of \"naming timeline from pets to cattle\", we started with what I affectionately call the \"Simpsons\" era. Servers were bare metal boxes set up by teams, they often had one-off names that became slang inside of teams and everything was a snowflake. The longer a server ran, the more cruft it picked up until it became a scary operation to even reboot them, much less attempt to rebuild them. I call it the \"Simpsons\" era because among the jobs I was working at the time, naming them after Simpsons characters was surprisingly common. Nothing fixed itself, everything was a manual operation. </p><p>Then we transition into the \"01 Era\". Tools like Puppet and Ansible have become common place, servers are more disposable and you start to see things like bastion hosts and other access control systems become the norm. Servers aren't all facing the internet, they're behind a load balancer and we've dropped the cute names for stuff like \"app01\" or \"vpn02\". Organizations designed it so they could lose some of their servers some of the time. However failures still weren't self-healing, someone still had to SSH in to see what broke, write up a fix in the tooling and then deploy it across the entire fleet. OS upgrades were still complicated affairs. </p><p>We're now in the \"UUID Era\". Servers exist to run containers, they are entirely disposable concepts. Nobody cares about how long a particular version of the OS is supported for, you just bake a new AMI and replace the entire machine. K8s wasn't the only technology enabling this, but it was the one that accelerated it. Now the idea of a bastion server with SSH keys that I go to the underlying server to fix problems is seen as more of a \"break-glass\" solution. Almost all solutions are \"destroy that Node, let k8s reorganize things as needed, make a new Node\". </p><p>A lot of the Linux skills that were critical to my career are largely nice to have now, not need to have. You can be happy or sad about that, I certainly switch between the two emotions on a regular basis, but it's just the truth. </p><p>The k8s jobs system isn't perfect, but it's so much better than the \"snowflake cron01 box\" that was an extremely common sight at jobs for years. Running on a cron schedule or running from a message queue, it was now possible to reliably put jobs into a queue, have them get run, have them restart if they didn't work and then move on with your life. </p><p>Not only does this free up humans from a time-consuming and boring task, but it's also simply a more efficient use of resources. You are still spinning up a pod for every item in the queue, but your teams have a lot of flexibility inside of the \"pod\" concept for what they need to run and how they want to run it. This has really been a quality of life improvement for a lot of people, myself included, who just need to be able to easily background tasks and not think about them again. </p><p><strong>Service Discoverability and Load Balancing</strong></p><p>Hard-coded IP addresses that lived inside of applications as the template for where requests should be routed has been a curse following me around for years. If you were lucky, these dependencies weren't based on IP address but were actually DNS entries and you could change the thing behind the DNS entry without coordinating a deployment of a million applications. </p><p>K8s allowed for simple DNS names to call other services. It removed an entire category of errors and hassle and simplified the entire thing down. With the Service API you had a stable, long lived IP and hostname that you could just point things towards and not think about any of the underlying concepts. You even have concepts like ExternalName that allow you to treat external services like they're in the cluster. </p><h2>What would I put in a Kubernetes 2.0?</h2><p>YAML was appealing because it wasn't JSON or XML, which is like saying your new car is great because it's neither a horse nor a unicycle. It demos nicer for k8s, looks nicer sitting in a repo and has the  of being a simple file format. In reality. YAML is just too much for what we're trying to do with k8s and it's not a safe enough format. Indentation is error-prone, the files don't scale great (you really don't want a super long YAML file), debugging can be annoying. YAML has  subtle behaviors outlined in its spec.</p><p>I still remember not believing what I was seeing the first time I saw the Norway Problem. For those lucky enough to not deal with it, the Norway Problem in YAML is when 'NO' gets interpreted as false. Imagine explaining to your Norwegian colleagues that their entire country evaluates to false in your configuration files. Add in accidental numbers from lack of quotes, the list goes on and on. There are much better posts on why YAML is crazy than I'm capable of writing: <a href=\"https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell\">https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell</a></p><p>HCL is already the format for Terraform, so at least we'd only have to hate one configuration language instead of two. It's strongly typed with explicit types. There's already good validation mechanisms. It is specifically designed to do the job that we are asking YAML to do and it's not much harder to read. It has built-in functions people are already using that would allow us to remove some of the third-party tooling from the YAML workflow. </p><p>I would wager 30% of Kubernetes clusters today are  being managed with HCL via Terraform. We don't need the Terraform part to get a lot of the benefits of a superior configuration language. </p><p>The only downsides are that HCL is slightly more verbose than YAML, and its Mozilla Public License 2.0 (MPL-2.0) would require careful legal review for integration into an Apache 2.0 project like Kubernetes. However, for the quality-of-life improvements it offers, these are hurdles worth clearing.</p><p>Let's take a simple YAML file. </p><pre><code># YAML doesn't enforce types\nreplicas: \"3\"  # String instead of integer\nresources:\n  limits:\n    memory: 512  # Missing unit suffix\n  requests:\n    cpu: 0.5m    # Typo in CPU unit (should be 500m)</code></pre><p>Even in the most basic example, there are footguns everywhere. HCL and the type system would catch all of these problems. </p><pre><code>replicas = 3  # Explicitly an integer\n\nresources {\n  limits {\n    memory = \"512Mi\"  # String for memory values\n  }\n  requests {\n    cpu = 0.5  # Number for CPU values\n  }\n}</code></pre><p>Take a YAML file like this that you probably have 6000 in your k8s repo. Now look at HCL without needing external tooling. </p><pre><code># Need external tools or templating for dynamic values\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  # Can't easily generate or transform values\n  DATABASE_URL: \"postgres://user:password@db:5432/mydb\"\n  API_KEY: \"static-key-value\"\n  TIMESTAMP: \"2023-06-18T00:00:00Z\"  # Hard-coded timestamp</code></pre><pre><code>resource \"kubernetes_config_map\" \"app_config\" {\n  metadata {\n    name = \"app-config\"\n  }\n  \n  data = {\n    DATABASE_URL = \"postgres://${var.db_user}:${var.db_password}@${var.db_host}:${var.db_port}/${var.db_name}\"\n    API_KEY      = var.api_key != \"\" ? var.api_key : random_string.api_key.result\n    TIMESTAMP    = timestamp()\n  }\n}\n\nresource \"random_string\" \"api_key\" {\n  length  = 32\n  special = false\n}</code></pre><p>Here's all the pros you get with this move. </p><ol><li>: Preventing type-related errors before deployment</li><li>: Reducing duplication and improving maintainability</li><li><strong>Functions and Expressions</strong>: Enabling dynamic configuration generation</li><li>: Supporting environment-specific configurations</li><li>: Simplifying repetitive configurations</li><li>: Improving documentation and readability</li><li>: Making errors easier to identify and fix</li><li>: Enabling reuse of configuration components</li><li>: Preventing invalid configurations</li><li>: Supporting complex data manipulations</li></ol><p>I know, I'm the 10,000 person to write this. Etcd has done a fine job, but it's a little crazy that it is the only tool for the job. For smaller clusters or smaller hardware configuration, it's a large use of resources in a cluster type where you will never hit the node count where it pays off. It's also a strange relationship between k8s and etcd now, where k8s is basically the only etcd customer left. </p><p>What I'm suggesting is taking the work of <a href=\"https://github.com/k3s-io/kine\" rel=\"noreferrer\">kine</a> and making it official. It makes sense for the long-term health of the project to have the ability to plug in more backends, adding this abstraction means it (should) be easier to swap in new/different backends in the future and it also allows for more specific tuning depending on the hardware I'm putting out there. </p><p>What I suspect this would end up looking like is much like this: <a href=\"https://github.com/canonical/k8s-dqlite\">https://github.com/canonical/k8s-dqlite</a>. Distributed SQlite in-memory with Raft consensus and almost zero upgrade work required that would allow cluster operators to have more flexibility with the persistence layer of their k8s installations. If you have a conventional server setup in a datacenter and etcd resource usage is not a problem, great! But this allows for lower-end k8s to be a nicer experience and (hopefully) reduces dependence on the etcd project. </p><h3>Beyond Helm: A Native Package Manager</h3><p>Helm is a perfect example of a temporary hack that has grown to be a permanent dependency. I'm grateful to the maintainers of Helm for all of their hard work, growing what was originally a hackathon project into the de-facto way to install software into k8s clusters. It has done as good a job as something could in fulfilling that role without having a deeper integration into k8s. </p><p>All that said, Helm is a nightmare to use. The Go templates are tricky to debug, often containing complex logic that results in really confusing error scenarios. The error messages you get from those scenarios are often gibberish. Helm isn't a very good package system because it fails at some of the basic tasks you need a package system to do, which are transitive dependencies and resolving conflicts between dependencies. </p><p>Tell me what this conditional logic is trying to do:</p><pre><code># A real-world example of complex conditional logic in Helm\n{{- if or (and .Values.rbac.create .Values.serviceAccount.create) (and .Values.rbac.create (not .Values.serviceAccount.create) .Values.serviceAccount.name) }}\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: {{ template \"myapp.fullname\" . }}\n  labels:\n    {{- include \"myapp.labels\" . | nindent 4 }}\n{{- end }}</code></pre><p>Or if I provide multiple values files to my chart, which one wins:</p><pre><code>helm install myapp ./mychart -f values-dev.yaml -f values-override.yaml --set service.type=NodePort</code></pre><p>Ok, what if I want to manage my application and all the application dependencies with a Helm chart. This makes sense, I have an application that itself has dependencies on other stuff so I want to put them all together. So I define my sub-charts or umbrella charts inside of my Chart.yaml. </p><pre><code>dependencies:\n- name: nginx\n  version: \"1.2.3\"\n  repository: \"&lt;https://example.com/charts&gt;\"\n- name: memcached\n  version: \"1.2.3\"\n  repository: \"&lt;https://another.example.com/charts&gt;\"\n</code></pre><p>But assuming I have multiple applications, it's entirely possible that I have 2 services both with a dependency on nginx or whatever like this:</p><p>Helm doesn't handle this situation gracefully because template names are global with their templates loaded alphabetically. Basically you need to:</p><ul><li>Don't declare a dependency on the same chart more than once (hard to do for a lot of microservices)</li><li>If you do have the same chart declared multiple times, has to use the exact same version</li></ul><p>The list of issues goes on and on. </p><ul><li>Cross-Namespace installation stinks</li><li>Chart verification process is a pain and nobody uses it</li></ul><p>Let's just go to the front page of artifacthub:</p><p>I'll grab elasticsearch cause that seems important. </p><p>Seems  for the Official Elastic helm chart. Certainly  will be right, it's an absolute critical dependency for the entire industry. </p><p>Nope. Also how is the maintainer of the chart \"Kubernetes\" and it's  not marked as a . Like Christ how much more verified does it get.</p><ul><li>No metadata in chart searching. You can only search by name and description, not by features, capabilities, or other metadata.</li></ul><ul><li>Helm doesn't strictly enforce semantic versioning</li></ul><pre><code># Chart.yaml with non-semantic version\napiVersion: v2\nname: myapp\nversion: \"v1.2-alpha\" </code></pre><ul><li>If you uninstall and reinstall a chart with CRDs, it might delete resources created by those CRDs. This one has screwed me  and is crazy unsafe. </li></ul><p>I could keep writing for another 5000 words and still wouldn't have outlined all the problems. There isn't a way to make Helm good enough for the task of \"package manager for all the critical infrastructure on the planet\". </p><h4>What would a k8s package system look like?</h4><p>Let's call our hypothetical package system KubePkg, because if there's one thing the Kubernetes ecosystem needs, it's another abbreviated name with a 'K' in it. We would try to copy as much of the existing work inside the Linux ecosystem while taking advantage of the CRD power of k8s. My idea looks something like this:</p><p>The packages are bundles like a Linux package:</p><p>There's a definition file that accounts for as many of the real scenarios that you actually encounter when installing a thing. </p><pre><code>apiVersion: kubepkg.io/v1\nkind: Package\nmetadata:\n  name: postgresql\n  version: 14.5.2\nspec:\n  maintainer:\n    name: \"PostgreSQL Team\"\n    email: \"<a href=\"https://matduggan.com/cdn-cgi/l/email-protection\" data-cfemail=\"e8858981869c8981868d9a9ba898879b9c8f9a8d9b9984c68d90898598848dc68b8785\">[email&nbsp;protected]</a>\"\n  description: \"PostgreSQL database server\"\n  website: \"https://postgresql.org\"\n  license: \"PostgreSQL\"\n  \n  # Dependencies with semantic versioning\n  dependencies:\n    - name: storage-provisioner\n      versionConstraint: \"&gt;=1.0.0\"\n    - name: metrics-collector\n      versionConstraint: \"^2.0.0\"\n      optional: true\n  \n  # Security context and requirements\n  security:\n    requiredCapabilities: [\"CHOWN\", \"SETGID\", \"SETUID\"]\n    securityContextConstraints:\n      runAsUser: 999\n      fsGroup: 999\n    networkPolicies:\n      - ports:\n        - port: 5432\n          protocol: TCP\n    \n  # Resources to be created (embedded or referenced)\n  resources:\n    - apiVersion: v1\n      kind: Service\n      metadata:\n        name: postgresql\n      spec:\n        ports:\n        - port: 5432\n    - apiVersion: apps/v1\n      kind: StatefulSet\n      metadata:\n        name: postgresql\n      spec:\n        # StatefulSet definition\n  \n  # Configuration schema using JSON Schema\n  configurationSchema:\n    type: object\n    properties:\n      replicas:\n        type: integer\n        minimum: 1\n        default: 1\n      persistence:\n        type: object\n        properties:\n          size:\n            type: string\n            pattern: \"^[0-9]+[GMK]i$\"\n            default: \"10Gi\"\n  \n  # Lifecycle hooks with proper sequencing\n  hooks:\n    preInstall:\n      - name: database-prerequisites\n        job:\n          spec:\n            template:\n              spec:\n                containers:\n                - name: init\n                  image: postgres:14.5\n    postInstall:\n      - name: database-init\n        job:\n          spec:\n            # Job definition\n    preUpgrade:\n      - name: backup\n        job:\n          spec:\n            # Backup job definition\n    postUpgrade:\n      - name: verify\n        job:\n          spec:\n            # Verification job definition\n    preRemove:\n      - name: final-backup\n        job:\n          spec:\n            # Final backup job definition\n  \n  # State management for stateful applications\n  stateManagement:\n    backupStrategy:\n      type: \"snapshot\"  # or \"dump\"\n      schedule: \"0 2 * * *\"  # Daily at 2 AM\n      retention:\n        count: 7\n    recoveryStrategy:\n      type: \"pointInTime\"\n      verificationJob:\n        spec:\n          # Job to verify recovery success\n    dataLocations:\n      - path: \"/var/lib/postgresql/data\"\n        volumeMount: \"data\"\n    upgradeStrategies:\n      - fromVersion: \"*\"\n        toVersion: \"*\"\n        strategy: \"backup-restore\"\n      - fromVersion: \"14.*.*\"\n        toVersion: \"14.*.*\"\n        strategy: \"in-place\"</code></pre><p>There's a real signing process that would be required and allow you more control over the process. </p><pre><code>apiVersion: kubepkg.io/v1\nkind: Repository\nmetadata:\n  name: official-repo\nspec:\n  url: \"https://repo.kubepkg.io/official\"\n  type: \"OCI\"  # or \"HTTP\"\n  \n  # Verification settings\n  verification:\n    publicKeys:\n      - name: \"KubePkg Official\"\n        keyData: |\n          -----BEGIN PUBLIC KEY-----\n          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvF4+...\n          -----END PUBLIC KEY-----\n    trustPolicy:\n      type: \"AllowList\"  # or \"KeyRing\"\n      allowedSigners:\n        - \"KubePkg Official\"\n        - \"Trusted Partner\"\n    verificationLevel: \"Strict\"  # or \"Warn\", \"None\"</code></pre><p>Like how great would it be to have something where I could automatically update packages without needing to do anything on my side. </p><pre><code>apiVersion: kubepkg.io/v1\nkind: Installation\nmetadata:\n  name: postgresql-main\n  namespace: database\nspec:\n  packageRef:\n    name: postgresql\n    version: \"14.5.2\"\n  \n  # Configuration values (validated against schema)\n  configuration:\n    replicas: 3\n    persistence:\n      size: \"100Gi\"\n    resources:\n      limits:\n        memory: \"4Gi\"\n        cpu: \"2\"\n  \n  # Update policy\n  updatePolicy:\n    automatic: false\n    allowedVersions: \"14.x.x\"\n    schedule: \"0 2 * * 0\"  # Weekly on Sunday at 2am\n    approvalRequired: true\n  \n  # State management reference\n  stateRef:\n    name: postgresql-main-state\n    \n  # Service account to use\n  serviceAccountName: postgresql-installer</code></pre><p>What k8s needs is a system that meets the following requirements:</p><ol><li>: Everything is a Kubernetes resource with proper status and events</li><li><strong>First-Class State Management</strong>: Built-in support for stateful applications</li><li>: Robust signing, verification, and security scanning</li><li><strong>Declarative Configuration</strong>: No templates, just structured configuration with schemas</li><li>: Comprehensive lifecycle hooks and upgrade strategies</li><li>: Linux-like dependency management with semantic versioning</li><li>: Complete history of changes with who, what, and when, not what Helm currently provides. </li><li>: Support for organizational policies and compliance. </li><li><strong>Simplified User Experience</strong>: Familiar Linux-like package management commands. It seems wild that we're trying to go a different direction from the package systems that have worked for decades. </li></ol><p>Try to imagine, across the entire globe, how much time and energy has been invested in trying to solve any one of the following three problems. </p><ol><li>I need this pod in this cluster to talk to that pod in that cluster. </li><li>There is a problem happening somewhere in the NAT traversal process and I need to solve it</li><li>I have run out of IP addresses with my cluster because I didn't account for how many you use. Remember: A company starting with a /20 subnet (4,096 addresses), deploys 40 nodes with 30 pods each, and suddenly realizes they're approaching their IP limit. Not that many nodes!</li></ol><p>I am not suggesting the entire internet switches over to IPv6 and right now k8s happily supports IPv6-only if you want and a dualstack approach. But I'm saying now is the time to flip the default and just go IPv6. You eliminate a huge collection of problems all at once. </p><ul><li>Flatter, less complicated network topology inside of the cluster. </li><li>The distinction between multiple clusters becomes a thing organizations can choose to ignore if they want if they want to get public IPs.</li><li>Easier to understand exactly the flow of traffic inside of your stack. </li></ul><p>It has nothing to do with driving IPv6 adoption across the entire globe and just an acknowledgement that we no longer live in a world where you have to accept the weird limitations of IPv4 in a universe where you may need 10,000 IPs suddenly with very little warning. </p><p>The benefits for organizations with public IPv6 addresses is pretty obvious, but there's enough value there for cloud providers and users that even the corporate overlords might get behind it. AWS never needs to try and scrounge up more private IPv4 space inside of a VPC. That's gotta be worth something. </p><p>The common rebuttal to these ideas is, \"Kubernetes is an open platform, so the community can build these solutions.\" While true, this argument misses a crucial point: <strong>defaults are the most powerful force in technology.</strong> The \"happy path\" defined by the core project dictates how 90% of users will interact with it. If the system defaults to expecting signed packages and provides a robust, native way to manage them, that is what the ecosystem will adopt.</p><p>This is an ambitious list, I know. But if we're going to dream, let's dream big. After all, we're the industry that thought naming a technology 'Kubernetes' would catch on, and somehow it did!</p><p>We see this all the time in other areas like mobile developer and web development, where platforms assess their situation and make  jumps forward. Not all of these are necessarily projects that the maintainers or companies  take on but I think they're all ideas that  should at least revisit and think \"is it worth doing now that we're this nontrivial percentage of all datacenter operations on the planet\"? </p>","contentLength":23667,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/kubernetes/comments/1lf9s3f/what_would_a_kubernetes_20_look_like/"},{"title":"What Would a Kubernetes 2.0 Look Like","url":"https://matduggan.com/what-would-a-kubernetes-2-0-look-like/","date":1750336745,"author":"/u/LaFoudre250","guid":162881,"unread":true,"content":"<p>Around 2012-2013 I started to hear a  in the sysadmin community about a technology called \"Borg\". It was (apparently) some sort of Linux container system inside of Google that ran all of their stuff. The terminology was a bit baffling, with something called a \"Borglet\" inside of clusters with \"cells\" but the basics started to leak. There was a concept of \"services\" and a concept of \"jobs\", where applications could use services to respond to user requests and then jobs to complete batch jobs that ran for much longer periods of time. </p><p>Then on June 7th, 2014, we got our first commit of Kubernetes. The Greek word for 'helmsman' that absolutely no one could pronounce correctly for the first three years. (Is it koo-ber-NET-ees? koo-ber-NEET-ees? Just give up and call it k8s like the rest of us.) </p><p>Microsoft, RedHat, IBM, Docker join the Kubernetes community pretty quickly after this, which raised Kubernetes from an interesting Google thing to \"maybe this is a real product?\" On July 21st 2015 we got the v1.0 release as well as the creation of the CNCF. </p><p>In the ten years since that initial commit, Kubernetes has become a large part of my professional life. I use it at home, at work, on side projects‚Äîanywhere it makes sense. It's a tool with a steep learning curve, but it's also a massive force multiplier. We no longer \"manage infrastructure\" at the server level; everything is declarative, scalable, recoverable and (if you‚Äôre lucky) self-healing.</p><p>But the journey hasn't been without problems. Some common trends have emerged, where mistakes or misconfiguration arise from where Kubernetes isn't opinionated enough. Even ten years on, we're still seeing a lot of churn inside of ecosystem and people stepping on well-documented landmines. So, knowing what we know now, what could we do differently to make this great tool even more applicable to more people and problems? </p><p>Let's start with the positive stuff. Why are we still talking about this platform now? </p><p>Containers as a tool for software development make perfect sense. Ditch the confusion of individual laptop configuration and have one standard, disposable concept that works across the entire stack. While tools like Docker Compose allowed for some deployments of containers, they were clunky and still required you as the admin to manage a lot of the steps. I set up a Compose stack with a deployment script that would remove the instance from the load balancer, pull the new containers, make sure they started and then re-added it to the LB, as did lots of folks. </p><p>K8s allowed for this concept to scale out, meaning it was possible to take a container from your laptop and deploy an identical container across thousands of servers. This flexibility allowed organizations to revisit their entire design strategy, dropping monoliths and adopting more flexible (and often more complicated) micro-service designs. </p><p>If you think of the history of Operations as a sort of \"naming timeline from pets to cattle\", we started with what I affectionately call the \"Simpsons\" era. Servers were bare metal boxes set up by teams, they often had one-off names that became slang inside of teams and everything was a snowflake. The longer a server ran, the more cruft it picked up until it became a scary operation to even reboot them, much less attempt to rebuild them. I call it the \"Simpsons\" era because among the jobs I was working at the time, naming them after Simpsons characters was surprisingly common. Nothing fixed itself, everything was a manual operation. </p><p>Then we transition into the \"01 Era\". Tools like Puppet and Ansible have become common place, servers are more disposable and you start to see things like bastion hosts and other access control systems become the norm. Servers aren't all facing the internet, they're behind a load balancer and we've dropped the cute names for stuff like \"app01\" or \"vpn02\". Organizations designed it so they could lose some of their servers some of the time. However failures still weren't self-healing, someone still had to SSH in to see what broke, write up a fix in the tooling and then deploy it across the entire fleet. OS upgrades were still complicated affairs. </p><p>We're now in the \"UUID Era\". Servers exist to run containers, they are entirely disposable concepts. Nobody cares about how long a particular version of the OS is supported for, you just bake a new AMI and replace the entire machine. K8s wasn't the only technology enabling this, but it was the one that accelerated it. Now the idea of a bastion server with SSH keys that I go to the underlying server to fix problems is seen as more of a \"break-glass\" solution. Almost all solutions are \"destroy that Node, let k8s reorganize things as needed, make a new Node\". </p><p>A lot of the Linux skills that were critical to my career are largely nice to have now, not need to have. You can be happy or sad about that, I certainly switch between the two emotions on a regular basis, but it's just the truth. </p><p>The k8s jobs system isn't perfect, but it's so much better than the \"snowflake cron01 box\" that was an extremely common sight at jobs for years. Running on a cron schedule or running from a message queue, it was now possible to reliably put jobs into a queue, have them get run, have them restart if they didn't work and then move on with your life. </p><p>Not only does this free up humans from a time-consuming and boring task, but it's also simply a more efficient use of resources. You are still spinning up a pod for every item in the queue, but your teams have a lot of flexibility inside of the \"pod\" concept for what they need to run and how they want to run it. This has really been a quality of life improvement for a lot of people, myself included, who just need to be able to easily background tasks and not think about them again. </p><p><strong>Service Discoverability and Load Balancing</strong></p><p>Hard-coded IP addresses that lived inside of applications as the template for where requests should be routed has been a curse following me around for years. If you were lucky, these dependencies weren't based on IP address but were actually DNS entries and you could change the thing behind the DNS entry without coordinating a deployment of a million applications. </p><p>K8s allowed for simple DNS names to call other services. It removed an entire category of errors and hassle and simplified the entire thing down. With the Service API you had a stable, long lived IP and hostname that you could just point things towards and not think about any of the underlying concepts. You even have concepts like ExternalName that allow you to treat external services like they're in the cluster. </p><h2>What would I put in a Kubernetes 2.0?</h2><p>YAML was appealing because it wasn't JSON or XML, which is like saying your new car is great because it's neither a horse nor a unicycle. It demos nicer for k8s, looks nicer sitting in a repo and has the  of being a simple file format. In reality. YAML is just too much for what we're trying to do with k8s and it's not a safe enough format. Indentation is error-prone, the files don't scale great (you really don't want a super long YAML file), debugging can be annoying. YAML has  subtle behaviors outlined in its spec.</p><p>I still remember not believing what I was seeing the first time I saw the Norway Problem. For those lucky enough to not deal with it, the Norway Problem in YAML is when 'NO' gets interpreted as false. Imagine explaining to your Norwegian colleagues that their entire country evaluates to false in your configuration files. Add in accidental numbers from lack of quotes, the list goes on and on. There are much better posts on why YAML is crazy than I'm capable of writing: <a href=\"https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell\">https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell</a></p><p>HCL is already the format for Terraform, so at least we'd only have to hate one configuration language instead of two. It's strongly typed with explicit types. There's already good validation mechanisms. It is specifically designed to do the job that we are asking YAML to do and it's not much harder to read. It has built-in functions people are already using that would allow us to remove some of the third-party tooling from the YAML workflow. </p><p>I would wager 30% of Kubernetes clusters today are  being managed with HCL via Terraform. We don't need the Terraform part to get a lot of the benefits of a superior configuration language. </p><p>The only downsides are that HCL is slightly more verbose than YAML, and its Mozilla Public License 2.0 (MPL-2.0) would require careful legal review for integration into an Apache 2.0 project like Kubernetes. However, for the quality-of-life improvements it offers, these are hurdles worth clearing.</p><p>Let's take a simple YAML file. </p><pre><code># YAML doesn't enforce types\nreplicas: \"3\"  # String instead of integer\nresources:\n  limits:\n    memory: 512  # Missing unit suffix\n  requests:\n    cpu: 0.5m    # Typo in CPU unit (should be 500m)</code></pre><p>Even in the most basic example, there are footguns everywhere. HCL and the type system would catch all of these problems. </p><pre><code>replicas = 3  # Explicitly an integer\n\nresources {\n  limits {\n    memory = \"512Mi\"  # String for memory values\n  }\n  requests {\n    cpu = 0.5  # Number for CPU values\n  }\n}</code></pre><p>Take a YAML file like this that you probably have 6000 in your k8s repo. Now look at HCL without needing external tooling. </p><pre><code># Need external tools or templating for dynamic values\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  # Can't easily generate or transform values\n  DATABASE_URL: \"postgres://user:password@db:5432/mydb\"\n  API_KEY: \"static-key-value\"\n  TIMESTAMP: \"2023-06-18T00:00:00Z\"  # Hard-coded timestamp</code></pre><pre><code>resource \"kubernetes_config_map\" \"app_config\" {\n  metadata {\n    name = \"app-config\"\n  }\n  \n  data = {\n    DATABASE_URL = \"postgres://${var.db_user}:${var.db_password}@${var.db_host}:${var.db_port}/${var.db_name}\"\n    API_KEY      = var.api_key != \"\" ? var.api_key : random_string.api_key.result\n    TIMESTAMP    = timestamp()\n  }\n}\n\nresource \"random_string\" \"api_key\" {\n  length  = 32\n  special = false\n}</code></pre><p>Here's all the pros you get with this move. </p><ol><li>: Preventing type-related errors before deployment</li><li>: Reducing duplication and improving maintainability</li><li><strong>Functions and Expressions</strong>: Enabling dynamic configuration generation</li><li>: Supporting environment-specific configurations</li><li>: Simplifying repetitive configurations</li><li>: Improving documentation and readability</li><li>: Making errors easier to identify and fix</li><li>: Enabling reuse of configuration components</li><li>: Preventing invalid configurations</li><li>: Supporting complex data manipulations</li></ol><p>I know, I'm the 10,000 person to write this. Etcd has done a fine job, but it's a little crazy that it is the only tool for the job. For smaller clusters or smaller hardware configuration, it's a large use of resources in a cluster type where you will never hit the node count where it pays off. It's also a strange relationship between k8s and etcd now, where k8s is basically the only etcd customer left. </p><p>What I'm suggesting is taking the work of <a href=\"https://github.com/k3s-io/kine\" rel=\"noreferrer\">kine</a> and making it official. It makes sense for the long-term health of the project to have the ability to plug in more backends, adding this abstraction means it (should) be easier to swap in new/different backends in the future and it also allows for more specific tuning depending on the hardware I'm putting out there. </p><p>What I suspect this would end up looking like is much like this: <a href=\"https://github.com/canonical/k8s-dqlite\">https://github.com/canonical/k8s-dqlite</a>. Distributed SQlite in-memory with Raft consensus and almost zero upgrade work required that would allow cluster operators to have more flexibility with the persistence layer of their k8s installations. If you have a conventional server setup in a datacenter and etcd resource usage is not a problem, great! But this allows for lower-end k8s to be a nicer experience and (hopefully) reduces dependence on the etcd project. </p><h3>Beyond Helm: A Native Package Manager</h3><p>Helm is a perfect example of a temporary hack that has grown to be a permanent dependency. I'm grateful to the maintainers of Helm for all of their hard work, growing what was originally a hackathon project into the de-facto way to install software into k8s clusters. It has done as good a job as something could in fulfilling that role without having a deeper integration into k8s. </p><p>All that said, Helm is a nightmare to use. The Go templates are tricky to debug, often containing complex logic that results in really confusing error scenarios. The error messages you get from those scenarios are often gibberish. Helm isn't a very good package system because it fails at some of the basic tasks you need a package system to do, which are transitive dependencies and resolving conflicts between dependencies. </p><p>Tell me what this conditional logic is trying to do:</p><pre><code># A real-world example of complex conditional logic in Helm\n{{- if or (and .Values.rbac.create .Values.serviceAccount.create) (and .Values.rbac.create (not .Values.serviceAccount.create) .Values.serviceAccount.name) }}\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: {{ template \"myapp.fullname\" . }}\n  labels:\n    {{- include \"myapp.labels\" . | nindent 4 }}\n{{- end }}</code></pre><p>Or if I provide multiple values files to my chart, which one wins:</p><pre><code>helm install myapp ./mychart -f values-dev.yaml -f values-override.yaml --set service.type=NodePort</code></pre><p>Ok, what if I want to manage my application and all the application dependencies with a Helm chart. This makes sense, I have an application that itself has dependencies on other stuff so I want to put them all together. So I define my sub-charts or umbrella charts inside of my Chart.yaml. </p><pre><code>dependencies:\n- name: nginx\n  version: \"1.2.3\"\n  repository: \"&lt;https://example.com/charts&gt;\"\n- name: memcached\n  version: \"1.2.3\"\n  repository: \"&lt;https://another.example.com/charts&gt;\"\n</code></pre><p>But assuming I have multiple applications, it's entirely possible that I have 2 services both with a dependency on nginx or whatever like this:</p><p>Helm doesn't handle this situation gracefully because template names are global with their templates loaded alphabetically. Basically you need to:</p><ul><li>Don't declare a dependency on the same chart more than once (hard to do for a lot of microservices)</li><li>If you do have the same chart declared multiple times, has to use the exact same version</li></ul><p>The list of issues goes on and on. </p><ul><li>Cross-Namespace installation stinks</li><li>Chart verification process is a pain and nobody uses it</li></ul><p>Let's just go to the front page of artifacthub:</p><p>I'll grab elasticsearch cause that seems important. </p><p>Seems  for the Official Elastic helm chart. Certainly  will be right, it's an absolute critical dependency for the entire industry. </p><p>Nope. Also how is the maintainer of the chart \"Kubernetes\" and it's  not marked as a . Like Christ how much more verified does it get.</p><ul><li>No metadata in chart searching. You can only search by name and description, not by features, capabilities, or other metadata.</li></ul><ul><li>Helm doesn't strictly enforce semantic versioning</li></ul><pre><code># Chart.yaml with non-semantic version\napiVersion: v2\nname: myapp\nversion: \"v1.2-alpha\" </code></pre><ul><li>If you uninstall and reinstall a chart with CRDs, it might delete resources created by those CRDs. This one has screwed me  and is crazy unsafe. </li></ul><p>I could keep writing for another 5000 words and still wouldn't have outlined all the problems. There isn't a way to make Helm good enough for the task of \"package manager for all the critical infrastructure on the planet\". </p><h4>What would a k8s package system look like?</h4><p>Let's call our hypothetical package system KubePkg, because if there's one thing the Kubernetes ecosystem needs, it's another abbreviated name with a 'K' in it. We would try to copy as much of the existing work inside the Linux ecosystem while taking advantage of the CRD power of k8s. My idea looks something like this:</p><p>The packages are bundles like a Linux package:</p><p>There's a definition file that accounts for as many of the real scenarios that you actually encounter when installing a thing. </p><pre><code>apiVersion: kubepkg.io/v1\nkind: Package\nmetadata:\n  name: postgresql\n  version: 14.5.2\nspec:\n  maintainer:\n    name: \"PostgreSQL Team\"\n    email: \"<a href=\"https://matduggan.com/cdn-cgi/l/email-protection\" data-cfemail=\"bad7dbd3d4cedbd3d4dfc8c9facad5c9ceddc8dfc9cbd694dfc2dbd7cad6df94d9d5d7\">[email&nbsp;protected]</a>\"\n  description: \"PostgreSQL database server\"\n  website: \"https://postgresql.org\"\n  license: \"PostgreSQL\"\n  \n  # Dependencies with semantic versioning\n  dependencies:\n    - name: storage-provisioner\n      versionConstraint: \"&gt;=1.0.0\"\n    - name: metrics-collector\n      versionConstraint: \"^2.0.0\"\n      optional: true\n  \n  # Security context and requirements\n  security:\n    requiredCapabilities: [\"CHOWN\", \"SETGID\", \"SETUID\"]\n    securityContextConstraints:\n      runAsUser: 999\n      fsGroup: 999\n    networkPolicies:\n      - ports:\n        - port: 5432\n          protocol: TCP\n    \n  # Resources to be created (embedded or referenced)\n  resources:\n    - apiVersion: v1\n      kind: Service\n      metadata:\n        name: postgresql\n      spec:\n        ports:\n        - port: 5432\n    - apiVersion: apps/v1\n      kind: StatefulSet\n      metadata:\n        name: postgresql\n      spec:\n        # StatefulSet definition\n  \n  # Configuration schema using JSON Schema\n  configurationSchema:\n    type: object\n    properties:\n      replicas:\n        type: integer\n        minimum: 1\n        default: 1\n      persistence:\n        type: object\n        properties:\n          size:\n            type: string\n            pattern: \"^[0-9]+[GMK]i$\"\n            default: \"10Gi\"\n  \n  # Lifecycle hooks with proper sequencing\n  hooks:\n    preInstall:\n      - name: database-prerequisites\n        job:\n          spec:\n            template:\n              spec:\n                containers:\n                - name: init\n                  image: postgres:14.5\n    postInstall:\n      - name: database-init\n        job:\n          spec:\n            # Job definition\n    preUpgrade:\n      - name: backup\n        job:\n          spec:\n            # Backup job definition\n    postUpgrade:\n      - name: verify\n        job:\n          spec:\n            # Verification job definition\n    preRemove:\n      - name: final-backup\n        job:\n          spec:\n            # Final backup job definition\n  \n  # State management for stateful applications\n  stateManagement:\n    backupStrategy:\n      type: \"snapshot\"  # or \"dump\"\n      schedule: \"0 2 * * *\"  # Daily at 2 AM\n      retention:\n        count: 7\n    recoveryStrategy:\n      type: \"pointInTime\"\n      verificationJob:\n        spec:\n          # Job to verify recovery success\n    dataLocations:\n      - path: \"/var/lib/postgresql/data\"\n        volumeMount: \"data\"\n    upgradeStrategies:\n      - fromVersion: \"*\"\n        toVersion: \"*\"\n        strategy: \"backup-restore\"\n      - fromVersion: \"14.*.*\"\n        toVersion: \"14.*.*\"\n        strategy: \"in-place\"</code></pre><p>There's a real signing process that would be required and allow you more control over the process. </p><pre><code>apiVersion: kubepkg.io/v1\nkind: Repository\nmetadata:\n  name: official-repo\nspec:\n  url: \"https://repo.kubepkg.io/official\"\n  type: \"OCI\"  # or \"HTTP\"\n  \n  # Verification settings\n  verification:\n    publicKeys:\n      - name: \"KubePkg Official\"\n        keyData: |\n          -----BEGIN PUBLIC KEY-----\n          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvF4+...\n          -----END PUBLIC KEY-----\n    trustPolicy:\n      type: \"AllowList\"  # or \"KeyRing\"\n      allowedSigners:\n        - \"KubePkg Official\"\n        - \"Trusted Partner\"\n    verificationLevel: \"Strict\"  # or \"Warn\", \"None\"</code></pre><p>Like how great would it be to have something where I could automatically update packages without needing to do anything on my side. </p><pre><code>apiVersion: kubepkg.io/v1\nkind: Installation\nmetadata:\n  name: postgresql-main\n  namespace: database\nspec:\n  packageRef:\n    name: postgresql\n    version: \"14.5.2\"\n  \n  # Configuration values (validated against schema)\n  configuration:\n    replicas: 3\n    persistence:\n      size: \"100Gi\"\n    resources:\n      limits:\n        memory: \"4Gi\"\n        cpu: \"2\"\n  \n  # Update policy\n  updatePolicy:\n    automatic: false\n    allowedVersions: \"14.x.x\"\n    schedule: \"0 2 * * 0\"  # Weekly on Sunday at 2am\n    approvalRequired: true\n  \n  # State management reference\n  stateRef:\n    name: postgresql-main-state\n    \n  # Service account to use\n  serviceAccountName: postgresql-installer</code></pre><p>What k8s needs is a system that meets the following requirements:</p><ol><li>: Everything is a Kubernetes resource with proper status and events</li><li><strong>First-Class State Management</strong>: Built-in support for stateful applications</li><li>: Robust signing, verification, and security scanning</li><li><strong>Declarative Configuration</strong>: No templates, just structured configuration with schemas</li><li>: Comprehensive lifecycle hooks and upgrade strategies</li><li>: Linux-like dependency management with semantic versioning</li><li>: Complete history of changes with who, what, and when, not what Helm currently provides. </li><li>: Support for organizational policies and compliance. </li><li><strong>Simplified User Experience</strong>: Familiar Linux-like package management commands. It seems wild that we're trying to go a different direction from the package systems that have worked for decades. </li></ol><p>Try to imagine, across the entire globe, how much time and energy has been invested in trying to solve any one of the following three problems. </p><ol><li>I need this pod in this cluster to talk to that pod in that cluster. </li><li>There is a problem happening somewhere in the NAT traversal process and I need to solve it</li><li>I have run out of IP addresses with my cluster because I didn't account for how many you use. Remember: A company starting with a /20 subnet (4,096 addresses), deploys 40 nodes with 30 pods each, and suddenly realizes they're approaching their IP limit. Not that many nodes!</li></ol><p>I am not suggesting the entire internet switches over to IPv6 and right now k8s happily supports IPv6-only if you want and a dualstack approach. But I'm saying now is the time to flip the default and just go IPv6. You eliminate a huge collection of problems all at once. </p><ul><li>Flatter, less complicated network topology inside of the cluster. </li><li>The distinction between multiple clusters becomes a thing organizations can choose to ignore if they want if they want to get public IPs.</li><li>Easier to understand exactly the flow of traffic inside of your stack. </li></ul><p>It has nothing to do with driving IPv6 adoption across the entire globe and just an acknowledgement that we no longer live in a world where you have to accept the weird limitations of IPv4 in a universe where you may need 10,000 IPs suddenly with very little warning. </p><p>The benefits for organizations with public IPv6 addresses is pretty obvious, but there's enough value there for cloud providers and users that even the corporate overlords might get behind it. AWS never needs to try and scrounge up more private IPv4 space inside of a VPC. That's gotta be worth something. </p><p>The common rebuttal to these ideas is, \"Kubernetes is an open platform, so the community can build these solutions.\" While true, this argument misses a crucial point: <strong>defaults are the most powerful force in technology.</strong> The \"happy path\" defined by the core project dictates how 90% of users will interact with it. If the system defaults to expecting signed packages and provides a robust, native way to manage them, that is what the ecosystem will adopt.</p><p>This is an ambitious list, I know. But if we're going to dream, let's dream big. After all, we're the industry that thought naming a technology 'Kubernetes' would catch on, and somehow it did!</p><p>We see this all the time in other areas like mobile developer and web development, where platforms assess their situation and make  jumps forward. Not all of these are necessarily projects that the maintainers or companies  take on but I think they're all ideas that  should at least revisit and think \"is it worth doing now that we're this nontrivial percentage of all datacenter operations on the planet\"? </p>","contentLength":23667,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lf9s0v/what_would_a_kubernetes_20_look_like/"},{"title":"MetalLB BGP setup","url":"https://www.reddit.com/r/kubernetes/comments/1lf91d6/metallb_bgp_setup/","date":1750334524,"author":"/u/Several_Yoghurt1759","guid":162808,"unread":true,"content":"<p>How do you guys maintain your BGP config on your ToR devices? Firewall in my case</p><p>If I‚Äôm setting up my production cluster with metallb bgp mode, and I‚Äôve peered with each of the nodes from the firewall what happens when the autoscaler scales out or in or a cluster upgrade spins up entirely new nodes? </p>","contentLength":305,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"My 1978 analog mockumentary was mistaken for AI. Is this the future of media perception?","url":"https://www.reddit.com/r/artificial/comments/1lf8y7q/my_1978_analog_mockumentary_was_mistaken_for_ai/","date":1750334264,"author":"/u/strippedlugnut","guid":162854,"unread":true,"content":"<p>I did an AMA on <a href=\"https://www.reddit.com/r/movies\">r/movies</a>, and the wildest takeaway was how many people assumed the real world 1978 trailer imagery was AI-generated. Ironically the only thing that was AI was all the audio that no one questioned until I told them.</p><p>It genuinely made me stop and think: <strong>Have we reached a point where analog artifacts look</strong></p>","contentLength":318,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PSA: XWayland doesn't have to be blurry on GNOME","url":"https://www.reddit.com/r/linux/comments/1lf8taf/psa_xwayland_doesnt_have_to_be_blurry_on_gnome/","date":1750333813,"author":"/u/mort96","guid":162883,"unread":true,"content":"<p>A lot of us who run GNOME Wayland try to avoid XWayland apps, because they're blurry when using DPI scaling.</p><p>Well, it turns out that since GNOME 47 (I think), GNOME has had a fix for this, it's just disabled by default. To enable the fix, follow these steps:</p><ol><li>Open Terminal and run: <code>gsettings set org.gnome.mutter experimental-features \"['scale-monitor-framebuffer', 'xwayland-native-scaling']\"</code></li><li>Log out and back in again</li></ol><p>Your XWayland apps like Electron apps, Steam, LMMS, etc etc. should now work great.</p><p>Note: if text in Steam is too small, go to Steam Settings -&gt; Interface and enable \"Scale text and icons to match monitor settings\".</p><p>You can check what version of GNOME you're using by going to Settings -&gt; System -&gt; About -Y System Details. It should have an entry called \"GNOME Version\". For me, it shows GNOME Version: 48, and Windowing System: Wayland.</p><p>If you're on KDE, you don't need to do anything, since KDE has had this fix implemented and enabled by default for ages now. I'm hoping GNOME will enable it by default soon.</p>","contentLength":1025,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Story of a Prisoner Who Became a Software Engineer","url":"https://analyticsindiamag.com/ai-features/the-story-of-a-prisoner-who-became-a-software-engineer/","date":1750333329,"author":"/u/Soul_Predator","guid":162853,"unread":true,"content":"<p>In a world where many may procrastinate learning to code or improving their skills despite leading a comfortable lifestyle, one man is proving that even the confines of prison cannot suppress a passion for coding. Meet the software engineer who, despite being incarcerated, is making his mark in the tech world. His story is a testament to the belief that anyone, anywhere, can master complex programming languages.</p><p> recently stumbled upon this individual‚Äîan open-source contributor and coder with expertise in Rust and Python programming languages, and an avid Linux user‚Äîwho continues to build and contribute to databases, even from behind bars.&nbsp;</p><p>What sounds like the plot of a movie is, in fact, the true story of <a href=\"https://www.linkedin.com/in/pthorpe92/\">Preston Thorpe</a>, a software engineer at Turso, an open-source distributed database powered by libSQL.  had the opportunity to speak exclusively with Thorpe, who opened up about his journey of programming during his time in prison.</p><h2>A Prisoner‚Äôs Attempt at a Better Outlook on Life Through Coding</h2><p>The 33-year-old software engineer spends his days working remotely from his prison cell in the Mountain View Correctional Facility in Charleston, Maine. Despite the confines of the facility, he has become a software engineer at Turso, actively contributing to projects like the rewrite of SQLite.&nbsp;</p><p>But his journey to this point has been far from conventional, driven by self-reflection, project-based learning, and an insatiable desire to improve. For nearly a decade, Thorpe was reportedly incarcerated for <a href=\"https://www.doj.nh.gov/news-and-media/preston-thorpe-sentenced-state-prison-possession-u-47700-synthetic-opioid-intent\">non-violent drug crimes</a>. However, instead of succumbing to the obvious hopelessness that often defines life behind bars, he discovered a sense of purpose through programming.</p><p>Explaining how it all started, Thorpe said, ‚ÄúThere was one day, after spending a few years in the more calm and respectful environment in the Maine prison, where I had an epiphany and started questioning everything about my life.‚Äù</p><p>‚ÄúI no longer knew why I had accepted that identity and situation, none of it made sense to me anymore, and I decided that I was no longer okay with being where I was or who I had become.‚Äù</p><p>Thorpe‚Äôs programming journey started with a simple but powerful resource: access to a computer through a prison college programme at the University of Maine at Augusta. With limited internet access and a passion to outgrow the curriculum in place, Thorpe created his own learning path.&nbsp;</p><p>He primarily attributes his success to project-based learning, having had just enough high school experience to understand what he needed to learn. His days were consumed by intense self-study, working on projects, and contributing to open-source software.</p><p>‚ÄúI started in Python until I felt like I remembered enough of the basics, then moved to C and built very fundamental things like my own ‚Äòstandard library‚Äô of data structures,‚Äù Thorpe said.&nbsp;</p><p>This project-based approach allowed him to learn the intricacies of various <a href=\"https://analyticsindiamag.com/ai-features/90-of-programming-languages-have-english-based-syntax/\">programming languages</a> while also developing practical tools that would serve as the foundation for his career.</p><p>Thorpe‚Äôs learning wasn‚Äôt restricted to just writing code. He immersed himself in the theory of computer science, reading academic papers, listening to lectures, and exploring the underlying architecture of software systems.&nbsp;</p><p>His interest in databases led him to explore relational databases, despite having no prior experience in the field. Thorpe explained that his database work initially involved logically isolated components, allowing him to focus on areas aligned with his existing knowledge.&nbsp;</p><p>His initial contributions included translating from Abstract Syntax Tree (AST) to bytecode and working on the Virtual DataBase Engine (VDBE). He didn‚Äôt immediately delve into specific database internals, often working on the IO layer or the command-line interface (CLI).&nbsp;</p><p>Thorpe also dedicated time to developing the extension library and <a href=\"https://analyticsindiamag.com/ai-features/why-developers-are-quietly-quitting-golang/\">Go language</a> bindings. Through a process of gradual familiarisation, extensive reading of research papers, and studying <a href=\"https://www.youtube.com/c/CMUDatabaseGroup\">CMU lectures</a>, he built the confidence to explore diverse areas and implement features across the entire codebase.</p><p>In a <a href=\"https://turso.tech/blog/working-on-databases-from-prison\">recent blog post</a> on his company‚Äôs website, Thorpe highlighted, ‚ÄúI either write code or manage Kubernetes clusters or other infrastructure for about 90 hours a week, and my only entertainment is a daily hour of tech/programming YouTube.‚Äù</p><p>Thorpe‚Äôs self-driven journey took a pivotal turn when he was accepted into Maine‚Äôs remote work programme‚Äîa rare opportunity for imprisoned individuals to pursue legitimate employment outside the prison.</p><p>This programme became the gateway to his professional career in tech. ‚ÄúBecause there was no precedent set for any of this, what I believe is the most crucial support was the fact that administrators took a chance and allowed me to earn their trust eventually,‚Äù he said.&nbsp;</p><p>His first job was with Unlocked Labs, a company focused on building educational technology for incarcerated individuals. Thorpe‚Äôs contributions there quickly gained recognition, and within a year, he was promoted to lead their development team.</p><p>Despite thriving in his role at Unlocked Labs, Thorpe‚Äôs ambition drove him to push even further. His exposure to the world of databases through various open-source projects eventually led him to Turso, a company working on rewriting SQLite.</p><h2>Grateful for the Absence of LLMs and Project-based Learning</h2><p>In today‚Äôs fast-evolving tech landscape, many developers turn to tools powered by large language models (LLMs) like <a href=\"https://analyticsindiamag.com/global-tech/anthropics-claude-code-has-been-writing-half-of-my-code/\">Claude Code</a> to speed up their learning and coding.&nbsp;</p><p>However, Thorpe views his lack of access to these tools during his learning years as a blessing in disguise. ‚ÄúI‚Äôm very grateful that LLMs are something that I did not have available to me for a large portion of my time learning,‚Äù he told .</p><p>‚ÄúWith the proper discipline, if it is a topic you are truly interested in, you can certainly use it to help teach you things, but I would worry for anyone who may be inclined to take shortcuts, as it could easily prevent learning as well.‚Äù</p><p>He firmly believes in the value of building real-world projects as a means of understanding and mastering programming concepts. He asserted that the knowledge gained from solving a problem and building a solution would surpass the learning acquired by breaking down each component and focusing on individual parts.</p><p>For Thorpe, learning didn‚Äôt just happen in isolation. He also credited his contributions to open-source projects as a key part of his development. ‚ÄúI have found reading code very valuable,‚Äù he said.&nbsp;</p><p>Looking ahead, Thorpe is particularly excited about the future of embedded and distributed databases. Moreover, he envisions significant future developments at Turso, including native support for efficient semantic searches and similarity matching in embedded databases. Such developments would enable more efficient reasoning over locally stored context, eliminating the need for separate vector databases or complex infrastructure.&nbsp;</p><p>His story proves that with determination, a focus on continuous learning, and an unwavering commitment to self-improvement, even the most unlikely paths can lead to success.&nbsp;</p><p>That being said, it‚Äôs important to recognise the lessons in his journey and understand that success is best achieved through ethical means, rather than indulging in illegal activities.</p>","contentLength":7378,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lf8o2p/the_story_of_a_prisoner_who_became_a_software/"},{"title":"Go for DevOps books","url":"https://www.reddit.com/r/golang/comments/1lf8glp/go_for_devops_books/","date":1750332636,"author":"/u/reisinge","guid":162882,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/reisinge\"> /u/reisinge </a>","contentLength":31,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HTML docs for clap apps without adding any dependencies","url":"https://www.reddit.com/r/rust/comments/1lf80w7/html_docs_for_clap_apps_without_adding_any/","date":1750331137,"author":"/u/winter-moon","guid":162982,"unread":true,"content":"<div><p>It works with any clap-based CLI (or similar help format) - no need to modify your code or recompile anything. Just point it at an executable and it recursively extracts all subcommands and options. </p></div>   submitted by   <a href=\"https://www.reddit.com/user/winter-moon\"> /u/winter-moon </a>","contentLength":233,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Zopdev Summer of Code: Inviting all Builders","url":"https://www.reddit.com/r/kubernetes/comments/1lf8021/zopdev_summer_of_code_inviting_all_builders/","date":1750331054,"author":"/u/Recent-Technology-83","guid":162807,"unread":true,"content":"<p>Zopdev Summer of Code is here - your opportunity to learn, build, and contribute to real-world open-source projects while working alongside industry experts.</p><p>Whether you're looking to boost your resume, gain hands-on experience, or explore new technologies, this is your chance to grow.</p><p>-------------------------------------------</p><p>This time, we‚Äôre offering two exciting tracks:</p><p><strong>Track 1: Zopdev + AI Agents:</strong></p><p>Work on AI intelligent systems that provide AI-powered agents helpful for the developers and it has to be deployed using the Zopdev. Note: On Contribution to the zopdev/helm-charts will have a bonus point.</p><p><strong>Track 2: Helm Chart Contributions:</strong></p><p>Contribute to our open-source Helm chart repository. Learn infrastructure as code, Kubernetes, and best practices in DevOps.</p><p><strong>Real Open-Source Contributions:</strong> Work on impactful projects used by real teams.  Learn directly from Zopdev engineers and maintainers. <strong>Structured Training Phase:</strong> Get the resources and guidance you need to contribute confidently.  Receive a Certificate of Participation and exclusive Zopdev swag.  Recognition and rewards for the most dedicated solution.  Collaborate with developers from around the world.</p><p>-------------------------------------------</p><p>Students, professionals, or hobbyist Basic knowledge on ML Models, AI Agents, Helm charts, Kubernetes. Eagerness to learn and contribute</p><p> June 14 ‚Äì June 29, 2025  Starts Start of July  Post-training phase</p><p>Here‚Äôs your chance to learn, contribute, and grow - earn a certificate, make an impact, and have fun alongside like-minded developers!</p><p>-------------------------------------------</p><p><strong>Ready to build, learn, and grow:</strong> Join us for Zopdev Summer of Code 2025 and be part of something meaningful.</p>","contentLength":1706,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI did pretty decent on Luna‚Äôs campaign photos","url":"https://www.reddit.com/r/artificial/comments/1lf7buw/ai_did_pretty_decent_on_lunas_campaign_photos/","date":1750328585,"author":"/u/LokiDMV","guid":162811,"unread":true,"content":"<p>Hey everyone! I‚Äôm reaching out to share something close to my heart. Luna, my amazing pitbull rescue, is a finalist in the Animal Welfare League of Alexandria‚Äôs 2026 photo calendar contest ‚Äî and she needs your votes!</p><p>If Luna wins, she‚Äôll get some truly amazing honors, including: * Being named Alexandria‚Äôs 2026 Animal of the Year * Gracing both the front and back covers of the AWLA calendar * A professional pet photography session * A special proclamation from the mayor naming a day in her honor (!!) * Featured on the AWLA‚Äôs homepage for all of 2026 * And her photo will be displayed on buses across Northern Virginia in late 2025! Pretty wild, right?</p><p>I‚Äôd be so grateful if you could help by voting. Each vote is $1, and all proceeds go directly to supporting the AWLA‚Äôs incredible work saving and caring for animals like Luna.</p><p>üíñ My personal goal is to raise $3000 for the shelter that saved her. Every dollar and vote makes a difference!</p><p>Thank you so much for supporting a pittie who beat the odds ‚Äî let‚Äôs show everyone how amazing these dogs really are!</p>","contentLength":1079,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Weekly: This Week I Learned (TWIL?) thread","url":"https://www.reddit.com/r/kubernetes/comments/1lf6z1r/weekly_this_week_i_learned_twil_thread/","date":1750327231,"author":"/u/gctaylor","guid":162713,"unread":true,"content":"<p>Did you learn something new this week? Share here!</p>","contentLength":50,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I got tired of the iPhone timer for my workouts, so I built my own solution with Flutter","url":"https://github.com/JosephDoUrden/SetTimer","date":1750326413,"author":"/u/JosephDoUrden","guid":162715,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lf6rtp/i_got_tired_of_the_iphone_timer_for_my_workouts/"},{"title":"The joy of (type) sets in Go","url":"https://bitfieldconsulting.com/posts/type-sets","date":1750325925,"author":"/u/EightLines_03","guid":162810,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lf6ndh/the_joy_of_type_sets_in_go/"},{"title":"Ban 'AI' generated posts","url":"https://www.reddit.com/r/linux/comments/1lf6m6p/ban_ai_generated_posts/","date":1750325784,"author":"/u/Keely369","guid":162718,"unread":true,"content":"<p>LLM generated posts are becoming the worst type of spam on here and it's only going to get worse.</p><p>We need a rule banning them. I stated this in a more polite way in my previous post but it was auto-deleted as breaking rule 1, which it did not.</p><p>LLM posts add nothing to the forum, take five seconds to generate with no thought or effort on the part of the OP and waste the time of people who don't recognise them for what they are. They're usually very lengthy as well, which compounds the issue.</p>","contentLength":493,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kubernetes Learning Roadmap Including Visual & Tracking Progress","url":"https://www.reddit.com/r/kubernetes/comments/1lf6hqd/kubernetes_learning_roadmap_including_visual/","date":1750325257,"author":"/u/bilou89","guid":162714,"unread":true,"content":"<p>Master Kubernetes step-by-step with this detailed roadmap. Learn Kubernetes architecture, pods, deployments, services, networking, Helm, RBAC, operators, CI/CD, and production-grade DevOps best practices.</p>","contentLength":204,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Experiences with Thalos, Rancher, Kubermatic, K3s or Open Nebula with OnKE","url":"https://www.reddit.com/r/kubernetes/comments/1lf6bhz/experiences_with_thalos_rancher_kubermatic_k3s_or/","date":1750324560,"author":"/u/Tiny_Sign7786","guid":163082,"unread":true,"content":"<p>I‚Äòm reaching out as I want to know about your experience with different K8s. </p><p>Kontext: We‚Äôre currently using Tanzu and have only problems with it. No update went just smooth, for a long time only EOL k8s versions available and the support is friendly said a joke. With the last case we lost the rest of our trust. We had a P2 because of a production cluster down due to the update. It took more than TWO!!! months to get the problem solved so that the cluster is updated to (the inbetween outdated) new k8s version. And even if the cluster is upgraded it seems like the root cause is still not figured out. What is really a problem as we still have to upgrade one cluster which runs most of our production workload and can‚Äôt be sure if it will work out or not.</p><p>We‚Äôre now planning to get rid of it and evaluate some alternatives. That‚Äôs where your experience should come in. On our shortlist are currently: - Thalos - k3s - Rancher - Open Nebula with OneKE - Kubermatic (haven‚Äôt intensively checked the different options yet)</p><p>We‚Äôre running our stuff in an on premise data center currently with vsphere. That also will probably stay as my team, opposite to Tanzu, has not the owner ship here. That‚Äôs why I‚Äôm for example not sure, if Open Nebula would be overkill as it would be rather a vsphere replacement than just Tanzu. What do you think?</p><p>And how are your experiences with the other platforms? Important factors would be:</p><ul><li>as less complexity is necessary</li><li>difficulty of setup, management, etc.</li><li>how good is the support of there is one</li><li>is there an active community to get help with issues</li><li>If not running bare metal, is it possible to spin up nodes automatically in VMWare (could not really find something in the documentation.</li></ul><p>Of course a lot of other stuff like backup/restore, etc. but that‚Äôs something I can figure out via documentation.</p><p>Thank‚Äôs in advance for sharing your experience. </p>","contentLength":1898,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real-time analytics with an all-in-one system: Are we there yet?","url":"https://questdb.com/blog/realtime-analytics-using-tsdb/","date":1750324407,"author":"/u/j1897OS","guid":162716,"unread":true,"content":"<p>Real-time data analytics have been around for more than a decade, and the\necosystem is quite mature. However, a robust pipeline requires a deep amount of\nhand-crafted integration work.</p><p>After all, there are many powerful and useful parts in a typical real-time\nanalytics toolchain. This is especially evident in use cases which combine\ninsights over a full historical dataset, while also needing to handle new data\nevery second from the real world.</p><p>While there are strong multi-product choices today, we want to know what would\nhappen if  tried to handle the full range of real-time\nanalytics challenges.</p><p>Can any emerging entrants become a true one-stop-shop solution?</p><p>To better understand the overall challenge, consider requirements behind an\n<a href=\"https://questdb.com/glossary/ohcl-candlestick\">open-high-low-close</a> (OHLC) or candlestick chart\nused for trading applications in financial markets. You can get a chart at\nvarious levels of detail: live updates from the current trading day, seamlessly\ncombined with the data from the past week, month, year, and so on.</p><p>To calculate the values for these charts, you have to partition the full dataset\ninto time slices of various sizes, and find the min/avg/max values for each\nslice. These time ranges can be significant.</p><p>This is an example of a general and versatile class of real-time analytics:\n<em><strong>aggregate functions over time slices</strong></em>.</p><p>There's a lot going on under-the-hood to make this work well and fast. To\nillustrate, we'll look at typical real-time analytics system design today, and\nthen we'll contrast that with a look at several database systems.</p><p>Like with financial charts, we tend to perform real-time analytics on a dataset\nthat is both massive and rapidly growing. This creates several tough challenges:</p><ol><li>Storing massive data volumes cheaply and effectively</li><li>Returning robust results at no more than few seconds of latency</li><li>Returning correct results after updates to existing data</li><li>Keeping data access to a minimum ‚Äî access itself costs money</li></ol><p>As the volume of the collected data grows, storage costs balloon. Unless you\nhave your own datacenter and a team committed to continuously procuring and\nmaintaining storage devices and systems, you'll end up as a client of cloud\nstorage, such as Amazon S3, Azure Blob, or Google Cloud Storage.</p><p>This creates a barrier in your software stack ‚Äî one type of storage for fresh\ndata, and another for historical data. You need a system that seamlessly jumps\nover the barrier and serves you the analytic results you need from any period\nyou want:</p><p>The cost of just keeping your data is relatively low, but the story quickly\nchanges once you need to access it. Your system must ensure it accesses only the\ndata which it absolutely needs.</p><p>Basically, if the data didn't change, you shouldn't need to access it again.\nThat's expensive and inefficient. Instead, it's better to store and reuse the\nresults of the analytics you performed once.</p><p>In this scenario, the greatest challenge is an update to the historical data:\nyou must keep the volume of accessed data low, and yet make sure you update\neverything that needs to be updated.</p><p>At the same time, the system must deal with the fresh data that just came in. It\nmust stay on top of possibly millions of events per second, and come up with the\nright answers about what just happened in the world.</p><p>In a typical modern setup, we are likely to use two separate systems, each\nspecialized in solving one challenge. We use Apache Kafka to ingest the data,\nand then fork the data pipeline so that one fork goes to the system optimized\nfor low-cost storage, and the other to the system optimized for real-time event\nprocessing.</p><p>For the recent data, we can use a stream processing engine like Apache Flink. It\ntakes in the events as they occur, aggregates them in memory, and outputs live\nresults with minimal latency:</p><p>For the historical data, the starting point is cheap storage. The primary choice\nfor most companies being cloud storage like S3 or Azure Blob Storage. This kind\nof storage comes with higher access latency. It's completely unstructured (the\nunit of data is a ), and immutable.</p><p>That means you need another system that builds upon this foundation to provide\nhigher-level services. One option is using a cloud-based data lake platform,\nlike Snowflake; another is an open-source analytics tool like Spark:</p><p>This kind of setup obviously has several moving parts, but there's even more\nwhen you take a closer look. For example, how do you access the output of\nrealtime stream processing?</p><p>A streaming engine like Apache Flink only solves the computation concern; its\noutput doesn't automatically come in a form ready for ad-hoc query access.</p><p>One option is storing the results in a general-purpose database, like Postgres.\nThen you can use the same database to store the results for historical data as\nwell, and finally there should be an API frontend component that queries the\ndatabase.</p><p>Another option is to treat Kafka itself as the source of truth. Flink outputs\nits results to a Kafka topic, and then the API frontend component loads them\ninto RAM and serves them. If the component fails, after restart it can just\nrescan the Kafka topic. It can also use a local, embedded database.</p><p>On the data lake side, the main challenge is doing the least amount of work\npossible while maintaining the correctness and completeness of the stored\nanalytics results. You can process the past day's worth of data during the\nnight, when the handover from the real-time system to the data lake occurs.</p><p>All these parts must account for, and be resilient to, failures. To manage this,\nyou need infrastructure that monitors operations and retries failed ones.</p><p>Putting it all together, we get a rough outline of a modern hybrid system for\nrealtime data analytics:</p><p>Since the need for real-time analytics has become mainstream and widespread,\nthere's an increasing demand for a simpler system, one that would automatically\nhandle both historical and new data in a uniform fashion, and simply provide you\nwith the results you want.</p><p>An emerging option for this workload is a streaming data lakehouse system.</p><p>Products from diverse categories have been converging on it, such as data lake\nproducts, real-time streaming engines, and time-series databases. Each one is\nadding features from the others, in a bid to build one complete, integrated\nsystem that handles all the concerns automatically:</p><p>We'll focus on systems that originate in the time-series database category.</p><p>In this category, the best paradigm for real-time analytics is that of the\n. A closely related concept is .</p><p>In its essence, a materialized view is a SQL query in solid-state form: its\nresults are persistent in a database table, available at no computation cost.\nYou can get them using a trivial query that doesn't need to spell out any of the\nbusiness logic needed to calculate them. A materialized view is as convenient to\ncreate as it is to access.</p><p>But to work for our use case, the database must make sure the materialized view\nis always up to date ‚Äî and <strong>that's where things get interesting</strong>. Databases\nvary widely in their support for low-latency updates of materialized views, and\nthose that do have good support vary widely in their approaches.</p><p>We found the following databases to be good at low-latency materialized views:\nTimescaleDB, ClickHouse, and InfluxDB. At QuestDB, we've\n<a href=\"https://questdb.com/blog/how-to-create-a-materialized-view/\">recently introduced materialized views</a>,\nand are constantly improving their performance and ergonomics.</p><p>TimescaleDB is an extension on Postgres and thus benefits from its maturity.\nThis is how you implement continuous aggregation:</p><ol><li> with the desired query. This runs the query\nagainst the existing data, and saves it to the table you named.</li><li><code>SELECT add_continuous_aggregate_policy(...)</code> to schedule a task that updates\nthe materialized view at a fixed time interval.</li></ol><p>When you query the materialized view table, TimescaleDB uses a hybrid approach:\nit takes everything available from the table, and for anything that's missing it\nruns the aggregation query against the base table.</p><p>Thus, you always get the full results, regardless of when the scheduled task\nlast ran. However, the query's runtime will go up in proportion to the volume of\nthe missing materialized results.</p><p>Given this, you'll have to find a balance that minimizes the system load induced\nby the scheduled task, and the runtime of the query. The scheduled task can be\nconfigured to scan only a recent portion of the base table, which limits the\nimpact on system load, but leaves earlier data permanently stale. You can also\nschedule another, less frequent task that updates the full table.</p><p>We should also note that TimescaleDB, due to its Postgres fundamentals, isn't as\noptimized for the ingestion of massive amounts of time-series data. QuestDB\ntypically ingests data at a rate many multiples faster. It's also quite complex\nto scale horizontally. This negatively impacts the resource and maintenance\ncosts.</p><p>TimescaleDB supports tiered storage in its Cloud edition. Once properly set up,\nyou can query the data across tiers transparently. However, setup and\nconfiguration is quite involved and requires knowledge of both Postgres and\nTimecaleDB concepts. You can't directly update the data in cold storage. You\nmust go through the manual steps of \"un-tiering\" it, updating and \"re-tiering\"\nit.</p><p>TimescaleDB benefits from the maturity of Postgres in terms of the support for\nmonitoring and diagnostics of the tasks that keep the materialized view up to\ndate. You can also integrate with Prometheus.</p><p>ClickHouse also supports , but with completely\ndifferent semantics. This is how you use it:</p><ol><li>Manually  that will hold the materialized view. Specify the\ncorrect table engine: .</li><li><code>CREATE MATERIALIZED VIEW ...</code> ‚Äî this sets up a scheduled task that will run\nwhenever you insert new data, and specifies the aggregation expression.\nExisting data won't be processed.</li><li>Manually backfill the table with existing data.</li></ol><p>Since ClickHouse runs the aggregation whenever you insert data, the latency of\nthe aggregated results is very low. However, updates and deletions aren't\nreflected and need to be handled manually.</p><p>ClickHouse supports tiered storage in its Cloud edition. It will automatically\nmove the older data to cold storage using its TTL feature. You can't directly\nupdate the data in cold storage, you must take manual steps to move it back to\nhot storage, delete the outdated data, insert data with updates, and move back\nto cold storage.</p><p>The materialized view table is like any other, and allows arbitrary\ninsert/update/delete actions, as well as schema changes. This makes it prone to\nincorrect data and errors in the continuous aggregation process.</p><p>ClickHouse is great at raw ingestion performance, but compared to TimescaleDB,\nit's not as mature for monitoring, diagnostics, and issue resolution.</p><p>All told, maintaining a large number of materialized views is a complex task,\nwith lots of hand-crafted code and tooling needed.</p><p>Basic steps to create continuous aggregation in InfluxDB resemble those for\nClickHouse:</p><ol><li>Create the destination table ( in InfluxDB terminology)</li><li>Create a scheduled task that runs continuous aggregation</li><li>Manually backfill the existing data</li></ol><p>Unlike ClickHouse, and more similar to TimescaleDB, this task runs on a fixed\ntime-interval schedule and isn't triggered by inserts. It only looks at the\nrecent data, and you can configure exactly how recent. It doesn't automatically\nbackfill, so it requires a manual backfill step.</p><p>This mechanism creates a conflict between low latency and low system load,\nbecause you have to set a short interval to get low latency. But on the\nflip-side, the task will rescan the whole specified range every time. Unlike\nTimescaleDB, there's no hybrid mechanism that fills the gaps by running a query\non the base table.</p><p>InfluxDB supports tiered storage in its Enterprise and Cloud editions. You can\nset up a data retention policy that copies the data to cold storage, where it\nremains available for querying.</p><p>Since InfluxDB is purpose-made for monitoring and alerting, the support in this\narea is solid. To this end, the company developed a whole ecosystem of tools:\nTelegraf, Chronograf, and Kapacitor.</p><p>InfluxDB's main drawback is widely considered to be its lack of full SQL\nsupport. Given that it requires its own DSL, it gives the impression of a\nspecial purpose tool. While it supports the use case of continuous aggregation\nitself, there's less support for more general and powerful data analytics on the\nsame dataset.</p><p>So, InfluxDB alone usually isn't enough for all the things you need to do with\nthe data.</p><p>With QuestDB, there's only one step to set up continuous aggregation:</p><ol><li><code>CREATE MATERIALIZED VIEW ...</code></li></ol><p>This creates the materialized view table, backfills it with the results of\nprocessing the existing data, and sets up the aggregation task to run on all\nchanges to the base table, including updates and deletions. The task is fired\nimmediately when changes occur, but it may be delayed when system load is high.</p><p>This simplicity is a key part of QuestDB's vision for a single-source real-time\nanalytics system. By handling both historical and fresh data through the same\nmaterialized view mechanism, we eliminate the need for separate systems and\ncomplex integration work. Whether you're querying data from last year or the\nlast second, you use the same SQL interface and get consistent results.</p><p>Another nice aspect of QuestDB's materialized views is that you can cascade them\n‚Äî a materialized view's base table can be another materialized view. This allows\nyou to create a very efficient pipeline of aggregations at different levels of\ngranularity.</p><p>QuestDB keeps maintainability in focus and exposes the status of materialized\nviews through the SQL interface:</p><div><div><div><pre></pre></div></div></div><p>With this, you can monitor refresh lag, and detect and diagnose failures.</p><p>While the computations you can use with materialized views are limited to\naggregate functions over time slices, QuestDB's general querying power is quite\nrobust. It supports JOINs, window functions, Common Table Expressions, nested\nSELECT expressions, and so on.</p><p>However, in the current version (8.3.1), QuestDB's materialized views aren't\nvery resilient to schema evolution. The materialized view will get invalidated\nif you DROP or ALTER a column, even when the materialized view doesn't depend on\nit.</p><p>QuestDB supports tiered storage in its Enterprise edition. It can keep your data\nin cold storage, in Parquet format, and query it without converting back to its\nnative format.</p><p>Overall, this is a significant step forward for this use case, and its\nnear-future roadmap contains some improvements:</p><ul><li><p>Better resilience of materialized views to schema evolution. You'll be able to\nmanipulate non-dependency columns without breaking the materialized view.</p></li><li><p>Support for a refresh policy based on a fixed time interval. If you align it\nwith the time slice interval, this will ensure the materialized view is always\nfresh, with significantly less impact on system load.</p></li></ul><p>The journey from complex, multi-system architectures to unified solutions is\nwell underway. Each database we examined brings valuable pieces to the puzzle:\nTimescaleDB's hybrid query approach, ClickHouse's raw performance, InfluxDB's\nmonitoring expertise, and QuestDB's simplified materialized views.</p><p>The database systems we reviewed all seem to have many building blocks needed,\nbut none of them seems to be fully ready to take over the all-in-one real-time\nanalytics system.</p><p>The ideal system would combine the best of these approaches: effortless setup\nand maintenance, consistent performance across all data ages, and a single\ninterface for both real-time and historical analytics. While we're not quite\nthere yet, the convergence of these technologies suggests that the one-stop-shop\nsolution for real-time analytics is within reach.</p><p>As these systems continue to evolve and borrow from each other's strengths, we\ncan expect to see more solutions that truly unify the real-time analytics\nexperience. The future belongs to systems that can handle the full spectrum of\nanalytics needs without requiring complex integration work or specialized\nknowledge of multiple technologies.</p>","contentLength":16035,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lf6a3k/realtime_analytics_with_an_allinone_system_are_we/"},{"title":"LiveKit Agent - workers auto dispatch issue in deployment","url":"https://www.reddit.com/r/kubernetes/comments/1lf68jn/livekit_agent_workers_auto_dispatch_issue_in/","date":1750324231,"author":"/u/InbaKrish007","guid":162911,"unread":true,"content":"<p>I have issue on the LiveKit agents deployment.</p><p>we are using Kubernetes setup with 4 pods (replica) each with below resources config, <code>yaml resources: requests: cpu: \"4\" memory: \"8Gi\" limits: cpu: \"4\" memory: \"8Gi\" </code></p><p>so that it should accept 25 to 30 concurrent sessions per pod and multiplied by 4 on total.</p><p>For Server we are using the LiveKit's cloud offering with free trail (mentions that 100 concurrent connections are provided).</p><p>Though we have this setup, on connecting 2 concurrent sessions, 3rd and upcoming sessions are not getting handled, the client side (built with client-sdk-js), creates a room with the LiveKit JWT token (generated from Ruby server), but the agent is not getting dispatched and joins the room.</p><p>-&gt; We have not modified any workeroptions in the LiveKit agents backend. -&gt; With Ruby server, we generate the the token with the logic below, ```ruby room = LivekitServer::Room.new(params[\"room_name\"]) participant = LivekitServer::Participant.new(**participant_params) token = room.create_access_token(participant:, time_to_live:) render json: { access_token: token.to_jwt }</p><p>def create_access_token(participant:, time_to_live: DEFAULT_TOKEN_TTL, video_grant: default_video_grant) token = LiveKit::AccessToken.new(ttl: time_to_live) token.identity = participant.identity token.name = participant.name token.video_grant = video_grant token.attributes = participant.attributes token end</p><p>def default_video_grant LiveKit::VideoGrant.new(roomJoin: true, room: name, canPublish: true, canPublishData: true, canSubscribe: true) end json { \"name\": \"user\", \"attributes\": { \"modality\": \"TEXT\" }, \"video\": { \"roomJoin\": true, \"room\": \"lr5x2n8epp\", \"canPublish\": true, \"canSubscribe\": true, \"canPublishData\": true }, \"exp\": 1750233704, \"nbf\": 1750230099, \"iss\": \"APIpcgNpfMyH9Eb\", \"sub\": \"anonymous\" } ```</p><p>What am I missing here? Based on the documentation and other parts, I guess there are no issue with the deployment and have followed the exact steps mentioned for the k8s setup. But as mentioned the agents are not getting dispatched automatically, and ends in client UI infinite loading (we haven't set any timeout yet).</p>","contentLength":2128,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Notification daemon for modern Wayland compositors","url":"https://www.reddit.com/r/linux/comments/1lf5bm5/notification_daemon_for_modern_wayland_compositors/","date":1750320539,"author":"/u/cyberlame","guid":162985,"unread":true,"content":"<p>Last year, a friend and I started a project ‚Äî a notification daemon designed specifically for modern Wayland compositors, built entirely in Rust. After about a year of work, we created something truly usable and with features we‚Äôre proud of. I‚Äôve been running it as my daily notification daemon since early on, so it‚Äôs not just a prototype ‚Äî it‚Äôs solid and practical.</p><p>But after pushing hard for so long, we hit a serious burnout a couple months ago. Since then, the project‚Äôs been quiet ‚Äî no new updates, no big release. We wanted to finish all the core features and release a 0.1 version with a big announcement, but that never happened.</p><p>I‚Äôm sharing this now because, even if I can‚Äôt keep working on it, I want the community to know it exists. Maybe someone out there will find it useful, or maybe it‚Äôll inspire others to do something similar or even pick it up.</p><p>Thanks for reading ‚Äî it‚Äôs tough to share something so personal and unfinished, but I hope it‚Äôs not the end for this project.</p>","contentLength":1013,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Wayland protocol for \"Sensitive\" Areas? (passwords etc)","url":"https://www.reddit.com/r/linux/comments/1lf57yg/wayland_protocol_for_sensitive_areas_passwords_etc/","date":1750320130,"author":"/u/Misicks0349","guid":163166,"unread":true,"content":"<p>I'm curious if this is a thing, I came across <a href=\"https://www.reddit.com/r/notinteresting/comments/1lexq73/apple_devices_hide_passkeys_if_you_take_a/\">this post</a> showing how apple devices will just straight up not show areas of the screen that have information like your passwords if you take a screenshot or screen record. Some wayland compositors have the option to exclude entire windows from screen capture but I'm not sure if theres anything like this where a client could say \"hey, there's a plaintext password in this box, don't display it in screen captures please :)\".</p>","contentLength":471,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[R] Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought","url":"https://arxiv.org/pdf/2505.12514","date":1750316828,"author":"/u/jsonathan","guid":162984,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/MachineLearning/comments/1lf4dxu/r_reasoning_by_superposition_a_theoretical/"},{"title":"From Collaborators to Consumers: Have We Killed the Soul of Open Source?","url":"https://my-notes.dragas.net/2025/06/19/from-collaborators-to-consumers-have-we-killed-the-soul-of-open-source/","date":1750314742,"author":"/u/dragasit","guid":163088,"unread":true,"content":"<p>I discovered Open Source when I was just a teenager, <a href=\"https://it-notes.dragas.net/2024/10/03/i-solve-problems-eurobsdcon/\">back in 1996</a>. At the time, in my eyes, it was a revolution: the ability to see the code, contribute, fork it, and give a project a new direction - perhaps a parallel one, or something completely different.</p><p>Like OpenBSD from NetBSD, DragonflyBSD from FreeBSD, or Nextcloud from Owncloud - the examples are endless. It was about freedom, the chance to be part of something or, in some cases, at the very center of something: its development.</p><p>To me, Open Source meant having the chance to develop an idea and find other people who shared it, turning what was just a project in my mind into a reality. All without needing big funding, a business plan, or having to risk anything. Just the pleasure of doing it and the joy of seeing it come to life. A waking dream.</p><p>Over time, I witnessed many exchanges of opinion - some of them quite heated - that led to hard forks or uncomfortable situations within development teams. People leaving, others taking over - you name it. But, in the end, the software was always at the center. It was an ideological battle over how to implement something (or how NOT to implement it).</p><p>This led to some fantastic pairings: Linux, a kernel without an operating system, and GNU, an operating system without a stable and complete kernel. Together, they revolutionized the world, changed the concept of computing, and proved that yes, Open Source works and produces quality software - often of a far greater quality than many of its closed-source, commercial counterparts.</p><p>And yet, there were the \"distro wars\" - and I didn't understand them. And if I didn't understand the distro wars back then, the situation today seems even more extreme. I appreciated the variety, the different ideas, and the different approaches, but never the fanaticism. I was a strong supporter of Debian, but I couldn't understand those who openly attacked alternatives (like Red Hat, at the time, or Suse). I thought: use what you like, contribute if you want but... hey, it's Open Source, you don't pay for it, you're not forced, just choose what you like best! If you're happy, tell the world. If you're dissatisfied, switch (to different software) or change THE software (meaning, implement what you think is necessary). But why wage war on others, on those with different ideas who made different choices? Is it the general polarization fueled by social media? Is it because Open Source has become more mainstream, bringing with it users who have a \"consumer\" mindset rather than a \"collaborator\" one?</p><p>And yet, there are still positive examples out there ‚Äî quiet, solid, and often overlooked. The BSD projects, for instance, show us that it's still possible to diverge in philosophy and approach without descending into hostility. FreeBSD, OpenBSD, and NetBSD took different paths. And yet, there are no \"wars\" between them. Their communities may disagree on technical choices, but they coexist with mutual respect. You rarely see a FreeBSD user shouting \"OpenBSD must die!\" or a NetBSD developer trolling others on social media. The tone is sober, the work is steady, and the focus remains on the code and its quality - not on brand wars or personal egos.</p><p>This is the spirit I fell in love with: different ideas, mutual respect, and the shared goal of building something useful and free. We may not all agree on everything, but we can still build in parallel, learn from each other, and avoid turning diversity into division.</p><p>Lately, all of this is becoming truly extreme. I read, for example, sharp and violent opinions from Wayland users against X11 (Xorg, etc.) - \"it must die!\" But, I wonder, why this violence?</p><p>I use Wayland on Linux and X11 on FreeBSD - both on the same computer, both with satisfaction. Why should I hate one of them? If I don't like it... I simply don't use it.</p><p>The world is becoming increasingly polarized and bitter, making people less and less inclined towards dialogue or tolerance for those with different ideas or positions. But, I ask myself, why should this be happening in the world of Open Source?</p><p>We are all in the same boat. We have the tools, the freedom of choice, and it costs us nothing. If we don't like a solution, we can say so and choose something else. Why this violence?  Who benefits?</p><p>When we fight violently over Open Source software, when we lash out with intolerance against a solution we dislike, the entire Open Source world loses an opportunity. The opportunity to reduce the chances of ending up in a computing monoculture, the opportunity to have a choice, the opportunity for someone to listen to our well-reasoned observations and learn from them.</p><p>It's up to us, every day, with every comment and contribution, to decide whether we want to build bridges or raise walls.</p>","contentLength":4776,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1lf3u9y/from_collaborators_to_consumers_have_we_killed/"},{"title":"I was reading this bash guide on GitHub, and found this:","url":"https://www.reddit.com/r/linux/comments/1lf2drq/i_was_reading_this_bash_guide_on_github_and_found/","date":1750309290,"author":"/u/rev155","guid":162575,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Should I switch from Python to Go for Discord bots?","url":"https://www.reddit.com/r/golang/comments/1lf22ab/should_i_switch_from_python_to_go_for_discord_bots/","date":1750308164,"author":"/u/GladJellyfish9752","guid":162717,"unread":true,"content":"<p>So I know Python and Rust pretty well, can handle JavaScript okay, and I've messed around with Go a little bit. Made a bunch of stuff in Python and Rust but lately I'm wondering if Go would be better for some things I want to build. Thinking I'll try Discord bots first since I already made a few in Python.</p><p>Here's what I'm curious about - is the Discord library support in Go actually good? I found discordgo but not sure how it stacks up against discord.py or discord.js. Like does it have all the features you need or are you missing stuff? And is the community around it active enough that you can get help when things break?</p><p>Also wondering about speed - would a Go bot actually handle more users at once or run commands faster than Python? My Python bots sometimes get slow when they've been running for days.</p><p>If Go works out well for Discord stuff I might try moving some of my other Python projects over too. Just want to see if it's worth learning more Go or if I should stick with what I already know. Anyone here made a similar switch or have thoughts on whether it's worth it?</p>","contentLength":1084,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Has Anyone launched Litmus Chaos Experiments via GitHub Actions ?","url":"https://www.reddit.com/r/kubernetes/comments/1lf1va3/has_anyone_launched_litmus_chaos_experiments_via/","date":1750307489,"author":"/u/Late_Organization_47","guid":162645,"unread":true,"content":"<div><p>Use case: We need to integrate Chaos Fault Injections via CI/CD as a part of POC.</p><p>Any leads and suggestions would be welcomed here üôÇ</p></div>   submitted by   <a href=\"https://www.reddit.com/user/Late_Organization_47\"> /u/Late_Organization_47 </a>","contentLength":177,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Workflow Engine","url":"https://www.reddit.com/r/golang/comments/1lf1v27/workflow_engine/","date":1750307468,"author":"/u/Used-Army2008","guid":162950,"unread":true,"content":"<p>What would be the easiest wf engine I can use to distribute tasks to workers and when they are done complete the WF? For Java there are plenty I found just a couple or too simple or too complicated for golang, what's everyone using in production?</p><p>My use case is compress a bunch of folders (with millions of files) and upload them to S3. Need to do it multiple times a day with different configuration. So I would love to just pass the config to a generic worker that does the job rather than having specialized workers for different tasks.</p>","contentLength":539,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How DynamoDB, key-value schemaless cloud-native data store scales: Architecture and Design Lessons","url":"https://javarevisited.substack.com/p/software-architecture-deep-dive-scaling","date":1750305514,"author":"/u/javinpaul","guid":162607,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lf1ae5/how_dynamodb_keyvalue_schemaless_cloudnative_data/"},{"title":"Rewriting Kafka in Rust Async: Insights and Lessons Learned in Rust","url":"https://www.reddit.com/r/rust/comments/1lf0bof/rewriting_kafka_in_rust_async_insights_and/","date":1750302393,"author":"/u/jonefeewang","guid":162809,"unread":true,"content":"<div><p>Hello everyone, I have taken some time to compile the insights and lessons I gathered during the process of rewriting Kafka in Rust(<a href=\"https://github.com/jonefeewang/stonemq\">https://github.com/jonefeewang/stonemq</a>). I hope you find them valuable.</p><p>Below is a concise TL;DR summary.</p><ol><li>Rewriting Kafka in Rust not only leverages Rust‚Äôs language advantages but also allows redesigning for superior performance and efficiency.</li><li>Design Experience: Avoid Turning Functions into async Whenever Possible</li><li>Design Experience: Minimize the Number of Tokio Tasks</li><li>Design Experience: Judicious Use of Unsafe Code for Performance-Critical Paths</li><li>Design Experience: Separating Mutable and Immutable Data to Optimize Lock Granularity</li><li>Design Experience: Separate Asynchronous and Synchronous Data Operations to Optimize Lock Usage</li><li>Design Experience: Employ Static Dispatch in Performance-Critical Paths Whenever Possible</li></ol></div>   submitted by   <a href=\"https://www.reddit.com/user/jonefeewang\"> /u/jonefeewang </a>","contentLength":881,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Giving this old Vaio mate and upgrades","url":"https://www.reddit.com/r/linux/comments/1lezj81/giving_this_old_vaio_mate_and_upgrades/","date":1750299960,"author":"/u/abraxas8484","guid":161760,"unread":true,"content":"<div><p>Gotta say, it's a fun project to fix up this thrift store Vaio with some much needed upgrades. Mate seems to work well with it :) and suggestions are welcomed </p></div>   submitted by   <a href=\"https://www.reddit.com/user/abraxas8484\"> /u/abraxas8484 </a>","contentLength":193,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Debugger is Here - Zed Blog","url":"https://zed.dev/blog/debugger","date":1750297770,"author":"/u/bschwind","guid":162550,"unread":true,"content":"<p>Over 2,000 developers asked, and we delivered.</p><p>Debugging in Zed is now a reality‚Äîand it's a big leap toward Zed 1.0.</p><p>We set out to build a debugger with three primary focuses:</p><ul><li>Fast: Spend less time context switching and more time debugging</li><li>Familiar: In line with Zed's design language and supports everything expected from a typical debugger flow</li><li>Configurable: You're able to customize the UI, keybindings, debug configurations and more</li></ul><p>Out of the box, Zed supports debugging popular languages including Rust, C/C++, JavaScript, Go, and Python.\nWith our extension system, Zed can support any debug adapter that implements the <a href=\"https://microsoft.github.io/debug-adapter-protocol/\">Debug Adapter Protocol (DAP)</a>.</p><p>To simplify the setup process, we've introduced locators, a system that translates build configurations into debug configurations. Meaning that you can write a build task once in  and reference it from  ‚Äî or, even better, rely on Zed's automatic configuration.</p><p>Zed automatically runs locators on built-in or language server-generated runnables, so in many cases you won't even need to write a debug configuration to get up and running.</p><p>We currently support locators for Cargo, Python, JavaScript, and Go, with more coming in the future.\nFor more information on configuring a debug session, <a href=\"https://zed.dev/docs/debugger\">see our documentation</a>.</p><p>Once in a debug session, Zed makes it easy to inspect your program's state, such as threads, variables, breakpoints, the call stack, and more.</p><div><figure><figcaption>Setting some breakpoints and running the test in a debug session.</figcaption></figure></div><p>The debugger panel is fully customizable too, just drag and rearrange tabs in whatever order you want; you can even move the debug panel around so it fits your workflow.</p><p>Zed also supports keyboard-driven debugging for users that prefer to keep their hands on the keyboard.\nYou can step through code, toggle breakpoints, and navigate a debug session without ever touching the mouse.</p><div><figure><figcaption>Navigating through the Debugger surfaces using only the keyboard.</figcaption></figure></div><p>Special thanks to <a href=\"https://github.com/RemcoSmitsDev\">Remco Smits</a> for driving a lot of the heavy lifting on this project‚Äîyour contributions have been critical to getting us here.</p><p>Zed's debugger supports debugging a variety of languages through the Debug Adapter Protocol.\nBut simply implementing the protocol wasn't enough‚Äîwe needed an architecture that could scale to collaborative debugging, support extensions, and efficiently cache and manage responses from debug adapters.</p><p>To achieve this, we built a two-layer architecture: a data layer that communicates directly with the debug adapters, and a UI layer that fetches data from the data layer to render the interface.</p><figure data-rehype-pretty-code-figure=\"\"><div><pre><code data-language=\"rust\" data-theme=\"dark-plus light-plus\"></code></pre></div></figure><figure data-rehype-pretty-code-figure=\"\"><div><pre><code data-language=\"rust\" data-theme=\"dark-plus light-plus\"></code></pre></div></figure><p>This separation means the UI layer only requests what it needs, allowing the data layer to lazily fetch information and avoid unnecessary requests.\nIt also makes the data layer solely responsible for maintaining session state, caching responses, and invalidating stale data.\nThis architecture will make implementing collaborative debugging significantly easier, since the same UI code can be reused across multiplayer sessions‚Äîand we only send essential data across the wire, preserving bandwidth.</p><p>Supporting every debug adapter out of the box wasn't feasible‚Äîthere are over <a href=\"https://microsoft.github.io/debug-adapter-protocol/implementors/adapters/\">70 DAP implementations</a>, each with its own quirks.\nTo solve this, we <a href=\"https://zed.dev/docs/extensions/debugger-extensions\">extended</a> Zed's extension API to support debugger integration.</p><figure data-rehype-pretty-code-figure=\"\"><div><pre><code data-language=\"rust\" data-theme=\"dark-plus light-plus\"></code></pre></div></figure><p>Adding DAP support via an extension involves defining a custom schema that integrates with our JSON server, implementing logic for downloading and launching the adapter, processing debug configuration to add sane default values, and integrating with locators for automatic configuration.\nThis design follows our approach to LSP extensions, giving extension authors full control to bring their own debug adapters to Zed with minimal friction.</p><p>We also wanted inline variable values to work out of the box.\nSurprisingly, the <a href=\"https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#textDocument_inlineValue\">inline values request</a> is a part of the <a href=\"https://microsoft.github.io/language-server-protocol/\">Language Server Protocol (LSP)</a> instead of the DAP.\nUsing the inline values approach would limit Zed to only showing inline values for DAPs which integrate with LSPs, which isn't many.\nA naive workaround might be to use regular expressions to match variable names between the source code and debugger values, but that quickly breaks down when dealing with scopes, and comments.\nInstead, we turned to <a href=\"https://tree-sitter.github.io/tree-sitter/\">Tree-sitter</a>. After all Zed is built by the creators of Tree-sitter!</p><p>Through Tree-sitter queries, we can accurately identify variables within the current execution scope, and easily support any language through  files without relying on an LSP server to be tightly integrated with a debug adapter.\nAt launch, inline values are supported for Python, Rust, and Go.\nMore languages will be supported in the coming weeks.</p><p>When we set out to build the debugger, we wanted to make it seamless to use, out of the way, and in line with Zed's high standard of quality.\nNow that we've built a strong foundation that is compatible with any debug adapter, we're ready to explore and implement advanced features such as:</p><ul><li>New views: While we support all the fundamental views, we're planning on adding more advanced views such as a watch list, memory view, disassembly view, and a stack trace view</li><li>Automatic configuration: We're going to add support for more languages and build systems</li></ul>","contentLength":5185,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1leystq/the_debugger_is_here_zed_blog/"},{"title":"Implementing a convolutional neural network from scratch with no libraries","url":"https://deadbeef.io/cnn_from_scratch","date":1750294884,"author":"/u/LlaroLlethri","guid":162682,"unread":true,"content":"<p>An unknown error occurred.</p>","contentLength":26,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1lexu30/implementing_a_convolutional_neural_network_from/"},{"title":"[D] What tasks don‚Äôt you trust zero-shot LLMs to handle reliably?","url":"https://www.reddit.com/r/MachineLearning/comments/1lewzg7/d_what_tasks_dont_you_trust_zeroshot_llms_to/","date":1750292387,"author":"/u/WristbandYang","guid":161759,"unread":true,"content":"<p>For some context I‚Äôve been working on a number of NLP projects lately (classifying textual conversation data). Many of our use cases are classification tasks that align with our niche objectives. I‚Äôve found in this setting that structured output from LLMs can often outperform traditional methods.</p><p>That said, my boss is now asking for likelihoods instead of just classifications. I haven‚Äôt implemented this yet, but my gut says this could be pushing LLMs into the ‚Äúlying machine‚Äù zone. I mean, how exactly would an LLM independently rank documents and do so accurately and consistently? </p><ul><li>What kinds of tasks have you found to be unreliable or risky for zero-shot LLM use?</li><li>And on the flip side, what types of tasks have worked surprisingly well for you? </li></ul>","contentLength":760,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Osprey Programming Language","url":"https://www.ospreylang.dev/","date":1750283030,"author":"/u/emanresu_2017","guid":162606,"unread":true,"content":"<p>Strong static typing prevents runtime errors while keeping syntax clean and readable. Expression-bodied\n          functions eliminate boilerplate.</p><ul><li>Explicit type annotations</li><li>Compile-time error checking</li><li>Expression-bodied functions</li></ul>","contentLength":225,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1letj43/osprey_programming_language/"},{"title":"Making Cobra CLIs even more fabulous","url":"https://www.reddit.com/r/golang/comments/1lethu1/making_cobra_clis_even_more_fabulous/","date":1750282937,"author":"/u/bashbunni","guid":161566,"unread":true,"content":"<p>I'm bashbunni a software developer at Charm, the creators of Bubble Tea, Glow, Gum, and all that terminal stuff. We use spf13's Cobra to power a ton of our CLIs, so we wanted to give it a little love through a new project called . </p><p>Fang is a layer on top of cobra to give you things like: - Fancy output: fully styled help and usage pages<p> - Fancy errors: fully styled errors</p> - Automatic : set it to the build info, or a version of your choice - Manpages: Adds a hidden  command to generate manpages using mango - Completions: Adds a  command to generate shell completions - Themeable: use the built-in theme, or make your own<p> - Improved UX: Silent usage output (help is not shown after a user error)</p></p>","contentLength":698,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Latest X.Org Server Activity Are A Lot Of Code Reverts","url":"https://www.phoronix.com/news/X.Org-Server-Lots-Of-Reverts","date":1750282125,"author":"/u/6e1a08c8047143c6869","guid":161613,"unread":true,"content":"\nThe X.Org Server has been seeing a lot of commits this week... to revert bad code.\n<p>Many Phoronix readers have been asking why I haven't been covering news of the \"X11Libre\" fork of the X.Org Server or if I somehow missed it... No, simply a vote of no confidence. It's highly unlikely to succeed long-term given the very limited experienced developers / resources and none of the major Linux stakeholders (companies) backing it. \n</p><p>A great example now are all of the reverts hitting the X.Org Server Git code after longtime X.Org developers began going through the code committed by the \"X11Libre\" developer prior to his ejection from the FreeDesktop.org camp.\n</p>There was <a href=\"https://gitlab.freedesktop.org/xorg/xserver/-/merge_requests/2019\">this revert</a> for not handling copyright and license notices correctly. Some existing code macros were moved to a new file while dropping the existing copyright holders from being mentioned in the new file and only adding the new contributor to that header file. The code license was also changed from MIT AND X11 to MIT OR X11.\n<p>Also merged this week was </p><a href=\"https://gitlab.freedesktop.org/xorg/xserver/-/merge_requests/2012\">this big revert</a> of prior \"RandR cleanups\" that ended up breaking at least some RandR functionality.\n<a href=\"https://gitlab.freedesktop.org/xorg/xserver/-/commit/538a6dd76feab02ab618d1c38e693a64b371cd66\">revert</a> to avoid unnecessarily breaking the NVIDIA driver. It was also <a href=\"https://gitlab.freedesktop.org/xorg/xserver/-/merge_requests/2017#note_2956688\">commented</a> by NVIDIA that some additional requests for other reverts are coming too.\n<p>There were also other reverts for code of </p><a href=\"https://gitlab.freedesktop.org/xorg/xserver/-/merge_requests/2015\">questionable value</a>. And <a href=\"https://gitlab.freedesktop.org/xorg/xserver/-/merge_requests/2014\">other reverts</a> making changes without knowing the prior knowledge for why some macros were added in the first place by X.Org developers.\n<a href=\"https://gitlab.freedesktop.org/xorg/xserver/-/merge_requests/?sort=created_date&amp;state=merged&amp;first_page_size=20\">the list goes on</a> with more reverts expected soon.","contentLength":1527,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1let6dd/the_latest_xorg_server_activity_are_a_lot_of_code/"},{"title":"[D] 500+ Case Studies of Machine Learning and LLM System Design","url":"https://www.reddit.com/r/MachineLearning/comments/1let433/d_500_case_studies_of_machine_learning_and_llm/","date":1750281966,"author":"/u/OhDeeDeeOh","guid":161563,"unread":true,"content":"<p>We've compiled a curated collections of real-world case studies from over 100 companies, showcasing practical machine learning applications‚Äîincluding those using large language models (LLMs) and generative AI. Explore insights, use cases, and lessons learned from building and deploying ML and LLM systems. Discover how top companies like Netflix, Airbnb, and Doordash leverage AI to enhance their products and operations</p>","contentLength":423,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is it worth switching to Golang from C#/.NET?","url":"https://www.reddit.com/r/golang/comments/1les1ce/is_it_worth_switching_to_golang_from_cnet/","date":1750279365,"author":"/u/Content_Opposite6466","guid":161612,"unread":true,"content":"<p>I work with .NET has been around for 7 years. But I want to try something new. I am considering Golang. There is also talk in the current company about replacing C# monoliths with Go microservices. What do you recommend on this issue? Is it worth it, both in work and in personal choice?</p>","contentLength":287,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I built an app to turn Discord messages into clean showcases","url":"https://www.reddit.com/r/rust/comments/1leqs1m/i_built_an_app_to_turn_discord_messages_into/","date":1750276305,"author":"/u/Megalith01","guid":161700,"unread":true,"content":"<p>So the app I made to solve a weirdly specific but kinda annoying problem I kept running into: making Discord messages and media look presentable.</p><p>You know how sometimes you want to show off a funny convo, a support message, or something cool that happened on your server, but screenshots always look messy, or you end up cropping stuff in Paint? Yeah, I got tired of that. So I made a tool.</p><p>the desktop app that lets you import messages, images, and media from Discord (via a discord bot you create), arrange them nicely, style them to your liking, and export them as clean showcase pieces. It‚Äôs simple, fast, and designed to make Discord content look professional with minimal effort.</p><p>It‚Äôs made using  (so it‚Äôs lightweight and fast) with a <strong>React (Vite + Tailwind + Framer Motion) + TypeScript</strong> frontend. Works across platforms (Linux, macOS, Windows).</p><p>I originally built this app for a streamer who wanted a better way to present Discord messages on stream and in highlight videos. Screenshots were always messy, cropping took too long. I liked the idea so i decided to release the app as open source.</p><p>It‚Äôs still a work in progress, but it‚Äôs very much usable, so feedback and ideas are welcome.</p>","contentLength":1199,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"http: TLS handshake error from 127.0.0.1 EOF","url":"https://www.reddit.com/r/kubernetes/comments/1leq0eb/http_tls_handshake_error_from_127001_eof/","date":1750274457,"author":"/u/Double_Intention_641","guid":161637,"unread":true,"content":"<p>I'm scratching my head on this, and hoping someone has seen this before.</p><p><code> Jun 18 12:15:30 node3 kubelet[2512]: I0618 12:15:30.923295 2512 ???:1] \"http: TLS handshake error from 127.0.0.1:56326: EOF\" Jun 18 12:15:32 node3 kubelet[2512]: I0618 12:15:32.860784 2512 ???:1] \"http: TLS handshake error from 127.0.0.1:58884: EOF\" Jun 18 12:15:40 node3 kubelet[2512]: I0618 12:15:40.922857 2512 ???:1] \"http: TLS handshake error from 127.0.0.1:58892: EOF\" Jun 18 12:15:42 node3 kubelet[2512]: I0618 12:15:42.860990 2512 ???:1] \"http: TLS handshake error from 127.0.0.1:56242: EOF\" </code></p><p>So twice every ten seconds, but only on 2 out of 3 worker nodes, and 0 of 3 control nodes. 'node1' is identically configured, and does not have this happen. All nodes were provisioned within a few hours of each other about a year ago.</p><p>I've tried what I felt was obvious. Metrics server? Node exporter? Victoria metrics agent? Scaled them down, but the log errors continue.</p><p>This is using K8S 1.33.1, and while it doesn't appear to be causing any issues, I'm irritated that I can't narrow it down. I'm open to suggestions, and hopefully it's something stupid I didn't manage to hit the right keywords for.</p>","contentLength":1174,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What helped me understand interface polymorphism better","url":"https://www.reddit.com/r/golang/comments/1lepxs8/what_helped_me_understand_interface_polymorphism/","date":1750274287,"author":"/u/Yierox","guid":161639,"unread":true,"content":"<p>Hi all. I have recently been learning Go after coming from learning some C before that, and mainly using Python, bash etc. for work. I make this post in the hope that someone also learning Go who might encounter this conceptual barrier I had might benefit.</p><p>I was struggling with wrapping my head around the concept of interfaces. I understood that any struct can implement an interface as long as it has all the methods that the interface has, then you can pass that interface to a function.</p><p>What I didn't know was that if a function is expecting an interface, that basically means that it is expecting a type that implements an interface. Since an interface is just a signature of a number of different methods, you can also pass in a different interface to that function as long as it still implements all those methods expected in the function argument. </p><p>Found that out the hard way while trying to figure out how on earth an interface of type  could still be accepted as an argument to the  method. Here is some code I wrote to explain (to myself in the future) what I learned.</p><p>For those more experienced, please correct or add to anything that I've said here as again I'm quite new to Go.</p><pre><code>package main import ( \"fmt\" ) type One interface { PrintMe() } type Two interface { // Notice this interface has an extra method PrintMe() PrintMeAgain() } func IExpectOne(i One) { // Notice this function expects an interface of type 'One' // However, we can also pass in interface of type 'Two' because // implicitly, it contains all the methods of interface type 'One' i.PrintMe() } func IExpectTwo(ii Two) { // THis function will work on any interface, not even explicitly one of type 'Two' // so long as it implements all of the 'Two' methods (PrintMe(), PrintMeAgain()) ii.PrintMe() ii.PrintMeAgain() } type OneStruct struct { t string } type TwoStruct struct { t string } func (s OneStruct) PrintMe() { fmt.Println(s.t) } func (s TwoStruct) PrintMe() { fmt.Println(s.t) } func (s TwoStruct) PrintMeAgain() { fmt.Println(s.t) } func main() { fmt.Println() fmt.Println(\"----Interfaces 2----\") one := OneStruct{\"Hello\"} two := TwoStruct{\"goodbye\"} oneI := One(one) twoI := Two(two) IExpectOne(oneI) IExpectOne(twoI) // Still works! IExpectTwo(twoI) // Below will cause compile error, because oneI ('One' interface) does not implement all the methods of twoI ('Two' interface) // IExpectTwo(oneI) } </code></pre>","contentLength":2390,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"More efficient way of calling Windows DLL functions","url":"https://www.reddit.com/r/golang/comments/1lep3zm/more_efficient_way_of_calling_windows_dll/","date":1750272363,"author":"/u/kjk","guid":161565,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/kjk\"> /u/kjk </a>","contentLength":26,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[R] Is anyone else finding it harder to get clean, human-written data for training models?","url":"https://www.reddit.com/r/MachineLearning/comments/1leoita/r_is_anyone_else_finding_it_harder_to_get_clean/","date":1750270971,"author":"/u/irfanpeekay","guid":161532,"unread":true,"content":"<p>I‚Äôve been thinking about this lately with so much AI-generated content on the internet now, is anyone else running into challenges finding good, original human written data for training?</p><p>Feels like the signal to noise ratio is dropping fast. I‚Äôm wondering if there‚Äôs growing demand for verified, high-quality human data.</p><p>Would love to hear if anyone here is seeing this in their own work. Just trying to get a better sense of how big this problem really is and if it‚Äôs something worth building around.</p>","contentLength":507,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["reddit"]}