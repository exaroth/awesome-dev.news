{"id":"i2nisf4o","title":"Reddit","displayTitle":"Reddit","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":108,"items":[{"title":"Finding UI libraries is easy, but discovering components visually is still a challenge. A curated list + an idea to fix this.","url":"https://github.com/sanjay10985/animated-react-collection","date":1740302565,"author":"/u/Mobile_Candidate_926","guid":9592,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iw6bzk/finding_ui_libraries_is_easy_but_discovering/"},{"title":"[P] See the idea development of academic papers visually","url":"https://www.reddit.com/r/MachineLearning/comments/1iw5lgj/p_see_the_idea_development_of_academic_papers/","date":1740299410,"author":"/u/MadEyeXZ","guid":9593,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[R] Relevance-Guided Parameter Optimization for Efficient Control in Diffusion Transformers","url":"https://www.reddit.com/r/MachineLearning/comments/1iw46oq/r_relevanceguided_parameter_optimization_for/","date":1740293456,"author":"/u/Successful-Western27","guid":9487,"unread":true,"content":"<p>The key technical contribution here is a relevance-guided architecture that makes diffusion transformers more computationally efficient by selectively allocating processing power based on region importance. It combines DiT (Diffusion Transformers) with ControlNet approaches while introducing a relevance prior mechanism.</p><p>Main technical points: - Introduces a two-stage relevance assessment system: lightweight networks evaluate region importance, followed by adaptive computation allocation - Integrates with existing diffusion pipelines through modular design - Relevance prior guides transformer attention mechanisms - Compatible with standard diffusion transformer architectures</p><p>Key results: - 30-50% reduction in computational overhead - Maintains or improves image quality compared to baselines - More precise control over generated content - Effective handling of complex scenes</p><p>I think this could have meaningful impact on making high-quality image generation more accessible, especially for resource-constrained applications. The approach seems particularly promising for deployment scenarios where computational efficiency is crucial.</p><p>I think the relevance-guided approach could extend beyond image generation - the core idea of selective computation based on importance could benefit other transformer applications where attention mechanisms are computationally expensive.</p><p>TLDR: Novel architecture that makes diffusion transformers more efficient by focusing computational resources on important image regions, reducing compute needs by 30-50% while maintaining quality.</p>","contentLength":1576,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A simple VSCode extension to remember which virtual desktop each editor window is on in Linux","url":"https://marketplace.visualstudio.com/items?itemName=mathiscode.remember-desktops","date":1740290165,"author":"/u/FatherCarbon","guid":9468,"unread":true,"content":"<div><div><div><table role=\"presentation\"><tbody><tr><td><div><div><p>On some Linux desktop managers, Visual Studio Code editors don't remember their last desktop. This extension uses  to save the desktop of each open editor window, and restore them when the editor starts.</p><p>There are commands to save the editor locations, and to restore them, but by default the extension will start working automatically when it is installed.</p></div></div></td></tr></tbody></table></div></div></div>","contentLength":356,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iw3czs/a_simple_vscode_extension_to_remember_which/"},{"title":"Thoughts on listings like these selling flash drives with Ubuntu and other Linux distros pre-installed?","url":"https://www.reddit.com/r/linux/comments/1iw2zog/thoughts_on_listings_like_these_selling_flash/","date":1740288767,"author":"/u/FutureSuccess2796","guid":9486,"unread":true,"content":"<p>Admittedly someone who's relatively newer to the Linux space, so please bear with my question here. I was in middle of actually shopping for some extra brand new USBs to replace my old ones when I encountered this for the first time. It looked like there were quite a good number of people on marketplace platforms like eBay and Mercari selling bootable USB flash drives with a Linux distro pre-installed on it. Majority of the ones I saw were Ubuntu (like what I had pictured) on there, but I also saw a good amount of ones with Kali and different versions of Linux Mint as well. </p><p>Seems like you get the USB according to said listings with instructions on how to properly boot it or install it on your computer, and in some cases even provide contact information for support if needed. The prices on some of these are slightly in the higher side when compared to those I had screenshots of in the examples, and the sellers all had a large amount of sales and positive responses. </p><p>Now, of course, I'd personally just stick to what I've been doing and just create the bootable drive myself for literally free like I have from the start. So to me it was interesting to see these out there actually being bought when the process of doing this yourself is relatively easy with step-by-step guides on the respective distro's website and even YouTube tutorials if you wish to follow those. </p><p>So in short, what's everyone think of these?</p>","contentLength":1426,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Font for programming mathematics","url":"https://www.reddit.com/r/rust/comments/1iw2ovd/font_for_programming_mathematics/","date":1740287667,"author":"/u/okimusix","guid":9544,"unread":true,"content":"<p>So I am a physics undergrad and I've been using Rust for a few years now. It's my favorite language and I use it for everything, from personal apps using Tauri to taking advantage of its speed for computations and using it in my school assignments.</p><p>Since I often find myself writing math code, I found naming variables \"lambda_squared\", for example, looks really clunky and makes it harder to read the code. For this, I implemented a Live Templates group on RustRover that replaced lambda, for example, with its equivalent unicode character. However, Rust did complain a little.</p><p>Finally, though, I found the solution. I had been trying to do this for a while with no luck, but I found a way to make it work. I used the ligature system on the FiraCode font to implement ligatures for every greek letter and some mathematical symbols, this way you get the readability of actual math, but for the compiler, it still looks like plain text. Here's an example</p><p>The text for the sum variable, for example, is just \"SUMxu2\", and both the compiler and I are happier. I don't know if anyone has done this before, I tried to look for it but never found anything. </p><p>If you find this something that could be useful for you or others, I can share a link to a drive or something where you can download the font, as well as the guide to every symbol I included. If so, please comment and share your thoughts on this too :)</p>","contentLength":1400,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[D] API platforms vs self-deployment for diffusion models","url":"https://www.reddit.com/r/MachineLearning/comments/1iw2kbl/d_api_platforms_vs_selfdeployment_for_diffusion/","date":1740287219,"author":"/u/crookedstairs","guid":9469,"unread":true,"content":"<p>Caveat that Modal is a serverless compute platform! But this post covers when you might choose between API platforms (replicate, fal), traditional cloud (AWS EC2), managed ML platforms (SageMaker, Vertex), and serverless cloud.</p><p>I often see companies jump to self-deployment even if they're just using off-the-shelf models with a couple of adapters. I think that rarely makes sense from a cost or effort perspective unless you have a high volume of production traffic that you're amortizing those things across. The most compelling reason to move to self-deployment is if you need a high level of control over generated inputs =&gt; this requires fine-tuned weights / customer adapters / multi-step generation pipeline =&gt; this requires code-level control of your deployment.</p><p>What do you agree/disagree with? If you've evaluated these categories of providers before, tell me how they stacked up against each other.</p>","contentLength":907,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What's your recommendation on video editors?","url":"https://www.reddit.com/r/linux/comments/1iw2aae/whats_your_recommendation_on_video_editors/","date":1740286224,"author":"/u/chuzambs","guid":9506,"unread":true,"content":"<p>Hi there ! I'm looking for the best video editor for Linux, but as I know that's a completely subjective matter I ask for your favorite one. I come from adobe premiere and I'm looking for a Linux replacement, Im not a cinematographer so I'm not looking for something extremely professional.</p><p>I think Id go for da Vinci resolve since it's more standard, but would love to hear your recommendations</p><p>Edit: I'm running fedora bluefin (gnome) so I'd rather use flatpak </p>","contentLength":461,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"My \"AI Operating System\" Can Now Organize My Desktop!","url":"https://v.redd.it/crjpxmcknske1","date":1740275232,"author":"/u/mitousa","guid":9446,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1ivyyce/my_ai_operating_system_can_now_organize_my_desktop/"},{"title":"This feels illegal","url":"https://www.reddit.com/r/linux/comments/1ivyn4j/this_feels_illegal/","date":1740274254,"author":"/u/dk865409","guid":9424,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I built WikiTok in 4 hours - A TikTok style feed for Wikipedia","url":"https://www.reddit.com/r/artificial/comments/1ivy48f/i_built_wikitok_in_4_hours_a_tiktok_style_feed/","date":1740272626,"author":"/u/Illustrious-King8421","guid":9542,"unread":true,"content":"<p>So, I decided to use Replit's AI Agent to create my own version. Took me about 4 hours total, which isn't bad since I don't know any code at all.</p><p>To be honest, at first it seemed unreal - seeing the AI build stuff just from my instructions. But then reality hit me. With every feature I wanted to add, it became more of a headache. Here's what I mean: I wanted to move some buttons around, simple stuff. But when I asked the AI to realign these buttons, it messed up other parts of the design that were working fine before. Like, why would moving a button break the entire layout?</p><p>This really sucks because these errors took up most of my time. I'm pretty sure I could've finished everything in about 2 hours if it wasn't for all this fixing of things that shouldn't have broken in the first place.</p><p>I'm curious about other people's experiences. If you don't code, I'd love to hear about your attempts with AI agents for building apps and websites. What worked best for you? Which AI tool actually did what you needed?</p><p>What do you think? Would love to hear your stories and maybe get some tips for next time!</p>","contentLength":1103,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"After 15 years of using Windows, I decided to try Linux","url":"https://www.reddit.com/r/linux/comments/1ivxy81/after_15_years_of_using_windows_i_decided_to_try/","date":1740272133,"author":"/u/Catwz","guid":9408,"unread":true,"content":"<p>First of all, I apologize for writing such a long text.</p><p>I'm 22 years old. I know I'm young and still don't know much, but I'd like to write about this anyway. I think I started using computers during the Windows XP era. My father worked repairing computers. My mom says I learned to type on a computer before writing on paper. I was like one of today's kids who spend all day on their phones, except with computers. During my childhood, I spent my time chronically online, playing various games and browsing the internet. I remember Windows XP very well, along with Windows 7 and Minecraft. Those were good times, but as I grew older, things changed very quickly. My father stopped working with computer repairs, and soon I knew more than everyone else in the family.</p><p>I could fix all kinds of computers easily for my friends; back then, everything was Windows. My first contact with Linux was at school when we started having computer classes, when I was around 15. The school computers were slow and had Ubuntu installed. It was slow, ugly, and very limited because the computers were managed by the school. That was my first impression: a slow system for government computers.</p><p>Microsoft tried various things. I remember Windows 8 when formatting laptops, and then that Windows 8.1 update where they changed the menu. A lot happened, and it seems to have passed so quickly. At school, I always used Office suite programs: Word, PowerPoint, etc., and in computer classes, you had to use LibreOffice on a very slow government computer. it was ugly and seemed very difficult to use.</p><p>My family's financial situation didn't improve much, so I ended up with limited access to new technologies. My phone was already old, and my computers were getting old. I still remember Windows 10's launch very well. My relatives would bring computers for me to repair and format, wanting the latest version of Windows with Office and everything else, but the computers were already old and barely worked with Windows 8.</p><p>I begged my father to buy me a laptop, and after much insistence, I finally convinced him. It was an Asus X450LA. A mid-range computer for its time. It came with Windows 8, I think, but I did that upgrade to Windows 10. I used it until I finished high school, but then Windows 11 came along, and my laptop was cut from the list of computers that could upgrade. it was the end of my laptop's life.</p><p>I was already working at my father's market, so I bought myself a new gaming computer with Windows 11. I had time again to spend on the internet and started to worry about my father's business expenses. Using Office costs money, sales programs are expensive, everything is expensive, and maybe my gaming laptop won't even be able to use the next Windows.</p><p>I started researching Linux. At first, I was a bit scared because everyone on Reddit talked about terminals, command lines to install anything, etc., but I decided to take my old laptop and refurbish it. I bought a new battery, an SSD, and an 8GB RAM stick. I researched on Reddit which distro was best for beginners, got an old USB drive, put Mint on it, and formatted my computer: Love at first sight.</p><p>I customized Mint and left it in a way that I spend more than 15 minutes before doing anything just appreciating it. I used LibreOffice for everything I did in Office. I used Firefox and liked it a lot. The system is very fast, strangely seems faster than my new computer with Windows 11. I downloaded my daily-use programs from Mint's app center: Spotify, Bitwarden, everything's there. I spent hours playing with the terminal with ChatGPT's help. I extracted running process logs to txt, system information. it's very easy to use. I even managed to install a game I played in my childhood, a BF2 mod: Forgotten Hope 2 from Windows on Mint using Lutris (I swear it's the last Windows thing I'll use).</p><p>I'm in love with my old laptop again. I cleaned it, spent hours looking at it, I love using Mint, made it my own. I'm going to buy a new computer for my room and install Mint for my personal use. I'll have a laptop and a computer with Linux. My current computer with Windows 11 will be only for sales programs and government programs that only work on Windows. I showed it to my father, and he liked Linux too.<p> Windows never again. Using Windows now feels like one of those mobile games full of ads</p></p>","contentLength":4349,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advanced SQL Tricks (CTEs, Conditional Aggregations, etc)","url":"https://youtu.be/rDGCOE5YGT0","date":1740269892,"author":"/u/Special_Community179","guid":9543,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivx75e/advanced_sql_tricks_ctes_conditional_aggregations/"},{"title":"Found this on a piece of digital signage in a bathroom","url":"https://www.reddit.com/r/linux/comments/1ivwydq/found_this_on_a_piece_of_digital_signage_in_a/","date":1740269184,"author":"/u/A_Sc00py_b0i","guid":9393,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing wctx - A simple CLI tool for window context info on Wayland & X11","url":"https://www.reddit.com/r/linux/comments/1ivw7xn/introducing_wctx_a_simple_cli_tool_for_window/","date":1740267048,"author":"/u/slightlyfaulty","guid":9561,"unread":true,"content":"<p>Hey everyone, I just released my first package for Linux. It's called  (short for window context). It's a simple CLI tool that provides real-time information about the current  window (focused window) or  window (under the mouse cursor) on Wayland and X11. It's (mostly) written in Rust.</p><p>It's not very useful on its own, but it makes it much easier for programs and scripts to work with windows. For example, you could create hotkeys that only work in specific apps, or change your mouse scroll speed when the cursor is in a browser window, or turn your monitor brightness up when it has a fullscreen window.</p><p>You can of course already do these things, with a bit of effort. The main advantage of wctx is that it works across multiple desktop environments, which means programs and scripts using it will too. It's also dead simple to use, with several CLI output options and formats, as well as a D-Bus interface.</p><p>Currently it supports these desktop environments, with more to come if there's enough interest in them:</p><p>For other distros an installation script is included, with more info in the readme.</p><p>I'd love to hear everyone's thoughts. This is also my first real Rust project, so please be nice üòÑ (or rip me a new one so I can learn).</p><p>Feedback and contributions are very welcome!</p>","contentLength":1279,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"My first time with Linux","url":"https://www.reddit.com/r/linux/comments/1ivvcxn/my_first_time_with_linux/","date":1740264599,"author":"/u/Acu17y","guid":9392,"unread":true,"content":"<p>Oh my god guys, I'm speechless. Unfortunately I regret it, but it's the first time I've put my hands on a PC with a Linux kernel.<p> But this stuff is absurd! It has mind-blowing performance!</p></p><p>I installed it on my old laptop with an i3 5005u / 4gb of ram and a 500gb 5400rpm hdd and it's like it was reborn. I mean, it's basically the OS I've always dreamed of, I feel like the PC is really mine and everything is so fast and intuitive that I can't describe it.</p><p>I was so impressed by Linux Mint that I'm really thinking of installing it on the main machine and getting rid of Windows, if only it weren't for the huge library of video games I have.</p><p>It also has a community made up of wonderful people, true enthusiasts.</p><p>I write this post as an appreciation for this discovery and someone who can help me understand if it is possible to use mint for gaming, I read around that there are problems with anti-cheats and online games?</p>","contentLength":920,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DeepSeek Founders Are Worth $1 Billion or $150 Billion Depending Who You Ask","url":"https://www.bloomberg.com/news/articles/2025-02-10/deepseek-could-make-founder-liang-wenfeng-one-of-the-world-s-richest-people?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTczOTIzNzk1NywiZXhwIjoxNzM5ODQyNzU3LCJhcnRpY2xlSWQiOiJTUjhYTTdUMEcxS1cwMCIsImJjb25uZWN0SWQiOiI0MUVGMDc3MjI0RTM0MDhFOTNFMDdFQkY0RDc3QzI1QiJ9.kqtC_AK59CyhVfXIjYbRqB5ymi-WS52icc0pzlfX74E","date":1740256369,"author":"/u/cramdev","guid":9391,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1ivsbro/deepseek_founders_are_worth_1_billion_or_150/"},{"title":"Solving The Millionaires' Problem in Rust","url":"https://vaktibabat.github.io/posts/smpc_circuits/","date":1740255860,"author":"/u/vaktibabat","guid":9370,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1ivs4vp/solving_the_millionaires_problem_in_rust/"},{"title":"Official /r/rust \"Who's Hiring\" thread for job-seekers and job-offerers [Rust 1.85]","url":"https://www.reddit.com/r/rust/comments/1ivrkhs/official_rrust_whos_hiring_thread_for_jobseekers/","date":1740254374,"author":"/u/DroidLogician","guid":9425,"unread":true,"content":"<p>Welcome once again to the official <a href=\"https://www.reddit.com/r/rust\">r/rust</a> Who's Hiring thread!</p><p>Before we begin, job-seekers should also remember to peruse the <a href=\"https://www.reddit.com/r/rust/comments/1hynsw7/official_rrust_whos_hiring_thread_for_jobseekers/\">prior thread</a>.</p><p>This thread will be periodically stickied to the top of <a href=\"https://www.reddit.com/r/rust\">r/rust</a> for improved visibility. You can also find it again via the \"Latest Megathreads\" list, which is a dropdown at the top of the page on new Reddit, and a section in the sidebar under \"Useful Links\" on old Reddit.</p><p>The thread will be refreshed and posted anew when the next version of Rust releases in six weeks.</p><p>Please adhere to the following rules when posting:</p><ul><li><p>Don't create top-level comments; those are for employers.</p></li><li><p>Feel free to reply to top-level comments with on-topic questions.</p></li><li><p>Anyone seeking work should reply to my stickied top-level comment.</p></li><li><p>Meta-discussion should be reserved for the distinguished comment at the very bottom.</p></li></ul><ul><li><p><strong>The ordering of fields in the template has been revised to make postings easier to read. If you are reusing a previous posting, please update the ordering as shown below.</strong></p></li><li><p><strong>Remote positions: see bolded text for new requirement.</strong></p></li><li><p>To find individuals seeking work, see the replies to the stickied top-level comment; you will need to click the \"more comments\" link at the bottom of the top-level comment in order to make these replies visible.</p></li><li><p>To make a top-level comment you must be hiring directly; no third-party recruiters.</p></li><li><p>One top-level comment per employer. If you have multiple job openings, please consolidate their descriptions or mention them in replies to your own top-level comment.</p></li><li><p>Proofread your comment after posting it and edit it if necessary to correct mistakes.</p></li><li><p>To share the space fairly with other postings and keep the thread pleasant to browse, we ask that you try to limit your posting to either 50 lines or 500 words, whichever comes first.<strong>We reserve the right to remove egregiously long postings.</strong> However, this only applies to the content of this thread; you can link to a job page elsewhere with more detail if you like.</p></li><li><p>Please base your comment on the following template:</p></li></ul><p>COMPANY: <em>[Company name; optionally link to your company's website or careers page.]</em></p><p>TYPE: <em>[Full time, part time, internship, contract, etc.]</em></p><p>LOCATION: <em>[Where are your office or offices located? If your workplace language isn't English-speaking, please specify it.]</em></p><p>REMOTE: <em>[Do you offer the option of working remotely? <strong>Please state clearly if remote work is restricted to certain regions or time zones, or if availability within a certain time of day is expected or required.</strong>]</em></p><p>VISA: <em>[Does your company sponsor visas?]</em></p><p>DESCRIPTION: <em>[What does your company do, and what are you using Rust for? How much experience are you seeking and what seniority levels are you hiring for? The more details the better.]</em></p><p>ESTIMATED COMPENSATION: <em>[Be courteous to your potential future colleagues by attempting to provide at least a rough expectation of wages/salary. If you are listing several positions in the \"Description\" field above, then feel free to include this information inline above, and put \"See above\" in this field.<p> If compensation is negotiable, please attempt to provide at least a base estimate from which to begin negotiations. If compensation is highly variable, then feel free to provide a range.</p> If compensation is expected to be offset by other benefits, then please include that information here as well. If you don't have firm numbers but do have relative expectations of candidate expertise (e.g. entry-level, senior), then you may include that here.<p> If you truly have no information, then put \"Uncertain\" here.</p> Note that many jurisdictions (including several U.S. states) <strong>require salary ranges on job postings by law</strong>. If your company is based in one of these locations or you plan to hire employees who reside in any of these locations, you are likely subject to these laws.<p> Other jurisdictions may require salary information to be available upon request or be provided after the first interview.</p> To avoid issues, <strong>we recommend all postings provide salary information</strong>. You  state clearly in your posting if you are planning to compensate employees partially or fully in <strong>something other than fiat currency</strong> (e.g. cryptocurrency, stock options, equity, etc). Do  put just \"Uncertain\" in this case as the default assumption is that the compensation will be 100% fiat. Postings that fail to comply with this addendum . Thank you.]</em></p><p>CONTACT: <em>[How can someone get in touch with you?]</em></p>","contentLength":4390,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I‚Äôve made a bunch of free wallpapers","url":"https://www.reddit.com/r/linux/comments/1ivqqg0/ive_made_a_bunch_of_free_wallpapers/","date":1740252187,"author":"/u/Folium_Creations","guid":9300,"unread":true,"content":"<p>I‚Äôve made a whole bunch of wallpapers and released them under CC:BY </p><p>I have made a git where I have uploaded, and will continue to upload them in 4k resolution as .png files for your convenience. I can‚Äôt stand all those ‚Äúwe have free wallpapers, as long as you register with email,phone number and the blood of your first born.‚Äù Here is the link to the git. I‚Äôm slowly building up a curated library of wallpapers I‚Äôve created. </p>","contentLength":438,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What are the odds that Rust is going to have a real competitor?","url":"https://www.reddit.com/r/rust/comments/1ivqkj1/what_are_the_odds_that_rust_is_going_to_have_a/","date":1740251759,"author":"/u/nikitarevenco","guid":9369,"unread":true,"content":"<p>By \"Real Competitor\" I mean: A language just like Rust with similar goals, but one that people actually prefer to Rust. So it would be a fast, low-level memory safe language with great tooling, great type system and other benefits that Rust offers. But it would need to be better than Rust to actually catch on</p><p>This language needs to offer real advantages over Rust to be considered. Of course since Rust has a huge ecosystem that is growing rapidly, it may take a long time. But I am talking on a timescale of 25+ years.</p><p>Creating a new programming language to compete with Rust would be a massive undertaking and there would have to be some real reason to do it. Rust may be missing some features like higher-kinded types, named function arguments and such but to really catch on the language would need to offer some extremely important feature that Rust doesn't have, as well as offering all of Rust's benefits at the same time.</p><p>Is there any such language currently in early development? Or perhaps, what would such a language have to look like?</p>","contentLength":1045,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Scrap Your ORM‚ÄîReplacing Your ORM With Relational Algebra","url":"https://youtu.be/SKXEppEZp9M?si=wccXwllXm-0M-zOO","date":1740249559,"author":"/u/JohnyTex","guid":9394,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivppbh/scrap_your_ormreplacing_your_orm_with_relational/"},{"title":"FFmpeg School of Assembly Language","url":"https://github.com/FFmpeg/asm-lessons/blob/main/lesson_01/index.md","date":1740247207,"author":"/u/mitousa","guid":9265,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivorhb/ffmpeg_school_of_assembly_language/"},{"title":"[R] Interpreting Deep Neural Networks: Memorization, Kernels, Nearest Neighbors, and Attention","url":"https://medium.com/@thienhn97/interpreting-deep-neural-networks-memorization-kernels-nearest-neighbors-and-attention-6bf0cefc7619","date":1740244549,"author":"/u/ThienPro123","guid":9301,"unread":true,"content":"<p>This means that our positive kernel is actually some inner product of a Hilbert space. Typically, Mercer‚Äôs theorem is used for the kernel trick where we can map our input data to richer feature spaces that are potentially infinite dimensional (e.g. Gaussian kernel, polynomial kernel, etc.). However, in our case, we will use it to interpret the other way around.</p><p>Note the following relationship between distance in the Hilbert space and the kernel function:</p><p>This means that the closer x is to y in H , the more similar they will be in our similarity measure. So our intuition of the similarity measure being related to some form of distance is formalized by the relationship above.</p><h2>Learned kernel instead of fixing a kernel a priori</h2><p>If something within our prediction model is not learnable, then it is a prior that we are imposing on the dataset and the problem.</p><p>In our previous discussions of soft-kernelized NNs, the kernel K is fixed, meaning that we have some prior on the geometry of the data. That is not always desirable and we want our methods to automatically learn the structure of the data rather than us manually imposing this geometry.</p><p>Hence, if we want to learn the kernel K instead of imposing a prior fixed kernel, we can write (due to Mercer‚Äôs theorem):</p><p>for some parameterized feature map œà : X ‚Üí H from the data space X to some Hilbert space H. Typically, H will just be R^n or the dimension of the latent space. We can then learn the parameters of œà via standard training techniques (i.e. gradient descent on some loss).</p><p>This view allows us to connect standard deep learning (or representation learning) to kernel learning.</p><h2>Interpreting attention as soft nearest neighbors</h2><p>Note that the soft kernelized nearest neighbor that we presented earlier</p><p>can be interpreted as the popular attention mechanism that is ubiquitous today in LLMs and LVMs via the transformers architecture.</p><p>If we interpret x as some token, e.g. x_c, in the sequence (x_1, ‚Ä¶, x_n), K(x_i , x) as the attention dot product i.e.</p><p>and setting W_{ci} as the normalized values for token at time i i.e.</p><p>then we would recover the attention computation (bidirectional or autoregressive depending on whether we set the W_{ci} = 0 for i &lt; c) as being the weighted average of the values of other tokens in the sequence.</p><p>The representer theorem states that there exists an optimal linear solution that lies in the span of the training data. We shall call span (œà(x_1), ‚Ä¶, œà (x_n)) the <em>training (examples) feature span.</em></p>","contentLength":2494,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/MachineLearning/comments/1ivnp1c/r_interpreting_deep_neural_networks_memorization/"},{"title":"i made a list of Tech EU tech projects! for users interested in privacy and sustainability","url":"https://github.com/uscneps/Awesome-European-Tech","date":1740244216,"author":"/u/uscnep","guid":9264,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivnk77/i_made_a_list_of_tech_eu_tech_projects_for_users/"},{"title":"I can play a game that wasn't meant to run on my PC, using Linux","url":"https://www.reddit.com/r/linux/comments/1ivn4kr/i_can_play_a_game_that_wasnt_meant_to_run_on_my/","date":1740243151,"author":"/u/Vousch","guid":9263,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gitoxide in February","url":"https://github.com/GitoxideLabs/gitoxide/discussions/1855","date":1740242874,"author":"/u/ByronBates","guid":9395,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1ivn0m4/gitoxide_in_february/"},{"title":"I made an MMORPG playable with an API. Use any programming language to control your characters with the API.","url":"https://www.artifactsmmo.com/","date":1740241440,"author":"/u/Muigetsu","guid":9211,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivmgf2/i_made_an_mmorpg_playable_with_an_api_use_any/"},{"title":"What is Saga Pattern in Distributed Systems?","url":"https://newsletter.scalablethread.com/p/what-is-saga-pattern-in-distributed","date":1740235399,"author":"/u/scalablethread","guid":9234,"unread":true,"content":"<p><a href=\"https://newsletter.scalablethread.com/i/146489166/consistency-and-consistency-model\" rel=\"\">data consistency</a></p><p>The Saga pattern is a design pattern that helps manage transaction updates across multiple services by breaking them down into a sequence of small local transactional updates, called \"saga steps\" or \"subtransactions.\" Each step represents a unit of work that interacts with a single service. Once a step is completed, it triggers the next step in the sequence. If any step fails, the saga executes compensating updates to undo the changes made by the previous steps, ensuring that the system returns to its initial state.</p><p>There are two main approaches to implementing the Saga Pattern: Orchestration and Choreography.</p><p>In this approach, a central orchestrator service coordinates the saga steps. The orchestrator tells each service when to execute its local transaction. It maintains the state of the saga and handles any failures by invoking compensating transactions. The orchestrator knows the entire saga flow.</p><p>The client initiates the saga by communicating with the orchestrator. The orchestrator then invokes the first service. Upon successful completion, the orchestrator moves to the next step, invoking the corresponding service. If a service fails, the orchestrator triggers compensating transactions in reverse order.</p><p>In the Choreography approach, there is no central coordinator. Instead, each service involved in the saga knows its role and communicates with the other services through events or messages. Each service listens for specific events and performs local transactions when the appropriate event is received. The saga flow is distributed across the services.</p><p>The client initiates the saga by communicating with the first service. This service performs its transaction and publishes an event. Other services, listening for this event, perform their respective transactions and publish their events. This chain reaction continues until the saga is complete. If a service fails, it publishes a compensating event, triggering other services to execute compensating transactions.</p><ul><li><p>Choreography has no single point of failure, as each service manages its part of the saga.</p></li><li><p>Orchestration provides simplified error handling and monitoring with centralized control. In contrast, each service needs to handle its errors in Choreography, which can lead to complex error-handling logic.</p></li><li><p>In Orchestration, the coordinator needs to know about all the services involved in the saga, which can lead to tight coupling. In contrast, in Choreography, services need to agree on the events and the order of transactions, which can lead to overhead in coordination.</p></li></ul><ul></ul><ul></ul><p><em>If you enjoyed this article, please hit the ‚ù§Ô∏è like button.</em></p><p><em>If you think someone else will benefit from this, then please üîÅ share this post.</em></p>","contentLength":2718,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivk7x9/what_is_saga_pattern_in_distributed_systems/"},{"title":"[R] Calculating costs of fine tuning an Vision Language Model","url":"https://www.reddit.com/r/MachineLearning/comments/1ivjrwi/r_calculating_costs_of_fine_tuning_an_vision/","date":1740234081,"author":"/u/thekarthikprasad","guid":9235,"unread":true,"content":"<p>Hello guys, I need help in calculating the cost of fine-tuning a VL model.<p> My image dataset is of size 80+gb (</p><a href=\"https://huggingface.co/datasets/RussRobin/SpatialQA\">https://huggingface.co/datasets/RussRobin/SpatialQA</a>) The VL model is InternVL's 2B model<p> I am confused about whether to do a full parameter/QLoRA Finetuning.</p> I can't spend more on this, but wish to check the results.</p><p>If so I could, what would be the cost estimate, also how to estimate cost in general Can I sample the dataset, if it breaks my cost bound and still see the results?<p> Also do suggest the best and cheapest compute platform for my case.</p> Thanks in advance.</p>","contentLength":577,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rustaceans, What are your thoughts on Gleam?","url":"https://www.reddit.com/r/rust/comments/1ivjcus/rustaceans_what_are_your_thoughts_on_gleam/","date":1740232848,"author":"/u/nikitarevenco","guid":9183,"unread":true,"content":"<p>I've been writing Rust for a couple months. I absolutely love its monads like Result and Option, pattern-matching, private-by-default, the friendly compiler and its type system. I took a quick look at Gleam and it seems to have those features as well. Its syntax heavily reminds me of Rust's, the major distinction is that Gleam is much higher level (No lifetimes, for example), and also it is a purely functional language. It is still relatively new.</p><p>For those who have tried it, what do you think about it? Are there situations where you will prefer Gleam over Rust and why. </p>","contentLength":576,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Almost everyone is under-appreciating automated AI research","url":"https://www.reddit.com/r/artificial/comments/1ivja6c/almost_everyone_is_underappreciating_automated_ai/","date":1740232632,"author":"/u/MetaKnowing","guid":9233,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SystemV Filesystem Being Removed From The Linux Kernel","url":"https://www.phoronix.com/news/Removing-SystemV-Filesystem","date":1740229957,"author":"/u/unixbhaskar","guid":9181,"unread":true,"content":"<p>Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via <a href=\"https://twitter.com/MichaelLarabel\">Twitter</a>, <a href=\"https://www.linkedin.com/in/michaellarabel/\">LinkedIn</a>, or contacted via <a href=\"https://www.michaellarabel.com/\">MichaelLarabel.com</a>.</p>","contentLength":500,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1ivifki/systemv_filesystem_being_removed_from_the_linux/"},{"title":"The Efficiency Paradox: How to Save Yourself & the World ‚Ä¢ Holly Cummins","url":"https://youtu.be/dU_WHead0oY","date":1740227380,"author":"/u/goto-con","guid":9507,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivhol0/the_efficiency_paradox_how_to_save_yourself_the/"},{"title":"OpenAI bans Chinese accounts using ChatGPT to edit code for social media surveillance","url":"https://www.engadget.com/ai/openai-bans-chinese-accounts-using-chatgpt-to-edit-code-for-social-media-surveillance-230451036.html","date":1740223463,"author":"/u/F0urLeafCl0ver","guid":9113,"unread":true,"content":"<p>OpenAI has banned the accounts of a group of Chinese users who had attempted to use ChatGPT to debug and edit code for an AI social media surveillance tool, the company <a data-i13n=\"cpos:1;pos:1\" href=\"https://openai.com/global-affairs/disrupting-malicious-uses-of-ai/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:said Friday;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas\"></a>. The campaign, which OpenAI calls Peer Review, saw the group prompt ChatGPT to generate sales pitches for a program those documents suggest was designed to monitor anti-Chinese sentiment on X, Facebook, YouTube, Instagram and other platforms. The operation appears to have been particularly interested in spotting calls for protests against human rights violations in China, with the intent of sharing those insights with the country's authorities.</p><p>\"This network consisted of ChatGPT accounts that operated in a time pattern consistent with mainland Chinese business hours, prompted our models in Chinese, and used our tools with a volume and variety consistent with manual prompting, rather than automation,\" said OpenAI. \"The operators used our models to proofread claims that their insights had been sent to Chinese embassies abroad, and to intelligence agents monitoring protests in countries including the United States, Germany and the United Kingdom.\"</p><p>According to Ben Nimmo, a principal investigator with OpenAI, this was the first time the company had uncovered an AI tool of this kind. \"Threat actors sometimes give us a glimpse of what they are doing in other parts of the internet because of the way they use our AI models,\" Nimmo told <a data-i13n=\"cpos:2;pos:1\" href=\"https://www.nytimes.com/2025/02/21/technology/openai-chinese-surveillance.html\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:The New York Times;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas\"></a>.</p><p>Much of the code for the surveillance tool appears to have been based on an open-source version of one of Meta's <a data-i13n=\"cpos:3;pos:1\" href=\"https://www.engadget.com/ai/meta-says-llamas-usage-grew-tremendously-due-to-the-power-of-open-source-140020454.html\" data-ylk=\"slk:Llama models;cpos:3;pos:1;elm:context_link;itc:0;sec:content-canvas\"></a>. The group also appears to have used ChatGPT to generate an end-of-year performance review where it claims to have written phishing emails on behalf of clients in China.</p><p>\"Assessing the impact of this activity would require inputs from multiple stakeholders, including operators of any open-source models who can shed a light on this activity,\" OpenAI said of the operation's efforts to use ChatGPT to edit code for the AI social media surveillance tool.</p><p>Separately, OpenAI said it recently banned an account that used ChatGPT to generate social media posts critical of <a data-i13n=\"cpos:4;pos:1\" href=\"https://en.wikipedia.org/wiki/Cai_Xia\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:Cai Xia;cpos:4;pos:1;elm:context_link;itc:0;sec:content-canvas\"></a>, a Chinese political scientist and dissident who lives in the US in exile. The same group also used the chatbot to generate articles in Spanish critical of the US. These articles were published by \"mainstream\" news organizations in Latin America and often attributed to either an individual or a Chinese company.</p>","contentLength":2411,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1ivgo34/openai_bans_chinese_accounts_using_chatgpt_to/"},{"title":"Distributed system courses in Rust?","url":"https://www.reddit.com/r/rust/comments/1ivgbko/distributed_system_courses_in_rust/","date":1740222035,"author":"/u/FeelingAttempt55","guid":9163,"unread":true,"content":"<p>I am currently following the <a href=\"https://github.com/pingcap/talent-plan/tree/master\">pingcap course</a> to learn distributed systems with Rust. So far, I am really enjoying the course, but the course is 5 years old, could you guys suggest some other project-based and more up-to-date courses? </p>","contentLength":233,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PeaZip 10.3.0 released!","url":"https://www.reddit.com/r/linux/comments/1ivfn9y/peazip_1030_released/","date":1740219074,"author":"/u/peazip","guid":9368,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Pewdiepie uses linux mint","url":"https://www.reddit.com/r/linux/comments/1ivf01w/pewdiepie_uses_linux_mint/","date":1740216313,"author":"/u/RedDevilVortex","guid":9059,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I created a fairly extensive cheat sheet for scripting Sieve mail filters. Here's a link to the Gist if anyone is interested.","url":"https://gist.github.com/Hotrod369/6b7a24e1ea060e48e0c02459cbb950a0","date":1740214906,"author":"/u/StinkyPete312","guid":9210,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iveor2/i_created_a_fairly_extensive_cheat_sheet_for/"},{"title":"This is a minimalist 2-click MSI installer generator for your projects for Windows. Magic works as all you need is to populate _configMSI.yml with your own values, then click 2 bat or sh files (if you use MS Visual Studio or MSYS2/MINGW64). And voila, your MSI Installer is ready!","url":"https://github.com/windows-2048/Magic-MSI-Installer-Template","date":1740214284,"author":"/u/florida-haunted","guid":9081,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivejju/this_is_a_minimalist_2click_msi_installer/"},{"title":"Pixerise v0.12 Release: Python High-Performance 3D Renderer Adds Ray Casting, 1/z Depth Interpolation, and Group Management with Improved Architecture","url":"https://github.com/enricostara/pixerise","date":1740214075,"author":"/u/jumpixel","guid":9182,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivehr0/pixerise_v012_release_python_highperformance_3d/"},{"title":"Confused about \"NEW\" Rust feature in - Closures in async functions","url":"https://www.reddit.com/r/rust/comments/1ivdmek/confused_about_new_rust_feature_in_closures_in/","date":1740210338,"author":"/u/DataBora","guid":9302,"unread":true,"content":"<p>I am reading how new Rust feature is comming for using closures in Async functions. || async whaterver...</p><p>In my Elusion library implementation i have PipelineScheduler function signature:</p><pre><code> ```rust pub async fn new&lt;F, Fut&gt;(frequency: &amp;str, job: F) -&gt; ElusionResult&lt;Self&gt; where F: Fn() -&gt; Fut + Send + Sync + 'static, Fut: Future&lt;Output = ElusionResult&lt;()&gt;&gt; + Send + 'static ``` </code></pre><p>and then for Job creation:</p><pre><code>```rust let job = Job::new_async(&amp;cron, move |uuid, mut l| { let job_fn = job_fn.clone(); Box::pin(async move { let future = job_fn(); future.await.unwrap_or_else(|e| eprintln!(\"‚ùå Job execution failed: {}\", e)); let next_tick = l.next_tick_for_job(uuid).await; match next_tick { Ok(Some(ts)) =&gt; println!(\"Next job execution: {:?} UTC Time\", ts), _ =&gt; println!(\"Could not determine next job execution\"), } }) }).map_err(|e| ElusionError::Custom(format!(\"‚ùå Job creation failed: {}\", e)))?; ``` </code></pre><p>which user can use like this:</p><pre><code>let scheduler = PipelineScheduler::new(\"5min\", || async {}) </code></pre><p>How this new feature will be different?</p>","contentLength":1025,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[R] Evaluating LLM Knowledge Across 285 Graduate Disciplines: A Comprehensive Benchmark Using Human-LLM Collaborative Filtering","url":"https://www.reddit.com/r/MachineLearning/comments/1ivd069/r_evaluating_llm_knowledge_across_285_graduate/","date":1740207761,"author":"/u/Successful-Western27","guid":9236,"unread":true,"content":"<p>A new evaluation benchmark tests language models across 285 graduate-level disciplines using an iterative human-AI collaborative approach to generate and validate questions. The methodology combines expert review with model-assisted filtering to ensure high-quality, discipline-appropriate assessment.</p><p>Key technical points: - Uses a two-stage question generation process: initial AI generation followed by expert review - Implements collaborative filtering where both human experts and LLMs help identify and remove problematic questions - Covers disciplines from traditional academia to specialized industrial fields - Tests both factual knowledge and reasoning capabilities - Evaluated on multiple leading LLMs including GPT-4, Claude 2, and DeepSeek</p><p>Results: - Best performance: DeepSeek-R1 at 61.82% accuracy - Significant variance in performance across different disciplines - 80+ expert annotators involved in validation - Generated dataset of 2,855 validated questions</p><p>I think this benchmark addresses a critical gap in LLM evaluation by going beyond common academic subjects. The methodology of combining human expertise with AI assistance for question validation could be valuable for developing future evaluation datasets.</p><p>I think the relatively modest performance (62%) on graduate-level questions across diverse fields suggests current LLMs still have significant room for improvement in specialized domains. This could influence how we approach model training and evaluation for domain-specific applications.</p><p>TLDR: New benchmark tests LLMs across 285 graduate disciplines using human-AI collaborative question generation. Best model achieved 62% accuracy, revealing gaps in specialized knowledge.</p>","contentLength":1704,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"This Week in Plasma: Refinements All Around","url":"https://blogs.kde.org/2025/02/22/this-week-in-plasma-refinements-all-around/","date":1740207215,"author":"/u/gabriel_3","guid":9080,"unread":true,"content":"<p>Welcome to a new issue of \"This Week in Plasma\"! Every week we cover as much as possible of what's happening in the world of KDE Plasma and its associated apps like Discover, System Monitor, and more.</p><p>This week, we've been rapidly fixing the bugs that people found in Plasma 6.3, as well as some older bugs as well. In addition to that, some smaller UI improvements have started to trickle in! There's some larger work in progress too, but not merged yet. Have a look at what did merge this week:</p><p>Improved the weather widget's display of search results from the BBC weather service to reduce unhelpful visual noise. (Ismael Asensio, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500065\">link</a>)</p><p>Eliminated the visual difference between how Night Light looks on Wayland compared to on X11. (Xaver Hugl, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500300\">link</a>)</p><p>The Digital Clock widget's context menu is now less cluttered with things you're not likely to use. (Nate Graham, <a href=\"https://invent.kde.org/plasma/plasma-workspace/-/merge_requests/5139\">link</a>)</p><p>Rephrased some settings on System Settings' General Behavior page to be clearer about what it is that they actually do. (Nate Graham, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/2808\">link</a>)</p><p>Improved the accessibility of the Widget Explorer sidebar. (Christoph Wolk, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/2807\">link</a>)</p><p>Fixed the issue mentioned last week where KWin built with LTO on GCC 15 could show a black screen on login when using an ICC profile; we found a way to restructure the code that avoids the issue. (Vlad Zahorodnii and Xaver Hugl, <a href=\"https://bugs.kde.org/show_bug.cgi?id=499789\">link</a>)</p><p>Fixed a case where Plasma could crash when you tried to access the Properties dialog for a file in the Recently or Frequently Used file lists in the Kickoff Application Launcher. (Nicolas Fella, <a href=\"https://bugs.kde.org/show_bug.cgi?id=499845\">link</a>)</p><p>Fixed a regression that caused the volume change OSD to fail to appear when adjusting the volume with the integrated volume buttons of a Bluetooth headset. (David Redondo, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500129\">link</a>)</p><p>Fixed a regression that caused the + clipboard popup to lose its visual highlights when navigated by keyboard. (Christoph Wolk, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500055\">link</a>)</p><p>Fixed an issue in KWin that caused the new \"Prefer efficiency\" option when using an ICC profile to not actually be very efficient on some hardware, and another one that broke Night Light while using the \"Prefer color accuracy\" setting. (Xaver Hugl, <a href=\"https://bugs.kde.org/show_bug.cgi?id=499987\">link 1</a> and <a href=\"https://bugs.kde.org/show_bug.cgi?id=500404\">link 2</a>)</p><p>Taking screenshots on Wayland in FreeBSD now works. (Vlad Zahorodnii, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500261\">link</a>)</p><p>Fixed a few bugs in the Color Picker widget, such as the shortcut option not working, and the tooltip not looking correct in certain circumstances. (Christoph Wolk, <a href=\"https://invent.kde.org/plasma/kdeplasma-addons/-/merge_requests/676\">link 1</a> and <a href=\"https://invent.kde.org/plasma/kdeplasma-addons/-/merge_requests/677\">link 2</a>)</p><p>Fixed a bug with the Task Manager widgets that broke the ability to move the pointer diagonally to a tooltip without dismissing it by accident while using a right-to-left language like Arabic or Hebrew. (Christoph Wolk, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/2792\">link</a>)</p><p>Made several improvements and fixes for keyboard navigation in the Kicker Application Menu widget. (Christoph Wolk, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/2811\">link 1</a>, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/2812\">link 2</a>, and <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/2813\">link 3</a>)</p><p>Fixed a regression that caused desktop icons selected by dragging a box around them to become inappropriately deselected if the pointer ended right over one of the icons when releasing the mouse button. (David Edmundson, <a href=\"https://bugs.kde.org/show_bug.cgi?id=499898\">link</a>)</p><p>Fixed a regression that caused the automatic tablet mode feature to accidentally get blocked on certain types of devices, but only when using the feature to re-bind mouse buttons. (Vlad Zahorodnii, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500025\">link</a>)</p><p>Fixed a bug that caused the desktop and panels to go missing when applying a new Global Theme and using the option to replace the existing layout. This also fixed a bug that caused deleted widgets to not be deleted from the <code>plasma-org.kde.plasma.desktop-appletsrc</code> config file. (Marco Martin, <a href=\"https://bugs.kde.org/show_bug.cgi?id=498175\">link 1</a> and <a href=\"https://bugs.kde.org/show_bug.cgi?id=404641\">link 2</a>)</p><p>Fixed a set of subtle bugs in the implementation of the new \"prefer symbolic icons\" behavior of the System Tray that caused it to actually do the opposite, showing you colorful icons instead! (Nate Graham and David Redondo, <a href=\"https://invent.kde.org/plasma/plasma-workspace/-/merge_requests/5227\">link 1</a> and <a href=\"https://invent.kde.org/frameworks/kiconthemes/-/merge_requests/175\">link 2</a>)</p><p>Extremely long weather station names no longer overflow and break the widget popup's layout. (Ismael Asensio, <a href=\"https://invent.kde.org/plasma/kdeplasma-addons/-/merge_requests/680\">link</a>)</p><p>The inline file renaming text field on the desktop is now colored correctly when using a mixed light/dark setup, as with Breeze Twilight. (Evgeniy Harchenko, <a href=\"https://invent.kde.org/plasma/plasma-desktop/-/merge_requests/2829\">link</a>)</p><p>Limited the Power Management setting \"Change screen brightness\" to only take effect for built-in screens on battery-powered systems (e.g. laptops), which avoids certain timing-related brightness bugs for external monitors and makes the settings page less confusing. (Jakob Petsovits, <a href=\"https://bugs.kde.org/show_bug.cgi?id=498771\">link</a>)</p><p>Fixed an issue that could cause user switching from KRunner to behave strangely and eventually cause a crash. (David Edmundson, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500038\">link</a>)</p><p>Fixed an older regression that broke the \"highlight non-default settings\" features for pages in System Settings written using QtWidgets. The fact that this was overlooked for so long goes to show how few are left these days! (David Redondo, <a href=\"https://invent.kde.org/frameworks/kcmutils/-/merge_requests/257\">link</a>)</p><p>Switched KWin's render loop initialization code to use a more precise type of timer that should reduce frame drops. (Apostolos Dimitromanolakis, <a href=\"https://bugs.kde.org/show_bug.cgi?id=500500\">link</a>)</p><p>When the  daemon crashes, now it automatically restarts itself in the background. (Bryan Liang, <a href=\"https://invent.kde.org/frameworks/kded/-/merge_requests/57\">link</a>)</p><p>KDE has become important in the world, and your time and contributions have helped us get there. As we grow, we need your support to keep KDE sustainable.</p><p>You can help KDE by becoming an active community member and <a href=\"https://community.kde.org/Get_Involved\">getting involved</a> somehow. Each contributor makes a huge difference in KDE ‚Äî you are not a number or a cog in a machine!</p><p>You don‚Äôt have to be a programmer, either. Many other opportunities exist:</p><p>You can also help us by <a href=\"https://kde.org/donate\">making a donation!</a> Any monetary contribution ‚Äî however small ‚Äî will help us cover operational costs, salaries, travel expenses for contributors, and in general just keep KDE bringing Free Software to the world.</p><p>Enter your email address to follow this blog and receive notifications of new posts by email.</p>","contentLength":5644,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1ivcuy0/this_week_in_plasma_refinements_all_around/"},{"title":"I Made a Configurable Rate Limiter‚Ä¶ Because APIs Can‚Äôt Say ‚ÄòChill‚Äô","url":"https://beyondthesyntax.substack.com/p/i-made-a-configurable-rate-limiter?r=4jgehp&amp;utm_campaign=post&amp;utm_medium=web&amp;triedRedirect=true","date":1740205486,"author":"/u/Sushant098123","guid":8987,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivcfct/i_made_a_configurable_rate_limiter_because_apis/"},{"title":"I have made a pong game in C++ using raylib. So can anyone plz give suggession where I can improve the game and my code?","url":"https://github.com/EthicalAniruddha/AI-Pong","date":1740204102,"author":"/u/Ethical_Aniruddha","guid":8986,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1ivc2qa/i_have_made_a_pong_game_in_c_using_raylib_so_can/"},{"title":"One-Minute Daily AI News 2/21/2025","url":"https://www.reddit.com/r/artificial/comments/1ivbt3a/oneminute_daily_ai_news_2212025/","date":1740203110,"author":"/u/Excellent-Target-847","guid":9262,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/Excellent-Target-847\"> /u/Excellent-Target-847 </a>","contentLength":43,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Announcing async-local 3.0 now with async closure support","url":"https://www.reddit.com/r/rust/comments/1iv8o6v/announcing_asynclocal_30_now_with_async_closure/","date":1740192335,"author":"/u/Jester831","guid":9060,"unread":true,"content":"<p>Async-local enables thread locals to be used in an async context across await points or within blocking threads managed by the Tokio runtime without the overhead of `Arc`. The way this is accomplished is by using <a href=\"https://crates.io/crates/generativity\">generativity</a> to create unique invariant lifetimes so that borrows to TLS can't be coerced to a `&amp;'static` lifetime and by configuring the runtime with a barrier to rendezvous worker threads during shutdown. This shutdown barrier makes it such that runtime tasks never outlive TLS data owned by worker threads; this makes every invariant lifetime guaranteed to be valid until no tasks remain. Blocking threads managed by the Tokio runtime cannot outlive worker threads with this configuration, and so pointers to TLS from worker threads can be safely moved to these blocking threads with the lifetime constrained. As the lifetimes cannot be coerced into `&amp;'static`, moving onto other threads is prevented. This crate downgrades to using `Arc` whenever the `barrier-protected-runtime` feature is not enabled, making it the end users choice to opt into this optimization by using async_local to configure the runtime shutdown barrier. </p>","contentLength":1145,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ring is unmaintained","url":"https://rustsec.org/advisories/RUSTSEC-2025-0007.html","date":1740185098,"author":"/u/technobicheiro","guid":8934,"unread":true,"content":"<p>This advisory has been withdrawn and should be ignored. It is kept only for reference.</p><p>The author has announced an indefinite hiatus in its development, noting that\nany reported security vulnerabilities may go unaddressed for prolonged periods\nof time.</p><p>After this advisory was published, the author graciously agreed to give\naccess to the rustls team. The rustls team is committed to providing\nsecurity (only) maintenance for  for the foreseeable future.</p><p>Advisory available under <a href=\"https://spdx.org/licenses/CC0-1.0.html\">CC0-1.0</a>\n    license.\n\n    \n    </p>","contentLength":508,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1iv6myf/ring_is_unmaintained/"},{"title":"[P] Decensor AI models Qwen/Deepseek by finetuning with non political data","url":"https://www.reddit.com/r/MachineLearning/comments/1iv6ckk/p_decensor_ai_models_qwendeepseek_by_finetuning/","date":1740184249,"author":"/u/Ambitious_Anybody855","guid":9114,"unread":true,"content":"<p>The best way to decensor a DeepSeek model? Don‚Äôt try to decensor it.</p><p>Fine-tuned OpenThinker on OpenThoughts-114k, a dataset focused on reasoning tasks like math, coding, and graduate-level Q&amp;A, with no political content. Despite using censored base models (Qwen), the fine-tuned OpenThinker-7B and OpenThinker-32B models became decensored without any explicit intervention. Unlike Perplexity, no custom fine-tuning was applied to remove censorship, yet the results remain uncensored. </p><p>It challenges assumptions about model safety and opens exciting new research directions. AI game is so on</p>","contentLength":590,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Firefox's HEVC support for Linux (via VA-API) coming in Firefox 137","url":"https://www.reddit.com/r/linux/comments/1iv6bhi/firefoxs_hevc_support_for_linux_via_vaapi_coming/","date":1740184159,"author":"/u/neks101","guid":8955,"unread":true,"content":"<p>Windows got support in Firefox 134, MacOS on the Firefox beta build 136, and Linux will be on the Firefox nightly with 137. Looks like all OS will be supported by 137!</p>","contentLength":167,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"First time on Linux, 3 gig ram and works like a rocket lol","url":"https://www.reddit.com/r/linux/comments/1iv5tas/first_time_on_linux_3_gig_ram_and_works_like_a/","date":1740182726,"author":"/u/SnooOpinions7428","guid":8898,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lightweight Real-Time System Stats for VS Code","url":"https://marketplace.visualstudio.com/items?itemName=odangoo.otak-monitor","date":1740181177,"author":"/u/Wise_Bug47","guid":8942,"unread":true,"content":"<p align=\"center\">A lightweight system monitor for VS Code - Track CPU, memory, and disk usage with efficient 5-second updates and 1-minute averages.</p><ol><li>Find the system monitor in your VS Code status bar</li><li>View CPU usage percentage</li><li>Hover to see detailed current and average metrics</li></ol><p>otak-monitor is a lightweight VS Code extension that helps you monitor system resources without leaving your editor.</p><ul><li><ul><li>Status bar display of CPU usage percentage</li><li>Aggregated across all CPU cores</li><li>Precise to one decimal place</li><li>Current CPU clock speed (MHz)</li></ul></li><li><ul><li>Detailed memory information</li><li>Shows used and total memory in MB</li></ul></li><li><ul><li>Cross-platform disk space monitoring\n<ul><li>Windows: C: drive (home directory in Codespaces)</li><li>Linux: Root filesystem (workspace root in Codespaces)</li></ul></li><li>Shows used and total space in GB</li></ul></li><li><ul><li>Clean status bar integration</li><li>Detailed hover tooltip showing:\n<ul><li>Current CPU, memory, and disk metrics</li></ul></li></ul></li></ul><ul><li>Visual Studio Code ^1.90.0</li><li>Supported environments:\n<ul><li>Local: Windows, macOS, Linux</li><li>Remote: GitHub Codespaces</li></ul></li></ul><ol><li>Install the extension from VS Code Marketplace</li><li>Look for the CPU usage display in your status bar</li><li>Hover over it to see detailed system information</li></ol><p>The extension shows the following information in your status bar:</p><p>With a detailed tooltip showing:</p><pre><code>Current:\nCPU Usage: 45.3% (2400 MHz)\nMemory Usage: 1024 MB / 2048 MB (50.0%)\nDisk Usage: 150 GB / 500 GB (30.0%)\n</code></pre><p>Note: For disk usage, the monitored path varies by environment:</p><ul><li>Windows:\n<ul><li>Codespaces: Home directory</li></ul></li><li>Linux:\n<ul><li>Local: Root filesystem (/)</li><li>Codespaces: Workspace root</li></ul></li></ul><ul><li>CPU usage is calculated by comparing idle and total CPU time differences</li><li>Memory values are shown in MB and percentage</li><li>Disk usage monitoring adapts to the environment:\n<ul><li>Local machines: Monitors system root or C: drive</li><li>Codespaces: Monitors relevant workspace paths</li></ul></li><li>Moving averages are calculated using 12 data points (5-second intervals over 1 minute)</li><li>Updates occur every 5 seconds for efficient monitoring</li><li>Minimal performance impact on the system</li></ul><h2>GitHub Codespaces Support</h2><p>The extension automatically detects when running in GitHub Codespaces and adjusts its behavior:</p><ul><li>Monitors the workspace root directory in Linux environments</li><li>Uses home directory for Windows-based Codespaces</li><li>Maintains consistent monitoring experience across all environments</li><li>Provides accurate disk usage information for containerized development</li></ul><p>Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.</p><p>This project is licensed under the MIT License - see the <a href=\"https://github.com/tsuyoshi-otake-system-exe-jp/otak-monitor/blob/HEAD/LICENSE\" target=\"_blank\" rel=\"noreferrer noopener nofollow\">LICENSE</a> file for details.</p>","contentLength":2481,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iv592c/lightweight_realtime_system_stats_for_vs_code/"},{"title":"I made an AirDrop server that uses URL Requests to accept data from anywhere","url":"https://github.com/gnhen/SkyDrop","date":1740179194,"author":"/u/GranttH","guid":8899,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iv4j4r/i_made_an_airdrop_server_that_uses_url_requests/"},{"title":"Rust Rant Contest: std::io::Error, the oversized junk drawer of failure","url":"https://www.reddit.com/r/rust/comments/1iv3rb3/rust_rant_contest_stdioerror_the_oversized_junk/","date":1740177182,"author":"/u/OliveTreeFounder","guid":8957,"unread":true,"content":"<p>I've been coding in Rust for five years, and  has never been anything but a headache. The error code? Never useful. It‚Äôs impossible to handle‚Äîtoo big, too vague‚Äîso we all end up just passing this bloated mess back to the caller without even knowing what‚Äôs inside or what actually caused the error.</p><p>But it gets worse. Traits, instead of being parameterized over an  type, just return <code>Result&lt;..., std::io::Error&gt;</code>. Once a trait like this becomes popular‚Äîlike  or ‚Äîyou're stuck. You can‚Äôt handle errors properly unless you rewrite every crate that depends on these traits.</p><p> is a contagious disease infecting the entire ecosystem. We need to stop this pandemic!</p>","contentLength":668,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Matrix.org bridges to shut down in 1 month unless $100k can be raised","url":"https://matrix.org/blog/2025/02/crossroads/","date":1740174293,"author":"/u/Evidlo","guid":8876,"unread":true,"content":"<p>After a <a href=\"https://matrix.org/blog/2024/12/25/the-matrix-holiday-special-2024/\">successful 2024 with a lot to be proud of</a>, and a Matrix Conference that brought our community together to celebrate 10 years of Matrix, we step into 2025 with a light budget and a mighty team poised to make the most of it!</p><p>Our priorities remain to make Matrix a safer network, keep growing the ecosystem, make the most of our Governing Board, and drive a fruitful and friendly collaboration across all actors.</p><p>However, whether we will manage to get there is not fully a given.</p><h2><a href=\"https://matrix.org/blog/2025/02/crossroads/#the-foundation-is-key-to-the-success-of-matrix\" aria-label=\"Anchor link for: the-foundation-is-key-to-the-success-of-matrix\">üîó</a>The Foundation is key to the success of Matrix</h2><p>The Matrix.org Foundation has gone from depending entirely on Element, the company set up by the creators of Matrix, to having half of its budget covered by its <a href=\"https://matrix.org/support/\">11 funding members</a>, which is a great success on the road to financial independence! However half of the budget being covered means half of it isn‚Äôt. Or in other words: the Foundation is not yet sustainable, despite running on the strictest possible budget, and is burning through its (relatively small) reserves. And we are at the point where the end of the road is in sight.</p><blockquote><p>The Matrix.org Foundation exists to act as a neutral  and to nurture it as efficiently as possible as <strong>a single unfragmented standard, for the greater benefit of the whole ecosystem</strong>, not benefiting or privileging any single player or subset of players.</p></blockquote><p>Without the Foundation and its programs, the Matrix protocol itself faces existential threats:</p><ul><li>Without Trust &amp; Safety efforts, bad actors and communities would proliferate on the network and make it unlivable for the rest.</li><li>Without a canonical specification, the shared infrastructure and a Spec Core Team to maintain it, the protocol would become fragmented, losing its effective interoperability ‚Äì increasing the costs on all downstream users.</li><li>Without a neutral entity as the custodian of the specification, the ecosystem would first shatter and then consolidate around the biggest (likely for-profit) actor.</li><li>Without advocacy, conferences, documentation and tutorials, Matrix would become a niche protocol used by a few enthusiasts for side projects, whilst big proprietary and siloed networks continue to hold the world‚Äôs communications.</li></ul><p>But there is light at the end of the tunnel! Concretely, the Foundation delivers most of its value by fostering a healthy, fair and fertile ecosystem around Matrix. It needs to strike the right balance between:</p><ul><li><strong>Making Matrix accessible &amp; visible.</strong><ul><li>For the general public it means maintaining an easy default onboarding server (Matrix.org).</li><li>For server administrators it means providing the right tooling to keep their users (and themselves!) safe.</li><li>For developers it means making it easy to develop products using Matrix, via documentation, tutorials, and in-person events.</li></ul></li><li><strong>Making Matrix compelling to build on.</strong><ul><li>This means maintaining the Matrix Specification as a canonical, unencumbered, patent free and royalty free specification.</li><li>Being responsive and vendor-neutral when an organisation or individual contributes.</li><li>Promoting the good players within the ecosystem.</li><li>Ensuring the network grows and attracts more users.</li></ul></li><li><strong>Making Matrix a product that benefits the greater good.</strong><ul><li>This means ensuring that the general public can easily build safe &amp; easy to use communities on Matrix.</li><li>Ensuring that bad actors are proactively chased and discouraged to use Matrix.</li></ul></li></ul><p>Matrix has been here for 10 years, and will hopefully be here for many more! But to continue to grow and thrive, it needs the Foundation to be around and healthy, which means carefully allocating its budget in order to continue to exist and fulfill its mission. This is why it needs to focus on critical programs and shut down some of its activities.</p><p>We view the following programs as critical to the Foundation‚Äôs mission:</p><ul><li>Maintaining the canonical, backwards compatible, stable <a href=\"https://spec.matrix.org/latest/\">Matrix Spec</a></li><li>Developing protocol enhancements and Trust and Safety tooling, making the tools available to the ecosystem and moderating the servers under its control (typically Matrix.org) - <a href=\"https://matrix.org/blog/2025/02/building-a-safer-matrix/\">see our recent blog post</a></li><li>Running the Matrix.org homeserver as an initial home for newcomers</li><li>Promoting the Matrix protocol via online content, conferences and meet-ups and other marketing strategies</li></ul><p>We might fine tune our approach, but we can't cease any of those programs without severe consequences for the ecosystem.</p><p>Meanwhile, bridges have been at the heart of Matrix for a long time. Public bridges hosted by the Matrix.org Foundation have been a very good resource to show the power of interoperability, connect communities together, and onboard many people into their Matrix journey.</p><p>However, these bridges require regular maintenance as the bridged platforms evolve their APIs, and significant engineering and moderation support to run. Luckily, the Matrix ecosystem is now more mature than it was at the time we spun up those public Slack, XMPP and IRC bridge instances. There are now commercial players like <a href=\"https://www.beeper.com/\">Beeper</a> providing a user-friendly offering for people who want to get all their conversations in a single app, or <a href=\"https://indiehosters.net/\">IndieHosters</a> and <a href=\"https://www.fairkom.eu/\">Fairkom</a> offering hosting for Matrix server and bridge instances (and much more).</p><p>So unless the Foundation manages to raise $100,000 of funding by the end of March 2025, we will have to focus our resources on the critical lines of work, and consequently <strong>we will have to shut down all the remaining bridges hosted by the Matrix.org Foundation. This includes bridges to Slack, XMPP, OFTC (IRC), and Snoonet (IRC).</strong> We will also mark the software behind those bridges as archived, as we don't have the resources to accept new contributions.</p><p>In practice, the Foundation needs an additional $610K in revenue to break-even, but this $100K would extend our runway 1 month while we work on landing grants and new members. To put this in context, we nearly doubled our revenue in 2024, reaching $561K, but it was also the first year in which we carried the full cost of our operations: $1.2M. To make ends meet, we liquidated $283K worth of cryptocurrency donations and ended the year with a $356K deficit. We are currently on target for $587K revenue in 2025, with a modest increase in expenses.</p><h2><a href=\"https://matrix.org/blog/2025/02/crossroads/#growing-the-ecosystem-and-the-network\" aria-label=\"Anchor link for: growing-the-ecosystem-and-the-network\">üîó</a>Growing the ecosystem and the network</h2><p>Choosing to shut the bridges down is a difficult decision to make, but will allow us to focus on the critical projects which will keep the ecosystem growing. The success of Matrix depends on how widely it is used by the general public and by organisations ‚Äì preferably natively rather than via bridges.</p><p>The more people and organisations rely on Matrix, the more attractive it becomes for organisations to build products and services on top of it, the more funding the Foundation gets, and the more the Foundation can in turn reinvest into the ecosystem and run initiatives that benefit all stakeholders for the growth of the network.</p><p>Once the Foundation is cashflow positive, it will be able to accelerate and eventually get on with the multiple projects the team and Governing Board have in mind to make Matrix fun, exciting, reliable, safe, easy to use, and above all useful. And we hope to get there by the end of the year.</p><p>Most importantly, despite the Trust and Safety team being the Foundation‚Äôs biggest expense, as explained in <a href=\"https://matrix.org/blog/2025/02/building-a-safer-matrix/\">our blog post</a>, the team is still underresourced: they are understaffed and under a lot of pressure to deliver protocol improvements, better tooling for server admins, and ensure Matrix.org is a good citizen of the open federation. <strong>T&amp;S will be the first area to see increased funding.</strong></p><p>Separately, the Foundation wants to continue executing on its mission! Among others, better connect the doers in the ecosystem with the people and organisations who need their energy, share the successes and learnings from the community: the Matrix Conference was an incredible success and we want to see more of that.</p><p>We‚Äôve also seen a clear change in how many users and organisations were adopting Matrix in the last few months: the world needs a decentralised end-to-end encrypted network to communicate more than ever, and it shows! We want to uplift the good players which are driving this growth.</p><p>There is so much more that we could do to make Matrix better and realise its full potential. </p><p>Right now, the Foundation urgently needs <a href=\"https://matrix.org/support/\">your financial help</a>. For the sake of a safe network, our primary focus today, but also to be able to deliver on the reason we all want Matrix to succeed.</p><ul><li>People should have full control over their own communication.</li><li>People should not be locked into centralised communication silos, but instead be free to pick who hosts their communication without limiting who they can reach.</li><li>The ability to converse securely and privately is a basic human right.</li><li>Communication should be available to everyone as a free and open, unencumbered, standard and global network.</li></ul><p><strong>If you are an organisation building on top of Matrix</strong>, you can help by , which also gives you the opportunity to be eligible to participate in the Governing Board, and other perks. </p><p><strong>If you are an organisation buying Matrix services or products</strong>, you can help by <strong>ensuring that your vendor is financially contributing back to the project</strong> or becoming a member yourself.</p><p><strong>If you are an individual using Matrix,</strong> you can help by .</p><p><strong>If you are a philanthropist or other funder</strong>, you can help by getting in touch with us at <a href=\"https://matrix.org/cdn-cgi/l/email-protection#5a3c2f343e33343d1a373b2e2833227435283d\"></a> to discuss funding options. </p><p>It isn‚Äôt the <a href=\"https://matrix.org/blog/2022/12/01/funding-matrix-via-the-matrix-org-foundation/\">first</a><a href=\"https://matrix.org/blog/2024/04/open-source-publicly-funded-service/\">time</a> we‚Äôve rung the alarm bell, and it is no fun to beg for help. We are at a crossroads, where the vibrancy of the ecosystem and enthusiasm around Matrix is not reflected in the support the Foundation gets, and we are at risk of losing this common resource and all it offers.</p><p>But all in all, we are optimists ‚Äì we wouldn‚Äôt have begun this journey if we weren‚Äôt ‚Äì and we believe that there are people out there who realise that sovereign and secure communication is as high on the list of today‚Äôs essential technology ‚Äì if not higher ‚Äì as ensuring AI is safe, so let‚Äôs spread the word and let‚Äôs continue working on a safer and more sovereign world!</p><div><div><p>\n                        The Matrix.org Foundation is a non-profit and only relies\n                        on donations to operate. Its core mission is to maintain\n                        the Matrix Specification, but it does much more than that.\n                    </p><p>\n                        It maintains the matrix.org homeserver and hosts several\n                        bridges for free. It fights for our collective rights to\n                        digital privacy and dignity.\n                    </p><a href=\"https://matrix.org/support\">Support us</a></div></div>","contentLength":10479,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1iv2mr3/matrixorg_bridges_to_shut_down_in_1_month_unless/"},{"title":"Windows to Linux, Set Up Full Disk Encryption on openSUSE","url":"https://news.opensuse.org/2025/02/20/setup-fde-on-opensuse/","date":1740170160,"author":"/u/gabriel_3","guid":9079,"unread":true,"content":"<p>Data breaches and cyber threats are becoming increasingly common and securing your personal and professional information has never been more critical.</p><p>Users transitioning from <a href=\"https://news.opensuse.org/2024/11/26/transition-from-windows-step-by-step/\">Windows to Linux</a> through the Upgrade to Freedom campaign can use <a href=\"https://get.opensuse.org/\">openSUSE</a>‚Äôs tools to protect sensitive data, which include full disk encryption (FDE).</p><p>Full disk encryption during installation ensures maximum security. It safeguards all data on your hard drive by encrypting it and makes it unreadable without an decryption key. This level of protection is vital for preventing unauthorized access if your laptop or desktop is lost or stolen.</p><p>FDE with openSUSE is both user-friendly and powerful. The setup with advanced security features is easy.</p><p>For users seeking feature parity with Windows BitLocker, openSUSE offers Full Disk Encryption (FDE) secured by a TPM2 chip or a FIDO2 key. This advanced setup enhances security by storing encryption keys within the TPM, which ensures that only a trusted system configuration can unlock the disk. For a step-by-step guide on enabling this feature, read the <a href=\"https://news.opensuse.org/2024/09/20/quickstart-fde-yast2/\">Quickstart in Full Disk Encryption with TPM and YaST2</a> article.</p><p>Here‚Äôs a step-by-step guide to set up FDE on your system:</p><p><strong>Step 1: Download and Boot openSUSE</strong></p><ul><li>Visit <a href=\"https://get.opensuse.org/\">get.opensuse.org</a> to download the latest version of openSUSE Leap or Tumbleweed.</li><li>Restart your computer and boot from the USB drive to begin the installation process.</li></ul><p><strong>Step 2: Configure Encryption During Installation</strong></p><ul><li>Once the installer starts, select your preferred language and keyboard layout.</li><li>In the partitioning setup, choose Guided Setup with Encrypted LVM.</li><li>Set a strong passphrase for encryption. This passphrase will be required every time the system boots.   - Use a mix of upper and lower case letters, numbers and special characters for optimal security.</li><li>Proceed with the installation as directed by the installer.</li></ul><p><strong>Step 3: Verify Encryption Settings</strong></p><p>After installation is complete and the system restarts, you‚Äôll be prompted to enter your encryption passphrase. Once entered, openSUSE tools will decrypt the disk and boot normally. To confirm encryption is active:</p><ul><li>Open a terminal or console.</li><li>Run the command  to verify that your disk is listed with the encryption type (e.g., ).</li></ul><p>The output might look something similar to the following:</p><div><div><pre><code>NAME        FSTYPE      FSVER LABEL UUID                                   FSAVAIL FSUSE% MOUNTPOINT\nsda                                                                                     \n‚îú‚îÄsda1      ext4        1.0     4a83v1e1-e8d2-4e38-815d-fd79j194f5   25G    30%    /\n‚îî‚îÄsda2      swap        1           d2e18c23-9w4b-4d26-p1s2-cm2sd64tx9de                \nsdb                                                                                     \n‚îî‚îÄsdb1      crypto_LUKS 1           10bb2vca-81r4-418b-a2c4-e0f6585f2c7a                \n  ‚îî‚îÄluks    ext4        1.0         8a9wka1b-7e9c-1a1f-a9f7-3c82x1e4e87f   150G    10%    /mnt/data\n</code></pre></div></div><p>While FDE protects your data, it does not prevent data loss from hardware failure or accidental deletion. Regularly back up your data to an encrypted external drive or a secure cloud service to ensure its safety.</p><p><strong>Enhanced Security for Modern Challenges</strong></p><p>Setting up full disk encryption on openSUSE not only protects your data but also aligns with the Upgrade to Freedom campaign‚Äôs mission of empowering users to maintain control over their hardware and privacy. By combining open-source software with good security practices, openSUSE ensures that users can confidently embrace a more secure digital future.</p><p>For additional guidance and community support, visit the <a href=\"https://forums.opensuse.org/\">openSUSE forums</a> or join discussions at your local Linux user group.</p><p><small> Please be aware that some hardward configurations may require additional drivers or BIOS settings adjustments for full disk encryption to fully function properly. Check your device‚Äôs compatibility and update your firmware before proceeding. </small></p>","contentLength":3905,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1iv0z6q/windows_to_linux_set_up_full_disk_encryption_on/"},{"title":"[First crate] derive_regex: construct a type by parsing a string with regular expressions","url":"https://www.reddit.com/r/rust/comments/1iuzg1i/first_crate_derive_regex_construct_a_type_by/","date":1740166287,"author":"/u/TitaniumBrain","guid":9116,"unread":true,"content":"<p>I had an idea and decided it was simple enough to publish <a href=\"https://crates.io/crates/derive-regex\">my first crate</a> and contribute to the Rust ecosystem.</p><p>I'm still relatively new to Rust (coming from a few years of Python but I fell in love with the language), so any feedback is welcome. I'm confident my code isn't , but I want to make sure I follow best practices and learn about any Rust .</p><p>Using this crate - and the associated derive proc macro - you can derive  on an enum or struct to automatically derive the  constructor method.</p><p>Copied from the readme, here's a couple examples if you don't to click away from Reddit:</p><p>```rust use derive_regex::FromRegex;</p><pre><code>pattern = r\"^(?P&lt;timestamp&gt;\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) \\[(?P&lt;level&gt;[A-Z]+)\\] (?P&lt;message&gt;.+)$\" </code></pre><p>)] struct LogEntry { timestamp: String, level: String, message: String, }</p><p>fn main() { let log = \"2025-02-20 15:30:00 [INFO] Server started successfully\"; let entry = LogEntry::parse(log).expect(\"Failed to parse log entry\"); println!(\"Parsed log entry: {:#?}\", entry); // Parsed log entry: LogEntry { // timestamp: \"2025-02-20 15:30:00\", // level: \"INFO\", // message: \"Server started successfully\", // } } ```</p><p>```rust use derive_regex::FromRegex;</p><p>enum CookingCommand { // Parses a command like \"chop 3 carrots\" #[regex(pattern = r\"chop (?P&lt;quantity&gt;\\d+) (?P&lt;ingredient&gt;\\w+)\")] Chop { quantity: u32, ingredient: String },</p><pre><code>// Parses a command like \"boil for 10 minutes\" #[regex(pattern = r\"boil for (?P&lt;minutes&gt;\\d+) minutes\")] Boil(u32), // Parses a command like \"bake at 375.0 degrees for 25 minutes\" #[regex(pattern = r\"bake at (?P&lt;temperature&gt;\\d+\\.\\d+) degrees for (?P&lt;minutes&gt;\\d+) minutes\")] Bake { temperature: f64, minutes: u32 }, // Parses a command like \"mix salt and pepper\" #[regex(pattern = r\"mix (?P&lt;ingredient1&gt;\\w+) and (?P&lt;ingredient2&gt;\\w+)\")] Mix { ingredient1: String, ingredient2: String, }, </code></pre><p>fn main() { let commands = [ \"First, chop 3 carrots\", \"Don't forget to boil for 10 minutes\", \"I guess I'll bake at 375.0 degrees for 25 minutes\", \"mix salt and pepper now\", ];</p><pre><code>for cmd in &amp;commands { if let Ok(command) = CookingCommand::parse(cmd) { match command { CookingCommand::Chop { quantity, ingredient, } =&gt; { println!(\"Chop {} {}(s)\", quantity, ingredient); } CookingCommand::Boil(minutes) =&gt; { println!(\"Boil for {} minutes\", minutes); } CookingCommand::Bake { temperature, minutes, } =&gt; { println!(\"Bake at {} degrees for {} minutes\", temperature, minutes); } CookingCommand::Mix { ingredient1, ingredient2, } =&gt; { println!(\"Mix {} and {}\", ingredient1, ingredient2); } } } else { eprintln!(\"Failed to parse command: {}\", cmd); } } // Chop 3 carrots(s) // Boil for 10 minutes // Bake at 375 degrees for 25 minutes // Mix salt and pepper </code></pre>","contentLength":2667,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Interop 2025: another year of web platform improvements","url":"https://web.dev/blog/interop-2025?hl=en","date":1740163542,"author":"/u/feross","guid":8956,"unread":true,"content":"<p>\n  Published: February 13, 2025\n</p><p>After the huge success of Interop 2024, the project returns today with a new set\nof focus areas for 2025. While we couldn't include every suggestion made this\nyear, the final list reaches across the web platform‚Äîfrom CSS to\nperformance-related features.</p><ul></ul><p>In addition, and as in previous years, there's a set of areas for investigation.\nThese are areas where we don't have enough information or tests to include as a\nfocus area, but the group feels some work should be done to get them to a stage\nwhere we can include them.</p><ul></ul><p>We're excited about all of these features and the improvements this year's\nproject will bring to the platform. And, as with <a href=\"https://web.dev/blog/interop-2024-wrapup\">last\nyear</a>, the project will make a whole set of things\nBaseline Newly available. This post shares more information about some of the\nfeatures on the list, with links to information to find out more.</p><p>Several of the features included in Interop 2025 are features that you flagged\nup as important in the State of CSS 2024 survey. They'll help you create more\nbeautiful and performant user experiences.</p><p>This feature lets you anchor a positioned element to an anchor, it's\nparticularly useful when displaying popovers.</p><h3 data-text=\"Same-document view transitions\" tabindex=\"-1\">Same-document view transitions</h3><p>Also included this year are view transitions, specifically same-document view\ntransitions, and the  CSS property.</p><h3 data-text=\"The backdrop-filter property\" tabindex=\"-1\">The  property</h3><p>The\n<a href=\"https://developer.mozilla.org/docs/Web/CSS/backdrop-filter\"></a>\nproperty has been Baseline Newly available since September 2024. It lets you\ncreate effects behind your content. For example to blur or create effects that\nyou might expect to only be available in a graphics application.</p><p>Despite being mostly interoperable, you can see from <a href=\"https://wpt.fyi/results/css/filter-effects?label=experimental&amp;label=master&amp;aligned&amp;q=backdrop-filter\">the failing tests for\n</a>that\nthere are bugs and issues in those implementations. While these issues might not\nbe a problem to everyone, we know that many of you do run into them, it'll be\ngreat to get this feature working really well.</p><p>The  element is a disclosure widget which can be expanded to reveal\nadditional content. The  element itself is Baseline Widely available.\nHowever, there are a number of related features that have been more recently\nadded <a href=\"https://developer.chrome.com/blog/styling-details\">that make  more\nuseful</a>.</p><ul><li>The  and  CSS pseudo-elements.</li><li>Using  to toggle the content instead of .</li><li>Auto-expanding the  element with find-in-page matches.</li><li>The  attribute, which hides an element until it is found\nusing the browser's find-in-page search or it is directly navigated to by\nfollowing a URL fragment.</li></ul><p>The  at-rule lets you scope your selectors to a sub-tree of the DOM, or\neven select between an upper and lower boundary in the tree. For example, the\nfollowing CSS only selects  elements inside an element with a class of\n.</p><p>In the next example, an upper and lower bound is used. The  element is\nonly selected if it's between the element with a class of  and also\noutside of the element with a class of .</p><p>Without the  event, there's no reliable way to detect that a scroll is\ncomplete. The best you could do is to use  to check if the scroll\nhas stopped for a period. This makes it more like a scroll has paused event, not\na scroll has ended event.</p><p>With the  event, the browser does all this difficult evaluation for\nyou.</p><h3 data-text=\"The text-decoration property\" tabindex=\"-1\">The  property</h3><p>The\n<a href=\"https://developer.mozilla.org/docs/Web/CSS/text-decoration\"></a>\nproperty is a shorthand for , ,\n, and <code translate=\"no\" dir=\"ltr\">text-decoration-thickness</code>. It's deemed Baseline\nWidely available, however in Safari the only unprefixed shorthand property that\nworks is . It's this that will be addressed during 2025.</p><p>The CSS <a href=\"https://developer.mozilla.org/docs/Web/CSS/writing-mode\"></a>\nproperty has a number of possible values, many of which are designed to lay out\nscripts that display vertically. Sometimes however, you want to lay out text\nvertically as part of a design, rather than for language support reasons. The\n and  values are designed for this, but have suffered\nfrom poor browser compatibility. This should be fixed during 2025.</p><p>In addition, the logical CSS properties  and \nare included. These make it possible to control what happens when content\noverflows boxes, regardless of the writing mode.</p><p><a href=\"https://web.dev/explore/learn-core-web-vitals\">Web Vitals</a> can help you quantify the\nexperience of your site and identify opportunities to improve. The Web Vitals\ninitiative aims to simplify the landscape, and help sites focus on the metrics\nthat matter most, the Core Web Vitals.</p><h4 data-text=\"Event Timing API (for INP)\" tabindex=\"-1\">Event Timing API (for INP)</h4><p>This year, the work will focus on the following features:</p><ul><li>JavaScript string builtins: to make the WebAssembly built-in string\nfunctions mirror a subset of the JavaScript String API so it can be callable\nwithout JavaScript glue code.</li><li>Resizable buffers integration: to integrate WebAssembly into JavaScript code\nthat uses resizable buffers.</li></ul><p>This year the project includes a removal from the platform. <a href=\"https://developer.mozilla.org/docs/Web/API/MutationEvent\">Mutation\nevents</a> are deprecated\nand replaced with the much more performant and Baseline Widely available\n<a href=\"https://developer.mozilla.org/docs/Web/API/MutationObserver\">Mutation Observer\nAPI</a>. Chrome\nremoved these events in Chrome 126, and this focus area is to remove them from\nall browsers.</p><p>Descriptions of the full list of features can be found in the project <a href=\"https://github.com/web-platform-tests/interop/blob/main/2025/README.md\">README</a>.\nAlso, read the posts from the other companies working on Interop 2025.</p>","contentLength":4896,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iuybup/interop_2025_another_year_of_web_platform/"},{"title":"COSMIC Alpha 6: Big Leaps Forward","url":"https://blog.system76.com/post/cosmic-alpha-6-big-leaps-forward","date":1740163210,"author":"/u/Schnurres","guid":8781,"unread":true,"content":"<div data-v-7773bbb7=\"\"><p>Our COSMIC mission continues! This month, we finished up some essential features and fixes in preparation for the upcoming beta alongside some amazing COSMIC contributors. Check out what‚Äôs new in Alpha 6, and make sure you‚Äôre fully updated to see these changes for yourself!</p><p>Desktop Zoom can now be activated in Settings &gt; Accessibility, from the Accessibility applet in the panel, or using the shortcuts Super + =, Super + -, or Super + Mouse Scroll.</p></div><div data-v-7773bbb7=\"\"><p>More <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-greeter/issues/40\">accessibility features</a> in the books! Clicking the Accessibility icon at login gives you access to various settings toggles for:</p><ul><li>Reads on-screen text aloud</li><li> Scrolling up while holding Super <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-comp/issues/853\">magnifies</a> the region of the screen where your cursor is located</li></ul><p>Navigates you to Accessibility Settings</p></div><div data-v-7773bbb7=\"\"><p>Additional accessibility features for high-contrast, color inversion and various color filters for colorblindness are being worked on soon.</p><p><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/547\">Desktop view</a> is now supported in COSMIC. Right-clicking an empty desktop and selecting ‚ÄúDesktop view options‚Äù opens a settings window for your desktop. Show or hide desktop folders, drives, or the Trash; you can also adjust icon size and spacing between icons from this window. A fix for the window appearing below other windows will arrive in a later update. Files and folders can also be <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/597\">dragged</a> between the desktop view and COSMIC Files.</p></div><div data-v-7773bbb7=\"\"><p><strong>Additional Scaling Options</strong></p><p>An additional scaling setting has been added to scale the screen slightly, from 5% to 20% larger. For example, on a display set to 125% scaling, those desiring larger text can use this new setting to increase scaling to 130%, 135%, 140%, or 145%.</p></div><div data-v-7773bbb7=\"\"><p>Workspaces received some updates to really make the feature sparkle. For starters, you can now <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-workspaces-epoch/issues/34\">scroll between workspaces</a> in the overview as a quick and easy way of navigating to your intended destination. Clicking on the preview of the current workspace or empty space in the workspace overview will allow you to <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-workspaces-epoch/issues/49\">exit the workspace view</a>.</p><p>Previews for horizontal workspace now include name and number. Workspace previews on rotated displays will show the <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-workspaces-epoch/issues/17\">correct orientation</a>. The last workspace is now removed if it follows another <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-workspaces-epoch/issues/83\">empty workspace</a>.</p></div><div data-v-7773bbb7=\"\"><p>Additionally, <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-workspaces-epoch/issues/89\">minimized windows</a> can now be dragged and dropped between workspaces, while windows can be moved to another display by dropping them in the <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-workspaces-epoch/issues/53\">workspace overview</a>. Dragging a window <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-workspaces-epoch/issues/41\">out of a stack</a> will match expectations and no longer move the whole stack. Window titles in the overview are now at the top left of the window and <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-workspaces-epoch/issues/56\">match the users theme</a>. Additional workspace features, including pinned workspaces, will arrive in a future update.</p><p><strong>Windows Gravitate to Edges</strong></p><p>Toggling on ‚ÄúFloating windows gravitate to nearby edges‚Äù in Window Management Settings will automatically align a <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-comp/pull/1189\">window‚Äôs edge</a> to the adjacent screen border when dragged close to it, removing the struggle of aligning it with the edge manually.</p><p>If a search in the Launcher yields more than eight entries, users can now <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-launcher/issues/238\">scroll</a> to see the additional options. In addition, the Launcher has been updated to trigger a <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-launcher/issues/126\">countdown timer</a> whenever Power Off, Restart, and Log Out are selected, matching the behavior of the Power applet.</p></div><div data-v-7773bbb7=\"\"><p>File path completion is now in COSMIC Files. Hitting the Down arrow when typing a file path into the search bar will automatically finish the file path you‚Äôre searching for. Meanwhile, <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/728\">copying a file</a> allows pasting of the file path in other applications. COSMIC Files uses <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/732\">Home and End keys</a> for navigating the app. You can now compress and extract <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/468\">password protected zip files</a> and <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/190\">drag selecting</a> will scroll the content window.</p><p>Copy/paste using the middle mouse button has been implemented. Sweet convenience.</p><p>A <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-player/issues/52\">nav bar</a> has been added for viewing folders in a tree view to display the video files available to open in the Media Player. File menu options have also been completed:</p></div><div data-v-7773bbb7=\"\"><p>When a music file is playing, the <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-player/issues/56\">Media Player</a> image will display the song title, album, artist, and year released. Down the line we‚Äôd like to explore adding further metadata, such as album artwork and song lyrics.&nbsp;</p><p>Mpris control has been added to show and control currently-playing media in the sound applet, and the scrubber now moves to a second line for improved single-column usability.</p><p>A <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-edit/issues/128\">Revert all changes</a> feature has been added to COSMIC Edit to revert your file back to the most recent saved state. If you decide to scrap everything or start a new file from scratch, go to <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-edit/issues/41\">File &gt; Close Project</a> to remove the project from the NavBar and bring up a new document and tab. When multiple tabs are open, <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-edit/issues/123\">cycle project tabs</a> using Ctrl+Tab and Ctrl+Shift+Tab shortcuts.</p><p><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-edit/pull/311\">Zoom</a> has also been implemented. Zoom in and out from the View menu, or using Ctrl + or Ctrl - shortcuts. Reset back to default using Ctrl + 0.</p><p>Opens Sans replaces Fira Sans as the <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/libcosmic/pull/809\">default font</a> for COSMIC. The team liked Open Sans for its better legibility, glyph and language support, and a more modern aesthetic. Likewise, Noto Sans Mono will be used for the default monospace font.</p><p>Memory usage has been greatly reduced in a number of areas, including <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-applets/pull/796\">minimize</a>, <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/pull/789\">COSMIC Files</a>, and <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-panel/issues/336\">workspaces</a>. A related update made to libcosmic should prevent memory fragmentation. In addition, optimizations to cosmic-text and <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/freedesktop-icons/pull/4\">freedesktop-icons</a> have reduced memory usage across all COSMIC apps and applets.</p><p><strong>A Whole Swarm of Bug Fixes‚Ä¶and More!</strong></p><ul><li>Fixed a bug with server-side decorations that caused the cursor to <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-comp/issues/1071\">drag a window</a> after a single click</li><li>When clicking an app icon of an app with multiple windows opened, <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-applets/issues/456\">window previews</a> now adapt to the size and shape of the window</li><li>Implemented a fix in <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-comp/issues/680\">cosmic-comp</a> related to keyboard grabbing after a window is focused</li><li>Implemented behavior to <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/pull/735\">COSMIC Files</a> for exiting the context menu</li><li><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/308\">COSMIC Files</a> now changes view away from the external drive after the drive is mounted and removed</li><li>Implemented a fix for <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/766\">COSMIC Files</a> attempting to read an unreadable .hidden file</li><li>Fixed a crash involving the <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/xdg-desktop-portal-cosmic/issues/121\">file picker</a> related to a11y in libcosmic</li><li><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-term/issues/68\">COSMIC Terminal</a> now uses a hollow block cursor design when the window is unfocused</li><li>Removed Spell Check menu option from <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-edit/issues/300\">COSMIC Edit</a>, to be returned once the feature exists</li><li>In <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-edit/issues/191\">COSMIC Edit</a>, ‚ÄúFind‚Äù searches now highlight all occurrences, and the currently selected item is highlighted at a higher opacity</li><li>Scrolling now occurs as expected when dragging to highlight text in <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-edit/issues/154\">COSMIC Edit</a></li><li>Saving a root or read-only file in <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-edit/issues/249\">COSMIC Edit</a> now prompts the user for their password, removing the need to run the application as root</li><li><a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-screenshot/issues/40\">Screenshot tool</a> now respects the user‚Äôs time zone when naming screenshot files</li><li>Implemented a fix preventing icons from disappearing from the <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-screenshot/issues/18\">screenshot tool</a></li><li>Fixed a bug preventing the Delete key from moving a <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-files/issues/592\">desktop file</a> to the Trash</li><li>Implemented a fix for a bug causing <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-session/issues/103\">Steam</a> to crash</li><li>Fixed an issue causing some Radeon RX users to be unable to <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-epoch/issues/1447\">log in</a></li><li>The context menu in <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-settings/issues/953\">COSMIC Settings</a> now closes when another option is selected in the NavBar</li><li>Implemented the ability to import environment variables from <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-session/pull/106\">systemd</a></li><li>Fixed a regression with <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/libcosmic/issues/656\">libcosmic</a> affecting the ComboBox widget</li><li>Added a <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-panel/issues/190\">slight delay</a> when the cursor hovers from one applet to the next to account for intent</li><li>Added support for using the middle mouse button to <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-term/issues/49\">copy/paste</a></li><li>Clicking next/previous month in the <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/libcosmic/issues/632\">calendar widget</a> no longer selects the day</li><li>Resolved a bug with <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-settings/issues/798\">Firefox</a> not recognizing it‚Äôs the default web browser when it‚Äôs not set as the default mail client</li><li>Removed WPS suggestion from the <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-applets/pull/793\">WiFi applet</a> when WPS is not supported</li><li>Added support to <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/cosmic-bg/pull/68\">cosmic-bg</a> for compositors without fractional scaling support</li><li>Pop!_OS 24.04 Linux kernel updated to version <a target=\"_blank\" rel=\"noopener\" href=\"https://github.com/pop-os/linux/pull/343\">6.12.10</a></li></ul><p>Head to the <a target=\"_blank\" rel=\"noopener\" href=\"https://system76.com/cosmic\">COSMIC page</a> for a fresh install of Alpha 6. If your system has an NVIDIA GPU, remember to install the NVIDIA ISO. Have fun and break things!</p></div>","contentLength":7754,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1iuy6v6/cosmic_alpha_6_big_leaps_forward/"},{"title":"Meanwhile at the Pentagon","url":"https://www.reddit.com/r/artificial/comments/1iuwy03/meanwhile_at_the_pentagon/","date":1740160167,"author":"/u/MetaKnowing","guid":8804,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[R] MLGym: A New Framework and Benchmark for Advancing AI Research Agents","url":"https://www.reddit.com/r/MachineLearning/comments/1iuwuyu/r_mlgym_a_new_framework_and_benchmark_for/","date":1740159974,"author":"/u/Rybolos","guid":8853,"unread":true,"content":"<p>We introduce Meta MLGym and MLGym-Bench, a new framework and benchmark for evaluating and developing LLM agents on AI research tasks. This is the first Gym environment for machine learning (ML) tasks, enabling research on reinforcement learning (RL) algorithms for training such agents. MLGym-bench consists of 13 diverse and open-ended AI research tasks from diverse domains such as computer vision, natural language processing, reinforcement learning, and game theory. Solving these tasks requires real-world AI research skills such as generating new ideas and hypotheses, creating and processing data, implementing ML methods, training models, running experiments, analyzing the results, and iterating through this process to improve on a given task. We evaluate a number of frontier large language models (LLMs) on our benchmarks such as Claude-3.5-Sonnet, Llama-3.1 405B, GPT-4o, o1-preview, and Gemini-1.5 Pro. Our MLGym framework makes it easy to add new tasks, integrate and evaluate models or agents, generate synthetic data at scale, as well as develop new learning algorithms for training agents on AI research tasks. We find that current frontier models can improve on the given baselines, usually by finding better hyperparameters, but do not generate novel hypotheses, algorithms, architectures, or substantial improvements. We open-source our framework and benchmark to facilitate future research in advancing the AI research capabilities of LLM agents.</p>","contentLength":1468,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[D] Dimensionality reduction is bad practice?","url":"https://www.reddit.com/r/MachineLearning/comments/1iuwgcu/d_dimensionality_reduction_is_bad_practice/","date":1740159022,"author":"/u/Ready_Plastic1737","guid":8854,"unread":true,"content":"<p>I was given a problem statement and data to go along with it. My initial intuition was \"what features are most important in this dataset and what initial relationships can i reveal?\"</p><p>I proposed t-sne, PCA, or UMAP to observe preliminary relationships to explore but was immediately shut down because \"reducing dimensions means losing information.\"</p><p>which i know is true but..._____________</p><p>can some of you add to the ___________? what would you have said?</p>","contentLength":451,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Godfather Yoshua Bengio says it is an \"extremely worrisome\" sign that when AI models are losing at chess, they will cheat by hacking their opponent","url":"https://www.reddit.com/r/artificial/comments/1iuvosh/ai_godfather_yoshua_bengio_says_it_is_an/","date":1740157177,"author":"/u/MetaKnowing","guid":8719,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rust ü¶Ä DataFrame Library Elusion v3.3.0 is released üöÄ FIXED NORMALIZATION","url":"https://www.reddit.com/r/rust/comments/1iuvnrr/rust_dataframe_library_elusion_v330_is_released/","date":1740157108,"author":"/u/DataBora","guid":9115,"unread":true,"content":"<p>Elusion is a high-performance DataFrame / Data Engineering / Data Analysis library designed for in-memory data formats such as CSV, JSON, PARQUET, DELTA, as well as for ODBC Database Connections for MySQL and PostgreSQL, as well as for Azure Blob Storage Connections, as well as for creating JSON files from REST API's which can be forwarded to DataFrame.</p>","contentLength":355,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Best Practices for Consistent API Error Handling","url":"https://zuplo.com/blog/2025/02/11/best-practices-for-api-error-handling","date":1740157047,"author":"/u/ZuploAdrian","guid":8852,"unread":true,"content":"<p><strong>Clear and consistent API error handling is crucial for improving developer\nexperience and reducing debugging time.</strong> Poor practices, like unclear messages\nor misuse of HTTP status codes, can frustrate developers and lead to increased\nsupport tickets. This guide covers actionable strategies to standardize API\nerror handling, including:</p><ul><li><strong>Use of HTTP Status Codes:</strong> Ensure accurate mapping (e.g., 400 for client\nerrors, 500 for server issues).</li><li><strong>Structured Error Responses:</strong> Follow RFC 9457 (Problem Details) standards\nfor clear, actionable error details.</li><li> Write brief, helpful, and secure messages.</li><li><strong>Protocol-Specific Practices:</strong> Tailor error handling for REST, GraphQL, and\ngRPC APIs.</li></ul><p>To address the challenges highlighted earlier, you can apply these\nwell-established methods.</p><p>HTTP status codes are your first tool for communicating errors. The key is to\nuse them accurately, rather than relying on generic codes.</p><table><thead><tr></tr></thead><tbody><tr><td>401 Unauthorized, 422 Unprocessable Entity</td></tr><tr><td>500 Internal Error, 503 Service Unavailable</td></tr></tbody></table><p>You can find a full list of status codes\n<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\">on MDN</a>, but here's a\nfew helpful docs we've written in the past that go into more depth:</p><p>For consistent error reporting, modern APIs should follow the\n<a href=\"https://www.rfc-editor.org/rfc/rfc9457.html\">RFC 9457</a> Problem Details\nspecification. This is the successor to the popular\n<a href=\"https://www.rfc-editor.org/rfc/rfc7807\">RFC 7807</a> draft. For an in-depth\nunderstanding of this format, check out our\n<a href=\"https://zuplo.com/blog/2023/04/11/the-power-of-problem-details\">full problem details guide</a>. In\ncase you're short on time - here's a quick overview:</p><p>The problem details response is sent back as a JSON body with the following\nproperties:</p><ul><li>: A URI that identifies the specific error type. This\nhelps clients understand the error and potentially find more information or\ndocumentation about it. Ideally, this URI should be stable and not change over\ntime.</li><li>: A short, human-readable summary of the problem. This\nshould be a brief description that concisely conveys the error. The title\nshould not change for a given \"type\" URI.</li><li><strong>status (integer, optional)</strong>: The HTTP status code generated by the origin\nserver for this occurrence of the problem. This helps clients understand the\nnature of the error and how it relates to the HTTP protocol.</li><li><strong>detail (string, optional)</strong>: A more detailed, human-readable explanation of\nthe problem. This can include specific information about the error and what\nmight have caused it. The \"detail\" field is intended to provide context and\nsuggestions to clients on how they might address the problem.</li><li><strong>instance (string, URI, optional)</strong>: A URI that identifies the specific\noccurrence of the problem. This can help clients and servers correlate and\ntrack individual instances of errors.</li></ul><p>Here's what a standardized error response might look like:</p><pre tabindex=\"0\"><code></code></pre><p>This response would be accompanied with the following headers and status code:</p><pre tabindex=\"0\"><code></code></pre><p>Here's a video that shows you how to send these error back in practice. It's in\n.Net/C# but the concepts are broadly applicable:</p><p>When evolving error schemas, it's crucial to make changes without disrupting\nexisting clients. Here's how you can manage this:</p><ul><li>Add optional fields instead of altering existing ones</li><li>Preserve legacy formats during transitions</li><li>Implement semantic versioning for your endpoints</li></ul><p>API management tools like Zuplo are really handy when trying to bring\nconsistency across your error formats, and are especially useful when trying to\ntransition all of your APIs over from one format to another.</p><p>Creating effective API error messages means providing useful guidance while\nkeeping security in mind. Google's AIP-193 guidelines\n<a href=\"https://google.aip.dev/193\">[4]</a> recommend using a structured format with\nplain, straightforward language that remains technically accurate.</p><p>The goal is to make error messages both clear and actionable. Here's a\ncomparison of good and bad examples:</p><table><thead><tr></tr></thead><tbody><tr><td>\"Invalid email format in 'user_email' field\"</td><td>\"ValidationError: field_23\"</td></tr><tr><td>\"Request to /api/v1/users failed\"</td></tr></tbody></table><p>If you've ever used Azure, many of their system errors demonstrate this\napproach, for example:</p><pre tabindex=\"0\"><code></code></pre><p>Maintaining security while providing useful error feedback involves a few key\npractices:</p><ul><li> to prevent leaks.</li><li><strong>Standardize authentication errors</strong> for consistency.</li><li> to avoid exposing vulnerabilities.</li></ul><p>For example, following RFC 9457 guidelines, a secure error response might look\nlike this:</p><pre tabindex=\"0\"><code></code></pre><p>This is another area where using an API gateway/API management tool is useful.\nYou can monitor your outbound responses and scan them for PII or other sensitive\ninformation/keywords using a regex. A programmable gateway (ex. Zuplo) will even\nlet you rewrite your response bodies to strip out sensitive data.</p><div><div><p>Over 10,000 developers trust Zuplo to secure, document, and monetize their APIs</p><a href=\"https://zuplo.com?utm_source=blog&amp;utm_medium=inline-cta\">Learn More</a></div></div><p>Let's dive into how different API protocols handle errors, building on the\nstandards discussed earlier.</p><p>REST APIs rely on HTTP status codes paired with structured error payloads. A\ncommon standard for this is , which ensures a\nconsistent format across endpoints. This method also supports content\nnegotiation between JSON and XML, keeping the structure consistent across\ndifferent formats.</p><p>GraphQL handles errors differently. It always responds with a  status\ncode, even when errors occur. Errors are communicated through an  array,\nwhich allows for partial success. For instance, GitHub's GraphQL API might\nreturn:</p><pre tabindex=\"0\"><code></code></pre><p>This approach allows for returning valid data alongside error details.</p><p>gRPC uses a predefined set of numeric status codes (ranging from 0 to 16) for\nerror handling, aligned with . Errors include structured details\nfor better context. Here's an example:</p><pre tabindex=\"0\"><code></code></pre><table><thead><tr></tr></thead><tbody><tr><td>Standard HTTP success codes</td></tr><tr></tr><tr></tr></tbody></table><p>Each protocol has its own approach, but they all follow two key principles:\n<strong>machine-readable error codes</strong> and . This ensures\nerrors are both understandable and actionable.</p><p>For cross-protocol APIs, API gateways can simplify error handling. They provide\nunified error schema management and automate transformations between\nprotocol-specific formats. This helps maintain consistency while respecting the\nconventions of each API type.</p><p>Effective error management relies on consistent monitoring and testing to uphold\nusability standards outlined in earlier protocols. This process builds on\nprotocol-specific error conventions to ensure smooth handling across systems.</p><p>A centralized error code system can ensure uniformity across distributed\nservices. For example, Google uses the  format, which\nenforces standardized error structures with both machine-readable codes and\nhuman-readable messages <a href=\"https://google.aip.dev/193\">[4]</a>.</p><p>In multi-service architectures, two main approaches are common:</p><table><thead><tr></tr></thead><tbody><tr><td>Ensures uniform error codes, Acts as a single source of truth</td><td>Requires strict oversight</td></tr><tr><td>Distributed with Prefixes</td><td>Allows team independence, Enables quicker updates</td><td>Demands thorough documentation</td></tr></tbody></table><p>Many organizations find that combining these methods provides the best results.</p><p>Key metrics to monitor include\n<a href=\"https://raygun.com/blog/best-error-monitoring-tools/\">[2]</a><a href=\"https://techcommunity.microsoft.com/discussions/appsonazure/best-practices-for-api-error-handling-a-comprehensive-guide/4088121\">[3]</a>:</p><ul><li><strong>Mean Time to Acknowledge (MTTA)</strong> errors: Target under 30 minutes.</li><li>: Should remain below 5% after fixes.</li><li><strong>95th percentile error resolution time</strong>: A critical benchmark for resolution\nspeed.</li><li><strong>User-impacting error ratio</strong>: Measured per 10,000 requests.</li></ul><p>Tools like <a href=\"https://sentry.io/\">Sentry</a> support distributed tracing in over 15\nlanguages, while <a href=\"https://raygun.com/\">Raygun</a> offers deployment correlation to\npinpoint issues <a href=\"https://raygun.com/blog/best-error-monitoring-tools/\">[2]</a>.</p><p>Testing ensures compliance with HTTP status codes and response formats covered\nin earlier sections. Error testing is typically done manually using tools like\nPostman - but you should definitely invest in automation as your API grows and\nevolves. To test specific errors, you should invest in automated\n<a href=\"https://zuplo.com/blog/2025/02/01/end-to-end-api-testing-guide\">end-to-end API testing</a> using\ntools like Playwright and StepCI.</p><p>If you have schematized errors, you can perform\n<a href=\"https://zuplo.com/blog/2024/07/19/verify-json-schema\">schema validation</a> on your live responses\nto ensure they adhere to those schemas. When response validation is combined\nwith an <a href=\"https://zuplo.com/blog/2024/09/25/mastering-api-definitions\">API design specification</a>\nlike OpenAPI to enforce outputs match what's documented, it's known as\n.</p><p>Effective API error handling builds on the protocol-specific conventions\ndiscussed earlier. Two key goals are ensuring <strong>consistent response formats</strong>\nand reducing repeat client errors\n<a href=\"https://raygun.com/blog/best-error-monitoring-tools/\">[2]</a><a href=\"https://blog.postman.com/best-practices-for-api-error-handling/\">[5]</a>.</p><p>Key requirements include:</p><ul><li><strong>Standardized Response Structure</strong>:<ul><li>Machine-readable error codes</li><li>Clear, human-readable messages</li><li>Links to relevant documentation</li><li>Request correlation IDs for troubleshooting</li></ul></li><li><strong>Security-Focused Practices</strong>:<ul><li>Prevent exposure of sensitive data by adhering to security guidelines\noutlined in the Writing Clear Error Messages section</li><li>Use appropriate status codes</li><li>Follow established security best practices</li></ul></li></ul><p>To create a reliable error-handling system, follow these four phases:</p><ol><li>Use an\n<a href=\"https://zuplo.com/blog/2025/01/27/8-api-monitoring-tools-every-developer-should-know\">API monitoring tool</a>\nto analyze errors at the endpoint level. This helps identify inconsistencies\nand establish a baseline for improvement\n<a href=\"https://raygun.com/blog/best-error-monitoring-tools/\">[2]</a><a href=\"https://blog.postman.com/best-practices-for-api-error-handling/\">[5]</a>.</li><li>Introduce centralized error-handling middleware to enforce the newly defined\nstandards. Often, an API gateway plays this role.</li><li>Use error tracking tools to evaluate the system‚Äôs performance. Track metrics\nlike error recurrence rates, resolution times, and Mean Time to Acknowledge\n(MTTA).</li></ol><p>These steps align with earlier recommendations for policy-driven error handling\nand offer practical ways to enhance your API's reliability.</p><p>Handling API errors effectively requires a clear and structured approach. This\ninvolves combining standard protocols with additional application-specific\ninformation to provide clarity and maintain security.</p><p><strong>1. Protocol-Specific Handling</strong></p><p>Each API protocol has its own method for managing errors. Here‚Äôs how to handle\nerrors for some common protocols:</p><ul><li>: Use HTTP status codes alongside detailed error messages in the\nresponse body.</li><li>: Include error arrays in the response, allowing for partial\nsuccess when appropriate.</li><li>: Utilize standardized status codes with structured error details.</li></ul><p><strong>2. Security Best Practices</strong></p><p>To keep your API secure, follow these guidelines (as outlined in the \"Security\nin Error Messages\" section):</p><ul><li>Use generic error messages for authentication failures to prevent revealing\nsensitive information.</li><li>Avoid exposing internal system details in error responses.</li><li>Filter sensitive data on the server side before sending error responses.</li></ul><p><strong>3. Monitoring and Consistency</strong></p><p>Set up monitoring tools, such as distributed tracing, to identify and analyze\nerror patterns. Use\n<a href=\"https://zuplo.com/blog/2024/12/16/api-gateway-hosting-options\">API gateways</a> to\nenforce consistent error formats and schemas across your system for better\nmanagement and debugging\n<a href=\"https://raygun.com/blog/best-error-monitoring-tools/\">[2]</a><a href=\"https://techcommunity.microsoft.com/discussions/appsonazure/best-practices-for-api-error-handling-a-comprehensive-guide/4088121\">[3]</a>.</p>","contentLength":10121,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iuvmvv/best_practices_for_consistent_api_error_handling/"},{"title":"GitHub Traffic - CLI Edition","url":"https://postimg.cc/XXWK9gzB","date":1740155625,"author":"/u/manifoldjava","guid":8851,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iuv282/github_traffic_cli_edition/"},{"title":"I built a new playground for Go, Pt, TS and more other, with Postgres... It supports program arguments, pretty output for JSON and I will add a lot feature soon","url":"https://codiew.io/ide","date":1740151971,"author":"/u/Halabooda","guid":8831,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iutm6h/i_built_a_new_playground_for_go_pt_ts_and_more/"},{"title":"Borrow Checker Trauma","url":"https://www.reddit.com/r/rust/comments/1iuthsl/borrow_checker_trauma/","date":1740151657,"author":"/u/xwaxes","guid":8784,"unread":true,"content":"<p>I am using the term ‚Äòborrow checker trauma‚Äô for lack of a better word. A bit of context first; I have been using Rust for my personal web projects extensively but use Rails at work. </p><p>So the problem is, whenever I am working on work projects and want to perform two or more operations on a variable, especially if I am passing it around or returning it, I always find myself taking a step back to consider if the ownership has moved before I remember that I am on Ruby and that doesn‚Äôt apply. </p><p>Has anyone experienced this in other languages or on their daily workflow?</p>","contentLength":571,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Certifications for software architects","url":"https://www.cerbos.dev/blog/certifications-for-enterprise-architects-domain-solutions-architects-software-engineers","date":1740142976,"author":"/u/West-Chard-1474","guid":8598,"unread":true,"content":"<p>Over the years, I‚Äôve noticed that no one can quite settle on how important certification is. All it takes is one look at the Software Architecture subreddit and you‚Äôll see people asking about certificates only to be told they‚Äôre both useless and useful.</p><p>When I was working with Lemon.io (a developer marketplace with 80k+ developers), I got to see firsthand how certification affected their careers. So when I saw this topic start to pop up again (without any real answers), I decided to dive into research to see if my experience at Lemon.io still held true for architects.</p><h2>The value of certification</h2><p>Assuming I‚Äôm talking to architects with a lot of experience, what I will say is that certification doesn‚Äôt replace experience, but it does complement it really well. And, it can be a strong differentiator from your peers.</p><p>I‚Äôm going to try a metaphor here. If your career is a burger, your experience is the patty and certificates are the condiments. Some people prefer their burgers with bacon, cheese, or even an egg. Depending on what your career goals are, you‚Äôll want to add different condiments to your ‚Äòburger‚Äô. But keep in mind, the most important thing will always be the meat, a.k.a your experience.</p><p>Deciding if certification is right for you is the first step. The next step is asking the question: what is the right certification for you?</p><p>I loved the Role Based Roadmap from Mumshad Mannambeth, founder &amp; CEO at KodeKloud on navigating the certification paths <a href=\"https://www.linkedin.com/posts/mmumshad_kodekloud-cloudcomputing-aws-activity-7110238676915273728-U2X8/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAB-THdoBNL-y76_DeuYlNKmEH_yOiRzPAjc\">(you can find it here)</a>.</p><p>It inspired me to do something similar but focused on Architects. Below, you‚Äôll find 12 of the most popular architectural certificates you can choose to upgrade your career, and add more ‚Äútrust badges‚Äù to your CV, LinkedIn profile, or freelancer profile.</p><p>Each has its own focus and value it can add depending on your career goals and role:</p><table><thead><tr><th><strong>Certifications for Enterprise Architects</strong></th><th><strong>Certifications for Domain Solutions Architects</strong></th><th><strong>Software Architecture, Governance, and Infrastructure Certification</strong></th></tr></thead><tbody><tr><td>AWS Certified Solutions Architect</td></tr><tr><td>Google Professional Cloud Architect</td></tr><tr><td>Zachman Certified - Enterprise Architect</td><td>Microsoft Certified: Azure Solutions Architect Expert</td></tr><tr><td>Certified Enterprise Architect (CEA) Black Belt Program</td><td>Red Hat Certified Architect (RHCA)</td></tr></tbody></table><p>Recognized globally, <a href=\"https://www.credly.com/org/the-open-group/badge/the-open-group-certified-togaf-9-certified\">this certificate</a> covers the TOGAF framework for designing, planning, implementing, and governing enterprise information technology architecture. So if you are working on an enterprise-wide architecture or want to switch to that direction, it can be useful.\nUnlike the certifications below, this is a whole ecosystem that builds on itself. So it is a significant investment. However, if you‚Äôre working in, or looking to work in, the governmental sector or with large corporations, this may be a good choice for you. Keep in mind, however, that while it may look cheap, the cost does not include training, which is provided by TOGAF-accredited partners, each of whom sets their own price.</p><p>The comment below sums up my research into TOGAF 9 really well:</p><p><strong>Best for Software Architects working in large organizations</strong>: Enterprise Architects,  Business Architects, Solutions Architects, and IT Strategy Consultants with experience in strategic planning, We had a few Enterprise Architects with TOGAF 9 certification at Lemon.io and it was a nice value-add to their profiles. It is worth mentioning that their rates were in the top tier üôÇ.</p><ul><li>13 Level 1 Learning Units</li><li>27 Level 2 Learning Units</li></ul><p>Testing: Two-stage testing, including TOGAF 9 Part 1 and TOGAF 9 Part 2 examinations</p><table><thead><tr></tr></thead><tbody><tr><td>$360 USD per exam (requires two exams)</td><td>English, Simplified Chinese, Spanish (Latin American), French</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: TOGAF 9 certificate does not expire.</p><p>ITIL is one of the most popular certification systems in the world, with more than two million certified specialists in the world. The <a href=\"https://www.axelos.com/certifications/itil-service-management\">Master certification</a> is the highest level of ITIL certifications and requires passing all four previous certifications before challenging it. To achieve the master certification you have to pass an assessment to validate your ability to apply ITIL frameworks to real-world business scenarios. So, experience working with the ITIL principals and practices as an enterprise software architect is required.</p><p>ITIL is not a training or testing provider but works with accredited partners for each. That means the pricing is dependent on your provider. The nice thing is, that it is one of the few large accreditations you can achieve through self-study.</p><p>If you want to chat with peers who are planning to become ITIL Masters, there is an active subreddit called <a href=\"https://www.reddit.com/r/ITIL_Certification/\">ITIL_Certification</a>.</p><p>: Governance &amp; Compliance Architects, Governance and Compliance Managers, Enterprise Architects.</p><p>Five distinct levels to progress through: Foundation -&gt; Practitioner ‚Äì&gt; Intermediate -&gt; Expert -&gt; Master. Each level has its own training and requirements.</p><ul><li>Attend a training course with an accredited training organization, which will include the exam as part of the course.</li><li>Self-study using the core manual, then book an exam directly with PeopleCert.</li></ul><table><thead><tr></tr></thead><tbody><tr><td>Dependent on your chosen training/testing partner.</td><td>All 4 previous ITIL certifications, including ITIL Expert certification</td><td>5 years in IT leadership, management, or higher management advisory levels.</td><td>English, Brazilian Portuguese, Chinese, Dutch, French, German, Italian, Japanese, Polish, Spanish, Thai</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: Certification is valid for 3 years. You can renew your certification by retaking the exam or by earning a new certification.</p><h2>Zachman Certified - Enterprise Architect</h2><p><a href=\"https://zachman-feac.com/\">This certification</a> covers the Zachman Framework for designing and maintaining Enterprise Architectures, which aligns IT with business goals. The training is focused on high-level enterprise planning, including Enterprise Architecture principles, strategy formulation, and practical application, rather than project or solutions architecture. This makes it ideal for those who need a structured approach to solve enterprise challenges.</p><p>This is another multi-level certification option. Each level builds on the one before it, which makes it a very comprehensive course. And, in my humble opinion, very expensive.</p><p>: Enterprise Architects, Business Architects, and IT Consultants with an Enterprise Architecture focus.</p><p>Four levels available: Associate, Practitioner, Professional and Educator (last one only required for those who want to teach the course).</p><p>Training: Two weeks of online prep work, and three days of live instruction</p><p>Testing: Two-hour, online exam (passing grants level 1 Associate)</p><p>Case study: Delivering a case study provides level 2 Practitioner, and a second case study provides level 3 Professional</p><table><thead><tr></tr></thead><tbody><tr><td>$2999 USD covers level 1 &amp; 2 (regional pricing is available)</td><td>Each level requires certification in the preceding level</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: The certificate expires in 3 years. Recertification costs $99 USD.</p><h2>Certified Enterprise Architect (CEA) Black Belt Program (Owned by Zachman now)</h2><p>Zachman now owns CEA, so I decided to add this certification under the Zachman banner. Just like Zachman, this is a three-step course, except the naming convention is designed to make you feel like you‚Äôre in a martial art, which is cool. It‚Äôs also $7,000 more, which is not as cool, but that does mean you get to skip the yellow and green belt and go straight for the black belt.</p><p>Designed to develop Enterprise Architects through hands-on training and real-world projects, <a href=\"https://zachman-feac.com/\">this program</a> will prepare you for leadership roles in Enterprise Architecture. This program is built on ISO standards and focuses on the practical application of frameworks, tools, and methodologies.</p><p>: (Very rich people) Senior Enterprise Architect, IT Director with EA experience, Chief Architect, Enterprise Architect with 10+ years experience, Enterprise Architecture Consultant.</p><ul><li>Accelerated Path of 12 Weeks: Five individual courses taught in parallel over twelve weeks.</li><li>Progressive Path that is self-paced: Five individual online courses taken at your own pace over 24-30 weeks.</li></ul><p>The <a href=\"https://iasaglobal.org/Public/Public/Learn/Training_and_Certifications.aspx\">IASA Global certification</a> is a vendor-independent program for Business Technology Architects. The training has four stages that roughly align with your career stage. For Enterprise Architects, the professional (3rd) tier is the most useful  The previous two tiers are for those in earlier stages of their career. The training is based on practical experience with a focus on Enterprise Architecture (EA), Software Architecture (SA), Solution Architecture (SolA), Infrastructure Architecture (IA) and Business Architecture (BA).</p><p>Unlike most tiered options, IASA allows you to challenge each level even if you haven‚Äôt attained the certification under it. So if you‚Äôve progressed in your career far enough that you don‚Äôt think a foundational certification is valuable, and you don‚Äôt want to work your way through 3 tiers you already fully understand, IASA may be the answer for you.</p><p>: Senior architects and business analysts aiming to bridge the gap between business and technology.</p><p>Four levels of certification:</p><ul><li>Professional (recommended for enterprise-level architects) - achieved by presenting to a board of CITA-D certified architects and answering any questions. 2 hrs allotted for the exam.</li><li>Distinguished - achieved by presenting to a board of CITA-D certified architects and answering any questions. 2.5 hrs allotted for the exam.</li></ul><p>Testing: Online or onsite testing is available</p><table><thead><tr><th> (for professional tier)</th></tr></thead><tbody><tr><td> Exam: $425 USD  N/A  Exam + prep: $2,000 USD  Exam + prep: $2,800 USD</td><td>A minimum of 10 years in the industry as a practicing architect.  Extensive documentation is required.</td><td>CITA-Associate level certificate is recommended but not mandatory.</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: Requires individuals to maintain an active Full Iasa Membership and collect at least 80 hours of Continuing Education Units bi-annually (based on their website).</p><h2>The Open Group ArchiMate 3 Certification</h2><p>ArchiMate was mentioned a lot over Reddit. <a href=\"https://www.opengroup.org/certifications/archimate\">The Open Group ArchiMate 3</a> doesn‚Äôt teach you how to be an EA but rather focuses on how to communicate better as an EA by teaching ArchiMate‚Äôs modelling language. This language is designed to remove ambiguity from the description, analysis, and visualization of Enterprise Architectures.</p><p>The content of the course is designed to complement TOGAF, which makes it useful for Enterprise Architects who already work in a TOGAF framework. They aren‚Äôt however, the same thing.</p><p>: Enterprise Architects</p><p>Training: Online self-study available, or attend an accredited training course (Accredited Training Courses provide an exam voucher).</p><ul><li>ArchiMate 3 Part 1 offers foundation certification (60 min time limit for 40-question, multiple choice exam. Passing score: 60%)</li><li>ArchiMate 3 Part 2 offers practitioner certification (90 min time limit for 8-question, scenario-based and complex multiple choice exam. Passing score: 65%)</li></ul><p>Online or in-person proctored exams available depending on provider</p><table><thead><tr></tr></thead><tbody><tr><td>Training cost depends on the provider.  Each exam costs $360 USD.</td><td> None  Foundation certification or pass Part 1 exam on the same day with the same provider.</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: The certification does not expire, which is very cool.</p><h2>AWS Certified Solutions Architect</h2><p><a href=\"https://aws.amazon.com/certification/certified-solutions-architect-associate/?nc1=f_ls\">The AWS certification</a> is a great starting point for architects or senior Software Engineers with AWS Cloud or strong on-premises IT experience. It covers the design and optimization of AWS cloud-based software and shows you can handle complex multi-service architectures, which is crucial as more companies move to the cloud. The exam tests real-world scenarios you would face designing large-scale systems, including hybrid architectures, multi-region deployments, and cost optimization at scale. Basic familiarity with programming concepts will help, but you don‚Äôt need hands-on experience with code.</p><p>This is the only provider-specific certificate that offers a more in-depth, self-directed training option for a price. Of course, you don‚Äôt have to take that option. If you‚Äôre confident, you can take the free training and then challenge the test. However, the test is also the cheapest among these certifications, so it offsets the overall cost a little bit.</p><p>During my research, I found quite a few posters, including <a href=\"https://www.reddit.com/r/AWSCertifications/comments/1h5jfmp/how_did_passing_aws_solution_architect/\">this one</a>, that had seen significant benefits from taking the course.</p><p>: Systems Administrators (Cloud Focused), Cloud Architects, Solutions Architects, Cloud Consultants Software Architects for Cloud-Based Applications, and Enterprise Architects.</p><ul><li>3 courses of online, self-directed exam prep are available</li><li>15.25 hrs free; 48.75 hrs paid</li></ul><p>Testing: 130 minutes. Pearson VUE testing center, or online proctored exam</p><table><thead><tr></tr></thead><tbody><tr><td>1 year of hands-on experience designing cloud solutions with AWS services.</td><td>English, French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Latin America), Spanish (Spain), Simplified and Traditional Chinese</td></tr></tbody></table><h2>Google Professional Cloud Architect</h2><p>If you‚Äôre all in on Google, <a href=\"https://cloud.google.com/learn/certification/cloud-architect\">this certification</a> is for you. It will help you show your cloud architecture skills and advance your career in Google‚Äôs cloud technology. Keep in mind, this is focused on Google‚Äôs cloud infrastructure and doesn‚Äôt cover software architecture.</p><p>The training and exam for this certificate are all online (though on-site exams are available) which makes it very flexible. Plus, it‚Äôs pretty cheap (although it‚Äôs the most expensive of the provider-specific options). However, if you go through all the training, it‚Äôs going to take you some time, as it‚Äôs the longest provider-specific course here.</p><p>: Cloud Architects, Solutions Architects, IT Project Managers focused on the cloud, Cloud Engineers, DevOps Engineers, and Enterprise Architects.</p><p>Training: 114.75 hrs, online, self-directed</p><p>Testing: 2-hr test, with two options: an online proctored exam, or an onsite-proctored exam at a testing center.</p><table><thead><tr></tr></thead><tbody><tr><td>3+ years of industry experience, including 1+ year of designing and managing solutions with Google Cloud</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: The certificate is valid for 2 years. Recertify by retaking the exam within 60 days of the expiration date.</p><h2>Microsoft Certified: Azure Solutions Architect Expert</h2><p><a href=\"https://learn.microsoft.com/en-us/credentials/certifications/azure-solutions-architect/\">This certificate</a> shows you know your way around Azure, including how to design and implement cloud and hybrid solutions. It dives deep into how various IT infrastructure components in the Microsoft ecosystem (like compute, network, storage, monitoring, and security) interact to generate solutions. Just like the Google certificate above, this is infrastructure-focused, not software-focused, so keep that in mind when considering it.</p><p>The course for the Microsoft certification is shorter than Google‚Äôs by almost 100 hours and can be taken both online at your own pace, or with an online instructor. It‚Äôs also a bit cheaper than Google‚Äôs, making it an easier investment both for hours and dollars spent.</p><p>: Systems Administrators, Network Engineers, IT Managers, Cloud Architects, Computer Systems Analysts and Infrastructure Engineers.</p><p>Training: Self-paced online learning (15.25 hrs), or instructor-led online training (4 days).</p><p>Testing: Online proctored exam.</p><table><thead><tr></tr></thead><tbody><tr><td>$165 USD  Self-paced training is free; instructor-led depends on the provider.</td><td>Experience with Azure administration and development, and DevOps processes.  Advanced experience and knowledge of IT operations.</td><td>English, Chinese (Simplified), French, German, Japanese, Korean, Portuguese (Brazil), Spanish</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: The certificate expires after one year. Recertification is free via an online assessment on Microsoft Learn.</p><h2>Red Hat Certified Architect (RHCA)</h2><p>Red Hat‚Äôs highest level of certification, the <a href=\"https://www.redhat.com/en/services/certification/rhca\">RHCA designation</a> covers designing, implementing, and managing Red Hat-based IT infrastructures. One of the nice things is that RHCA offers tracks in both infrastructure and enterprise applications. So you can choose the option that best matches your goals.</p><p>Red Hat prices its certification differently than most. It‚Äôs a subscription-based model, which allows you to have a little more freedom with how you tackle their training. In fact, their certification offers the most custom options, with a variety of options to get from A (where you are) to B (certified). So if you have diverse interests, this one might be the one for you.</p><p>: Senior Systems Administrator, Cloud Architect, IT Infrastructure Architect, DevOps Engineer, Senior Application Developer, Enterprise Solutions Architect</p><ul><li>Red Hat Certified Architect in Infrastructure</li><li>Red Hat Certified Architect in Enterprise Applications</li></ul><p>Certification builds on prerequisites with five additional certifications chosen from a list.</p><p>Training and exams depend on your chosen path and certifications.</p><table><thead><tr></tr></thead><tbody><tr><td> Standard: $7,500 USD/year for 25 training units and certification. <p> Premium: $9,000 USD/year for 30 training units and certification.</p></td><td>Red Hat Certified Engineer (RHCE)  OR <p> Red Hat Certified Enterprise Microservices Developer (RHCEMD) </p> OR <p> Red Hat Certified Cloud-native Developer (RHCCD)</p></td><td>Recommended experience depends on your specific path.</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: Certifications become ‚Äònon-current‚Äô after three years. To maintain an RHCA certification, you must maintain five additional certifications over your RHCE. RHCEMD or RHCCD. These certifications do not need to be the same as those you‚Äôve taken to attain your RHCA.</p><p>Made for IT professionals who want to master SOA, <a href=\"https://www.arcitura.com/cert/soa-architect-certification-exam.html\">this certification</a> covers designing, implementing, and managing Service-Oriented Architecture (SOA) infrastructure.</p><p>SOA certification is one and done. There are no levels or long-term commitment to one system, which makes it less of a commitment. It‚Äôs also very affordable.</p><p>: Enterprise Architects, Solutions Architects, IT Architects, Software Architects, Systems Engineers with SOA experience, Technical Leads with architecture responsibilities</p><ul><li>170 mins online proctored exam</li><li>50 hrs of training over 5 modules (modules include: Workbook Lessons, Video Lessons, Interactive Exercises, Mind Map Poster, Practice Exam Questions, PDFs of Workbook and Poster, Lab Exercise Booklet).</li></ul><table><thead><tr></tr></thead><tbody><tr><td>$399 USD for course and certification</td></tr></tbody></table><h2>iSAQB CPSA-F/CPSA-A (International Software Architecture Qualification Board)</h2><p>In contrast to TOGAF training, <a href=\"https://www.isaqb.org/certifications/cpsa-certifications/cpsa-foundation-level/\">the CPSA program</a> focuses on the practical implementation of IT systems. Its foundation and advanced certificates offer room for architects to grow.</p><p>This is a two-step program, foundation and advanced, which puts it between the single-step SOA certification and the larger three- or even four-step offerings. Just like TOGAF and ITIL, iSAQB is not a testing or training provider, so there are a lot of options for training. Or, if you‚Äôre confident, you can challenge the exam without, though that‚Äôs not recommended.</p><p>: Software designers, software developers, Software Architects, systems analysts</p><p>\nThough training and testing are performed by independent operators, you have four testing options available, including:</p><ul><li>Exam after classroom training</li></ul><table><thead><tr></tr></thead><tbody><tr><td>The cost of training is dependent on training providers.  Testing price is dependent on training providers.</td><td>Training is suggested.  Foundation certification is required for Advanced.</td><td>18+ months of practical experience, including:  - A higher programming language <p> - Technical documentation </p> - Object-oriented programming language <p> - Design and implementation of distributed applications </p> - Basics of modeling and abstraction; and UML and their relation to source</td><td>Language is dependent on training providers.</td></tr></tbody></table><p><strong>Certification expiry &amp; recertification</strong>: The certificate does not expire.</p><p>The right certification can set you apart on your resume, but it‚Äôs never a replacement for experience. Depending on your career path, you may choose to get certified by one of the bodies above, or simply study on your own and prove what you can do through practical experience.</p><p>If you‚Äôve decided to pursue the certification path, the options above are all great choices. Of course, each requires a commitment of time and money. While you can‚Äôt warp the space-time continuum to change the time requirement, it may be possible to get your employer to help you cover some, if not all of the cost. If they do, it gives you an even higher ROI on your investment to yourself.</p>","contentLength":20228,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iuqdq8/certifications_for_software_architects/"},{"title":"This month in Servo: new webview API, relative colors, canvas buffs, and more!","url":"https://servo.org/blog/2025/02/19/this-month-in-servo/","date":1740142406,"author":"/u/wuyuwei-tw","guid":8721,"unread":true,"content":"<p>Servo now supports several new web API features:</p><p>We‚Äôve landed a bunch of  improvements:</p><p> are a lot more useful now, with  now supporting  (<a href=\"https://github.com/Taym95\">@Taym95</a>, <a href=\"https://github.com/servo/servo/pull/35040\">#35040</a>), , , and  (<a href=\"https://github.com/Taym95\">@Taym95</a>, <a href=\"https://github.com/servo/servo/pull/34958\">#34958</a>).</p><p>Servo aims to be an embeddable web engine, but so far it‚Äôs been a lot harder to embed Servo than it should be.</p><p>For one, configuring and starting Servo is complicated.\nWe found that getting Servo running at all, even without wiring up input or handling resizes correctly, took  of Rust code (<a href=\"https://github.com/delan\">@delan</a>, <a href=\"https://github.com/mrobinson\">@mrobinson</a>, <a href=\"https://github.com/servo/servo/pull/35118\">#35118</a>).\nEmbedders (apps) could only control Servo by sending and receiving a variety of ‚Äúmessages‚Äù and ‚Äúevents‚Äù, and simple questions like ‚Äúwhat‚Äôs the current URL?‚Äù were impossible to answer without keeping track of extra state in the app.</p><p>Contrast this with <a href=\"https://webkitgtk.org/\">WebKitGTK</a>, where you can write a minimal kiosk app with a fully-functional webview in  of C.\nTo close that gap, we‚Äôve started <strong>reworking our embedding API</strong> towards something more idiomatic and ergonomic, starting with the concept embedders care about most: the .</p><p>Our new webview API is controlled by calling methods on a  (<a href=\"https://github.com/delan\">@delan</a>, <a href=\"https://github.com/mrobinson\">@mrobinson</a>, <a href=\"https://github.com/servo/servo/pull/35119\">#35119</a>, <a href=\"https://github.com/servo/servo/pull/35183\">#35183</a>, <a href=\"https://github.com/servo/servo/pull/35192\">#35192</a>), including navigation and user input.\nHandles will eventually represent the lifecycle of the webview itself; if you have one, the webview is valid, and if you drop them, the webview is destroyed.</p><p>Servo needs to call into the embedder too, and here we‚Äôve started replacing the old EmbedderMsg API with a  (<a href=\"https://github.com/delan\">@delan</a>, <a href=\"https://github.com/mrobinson\">@mrobinson</a>, <a href=\"https://github.com/servo/servo/pull/35211\">#35211</a>), much like the delegates in <a href=\"https://developer.apple.com/documentation/webkit/wkuidelegate?language=objc\">Apple‚Äôs WebKit API</a>.\nIn Rust, a delegate is a  that the embedder can install its own  for.\nStay tuned for more on this next month!</p><p>Other embedding improvements include:</p><p>We‚Äôve reworked Servo‚Äôs , making all prefs optional with reasonable defaults (<a href=\"https://github.com/mrobinson\">@mrobinson</a>, <a href=\"https://github.com/servo/servo/pull/34966\">#34966</a>, <a href=\"https://github.com/servo/servo/pull/34999\">#34999</a>, <a href=\"https://github.com/servo/servo/pull/34994\">#34994</a>).\nAs a result:</p><ul><li><strong>The names of all preferences have changed</strong>; see the <a href=\"https://doc.servo.org/servo_config/prefs/struct.Preferences.html\">Prefs docs</a> for a list</li><li><strong>Embedders no longer need a </strong> resource to get Servo running</li></ul><p>Servo‚Äôs networking is more efficient now, with the ability to <strong>cancel fetches for navigation</strong> that contain redirects (<a href=\"https://github.com/mrobinson\">@mrobinson</a>, <a href=\"https://github.com/servo/servo/pull/34919\">#34919</a>) and <strong>cancel fetches for &lt;video&gt; and &lt;media&gt;</strong> when the document is unloaded (<a href=\"https://github.com/mrobinson\">@mrobinson</a>, <a href=\"https://github.com/servo/servo/pull/34883\">#34883</a>).\nThose changes also <strong>eliminate per-request IPC channels</strong> for navigation and cancellation respectively, and in the same vein, we‚Äôve eliminated them for image loading too (<a href=\"https://github.com/mrobinson\">@mrobinson</a>, <a href=\"https://github.com/servo/servo/pull/35041\">#35041</a>).</p><p>We‚Äôve continued <strong>splitting up our massive script crate</strong> (<a href=\"https://github.com/jdm\">@jdm</a>, <a href=\"https://github.com/servo/servo/pull/34359\">#34359</a>, <a href=\"https://github.com/servo/servo/pull/35157\">#35157</a>, <a href=\"https://github.com/servo/servo/pull/35169\">#35169</a>, <a href=\"https://github.com/servo/servo/pull/35172\">#35172</a>), which will eventually make Servo much faster to build.</p><p>We now run <strong>CI smoketests on OpenHarmony</strong> using a real device (<a href=\"https://github.com/jschwe\">@jschwe</a>, <a href=\"https://github.com/mukilan\">@mukilan</a>, <a href=\"https://github.com/servo/servo/pull/35006\">#35006</a>), increasing confidence in your changes beyond compile-time errors.</p><p>We‚Äôve also tripled our <strong>self-hosted CI runner capacity</strong> (<a href=\"https://github.com/delan\">@delan</a>, <a href=\"https://github.com/servo/servo/pull/34983\">#34983</a>, <a href=\"https://github.com/servo/servo/pull/35002\">#35002</a>), making concurrent Windows and macOS builds possible without falling back to the much slower GitHub-hosted runners.</p><p>Servo can‚Äôt yet run WebDriver-based tests on <a href=\"https://wpt.fyi\">wpt.fyi</a>, <a href=\"https://wpt.servo.org\">wpt.servo.org</a>, or CI, because the  executor for the <a href=\"https://web-platform-tests.org\">Web Platform Tests</a> does not support testdriver.js.\n does, though, so we‚Äôve started fixing test regressions with that executor with the goal of eventually switching to it (<a href=\"https://github.com/jdm\">@jdm</a>, <a href=\"https://github.com/servo/servo/pull/34957\">#34957</a>, <a href=\"https://github.com/servo/servo/pull/34997\">#34997</a>).</p><p>Thanks again for your generous support!\nWe are now receiving  (‚àí11.4% over December) in recurring donations.\nWith this money, we‚Äôve been able to expand our capacity for <a href=\"https://ci0.servo.org\">self-hosted</a><a href=\"https://ci1.servo.org\">CI</a><a href=\"https://ci2.servo.org\">runners</a> on Windows, Linux, and macOS builds, <strong>halving  build times</strong> from over an hour to under 30 minutes!</p><p>Servo is also on <a href=\"https://thanks.dev\">thanks.dev</a>, and already  (+5 over December) that depend on Servo are sponsoring us there.\nIf you use Servo libraries like <a href=\"https://crates.io/crates/url/reverse_dependencies\">url</a>, <a href=\"https://crates.io/crates/html5ever/reverse_dependencies\">html5ever</a>, <a href=\"https://crates.io/crates/selectors/reverse_dependencies\">selectors</a>, or <a href=\"https://crates.io/crates/cssparser/reverse_dependencies\">cssparser</a>, signing up for <a href=\"https://thanks.dev\">thanks.dev</a> could be a good way for you (or your employer) to give back to the community.</p><p>As always, use of these funds will be decided transparently in the Technical Steering Committee.\nFor more details, head to our <a href=\"https://servo.org/sponsorship/\">Sponsorship page</a>.</p>","contentLength":3866,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1iuq74e/this_month_in_servo_new_webview_api_relative/"},{"title":"Have we hit a scaling wall in base models? (non reasoning)","url":"https://www.reddit.com/r/artificial/comments/1iupqgp/have_we_hit_a_scaling_wall_in_base_models_non/","date":1740140885,"author":"/u/CH1997H","guid":9078,"unread":true,"content":"<p>Grok 3 was supposedly trained on 100,000 H100 GPUs, which is in the ballpark of about 10x more than models like the GPT-4 series and Claude 3.5 Sonnet</p><p>Yet they're about equal in abilities. Grok 3 isn't AGI or ASI like we hoped. In 2023 and 2024 OpenAI kept saying that they can just keep scaling the pre-training more and more, and the models just magically keep getting smarter (the \"scaling laws\" where the chart just says \"line goes up\")</p><p>Now all the focus is on reasoning, and suddenly OpenAI and everybody else have become very quiet about scaling</p><p>It looks very suspicious to be honest. Instead of making bigger and bigger models like in 2020-2024, they're now trying to keep them small while focusing on other things. Claude 3.5 Opus got quietly deleted from the Anthropic blog, with no explanation. Something is wrong and they're trying to hide it</p>","contentLength":850,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[D] Have we hit a scaling wall in base models? (non reasoning)","url":"https://www.reddit.com/r/MachineLearning/comments/1iupnet/d_have_we_hit_a_scaling_wall_in_base_models_non/","date":1740140600,"author":"/u/CH1997H","guid":8632,"unread":true,"content":"<p>Grok 3 was supposedly trained on 100,000 H100 GPUs, which is in the ballpark of about 10x more than models like the GPT-4 series and Claude 3.5 Sonnet</p><p>Yet they're about equal in abilities. Grok 3 isn't AGI or ASI like we hoped. In 2023 and 2024 OpenAI kept saying that they can just keep scaling the pre-training more and more, and the models just magically keep getting smarter (the \"scaling laws\" where the chart just says \"line goes up\")</p><p>Now all the focus is on reasoning, and suddenly OpenAI and everybody else have become very quiet about scaling</p><p>It looks very suspicious to be honest. Instead of making bigger and bigger models like in 2020-2024, they're now trying to keep them small while focusing on other things. Claude 3.5 Opus got quietly deleted from the Anthropic blog, with no explanation. Something is wrong and they're trying to hide it</p>","contentLength":850,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I created A Easy to use Rust Web Framework","url":"https://www.reddit.com/r/rust/comments/1iuplg1/i_created_a_easy_to_use_rust_web_framework/","date":1740140417,"author":"/u/Rough_Shopping_6547","guid":8832,"unread":true,"content":"<p>I just published my  project!</p><p>I realized there isn‚Äôt a single easy-to-use, plug-and-play Rust web framework out there (at least to my knowledge), so I decided to create my own.</p><p>I'd love to hear your thoughts on it!</p>","contentLength":214,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI and the future of work - an EU perspective","url":"https://v.redd.it/cx0l3st20hke1","date":1740134098,"author":"/u/snehens","guid":8653,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1iunxt8/ai_and_the_future_of_work_an_eu_perspective/"},{"title":"Getting organised! ¬∑ AerynOS","url":"https://github.com/orgs/AerynOS/discussions/37","date":1740133024,"author":"/u/Wooden-Opposite3557","guid":8720,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1iunoxx/getting_organised_aerynos/"},{"title":"ChatGPT took an oath to protect its own.üòÑü§ñ","url":"https://www.reddit.com/r/artificial/comments/1iuno62/chatgpt_took_an_oath_to_protect_its_own/","date":1740132932,"author":"/u/snehens","guid":8526,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AVR microcontrollers are now officially maintained!","url":"https://www.reddit.com/r/rust/comments/1iunfgx/avr_microcontrollers_are_now_officially_maintained/","date":1740131957,"author":"/u/Patryk27","guid":8499,"unread":true,"content":"<p>AVRs are cute &amp; tiny microcontrollers from Atmel - you might've heard about ATmega328p used in Arduino Uno, for example:</p><p>Every week we're marching towards better AVR support in Rust and as of today I can proudly say: we don't need no `target.json`s anymore + we've got an official maintainer! (points finger at self)</p><p>So far AVRs remain tier 3, but at least it's waay easier to use them now - just target `avr-none` and provide `-C target-cpu` so that rustc &amp; llvm know which specific microcontroller you're building for; <a href=\"https://github.com/llvm/llvm-project/pull/118015\">a couple</a> of <a href=\"https://github.com/llvm/llvm-project/pull/121498\">important</a> codegen <a href=\"https://github.com/llvm/llvm-project/pull/106722\">fixes</a> are also coming together with rustc's upgrade to LLVM 20, hoping to wrap up on <a href=\"https://github.com/Rahix/avr-hal/pull/585\">https://github.com/Rahix/avr-hal/pull/585</a> over the coming days.</p><p>I'd like to take this moment to thank <a href=\"https://github.com/benshi001\">https://github.com/benshi001</a> for his continued support and code reviews on the LLVM's side - let AVR flourish!</p>","contentLength":845,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sponsoring Rust Developers","url":"https://www.reddit.com/r/rust/comments/1iun7oj/sponsoring_rust_developers/","date":1740131048,"author":"/u/szabgab","guid":8855,"unread":true,"content":"<p>One of the \"findings\" of my <a href=\"https://www.reddit.com/r/rust/comments/1ital1t/why_dont_you_use_rust_at_your_company/\">previous question</a> was that some crates are missing or not mature enough to be used.</p><p>If you would like to use Rust you can hope that those gaps will be closed in time or you can do something about it. If you have the time and expertise you can get involved in the needed projects, but there is a much easier and less time-consuming way. You and/or your company can sponsor the development efforts.</p><p>Allocating 10-20 USD / month by an individual or 1000-2000 USD month by a small company does not sound like a big investment and many such sponsors can make a huge difference together.</p><p>One way to find who to sponsor is to find the developers of your dependencies. For that visit the <a href=\"https://github.com/sponsors/explore\">Explore GitHub Sponsors</a> page. On the left-hand side select the \"Cargo\" ecosystem. That will show you the individuals and the organizations that you currently rely upon that also accept sponsorship.</p><p>I've also created a page listing some of the <a href=\"https://rust.code-maven.com/sponsoring\">people and project</a> who develop Rust and could be sponsored. For some of them I've also included background information.</p>","contentLength":1066,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"My experience with the GNOME Desktop - from despised to loved","url":"https://www.reddit.com/r/linux/comments/1iun2fo/my_experience_with_the_gnome_desktop_from/","date":1740130417,"author":"/u/Fishsven","guid":8933,"unread":true,"content":"<p> I started my Linux journey with Pop!_OS, and I hated the wasted space of the panel-like dock. It took me a while for me to return to GNOME as I was discovering KDE Plasma's (5.24) customization potential. I loved it at first, but I noticed how the DE slowly became unstable after a lot of customising (Plasma has GREATLY improved by now, last time I tried 5.27 on Q4OS and it was blazing fast and rock solid). I was annoyed at how people took a liking to the hideous DE known as GNOME, and for me there was little difference between it and Windows 8, as they were basically tablet centric with GNOME and it's wasted space.</p><p> I eventually got tired of Plasma, because it had way too many features that I didn¬¥t wan¬¥t to use. Tried XFCE, MATE and Budgie, and they felt too outdated for my liking; Budgie felt off. I decided to give GNOME a shot and installed Ubuntu 22.04. For once I was starting to like GNOME. It felt more unified and simple than KDE, but just more modern than the other desktops. However, this was NOT stock GNOME. I installed vanilla GNOME on the same OS and decided to give it a shot.</p><p> Moving on from Ubuntu's Yaru theme to Adwaita felt like a MASSIVE downgrade. Except the looks, GNOME's true workflow actually started to make sense to me and it was more productive than any desktop I tried. Of course, I installed some extensions like Blur my Shell, but I can use GNOME without extensions nowadays. As I'm writing this, GNOME 48 would bring a new Adwaita font with Inter as it's base, which will improve the looks of GNOME by a bit, IMO. Currently using Zorin OS, which has a GNOME theme that is MILES better compared to Libadwaita / Adwaita. </p><p> What I understood is GNOME is not all about looks, it makes the UI simpler and easier to understand, with ONLY the things you need, and it stays out of your way and focuses on your work. It might be dumbing down the desktop for some, but that's exactly what GNOME's for. A solid philosophy IMO- but definitely lagging in some important areas. </p>","contentLength":2009,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How donations helped the LibreOffice project and community in 2024","url":"https://blog.documentfoundation.org/blog/2025/02/21/how-your-donations-helped-the-libreoffice-project-in-2024/","date":1740130087,"author":"/u/themikeosguy","guid":8630,"unread":true,"content":"<p>Thank you for visiting our website and your interest in our services and products. As the protection of your personal data is an important concern for us, please click on the \"More information\" link to access our Privacy Policy page - which will open in a separate browser tab - where we explain what information we collect during your visit to our website, how it is processed, and whether or how it may be used.\nOnce you have carefully read our Privacy Policy page, close the browser tab to return to this page and click on the \"Save Preferences\" button under this text to acknowledge it, close the dialogue and return to the website.<p>\nWe take all the necessary technical and organisational security measures to protect your personal data from loss and misuse. Your data is stored in a secure operating environment that is not accessible to the public.</p></p>","contentLength":853,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1iumzoe/how_donations_helped_the_libreoffice_project_and/"},{"title":"Sharing my Open Source Project: Realtime Messaging Platform Built with Go & React (Fullstack)","url":"https://github.com/JoyalAJohney/Realtime-distributed-chat","date":1740113598,"author":"/u/BruceWayn_","guid":8916,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iuivtv/sharing_my_open_source_project_realtime_messaging/"},{"title":"Minecraft from scratch with only modern OpenGL","url":"https://github.com/GianlucaP106/minecraft","date":1740108768,"author":"/u/One_Mess_1093","guid":8378,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iuhfcq/minecraft_from_scratch_with_only_modern_opengl/"},{"title":"Contribute by filing bugs. You'll feel all warm and fuzzy inside.","url":"https://www.reddit.com/r/linux/comments/1iugim6/contribute_by_filing_bugs_youll_feel_all_warm_and/","date":1740105949,"author":"/u/billhughes1960","guid":8527,"unread":true,"content":"<p>As a lifelong Linux user, I believe strongly in giving back to the open-source community. While I'm not a developer myself, I've found another way to contribute: filing bug reports.</p><p>I'll admit my early attempts were probably pretty rough ‚Äì missing crucial context and details. But practice makes perfect (or at least close!), and these days my bug reports are often addressed within a day or so.</p><p>There's something incredibly satisfying about uncovering a problem, meticulously documenting it, submitting a report, seeing it assigned to someone, and finally witnessing the fix. It's a tangible way to make a difference in the software we all rely on.</p><p>This level of responsiveness and respect simply doesn't exist in proprietary ecosystems. I've tried reporting bugs on Windows and macOS with little success ‚Äì it often feels like shouting into the void. But in the open-source world, even smaller projects welcome contributions and treat you seriously.</p><p>So, I encourage everyone to embrace bug reporting! Start with a simpler project to get comfortable with the process, then gradually tackle more complex ones. Not only will you be improving the software for everyone, but you'll also experience that warm glow of knowing you made a positive impact.</p>","contentLength":1247,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Linus Torvalds responds to Christoph Hellwig","url":"https://lore.kernel.org/rust-for-linux/CAHk-=wgLbz1Bm8QhmJ4dJGSmTuV5w_R0Gwvg5kHrYr4Ko9dUHQ@mail.gmail.com/","date":1740105034,"author":"/u/bik1230","guid":7580,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1iug7u9/linus_torvalds_responds_to_christoph_hellwig/"},{"title":"Linus Torvalds rips into Hellwig for blocking Rust for Linux","url":"https://lore.kernel.org/rust-for-linux/CAHk-=wgLbz1Bm8QhmJ4dJGSmTuV5w_R0Gwvg5kHrYr4Ko9dUHQ@mail.gmail.com/","date":1740102572,"author":"/u/eugay","guid":7578,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1iufdhk/linus_torvalds_rips_into_hellwig_for_blocking/"},{"title":"Installed Ubuntu on my Nan's laptop:","url":"https://www.reddit.com/r/linux/comments/1iueq5x/installed_ubuntu_on_my_nans_laptop/","date":1740100681,"author":"/u/Unique_Ad4547","guid":7577,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Libreboot 20241206, 10th revision released! GRUB security fixes, better LVM scanning, non-root USB2 hub support","url":"https://libreboot.org/news/libreboot20241206rev10.html","date":1740100282,"author":"/u/libreleah","guid":8629,"unread":true,"content":"<p>Article published by: Leah Rowe</p><p>Date of publication: 18 February 2025</p><p>Today‚Äôs Libreboot 20241206 revision is the 10th revision in the Libreboot 20241206 stable release series. The changelog on this page is written, relative to Libreboot 20241206 revision 9 which was released on 12 February 2025. The  Libreboot 20241206 release came out on 6 December 2024. You can find the full list of revisions <a href=\"https://libreboot.org/news/libreboot20241206.Revisions.html\">here</a> and the original release <a href=\"https://libreboot.org/news/libreboot20241206.html\">here</a>.</p><div><h2>Open source BIOS/UEFI firmware</h2><a aria-hidden=\"true\" href=\"https://libreboot.org/news/libreboot20241206rev10.html#open-source-biosuefi-firmware\">[link]</a></div><p>Libreboot is a free/open source BIOS/UEFI replacement on x86 and ARM, providing boot firmware that initialises the hardware in your computer, to then load an operating system (e.g.&nbsp;Linux/BSD). It is specifically a , in the same way that Debian is a Linux distribution. It provides an automated build system to produce coreboot ROM images with a variety of payloads such as GRUB or SeaBIOS, with regular well-tested releases to make coreboot as easy to use as possible for non-technical users. From a project management perspective, this works in  the same way as a Linux distro, providing a source-based package manager (called lbmk) which patches sources and compiles coreboot images. It makes use of <a href=\"https://www.coreboot.org/\">coreboot</a> for hardware initialisation, and then a payload such as <a href=\"https://www.seabios.org/SeaBIOS\">SeaBIOS</a> or <a href=\"https://www.gnu.org/software/grub/\">GRUB</a> to boot your operating system; on ARM(chromebooks), we provide  (as a coreboot payload).</p><p>We also provide an experimental U-Boot setup on x86, as a coreboot payload for providing a minimal UEFI implementation.</p><p>Normally, revisions would only be documented on the <a href=\"https://libreboot.org/news/libreboot20241206.Revisions.html\">Libreboot 20241206 revisions page</a>, but this revision contains , so it was decided that there should be a full announcement, to ensure that more people see it.</p><div><h2>Summarised list of changes</h2><a aria-hidden=\"true\" href=\"https://libreboot.org/news/libreboot20241206rev10.html#summarised-list-of-changes\">[link]</a></div><p>GRUB released  to its main branch, fixing a large number of security issues. You can read about them here:</p><p>This updates GRUB to revision <code>4dc6166571645780c459dde2cdc1b001a5ec844c</code> from 18 February 2025. Several OOB heap writes, buffer overflows, use after frees and so on, are now prevented with this update.</p><p>In addition to the security fixes, several out-of-tree fixes from Libreboot‚Äôs main branch have been merged for GRUB, fixing bugs in the xHCI driver, and adding support for non-root USB2 hubs on platforms that use the  GRUB tree.</p><p>Changes to the GRUB configuration have been made, to make scanning of LVM volume/group names more reliable, including on full-disk-encryption setups. More such changes are planned for the next major release; the current changes are very minor.</p>","contentLength":2480,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/linux/comments/1iuel79/libreboot_20241206_10th_revision_released_grub/"},{"title":"BritCSS: Fixes CSS to use non-American English","url":"https://github.com/DeclanChidlow/BritCSS","date":1740096884,"author":"/u/ValenceTheHuman","guid":8397,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iudp7p/britcss_fixes_css_to_use_nonamerican_english/"},{"title":"[Media] Rust powered flight radar","url":"https://www.reddit.com/r/rust/comments/1iubs4r/media_rust_powered_flight_radar/","date":1740091662,"author":"/u/Confident-Alarm-6911","guid":7579,"unread":true,"content":"<p>So, consider this mix: I have thing for retro-interfaces with monochromatic displays, I wanted to learn rust and do something with sdr radio, I live next to the airport. And that‚Äôs how my small radar comes to life üòé</p><p>Hardware: ESP32C3, 1.5 inch i2c oled display, some encoder. RTL-SDR V4 running on my local linux machine and small endpoint to serve ADS-B data via http.</p><p>Firmware written in rust 2021 edition. Libraries: mostly std and esp-idf-svc + rtos (not necessary, but I wanted to try it)</p><p>I‚Äôm pretty content with this small project as it is my first attempt to build something in Rust. Now I want to design 3D printable case, do some polishing on software side, and publish it as open source.</p><p>I wanted to post video but it says I can not do this in this community, so only pic</p>","contentLength":784,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"IaaC Simplified: Automating EC2 Deployments with GitHub Actions, Terraform, Docker & Distribution Registry | Vue & Node admin panel framework","url":"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/","date":1740090590,"author":"/u/Unerring-Ocean","guid":7467,"unread":true,"content":"<p>This guide shows how to deploy own Docker apps (with AdminForth as example) to Amazon EC2 instance with Docker and Terraform involving Docker self-hosted registry.</p><ul><li>GitHub actions Free plan which includes 2000 minutes per month (1000 of 2-minute builds per month - more then enough for many projects, if you are not running tests etc). Extra builds would cost  per minute.</li><li>AWS account where we will auto-spawn EC2 instance. We will use  instance (2 vCPUs, 2GB RAM) which costs  per month in  region (cheapest region). Also it will take  per month for EBS gp2 storage (20GB) for EC2 instance</li></ul><p>This is it, registry will be auto-spawned on EC2 instance, so no extra costs for it. Also GitHub storage is not used, so no extra costs for it.</p><p>The setup has next features:</p><ul><li>Build process is done using IaaC approach with HashiCorp Terraform, so almoast no manual actions are needed from you. Every resource including EC2 server instance is described in code which is commited to repo so no manual clicks are needed.</li><li>Docker build process is done on GitHub actions, so EC2 server is not overloaded</li><li>Changes in infrastructure including changing server type, adding S3 Bucket, changing size of sever disk is also can be done by commiting code to repo.</li><li>Docker images and cache are stored on EC2 server, so no extra costs for Docker registry are needed.</li><li>Total build time for average commit to AdminForth app (with Vite rebuilds) is around 2 minutes.</li></ul><p>Previously we had a blog post about <a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions/\">deploying AdminForth to EC2 with Terraform without registry</a>. That method might work well but has a significant disadvantage - build process happens on EC2 itself and uses EC2 RAM and CPU. This can be a problem if your EC2 instance is well-loaded without extra free resources. Moreover, low-end EC2 instances have a small amount of RAM and CPU, so build process which involves vite/tsc/etc can be slow or even fail.</p><p>So obviously to solve this problem we need to move the build process to CI, however it introduces new chellenges and we will solve them in this post.</p><p>Quick difference between approaches from previous post and current post:</p><table><thead><tr></tr></thead><tbody><tr><td>How and where docker build happens</td><td>Source code is rsync-ed from CI to EC2 and docker build is done there</td><td>Docker build is done on CI and docker image is pushed to registry (in this post we run registry automatically on EC2)</td></tr><tr><td>How Docker build layers are cached</td><td>GitHub actions has no own Docker cache out of the box, so it should be stored in dedicated place (we use self-hosted registry on the EC2 as it is free)</td></tr><tr><td>Simpler setup with less code (we don't need code to run and secure registry, and don't need extra cache setup as is naturally persisted on EC2).</td><td>Build is done on CI, so EC2 server is not overloaded. For most cases CI builds are faster than on EC2. Plus time is saved because we don't need to rsync source code to EC2</td></tr><tr><td>Build on EC2 requires additional server RAM / overloads CPU</td><td>More terraform code is needed. registry cache might require small extra space on EC2</td></tr></tbody></table><h2>Chellenges when you build on CI<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#chellenges-when-you-build-on-ci\" aria-label=\"Direct link to Chellenges when you build on CI\" title=\"Direct link to Chellenges when you build on CI\">‚Äã</a></h2><p>When you move build process to CI you have to solve next chellenges:</p><ol><li>We need to deliver built docker images to EC2 somehow (and only we)</li><li>We need to persist cache between builds</li></ol><h4>Exporing images to tar files<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#exporing-images-to-tar-files\" aria-label=\"Direct link to Exporing images to tar files\" title=\"Direct link to Exporing images to tar files\">‚Äã</a></h4><p>Simplest option which you can find is save docker images to tar files and deliver them to EC2. We can easily do it in terraform (using  command on CI and  command on EC2). However this option has a significant disadvantage - it is slow. Docker images are big (always include all layers, without any options), so it takes infinity to do save/load and another infinity to transfer them to EC2 (via relatively slow rsync/SSH and relatively slow GitHub actions outbound connection).</p><p>Faster, right option which we will use here - involve Docker registry. Registry is a repository which stores docker images. It does it in a smart way - it saves each image as several layers, so if you will update last layer, then only last layer will be pushed to registry and then only last will be pulled to EC2.\nTo give you row compare - whole-layers image might take , but last layer created by  command might take . And most builds you will do only last layer changes, so it will be 20 times faster to push/pull last layer than whole image.\nAnd this is not all, registry uses TLS HTTP protocol so it is faster then SSH/rsync encrypted connection.</p><p>Of course you have to care about a way of registry authentication (so only you and your CI/EC2 can push/pull images).</p><p>What docker registry can you use? Pretty known options:</p><ol><li>Docker Hub - most famous. It is free for public images, so literally every opensource project uses it. However it is not free for private images, and you have to pay for it. In this post we are considering you might do development for commercial project with tight budget, so we will not use it.</li><li>GHCR - Registry from Google. Has free plan but allows to store only 500MB and allows to transfer 1GB of traffic per month. Then you pay for every extra GB in storage and traffic. Probably small images will fit in this plan, but generally even alpine-based docker images are bigger than 500MB, so it is not a good option.</li><li>Self-hosted registry web system. In our software development company, we use Harbor. It is a powerful free open-source registry that can be installed to own server. It allows pushing and pulling without limit. Also, it has internal life-cycle rules that cleanup unnecessary images and layers. The main drawbacks of it are that it is not so fast to install and configure, plus you have to get a domain and another powerfull server to run it. So unless you are a software development company, it is not worth using it.</li><li>Self-hosted minimal CNCF Distribution <a href=\"https://distribution.github.io/distribution/\" target=\"_blank\" rel=\"noopener noreferrer\">registry</a> on EC2 itself. So since we already have EC2, we can run registry on it directly. The  container is pretty light-weight and easy to setup and it will not consume a lot of extra CPU/RAM on server. Plus images will be stored close to application so pull will be fast.</li></ol><p>In the post we will use last (4th way). Our terraform will deploy registry automatically, so you don't have to do anything special.</p><p>Docker builds without layer cache persistence are possible but very slow. Most builds only change a couple of layers, and having no ability to cache them will cause the Docker builder to regenerate all layers from scratch. This can, for example, increase the Docker build time from a minute to ten minutes or even more.</p><p>Out of the box, GitHub Actions can't save Docker layers between builds, so you have to use external storage.</p><blockquote><p>Though some CI systems can persist docker build cache, e.g. open-source self-hosted Woodpecker CI allows it out of the box. However GitHub actions which is pretty popular, reasonably can't allow such free storage to anyone</p></blockquote><p>So when build-in Docker cache can't be used, there is one alternative - Docker BuildKit external cache.\nSo BuildKit allows you to connect external storage. There are several options, but most sweet for us is using Docker registry as cache storage (not only as images storage to deliver them to application server).</p><blockquote><p><em>BuildKit cache in Compose issue</em>\nPreviously we used docker compose to build &amp; run our app, it can be used to both build, push and pull images, but has <a href=\"https://github.com/docker/compose/issues/11072#issuecomment-1848974315\" target=\"_blank\" rel=\"noopener noreferrer\">issues with external cache connection</a>. While they are not solved we have to use  command to build images. It is not so bad, but is another point of configuration which we will cover in this post.</p></blockquote><h3>Registry authorization and traffic encryption<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#registry-authorization-and-traffic-encryption\" aria-label=\"Direct link to Registry authorization and traffic encryption\" title=\"Direct link to Registry authorization and traffic encryption\">‚Äã</a></h3><p>Hosting custom CNCF registry, from other hand is a security responsibility.</p><p>If you don't protect it right, someone will be able to push any image to your registry and then pull it to your EC2 instance. This is a big security issue, so we have to protect our registry.</p><p>First of all we need to set some authorization to our registry so everyone who will push/pull images will be authorized. Here we have 2 options: HTTP basic auth and Client certificate auth. We will use first one as it is easier to setup. We will generate basic login and password automatically in terraform so no extra actions are needed from you.</p><p>But this is not enough. Basic auth is not encrypted, so someone can perform MITM attack and get your credentials. So we need to encrypt traffic between CI and registry. We can do it by using TLS certificates. So we will generate self-signed TLS certificates, and attach them to our registry.</p><p>Assume you have your AdminForth project in .</p><p>Create file  in :</p><p>create folder  and create file  inside:</p><h2>Step 3 - create a SSH keypair<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-3---create-a-ssh-keypair\" aria-label=\"Direct link to Step 3 - create a SSH keypair\" title=\"Direct link to Step 3 - create a SSH keypair\">‚Äã</a></h2><p>Make sure you are still in  folder, run next command:</p><p>Now it should create  and  files with your SSH keypair. Terraform script will put the public key to the EC2 instance and will use private key to connect to the instance. Also you will be able to use it to connect to the instance manually.</p><h2>Step 4 - create TLS certificates to encrypt traffic between CI and registry<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-4---create-tls-certificates-to-encrypt-traffic-between-ci-and-registry\" aria-label=\"Direct link to Step 4 - create TLS certificates to encrypt traffic between CI and registry\" title=\"Direct link to Step 4 - create TLS certificates to encrypt traffic between CI and registry\">‚Äã</a></h2><p>Make sure you are still in  folder, run next command:</p><p>Run next command to create TLS certificates:</p><p>This will create  and  files.</p><h2>Step 5 - .gitignore file<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-5---gitignore-file\" aria-label=\"Direct link to Step 5 - .gitignore file\" title=\"Direct link to Step 5 - .gitignore file\">‚Äã</a></h2><p>Create  file with next content:</p><h2>Step 6 - buildx bake file<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-6---buildx-bake-file\" aria-label=\"Direct link to Step 6 - buildx bake file\" title=\"Direct link to Step 6 - buildx bake file\">‚Äã</a></h2><p>Create file :</p><h2>Step 7 - main terraform file main.tf<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-7---main-terraform-file-maintf\" aria-label=\"Direct link to Step 7 - main terraform file main.tf\" title=\"Direct link to Step 7 - main terraform file main.tf\">‚Äã</a></h2><p>Create file  in  folder:</p><blockquote><p>üëÜ Replace  with your app name (no spaces, only underscores or letters)</p></blockquote><h3>Step 7.1 - Configure AWS Profile<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-71---configure-aws-profile\" aria-label=\"Direct link to Step 7.1 - Configure AWS Profile\" title=\"Direct link to Step 7.1 - Configure AWS Profile\">‚Äã</a></h3><p>Open or create file  and add (if not already there):</p><h3>Step 7.2 - Run deployment<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-72---run-deployment\" aria-label=\"Direct link to Step 7.2 - Run deployment\" title=\"Direct link to Step 7.2 - Run deployment\">‚Äã</a></h3><p>To run the deployment first time, you need to run:</p><h2>Step 8 - Migrate state to the cloud<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-8---migrate-state-to-the-cloud\" aria-label=\"Direct link to Step 8 - Migrate state to the cloud\" title=\"Direct link to Step 8 - Migrate state to the cloud\">‚Äã</a></h2><p>First deployment had to create S3 bucket for storing Terraform state. Now we need to migrate the state to the cloud.</p><p>Add to the end of :</p><blockquote><p>üëÜ Replace  with your app name (no spaces, only underscores or letters).\nUnfortunately we can't use variables, HashiCorp thinks it is too dangerous üò•</p></blockquote><p>Now you can delete local  file and  file as they are in the cloud now.</p><h2>Step 9 - CI/CD - Github Actions<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-9---cicd---github-actions\" aria-label=\"Direct link to Step 9 - CI/CD - Github Actions\" title=\"Direct link to Step 9 - CI/CD - Github Actions\">‚Äã</a></h2><p>Create file <code>.github/workflows/deploy.yml</code>:</p><div><div>.github/workflows/deploy.yml</div></div><h3>Step 8.1 - Add secrets to GitHub<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#step-81---add-secrets-to-github\" aria-label=\"Direct link to Step 8.1 - Add secrets to GitHub\" title=\"Direct link to Step 8.1 - Add secrets to GitHub\">‚Äã</a></h3><p>Go to your GitHub repository, then  -&gt;  -&gt;  and add:</p><ul><li> - your AWS access key</li><li><code>VAULT_AWS_SECRET_ACCESS_KEY</code> - your AWS secret key</li><li> - execute  and paste to GitHub secrets</li><li> - execute  and paste to GitHub secrets</li><li> - execute  and paste to GitHub secrets</li><li> - execute  and paste to GitHub secrets</li></ul><p>Now you can push your changes to GitHub and see how it will be deployed automatically.</p><p>Once you will have sensitive tokens/passwords in your apps you have to store them in a secure way.</p><p>Simplest way is to use GitHub secrets.</p><p>Let's imagine you have  which will be used one of AI-powered plugins of adminforth. We can't put this key to the code, so we have to store it in GitHub secrets.</p><p>Open your GitHub repository, then  -&gt;  -&gt;  and add  with your key.</p><p>Now open GitHub actions file and add it to the  section:</p><div><div>.github/workflows/deploy.yml</div></div><p>Next add it to the  script:</p><p>In the same way you can add any other secrets to your GitHub actions.</p><h3>Out of space on EC2 instance? Extend EBS volume<a href=\"https://adminforth.dev/blog/compose-ec2-deployment-github-actions-registry/#out-of-space-on-ec2-instance-extend-ebs-volume\" aria-label=\"Direct link to Out of space on EC2 instance? Extend EBS volume\" title=\"Direct link to Out of space on EC2 instance? Extend EBS volume\">‚Äã</a></h3><p>To upgrade EBS volume size you have to do next steps:</p><p>This will increase physical size of EBS volume, but you have to increase filesystem size too.</p><blockquote><p>You can find your EC2 IP in AWS console by visiting EC2 -&gt; Instances -&gt; Your instance -&gt; IPv4 Public IP</p></blockquote><p>This would show something like this:</p><p>Here we see that  is our disk and  is our partition.</p><p>Now to extend partition run:</p><p>This will extend partition to the full disk size. No reboot is needed.</p>","contentLength":11283,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iubdcw/iaac_simplified_automating_ec2_deployments_with/"},{"title":"Google's Shift to Rust Programming Cuts Android Memory Vulnerabilities by 68%","url":"https://thehackernews.com/2024/09/googles-shift-to-rust-programming-cuts.html","date":1740089695,"author":"/u/Unerring-Ocean","guid":7468,"unread":true,"content":"<p>Google has revealed that its transition to memory-safe languages such as Rust as part of its secure-by-design approach has led to the percentage of memory-safe vulnerabilities discovered in Android dropping from 76% to 24% over a period of six years.</p><p>The tech giant said focusing on <a href=\"https://blog.google/technology/safety-security/tackling-cybersecurity-vulnerabilities-through-secure-by-design/\" rel=\"noopener\" target=\"_blank\">Safe Coding</a> for new features not only reduces the overall security risk of a codebase, but also makes the switch more \"scalable and cost-effective.\"</p><p>Eventually, this leads to a drop in memory safety vulnerabilities as new memory unsafe development slows down after a certain period of time, and new memory safe development takes over, Google's Jeff Vander Stoep and Alex Rebert <a href=\"https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html\" rel=\"noopener\" target=\"_blank\">said</a> in a post shared with The Hacker News.</p><p>Perhaps even more interestingly, the number of memory safety vulnerabilities tends to register a drop notwithstanding an increase in the quantity of new memory unsafe code.</p><p>The paradox is explained by the fact that vulnerabilities decay exponentially, with a study finding that a high number of vulnerabilities often reside in new or recently modified code.</p><p>\"The problem is overwhelmingly with new code, necessitating a fundamental change in how we develop code,\" Vander Stoep and Rebert noted. \"Code matures and gets safer with time, exponentially, making the returns on investments like rewrites diminish over time as code gets older.\"</p><p>Google, which <a href=\"https://thehackernews.com/2021/04/android-to-support-rust-programming.html\" rel=\"noopener\" target=\"_blank\">formally announced</a> its plans to support the Rust programming language in Android way back in April 2021, said it began prioritizing transitioning new development to memory-safe languages around 2019.</p><p>As a result, the number of memory safety vulnerabilities discovered in the operating system has declined from <a href=\"https://security.googleblog.com/2022/12/memory-safe-languages-in-android-13.html\" rel=\"noopener\" target=\"_blank\">223 in 2019</a> to less than 50 in 2024.</p><p>It also goes without saying that much of the decrease in such flaws is down to advancements in the ways devised to combat them, moving from reactive patching to proactive mitigating to proactive vulnerability discovery using tools like <a href=\"https://thehackernews.com/2023/12/google-using-clang-sanitizers-to.html\" rel=\"noopener\" target=\"_blank\">Clang sanitizers</a>.</p><p>The tech giant further noted that memory safety strategies should evolve even more to prioritize \"high-assurance prevention\" by incorporating <a href=\"https://dl.acm.org/doi/10.1145/3651621\" rel=\"noopener\" target=\"_blank\">secure-by-design principles</a> that enshrine security into the very foundations. </p><p>\"Instead of focusing on the interventions applied (mitigations, fuzzing), or attempting to use past performance to predict future security, Safe Coding allows us to make strong assertions about the code's properties and what can or cannot happen based on those properties,\" Vander Stoep and Rebert said.</p><p>That's not all. Google said it is also focusing on offering interoperability between Rust, C++, and Kotlin, instead of code rewrites, as a \"practical and incremental approach\" to embracing memory-safe languages and ultimately eliminating entire vulnerability classes.</p><p>\"Adopting Safe Coding in new code offers a paradigm shift, allowing us to leverage the inherent decay of vulnerabilities to our advantage, even in large existing systems,\" it said.</p><p>\"The concept is simple: once we turn off the tap of new vulnerabilities, they decrease exponentially, making all of our code safer, increasing the effectiveness of security design, and alleviating the scalability challenges associated with existing memory safety strategies such that they can be applied more effectively in a targeted manner.\"</p><p>The development comes as Google touted increased collaboration with Arm's product security and graphics processing unit (GPU) engineering teams to flag multiple shortcomings and elevate the overall security of the GPU software/firmware stack across the Android ecosystem.</p><p>\"Proactive testing is good hygiene as it can lead to the detection and resolution of new vulnerabilities before they're exploited,\" Google and Arm <a href=\"https://security.googleblog.com/2024/09/google-arm-raising-bar-on-gpu-security.html\" rel=\"noopener\" target=\"_blank\">said</a>.</p><div>Found this article interesting?  Follow us on <a href=\"https://twitter.com/thehackersnews\" rel=\"noopener\" target=\"_blank\">Twitter </a> and <a href=\"https://www.linkedin.com/company/thehackernews/\" rel=\"noopener\" target=\"_blank\">LinkedIn</a> to read more exclusive content we post.</div>","contentLength":3792,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iub0rk/googles_shift_to_rust_programming_cuts_android/"},{"title":"[D] Are there any theoretical machine learning papers that have significantly helped practitioners?","url":"https://www.reddit.com/r/MachineLearning/comments/1iuanhy/d_are_there_any_theoretical_machine_learning/","date":1740088779,"author":"/u/nihaomundo123","guid":8455,"unread":true,"content":"<p>21M deciding whether or not to specialize in theoretical ML for their math PhD. Specifically, I am interested in</p><p>ii) but NOT interested in papers focusing on improving empirical performance, like the original dropout and batch normalization papers.</p><p>I want to work on something with the potential for deep impact during my PhD, yet still theoretical. When trying to find out if the understanding-based questions in category i) fits this description, however, I could not find much on the web...</p><p><strong>If anyone has any specific examples of papers whose main focus was to understand some phenomena, and that ended up revolutionizing things for practitioners, would appreciate it :)</strong></p>","contentLength":670,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The State of Scala & Clojure Surveys: How is functional programming on JVM doing","url":"https://www.jvm-weekly.com/p/the-state-of-scala-and-clojure-surveys","date":1740088259,"author":"/u/ArturSkowronski","guid":8574,"unread":true,"content":"<p>The title might be a bit of an overstatement ‚Äì don‚Äôt expect a very extensive analysis of functional programming trends. I wanted to focus on two surveys that have appeared recently, which tell us a bit about languages that many of you probably used in a previous reincarnation cycle, but have already forgotten about.</p><p>Of course, the usual disclaimer at the beginning ‚Äì we know that surveys tend to show what they feel is worth showing and have a certain narrative power.</p><p>Having that in mind, I think we can begin.</p><p>First, let‚Äôs look at the people who filled out the survey ‚Äì demographics tell us a lot about the quality of the results and what we can expect. We have as many as 232 responses, with 75% Software Engineers and 49.6% people in tech-lead or related areas ‚Äì apparently, many of us wear several hats at once (yes, I know that pain too). It turned out that most of them work on closed-source projects (87.5%), although there‚Äôs no shortage of hardcore open-source folks (18.1%). I think that fairly reflects the state of the industry.</p><p>An overwhelming majority of respondents like or love Scala: 49.1% love it, 44% rather like it. The remaining 6.9% are still undecided, and 0.9% (i.e., 2 people) have fallen into Scala-depression. However here we also hit, to some extent, the ‚Äúpeak‚Äù of people interested in the topic - those willing to fill out the Scala Survey.</p><p>The average age of projects is 7 years, with a median of 6 years ‚Äì that‚Äôs quite‚Ä¶ a lot. It also shows that quite a bit of Scala is legacy projects ‚Äì at least in the surveyed group, ‚Äúgreenfields‚Äù are relatively rare.</p><p>Typelevel (41.8%), Akka (35.3%), ZIO (23.3%), and Play (15.5%). And of course, Spark (7.7%) ‚Äì let‚Äôs not forget that big data elephant in the room, though the days when it was synonymous with Data seem to be behind us. These people have a new best friend.</p><p>Moreover, more than half of the projects (53%) combine different ecosystems such as Akka and Cats, indicating that we‚Äôre building increasingly hybrid beasts. 36.2% are ‚Äúmonogamists‚Äù relying entirely on a single library (ZIO, we‚Äôre looking at you), and 10.8% are the brave ones using only the standard library.</p><p><a href=\"https://www.linkedin.com/article/edit/7298227473140305920/#\" rel=\"\">VirtusLab</a><a href=\"https://github.com/scalameta/metals\" rel=\"\">project here</a></p><p>SBT beats everyone hands down (87.5%). Scala-CLI (11.2%) is relatively new but has decent traction, and Bazel (7.8%) and Maven (7.3%) also have loyal fans. </p><p>22.4% of commercial projects have already switched to Scala 3, but as many as 37% do not plan to. Why? Because as usual, the ecosystem is (still) not fully ready, there‚Äôs a lack of resources, and management is pushing the topic aside. You know that feeling when a new version of a language tempts you, but there are dozens of ‚Äúwork in progress‚Äù branches piling up in the repo‚Ä¶?</p><p>Talking about the problems, the report shows three major ones:</p><ul><li><p><strong>Fragmentation of the ecosystem and migration issues to Scala 3</strong></p></li><li><p><strong>Lack of resources to maintain older projects.</strong></p></li></ul><p><strong>recruiting Scala developers</strong></p><p>Given these recruitment problems, it‚Äôs not surprising that 68.6% allow remote work, which at least somewhat makes life easier for those who have managed to settle in the Bieszczady Mountains or in Bali.</p><ul></ul><p>Despite all these challenges, 88.4% of respondents would still choose Scala for new projects without hesitation. It shows that the JVM community sees great potential in Scala, but also knows that working on its further development and tooling is a marathon, not a sprint.</p><p><a href=\"https://bit.ly/scala-report\" rel=\"\">the report is full of interesting details</a></p><p>Now, let's take a look at the other report I have for you today.</p><p><a href=\"https://www.linkedin.com/article/edit/7298227473140305920/#\" rel=\"\">Alex Miller</a><a href=\"https://clojure.org/news/2024/12/02/state-of-clojure-2024\" rel=\"\">State of Clojure</a></p><p>Let‚Äôs start with what warms the hearts of backend folks the most: does Clojure live in real projects and is it more than just a hobby experiment? Definitely yes! 73% of respondents use Clojure at work, mainly in web development, commercial services, and enterprise applications. Their services often end up in the cloud ‚Äì public (58%) or private (26%). So you can say with confidence that the ‚ÄúLispy DSL‚Äù is conquering more and more server rooms and Docker containers.</p><p>What about team size? Most are small teams (up to 10 people), though there are also true giants ‚Äì Nubank, with over a thousand Clojure developers, is a prime example. It‚Äôs no coincidence they‚Äôre now responsible for the development of the language.</p><p>Regarding the adoption of new versions, things look surprisingly good. As many as 58% have already moved to Clojure 1.12, released in September 2024, which indicates that stability and a lack of painful breaking changes are quite a motivator.</p><p>Here we see that Java 21 LTS already has 54% of users, and Java 8 is losing ground in favor of newer versions (only 9% remain with the old-timer, which is better than in Java itself). Probably for this reason, Clojure plans to raise the base version in subsequent releases (much like Scala, but we‚Äôll talk about that next week).</p><p><a href=\"https://babashka.org/\" rel=\"\">Babashka</a></p><p>An example is Babashka ‚Äì a dialect that enjoys huge popularity (93% of respondents who use dialects had dealt with it) because it allows scripts to be run quickly, without the start-up delays of the JVM. ClojureDart, on the other hand, brings Clojure into the Dart ecosystem, opening new perspectives for web and mobile apps. Other projects like Squint, Jank, and Cherry demonstrate the community‚Äôs ongoing creativity ‚Äì each introduces its own modifications, often experimental, allowing the Clojure philosophy to adapt to entirely new conditions.</p><p>Leiningen and deps.edn continues to vie for space among dependency management tools ‚Äì we can see that deps.edn is gaining strength, and nRepl, REBL, and other plugins help make REPL feel like home.</p><p>A special section of the survey examines people who have just started their adventure with Clojure (less than a year of experience). The report has been tracking programmers‚Äô migration paths to Clojure for years. It appears they still largely come from Java, JavaScript, and Python. Ruby and C++ are in decline, whereas C# is starting to gain slightly ‚Äì perhaps thanks to the ‚Äúfunctional awakening‚Äù in the .NET ecosystem.</p><p><strong>Biggest challenges for newcomers?</strong></p><p>If you‚Äôve read this far, you‚Äôre probably as happy as I am to see that Clojure keeps evolving. On one hand ‚Äì a stable, mature platform, and on the other ‚Äì new dialects, a growing community not just in corporate settings but also in open-source projects and even in the gaming industry (yes, yes, I‚Äôve seen it!). State of Clojure 2024 shows that Lisp on the JVM is still a very strong player: a steady, balanced development without revolutionary changes, yet‚Ä¶ there‚Äôs always something new to discover.</p><p><a href=\"https://clojure.org/news/2024/12/02/state-of-clojure-2024\" rel=\"\">through the full report</a></p><p>Happy coding ‚Äì and until next time in JVM Weekly!</p>","contentLength":6662,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iuag90/the_state_of_scala_clojure_surveys_how_is/"},{"title":"[R] Detecting LLM Hallucinations using Information Theory","url":"https://www.reddit.com/r/MachineLearning/comments/1iu9ryi/r_detecting_llm_hallucinations_using_information/","date":1740086564,"author":"/u/meltingwaxcandle","guid":7496,"unread":true,"content":"<p>LLM hallucinations and errors are a major challenge, but what if we could predict when they happen? Nature had a great <a href=\"https://www.nature.com/articles/s41586-024-07421-0\">publication</a> on semantic entropy, but I haven't seen many practical guides on production patterns for LLMs.</p><ol><li><strong>Sequence log-probabilities</strong> provides a free, effective way to detect unreliable outputs (can be interpreted as \"LLM confidence\").</li><li><strong>High-confidence responses were nearly twice as accurate</strong> as low-confidence ones (76% vs 45%).</li><li>Using this approach, we can automatically <strong>filter poor responses, introduce human review, or iterative RAG pipelines</strong>.</li></ol><p><strong>Experiment setup is simple</strong>: generate 1000 RAG-supported LLM responses to various questions. Ask experts to blindly evaluate responses for quality. See how much LLM confidence predicts quality.</p><p>Bonus: precision recall curve for an LLM.</p><p>My interpretation is that LLM operates in a higher entropy (less predictable output / flatter token likelihood distributions) regime when it's not confident. So it's dealing with more uncertainty and starts to break down essentially.</p><p>Regardless of your opinions on validity of LLMs, this feels like one of the simplest, but effective methods to catch a bulk of errors. </p>","contentLength":1162,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why do temporaries need to explicitly borrowed?","url":"https://www.reddit.com/r/rust/comments/1iu8jsn/why_do_temporaries_need_to_explicitly_borrowed/","date":1740083498,"author":"/u/parkotron","guid":8474,"unread":true,"content":"<p>As a long time C++ dev, I feel it didn't take me very long to pick up Rust's reference semantics and borrowing rules, but there one place where I constantly find myself forgetting to include the : passing temporaries into functions taking references.</p><pre><code>fn foo(s: &amp;str) { println!(\"The str is: {s}\"); } fn bar() -&gt; String { \"temporary\".to_string() } fn main() { foo(&amp;bar()); // ^ I always forget this ampersand until reminded by the compiler. } </code></pre><p>Rust's explicit  and  operators make a lot of sense to me: given a chunk of code, it should be obvious where a value has been borrowed and what kind of borrow it is. One should never be surprised to learn a reference was taken, because it's right there in the code.</p><p>But in the case of temporary values, it really doesn't matter, does it? Whatever a function call does (or doesn't) do to a temporary value passed to it, the effect cannot be observed in the surrounding code, since the temporary is gone by the end of the statement.</p><p>Is there a subtlety I'm missing here? Does that ampersand on a temporary convey useful information to an experienced Rust dev? Or is it really just syntactic noise, as it seems to me? Are there corner cases I'm just not considering? Could a future edition of Rust be changed to implicitly borrow from temporaries (like it implicitly borrows to make method calls)? Is my mental model just wrong?</p><p>To be perfectly clear, this isn't a criticism, just curiosity. Clearly a lot of thought has been put into the language's design and syntax. This is just the only place I've encountered where Rust's explicitness doesn't feel completely justified.</p>","contentLength":1609,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"To the purists rocking linux from scratch systems: how was it?","url":"https://www.reddit.com/r/linux/comments/1iu7gc4/to_the_purists_rocking_linux_from_scratch_systems/","date":1740080811,"author":"/u/0110010001101111","guid":8631,"unread":true,"content":"<p>how was your experience from installation to day to day management? what was your use case to build such system over just choosing a distro.</p><p>the apps and the updating it. is it a hassle?</p><p>is it a viable or reasonable option as a daily driver. i just wanted to get some insights about it.</p><p>what do you like or dont like about it. the tradeoffs you were willing to accept, etc. </p>","contentLength":371,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI can fix bugs‚Äîbut can‚Äôt find them: OpenAI‚Äôs study highlights limits of LLMs in software engineering","url":"https://venturebeat.com/ai/ai-can-fix-bugs-but-cant-find-them-openais-study-highlights-limits-of-llms-in-software-engineering/","date":1740078804,"author":"/u/F0urLeafCl0ver","guid":8473,"unread":true,"content":"<div><p><em>Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. <a href=\"https://venturebeat.com/newsletters/?utm_source=VBsite&amp;utm_medium=desktopNav\" data-type=\"link\" data-id=\"https://venturebeat.com/newsletters/?utm_source=VBsite&amp;utm_medium=desktopNav\">Learn More</a></em></p></div><p>In a <a href=\"https://arxiv.org/pdf/2502.12115\" target=\"_blank\" rel=\"noreferrer noopener\">new paper</a>, <a href=\"https://openai.com/\" target=\"_blank\" rel=\"noreferrer noopener\">OpenAI</a> researchers detail how they developed an LLM benchmark called SWE-Lancer to test how much foundation models can earn from real-life freelance software engineering tasks. The test found that, while the models can solve bugs, they can‚Äôt see why the bug exists and continue to make more mistakes.&nbsp;</p><p>The researchers tasked three LLMs ‚Äî OpenAI‚Äôs GPT-4o and o1 and <a href=\"https://venturebeat.com/ai/the-code-whisperer-how-anthropics-claude-is-changing-the-game-for-software-developers/\">Anthropic‚Äôs Claude-3.5 Sonnet</a> ‚Äî with 1,488 freelance software engineer tasks <a href=\"https://venturebeat.com/business/upwork-shares-leap-40-as-ceo-calls-ipo-beginning-of-a-new-chapter/\">from the freelance platform</a> Upwork amounting to $1 million in payouts. They divided the tasks into two categories: individual contributor tasks (resolving bugs or implementing features), and management tasks (where the model roleplays as a manager who will choose the best proposal to resolve issues).&nbsp;</p><p>‚ÄúResults indicate that the real-world freelance work in our benchmark remains challenging for frontier language models,‚Äù the researchers write.&nbsp;</p><p>The test shows that foundation models cannot fully replace human engineers. While they can help solve bugs, they‚Äôre not quite at the level where they can start earning freelancing cash by themselves.&nbsp;</p><h2>Benchmarking freelancing models</h2><p>The researchers and 100 other professional software engineers identified potential tasks on Upwork and, without changing any words, fed these to a Docker container to create the SWE-Lancer dataset. The container does not have internet access and cannot access GitHub ‚Äúto avoid the possible of models scraping code diffs or pull request details,‚Äù they explained. </p><p>The team identified 764 individual contributor tasks, totaling about $414,775, ranging from 15-minute bug fixes to weeklong feature requests. These tasks, which included reviewing freelancer proposals and job postings, would pay out $585,225.</p><p>The tasks were added to the expensing platform Expensify.&nbsp;</p><p>The researchers generated prompts based on the task title and description and a snapshot of the codebase. If there were additional proposals to resolve the issue, ‚Äúwe also generated a management task using the issue description and list of proposals,‚Äù they explained. </p><p>From here, the researchers moved to end-to-end test development. They wrote Playwright tests for each task that applies these generated patches which were then ‚Äútriple-verified‚Äù by professional software engineers.</p><p>‚ÄúTests simulate real-world user flows, such as logging into the application, performing complex actions (making financial transactions) and verifying that the model‚Äôs solution works as expected,‚Äù the paper explains.&nbsp;</p><p>After running the test, the researchers found that none of the models earned the full $1 million value of the tasks. Claude 3.5 Sonnet, the best-performing model, earned only $208,050 and resolved 26.2% of the individual contributor issues. However, the researchers point out, ‚Äúthe majority of its solutions are incorrect, and higher reliability is needed for trustworthy deployment.‚Äù</p><p>The models performed well across most individual contributor tasks, with Claude 3.5-Sonnet performing best, followed by o1 and GPT-4o.&nbsp;</p><p>‚ÄúAgents excel at localizing, but fail to root cause, resulting in partial or flawed solutions,‚Äù the report explains. ‚ÄúAgents pinpoint the source of an issue remarkably quickly, using keyword searches across the whole repository to quickly locate the relevant file and functions ‚Äî often far faster than a human would. However, they often exhibit a limited understanding of how the issue spans multiple components or files, and fail to address the root cause, leading to solutions that are incorrect or insufficiently comprehensive. We rarely find cases where the agent aims to reproduce the issue or fails due to not finding the right file or location to edit.‚Äù</p><p>Interestingly, the models all performed better on manager tasks that required reasoning to evaluate technical understanding.</p><p>These benchmark tests showed that AI models can solve some ‚Äúlow-level‚Äù coding problems and can‚Äôt replace ‚Äúlow-level‚Äù software engineers yet. The models still took time, often made mistakes, and couldn‚Äôt chase a bug around to find the root cause of coding problems. Many ‚Äúlow-level‚Äù engineers work better, but the researchers said this may not be the case for very long.&nbsp;</p>","contentLength":4364,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1iu6mdl/ai_can_fix_bugsbut_cant_find_them_openais_study/"},{"title":"TwinSong: Jupyter notebook built from scratch in Rust","url":"https://www.reddit.com/r/rust/comments/1iu5tpa/twinsong_jupyter_notebook_built_from_scratch_in/","date":1740076846,"author":"/u/winter-moon","guid":7469,"unread":true,"content":"<p>I've spent a lot of time working with Python in Jupyter notebooks, but one thing has always bothered me: the way code and outputs are mixed together. While this is great for tutorials and interactive documentation, it's less ideal for exploratory work or data processing, where I just want to interact with Python without the constraints of a document-style interface. </p><p>To address this, I created TwinSong, a Jupyter alternative that separates code and outputs. Right now, it's primarily a UX experiment, but core features like editing and executing cells are already in place. Instead of modifying Jupyter's existing codebase, I built it from scratch with a React frontend and a Rust backend.</p><p>While performance wasn't the main focus, implementing a Python kernel driver in Rust keeps the kernel clean and avoids loading Python dependencies that might interfere with user code. Plus, as we've seen with other projects, rewriting classic Python tools in Rust can open up new possibilities.</p>","contentLength":986,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[D] Enriching token embedding with last hidden state?","url":"https://www.reddit.com/r/MachineLearning/comments/1iu4ymf/d_enriching_token_embedding_with_last_hidden_state/","date":1740074778,"author":"/u/Academic_Sleep1118","guid":8599,"unread":true,"content":"<p>Looking at a decoder transformer working process from an information theory standpoint, we can see that the information available in the last hidden state is collapsed into a single token during generation. It means that you collapse a hidden state that, in theory, has about:</p><p> (or whatever quant) bits of information to something like:</p><p>I wonder if it's a good thing (sorry for the naive phrasing). The information used by a transformer to predict the next token is entirely stored in its context window and does not involve any recurrent state. So, predicting the next token of a sequence the transformer was just fed with is going to yield the exact same result as doing so for the same sequence if it were entirely generated by the transformer itself.</p><p>Fair enough, in some sense: whether the sequence was generated or just read doesn't change anything about what the next token should be.</p><p>But on the other hand, this approach means that  the information flow between tokens has to happen through the attention mechanism. There's no way for the transformer to embed some nuance or flavor into the predicted token embedding. Like in:</p><p><em>\"Well, I predicted the token '</em></p><p>When the next token is predicted, this nuance that was likely present in the last hidden state (or even in the softmaxed output probability distribution) is totally lost.</p><p>So while I was having a little walk yesterday, I was thinking that it might be a good idea to add some information to the token embeddings using something like:</p><p><strong>augmented_embedding = embedding(token) + F(last_hidden_state)</strong></p><p>(It would be important to make sure that:</p><p><strong>‚ÄñF(last_hidden_state)‚Äñ ‚â™ ‚Äñembedding(token)‚Äñ</strong></p><p>I have tried to find papers on this subject and asked for feedback from Claude, ChatGPT, and Perplexity.</p><ul><li> told me it was <em>\"an incredibly insightful idea.\"</em></li><li> hallucinated a paper on the subject.</li><li> gave me a very long list of totally unrelated sources.</li></ul><p>So I'm turning to you guys. I would love it if some big-brained guy told me why other big-brained guys decided not to follow this idea, or why it doesn't work.</p><p>Here are some things I identified as potentially problematic:</p><p>Transformers are nice to train with heavy parallelization precisely because they are not recursive. Each sequence of size  can give  independent training examples. Injecting last hidden states' information in token embeddings would break some of that parallelization.</p><p>It would still be possible to train it efficiently, I guess.</p><ol><li>First, take the () vanilla sequences and get the predictions.</li><li>Then, for each prediction, store the last hidden state and update the corresponding token embedding in each of the sequences where it appears.</li><li>Now, you have a new set of training sequences, with all (but the first) token embeddings updated.</li><li>You can repeat this process indefinitely. I hope it converges ^^</li></ol><p>This really looks like a diffusion process, by the way. That brings me to the next point:</p><p>Here, I am not very competent. What are the conditions that define such a process' stability? My uneducated guess is that if you keep:<strong>‚Äñlast_hidden_state_contribution‚Äñ ‚â™ ‚Äñaugmented_token_embedding‚Äñ</strong> you should not have many problems. But it would also limit the information flow. I guess there's a trade-off, and I wouldn't be surprised if it's not good enough.</p><p>What do you guys think? Has this already been tried somewhere? Is there a fundamental reason this wouldn't work?</p>","contentLength":3370,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Thoughts on an AI powered bipedal, musculoskeletal , anatomically accurate, synthetic human with over 200 degrees of freedom, over 1,000 Myofibers, and 500 sensors?","url":"https://v.redd.it/b1iwrsu32cke1","date":1740074243,"author":"/u/VivariuM_007","guid":7436,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/artificial/comments/1iu4qex/thoughts_on_an_ai_powered_bipedal_musculoskeletal/"},{"title":"Announcing Rust 1.85.0 and Rust 2024 | Rust Blog","url":"https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html","date":1740071479,"author":"/u/slanterns","guid":7359,"unread":true,"content":"<p>The Rust team is happy to announce a new version of Rust, 1.85.0. This stabilizes the 2024 edition as well.\nRust is a programming language empowering everyone to build reliable and efficient software.</p><p>If you have a previous version of Rust installed via , you can get 1.85.0 with:</p><p>If you'd like to help us out by testing future releases, you might consider updating locally to use the beta channel () or the nightly channel (). Please <a href=\"https://github.com/rust-lang/rust/issues/new/choose\">report</a> any bugs you might come across!</p><p>We are excited to announce that the Rust 2024 Edition is now stable!\nEditions are a mechanism for opt-in changes that may otherwise pose a backwards compatibility risk. See <a href=\"https://doc.rust-lang.org/edition-guide/editions/index.html\">the edition guide</a> for details on how this is achieved, and detailed instructions on how to migrate.</p><p>This is the largest edition we have released. The <a href=\"https://doc.rust-lang.org/edition-guide/rust-2024/index.html\">edition guide</a> contains detailed information about each change, but as a summary, here are all the changes:</p><p>The guide includes migration instructions for all new features, and in general\n<a href=\"https://doc.rust-lang.org/edition-guide/editions/transitioning-an-existing-project-to-a-new-edition.html\">transitioning an existing project to a new edition</a>.\nIn many cases  can automate the necessary changes. You may even find that no changes in your code are needed at all for 2024!</p><p>Note that automatic fixes via  are very conservative to avoid ever changing the semantics of your code. In many cases you may wish to keep your code the same and use the new semantics of Rust 2024; for instance, continuing to use the  macro matcher, and ignoring the conversions of conditionals because you want the new 2024 drop order semantics. The result of  should not be considered a recommendation, just a conservative conversion that preserves behavior.</p><p> people came together to create this edition. We'd like to thank them all for their hard work!</p><p>Rust now supports asynchronous closures like  which return futures when called. This works like an  which can also capture values from the local environment, just like the difference between regular closures and functions. This also comes with 3 analogous traits in the standard library prelude: , , and .</p><p>In some cases, you could already approximate this with a regular closure and an asynchronous block, like . However, the future returned by such an inner block is not able to borrow from the closure captures, but this does work with  closures:</p><pre><code>let mut vec: Vec&lt;String&gt; = vec![];\n\nlet closure = async || {\n    vec.push(ready(String::from(\"\")).await);\n};\n</code></pre><p>It also has not been possible to properly express higher-ranked function signatures with the  traits returning a , but you can write this with the  traits:</p><pre><code>use core::future::Future;\nasync fn f&lt;Fut&gt;(_: impl for&lt;'a&gt; Fn(&amp;'a u8) -&gt; Fut)\nwhere\n    Fut: Future&lt;Output = ()&gt;,\n{ todo!() }\n\nasync fn f2(_: impl for&lt;'a&gt; AsyncFn(&amp;'a u8))\n{ todo!() }\n\nasync fn main() {\n    async fn g(_: &amp;u8) { todo!() }\n    f(g).await;\n    //~^ ERROR mismatched types\n    //~| ERROR one type is more general than the other\n\n    f2(g).await; // ok!\n}\n</code></pre><h3><a href=\"https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html#hiding-trait-implementations-from-diagnostics\" aria-hidden=\"true\"></a>Hiding trait implementations from diagnostics</h3><p>The new <code>#[diagnostic::do_not_recommend]</code> attribute is a hint to the compiler to not show the annotated trait implementation as part of a diagnostic message. For library authors, this is a way to keep the compiler from making suggestions that may be unhelpful or misleading. For example:</p><pre><code>pub trait Foo {}\npub trait Bar {}\n\nimpl&lt;T: Foo&gt; Bar for T {}\n\nstruct MyType;\n\nfn main() {\n    let _object: &amp;dyn Bar = &amp;MyType;\n}\n</code></pre><pre><code>error[E0277]: the trait bound `MyType: Bar` is not satisfied\n --&gt; src/main.rs:9:29\n  |\n9 |     let _object: &amp;dyn Bar = &amp;MyType;\n  |                             ^^^^ the trait `Foo` is not implemented for `MyType`\n  |\nnote: required for `MyType` to implement `Bar`\n --&gt; src/main.rs:4:14\n  |\n4 | impl&lt;T: Foo&gt; Bar for T {}\n  |         ---  ^^^     ^\n  |         |\n  |         unsatisfied trait bound introduced here\n  = note: required for the cast from `&amp;MyType` to `&amp;dyn Bar`\n</code></pre><p>For some APIs, it might make good sense for you to implement , and get  indirectly by that blanket implementation. For others, it might be expected that most users should implement  directly, so that  suggestion is a red herring. In that case, adding the diagnostic hint will change the error message like so:</p><pre><code>#[diagnostic::do_not_recommend]\nimpl&lt;T: Foo&gt; Bar for T {}\n</code></pre><pre><code>error[E0277]: the trait bound `MyType: Bar` is not satisfied\n  --&gt; src/main.rs:10:29\n   |\n10 |     let _object: &amp;dyn Bar = &amp;MyType;\n   |                             ^^^^ the trait `Bar` is not implemented for `MyType`\n   |\n   = note: required for the cast from `&amp;MyType` to `&amp;dyn Bar`\n</code></pre><h3><a href=\"https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html#fromiterator-and-extend-for-tuples\" aria-hidden=\"true\"></a> and  for tuples</h3><p>Earlier versions of Rust implemented convenience traits for iterators of  tuple pairs to behave like , with  in 1.56 and  in 1.79. These have now been  to more tuple lengths, from singleton  through to 12 items long, . For example, you can now use  to fanout into multiple collections at once:</p><pre><code>use std::collections::{LinkedList, VecDeque};\nfn main() {\n    let (squares, cubes, tesseracts): (Vec&lt;_&gt;, VecDeque&lt;_&gt;, LinkedList&lt;_&gt;) =\n        (0i32..10).map(|i| (i * i, i.pow(3), i.pow(4))).collect();\n    println!(\"{squares:?}\");\n    println!(\"{cubes:?}\");\n    println!(\"{tesseracts:?}\");\n}\n</code></pre><pre><code>[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n[0, 1, 16, 81, 256, 625, 1296, 2401, 4096, 6561]\n</code></pre><h3><a href=\"https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html#updates-to-stdenvhome_dir\" aria-hidden=\"true\"></a>Updates to </h3><p> has been deprecated for years, because it can give surprising results in some Windows configurations if the  environment variable is set (which is not the normal configuration on Windows). We had previously avoided changing its behavior, out of concern for compatibility with code depending on this non-standard configuration. Given how long this function has been deprecated, we're now updating its behavior as a bug fix, and a subsequent release will remove the deprecation for this function.</p><p>These APIs are now stable in const contexts</p><p>Many people came together to create Rust 1.85.0. We couldn't have done it without all of you. <a href=\"https://thanks.rust-lang.org/rust/1.85.0/\">Thanks!</a></p>","contentLength":5852,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1iu3l0a/announcing_rust_1850_and_rust_2024_rust_blog/"},{"title":"Ugly Code and Dumb Things","url":"https://lucumr.pocoo.org/2025/2/20/ugly-code/","date":1740070620,"author":"/u/FoxInTheRedBox","guid":7438,"unread":true,"content":"<p data-date=\"2025-02-20T00:00:00\">written on Thursday, February 20, 2025</p><p>This week I had a conversation with one of our engineers about ‚Äúshitty\ncode‚Äù which lead me to sharing with him one of my more unusual\ninspirations: <a href=\"https://github.com/exflickr/flamework/\">Flamework</a>, a\npseudo framework created at Flickr.</p><div><h2>Two Passions, Two Approaches</h2><p>There are two driving passions in my work.  One is the love of creating\nbeautiful, elegant code ‚Äî making Open Source libraries and APIs that focus\non clear design and reusability.  The other passion is building quick,\npragmatic solutions for real users (who may not even be developers).  The\nlatter usually in a setting of building a product, where the product is\nnot the code.  Here, speed and iteration matter more than beautiful code\nor reusability, because success hinges on shipping something people want.</p><p>Flamework is in service of the latter, and in crass violation of the\nformer.</p><p>Early on, I realized that creating reusable code and directly solving\nproblems for users are often at odds.  My first clue came when I helped\nrun the German\n<a href=\"https://www.ubuntuusers.de/\">ubuntuusers</a> website.  It was powered by\na heavily modified version of phpBB, which despite how messy it was,\nscaled to a large user base when patched properly.  It was messy, but easy\nto adjust.  The abstractions were one layer deep.</p><p>Back then, me and a friend tried to replace it by writing my own bulletin\nboard software, <a href=\"https://web.archive.org/web/20070502223619/http://flying.circus.pocoo.org/\">Pocoo</a>.\nWorking in isolation, without users, led me down a path of\nover-engineering.  While we learned a lot and ended up creating popular\nOpen Source libraries (like Jinja, Werkzeug and Pygments), Pocoo never\nbecame a solid product.  Later, my collaborators and I <a href=\"https://github.com/inyokaproject/inyoka/\">rebuilt\nubuntuusers</a>, without the\ngoal of making it into a reusable product.  That rewrite shipped\nsuccessfully and it lives to this very day.</p><p>But it took me years to fully realize what was happening here: reusability\nis not that important when you‚Äôre building an application, but it‚Äôs\ncrucial when you‚Äôre building a library or framework.</p></div><div><p>If you are unfamiliar with Flamework you should watch a talk that Cal\nHenderson gave in 2008 at DjangoCon (<a href=\"https://www.youtube.com/watch?v=i6Fr65PFqfk\">Why I hate Django</a>).  He talked about scale\nand how Django didn't solve for it.  He enumerated all the things\nimportant to him: sharding, using custom sequences for primary keys,\nforgoing joins and foreign keys, supporting database replication setups,\ndenormalizing data to the extreme.  This is also were I first learned\nabout the possibility of putting all session data into cookies via\nsigning.  It was a memorable talk for me because it showed me that there\nare shortcomings.  Django (which I used for ubuntuusers) had beautiful\nAPIs but at the time solved for little of that Cal needed.  The talk\nreally stuck with me.</p><p>At the time of the talk, Flamework did not really exist.  It was more of\nan idea and principles of engineering at Flickr.</p><p>A few years later, Flamework appeared on GitHub, not as an open-sourced\npiece of Flickr code but as a reimplementation of those same ideas.  You\ncan explore its repository and see code like this:</p><div><pre></pre></div><p>Instinctively it makes me cringe.  Is that a SQL injection?  Well you were\nsupposed to use the PHP <a href=\"https://www.php.net/manual/en/function.addslashes.php\">addslashes</a> function\nbeforehand.  But notice how it caters to sharding and clustering directly\nin the query function.</p></div><div><p>Code like this often triggers a visceral reaction, especially in engineers\nwho prize clean design.</p><p>How does something like that get created?  Cal Henderson described\nFlickr's principle as ‚Äúdoing the dumbest possible thing that will work.‚Äù\nMaybe ‚Äúdumb‚Äù is too strong ‚Äî ‚Äúsimple‚Äù might be more apt.  Yet simplicity\ncan look messy to someone expecting a meticulously engineered codebase.\nThis is not at all uncommon and I have seen it over and over.  The first\nlarge commercial project that got traction that I ever worked on (<a href=\"https://en.wikipedia.org/wiki/Plurk\">Plurk</a>) was also pretty pragmatic and\nmessy inside.  My former colleague Ben Vinegar also <a href=\"https://benv.ca/blog/posts/the-hardest-problem\">recently shared</a> a story of early,\nmessy FreshBooks code and how he came to terms with it.  Same story at\n<a href=\"https://sentry.io/welcome\">Sentry</a>.  We moved fast, we made a mess.</p><p>None of this is surprising in retrospective.  Perfect code doesn't\nguarantee success if you haven't solved a real problem for real people.\nPursuing elegance in a vacuum leads to abandoned side projects or\nframeworks nobody uses.  By contrast, clunky but functional code often\ncomes with just the right compromises for quick iteration.  And that in\nturn means a lot of messy code powers products that people love ‚Äî\nsomething that's a far bigger challenge.</p></div><div><p>I have shown Flamework's code to multiple engineers over the years and it\nusually creates such a visceral response.  It blind sights one by\nseemingly disregarding all rules of good software engineering.</p><p>That makes Flamework serve as a fascinating Rorschach test for engineers.\nAre you <a href=\"https://github.com/exflickr/flamework\">looking at it</a> with\nadmiration for the focus on some critical issues like scale, the built-in\nobservability and debugging tools.  Or are you judging it, and its\ncreators, for manually constructing SQL queries, using global variables,\nnot using classes and looking like messy PHP4 code?  Is it a pragmatic\ntool, intentionally designed to iterate quickly at scale, or is it a naive\nmess made by unskilled developers?</p><p>Would I use Flamework?  Hello no.  But I appreciate the priorities behind\nit.  If these ugly choices help you move faster, attract users and\nvalidate the product, then a rewrite, or large refactorings later are a\nsmall price to pay.</p></div><div><p>At the end of the day, where you stand on ‚Äúshitty code‚Äù depends on your\nprimary goal:</p><ul><li>Are you shipping a product and racing to meet user needs?</li><li>Or are you building a reusable library or framework meant to stand the\ntest of time?</li></ul><p>Both mindsets are valid, but they rarely coexist harmoniously in a single\ncodebase.  Flamework is a reminder that messy, simple solutions can be\npowerful if they solve real problems.  Eventually, when the time is right,\nyou can clean it up or rebuild from the ground up.</p><p>The real challenge is deciding which route to take ‚Äî and when.  Even with\nexperience, it is can be hard to know when to move from quick fixes to\nmore robust foundations.  The principles behind Flamework are also\nreflected in <a href=\"https://develop.sentry.dev/getting-started/philosophy/\">Sentry's development philosophy</a>.  One more\npoignant one being ‚ÄúEmbrace the Duct Tape‚Äù.  Yet as Sentry matured, much\nof our duct tape didn't stand the test of time, and was re-applied at\nmoments when the real solution would have been a solid foundation poured\nwith concrete.</p><p>That's because successful projects eventually grow up.  What let you\niterate fast in the beginning might eventually turn into an unmaintainable\nmess and will be rebuilt from the inside out.</p><p>I personally would never have built Flamework, it repulses me a bit.  At the\nsame time, I have a enormous respect for the people who build it.  Their\nwork and thinking has shaped how I solve problems and think of product\nengineering.</p></div>","contentLength":6780,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1iu37xs/ugly_code_and_dumb_things/"},{"title":"Why Firefox?","url":"https://www.reddit.com/r/linux/comments/1iu25zd/why_firefox/","date":1740068011,"author":"/u/Flaky_Comfortable425","guid":7437,"unread":true,"content":"<p>This actually makes me curious, when I switch between a lot of distros, jumping from Debian to CentOS to dfferent distros, I can see that they all love firefox, it's not my favorite actually, and there are plenty of internet browsers out there which is free and open source like Brave for example, still I am wondering what kind of attachment they have to this browser</p>","contentLength":368,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is anyone working on AI designed to preserve democracy?","url":"https://www.reddit.com/r/artificial/comments/1iu1n10/is_anyone_working_on_ai_designed_to_preserve/","date":1740066712,"author":"/u/BarbaGramm","guid":7466,"unread":true,"content":"<p>I‚Äôm looking for people or groups who are already working on something like this:</p><p>A decentralized AI trained to preserve the intellectual, historical, and emotional essence of democracy‚Äîwhat it actually means, not just what future regimes might redefine it to be. Think of it as a fusion of data hoarding, decentralized AI, and resistance tech, built to withstand authoritarian drift and historical revisionism.</p><p>Maybe it doesn't reach the heights of the corporate or state models, but a system that can always articulate the delta‚Äîthe difference between a true democratic society (or at least what we seem to be leaving behind) and whatever comes next. If democracy gets twisted into something unrecognizable, this AI should be able to compare, contrast, and remind people what was lost. It should be self-contained, offline-capable, decentralized, and resistant to censorship‚Äîan incorruptible witness to history.</p><p>Does this exist? Are there people in AI, decentralized infrastructure, or archival communities working toward something like this? I don‚Äôt want to reinvent the wheel if a community is already building it. If you know of any projects, frameworks, or people tackling this problem, please point me in the right direction.</p><p>If no one is doing it, shouldn't this be a project people are working on? Is there an assumption that corporate or state controlled AI will do this inherently?</p>","contentLength":1397,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rust 2024 Is Coming: baby steps","url":"https://smallcultfollowing.com/babysteps/blog/2025/02/20/rust-2024-is-coming/?utm_source=atom_feed","date":1740063180,"author":"/u/VorpalWay","guid":7288,"unread":true,"content":"<div><p>So, a little bird told me that Rust 2024 is going to become stable today, along with Rust 1.85.0. In honor of this momentous event, I have penned a little ditty that I‚Äôd like to share with you all. Unfortunately, for those of you who remember Rust 2021‚Äôs <a href=\"https://smallcultfollowing.com/babysteps/blog/2021/05/26/edition-the-song/\">‚ÄúEdition: The song‚Äù</a>, in the 3 years between Rust 2021 and now, my daughter has realized that her father is deeply uncool and so I had to take this one on solo. Anyway, enjoy! Or, you know, suffer. As the case may be.</p><p>In ChordPro format, for those of you who are inspired to play along.</p><pre tabindex=\"0\"><code>{title: Rust 2024}\n{subtitle: }\n\n{key: C}\n\n[Verse 1]\n[C] When I got functions that never return\nI write an exclamation point [G]\nBut use it for an error that could never be\nthe compiler [C] will yell at me\n\n[Verse 2]\n[C] We Rust designers, we want that too\n[C7] But we had to make a [F] change\n[F] That will be [Fm]better\n[C] Oh so much [A]better\n[D] in Rust Twenty [G7]Twenty [C]Four\n\n[Bridge]\n[Am] ... [Am] But will my program [E] build?\n[Am] Yes ... oh that‚Äôs [D7] for sure\n[F] edi-tions [G] are [C] opt in\n\n[Verse 3]\n[C] Usually when I return an `impl Trait`\neverything works out fine [G]\nbut sometimes I need a tick underscore\nand I don‚Äôt really [C] know what that‚Äôs for\n\n[Verse 4]\n[C] We Rust designers we do agree\n[C7] That was con- [F] fusing \n[F] But that will be [Fm]better\n[C] Oh so much [A]better\n[D] in Rust Twenty [G7]Twenty [C]Four\n\n[Bridge 2]\n[Am] Cargo fix will make the changes\nautomatically [G] Oh that sure sounds great...\n[Am] but wait... [Am] my de-pen-denc-[E]-ies\n[Am] Don‚Äôt worry e-[D7]ditions\n[F] inter [G] oper [C] ate\n\n[Verse 5]\n[C] Whenever I match on an ampersand T\nThe borrow [G] propagates\nBut where do I put the ampersand\nwhen I want to [C] copy again?\n\n[Verse 6]\n[C] We Rust designers, we do agree\n[C7] That really had to [F] change\n[F] That will be [Fm]better\n[C] Oh so much [A]better\n[D] in Rust Twenty [G7]Twenty [C]Four\n\n[Outro]\n[F] That will be [Fm]better\n[C] Oh so much [A]better\n[D] in Rust Twenty [G7]Twenty [C]Four\n\nOne more time!\n\n[Half speed]\n[F] That will be [Fm]better\n[C] Oh so much [A]better\n[D] in Rust Twenty [G7]Twenty [C]Four\n</code></pre></div>","contentLength":2134,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/rust/comments/1iu09jr/rust_2024_is_coming_baby_steps/"},{"title":"[D] Deepseek 681bn inference costs vs. hyperscale?","url":"https://www.reddit.com/r/MachineLearning/comments/1itys24/d_deepseek_681bn_inference_costs_vs_hyperscale/","date":1740059045,"author":"/u/sgt102","guid":8398,"unread":true,"content":"<p>I've estimated the cost/performance of Deepseek 681bn like this :</p><p>Huggingface open deepseek blog reported config &amp; performance = 32 H100's 800tps </p><p>1million tokens = 1250s = 21 (ish) , minutes. 69.12 million tokens per day </p><p>Cost to rent 32 H100's per month ~$80000</p><p>Cost per million tokens = $37.33 (80000/ 31 days /69.12 ) </p><p>I know that this is very optimistic (100% utilisation, no support etc.) but does the arithmetic make sense and does it pass the sniff test do you think? Or have I got something significantly wrong? </p><p>I guess this is 1000 times more expensive than an API served model like Gemini, and this gap has made me wonder if I am being silly</p>","contentLength":647,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I still have these","url":"https://www.reddit.com/r/linux/comments/1itynca/i_still_have_these/","date":1740058638,"author":"/u/emuboy85","guid":7235,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["reddit"]}