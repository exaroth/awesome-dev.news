{"id":"KWcVEiwEzuiDsTqLn6LojC9X2yBX45N36DRtYHsFby6oiM4t597YhKBSdxr5wqMdj8kvSgDuiUuV6yvogw","title":"GitHub All Languages Daily Trending","displayTitle":"Github Trending","url":"https://mshibanami.github.io/GitHubTrendingRSS/daily/all.xml","feedLink":"http://mshibanami.github.io/GitHubTrendingRSS","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":48,"items":[{"title":"puckeditor/puck","url":"https://github.com/puckeditor/puck","date":1755916335,"author":"","guid":237172,"unread":true,"content":"<p>The visual editor for React</p><p>Puck is a modular, open-source visual editor for React.js. You can use Puck to build custom drag-and-drop experiences with your own application and React components.</p><p>Because Puck is just a React component, it plays well with all React.js environments, including Next.js. You own your data and thereâ€™s no vendor lock-in.</p><p>Puck is also <a href=\"https://github.com/puckeditor/puck?tab=MIT-1-ov-file#readme\">licensed under MIT</a>, making it suitable for both internal systems and commercial applications.</p><pre><code>npm i @measured/puck --save # or npx create-puck-app my-app\n</code></pre><pre><code>// Editor.jsx\nimport { Puck } from \"@measured/puck\";\nimport \"@measured/puck/puck.css\";\n\n// Create Puck component config\nconst config = {\n  components: {\n    HeadingBlock: {\n      fields: {\n        children: {\n          type: \"text\",\n        },\n      },\n      render: ({ children }) =&gt; {\n        return &lt;h1&gt;{children}&lt;/h1&gt;;\n      },\n    },\n  },\n};\n\n// Describe the initial data\nconst initialData = {};\n\n// Save the data to your database\nconst save = (data) =&gt; {};\n\n// Render Puck editor\nexport function Editor() {\n  return &lt;Puck config={config} data={initialData} onPublish={save} /&gt;;\n}\n</code></pre><pre><code>// Page.jsx\nimport { Render } from \"@measured/puck\";\nimport \"@measured/puck/puck.css\";\n\nexport function Page() {\n  return &lt;Render config={config} data={data} /&gt;;\n}\n</code></pre><p>Use  to quickly spin up a a pre-configured app based on our provided <a href=\"https://github.com/puckeditor/puck/tree/main/recipes\">recipes</a>:</p><pre><code>npx create-puck-app my-app\n</code></pre><p>Available recipes include:</p><ul><li><a href=\"https://github.com/puckeditor/puck/tree/main/recipes/next\"></a>: Next.js example, using App Router and static page generation</li><li><a href=\"https://github.com/puckeditor/puck/tree/main/recipes/remix\"></a>: Remix Run v2 example, using dynamic routes at root-level</li><li><a href=\"https://github.com/puckeditor/puck/tree/main/recipes/react-router\"></a>: React Router v7 app example, using dynamic routes to create pages at any level</li></ul>","contentLength":1593,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dokploy/dokploy","url":"https://github.com/Dokploy/dokploy","date":1755916335,"author":"","guid":237173,"unread":true,"content":"<p>Open Source Alternative to Vercel, Netlify and Heroku.</p><p>Dokploy is a free, self-hostable Platform as a Service (PaaS) that simplifies the deployment and management of applications and databases.</p><p>Dokploy includes multiple features to make your life easier.</p><ul><li>: Deploy any type of application (Node.js, PHP, Python, Go, Ruby, etc.).</li><li>: Create and manage databases with support for MySQL, PostgreSQL, MongoDB, MariaDB, and Redis.</li><li>: Automate backups for databases to an external storage destination.</li><li>: Native support for Docker Compose to manage complex applications.</li><li>: Scale applications to multiple nodes using Docker Swarm to manage the cluster.</li><li>: Deploy open-source templates (Plausible, Pocketbase, Calcom, etc.) with a single click.</li><li>: Automatically integrates with Traefik for routing and load balancing.</li><li>: Monitor CPU, memory, storage, and network usage for every resource.</li><li>: Easily deploy and manage Docker containers.</li><li>: Manage your applications and databases using the command line or through the API.</li><li>: Get notified when your deployments succeed or fail (via Slack, Discord, Telegram, Email, etc.).</li><li>: Deploy and manage your applications remotely to external servers.</li><li>: Self-host Dokploy on your VPS.</li></ul><p>To get started, run the following command on a VPS:</p><pre><code>curl -sSL https://dokploy.com/install.sh | sh\n</code></pre><p>ğŸ™ We're deeply grateful to all our sponsors who make Dokploy possible! Your support helps cover the costs of hosting, testing, and developing new features.</p><a href=\"https://github.com/dokploy/dokploy/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=dokploy/dokploy\" alt=\"Contributors\"></a><a href=\"https://youtu.be/mznYKPvhcfw\"><img src=\"https://dokploy.com/banner.png\" alt=\"Watch the video\" width=\"400\"></a>","contentLength":1441,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"dream-num/univer","url":"https://github.com/dream-num/univer","date":1755916335,"author":"","guid":237174,"unread":true,"content":"<p>Univer is a full-stack framework for creating and editing spreadsheets, documents, and slides on both web and server.</p><ul><li>ğŸ“ˆ Univer is designed to support ,  and .</li><li>ğŸ§™â€â™€ï¸ Univer is . It can run both on browsers and Node.js (in the future, mobile devices as well), with the same API.</li><li>âš™ï¸ Univer is easily , allowing seamless integration into your applications.</li><li>ğŸ‡ Univer is , offering a wide range of features including , , , , , ,  and more features on the horizon.</li><li>ğŸ”Œ Univer is , thanks to its  that makes it a delight for developers to implement their unique requirements on the top of Univer.</li><li>ğŸ’„ Univer is , allowing you to personalize its appearance using . It also provides support for internationalization (i18n).</li><li>ğŸ¥¤ Univer is . The  &amp;  make it easy to hands on.</li><li>âš¡ Univer in . \n  <ul><li>âœï¸ Univer boasts an efficient  based on canvas, capable of rendering various document types flawlessly. The rendering engines supports advanced typesetting features such as ,  and .</li><li>ğŸ§® Univer incorporates a lightning-fast  that can operate in Web Workers or even on the server side.</li></ul></li><li>ğŸŒŒ Univer is a  system. Documents, spreadsheets and slides can interoperate with each others and even rendered on the same canvas, allowing information and data flow within Univer.</li></ul><p>Univer provides a wide range of features for spreadsheets, documents and presentations. Here are some of the key features:</p><ul><li>: Univer supports core spreadsheet functionality, including cells, rows, columns, worksheets, and workbooks.</li><li>: Extensive support for various formulas, including mathematical, statistical, logical, text, date and time, lookup and reference, engineering, financial, and information formulas.</li><li>: Allows restricting access to specific elements.</li><li>: Supports formatting numbers based on specific criteria.</li><li>: Enables linking to external websites, email addresses, and other locations within a spreadsheet.</li><li>: Allows inserting images into a spreadsheet and positioning them anywhere on the sheet.</li><li>: Provides the ability to search for specific text within a spreadsheet and replace it with other text.</li><li>: Allows filtering data based on specific criteria.</li><li>: Allows sorting data based on specific criteria.</li><li>: Supports restricting the type of data that can be entered into a cell.</li><li>: Supports applying formatting to cells based on specific criteria.</li><li>: Enables adding comments to cells to provide additional information.</li><li>: Supports displaying cross-highlighting in spreadsheets to help users quickly locate selected cells.</li><li>: Provides a distraction-free editing experience with a clean interface and minimal distractions.</li><li>[^1]: Supports pivot tables, allowing users to summarize and analyze data.</li><li>[^1]: Supports sparklines, which are small charts that fit within a cell to provide a visual representation of data.</li><li>[^1]: Allows printing a spreadsheet or exporting it to PDF.</li><li>[^1]: Support for importing and exporting data in XLSX.</li><li>[^1]: Supports various types of charts, including bar charts, line charts, pie charts, scatter plots, and more.</li><li>[^1]: Supports multiple users editing a spreadsheet simultaneously. File history and recovering are also provided.</li><li>[^1]: Allows users to view and restore previous versions of a spreadsheet.</li></ul><ul><li>: Univer supports core document features, including paragraphs, headings, lists, superscript, subscript, and more.</li><li>: Supports ordered lists, unordered lists, and task lists.</li><li>: Supports inserting links to external websites, email addresses, and other locations within a document.</li><li>: Allows inserting images into a document and supporting text and image layout.</li><li>: Allows adding headers and footers to a document.</li><li>: Enables adding comments to a document to provide additional information.</li><li>[^1]: Allows printing a document or exporting it to PDF.</li><li>[^1]: Supports importing and exporting data in DOCX format.</li><li>[^1]: Supports multiple users editing a document simultaneously.</li></ul><h3>ğŸ“½ï¸ Univer Slides (Under Development)</h3><ul><li>: Univer will support core presentation features, including slides, shapes, text, images, and more.</li></ul><p>Univer supports multiple languages, including:</p><ul></ul><p> and  are officially supported, while the others are contributed and maintained by the community.</p><p>Embed Univer in AI products as a data presentation tool.</p><p>Univer is committed to maintaining a secure codebase. We follow best practices for security and regularly update our dependencies. For more information, please refer to our <a href=\"https://raw.githubusercontent.com/dream-num/univer/dev/SECURITY.md\">Security Policy</a>.</p><p>Univer is an inclusive and welcoming project. Please read our <a href=\"https://raw.githubusercontent.com/dream-num/univer/dev/CODE_OF_CONDUCT.md\">Code of Conduct</a> before participating in the community.</p><p>Join the Univer community:</p><p>You can also find Univer on:</p><p>If you would like to contribute code to Univer, please refer to the contributing guide as well. It would guide you through the process of setting up the development environment and submitting a pull request.</p><p>The growth and development of the Univer project rely on the support of its backers and sponsors. If you are interested in supporting our project, we kindly invite you to consider becoming a sponsor. You can sponsor us through <a href=\"https://opencollective.com/univer\">Open Collective</a>.</p><p>Thanks to our sponsors, just part of them are listed here because of the space limit, ranking is no particular order:</p><p>Copyright Â© 2021-2025 DreamNum Co,Ltd. All Rights Reserved.</p><p>[^1]: These features are provided by the non-OSS version of Univer, which is free for commercial use and also includes paid upgrade plans.</p>","contentLength":5300,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SpecterOps/BloodHound","url":"https://github.com/SpecterOps/BloodHound","date":1755916335,"author":"","guid":237175,"unread":true,"content":"<p>Six Degrees of Domain Admin</p><p>BloodHound is a monolithic web application composed of an embedded React frontend with <a href=\"https://www.sigmajs.org/\">Sigma.js</a> and a <a href=\"https://go.dev/\">Go</a> based REST API backend. It is deployed with a <a href=\"https://www.postgresql.org/\">Postgresql</a> application database and a <a href=\"https://neo4j.com/\">Neo4j</a> graph database, and is fed by the <a href=\"https://github.com/SpecterOps/SharpHound\">SharpHound</a> and <a href=\"https://github.com/SpecterOps/AzureHound\">AzureHound</a> data collectors.</p><p>BloodHound leverages graph theory to reveal hidden and often unintended relationships across identity and access management systems. Powered by <a href=\"https://specterops.io/opengraph/\">OpenGraph</a>, BloodHound now supports comprehensive analysis beyond Active Directory and Azure environments, enabling users to map complex privilege relationships across <a href=\"https://bloodhound.specterops.io/opengraph/library\">diverse identity platforms</a>. Attackers can utilize BloodHound to rapidly discover sophisticated attack paths otherwise impossible to identify manually, while defenders can proactively identify and mitigate these risks. Both red and blue teams benefit from BloodHound's expanded capabilities, gaining deeper insights into identity and privilege structures across their entire security landscape.</p><h2>Running BloodHound Community Edition</h2><p>Please check out the <a href=\"https://github.com/SpecterOps/BloodHound/wiki/Contact\">Contact page</a> in our wiki for details on how to reach out with questions and suggestions.</p><pre><code>Copyright 2025 Specter Ops, Inc.\n\nLicensed under the Apache License, Version 2.0\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre><p>Unless otherwise annotated by a lower-level LICENSE file or license header, all files in this repository are released under the  license. A full copy of the license may be found in the top-level <a href=\"https://raw.githubusercontent.com/SpecterOps/BloodHound/main/LICENSE\">LICENSE</a> file.</p>","contentLength":1896,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"dataease/SQLBot","url":"https://github.com/dataease/SQLBot","date":1755916335,"author":"","guid":237176,"unread":true,"content":"<p>åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿã€‚Text-to-SQL Generation via LLMs using RAG.</p><p>SQLBot æ˜¯ä¸€æ¬¾åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿã€‚SQLBot çš„ä¼˜åŠ¿åŒ…æ‹¬ï¼š</p><ul><li>: åªéœ€é…ç½®å¤§æ¨¡å‹å’Œæ•°æ®æºå³å¯å¼€å¯é—®æ•°ä¹‹æ—…ï¼Œé€šè¿‡å¤§æ¨¡å‹å’Œ RAG çš„ç»“åˆæ¥å®ç°é«˜è´¨é‡çš„ text2sqlï¼›</li><li>: æ”¯æŒå¿«é€ŸåµŒå…¥åˆ°ç¬¬ä¸‰æ–¹ä¸šåŠ¡ç³»ç»Ÿï¼Œä¹Ÿæ”¯æŒè¢« n8nã€MaxKBã€Difyã€Coze ç­‰ AI åº”ç”¨å¼€å‘å¹³å°é›†æˆè°ƒç”¨ï¼Œè®©å„ç±»åº”ç”¨å¿«é€Ÿæ‹¥æœ‰æ™ºèƒ½é—®æ•°èƒ½åŠ›ï¼›</li><li>: æä¾›åŸºäºå·¥ä½œç©ºé—´çš„èµ„æºéš”ç¦»æœºåˆ¶ï¼Œèƒ½å¤Ÿå®ç°ç»†ç²’åº¦çš„æ•°æ®æƒé™æ§åˆ¶ã€‚</li></ul><pre><code># åˆ›å»ºç›®å½•\nmkdir -p /opt/sqlbot\ncd /opt/sqlbot\n\n# ä¸‹è½½ docker-compose.yaml\ncurl -o docker-compose.yaml https://raw.githubusercontent.com/dataease/SQLBot/main/docker-compose.yaml\n\n# å¯åŠ¨æœåŠ¡\ndocker compose up -d\n</code></pre><ul><li>åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: http://&lt;ä½ çš„æœåŠ¡å™¨IP&gt;:8000/</li></ul><p>å¦‚ä½ æœ‰æ›´å¤šé—®é¢˜ï¼Œå¯ä»¥åŠ å…¥æˆ‘ä»¬çš„æŠ€æœ¯äº¤æµç¾¤ä¸æˆ‘ä»¬äº¤æµã€‚</p><img width=\"396\" height=\"396\" alt=\"contact_me_qr\" src=\"https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030\"><img alt=\"q&amp;a\" src=\"https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280\">","contentLength":927,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"plait-board/drawnix","url":"https://github.com/plait-board/drawnix","date":1755830055,"author":"","guid":236010,"unread":true,"content":"<p>å¼€æºç™½æ¿å·¥å…·ï¼ˆSaaSï¼‰ï¼Œä¸€ä½“åŒ–ç™½æ¿ï¼ŒåŒ…å«æ€ç»´å¯¼å›¾ã€æµç¨‹å›¾ã€è‡ªç”±ç”»ç­‰ã€‚All in one open-source whiteboard tool with mind, flowchart, freehand and etc.</p><div align=\"center\"><h2> å¼€æºç™½æ¿å·¥å…·ï¼ˆSaaSï¼‰ï¼Œä¸€ä½“åŒ–ç™½æ¿ï¼ŒåŒ…å«æ€ç»´å¯¼å›¾ã€æµç¨‹å›¾ã€è‡ªç”±ç”»ç­‰ </h2></div><ul><li>ğŸ–¼ï¸ ğŸ“ƒ å¯¼å‡ºä¸º PNG, JSON()</li><li>âœ¨ æ”¯æŒ markdown æ–‡æœ¬è½¬æ€ç»´å¯¼å›¾ï¼ˆæ–°æ”¯æŒ ğŸ”¥ğŸ”¥ğŸ”¥ï¼‰</li></ul><p> ï¼Œæºäºç»˜ç”»(  )ä¸å‡¤å‡°(  )çš„çµæ„Ÿäº¤ç»‡ã€‚</p><p>å‡¤å‡°è±¡å¾ç€ç”Ÿç”Ÿä¸æ¯çš„åˆ›é€ åŠ›ï¼Œè€Œ  ä»£è¡¨ç€äººç±»æœ€åŸå§‹çš„è¡¨è¾¾æ–¹å¼ã€‚åœ¨è¿™é‡Œï¼Œæ¯ä¸€æ¬¡åˆ›ä½œéƒ½æ˜¯ä¸€æ¬¡è‰ºæœ¯çš„æ¶…æ§ƒï¼Œæ¯ä¸€ç¬”ç»˜ç”»éƒ½æ˜¯çµæ„Ÿçš„é‡ç”Ÿã€‚</p><p>åˆ›æ„å¦‚åŒå‡¤å‡°ï¼Œæµ´ç«æ–¹èƒ½é‡ç”Ÿï¼Œè€Œ  è¦åšæŠ€æœ¯ä¸åˆ›æ„ä¹‹ç«çš„å®ˆæŠ¤è€…ã€‚</p><p> çš„å®šä½æ˜¯ä¸€ä¸ªå¼€ç®±å³ç”¨ã€å¼€æºã€å…è´¹çš„å·¥å…·äº§å“ï¼Œå®ƒçš„åº•å±‚æ˜¯  æ¡†æ¶ï¼Œ æ˜¯æˆ‘å¸å¼€æºçš„ä¸€æ¬¾ç”»å›¾æ¡†æ¶ï¼Œä»£è¡¨ç€å…¬å¸åœ¨çŸ¥è¯†åº“äº§å“ä¸Šçš„é‡è¦æŠ€æœ¯æ²‰æ·€ã€‚</p><p>Drawnix æ˜¯æ’ä»¶æ¶æ„ï¼Œä¸å‰é¢è¯´åˆ°å¼€æºå·¥å…·æ¯”æŠ€æœ¯æ¶æ„æ›´å¤æ‚ä¸€äº›ï¼Œä½†æ˜¯æ’ä»¶æ¶æ„ä¹Ÿæœ‰ä¼˜åŠ¿ï¼Œæ¯”å¦‚èƒ½å¤Ÿæ”¯æŒå¤šç§ UI æ¡†æ¶ï¼ˆï¼‰ï¼Œèƒ½å¤Ÿé›†æˆä¸åŒå¯Œæ–‡æœ¬æ¡†æ¶ï¼ˆå½“å‰ä»…æ”¯æŒ  æ¡†æ¶ï¼‰ï¼Œåœ¨å¼€å‘ä¸Šå¯ä»¥å¾ˆå¥½çš„å®ç°ä¸šåŠ¡çš„åˆ†å±‚ï¼Œå¼€å‘å„ç§ç»†ç²’åº¦çš„å¯å¤ç”¨æ’ä»¶ï¼Œå¯ä»¥æ‰©å±•æ›´å¤šçš„ç”»æ¿çš„åº”ç”¨åœºæ™¯ã€‚</p><pre><code>drawnix/\nâ”œâ”€â”€ apps/\nâ”‚   â”œâ”€â”€ web                   # drawnix.com\nâ”‚   â”‚    â””â”€â”€ index.html       # HTML\nâ”œâ”€â”€ dist/                     # æ„å»ºäº§ç‰©\nâ”œâ”€â”€ packages/\nâ”‚   â””â”€â”€ drawnix/              # ç™½æ¿åº”ç”¨\nâ”‚   â””â”€â”€ react-board/          # ç™½æ¿ React è§†å›¾å±‚\nâ”‚   â””â”€â”€ react-text/           # æ–‡æœ¬æ¸²æŸ“æ¨¡å—\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ ...\nâ””â”€â”€ README.md\nâ””â”€â”€ README_en.md\n\n</code></pre><p>è¿‘æœŸä¼šé«˜é¢‘è¿­ä»£ drawnix.comï¼Œç›´åˆ°å‘å¸ƒ  ç‰ˆæœ¬ã€‚</p><pre><code>npm install\n\nnpm run start\n</code></pre><pre><code>docker pull pubuzhixing/drawnix:latest\n</code></pre>","contentLength":1833,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"skills/introduction-to-github","url":"https://github.com/skills/introduction-to-github","date":1755830055,"author":"","guid":236011,"unread":true,"content":"<p>Get started using GitHub in less than an hour.</p><p>People use GitHub to build some of the most advanced technologies in the world. Whether youâ€™re visualizing data or building a new game, thereâ€™s a whole community and set of tools on GitHub that can help you do it even better. GitHub Skillsâ€™ â€œIntroduction to GitHubâ€ course guides you through everything you need to start contributing in less than an hour.</p><ul><li>: New developers, new GitHub users, and students.</li><li>: We'll introduce repositories, branches, commits, and pull requests.</li><li>: We'll make a short Markdown file you can use as your <a href=\"https://docs.github.com/account-and-profile/setting-up-and-managing-your-github-profile/customizing-your-profile/managing-your-profile-readme\">profile README</a>.</li><li>: None. This course is a great introduction for your first day on GitHub.</li><li>: This course takes less than one hour to complete.</li></ul><p>In this course, you will:</p><ol></ol><ol><li>Right-click  and open the link in a new tab.</li><li>In the new tab, most of the prompts will automatically fill in for you. \n  <ul><li>For owner, choose your personal account or an organization to host the repository.</li><li>Scroll down and click the  button at the bottom of the form.</li></ul></li><li>After your new repository is created, wait about 20 seconds, then refresh the page. Follow the step-by-step instructions in the new repository's README.</li></ol>","contentLength":1161,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"google/googletest","url":"https://github.com/google/googletest","date":1755830055,"author":"","guid":236012,"unread":true,"content":"<p>GoogleTest - Google Testing and Mocking Framework</p><p>Our documentation is now live on GitHub Pages at <a href=\"https://google.github.io/googletest/\">https://google.github.io/googletest/</a>. We recommend browsing the documentation on GitHub Pages rather than directly in the repository.</p><p>We use Google's internal systems for continuous integration.</p><ul><li>We are planning to take a dependency on <a href=\"https://github.com/abseil/abseil-cpp\">Abseil</a>.</li></ul><h2>Welcome to , Google's C++ test framework!</h2><p>This repository is a merger of the formerly separate GoogleTest and GoogleMock projects. These were so closely related that it makes sense to maintain and release them together.</p><ul><li>xUnit test framework:  Googletest is based on the <a href=\"https://en.wikipedia.org/wiki/XUnit\">xUnit</a> testing framework, a popular architecture for unit testing</li><li>Test discovery:  Googletest automatically discovers and runs your tests, eliminating the need to manually register your tests</li><li>Rich set of assertions:  Googletest provides a variety of assertions, such as equality, inequality, exceptions, and more, making it easy to test your code</li><li>User-defined assertions:  You can define your own assertions with Googletest, making it simple to write tests that are specific to your code</li><li>Death tests:  Googletest supports death tests, which verify that your code exits in a certain way, making it useful for testing error-handling code</li><li>Fatal and non-fatal failures:  You can specify whether a test failure should be treated as fatal or non-fatal with Googletest, allowing tests to continue running even if a failure occurs</li><li>Value-parameterized tests:  Googletest supports value-parameterized tests, which run multiple times with different input values, making it useful for testing functions that take different inputs</li><li>Type-parameterized tests:  Googletest also supports type-parameterized tests, which run with different data types, making it useful for testing functions that work with different data types</li><li>Various options for running tests:  Googletest provides many options for running tests including running individual tests, running tests in a specific order and running tests in parallel</li></ul><p>In addition to many internal projects at Google, GoogleTest is also used by the following notable projects:</p><h2>Related Open Source Projects</h2><p><a href=\"https://github.com/nholthaus/gtest-runner\">GTest Runner</a> is a Qt5 based automated test-runner and Graphical User Interface with powerful features for Windows and Linux platforms.</p><p><a href=\"https://github.com/ospector/gtest-gbar\">GoogleTest UI</a> is a test runner that runs your test binary, allows you to track its progress via a progress bar, and displays a list of test failures. Clicking on one shows failure text. GoogleTest UI is written in C#.</p><p><a href=\"https://github.com/kinow/gtest-tap-listener\">GTest TAP Listener</a> is an event listener for GoogleTest that implements the <a href=\"https://en.wikipedia.org/wiki/Test_Anything_Protocol\">TAP protocol</a> for test result output. If your test runner understands TAP, you may find it useful.</p><p><a href=\"https://github.com/google/gtest-parallel\">gtest-parallel</a> is a test runner that runs tests from your binary in parallel to provide significant speed-up.</p><p><a href=\"https://marketplace.visualstudio.com/items?itemName=DavidSchuldenfrei.gtest-adapter\">GoogleTest Adapter</a> is a VS Code extension allowing to view GoogleTest in a tree view and run/debug your tests.</p><p><a href=\"https://github.com/matepek/vscode-catch2-test-adapter\">C++ TestMate</a> is a VS Code extension allowing to view GoogleTest in a tree view and run/debug your tests.</p><p><a href=\"https://pypi.org/project/cornichon/\">Cornichon</a> is a small Gherkin DSL parser that generates stub code for GoogleTest.</p><p>Please read <a href=\"https://github.com/google/googletest/raw/main/CONTRIBUTING.md\"></a> for details on how to contribute to this project.</p>","contentLength":3114,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Budibase/budibase","url":"https://github.com/Budibase/budibase","date":1755830055,"author":"","guid":236013,"unread":true,"content":"<p>Create business apps and automate workflows in minutes. Supports PostgreSQL, MySQL, MariaDB, MSSQL, MongoDB, Rest API, Docker, K8s, and more ğŸš€ No code / Low code platform..</p><h3 align=\"center\"> The low code platform you'll enjoy using </h3><p align=\"center\"> Budibase is an open-source low-code platform that saves engineers 100s of hours building forms, portals, and approval apps, securely. </p><h3>Build and ship real software</h3><p>Unlike other platforms, with Budibase you build and ship single page applications. Budibase applications have performance baked in and can be designed responsively, providing users with a great experience. </p><h3>Open source and extensible</h3><p>Budibase is open-source - licensed as GPL v3. This should fill you with confidence that Budibase will always be around. You can also code against Budibase or fork it and make changes as you please, providing a developer-friendly experience. </p><h3>Load data or start from scratch</h3><p>Budibase pulls data from multiple sources, including MongoDB, CouchDB, PostgreSQL, MariaDB, MySQL, Airtable, S3, DynamoDB, or a REST API. And unlike other platforms, with Budibase you can start from scratch and create business apps with no data sources. <a href=\"https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas\">Request new datasources</a>.</p><h3>Design and build apps with powerful pre-made components</h3><p>Budibase comes out of the box with beautifully designed, powerful components which you can use like building blocks to build your UI. We also expose many of your favourite CSS styling options so you can go that extra creative mile. <a href=\"https://github.com/Budibase/budibase/discussions?discussions_q=category%3AIdeas\">Request new component</a>.</p><h3>Automate processes, integrate with other tools and connect to webhooks</h3><h3>Integrate with your favorite tools</h3><p>Budibase integrates with a number of popular tools allowing you to build apps that perfectly fit your stack.</p><h3>Deploy with confidence and security</h3><p>Budibase is made to scale. With Budibase, you can self-host on your own infrastructure and globally manage users, onboarding, SMTP, apps, groups, theming and more. You can also provide users/groups with an app portal and disseminate user management to the group manager.</p><p>As with anything that we build in Budibase, our new public API is simple to use, flexible, and introduces new extensibility. To summarize, the Budibase API enables:</p><ul></ul><p>You can learn more about the Budibase API at the following places:</p><p>Deploy Budibase using Docker, Kubernetes, and Digital Ocean on your existing infrastructure. Or use Budibase Cloud if you don't need to self-host and would like to get started quickly.</p><p>If you have a question or would like to talk with other Budibase users and join our community, please hop over to <a href=\"https://github.com/Budibase/budibase/discussions\">Github discussions</a></p><p>Budibase is dedicated to providing everyone a welcoming, diverse, and harassment-free experience. We expect everyone in the Budibase community to abide by our <a href=\"https://github.com/Budibase/budibase/raw/HEAD/docs/CODE_OF_CONDUCT.md\"></a>. Please read it. </p><h2>ğŸ™Œ Contributing to Budibase</h2><p>From opening a bug report to creating a pull request: every contribution is appreciated and welcomed. If you're planning to implement a new feature or change the API, please create an issue first. This way, we can ensure your work is not in vain. Environment setup instructions are available <a href=\"https://github.com/Budibase/budibase/tree/HEAD/docs/CONTRIBUTING.md\">here</a>.</p><h3>How the repository is organized</h3><p>Budibase is a monorepo managed by lerna. Lerna manages the building and publishing of the budibase packages. At a high level, here are the packages that make up Budibase.</p><ul><li><p><a href=\"https://github.com/Budibase/budibase/tree/HEAD/packages/builder\">packages/builder</a> - contains code for the budibase builder client-side svelte application.</p></li><li><p><a href=\"https://github.com/Budibase/budibase/tree/HEAD/packages/client\">packages/client</a> - A module that runs in the browser responsible for reading JSON definition and creating living, breathing web apps from it.</p></li><li><p><a href=\"https://github.com/Budibase/budibase/tree/HEAD/packages/server\">packages/server</a> - The budibase server. This Koa app is responsible for serving the JS for the builder and budibase apps, as well as providing the API for interaction with the database and file system.</p></li></ul><p>Budibase is open-source, licensed as <a href=\"https://www.gnu.org/licenses/gpl-3.0.en.html\">GPL v3</a>. The client and component libraries are licensed as <a href=\"https://directory.fsf.org/wiki/License:MPL-2.0\">MPL</a> - so the apps you build can be licensed however you like.</p><p>If you are having issues between updates of the builder, please use the guide <a href=\"https://github.com/Budibase/budibase/raw/HEAD/docs/CONTRIBUTING.md#troubleshooting\">here</a> to clear down your environment.</p><p>Thanks goes to these wonderful people (<a href=\"https://allcontributors.org/docs/en/emoji-key\">emoji key</a>):</p><a href=\"https://github.com/Budibase/budibase/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=Budibase/budibase\"></a>","contentLength":3988,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"nextjs/saas-starter","url":"https://github.com/nextjs/saas-starter","date":1755830055,"author":"","guid":236014,"unread":true,"content":"<p>Get started quickly with Next.js, Postgres, Stripe, and shadcn/ui.</p><p>This is a starter template for building a SaaS application using  with support for authentication, Stripe integration for payments, and a dashboard for logged-in users.</p><ul><li>Marketing landing page () with animated Terminal element</li><li>Pricing page () which connects to Stripe Checkout</li><li>Dashboard pages with CRUD operations on users/teams</li><li>Basic RBAC with Owner and Member roles</li><li>Subscription management with Stripe Customer Portal</li><li>Email/password authentication with JWTs stored to cookies</li><li>Global middleware to protect logged-in routes</li><li>Local middleware to protect Server Actions or validate Zod schemas</li><li>Activity logging system for any user events</li></ul><pre><code>git clone https://github.com/nextjs/saas-starter\ncd saas-starter\npnpm install\n</code></pre><p><a href=\"https://docs.stripe.com/stripe-cli\">Install</a> and log in to your Stripe account:</p><p>Use the included setup script to create your  file:</p><p>Run the database migrations and seed the database with a default user and team:</p><pre><code>pnpm db:migrate\npnpm db:seed\n</code></pre><p>This will create the following user and team:</p><ul></ul><p>You can also create new users through the  route.</p><p>Finally, run the Next.js development server:</p><p>You can listen for Stripe webhooks locally through their CLI to handle subscription change events:</p><pre><code>stripe listen --forward-to localhost:3000/api/stripe/webhook\n</code></pre><p>To test Stripe payments, use the following test card details:</p><ul><li>Card Number: </li><li>Expiration: Any future date</li></ul><p>When you're ready to deploy your SaaS application to production, follow these steps:</p><h3>Set up a production Stripe webhook</h3><ol><li>Go to the Stripe Dashboard and create a new webhook for your production environment.</li><li>Set the endpoint URL to your production API route (e.g., <code>https://yourdomain.com/api/stripe/webhook</code>).</li><li>Select the events you want to listen for (e.g., <code>checkout.session.completed</code>, <code>customer.subscription.updated</code>).</li></ol><ol><li>Push your code to a GitHub repository.</li><li>Connect your repository to <a href=\"https://vercel.com/\">Vercel</a> and deploy it.</li><li>Follow the Vercel deployment process, which will guide you through setting up your project.</li></ol><h3>Add environment variables</h3><p>In your Vercel project settings (or during deployment), add all the necessary environment variables. Make sure to update the values for the production environment, including:</p><ol><li>: Set this to your production domain.</li><li>: Use your Stripe secret key for the production environment.</li><li>: Use the webhook secret from the production webhook you created in step 1.</li><li>: Set this to your production database URL.</li><li>: Set this to a random string.  will generate one.</li></ol><p>While this template is intentionally minimal and to be used as a learning resource, there are other paid versions in the community which are more full-featured:</p>","contentLength":2577,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"firecrawl/firecrawl","url":"https://github.com/firecrawl/firecrawl","date":1755830055,"author":"","guid":236015,"unread":true,"content":"<p>The Web Data API for AI - Turn entire websites into LLM-ready markdown or structured data ğŸ”¥</p><p>Empower your AI apps with clean data from any website. Featuring advanced scraping, crawling, and data extraction capabilities.</p><p><em>This repository is in development, and weâ€™re still integrating custom modules into the mono repo. It's not fully ready for self-hosted deployment yet, but you can run it locally.</em></p><p><a href=\"https://firecrawl.dev?ref=github\">Firecrawl</a> is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required. Check out our <a href=\"https://docs.firecrawl.dev\">documentation</a>.</p><p><em>Pst. hey, you, join our stargazers :)</em></p><a href=\"https://github.com/firecrawl/firecrawl\"><img src=\"https://img.shields.io/github/stars/firecrawl/firecrawl.svg?style=social&amp;label=Star&amp;maxAge=2592000\" alt=\"GitHub stars\"></a><p>We provide an easy to use API with our hosted version. You can find the playground and documentation <a href=\"https://firecrawl.dev/playground\">here</a>. You can also self host the backend if you'd like.</p><p>Check out the following resources to get started:</p><p>To run locally, refer to guide <a href=\"https://github.com/firecrawl/firecrawl/raw/main/CONTRIBUTING.md\">here</a>.</p><p>To use the API, you need to sign up on <a href=\"https://firecrawl.dev\">Firecrawl</a> and get an API key.</p><ul><li><a href=\"https://raw.githubusercontent.com/firecrawl/firecrawl/main/#scraping\"></a>: scrapes a URL and get its content in LLM-ready format (markdown, structured data via <a href=\"https://raw.githubusercontent.com/firecrawl/firecrawl/main/#llm-extraction-beta\">LLM Extract</a>, screenshot, html)</li><li><a href=\"https://raw.githubusercontent.com/firecrawl/firecrawl/main/#crawling\"></a>: scrapes all the URLs of a web page and return content in LLM-ready format</li><li><a href=\"https://raw.githubusercontent.com/firecrawl/firecrawl/main/#map\"></a>: input a website and get all the website urls - extremely fast</li><li><a href=\"https://raw.githubusercontent.com/firecrawl/firecrawl/main/#search\"></a>: search the web and get full content from results</li><li><a href=\"https://raw.githubusercontent.com/firecrawl/firecrawl/main/#extract\"></a>: get structured data from single page, multiple pages or entire websites with AI.</li></ul><ul><li>: markdown, structured data, screenshot, HTML, links, metadata</li><li>: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration</li><li>: exclude tags, crawl behind auth walls with custom headers, max crawl depth, etc...</li><li>: pdfs, docx, images</li><li>: designed to get the data you need - no matter how hard it is</li><li>: click, scroll, input, wait and more before extracting data</li><li>: scrape thousands of URLs at the same time with a new async endpoint.</li></ul><p>You can find all of Firecrawl's capabilities and how to use them in our <a href=\"https://docs.firecrawl.dev\">documentation</a></p><p>Used to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/crawl \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: Bearer fc-YOUR_API_KEY' \\\n    -d '{\n      \"url\": \"https://docs.firecrawl.dev\",\n      \"limit\": 10,\n      \"scrapeOptions\": {\n        \"formats\": [\"markdown\", \"html\"]\n      }\n    }'\n</code></pre><p>Returns a crawl job id and the url to check the status of the crawl.</p><pre><code>{\n  \"success\": true,\n  \"id\": \"123-456-789\",\n  \"url\": \"https://api.firecrawl.dev/v2/crawl/123-456-789\"\n}\n</code></pre><p>Used to check the status of a crawl job and get its result.</p><pre><code>curl -X GET https://api.firecrawl.dev/v2/crawl/123-456-789 \\\n  -H 'Content-Type: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY'\n</code></pre><pre><code>{\n  \"status\": \"completed\",\n  \"total\": 36,\n  \"creditsUsed\": 36,\n  \"expiresAt\": \"2024-00-00T00:00:00.000Z\",\n  \"data\": [\n    {\n      \"markdown\": \"[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...\",\n      \"html\": \"&lt;!DOCTYPE html&gt;&lt;html lang=\\\"en\\\" class=\\\"js-focus-visible lg:[--scroll-mt:9.5rem]\\\" data-js-focus-visible=\\\"\\\"&gt;...\",\n      \"metadata\": {\n        \"title\": \"Build a 'Chat with website' using Groq Llama 3 | Firecrawl\",\n        \"language\": \"en\",\n        \"sourceURL\": \"https://docs.firecrawl.dev/learn/rag-llama3\",\n        \"description\": \"Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a 'Chat with your website' bot.\",\n        \"ogLocaleAlternate\": [],\n        \"statusCode\": 200\n      }\n    }\n  ]\n}\n</code></pre><p>Used to scrape a URL and get its content in the specified formats.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/scrape \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: Bearer YOUR_API_KEY' \\\n    -d '{\n      \"url\": \"https://docs.firecrawl.dev\",\n      \"formats\" : [\"markdown\", \"html\"]\n    }'\n</code></pre><pre><code>{\n  \"success\": true,\n  \"data\": {\n    \"markdown\": \"Launch Week I is here! [See our Day 2 Release ğŸš€](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[ğŸ’¥ Get 2 months free...\",\n    \"html\": \"&lt;!DOCTYPE html&gt;&lt;html lang=\\\"en\\\" class=\\\"light\\\" style=\\\"color-scheme: light;\\\"&gt;&lt;body class=\\\"__variable_36bd41 __variable_d7dc5d font-inter ...\",\n    \"metadata\": {\n      \"title\": \"Home - Firecrawl\",\n      \"description\": \"Firecrawl crawls and converts any website into clean markdown.\",\n      \"language\": \"en\",\n      \"keywords\": \"Firecrawl,Markdown,Data,Mendable,Langchain\",\n      \"robots\": \"follow, index\",\n      \"ogTitle\": \"Firecrawl\",\n      \"ogDescription\": \"Turn any website into LLM-ready data.\",\n      \"ogUrl\": \"https://www.firecrawl.dev/\",\n      \"ogImage\": \"https://www.firecrawl.dev/og.png?123\",\n      \"ogLocaleAlternate\": [],\n      \"ogSiteName\": \"Firecrawl\",\n      \"sourceURL\": \"https://firecrawl.dev\",\n      \"statusCode\": 200\n    }\n  }\n}\n</code></pre><p>Used to map a URL and get urls of the website. This returns most links present on the website.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/map \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: Bearer YOUR_API_KEY' \\\n    -d '{\n      \"url\": \"https://firecrawl.dev\"\n    }'\n</code></pre><pre><code>{\n  \"success\": true,\n  \"links\": [\n    { \"url\": \"https://firecrawl.dev\", \"title\": \"Firecrawl\", \"description\": \"Firecrawl is a tool that allows you to crawl a website and get the data you need.\" },\n    { \"url\": \"https://www.firecrawl.dev/pricing\", \"title\": \"Firecrawl Pricing\", \"description\": \"Firecrawl Pricing\" },\n    { \"url\": \"https://www.firecrawl.dev/blog\", \"title\": \"Firecrawl Blog\", \"description\": \"Firecrawl Blog\" },\n    { \"url\": \"https://www.firecrawl.dev/playground\", \"title\": \"Firecrawl Playground\", \"description\": \"Firecrawl Playground\" },\n    { \"url\": \"https://www.firecrawl.dev/smart-crawl\", \"title\": \"Firecrawl Smart Crawl\", \"description\": \"Firecrawl Smart Crawl\" }\n  ]\n}\n</code></pre><p>Map with  param allows you to search for specific urls inside a website.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/map \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: Bearer YOUR_API_KEY' \\\n    -d '{\n      \"url\": \"https://firecrawl.dev\",\n      \"search\": \"docs\"\n    }'\n</code></pre><p>Response will be an ordered list from the most relevant to the least relevant.</p><pre><code>{\n  \"success\": true,\n  \"links\": [\n    { \"url\": \"https://docs.firecrawl.dev\", \"title\": \"Firecrawl Docs\", \"description\": \"Firecrawl Docs\" },\n    { \"url\": \"https://docs.firecrawl.dev/sdks/python\", \"title\": \"Firecrawl Python SDK\", \"description\": \"Firecrawl Python SDK\" },\n    { \"url\": \"https://docs.firecrawl.dev/learn/rag-llama3\", \"title\": \"Firecrawl RAG Llama 3\", \"description\": \"Firecrawl RAG Llama 3\" }\n  ]\n}\n</code></pre><p>Search the web and get full content from results</p><p>Firecrawlâ€™s search API allows you to perform web searches and optionally scrape the search results in one operation.</p><ul><li>Choose specific output formats (markdown, HTML, links, screenshots)</li><li>Search the web with customizable parameters (language, country, etc.)</li><li>Optionally retrieve content from search results in various formats</li><li>Control the number of results and set timeouts</li></ul><pre><code>curl -X POST https://api.firecrawl.dev/v2/search \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer fc-YOUR_API_KEY\" \\\n  -d '{\n    \"query\": \"what is firecrawl?\",\n    \"limit\": 5\n  }'\n</code></pre><pre><code>{\n  \"success\": true,\n  \"data\": [\n    {\n      \"url\": \"https://firecrawl.dev\",\n      \"title\": \"Firecrawl | Home Page\",\n      \"description\": \"Turn websites into LLM-ready data with Firecrawl\"\n    },\n    {\n      \"url\": \"https://docs.firecrawl.dev\",\n      \"title\": \"Documentation | Firecrawl\",\n      \"description\": \"Learn how to use Firecrawl in your own applications\"\n    }\n  ]\n}\n</code></pre><pre><code>curl -X POST https://api.firecrawl.dev/v2/search \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer fc-YOUR_API_KEY\" \\\n  -d '{\n    \"query\": \"what is firecrawl?\",\n    \"limit\": 5,\n    \"scrapeOptions\": {\n      \"formats\": [\"markdown\", \"links\"]\n    }\n  }'\n</code></pre><p>Get structured data from entire websites with a prompt and/or a schema.</p><p>You can extract structured data from one or multiple URLs, including wildcards:</p><p>When you use /*, Firecrawl will automatically crawl and parse all URLs it can discover in that domain, then extract the requested data.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/extract \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: Bearer YOUR_API_KEY' \\\n    -d '{\n      \"urls\": [\n        \"https://firecrawl.dev/*\", \n        \"https://docs.firecrawl.dev/\", \n        \"https://www.ycombinator.com/companies\"\n      ],\n      \"prompt\": \"Extract the company mission, whether it is open source, and whether it is in Y Combinator from the page.\",\n      \"schema\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"company_mission\": {\n            \"type\": \"string\"\n          },\n          \"is_open_source\": {\n            \"type\": \"boolean\"\n          },\n          \"is_in_yc\": {\n            \"type\": \"boolean\"\n          }\n        },\n        \"required\": [\n          \"company_mission\",\n          \"is_open_source\",\n          \"is_in_yc\"\n        ]\n      }\n    }'\n</code></pre><pre><code>{\n  \"success\": true,\n  \"id\": \"44aa536d-f1cb-4706-ab87-ed0386685740\",\n  \"urlTrace\": []\n}\n</code></pre><p>If you are using the sdks, it will auto pull the response for you:</p><pre><code>{\n  \"success\": true,\n  \"data\": {\n    \"company_mission\": \"Firecrawl is the easiest way to extract data from the web. Developers use us to reliably convert URLs into LLM-ready markdown or structured data with a single API call.\",\n    \"supports_sso\": false,\n    \"is_open_source\": true,\n    \"is_in_yc\": true\n  }\n}\n</code></pre><p>Used to extract structured data from scraped pages.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/scrape \\\n  -H 'Content-Type: application/json' \\\n  -H 'Authorization: Bearer YOUR_API_KEY' \\\n  -d '{\n    \"url\": \"https://www.mendable.ai/\",\n    \"formats\": [\n      {\n        \"type\": \"json\",\n        \"schema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"company_mission\": { \"type\": \"string\" },\n            \"supports_sso\": { \"type\": \"boolean\" },\n            \"is_open_source\": { \"type\": \"boolean\" },\n            \"is_in_yc\": { \"type\": \"boolean\" }\n          }\n        }\n      }\n    ]\n  }'\n</code></pre><pre><code>{\n  \"success\": true,\n  \"data\": {\n    \"content\": \"Raw Content\",\n    \"metadata\": {\n      \"title\": \"Mendable\",\n      \"description\": \"Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide\",\n      \"robots\": \"follow, index\",\n      \"ogTitle\": \"Mendable\",\n      \"ogDescription\": \"Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide\",\n      \"ogUrl\": \"https://mendable.ai/\",\n      \"ogImage\": \"https://mendable.ai/mendable_new_og1.png\",\n      \"ogLocaleAlternate\": [],\n      \"ogSiteName\": \"Mendable\",\n      \"sourceURL\": \"https://mendable.ai/\"\n    },\n    \"json\": {\n      \"company_mission\": \"Train a secure AI on your technical resources that answers customer and employee questions so your team doesn't have to\",\n      \"supports_sso\": true,\n      \"is_open_source\": false,\n      \"is_in_yc\": true\n    }\n  }\n}\n</code></pre><h3>Extracting without a schema (New)</h3><p>You can now extract without a schema by just passing a  to the endpoint. The llm chooses the structure of the data.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/scrape \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: Bearer YOUR_API_KEY' \\\n    -d '{\n      \"url\": \"https://docs.firecrawl.dev/\",\n      \"formats\": [\n        {\n          \"type\": \"json\",\n          \"prompt\": \"Extract the company mission from the page.\"\n        }\n      ]\n    }'\n</code></pre><h3>Interacting with the page with Actions (Cloud-only)</h3><p>Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.</p><p>Here is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/scrape \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: Bearer YOUR_API_KEY' \\\n    -d '{\n        \"url\": \"google.com\",\n        \"formats\": [\"markdown\"],\n        \"actions\": [\n            {\"type\": \"wait\", \"milliseconds\": 2000},\n            {\"type\": \"click\", \"selector\": \"textarea[title=\\\"Search\\\"]\"},\n            {\"type\": \"wait\", \"milliseconds\": 2000},\n            {\"type\": \"write\", \"text\": \"firecrawl\"},\n            {\"type\": \"wait\", \"milliseconds\": 2000},\n            {\"type\": \"press\", \"key\": \"ENTER\"},\n            {\"type\": \"wait\", \"milliseconds\": 3000},\n            {\"type\": \"click\", \"selector\": \"h3\"},\n            {\"type\": \"wait\", \"milliseconds\": 3000},\n            {\"type\": \"screenshot\"}\n        ]\n    }'\n</code></pre><h3>Batch Scraping Multiple URLs (New)</h3><p>You can now batch scrape multiple URLs at the same time. It is very similar to how the /crawl endpoint works. It submits a batch scrape job and returns a job ID to check the status of the batch scrape.</p><pre><code>curl -X POST https://api.firecrawl.dev/v2/batch/scrape \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: Bearer YOUR_API_KEY' \\\n    -d '{\n      \"urls\": [\"https://docs.firecrawl.dev\", \"https://docs.firecrawl.dev/sdks/overview\"],\n      \"formats\" : [\"markdown\", \"html\"]\n    }'\n</code></pre><pre><code>from firecrawl import Firecrawl\n\nfirecrawl = Firecrawl(api_key=\"fc-YOUR_API_KEY\")\n\n# Scrape a website (returns a Document)\ndoc = firecrawl.scrape(\n    \"https://firecrawl.dev\",\n    formats=[\"markdown\", \"html\"],\n)\nprint(doc.markdown)\n\n# Crawl a website\nresponse = firecrawl.crawl(\n    \"https://firecrawl.dev\",\n    limit=100,\n    scrape_options={\"formats\": [\"markdown\", \"html\"]},\n    poll_interval=30,\n)\nprint(response)\n</code></pre><h3>Extracting structured data from a URL</h3><p>With LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:</p><pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\nclass Article(BaseModel):\n    title: str\n    points: int\n    by: str\n    commentsURL: str\n\nclass TopArticles(BaseModel):\n    top: List[Article] = Field(..., description=\"Top 5 stories\")\n\n# Use JSON format with a Pydantic schema\ndoc = firecrawl.scrape(\n    \"https://news.ycombinator.com\",\n    formats=[{\"type\": \"json\", \"schema\": TopArticles}],\n)\nprint(doc.json)\n</code></pre><p>To install the Firecrawl Node SDK, you can use npm:</p><pre><code>npm install @mendable/firecrawl-js\n</code></pre><ol><li>Set the API key as an environment variable named  or pass it as a parameter to the  class.</li></ol><pre><code>import Firecrawl from '@mendable/firecrawl-js';\n\nconst firecrawl = new Firecrawl({ apiKey: 'fc-YOUR_API_KEY' });\n\n// Scrape a website\nconst doc = await firecrawl.scrape('https://firecrawl.dev', {\n  formats: ['markdown', 'html'],\n});\nconsole.log(doc);\n\n// Crawl a website\nconst response = await firecrawl.crawl('https://firecrawl.dev', {\n  limit: 100,\n  scrapeOptions: { formats: ['markdown', 'html'] },\n});\nconsole.log(response);\n</code></pre><h3>Extracting structured data from a URL</h3><p>With LLM extraction, you can easily extract structured data from any URL. We support zod schema to make it easier for you too. Here is how to use it:</p><pre><code>import Firecrawl from '@mendable/firecrawl-js';\nimport { z } from 'zod';\n\nconst firecrawl = new Firecrawl({ apiKey: 'fc-YOUR_API_KEY' });\n\n// Define schema to extract contents into\nconst schema = z.object({\n  top: z\n    .array(\n      z.object({\n        title: z.string(),\n        points: z.number(),\n        by: z.string(),\n        commentsURL: z.string(),\n      })\n    )\n    .length(5)\n    .describe('Top 5 stories on Hacker News'),\n});\n\n// Use the v2 extract API with direct Zod schema support\nconst extractRes = await firecrawl.extract({\n  urls: ['https://news.ycombinator.com'],\n  schema,\n  prompt: 'Extract the top 5 stories',\n});\n\nconsole.log(extractRes);\n</code></pre><h2>Open Source vs Cloud Offering</h2><p>Firecrawl is open source available under the AGPL-3.0 license.</p><p>To deliver the best possible product, we offer a hosted version of Firecrawl alongside our open-source offering. The cloud solution allows us to continuously innovate and maintain a high-quality, sustainable service for all users.</p><p>Firecrawl Cloud is available at <a href=\"https://firecrawl.dev\">firecrawl.dev</a> and offers a range of features that are not available in the open source version:</p><p><em>It is the sole responsibility of the end users to respect websites' policies when scraping, searching and crawling with Firecrawl. Users are advised to adhere to the applicable privacy policies and terms of use of the websites prior to initiating any scraping activities. By default, Firecrawl respects the directives specified in the websites' robots.txt files when crawling. By utilizing Firecrawl, you expressly agree to comply with these conditions.</em></p><a href=\"https://github.com/firecrawl/firecrawl/graphs/contributors\"><img alt=\"contributors\" src=\"https://contrib.rocks/image?repo=firecrawl/firecrawl\"></a><p>This project is primarily licensed under the GNU Affero General Public License v3.0 (AGPL-3.0), as specified in the LICENSE file in the root directory of this repository. However, certain components of this project are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.</p><ul><li>The AGPL-3.0 license applies to all parts of the project unless otherwise specified.</li><li>The SDKs and some UI components are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.</li><li>When using or contributing to this project, ensure you comply with the appropriate license terms for the specific component you are working with.</li></ul><p>For more details on the licensing of specific components, please refer to the LICENSE files in the respective directories or contact the project maintainers.</p>","contentLength":17377,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"n8n-io/self-hosted-ai-starter-kit","url":"https://github.com/n8n-io/self-hosted-ai-starter-kit","date":1755743657,"author":"","guid":234831,"unread":true,"content":"<p>The Self-hosted AI Starter Kit is an open-source template that quickly sets up a local AI environment. Curated by n8n, it provides essential tools for creating secure, self-hosted AI workflows.</p><p><strong>Self-hosted AI Starter Kit</strong> is an open-source Docker Compose template designed to swiftly initialize a comprehensive local AI and low-code development environment.</p><p>Curated by <a href=\"https://github.com/n8n-io\">https://github.com/n8n-io</a>, it combines the self-hosted n8n platform with a curated list of compatible AI products and components to quickly get started with building self-hosted AI workflows.</p><p>âœ… <a href=\"https://n8n.io/\"></a> - Low-code platform with over 400 integrations and advanced AI components</p><p>âœ… <a href=\"https://ollama.com/\"></a> - Cross-platform LLM platform to install and run the latest local LLMs</p><p>âœ… <a href=\"https://qdrant.tech/\"></a> - Open-source, high performance vector store with an comprehensive API</p><p>âœ… <a href=\"https://www.postgresql.org/\"></a> - Workhorse of the Data Engineering world, handles large amounts of data safely.</p><p>â­ï¸  for scheduling appointments</p><p>â­ï¸  securely without data leaks</p><p>â­ï¸  for enhanced company communications and IT operations</p><p>â­ï¸ <strong>Private Financial Document Analysis</strong> at minimal cost</p><pre><code>git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git\ncd self-hosted-ai-starter-kit\ncp .env.example .env # you should update secrets and passwords inside\n</code></pre><h3>Running n8n using Docker Compose</h3><pre><code>git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git\ncd self-hosted-ai-starter-kit\ncp .env.example .env # you should update secrets and passwords inside\ndocker compose --profile gpu-nvidia up\n</code></pre><h3>For AMD GPU users on Linux</h3><pre><code>git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git\ncd self-hosted-ai-starter-kit\ncp .env.example .env # you should update secrets and passwords inside\ndocker compose --profile gpu-amd up\n</code></pre><h4>For Mac / Apple Silicon users</h4><p>If youâ€™re using a Mac with an M1 or newer processor, you can't expose your GPU to the Docker instance, unfortunately. There are two options in this case:</p><ol><li>Run the starter kit fully on CPU, like in the section \"For everyone else\" below</li><li>Run Ollama on your Mac for faster inference, and connect to that from the n8n instance</li></ol><p>If you want to run Ollama on your mac, check the <a href=\"https://ollama.com/\">Ollama homepage</a> for installation instructions, and run the starter kit as follows:</p><pre><code>git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git\ncd self-hosted-ai-starter-kit\ncp .env.example .env # you should update secrets and passwords inside\ndocker compose up\n</code></pre><h5>For Mac users running OLLAMA locally</h5><p>If you're running OLLAMA locally on your Mac (not in Docker), you need to modify the OLLAMA_HOST environment variable</p><pre><code>git clone https://github.com/n8n-io/self-hosted-ai-starter-kit.git\ncd self-hosted-ai-starter-kit\ncp .env.example .env # you should update secrets and passwords inside\ndocker compose --profile cpu up\n</code></pre><p>The core of the Self-hosted AI Starter Kit is a Docker Compose file, pre-configured with network and storage settings, minimizing the need for additional installations. After completing the installation steps above, simply follow the steps below to get started.</p><ol><li>Click the  button at the bottom of the canvas, to start running the workflow.</li><li>If this is the first time youâ€™re running the workflow, you may need to wait until Ollama finishes downloading Llama3.2. You can inspect the docker console logs to check on the progress.</li></ol><p>With your n8n instance, youâ€™ll have access to over 400 integrations and a suite of basic and advanced AI nodes such as <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/\">AI Agent</a>, <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.text-classifier/\">Text classifier</a>, and <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.information-extractor/\">Information Extractor</a> nodes. To keep everything local, just remember to use the Ollama node for your language model and Qdrant as your vector store.</p><blockquote><p>[!NOTE] This starter kit is designed to help you get started with self-hosted AI workflows. While itâ€™s not fully optimized for production environments, it combines robust components that work well together for proof-of-concept projects. You can customize it to meet your specific needs</p></blockquote><pre><code>docker compose --profile gpu-nvidia pull\ndocker compose create &amp;&amp; docker compose --profile gpu-nvidia up\n</code></pre><ul><li><h3>For Mac / Apple Silicon users</h3></li></ul><pre><code>docker compose pull\ndocker compose create &amp;&amp; docker compose up\n</code></pre><pre><code>docker compose --profile cpu pull\ndocker compose create &amp;&amp; docker compose --profile cpu up\n</code></pre><p>n8n is full of useful content for getting started quickly with its AI concepts and nodes. If you run into an issue, go to <a href=\"https://raw.githubusercontent.com/n8n-io/self-hosted-ai-starter-kit/main/#support\">support</a>.</p><p>For more AI workflow ideas, visit the <a href=\"https://n8n.io/workflows/categories/ai/\"><strong>official n8n AI template gallery</strong></a>. From each workflow, select the  button to automatically import the workflow into your local n8n instance.</p><p>The self-hosted AI starter kit will create a shared folder (by default, located in the same directory) which is mounted to the n8n container and allows n8n to access files on disk. This folder within the n8n container is located at  -- this is the path youâ€™ll need to use in nodes that interact with the local filesystem.</p><p><strong>Nodes that interact with the local filesystem</strong></p><p>This project is licensed under the Apache License 2.0 - see the <a href=\"https://raw.githubusercontent.com/n8n-io/self-hosted-ai-starter-kit/main/LICENSE\">LICENSE</a> file for details.</p><p>Join the conversation in the <a href=\"https://community.n8n.io/\">n8n Forum</a>, where you can:</p><ul><li>: Show off what youâ€™ve built with n8n and inspire others in the community.</li><li>: Whether youâ€™re just getting started or youâ€™re a seasoned pro, the community and our team are ready to support with any challenges.</li><li>: Have an idea for a feature or improvement? Let us know! Weâ€™re always eager to hear what youâ€™d like to see next.</li></ul>","contentLength":5257,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"simstudioai/sim","url":"https://github.com/simstudioai/sim","date":1755743657,"author":"","guid":234832,"unread":true,"content":"<p>Sim is an open-source AI agent workflow builder. Sim's interface is a lightweight, intuitive way to rapidly build and deploy LLMs that connect with your favorite tools.</p><p align=\"center\">Build and deploy AI agent workflows in minutes.</p><p>Docker must be installed and running on your machine.</p><table><tbody><tr><td>Port to run Sim on (default )</td></tr><tr><td>Skip pulling latest Docker images</td></tr></tbody></table><h3>Self-hosted: Docker Compose</h3><pre><code># Clone the repository\ngit clone https://github.com/simstudioai/sim.git\n\n# Navigate to the project directory\ncd sim\n\n# Start Sim\ndocker compose -f docker-compose.prod.yml up -d\n</code></pre><h4>Using Local Models with Ollama</h4><p>Run Sim with local AI models using <a href=\"https://ollama.ai\">Ollama</a> - no external APIs required:</p><pre><code># Start with GPU support (automatically downloads gemma3:4b model)\ndocker compose -f docker-compose.ollama.yml --profile setup up -d\n\n# For CPU-only systems:\ndocker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d\n</code></pre><pre><code>docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b\n</code></pre><h3>Self-hosted: Dev Containers</h3><ol><li>Open the project and click \"Reopen in Container\" when prompted</li><li>Run  in the terminal or use the  alias \n  <ul><li>This starts both the main application and the realtime socket server</li></ul></li></ol><h3>Self-hosted: Manual Setup</h3><p> Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the  PostgreSQL extension.</p><ol><li>Clone and install dependencies:</li></ol><pre><code>git clone https://github.com/simstudioai/sim.git\ncd sim\nbun install\n</code></pre><ol start=\"2\"><li>Set up PostgreSQL with pgvector:</li></ol><p>You need PostgreSQL with the  extension for embedding support. Choose one option:</p><p><strong>Option A: Using Docker (Recommended)</strong></p><pre><code># Start PostgreSQL with pgvector extension\ndocker run --name simstudio-db \\\n  -e POSTGRES_PASSWORD=your_password \\\n  -e POSTGRES_DB=simstudio \\\n  -p 5432:5432 -d \\\n  pgvector/pgvector:pg17\n</code></pre><p><strong>Option B: Manual Installation</strong></p><pre><code>cd apps/sim\ncp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)\n</code></pre><p>Update your  file with the database URL:</p><pre><code>DATABASE_URL=\"postgresql://postgres:your_password@localhost:5432/simstudio\"\n</code></pre><ol start=\"5\"><li>Start the development servers:</li></ol><p><strong>Recommended approach - run both servers together (from project root):</strong></p><p>This starts both the main Next.js application and the realtime socket server required for full functionality.</p><p><strong>Alternative - run servers separately:</strong></p><p>Next.js app (from project root):</p><p>Realtime socket server (from  directory in a separate terminal):</p><pre><code>cd apps/sim\nbun run dev:sockets\n</code></pre><p>Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:</p><ul><li>Go to <a href=\"https://sim.ai\">https://sim.ai</a> â†’ Settings â†’ Copilot and generate a Copilot API key</li><li>Set  in your self-hosted environment to that value</li><li>Host Sim on a publicly available DNS and set NEXT_PUBLIC_APP_URL and BETTER_AUTH_URL to that value (<a href=\"https://ngrok.com/\">ngrok</a>)</li></ul><p>This project is licensed under the Apache License 2.0 - see the <a href=\"https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE\">LICENSE</a> file for details.</p><p align=\"center\">Made with â¤ï¸ by the Sim Team</p>","contentLength":2808,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"epicenter-so/epicenter","url":"https://github.com/epicenter-so/epicenter","date":1755743657,"author":"","guid":234833,"unread":true,"content":"<p>Press shortcut â†’ speak â†’ get text. Free and open source. More local-first apps soon â¤ï¸</p><p align=\"center\">Local-first, open-source apps</p><p align=\"center\">Own your data. Use any model you want. Free and open source â¤ï¸</p><blockquote><p> The <a href=\"https://github.com/braden-w/whispering/\">Whispering</a> repository is now part of ! You can find it <a href=\"https://github.com/epicenter-so/epicenter/tree/main/apps/whispering\">here</a>. Everything else remains the sameâ€”same tools, same philosophy, same team.</p></blockquote><p>Epicenter is an ecosystem of open-source, local-first apps. Our eventual goal is to store all of your dataâ€”notes, transcripts, chat historiesâ€”in a single folder of plain text and SQLite. Every tool we build shares this memory. It's open, tweakable, and yours. Grep it, open it in Obsidian, host it wherever you like. The choice is yours.</p><table><tbody><tr><td align=\"center\" width=\"50%\"><p>Press shortcut â†’ speak â†’ get text. Desktop transcription that cuts out the middleman. Bring your own API key.</p></td><td align=\"center\" width=\"50%\"><p>A local-first assistant you can chat with. It lives in your folder, becoming the access point to everything you've ever written, thought, or built.</p></td></tr></tbody></table><p>Our vision is to build a personal workspace where you own your data, choose your models, and replace siloed apps with open, interoperable alternatives. All while preserving authenticity and being free and open source.</p><p>Epicenter will have more apps in the future, but for now, the best way to get started is to run Whispering locally:</p><pre><code># Prerequisites: Install Bun from https://bun.sh (run bun upgrade if there's issues)\ngit clone https://github.com/epicenter-so/epicenter.git\ncd epicenter\nbun install  # Will prompt to upgrade if your Bun version is too old\ncd apps/whispering\nbun dev\n</code></pre><p>If you think like a generalist, build like a hacker, and value tools that respect your mindâ€”you'll fit right in.</p><h3>We're looking for contributors</h3><p>If you're passionate about open source, local-first software, or are just a cracked Svelte/TypeScript developerâ€”we'd love to build with you.</p><p>Contributors coordinate and share ideas in our Discord community.</p><p><a href=\"https://raw.githubusercontent.com/epicenter-so/epicenter/main/LICENSE\">MIT</a>. Build on it. Fork it. Make it yours. Please contribute if you can.</p><p align=\"center\"><sub>Built with â¤ï¸ for data ownership, local-first, and open-souce</sub></p>","contentLength":1999,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"microsoft/BitNet","url":"https://github.com/microsoft/BitNet","date":1755743657,"author":"","guid":234834,"unread":true,"content":"<p>Official inference framework for 1-bit LLMs</p><p>Try it out via this <a href=\"https://bitnet-demo.azurewebsites.net/\">demo</a>, or build and run it on your own <a href=\"https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source\">CPU</a> or <a href=\"https://github.com/microsoft/BitNet/raw/main/gpu/README.md\">GPU</a>.</p><p>bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support  and  inference of 1.58-bit models on CPU and GPU (NPU support will coming next).</p><p>The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of  to  on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by  to , further boosting overall efficiency. On x86 CPUs, speedups range from  to  with energy reductions between  to . Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the <a href=\"https://arxiv.org/abs/2410.16144\">technical report</a> for more details.</p><img src=\"https://raw.githubusercontent.com/microsoft/BitNet/main/assets/m2_performance.jpg\" alt=\"m2_performance\" width=\"800\"><img src=\"https://raw.githubusercontent.com/microsoft/BitNet/main/assets/intel_performance.jpg\" alt=\"m2_performance\" width=\"800\"><blockquote><p>The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.</p></blockquote><p>A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:</p><p>This project is based on the <a href=\"https://github.com/ggerganov/llama.cpp\">llama.cpp</a> framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in <a href=\"https://github.com/microsoft/T-MAC/\">T-MAC</a>. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.</p><p>â—ï¸<strong>We use existing 1-bit LLMs available on <a href=\"https://huggingface.co/\">Hugging Face</a> to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.</strong></p><ul><li>clang&gt;=18 \n  <ul><li><p>For Windows users, install <a href=\"https://visualstudio.microsoft.com/downloads/\">Visual Studio 2022</a>. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):</p><ul><li>Desktop-development with C++</li><li>C++-CMake Tools for Windows</li><li>C++-Clang Compiler for Windows</li><li>MS-Build Support for LLVM-Toolset (clang)</li></ul></li></ul></li></ul><blockquote><p>[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.</p></blockquote><pre><code>git clone --recursive https://github.com/microsoft/BitNet.git\ncd BitNet\n</code></pre><pre><code># (Recommended) Create a new conda environment\nconda create -n bitnet-cpp python=3.9\nconda activate bitnet-cpp\n\npip install -r requirements.txt\n</code></pre><pre><code># Manually download the model and run with local path\nhuggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T\npython setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s\n\n</code></pre><pre>usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]\n                    [--use-pretuned]\n\nSetup the environment for running inference\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}\n                        Model used for inference\n  --model-dir MODEL_DIR, -md MODEL_DIR\n                        Directory to save/load the model\n  --log-dir LOG_DIR, -ld LOG_DIR\n                        Directory to save the logging info\n  --quant-type {i2_s,tl1}, -q {i2_s,tl1}\n                        Quantization type\n  --quant-embd          Quantize the embeddings to f16\n  --use-pretuned, -p    Use the pretuned kernel parameters\n</pre><pre><code># Run inference with the quantized model\npython run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p \"You are a helpful assistant\" -cnv\n</code></pre><pre>usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]\n\nRun inference\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -m MODEL, --model MODEL\n                        Path to model file\n  -n N_PREDICT, --n-predict N_PREDICT\n                        Number of tokens to predict when generating text\n  -p PROMPT, --prompt PROMPT\n                        Prompt to generate text from\n  -t THREADS, --threads THREADS\n                        Number of threads to use\n  -c CTX_SIZE, --ctx-size CTX_SIZE\n                        Size of the prompt context\n  -temp TEMPERATURE, --temperature TEMPERATURE\n                        Temperature, a hyperparameter that controls the randomness of the generated text\n  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)\n                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)\n</pre><p>We provide scripts to run the inference benchmark providing a model.</p><pre><code>usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  \n   \nSetup the environment for running the inference  \n   \nrequired arguments:  \n  -m MODEL, --model MODEL  \n                        Path to the model file. \n   \noptional arguments:  \n  -h, --help  \n                        Show this help message and exit. \n  -n N_TOKEN, --n-token N_TOKEN  \n                        Number of generated tokens. \n  -p N_PROMPT, --n-prompt N_PROMPT  \n                        Prompt to generate text from. \n  -t THREADS, --threads THREADS  \n                        Number of threads to use. \n</code></pre><p>Here's a brief explanation of each argument:</p><ul><li>, : The path to the model file. This is a required argument that must be provided when running the script.</li><li>, : The number of tokens to generate during the inference. It is an optional argument with a default value of 128.</li><li>, : The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.</li><li>, : The number of threads to use for running the inference. It is an optional argument with a default value of 2.</li><li>, : Show the help message and exit. Use this argument to display usage information.</li></ul><pre><code>python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  \n</code></pre><p>This command would run the inference benchmark using the model located at , generating 200 tokens from a 256 token prompt, utilizing 4 threads.</p><p>For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:</p><pre><code>python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M\n\n# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate\npython utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128\n</code></pre><h3>Convert from  Checkpoints</h3><pre><code># Prepare the .safetensors model file\nhuggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16\n\n# Convert to gguf model\npython ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16\n</code></pre><h3>FAQ (Frequently Asked Questions)ğŸ“Œ</h3><h4>Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?</h4><p> This is an issue introduced in recent version of llama.cpp. Please refer to this <a href=\"https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323\">commit</a> in the <a href=\"https://github.com/abetlen/llama-cpp-python/issues/1942\">discussion</a> to fix this issue.</p><h4>Q2: How to build with clang in conda environment on windows?</h4><p> Before building the project, verify your clang installation and access to Visual Studio tools by running:</p><p>This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:</p><pre><code>'clang' is not recognized as an internal or external command, operable program or batch file.\n</code></pre><p>It indicates that your command line window is not properly initialized for Visual Studio tools.</p><p>â€¢ If you are using Command Prompt, run:</p><pre><code>\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Professional\\Common7\\Tools\\VsDevCmd.bat\" -startdir=none -arch=x64 -host_arch=x64\n</code></pre><p>â€¢ If you are using Windows PowerShell, run the following commands:</p><pre><code>Import-Module \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Professional\\Common7\\Tools\\Microsoft.VisualStudio.DevShell.dll\" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments \"-arch=x64 -host_arch=x64\"\n</code></pre><p>These steps will initialize your environment and allow you to use the correct Visual Studio tools.</p>","contentLength":8820,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Leantime/leantime","url":"https://github.com/Leantime/leantime","date":1755743657,"author":"","guid":234835,"unread":true,"content":"<p>Leantime is a goals focused project management system for non-project managers. Building with ADHD, Autism, and dyslexia in mind.</p><table><thead><tr><th>Information/Knowledge Management</th></tr></thead><tbody><tr><td>Task management viakanban boards, gantt, table, list and calendar views</td><td>Project Dashboards, reports &amp; status updates</td></tr><tr><td>Unlimited subtasks and dependencies</td><td>Multiple user roles and per project permissions</td></tr><tr><td>Lean &amp; Business Model Canvas</td><td>Two factor authentication</td></tr><tr><td>File Storage via S3 or local filesystem</td></tr><tr><td>Timetracking &amp; timesheets</td><td>Screen &amp; webcam recording</td><td>Extendable via plugins and API</td></tr><tr><td>Comments/discussions on everything</td><td>Integrates with Slack, Mattermost, Discord</td></tr><tr><td>Available in over 20 languages</td></tr><tr><td>*yes, all of these features are included in the OSS version</td></tr></tbody></table><ul><li>MySQL 8.0+ or MariaDB 10.6+</li><li>Apache or Nginx (IIS works with some modifications)</li><li>Multibyte String (mbstring)</li></ul><p>Ctype PHP Extension cURL PHP Extension DOM PHP Extension Fileinfo PHP Extension Filter PHP Extension Hash PHP Extension Mbstring PHP Extension OpenSSL PHP Extension PCRE PHP Extension PDO PHP Extension Session PHP Extension Tokenizer PHP Extension XML PHP Extension</p><h3>ï¸âš¡ï¸ Installation (Production)</h3><p>There are two main ways to install LeanTime for production. The first of which is to install all needed pieces of the system locally. The second is to use the officially supported Docker image.</p><h4>Local Production Installation</h4><ul><li>Download latest release package (file is called: Leantime-vx.x.x.zip) from the <a href=\"https://github.com/Leantime/leantime/releases\">release page</a></li><li>Create an empty MySQL database</li><li>Upload the entire directory to your server</li><li>Point your domain root to the  directory</li><li>Rename  to </li><li>Fill in your database credentials (username, password, host, dbname) in </li><li>Navigate to </li><li>Follow instructions to install database and set up first user account</li></ul><p>Whilst the steps above are applicable to Internet Information Services (IIS), there is an additional configuration change that may be required in IIS to ensure full functionality - you need to allow the PATCH method:</p><ul><li>Expand the server and sites on the left and select the LeanTime site</li><li>Double click on </li><li>Double click on the PHP handler mapping that is used by the site</li><li>Click </li><li>In the <code>One of the following verbs</code> text box, add  - for example: </li><li>In the  text box, put a double quote character () at the start and at the end of the path to the  file (<em>this isn't needed if the path doesn't have a space in it</em>)</li><li>A popup will appear asking if you want to create a FastCGI application - click </li></ul><p>Note: You may need to repeat this when you upgrade PHP.</p><h4>Production Installation via Docker</h4><p>We maintain an official <a href=\"https://hub.docker.com/r/leantime/leantime\">Docker image on dockerhub</a>. To run the image enter your MySQL credentials and execute. You can pass in all the configuration variables from .env</p><pre><code>docker run -d --restart unless-stopped -p 8080:8080 --network leantime-net \\\n-e LEAN_DB_HOST=mysql_leantime \\\n-e LEAN_DB_USER=admin \\\n-e LEAN_DB_PASSWORD=321.qwerty \\\n-e LEAN_DB_DATABASE=leantime \\\n-e LEAN_EMAIL_RETURN=changeme@local.local \\\n--name leantime leantime/leantime:latest\n</code></pre><p>Once started you can go to  and run the installation script.</p><p><strong>Important: If you are planning to use plugins you need to mount the plugin folder <code>plugins:/var/www/html/app/Plugins</code> and ensure the www-data user has access to it. Otherwise installation may fail or plugins will be removed after a restart</strong></p><h5>Docker Installation Notes</h5><p>If you intend to place Leantime behind a reverse proxy (nginx, etc.) to handle custom domain name resolution and SSL offloading, you will need to set the following environment variable in docker</p><pre><code>-e LEAN_APP_URL=https://yourdomain.com \\\n</code></pre><ul><li>Update yourdomain.com to your custom domain name. </li></ul><h3>ğŸ¤“ Installation (Development)</h3><p>There are two ways to install a development setup of LeanTime. The first (but most technical) is to install all pieces of the system locally. The second (and preferred method) is to use a docker containerized development environment.</p><h4>Local Development Installation</h4><ul><li>Clone repository to your local server</li><li>Run webpack builder via </li><li>Point your local domain to the  directory</li><li>Rename  to </li><li>Fill in your database credentials (username, password, host, dbname) in </li><li>Navigate to </li><li>Follow instructions to install database and user account</li></ul><h4>Development Installation via Docker</h4><p>For development, we use a dockerized development environment. You will need to have , , , ,  and  installed.</p><ul><li>Notes for Windows Environments: \n  <ul><li>Run all commands within the git bash terminal in order to utilize unix specific commands</li><li>If installing php from a zip file, make sure to configure php.ini It does not exist initially, so copy C:\\php\\php.ini-development to C:\\php\\php.ini. You will also need to edit php.ini in a text editor and enable all needed extensions for the build process. You can find these by running the make commands and looking for any extensions that error out as missing. You can enable them by searching php.ini for the extension that will look like:  and removing the semicolon.</li></ul></li></ul><p>In order to build the development docker image, in the root of this repository, run a primer with</p><p>this will start the development server on port 8090.</p><p>The dev environment provides a MySQL server, mail server, s3 server, and should be good to go for your needs out of the box. The configuration of the development environment is found in , and is already seeded with the appropriate values. <strong>You should probably not be modifying this unless you plan to work on a feature for a specific integration</strong>. the applications you get are as follows</p><p>Additionally, Xdebug is enabled, but you will have to modify your IDE key in the  file(or alternatively, on your IDE). You also need to have port 9003 temporarily open on your firewall so you can utilize it effectively. This is because connections from docker to the host will count as external inbound connections </p><p>Static Analysis  Code Style  (to fix code style automatically use ) Unit Tests  Acceptance Tests  (requires docker)</p><p>You can test individual acceptance test groups directly using: For api: <code>docker compose --file .dev/docker-compose.yaml --file .dev/docker-compose.tests.yaml exec leantime-dev php vendor/bin/codecept run -g api --steps</code> For timesheets: <code>docker compose --file .dev/docker-compose.yaml --file .dev/docker-compose.tests.yaml exec leantime-dev php vendor/bin/codecept run -g timesheet --steps</code></p><ul><li>Make sure to take a backup of your database and files</li><li>Replace all files in your directory with the updated version</li><li>If there were any database changes, the system will redirect you to </li></ul><ul><li>Run <code>php bin/leantime system:update</code></li></ul><ul><li>Before updating, make sure your mysql container was started using a mounted volume, otherwise your content will be deleted</li><li>Delete/Stop existing container</li><li>Pull the latest docker image and rebuild using your compose file</li></ul><p>Please refer to our <a href=\"https://docs.leantime.io/installation/common-issues\">documentation</a> about common issues found when installing or updating Leantime</p><h4>You can extend Leantime by:</h4><h2>ğŸ›Ÿ Let us install it for you.</h2><p>Hassle free installation service in your environments. We can do full installations, updates, configurations or plugin installations. See our <a href=\"https://marketplace.leantime.io/product-category/services/technical/\">Marketplace</a> for details.</p><h2>â˜ï¸ Not interested in hosting yourself? Let us do it for you</h2><h2>ğŸ¤™ Need technical support?</h2><p>We can help you set up Leantime in your environment and customize it to your needs. Our support plans are <a href=\"https://leantime.io/priority-support/\">outlined on our website</a>.</p><p>Please note: We currently only support the official Leantime docker compose and standard installations. We only offer support for the most recent version.</p><p>We do not offer support for Cloudron, Elestio, Turnkey, or other external distribution platforms sharing unofficial versions of Leantime.</p><p>We're excited you are interested in contributing to Leantime. We want to make sure you have a great experience contributing to Leantime and that the new features you build will make it into core. </p><p>Find an issue on Github (or create a new one) add your name to it or comment that you will be working on it. Once fixed, create a Pull Request.</p><p>If you have an idea about new features please reach out to us on Discord. This is where we coordinate feature development and discuss whether core is the right place to add your new features (Plugins is the alternative).</p><p>Language files and translations are stored in . Once updates please create a Pull Request.</p><p>Leantime is licensed under AGPLv3. This file forms part of the Leantime Software for which the following exception is added: Plugins within the  directory which may contain plugins licensed under other licenses including our enterprise license.</p><img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=856e290f-a6e9-4fbd-9b95-a835e39a0492\">","contentLength":8298,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ComposersDesktop/CDP8","url":"https://github.com/ComposersDesktop/CDP8","date":1755743657,"author":"","guid":234836,"unread":true,"content":"<p>New version of CDP software</p><h3>Full release as of 24 October 2023</h3><h4>Copyright (c) 2022 Composers Desktop Project</h4><pre><code>The CDP System is free software; you can redistribute them and/or modify them  \nunder the  terms of the GNU Lesser General Public License as published by   \nthe Free Software Foundation; either version 2.1 of the License,   \nor (at your option) any later version.\n\nThe CDP System is distributed in the hope that it will be useful, but WITHOUT  \nANY WARRANTY; without even the implied warranty of MERCHANTABILITY or \nFITNESS FOR A PARTICULAR PURPOSE.  \nSee the GNU Lesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License  \nalong with this software (see the top-level file COPYING); if not, write to  \nthe Free Software  Foundation, Inc., 51 Franklin St, Fifth Floor,  \nBoston, MA 02110-1301 USA\n</code></pre><ul><li>approximately 80 new programs/processes by Trevor Wishart. See details in the <a href=\"https://raw.githubusercontent.com/ComposersDesktop/CDP8/main/docs\">docs</a> folder.</li><li>majority already available for use in Soundloom 17.0.4.</li><li>includes new programs for multichannel (&lt;= 8 channels) production, waveset distortion, speech/voice processing.</li><li> (.pvx) analysis file support for all pvoc-related programs. This is the standard phase vocoder analysis file format used in Csound. See also the downloadable utilities (Mac, Win32), with example files, in the companion PVXTOOLS distribution:</li><li>play program  will play mono/stereo .pvx files.</li><li>classic CDP directory utility  now recognises .pvx files with format details.</li><li>See also Tabula Vigilans (TV): some bugs fixed, full MIDI device I/O now working on Linux.</li></ul><ul><li>Developers to get involved (whether CDP8 programs or TV), especially to add new software, create new user interfaces, create libraries, and so many other things we have not thought of. Join the new  mailing list (see  for details); get immediate news of any updates pushed to github.</li></ul>","contentLength":1860,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"bitwarden/clients","url":"https://github.com/bitwarden/clients","date":1755743657,"author":"","guid":234837,"unread":true,"content":"<p>Bitwarden client apps (web, browser extension, desktop, and cli).</p><p>This repository houses all Bitwarden client applications except the mobile applications (<a href=\"https://github.com/bitwarden/ios\">iOS</a> | <a href=\"https://github.com/bitwarden/android\">android</a>).</p><p>Interested in contributing in a big way? Consider joining our team! We're hiring for many positions. Please take a look at our <a href=\"https://bitwarden.com/careers/\">Careers page</a> to see what opportunities are <a href=\"https://bitwarden.com/careers/#open-positions\">currently open</a> as well as what it's like to work at Bitwarden.</p><p>Code contributions are welcome! Please commit any pull requests against the  branch. Learn more about how to contribute by reading the <a href=\"https://contributing.bitwarden.com/contributing/\">Contributing Guidelines</a>. Check out the <a href=\"https://contributing.bitwarden.com/\">Contributing Documentation</a> for how to get started with your first contribution.</p><p>Security audits and feedback are welcome. Please open an issue or email us privately if the report is sensitive in nature. You can read our security policy in the <a href=\"https://raw.githubusercontent.com/bitwarden/clients/main/SECURITY.md\"></a> file.</p>","contentLength":823,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"laude-institute/terminal-bench","url":"https://github.com/laude-institute/terminal-bench","date":1755743657,"author":"","guid":234838,"unread":true,"content":"<p>A benchmark for LLMs on complicated tasks in the terminal</p><pre><code>#####################################################################\n#  _____                   _             _     ______________       #\n# |_   _|__ _ __ _ __ ___ (_)_ __   __ _| |   ||            ||      #\n#   | |/ _ \\ '__| '_ ` _ \\| | '_ \\ / _` | |   || &gt;          ||      #\n#   | |  __/ |  | | | | | | | | | | (_| | |   ||            ||      #\n#   |_|\\___|_|  |_| |_| |_|_|_| |_|\\__,_|_|   ||____________||      #\n#   ____                  _                   |______________|      #\n#  | __ )  ___ _ __   ___| |__                 \\\\############\\\\     #\n#  |  _ \\ / _ \\ '_ \\ / __| '_ \\                 \\\\############\\\\    # \n#  | |_) |  __/ | | | (__| | | |                 \\      ____    \\   #\n#  |____/ \\___|_| |_|\\___|_| |_|                  \\_____\\___\\____\\  #\n#                                                                   #\n#####################################################################\n</code></pre><p>Terminal-Bench is the benchmark for testing AI agents in real terminal environments. From compiling code to training models and setting up servers, Terminal-Bench evaluates how well agents can handle real-world, end-to-end tasks - autonomously.</p><p>Whether you're building LLM agents, benchmarking frameworks, or stress-testing system-level reasoning, Terminal-Bench gives you a reproducible task suite and execution harness designed for practical, real-world evaluation.</p><p>Terminal-Bench consists of two parts: a , and an  that connects a language model to our terminal sandbox.</p><p>Terminal-Bench is currently in  with ~100 tasks. Over the coming months, we are going to expand Terminal-Bench into comprehensive testbed for AI agents in text-based environments. Any contributions are welcome, especially new and challenging tasks!</p><p>Terminal-Bench is distributed as a pip package and can be run using the Terminal-Bench CLI: .</p><pre><code>uv tool install terminal-bench\n</code></pre><pre><code>pip install terminal-bench\n</code></pre><p>Each task in Terminal-Bench includes</p><ul><li>a instruction in English,</li><li>a test script to verify if the language model / agent completed the task successfully,</li><li>a reference (\"oracle\") solution that solves the task.</li></ul><p>Tasks are located in the <a href=\"https://raw.githubusercontent.com/laude-institute/terminal-bench/main/tasks\"></a> folder of the repository, and the aforementioned list of current tasks gives an overview that is easy to browse.</p><p>The harness connects language models to a sandboxed terminal environment. After <a href=\"https://www.tbench.ai/docs/installation\">installing the terminal-bench package</a> (along with the dependencies  and ) you can view how to run the harness using:</p><p>For detailed information about running the harness and its options, see the <a href=\"https://www.tbench.ai/docs/first-steps\">documentation</a>.</p><h3>Submit to Our Leaderboard</h3><p>Terminal-Bench-Core v0.1.1 is the set of tasks for Terminal-Bench's beta release and corresponds to the current leaderboard. To evaluate on it pass <code>--dataset-name terminal-bench-core</code> and  to the harness. For example:</p><pre><code>tb run \\\n    --agent terminus \\\n    --model-name anthropic/claude-3-7-latest \\\n    --dataset-name terminal-bench-core\n    --dataset-version 0.1.1\n    --n-concurrent 8\n</code></pre><p>For more information on Terminal-Bench datasets and versioning view our <a href=\"https://www.tbench.ai/docs/registry\">registry overview</a>.</p><p>If you found Terminal-Bench useful, please cite us as:</p><pre><code>@misc{tbench_2025,\n      title={Terminal-Bench: A Benchmark for AI Agents in Terminal Environments}, \n      url={https://github.com/laude-institute/terminal-bench}, \n      author={The Terminal-Bench Team}, year={2025}, month={Apr}} \n</code></pre>","contentLength":3347,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"puppeteer/puppeteer","url":"https://github.com/puppeteer/puppeteer","date":1755743657,"author":"","guid":234839,"unread":true,"content":"<p>JavaScript API for Chrome and Firefox</p><img src=\"https://user-images.githubusercontent.com/10379601/29446482-04f7036a-841f-11e7-9872-91d1fc2ea683.png\" height=\"200\" align=\"right\"><blockquote><p>Puppeteer is a JavaScript library which provides a high-level API to control Chrome or Firefox over the <a href=\"https://chromedevtools.github.io/devtools-protocol/\">DevTools Protocol</a> or <a href=\"https://pptr.dev/webdriver-bidi\">WebDriver BiDi</a>. Puppeteer runs in the headless (no visible UI) by default</p></blockquote><pre><code>npm i puppeteer # Downloads compatible Chrome during installation.\nnpm i puppeteer-core # Alternatively, install as a library, without downloading Chrome.\n</code></pre><pre><code>import puppeteer from 'puppeteer';\n// Or import puppeteer from 'puppeteer-core';\n\n// Launch the browser and open a new blank page\nconst browser = await puppeteer.launch();\nconst page = await browser.newPage();\n\n// Navigate the page to a URL.\nawait page.goto('https://developer.chrome.com/');\n\n// Set screen size.\nawait page.setViewport({width: 1080, height: 1024});\n\n// Type into search box using accessible input name.\nawait page.locator('aria/Search').fill('automate beyond recorder');\n\n// Wait and click on first result.\nawait page.locator('.devsite-result-item-link').click();\n\n// Locate the full title with a unique string.\nconst textSelector = await page\n  .locator('text/Customize and automate')\n  .waitHandle();\nconst fullTitle = await textSelector?.evaluate(el =&gt; el.textContent);\n\n// Print the full title.\nconsole.log('The title of this blog post is \"%s\".', fullTitle);\n\nawait browser.close();\n</code></pre>","contentLength":1294,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"moeru-ai/airi","url":"https://github.com/moeru-ai/airi","date":1755743657,"author":"","guid":234840,"unread":true,"content":"<p>ğŸ’–ğŸ§¸ Self hosted, you owned Grok Companion, a container of souls of waifu, cyber livings to bring them into our worlds, wishing to achieve Neuro-sama's altitude. Capable of realtime voice chat, Minecraft, Factorio playing. Web / macOS / Windows supported.</p><p align=\"center\">Re-creating Neuro-sama, a container of souls of AI waifu / virtual characters to bring them into our worlds.</p><blockquote><p>[!WARNING]  We  have any officially minted cryptocurrency or token associated with this project. Please check the information and proceed with caution.</p></blockquote><blockquote><p>We got a whole dedicated organization <a href=\"https://github.com/proj-airi\">@proj-airi</a> for all the sub-project that born from Project AIRI, check it out!</p><p>RAG, memory system, embedded database, icons, Live2D utilities, and more!</p></blockquote><p>Have you dreamed about having a cyber living being (cyber waifu / husbando, digital pet), or digital companion that could play with and talk to you?</p><p>With the power of modern large language models like <a href=\"https://chatgpt.com\">ChatGPT</a>, and famous <a href=\"https://claude.ai\">Claude</a>, asking a virtual being able to have role playing and chat with us is already easy enough for everyone. Platforms like <a href=\"https://character.ai\">Character.ai (a.k.a. c.ai)</a> and <a href=\"https://janitorai.com/\">JanitorAI</a>, and local playgrounds like <a href=\"https://github.com/SillyTavern/SillyTavern\">SillyTavern</a> is already a well-enough solution for chat based, or visual adventure game like experience.</p><blockquote><p>But, what about the abilities to play games? And see what you are coding at? Chatting while playing games, watching videos, and capable of doing many other things.</p></blockquote><p>Perhaps you know <a href=\"https://www.youtube.com/@Neurosama\">Neuro-sama</a> already, she is currently the best companion capable of playing games, chatting, and interacting with you and the participants (in VTuber community), some call this kind of being, \"digital human\" too. <strong>Sadly, it's not open sourced, you cannot interact with her after she went offline from live stream</strong>.</p><p>Therefore, this project, AIRI, offers another possibility here: <strong>let you own your digital life, cyber living, easily, anywhere, anytime</strong>.</p><h2>DevLogs we posted &amp; Recent updates</h2><h2>What's so special for this project?</h2><blockquote><p>[!TIP] Worry about the performance drop since we are using Web related technologies?</p><p>Don't worry, while Web browser version meant to give a insight about how much we can push and do inside browsers, and webviews, we will never fully rely on this, the desktop version of AIRI is capable of using native <a href=\"https://developer.nvidia.com/cuda-toolkit\">NVIDIA CUDA</a> and <a href=\"https://developer.apple.com/metal/\">Apple Metal</a> by default (thanks to HuggingFace &amp; beloved <a href=\"https://github.com/huggingface/candle\">candle</a> project), without any complex dependency managements, considering the tradeoff, it was partially powered by Web technologies for graphics, layouts, animations, and the WIP plugin systems for everyone to integrate things.</p></blockquote><p>This means that <strong>ã‚¢ã‚¤ãƒª VTuber is capable to run on modern browsers and devices</strong>, and even on mobile devices (already done with PWA support), this brought a lot of possibilities for us (the developers) to build and extend the power of ã‚¢ã‚¤ãƒª VTuber to the next level, while still left the flexibilities for users to enable features that requires TCP connections or other non-Web technologies such as connect to voice channel to Discord, or playing Minecraft, Factorio with you and your friends.</p><blockquote><p>We are still in the early stage of development where we are seeking out talented developers to join us and help us to make ã‚¢ã‚¤ãƒª VTuber a reality.</p><p>It's ok if you are not familiar with Vue.js, TypeScript, and devtools that required for this project, you can join us as an artist, designer, or even help us to launch our first live stream.</p><p>Even you are a big fan of React or Svelte, even Solid, we welcome you, you can open a sub-directory to add features that you want to see in ã‚¢ã‚¤ãƒª VTuber, or would like to experiment with.</p><p>Fields (and related projects) that we are looking for:</p><ul></ul></blockquote><img src=\"https://raw.githubusercontent.com/moeru-ai/airi/main/docs/content/public/readme-image-pc-preview.avif\"><blockquote><p>For detailed instructions to develop this project, follow the <a href=\"https://raw.githubusercontent.com/moeru-ai/airi/main/.github/CONTRIBUTING.md\">CONTRIBUTING.md</a></p></blockquote><blockquote><p>[!NOTE] By default,  will start the development server for the Stage Web (browser version), if you would like to try developing the desktop version, please make sure you read <a href=\"https://raw.githubusercontent.com/moeru-ai/airi/main/.github/CONTRIBUTING.md\">CONTRIBUTING.md</a> to setup the environment correctly.</p></blockquote><h3>Stage Tamagotchi (Desktop version)</h3><p>Please update the version in  after running the :</p><pre><code>npx bumpp --no-commit --no-tag\n</code></pre><h2>Supported the following LLM API Providers (powered by <a href=\"https://github.com/moeru-ai/xsai\">xsai</a>)</h2><h2>Sub-projects born from this project</h2><pre><code>%%{ init: { 'flowchart': { 'curve': 'catmullRom' } } }%%\n\nflowchart TD\n  Core(\"Core\")\n  Unspeech(\"unspeech\")\n  DBDriver(\"@proj-airi/drizzle-duckdb-wasm\")\n  MemoryDriver(\"[WIP] Memory Alaya\")\n  DB1(\"@proj-airi/duckdb-wasm\")\n  SVRT(\"@proj-airi/server-runtime\")\n  Memory(\"Memory\")\n  STT(\"STT\")\n  Stage(\"Stage\")\n  StageUI(\"@proj-airi/stage-ui\")\n  UI(\"@proj-airi/ui\")\n\n  subgraph AIRI\n    DB1 --&gt; DBDriver --&gt; MemoryDriver --&gt; Memory --&gt; Core\n    UI --&gt; StageUI --&gt; Stage --&gt; Core\n    Core --&gt; STT\n    Core --&gt; SVRT\n  end\n\n  subgraph UI_Components\n    UI --&gt; StageUI\n    UITransitions(\"@proj-airi/ui-transitions\") --&gt; StageUI\n    UILoadingScreens(\"@proj-airi/ui-loading-screens\") --&gt; StageUI\n    FontCJK(\"@proj-airi/font-cjkfonts-allseto\") --&gt; StageUI\n    FontXiaolai(\"@proj-airi/font-xiaolai\") --&gt; StageUI\n  end\n\n  subgraph Apps\n    Stage --&gt; StageWeb(\"@proj-airi/stage-web\")\n    Stage --&gt; StageTamagotchi(\"@proj-airi/stage-tamagotchi\")\n    Core --&gt; RealtimeAudio(\"@proj-airi/realtime-audio\")\n    Core --&gt; PromptEngineering(\"@proj-airi/playground-prompt-engineering\")\n  end\n\n  subgraph Server_Components\n    Core --&gt; ServerSDK(\"@proj-airi/server-sdk\")\n    ServerShared(\"@proj-airi/server-shared\") --&gt; SVRT\n    ServerShared --&gt; ServerSDK\n  end\n\n  STT --&gt;|Speaking| Unspeech\n  SVRT --&gt;|Playing Factorio| F_AGENT\n  SVRT --&gt;|Playing Minecraft| MC_AGENT\n\n  subgraph Factorio_Agent\n    F_AGENT(\"Factorio Agent\")\n    F_API(\"Factorio RCON API\")\n    factorio-server(\"factorio-server\")\n    F_MOD1(\"autorio\")\n\n    F_AGENT --&gt; F_API -.-&gt; factorio-server\n    F_MOD1 -.-&gt; factorio-server\n  end\n\n  subgraph Minecraft_Agent\n    MC_AGENT(\"Minecraft Agent\")\n    Mineflayer(\"Mineflayer\")\n    minecraft-server(\"minecraft-server\")\n\n    MC_AGENT --&gt; Mineflayer -.-&gt; minecraft-server\n  end\n\n  XSAI(\"xsAI\") --&gt; Core\n  XSAI --&gt; F_AGENT\n  XSAI --&gt; MC_AGENT\n\n  Core --&gt; TauriMCP(\"@proj-airi/tauri-plugin-mcp\")\n  Memory_PGVector(\"@proj-airi/memory-pgvector\") --&gt; Memory\n\n  style Core fill:#f9d4d4,stroke:#333,stroke-width:1px\n  style AIRI fill:#fcf7f7,stroke:#333,stroke-width:1px\n  style UI fill:#d4f9d4,stroke:#333,stroke-width:1px\n  style Stage fill:#d4f9d4,stroke:#333,stroke-width:1px\n  style UI_Components fill:#d4f9d4,stroke:#333,stroke-width:1px\n  style Server_Components fill:#d4e6f9,stroke:#333,stroke-width:1px\n  style Apps fill:#d4d4f9,stroke:#333,stroke-width:1px\n  style Factorio_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px\n  style Minecraft_Agent fill:#f9d4f2,stroke:#333,stroke-width:1px\n\n  style DBDriver fill:#f9f9d4,stroke:#333,stroke-width:1px\n  style MemoryDriver fill:#f9f9d4,stroke:#333,stroke-width:1px\n  style DB1 fill:#f9f9d4,stroke:#333,stroke-width:1px\n  style Memory fill:#f9f9d4,stroke:#333,stroke-width:1px\n  style Memory_PGVector fill:#f9f9d4,stroke:#333,stroke-width:1px\n</code></pre>","contentLength":6889,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"imsyy/SPlayer","url":"https://github.com/imsyy/SPlayer","date":1755657250,"author":"","guid":233609,"unread":true,"content":"<p>ğŸ‰ ä¸€ä¸ªç®€çº¦çš„éŸ³ä¹æ’­æ”¾å™¨ï¼Œæ”¯æŒé€å­—æ­Œè¯ï¼Œä¸‹è½½æ­Œæ›²ï¼Œå±•ç¤ºè¯„è®ºåŒºï¼ŒéŸ³ä¹äº‘ç›˜åŠæ­Œå•ç®¡ç†ï¼ŒéŸ³ä¹é¢‘è°±ï¼Œç§»åŠ¨ç«¯åŸºç¡€é€‚é… | ç½‘æ˜“äº‘éŸ³ä¹ | A minimalist music player</p><ul><li>ğŸŒš Light / Dark / Auto æ¨¡å¼è‡ªåŠ¨åˆ‡æ¢</li><li>ğŸ“ æœ¬åœ°æ­Œæ›²ç®¡ç†åŠåˆ†ç±»ï¼ˆå»ºè®®å…ˆä½¿ç”¨ <a href=\"https://www.cnblogs.com/vinlxc/p/11347744.html\">éŸ³ä¹æ ‡ç­¾</a> è¿›è¡ŒåŒ¹é…åå†ä½¿ç”¨ï¼‰</li><li>ğŸµ <strong>æ”¯æŒæ’­æ”¾éƒ¨åˆ†æ— ç‰ˆæƒæ­Œæ›²ï¼ˆå¯èƒ½ä¼šä¸åŸæ›²ä¸åŒ¹é…ï¼Œå®¢æˆ·ç«¯ç‹¬å åŠŸèƒ½ï¼‰</strong></li><li>â¬‡ï¸ ä¸‹è½½æ­Œæ›²ï¼ˆ æœ€é«˜æ”¯æŒ Hi-Resï¼Œéœ€å…·æœ‰ç›¸åº”ä¼šå‘˜è´¦å· ï¼‰</li></ul><p>å¯ä»¥é€šè¿‡  å·¥ä½œæµè·å–æœ€æ–°çš„å¼€å‘ç‰ˆï¼Œç›®å‰å¼€å‘ç‰ˆä»…æä¾›  ç‰ˆæœ¬</p><blockquote><p>è¯·å°½é‡æ‹‰å–æœ€æ–°åˆ†æ”¯åä½¿ç”¨æœ¬åœ°æ„å»ºæ–¹å¼ï¼Œåœ¨çº¿éƒ¨ç½²çš„ä»“åº“å¯èƒ½æ›´æ–°ä¸åŠæ—¶</p></blockquote><pre><code># æ„å»º\ndocker build -t splayer .\n\n# è¿è¡Œ\ndocker run -d --name SPlayer -p 25884:25884 splayer\n# æˆ–ä½¿ç”¨ Docker Compose\ndocker-compose up -d\n</code></pre><pre><code># ä» Docker Hub æ‹‰å–\ndocker pull imsyy/splayer:latest\n# ä» GitHub ghcr æ‹‰å–\ndocker pull ghcr.io/imsyy/splayer:latest\n\n# è¿è¡Œ\ndocker run -d --name SPlayer -p 25884:25884 imsyy/splayer:latest\n</code></pre><ol><li><p>ç‚¹å‡»æœ¬ä»“åº“å³ä¸Šè§’çš„ ï¼Œå¤åˆ¶æœ¬ä»“åº“åˆ°ä½ çš„  è´¦å·</p></li><li><p>å¤åˆ¶  æ–‡ä»¶å¹¶é‡å‘½åä¸º </p></li><li><p>å°†  æ–‡ä»¶ä¸­çš„  æ”¹ä¸ºç¬¬ä¸€æ­¥å¾—åˆ°çš„ API åœ°å€</p><pre><code>VITE_API_URL = \"https://example.com\";\n</code></pre></li><li><p>å°† <code>Build and Output Settings</code> ä¸­çš„  æ”¹ä¸º </p></li></ol><ol><li><p>é‡å¤  ä¸­çš„ 1 - 4 æ­¥éª¤</p></li><li><pre><code>git clone https://github.com/imsyy/SPlayer.git\n</code></pre></li><li><pre><code>pnpm install\n# æˆ–\nyarn install\n# æˆ–\nnpm install\n</code></pre></li><li><pre><code>pnpm build\n# æˆ–\nyarn build\n# æˆ–\nnpm build\n</code></pre></li></ol><ol><li><p>ä½¿ç”¨  å®‰è£…é¡¹ç›®ä¾èµ–ï¼ˆè‹¥å®‰è£…è¿‡ç¨‹ä¸­é‡åˆ°ç½‘ç»œé”™è¯¯ï¼Œè¯·ä½¿ç”¨å›½å†…é•œåƒæºæ›¿ä»£ï¼Œæ­¤å¤„ä¸å†èµ˜è¿°ï¼‰</p></li><li><p>å¤åˆ¶  æ–‡ä»¶å¹¶é‡å‘½åä¸º  å¹¶ä¿®æ”¹é…ç½®</p></li><li><p>æ‰“åŒ…å®¢æˆ·ç«¯ï¼Œè¯·ä¾æ®ä½ çš„ç³»ç»Ÿç±»å‹æ¥é€‰æ‹©ï¼Œæ‰“åŒ…æˆåŠŸåï¼Œä¼šè¾“å‡ºå®‰è£…åŒ…æˆ–å¯æ‰§è¡Œæ–‡ä»¶åœ¨  ç›®å½•ä¸­ï¼Œå¯è‡ªè¡Œå®‰è£…</p><table><tbody></tbody></table></li></ol><p>æœ¬é¡¹ç›®éƒ¨åˆ†åŠŸèƒ½ä½¿ç”¨äº†ç½‘æ˜“äº‘éŸ³ä¹çš„ç¬¬ä¸‰æ–¹ API æœåŠ¡ï¼Œ</p><p>åŒæ—¶ï¼Œæœ¬é¡¹ç›®å¼€å‘è€…æ‰¿è¯º <strong>ä¸¥æ ¼éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„å’Œç½‘æ˜“äº‘éŸ³ä¹ API ä½¿ç”¨åè®®ï¼Œä¸ä¼šåˆ©ç”¨æœ¬é¡¹ç›®è¿›è¡Œä»»ä½•è¿æ³•æ´»åŠ¨ã€‚</strong> å¦‚å› ä½¿ç”¨æœ¬é¡¹ç›®è€Œå¼•èµ·çš„ä»»ä½•çº çº·æˆ–è´£ä»»ï¼Œå‡ç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…ã€‚<strong>æœ¬é¡¹ç›®å¼€å‘è€…ä¸æ‰¿æ‹…ä»»ä½•å› ä½¿ç”¨æœ¬é¡¹ç›®è€Œå¯¼è‡´çš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥è´£ä»»ï¼Œå¹¶ä¿ç•™è¿½ç©¶ä½¿ç”¨è€…è¿æ³•è¡Œä¸ºçš„æƒåˆ©</strong></p><p>è¯·ä½¿ç”¨è€…åœ¨ä½¿ç”¨æœ¬é¡¹ç›®æ—¶éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„ï¼Œ<strong>ä¸è¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•å•†ä¸šåŠéæ³•ç”¨é€”ã€‚å¦‚æœ‰è¿åï¼Œä¸€åˆ‡åæœç”±ä½¿ç”¨è€…è‡ªè´Ÿã€‚</strong> åŒæ—¶ï¼Œä½¿ç”¨è€…åº”è¯¥è‡ªè¡Œæ‰¿æ‹…å› ä½¿ç”¨æœ¬é¡¹ç›®è€Œå¸¦æ¥çš„é£é™©å’Œè´£ä»»ã€‚æœ¬é¡¹ç›®å¼€å‘è€…ä¸å¯¹æœ¬é¡¹ç›®æ‰€æä¾›çš„æœåŠ¡å’Œå†…å®¹åšå‡ºä»»ä½•ä¿è¯</p>","contentLength":2514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"awslabs/mcp","url":"https://github.com/awslabs/mcp","date":1755657250,"author":"","guid":233610,"unread":true,"content":"<p>AWS MCP Servers â€” helping you get the most out of AWS, wherever you use MCP.</p><p>A suite of specialized MCP servers that help you get the most out of AWS, wherever you use MCP.</p><h2>What is the Model Context Protocol (MCP) and how does it work with AWS MCP Servers?</h2><blockquote><p>The Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you're building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.</p></blockquote><p>An MCP Server is a lightweight program that exposes specific capabilities through the standardized Model Context Protocol. Host applications (such as chatbots, IDEs, and other AI tools) have MCP clients that maintain 1:1 connections with MCP servers. Common MCP clients include agentic AI coding assistants (like Q Developer, Cline, Cursor, Windsurf) as well as chatbot applications like Claude Desktop, with more clients coming soon. MCP servers can access local data sources and remote services to provide additional context that improves the generated outputs from the models.</p><p>AWS MCP Servers use this protocol to provide AI applications access to AWS documentation, contextual guidance, and best practices. Through the standardized MCP client-server architecture, AWS capabilities become an intelligent extension of your development environment or AI application.</p><p>AWS MCP servers enable enhanced cloud-native development, infrastructure management, and development workflowsâ€”making AI-assisted cloud computing more accessible and efficient.</p><p>The Model Context Protocol is an open source project run by Anthropic, PBC. and open to contributions from the entire community. For more information on MCP, you can find further documentation <a href=\"https://modelcontextprotocol.io/introduction\">here</a></p><h2>Server Sent Events Support Removal</h2><p> On May 26th, 2025, Server Sent Events (SSE) support was removed from all MCP servers in their latest major versions. This change aligns with the Model Context Protocol specification's <a href=\"https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#backwards-compatibility\">backwards compatibility guidelines</a>.</p><p>We are actively working towards supporting <a href=\"https://modelcontextprotocol.io/specification/draft/basic/transports#streamable-http\">Streamable HTTP</a>, which will provide improved transport capabilities for future versions.</p><p>For applications still requiring SSE support, please use the previous major version of the respective MCP server until you can migrate to alternative transport methods.</p><p>MCP servers enhance the capabilities of foundation models (FMs) in several key ways:</p><ul><li><p>: By providing relevant information directly in the model's context, MCP servers significantly improve model responses for specialized domains like AWS services. This approach reduces hallucinations, provides more accurate technical details, enables more precise code generation, and ensures recommendations align with current AWS best practices and service capabilities.</p></li><li><p><strong>Access to Latest Documentation</strong>: FMs may not have knowledge of recent releases, APIs, or SDKs. MCP servers bridge this gap by pulling in up-to-date documentation, ensuring your AI assistant always works with the latest AWS capabilities.</p></li><li><p>: MCP servers convert common workflows into tools that foundation models can use directly. Whether it's CDK, Terraform, or other AWS-specific workflows, these tools enable AI assistants to perform complex tasks with greater accuracy and efficiency.</p></li><li><p><strong>Specialized Domain Knowledge</strong>: MCP servers provide deep, contextual knowledge about AWS services that might not be fully represented in foundation models' training data, enabling more accurate and helpful responses for cloud development tasks.</p></li></ul><h2>Available MCP Servers: Quick Installation</h2><p>Get started quickly with one-click installation buttons for popular MCP clients. Click the buttons below to install servers directly in Cursor or VS Code:</p><h3>ğŸš€ Getting Started with AWS</h3><p>For general AWS interactions and comprehensive API support, we recommend starting with:</p><h3>Browse by What You're Building</h3><h4>ğŸ“š Real-time access to official AWS documentation</h4><h3>ğŸ—ï¸ Infrastructure &amp; Deployment</h3><p>Build, deploy, and manage cloud infrastructure with Infrastructure as Code best practices.</p><p>Enhance AI applications with knowledge retrieval, content generation, and ML capabilities</p><p>Work with databases, caching systems, and data processing workflows.</p><h3>ğŸ› ï¸ Developer Tools &amp; Support</h3><p>Accelerate development with code analysis, documentation, and testing utilities.</p><h3>ğŸ“¡ Integration &amp; Messaging</h3><p>Connect systems with messaging, workflows, and location services.</p><p>Monitor, optimize, and manage your AWS infrastructure and costs.</p><h3>ğŸ§¬ Healthcare &amp; Lifesciences</h3><p>Interact with AWS HealthAI services.</p><h3>Browse by How You're Working</h3><h4>ğŸ‘¨â€ğŸ’» Vibe Coding &amp; Development</h4><p><em>AI coding assistants like Amazon Q Developer CLI, Cline, Cursor, and Claude Code helping you build faster</em></p><h5>Core Development Workflow</h5><h5>Container &amp; Serverless Development</h5><h5>Lifesciences Workflow Development</h5><h4>ğŸ’¬ Conversational Assistants</h4><p><em>Customer-facing chatbots, business agents, and interactive Q&amp;A systems</em></p><h5>Content Processing &amp; Generation</h5><h4>ğŸ¤– Autonomous Background Agents</h4><p><em>Headless automation, ETL pipelines, and operational systems</em></p><h2>MCP AWS Lambda Handler Module</h2><p>A Python library for creating serverless HTTP handlers for the Model Context Protocol (MCP) using AWS Lambda. This module provides a flexible framework for building MCP HTTP endpoints with pluggable session management, including built-in DynamoDB support.</p><ul><li>Easy serverless MCP HTTP handler creation using AWS Lambda</li><li>Pluggable session management system</li><li>Built-in DynamoDB session backend support</li><li>Customizable authentication and authorization</li><li>Example implementations and tests</li></ul><h2>When to use Local vs Remote MCP Servers?</h2><p>AWS MCP servers can be run either locally on your development machine or remotely on the cloud. Here's when to use each approach:</p><ul><li>: Perfect for local development, testing, and debugging</li><li>: Continue working when internet connectivity is limited</li><li>: Keep sensitive data and credentials on your local machine</li><li>: Minimal network overhead for faster response times</li><li>: Direct control over server resources and configuration</li></ul><ul><li>: Share consistent server configurations across your team</li><li>: Offload heavy processing to dedicated cloud resources</li><li>: Access your MCP servers from anywhere, any device</li><li>: Get the latest features and security patches automatically</li><li>: Easily handle varying workloads without local resource constraints</li></ul><blockquote><p>: Some MCP servers, like AWS Knowledge MCP, are provided as fully managed services by AWS. These AWS-managed remote servers require no setup or infrastructure management on your part - just connect and start using them.</p></blockquote><h2>Use Cases for the Servers</h2><p>For example, you can use the <strong>AWS Documentation MCP Server</strong> to help your AI assistant research and generate up-to-date code for any AWS service, like Amazon Bedrock Inline agents. Alternatively, you could use the  or the  to have your AI assistant create infrastructure-as-code implementations that use the latest APIs and follow AWS best practices. With the , you could ask \"What would be the estimated monthly cost for this CDK project before I deploy it?\" or \"Can you help me understand the potential AWS service expenses for this infrastructure design?\" and receive detailed cost estimations and budget planning insights. The  enables natural language interaction with Valkey data stores, allowing AI assistants to efficiently manage data operations through a simple conversational interface.</p><p>Each server has specific installation instructions with one-click installs for Cursor and VSCode. Generally, you can:</p><ol><li>Install Python using </li><li>Configure AWS credentials with access to required services</li><li>Add the server to your MCP client configuration</li></ol><p>Example configuration for Amazon Q CLI MCP ():</p><pre><code>{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.core-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n</code></pre><p>See individual server READMEs for specific requirements and configuration options.</p><p>When configuring MCP servers on Windows, you'll need to use a slightly different configuration format:</p><pre><code>{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"awslabs.core-mcp-server@latest\",\n        \"awslabs.core-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      }\n    }\n  }\n}\n</code></pre><p>If you have problems with MCP configuration or want to check if the appropriate parameters are in place, you can try the following:</p><pre><code># Run MCP server manually with timeout 15s\n$ timeout 15s uv tool run &lt;MCP Name&gt; &lt;args&gt; 2&gt;&amp;1 || echo \"Command completed or timed out\"\n\n# Example (Aurora MySQL MCP Server)\n$ timeout 15s uv tool run awslabs.mysql-mcp-server --resource_arn &lt;Your Resource ARN&gt; --secret_arn &lt;Your Secret ARN&gt; ... 2&gt;&amp;1 || echo \"Command completed or timed out\"\n\n# If the arguments are not set appropriately, you may see the following message:\nusage: awslabs.mysql-mcp-server [-h] --resource_arn RESOURCE_ARN --secret_arn SECRET_ARN --database DATABASE\n                                --region REGION --readonly READONLY\nawslabs.mysql-mcp-server: error: the following arguments are required: --resource_arn, --secret_arn, --database, --region, --readonly\n</code></pre><p><strong>Note about performance when using  suffix:</strong></p><p>Using the  suffix checks and downloads the latest MCP server package from pypi every time you start your MCP clients, but it comes with a cost of increased initial load times. If you want to minimize the initial load time, remove  and manage your uv cache yourself using one of these approaches:</p><ul><li>: where {tool} is the mcp server you want to delete from cache and install again (e.g.: \"awslabs.lambda-tool-mcp-server\") (remember to remove the '&lt;&gt;').</li><li>: this will refresh the tool with the latest version and add it to the uv cache.</li></ul><h3>Running MCP servers in containers</h3><p><em>This example uses docker with the \"awslabs.nova-canvas-mcp-server and can be repeated for each MCP server</em></p><ul><li><p>Optionally save sensitive environmental variables in a file:</p><pre><code># contents of a .env file with fictitious AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre></li><li><p>Use the docker options: , , and  as needed because the  are not available within the container.</p><pre><code>{\n  \"mcpServers\": {\n    \"awslabs.nova-canvas-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"AWS_REGION=us-east-1\",\n        \"--env-file\",\n        \"/full/path/to/.env\",\n        \"--volume\",\n        \"/full/path/to/.aws:/app/.aws\",\n        \"public.ecr.aws/awslabs-mcp/awslabs/nova-canvas-mcp-server:latest\"\n      ],\n      \"env\": {}\n    }\n  }\n}\n</code></pre></li><li><p>For testing local changes you can build and tag the image. You have to update the MCP configuration to use this tag instead of the ECR image.</p><pre><code>cd src/nova-canvas-mcp-server\ndocker build -t awslabs/nova-canvas-mcp-server .\n</code></pre></li></ul><h3>Getting Started with Amazon Q Developer CLI</h3><h3>Getting Started with Kiro</h3><h3>Getting Started with Cline and Amazon Bedrock</h3><h3>Getting Started with Cursor</h3><h3>Getting Started with Windsurf</h3><h3>Getting Started with VS Code</h3><p>Ready-to-use examples of AWS MCP Servers in action are available in the <a href=\"https://raw.githubusercontent.com/awslabs/mcp/main/samples/\">samples</a> directory. These samples provide working code and step-by-step guides to help you get started with each MCP server.</p><p>You can use these MCP servers with your AI coding assistant to <a href=\"https://en.wikipedia.org/wiki/Vibe_coding\">vibe code</a>. For tips and tricks on how to improve your vibe coding experience, please refer to our <a href=\"https://raw.githubusercontent.com/awslabs/mcp/main/VIBE_CODING_TIPS_TRICKS.md\">guide</a>.</p><p>Big shout out to our awesome contributors! Thank you for making this project better!</p><p>Contributions of all kinds are welcome! Check out our <a href=\"https://raw.githubusercontent.com/awslabs/mcp/main/CONTRIBUTING.md\">contributor guide</a> for more information.</p><p>This project is licensed under the Apache-2.0 License.</p><p>Before using an MCP Server, you should consider conducting your own independent assessment to ensure that your use would comply with your own specific security and quality control practices and standards, as well as the laws, rules, and regulations that govern you and your content.</p>","contentLength":12139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HeyPuter/puter","url":"https://github.com/HeyPuter/puter","date":1755657250,"author":"","guid":233611,"unread":true,"content":"<p>ğŸŒ The Internet OS! Free, Open-Source, and Self-Hostable.</p><h3 align=\"center\">The Internet OS! Free, Open-Source, and Self-Hostable.</h3><p>Puter is an advanced, open-source internet operating system designed to be feature-rich, exceptionally fast, and highly extensible. Puter can be used as:</p><ul><li>A privacy-first personal cloud to keep all your files, apps, and games in one secure place, accessible from anywhere at any time.</li><li>A platform for building and publishing websites, web apps, and games.</li><li>An alternative to Dropbox, Google Drive, OneDrive, etc. with a fresh interface and powerful features.</li><li>A remote desktop environment for servers and workstations.</li><li>A friendly, open-source project and community to learn about web development, cloud computing, distributed systems, and much more!</li></ul><pre><code>git clone https://github.com/HeyPuter/puter\ncd puter\nnpm install\nnpm start\n</code></pre><pre><code>mkdir puter &amp;&amp; cd puter &amp;&amp; mkdir -p puter/config puter/data &amp;&amp; sudo chown -R 1000:1000 puter &amp;&amp; docker run --rm -p 4100:4100 -v `pwd`/puter/config:/etc/puter -v `pwd`/puter/data:/var/puter  ghcr.io/heyputer/puter\n</code></pre><pre><code>mkdir -p puter/config puter/data\nsudo chown -R 1000:1000 puter\nwget https://raw.githubusercontent.com/HeyPuter/puter/main/docker-compose.yml\ndocker compose up\n</code></pre><pre><code>mkdir -p puter\ncd puter\nNew-Item -Path \"puter\\config\" -ItemType Directory -Force\nNew-Item -Path \"puter\\data\" -ItemType Directory -Force\nInvoke-WebRequest -Uri \"https://raw.githubusercontent.com/HeyPuter/puter/main/docker-compose.yml\" -OutFile \"docker-compose.yml\"\ndocker compose up\n</code></pre><p>Puter is available as a hosted service at <a href=\"https://puter.com\"></a>.</p><ul><li> Linux, macOS, Windows</li><li> 2GB minimum (4GB recommended)</li><li> 1GB free space</li><li> Version 16+ (Version 23+ recommended)</li><li> Latest stable version</li></ul><p>Connect with the maintainers and community through these channels:</p><p>We are always happy to help you with any questions you may have. Don't hesitate to ask!</p><p>This repository, including all its contents, sub-projects, modules, and components, is licensed under <a href=\"https://github.com/HeyPuter/puter/raw/main/LICENSE.txt\">AGPL-3.0</a> unless explicitly stated otherwise. Third-party libraries included in this repository may be subject to their own licenses.</p>","contentLength":2039,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HunxByts/GhostTrack","url":"https://github.com/HunxByts/GhostTrack","date":1755657250,"author":"","guid":233612,"unread":true,"content":"<p>Useful tool to track location or mobile number</p><p>Useful tool to track location or mobile number, so this tool can be called osint or also information gathering</p><img src=\"https://github.com/HunxByts/GhostTrack/raw/main/asset/bn.png\"><h3>Instalation on Linux (deb)</h3><pre><code>sudo apt-get install git\nsudo apt-get install python3\n</code></pre><pre><code>pkg install git\npkg install python3\n</code></pre><pre><code>git clone https://github.com/HunxByts/GhostTrack.git\ncd GhostTrack\npip3 install -r requirements.txt\npython3 GhostTR.py\n</code></pre><p>Display on the menu </p><img src=\"https://github.com/HunxByts/GhostTrack/blob/main/asset/ip.png \"><p>on the IP Track menu, you can combo with the seeker tool to get the target IP</p><p>Display on the menu </p><img src=\"https://github.com/HunxByts/GhostTrack/raw/main/asset/phone.png\"><p>on this menu you can search for information from the target phone number</p><p>Display on the menu </p><img src=\"https://github.com/HunxByts/GhostTrack/raw/main/asset/User.png\"> on this menu you can search for information from the target username on social media \n","contentLength":687,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"bytedance/UI-TARS","url":"https://github.com/bytedance/UI-TARS","date":1755657250,"author":"","guid":233613,"unread":true,"content":"<p>We also offer a  version, which can operate on your . To use it, please visit <a href=\"https://github.com/bytedance/UI-TARS-desktop\">https://github.com/bytedance/UI-TARS-desktop</a>. To use UI-TARS in web automation, you may refer to the open-source project <a href=\"https://github.com/web-infra-dev/Midscene\">Midscene.js</a>. : Since Qwen 2.5vl based models ultilizes absolute coordinates to ground objects, please kindly refer to our illustration about how to process coordinates in this <a href=\"https://raw.githubusercontent.com/bytedance/UI-TARS/main/README_coordinates.md\">guide</a>.</p><ul><li>ğŸŒŸ 2025.04.16: We shared the latest progress of the UI-TARS-1.5 model in our <a href=\"https://seed-tars.com/1.5\">blog</a>, which excels in playing games and performing GUI tasks, and we open-sourced the <a href=\"https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B\">UI-TARS-1.5-7B</a>.</li><li>âœ¨ 2025.03.23: We updated the OSWorld inference scripts from the original official <a href=\"https://github.com/xlang-ai/OSWorld/raw/main/run_uitars.py\">OSWorld repository</a>. Now, you can use the OSWorld official inference scripts to reproduce our results.</li></ul><p>UI-TARS-1.5, an open-source multimodal agent built upon a powerful vision-language model. It is capable of effectively performing diverse tasks within virtual worlds.</p><p>Leveraging the foundational architecture introduced in <a href=\"https://arxiv.org/abs/2501.12326\">our recent paper</a>, UI-TARS-1.5 integrates advanced reasoning enabled by reinforcement learning. This allows the model to reason through its thoughts before taking action, significantly enhancing its performance and adaptability, particularly in inference-time scaling. Our new 1.5 version achieves state-of-the-art results across a variety of standard benchmarks, demonstrating strong reasoning capabilities and notable improvements over prior models.</p><h2>ğŸš€ Quick Start Guide: Deploying and Using Our Model</h2><p>To help you get started quickly with our model, we recommend following the steps below in order. These steps will guide you through deployment, prediction post-processing to make the model take actions in your environment.</p><h3>âœ… Step 1: Deployment &amp; Inference</h3><p>ğŸ‘‰ <a href=\"https://raw.githubusercontent.com/bytedance/UI-TARS/main/README_deploy.md\">Deployment and Inference</a>. This includes instructions for model deployment using huggingface endpoint, and running your first prediction.</p><h3>âœ… Step 2: Post Processing</h3><pre><code>pip install ui-tars\n# or\nuv pip install ui-tars\n</code></pre><pre><code>from ui_tars.action_parser import parse_action_to_structure_output, parsing_response_to_pyautogui_code\n\nresponse = \"Thought: Click the button\\nAction: click(start_box='(100,200)')\"\noriginal_image_width, original_image_height = 1920, 1080\nparsed_dict = parse_action_to_structure_output(\n    response,\n    factor=1000,\n    origin_resized_height=original_image_height,\n    origin_resized_width=original_image_width,\n    model_type=\"qwen25vl\"\n)\nprint(parsed_dict)\nparsed_pyautogui_code = parsing_response_to_pyautogui_code(\n    responses=parsed_dict,\n    image_height=original_image_height,\n    image_width=original_image_width\n)\nprint(parsed_pyautogui_code)\n</code></pre><h5>FYI: Coordinates visualization</h5><p>To help you better understand the coordinate processing, we also provide a <a href=\"https://raw.githubusercontent.com/bytedance/UI-TARS/main/README_coordinates.md\">guide</a> for coordinates processing visualization.</p><p>To accommodate different device environments and task complexities, the following three prompt templates in <a href=\"https://raw.githubusercontent.com/bytedance/UI-TARS/main/codes/ui_tars/prompt.py\">codes/ui_tars/prompt.py</a>. are designed to guide GUI agents in generating appropriate actions. Choose the template that best fits your use case:</p><p>: GUI tasks on  such as Windows, Linux, or macOS.</p><ul><li>Supports common desktop operations: mouse clicks (single, double, right), drag actions, keyboard shortcuts, text input, scrolling, etc.</li><li>Ideal for browser navigation, office software interaction, file management, and other desktop-based tasks.</li></ul><p>: GUI tasks on <strong>mobile devices or Android emulators</strong>.</p><ul><li>Includes mobile-specific actions: , , , .</li><li>Suitable for launching apps, scrolling views, filling input fields, and navigating within mobile apps.</li></ul><p>: Lightweight tasks focused solely on , or for use in model training and evaluation.</p><ul><li>Only outputs the  without any reasoning ().</li><li>Useful for evaluating grounding capability.</li></ul><p>When developing or evaluating multimodal interaction systems, choose the appropriate prompt template based on your target platform (desktop vs. mobile)</p><p><strong>Online Benchmark Evaluation</strong></p><p><strong>Grounding Capability Evaluation</strong></p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>Here we compare performance across different model scales of UI-TARS on the OSworld benchmark.</p><table><thead><tr></tr></thead></table><p>While UI-TARS-1.5 represents a significant advancement in multimodal agent capabilities, we acknowledge several important limitations:</p><ul><li> Given its enhanced performance in GUI tasks, including successfully navigating authentication challenges like CAPTCHA, UI-TARS-1.5 could potentially be misused for unauthorized access or automation of protected content. To mitigate this risk, extensive internal safety evaluations are underway.</li><li> UI-TARS-1.5 still requires substantial computational resources, particularly for large-scale tasks or extended gameplay scenarios.</li><li>: UI-TARS-1.5 may occasionally generate inaccurate descriptions, misidentify GUI elements, or take suboptimal actions based on incorrect inferencesâ€”especially in ambiguous or unfamiliar environments.</li><li> The released UI-TARS-1.5-7B focuses primarily on enhancing general computer use capabilities and is not specifically optimized for game-based scenarios, where the UI-TARS-1.5 still holds a significant advantage.</li></ul><p>We are providing early research access to our top-performing UI-TARS-1.5 model to facilitate collaborative research. Interested researchers can contact us at <a href=\"mailto:TARS@bytedance.com\">TARS@bytedance.com</a>.</p><p>Looking ahead, we envision UI-TARS evolving into increasingly sophisticated agentic experiences capable of performing real-world actions, thereby empowering platforms such as <a href=\"https://team.doubao.com/en/\">doubao</a> to accomplish more complex tasks for you :)</p><p>If you find our paper and model useful in your research, feel free to give us a cite.</p><pre><code>@article{qin2025ui,\n  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},\n  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},\n  journal={arXiv preprint arXiv:2501.12326},\n  year={2025}\n}\n</code></pre>","contentLength":5757,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"aaPanel/BillionMail","url":"https://github.com/aaPanel/BillionMail","date":1755657250,"author":"","guid":233614,"unread":true,"content":"<p>BillionMail gives you open-source MailServer, NewsLetter, Email Marketing â€” fully self-hosted, dev-friendly, and free from monthly fees. Join the discord: https://discord.gg/asfXzBUhZr</p><p>BillionMail is a <strong>future open-source Mail server, Email marketing platform</strong> designed to help businesses and individuals manage their email campaigns with ease. Whether you're sending newsletters, promotional emails, or transactional messages, this tool will provide  over your email marketing efforts. With features like , and , you'll be able to create, send, and track emails like a pro.</p><p><strong>Billion emails. Any business. Guaranteed.</strong></p><h3>Step 1ï¸âƒ£ Install BillionMail:</h3><p>âœ… It takes  from installation to <strong>âœ… successful email sending</strong></p><pre><code>cd /opt &amp;&amp; git clone https://github.com/aaPanel/BillionMail &amp;&amp; cd BillionMail &amp;&amp; bash install.sh\n</code></pre><h3>Step 2ï¸âƒ£: Connect Your Domain</h3><ul></ul><h3>Step 3ï¸âƒ£: Build Your Campaign</h3><ul><li>Write or paste your email</li><li>Set send time or send now</li></ul><h2>Other installation methods</h2><h3>One-click installation on aaPanel</h3><pre><code>cd /opt &amp;&amp; git clone https://github.com/aaPanel/BillionMail &amp;&amp; cd BillionMail &amp;&amp; cp env_init .env &amp;&amp; docker compose up -d || docker-compose up -d\n</code></pre><ul></ul><p>BillionMail has integrated , you can access WebMail via .</p><p>Most email marketing platforms are either , , or . BillionMail aims to be different:</p><p>âœ…  â€“ No hidden costs, no vendor lock-in. ğŸ“Š  â€“ Track email delivery, open rates, click-through rates, and more. ğŸ“§  â€“ No restrictions on the number of emails you can send. ğŸ¨  â€“ Custom professional marketing templates for reuse. ğŸ”’  â€“ Your data stays with you, no third-party tracking. ğŸš€  â€“ Run it on your own server for complete control.</p><p>BillionMail is a , and we need your support to get started! Here's how you can help:</p><ol><li>: Show your interest by starring this repo.</li><li>: Share BillionMail with your networkâ€”developers, marketers, and open-source enthusiasts.</li><li>: Let us know what features you'd like to see in BillionMail by opening an issue or joining the discussion.</li><li>: Once development begins, we'll welcome contributions from the community. Stay tuned for updates!</li></ol><p>ğŸ“§ <strong>BillionMail â€“ The Future of Open-Source Email Marketing.</strong></p><p>If you encounter any issues or have feature requests, please <a href=\"https://github.com/aaPanel/BillionMail/issues\">open an issue</a>. Be sure to include:</p><ul><li>A clear description of the problem or request.</li><li>Steps to reproduce the issue (if applicable).</li><li>Screenshots or error logs (if applicable).</li></ul><p>âœ…It takes  from installation to </p><pre><code>cd /opt &amp;&amp; git clone https://github.com/aaPanel/BillionMail &amp;&amp; cd BillionMail &amp;&amp; bash install.sh\n</code></pre><p> (Please install Docker and docker-compose-plugin manually, and modify .env file)</p><pre><code>cd /opt &amp;&amp; git clone https://github.com/aaPanel/BillionMail &amp;&amp; cd BillionMail &amp;&amp; cp env_init .env &amp;&amp; docker compose up -d || docker-compose up -d\n</code></pre><p>BillionMail is licensed under the . This means you can:</p><p>âœ… Use the software for free. âœ… Modify and distribute the code.<p> âœ… Use it privately without restrictions.</p></p><p>See the <a href=\"https://raw.githubusercontent.com/aaPanel/BillionMail/dev/LICENSE\">LICENSE</a> file for more details.</p>","contentLength":2906,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"enescingoz/awesome-n8n-templates","url":"https://github.com/enescingoz/awesome-n8n-templates","date":1755570875,"author":"","guid":231868,"unread":true,"content":"<p>Supercharge your workflow automation with this curated collection of n8n templates! Instantly connect your favorite apps-like Gmail, Telegram, Google Drive, Slack, and more-with ready-to-use, AI-powered automations. Save time, boost productivity, and unlock the true potential of n8n in just a few clicks.</p><p>This repository contains a collection of n8n automation templates sourced from the internet. These templates are designed to help automate a wide range of tasks and workflows using <a href=\"https://n8n.partnerlinks.io/h1pwwf5m4toe\">n8n</a>, making it easier for users to discover and use ready-made automations for various platforms and services.</p><p>All automation templates in this repository were found online and are uploaded here solely for easy access and sharing. None of the templates are created or owned by the repository author. If you encounter any issues, errors, or damages resulting from the use of these templates, the repository author assumes no responsibility or liability. All rights to the original templates belong to their respective creators.</p><p>â˜• Before diving into the long list of categories and templates, grab your coffee-and if you enjoy my work, donâ€™t forget to buy me a coffee!</p><h2>Categories &amp; Template List</h2><p>ğŸ¤– Want to translate, rewrite, and repost Twitter (X) threads automatically?</p><p>Looking to effortlessly transform and publish entire Twitter (X) threads in multiple languages? Check out my <a href=\"https://n8n.partnerlinks.io/h1pwwf5m4toe\">n8n</a> Twitter Thread (Flood) Translator &amp; Poster workflowâ€”it automates extraction, translation, rewriting, and posting in one seamless process. Perfect for creators, marketers, and anyone aiming to reach new audiences with minimal effort and ultra-low cost!</p><h2>ğŸ§µ If you want to scrape Twitter (X) threads, definitely check this workflow</h2><p>Looking to extract and merge entire Twitter (X) threads quickly and affordably? Check out my <a href=\"https://n8n.io/workflows/4088-extract-and-merge-twitter-x-threads-using-twitterapiio/\">n8n Twitter Thread Fetcher workflow</a>-itâ€™s lightning-fast, cost-effective, and perfect for automating Twitter thread extraction for research, content curation, or archiving!</p><table><thead><tr></tr></thead><tbody><tr><td>Auto-label incoming Gmail messages with AI nodes</td><td>Automatically labels incoming Gmail messages using AI. The workflow retrieves message content, suggests labels like Partnership or Inquiry, and assigns them for better organization.</td></tr><tr><td>Basic Automatic Gmail Email Labelling with OpenAI and Gmail API</td><td>Uses OpenAI and Gmail API to trigger on new emails, analyze content, and assign or create labels automatically. Helps categorize emails efficiently using AI.</td></tr><tr><td>Compose reply draft in Gmail with OpenAI Assistant</td><td>Generates draft replies in Gmail using OpenAI. Triggers on new emails, extracts content, and creates a suggested reply draft to streamline responses.</td></tr><tr><td>Analyze &amp; Sort Suspicious Email Contents with ChatGPT</td><td>Analyzes suspicious emails using ChatGPT, classifies them, and can generate screenshots for review. Helps identify and sort potentially dangerous emails.</td></tr><tr><td>Analyze Suspicious Email Contents with ChatGPT Vision</td><td>Uses both text and image analysis (ChatGPT Vision) to evaluate suspicious emails. Extracts screenshots, analyzes headers and content, and flags phishing attempts.</td></tr><tr><td>A Very Simple \"Human in the Loop\" Email Response System Using AI and IMAP</td><td>Implements a simple workflow for human-in-the-loop email responses. Uses IMAP to fetch emails, summarizes content with AI, and drafts professional replies for review before sending.</td></tr><tr><td>Auto Categorise Outlook Emails with AI</td><td>Automatically categorizes Outlook emails using AI models. Moves messages to folders and assigns categories based on content, reducing manual sorting.</td></tr><tr><td>Microsoft Outlook AI Email Assistant with contact support from Monday and Airtable</td><td>An AI-powered assistant for Outlook that processes emails, sanitizes content, and assigns categories using rules from Airtable. Integrates with Monday.com for contact support.</td></tr><tr><td>ğŸ“ˆ Receive Daily Market News from FT.com to your Microsoft outlook inbox</td><td>Extracts financial news from FT.com and delivers daily updates to your Outlook inbox. Automates content extraction and email delivery for timely market insights.</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>Agentic Telegram AI bot with LangChain nodes and new tools</td><td>An advanced Telegram bot leveraging LangChain and OpenAI for conversational AI. Supports memory, dynamic tool use, and handles incoming events for rich, context-aware chat interactions.</td></tr><tr><td>AI-Powered Childrenâ€™s Arabic Storytelling on Telegram</td><td>A Telegram bot that uses OpenAI to generate and narrate childrenâ€™s stories in Arabic, making storytelling interactive and educational for young users.</td></tr><tr><td>AI-Powered Childrenâ€™s English Storytelling on Telegram with OpenAI</td><td>Creates and tells childrenâ€™s stories in English using OpenAI to engage young audiences in an interactive way.</td></tr><tr><td>Automated AI image analysis and response via Telegram</td><td>Lets users send images to Telegram and receive AI-based analysis and feedback automatically.</td></tr><tr><td>Angie, Personal AI Assistant with Telegram Voice and Text</td><td>Personal voice &amp; text assistant bot that answers queries, manages tasks, and interacts naturally using AI.</td></tr><tr><td>Chat with OpenAIâ€™s GPT via a simple Telegram Bot</td><td>A minimal Telegram bot that forwards user messages to GPT and returns AI-generated replies. Ideal starting point for AI chat.</td></tr><tr><td>Telegram AI bot assistant: ready-made template for voice &amp; text messages</td><td>Ready-made assistant bot handling both voice and text input, leveraging AI for smart conversational responses in Telegram.</td></tr><tr><td>Telegram AI Bot: NeurochainAI Text &amp; Image</td><td>Integrates NeurochainAI API for text and image generation inside Telegram, enabling creative media interactions.</td></tr><tr><td>Telegram AI bot with LangChain nodes</td><td>Uses LangChain nodes for advanced AI conversations and tool use in Telegram.</td></tr><tr><td>A general-purpose AI chatbot template for Telegram that can be customized for various use cases.</td></tr><tr><td>Telegram Bot with Supabase memory and OpenAI assistant integration</td><td>Adds long-term memory with Supabase to a Telegram bot, coupled with OpenAI for rich, context-aware conversations.</td></tr><tr><td>Allows users to upload a PDF to Telegram and chat with its contents using AI-powered summarization and Q&amp;A.</td></tr><tr><td>ğŸ¤– Telegram Messaging Agent for Text_Audio_Images</td><td>Multi-modal agent that processes text, audio, and images in Telegram chats using AI for responses.</td></tr><tr><td>Telegram to Spotify with OpenAI</td><td>Lets users request songs or playlists in Telegram and automatically create them in Spotify via OpenAI.</td></tr><tr><td>Send a random recipe once a day to Telegram</td><td>Scheduled workflow that fetches a random recipe daily and posts it to a Telegram chat.</td></tr><tr><td>Detect toxic language in Telegram messages</td><td>Monitors Telegram chats and flags messages containing toxic language using AI moderation.</td></tr><tr><td>Translate Telegram audio messages with AI (55 supported languages)</td><td>Receives voice messages, transcribes them, and sends back translations in over 50 languages.</td></tr><tr><td>Empower Your AI Chatbot with Long-Term Memory and Dynamic Tool Routing</td><td>External workflow enhancing an AI chatbot with long-term memory and dynamic tool routing capabilities.</td></tr></tbody></table><h3>Google Drive &amp; Google Sheets</h3><table><thead><tr></tr></thead><tbody><tr><td>Automated End-to-End Fine-Tuning of OpenAI Models with Google Drive Integration</td><td>Automates the fine-tuning of OpenAI models by integrating with Google Drive for data input and output, streamlining custom AI model training.</td></tr><tr><td>Automatic Background Removal for Images in Google Drive</td><td>Automatically removes backgrounds from images stored in Google Drive, preparing them for various uses like product catalogs or marketing materials.</td></tr><tr><td>Build an OpenAI Assistant with Google Drive Integration</td><td>Demonstrates building an OpenAI Assistant that accesses and utilizes files in Google Drive, enabling it to answer questions or perform tasks based on document content.</td></tr><tr><td>RAG Chatbot for Company Documents using Google Drive and Gemini</td><td>Creates a Retrieval-Augmented Generation (RAG) chatbot that answers questions based on company documents stored in Google Drive, leveraging Google Gemini.</td></tr><tr><td>RAG_Context-Aware Chunking: Google Drive to Pinecone via OpenRouter &amp; Gemini</td><td>Implements context-aware chunking for Google Drive documents, sending them to Pinecone for vector storage and using OpenRouter &amp; Gemini for advanced RAG.</td></tr><tr><td>Summarize the New Documents from Google Drive and Save Summary in Google Sheet</td><td>Monitors Google Drive for new documents, summarizes their content using AI, and saves these summaries into a Google Sheet for quick overview and analysis.</td></tr><tr><td>Upload to Instagram and Tiktok from Google Drive</td><td>Automates uploading media from Google Drive directly to Instagram and TikTok, streamlining social media content publishing.</td></tr><tr><td>Author and Publish Blog Posts From Google Sheets</td><td>Enables authoring blog posts in Google Sheets and automatically publishing them to a content management system, simplifying content creation and publishing.</td></tr><tr><td>Chat with a Google Sheet using AI</td><td>Allows users to interact with and query data within a Google Sheet using natural language via an AI model, making data analysis more accessible.</td></tr><tr><td>Chat with your event schedule from Google Sheets in Telegram</td><td>Connects a Google Sheet containing an event schedule to Telegram, allowing users to query their schedule through a Telegram bot.</td></tr><tr><td>Qualify new leads in Google Sheets via OpenAIâ€™s GPT-4</td><td>Uses OpenAI's GPT-4 to analyze and qualify new leads entered into a Google Sheet, helping sales teams prioritize their outreach.</td></tr><tr><td>Screen Applicants With AI, notify HR and save them in a Google Sheet</td><td>Automates the screening of job applicants using AI, notifies HR of qualified candidates, and saves applicant data into a Google Sheet.</td></tr><tr><td>Summarize Google Sheets form feedback via OpenAIâ€™s GPT-4</td><td>Summarizes feedback collected through Google Forms and stored in Google Sheets using OpenAI's GPT-4, providing quick insights from survey responses.</td></tr></tbody></table><p>*More sections and tables can be added below as the project expands.</p><table><thead><tr></tr></thead><tbody><tr><td>Auto-Categorize blog posts in wordpress using A.I.</td><td>This workflow automates the categorization of WordPress blog posts using AI, streamlining content organization and management.</td></tr><tr><td>Auto-Tag Blog Posts in WordPress with AI</td><td>This workflow automatically tags WordPress blog posts using AI, improving SEO and content discoverability.</td></tr><tr><td>Automate Blog Creation in Brand Voice with AI</td><td>This workflow automates the creation of blog posts, ensuring they adhere to a specific brand voice using AI.</td></tr><tr><td>Automate Content Generator for WordPress with DeepSeek R1</td><td>This workflow automates content generation for WordPress using the DeepSeek R1 AI model, enabling rapid content creation.</td></tr><tr><td>WordPress - AI Chatbot to enhance user experience - with Supabase and OpenAI</td><td>This workflow integrates an AI chatbot into WordPress using Supabase and OpenAI to enhance user experience by providing intelligent interactions.</td><td>Customer Support/Marketing</td></tr></tbody></table><h3>PDF &amp; Document Processing</h3><table><thead><tr></tr></thead><tbody><tr><td>Ask questions about a PDF using AI</td><td>This workflow fetches a PDF from Google Drive, splits it into chunks, embeds the chunks using OpenAI embeddings, and enables chat interactions with the document content.</td><td>Customer Support/Knowledge Management</td></tr><tr><td>Breakdown Documents into Study Notes using Templating MistralAI and Qdrant</td><td>This workflow triggers on new files, processes documents with MistralAI embeddings, and stores data in Qdrant vector store for study note generation.</td><td>Education/Knowledge Management</td></tr><tr><td>CV Resume PDF Parsing with Multimodal Vision AI</td><td>This workflow converts candidate resume PDFs to images, uses a Vision Language Model to assess candidate fit, and includes logic to bypass hidden AI prompts in resumes.</td></tr><tr><td>Chat with PDF docs using AI (quoting sources)</td><td>This workflow enables chat interactions with PDF documents, allowing users to ask questions and receive answers with quoted sources from the document.</td><td>Customer Support/Knowledge Management</td></tr><tr><td>Convert URL HTML to Markdown Format and Get Page Links</td><td>This workflow converts HTML content from a given URL into Markdown format and extracts all page links, useful for content scraping and analysis.</td></tr><tr><td>ETL pipeline for text processing</td><td>This workflow implements an ETL pipeline for text processing, extracting data from Twitter, storing it in MongoDB and PostgreSQL, and sending alerts to Slack based on sentiment analysis.</td></tr><tr><td>Extract and process information directly from PDF using Claude and Gemini</td><td>This workflow extracts and processes information directly from PDFs using advanced AI models like Claude and Gemini, enabling intelligent document analysis.</td></tr><tr><td>Extract data from resume and create PDF with Gotenberg</td><td>This workflow extracts structured data from resumes using AI, converts it into HTML, and then generates a well-formatted PDF using Gotenberg.</td></tr><tr><td>Extract license plate number from image uploaded via an n8n form</td><td>This workflow extracts license plate numbers from images uploaded via an n8n form using a Vision Language Model, then displays the extracted information.</td></tr><tr><td>Extract text from PDF and image using Vertex AI (Gemini) into CSV</td><td>This workflow extracts text from PDFs and images using Vertex AI (Gemini), routes based on file type, and converts the extracted data into a CSV format.</td></tr><tr><td>Invoice data extraction with LlamaParse and OpenAI</td><td>This workflow extracts structured data from invoices using LlamaParse and OpenAI, then processes it with a structured output parser for detailed invoice data extraction.</td></tr><tr><td>Write a WordPress post with AI (starting from a few keywords)</td><td>This workflow uses AI to write WordPress posts based on a few keywords, simplifying the content creation process.</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>This workflow creates an AI-powered Discord bot that categorizes user messages (success story, urgent issue, ticket) and routes them to the appropriate department (customer success, IT, customer support).</td></tr><tr><td>Send daily translated Calvin and Hobbes Comics to Discord</td><td>This workflow automates the daily retrieval of Calvin and Hobbes comics, translates the dialogues into English and Korean (or other languages), and posts them to Discord.</td></tr><tr><td>Share YouTube Videos with AI Summaries on Discord</td><td>This workflow automatically shares new YouTube videos on Discord along with AI-generated summaries of their content, leveraging caption data.</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>Chat with Postgresql Database</td><td>This workflow enables an AI assistant to chat with a PostgreSQL database, allowing users to query and retrieve data using natural language. It supports custom SQL queries and schema introspection.</td></tr><tr><td>Generate SQL queries from schema only - AI-powered</td><td>This workflow uses AI to generate SQL queries based on a given database schema, making it easier to interact with databases without manual query writing.</td></tr><tr><td>MongoDB AI Agent - Intelligent Movie Recommendations</td><td>This workflow creates an AI agent that provides intelligent movie recommendations by interacting with a MongoDB database, using aggregation pipelines to fetch relevant movie data.</td></tr><tr><td>Supabase Insertion &amp; Upsertion &amp; Retrieval</td><td>This workflow demonstrates how to perform insertion, upsertion, and retrieval operations with Supabase, specifically for handling vector embeddings and associated metadata.</td></tr><tr><td>Talk to your SQLite database with a LangChain AI Agent</td><td>This workflow allows users to interact with a SQLite database using a LangChain AI agent, enabling natural language queries and data retrieval from the database.</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>AI Agent for project management and meetings with Airtable and Fireflies</td><td>This workflow uses an AI agent to automate project management tasks and meeting follow-ups by analyzing call transcripts from Fireflies. It creates tasks in Airtable and notifies clients about their tasks.</td></tr><tr><td>AI Agent to chat with Airtable and analyze data</td><td>This workflow creates an AI agent that can chat with Airtable, analyze data, and perform queries based on user requests. It can handle aggregation functions and generate graphs/images.</td></tr><tr><td>Get Airtable data via AI and Obsidian Notes</td><td>This workflow retrieves data from Airtable using an AI agent and integrates it with Obsidian Notes, allowing for seamless data access and organization within Obsidian.</td></tr><tr><td>Handling Job Application Submissions with AI and n8n Forms</td><td>This workflow automates the handling of job application submissions by extracting information from resumes (PDFs) using AI, parsing it into a structured format, and potentially storing it in Airtable.</td></tr><tr><td>vAssistant for Hubspot Chat using OpenAi and Airtable</td><td>This workflow integrates an OpenAI assistant with HubSpot Chat and Airtable to provide automated responses and manage customer interactions. It fetches chat messages, processes them with AI, and can store relevant information in Airtable.</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>Add positive feedback messages to a table in Notion</td><td>Captures positive feedback from Typeform, analyzes sentiment with Google Cloud Natural Language, and adds it to a Notion table, with Slack notifications for high-scoring feedback.</td></tr><tr><td>Analyse papers from Hugging Face with AI and store them in Notion</td><td>Automatically fetches and analyzes papers from Hugging Face, extracts key information using AI, and stores the structured data in a Notion database.</td></tr><tr><td>Automate Competitor Research with Exa.ai, Notion and AI Agents</td><td>Builds a competitor research agent using Exa.ai to find similar companies. AI agents then scour the internet for company overviews, product offerings, and customer reviews, compiling a report into a Notion table.</td></tr><tr><td>Automate LinkedIn Outreach with Notion and OpenAI</td><td>Automates LinkedIn outreach by fetching daily posts from a Notion database, formatting them with OpenAI for LinkedIn engagement, and then posting them to LinkedIn.</td></tr><tr><td>Notion AI Assistant Generator</td><td>Generates a custom AI Assistant chatbot workflow for a specific Notion database schema, allowing users to chat with their Notion data.</td></tr><tr><td>Notion knowledge base AI assistant</td><td>Creates an AI assistant that can search and retrieve information from a Notion knowledge base, providing answers to user queries.</td></tr><tr><td>Notion to Pinecone Vector Store Integration</td><td>Integrates Notion with Pinecone, allowing Notion pages to be converted into vector embeddings and stored in Pinecone for advanced search and retrieval.</td></tr><tr><td>Store Notionâ€™s Pages as Vector Documents into Supabase with OpenAI</td><td>Automates storing Notion pages as vector documents in a Supabase database, using OpenAI to generate embeddings for the content.</td></tr><tr><td>Turn Emails into AI-Enhanced Tasks in Notion (Multi-User Support) with Gmail, Airtable and Softr</td><td>Transforms emails into AI-enhanced tasks in Notion, supporting multiple users. It integrates with Gmail for email triggers, Airtable for routing, and Softr for a user interface.</td></tr><tr><td>Upsert huge documents in a vector store with Supabase and Notion</td><td>Manages large documents by splitting them into chunks, generating embeddings, and upserting them into a Supabase vector store, with Notion serving as the document source.</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>AI-Powered Information Monitoring with OpenAI, Google Sheets, Jina AI and Slack</td><td>Monitors RSS feeds, summarizes articles with OpenAI and Jina AI, classifies them, and sends formatted notifications to Slack, enabling AI-powered information monitoring.</td></tr><tr><td>Creating a AI Slack Bot with Google Gemini</td><td>Builds an AI Slack bot using Google Gemini, handling webhooks, integrating an AI agent, managing memory, and responding to Slack messages.</td></tr><tr><td>Customer Support Channel and Ticketing System with Slack and Linear</td><td>Automates customer support by querying Slack for messages with a ticket emoji, deciding if a new Linear ticket is needed, creating or updating tickets, and notifying Slack.</td></tr><tr><td>Enhance Security Operations with the Qualys Slack Shortcut Bot!</td><td>Creates a Slack shortcut bot for Qualys to enhance security operations, allowing users to trigger actions like creating reports or starting vulnerability scans directly from Slack.</td></tr><tr><td>Enrich Pipedrive's Organization Data with OpenAI GPT-4o &amp; Notify it in Slack</td><td>Enriches Pipedrive organization data by scraping website content, using OpenAI GPT-4o to generate a summary, and adding it as a note in Pipedrive, then notifying a Slack channel.</td></tr><tr><td>IT Ops AI SlackBot Workflow - Chat with your knowledge base</td><td>Creates an AI Slackbot for IT Operations, enabling users to chat with a knowledge base to retrieve information and get answers directly within Slack.</td></tr><tr><td>Sentiment Analysis Tracking on Support Issues with Linear and Slack</td><td>Tracks sentiment on support issues by integrating with Linear and Slack, performing sentiment analysis using OpenAI on Linear comments, and notifying relevant Slack channels.</td></tr><tr><td>Slack slash commands AI Chat Bot</td><td>Implements an AI chatbot accessible via Slack slash commands, processing user commands, interacting with an AI model, and responding within Slack.</td></tr><tr><td>Venafi Cloud Slack Cert Bot</td><td>Provides a Slack bot that interacts with Venafi Cloud for certificate management, allowing users to check certificate status, receive alerts, or request certificate actions via Slack.</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>Advanced AI Demo (Presented at AI Developers #14 meetup)</td><td>Advanced AI capabilities demo.</td></tr><tr><td>AI agent that can scrape webpages</td><td>AI agent for web scraping.</td></tr><tr><td>AI Crew to Automate Fundamental Stock Analysis - Q&amp;A Workflow</td><td>Stock analysis automation.</td></tr><tr><td>AI Customer feedback sentiment analysis</td><td>Sentiment analysis on customer feedback.</td><td>Customer Service/Marketing/Data Analysis</td></tr><tr><td>AI Data Extraction with Dynamic Prompts and Airtable</td><td>AI-driven data extraction with Airtable integration.</td><td>AI/Data Extraction/Database</td></tr><tr><td>AI Data Extraction with Dynamic Prompts and Baserow</td><td>AI-driven data extraction with Baserow integration.</td><td>AI/Data Extraction/Database</td></tr><tr><td>AI-Driven Lead Management and Inquiry Automation with ERPNext &amp; n8n</td><td>Lead management automation.</td></tr><tr><td>AI Fitness Coach Strava Data Analysis and Personalized Training Insights</td><td>Fitness coaching via Strava data analysis.</td></tr><tr><td>AI-Powered Candidate Shortlisting Automation for ERPNext</td><td>Candidate shortlisting automation.</td></tr><tr><td>AI-Powered Email Automation for Business: Summarize &amp; Respond with RAG</td><td>Email automation with summarization and response.</td><td>Business Automation/AI/Communication</td></tr><tr><td>AI-Powered RAG Workflow For Stock Earnings Report Analysis</td><td>Stock earnings report analysis with RAG.</td></tr><tr><td>AI-Powered Social Media Amplifier</td><td>Amplifies social media presence using AI.</td><td>Marketing/AI/Social Media</td></tr><tr><td>AI-powered WooCommerce Support-Agent</td><td>Creates an AI-powered support agent for WooCommerce stores.</td><td>E-commerce/AI/Customer Service</td></tr><tr><td>AI-Powered YouTube Video Summarization &amp; Analysis</td><td>Summarizes and analyzes YouTube videos using AI.</td><td>Content Creation/AI/Data Analysis</td></tr><tr><td>AI: Ask questions about any data source (using the n8n workflow retriever)</td><td>Allows users to ask questions about various data sources using an n8n workflow retriever.</td><td>AI/Data Analysis/Workflow Automation</td></tr><tr><td>AI: Summarize podcast episode and enhance using Wikipedia</td><td>Summarizes podcast episodes and enhances the summary with information from Wikipedia using AI.</td><td>Content Creation/AI/Data Analysis</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>Automate Sales Meeting Prep with AI &amp; APIFY Sent To WhatsApp</td><td>This workflow automates sales meeting preparation using AI and Apify, sending relevant information to WhatsApp.</td></tr><tr><td>Building Your First WhatsApp Chatbot</td><td>This workflow guides you through building your first WhatsApp chatbot.</td><td>Customer Service/Development</td></tr><tr><td>Complete business WhatsApp AI-Powered RAG Chatbot using OpenAI</td><td>This workflow builds a complete business WhatsApp AI-powered RAG chatbot using OpenAI.</td><td>Customer Service/AI/Development</td></tr><tr><td>Respond to WhatsApp Messages with AI Like a Pro!</td><td>This workflow enables professional AI-powered responses to WhatsApp messages.</td><td>Customer Service/AI/Communication</td></tr></tbody></table><h3>Instagram, Twitter, Social Media</h3><table><thead><tr></tr></thead><tbody><tr><td>AI agent for Instagram DM_inbox. Manychat + Open AI integration</td><td>Integrates Manychat with OpenAI to create an AI agent for managing Instagram direct messages.</td><td>Marketing/Customer Service/AI</td></tr><tr><td>Create dynamic Twitter profile banner</td><td>Automates the creation of dynamic Twitter profile banners.</td></tr><tr><td>Generate Instagram Content from Top Trends with AI Image Generation</td><td>Creates Instagram content by analyzing top trends and generating relevant images using AI.</td></tr><tr><td>OpenAI-powered tweet generator</td><td>Generates tweets using OpenAI's language models.</td><td>Marketing/Social Media/AI</td></tr><tr><td>Post New YouTube Videos to X</td><td>Automatically posts new YouTube videos to X (formerly Twitter).</td></tr><tr><td>Creates an AI-generated digest of Reddit content.</td></tr><tr><td>Social Media Analysis and Automated Email Generation</td><td>Analyzes social media data and generates automated email reports.</td></tr><tr><td>Speed Up Social Media Banners With BannerBear.com</td><td>Automates the creation of social media banners using BannerBear.com.</td></tr><tr><td>Twitter Virtual AI Influencer</td><td>Manages a virtual AI influencer's Twitter account.</td></tr><tr><td>Update Twitter banner using HTTP request</td><td>Updates a Twitter banner using HTTP requests.</td></tr></tbody></table><h3>Other Integrations &amp; Use Cases</h3><table><thead><tr></tr></thead><tbody><tr><td>Extracts API schemas from web services for documentation or integration purposes.</td></tr><tr><td>Analyze feedback and send a message on Mattermost</td><td>Analyzes user feedback and sends notifications to Mattermost channels.</td></tr><tr><td>Analyze feedback using AWS Comprehend</td><td>Performs sentiment analysis on feedback using AWS Comprehend and sends results to Mattermost.</td></tr><tr><td>Automate Pinterest Analysis &amp; AI-Powered Content Suggestions</td><td>Analyzes Pinterest data and provides AI-powered content suggestions.</td></tr><tr><td>Automate SIEM Alert Enrichment</td><td>Enriches SIEM alerts with MITRE ATT&amp;CK data and integrates with Zendesk.</td></tr><tr><td>Automate Screenshots with URLbox &amp; Analyze with AI</td><td>Takes screenshots of webpages and analyzes them using AI.</td></tr><tr><td>Automate testimonials in Strapi</td><td>Automates the process of collecting and managing testimonials in Strapi.</td></tr><tr><td>Bitrix24 Chatbot Application</td><td>Example workflow for creating a Bitrix24 chatbot with webhook integration.</td></tr><tr><td>ChatGPT Automatic Code Review in Gitlab MR</td><td>Automates code reviews in GitLab merge requests using ChatGPT.</td></tr><tr><td>Classify new bugs in Linear with OpenAI's GPT-4</td><td>Automatically classifies and routes new bug reports in Linear using AI.</td></tr><tr><td>Create, update, and get a profile in Humantic AI</td><td>Manages user profiles in Humantic AI platform.</td></tr><tr><td>Enhance Customer Chat with Twilio and Redis</td><td>Implements message buffering for customer chats using Twilio and Redis.</td></tr><tr><td>Hacker News Throwback Machine</td><td>Shows what was popular on Hacker News on this day in previous years.</td></tr><tr><td>Handling Appointment Leads with Twilio, Cal.com and AI</td><td>Manages appointment scheduling and follow-ups using Twilio and Cal.com.</td></tr><tr><td>Integrating AI with Open-Meteo API</td><td>Enhances weather forecasting with AI analysis.</td></tr><tr><td>Introduction to the HTTP Tool</td><td>Basic tutorial on using HTTP tools in n8n.</td></tr><tr><td>KB Tool - Confluence Knowledge Base</td><td>Integrates with Confluence for knowledge base management.</td></tr><tr><td>LINE Assistant with Google Calendar and Gmail</td><td>Creates a LINE assistant that integrates with Google Calendar and Gmail.</td><td>Productivity/Communication</td></tr><tr><td>Monthly Spotify Track Archiving</td><td>Archives and classifies monthly Spotify tracks into playlists.</td></tr><tr><td>Obsidian Notes Read Aloud</td><td>Converts Obsidian notes into audio format as a podcast feed.</td></tr><tr><td>Optimize &amp; Update Printify Title and Description</td><td>Automates optimization of Printify product titles and descriptions.</td></tr><tr><td>Qualify replies from Pipedrive persons with AI</td><td>Uses AI to qualify and categorize replies from Pipedrive contacts.</td></tr><tr><td>Siri AI Agent with Apple Shortcuts</td><td>Creates a Siri-powered AI agent using Apple Shortcuts.</td></tr><tr><td>Text automations using Apple Shortcuts</td><td>Implements text-based automations with Apple Shortcuts.</td></tr><tr><td>UTM Link Creator &amp; QR Code Generator</td><td>Creates UTM links, generates QR codes, and schedules Google Analytics reports.</td></tr><tr><td>Use AI to organize your Todoist Inbox</td><td>Automatically organizes tasks in Todoist using AI.</td></tr><tr><td>Using External Workflows as Tools in n8n</td><td>Demonstrates how to use external workflows as tools within n8n.</td></tr><tr><td>Visualize SQL Agent queries with OpenAI and Quickchart.io</td><td>Creates visualizations from SQL queries using OpenAI and Quickchart.io.</td><td>Data Analysis/Visualization</td></tr><tr><td>Zoom AI Meeting Assistant</td><td>Creates meeting summaries, ClickUp tasks, and schedules follow-ups from Zoom meetings.</td><td>Productivity/Communication</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>Conversational Interviews with AI Agents and n8n Forms</td><td>Implements AI-powered conversational interviews using n8n Forms for interactive data collection.</td></tr><tr><td>Email Subscription Service with n8n Forms, Airtable and AI</td><td>Manages email subscriptions with n8n Forms, stores data in Airtable, and uses AI for processing.</td></tr><tr><td>Qualifying Appointment Requests with AI &amp; n8n Forms</td><td>Uses AI to qualify and process appointment requests submitted through n8n Forms.</td></tr></tbody></table><h3>AI Research, RAG, and Data Analysis</h3><ul><li>ALL_unique_nodes.txt (node reference)</li></ul><p>If you would like to contribute additional templates or suggest new categories, feel free to open an issue or pull request!</p>","contentLength":27608,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"mfts/papermark","url":"https://github.com/mfts/papermark","date":1755570875,"author":"","guid":231869,"unread":true,"content":"<p>Papermark is the open-source DocSend alternative with built-in analytics and custom domains.</p><div align=\"center\"><h3>The open-source DocSend alternative.</h3></div><p>Papermark is the open-source document-sharing alternative to DocSend, featuring built-in analytics and custom domains.</p><ul><li> Share your documents securely by sending a custom link.</li><li> Add a custom domain and your own branding.</li><li> Gain insights through document tracking and soon page-by-page analytics.</li><li><strong>Self-hosted, Open-source:</strong> Host it yourself and customize it as needed.</li></ul><p>Here's what you need to run Papermark:</p><ul><li>Node.js (version &gt;= 18.17.0)</li></ul><pre><code>git clone https://github.com/mfts/papermark.git\ncd papermark\n</code></pre><h3>2. Install npm dependencies</h3><h3>3. Copy the environment variables to  and change the values</h3><h3>4. Initialize the database</h3><h3>6. Open the app in your browser</h3><p>To prepare the Tinybird database, follow these steps:</p><ol start=\"0\"><li>We use  to manage our Python dependencies. If you don't have it installed, you can install it using the following command: </li><li>Download the Tinybird CLI from <a href=\"https://www.tinybird.co/docs/cli.html\">here</a> and install it on your system.</li><li>After authenticating with the Tinybird CLI, navigate to the  directory: </li><li>Push the necessary data sources using the following command: <pre><code>tb push datasources/*\ntb push endpoints/get_*\n</code></pre></li><li>Don't forget to set the  with the appropriate rights in your  file.</li></ol><pre><code>pipenv shell\n## start: pkgx-specific\ncd ..\ncd papermark\n## end: pkgx-specific\npipenv update tinybird-cli\n</code></pre><p>Papermark is an open-source project, and we welcome contributions from the community.</p><p>If you'd like to contribute, please fork the repository and make any changes you'd like. Pull requests are warmly welcome.</p><a href=\"https://github.com/mfts/papermark/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=mfts/papermark\"></a>","contentLength":1558,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"bytebot-ai/bytebot","url":"https://github.com/bytebot-ai/bytebot","date":1755570875,"author":"","guid":231870,"unread":true,"content":"<p>Bytebot is a self-hosted AI desktop agent that automates computer tasks through natural language commands, operating within a containerized Linux desktop environment.</p><p>A desktop agent is an AI that has its own computer. Unlike browser-only agents or traditional RPA tools, Bytebot comes with a full virtual desktop where it can:</p><ul><li>Use any application (browsers, email clients, office tools, IDEs)</li><li>Download and organize files with its own file system</li><li>Log into websites and applications using password managers</li><li>Read and process documents, PDFs, and spreadsheets</li><li>Complete complex multi-step workflows across different programs</li></ul><p>Think of it as a virtual employee with their own computer who can see the screen, move the mouse, type on the keyboard, and complete tasks just like a human would.</p><h2>Why Give AI Its Own Computer?</h2><p>When AI has access to a complete desktop environment, it unlocks capabilities that aren't possible with browser-only agents or API integrations:</p><p>Give Bytebot a task like \"Download all invoices from our vendor portals and organize them by date\" and it will:</p><ul><li>Handle authentication (including 2FA via password managers)</li><li>Download the files to its local file system</li><li>Organize them into folders</li><li>Generate reports or summaries as needed</li></ul><p>Upload files directly to Bytebot's desktop and it can:</p><ul><li>Read entire PDFs into its context</li><li>Extract data from complex documents</li><li>Cross-reference information across multiple files</li><li>Create new documents based on analysis</li><li>Handle formats that APIs can't access</li></ul><p>Bytebot isn't limited to web interfaces. It can:</p><ul><li>Use desktop applications like text editors, VS Code, or email clients</li><li>Run scripts and command-line tools</li><li>Install new software as needed</li><li>Configure applications for specific workflows</li></ul><p>Just click and add your AI provider API key.</p><pre><code>git clone https://github.com/bytebot-ai/bytebot.git\ncd bytebot\n\n# Add your AI provider key (choose one)\necho \"ANTHROPIC_API_KEY=sk-ant-...\" &gt; docker/.env\n# Or: echo \"OPENAI_API_KEY=sk-...\" &gt; docker/.env\n# Or: echo \"GEMINI_API_KEY=...\" &gt; docker/.env\n\ndocker-compose -f docker/docker-compose.yml up -d\n\n# Open http://localhost:9992\n</code></pre><p>Bytebot consists of four integrated components:</p><ol><li>: A complete Ubuntu Linux environment with pre-installed applications</li><li>: Understands your tasks and controls the desktop to complete them</li><li>: Web UI where you create tasks and watch Bytebot work</li><li>: REST endpoints for programmatic task creation and desktop control</li></ol><ul><li>: Just describe what you need done</li><li>: Drop files onto tasks for Bytebot to process</li><li>: Watch Bytebot work in real-time</li><li>: Take control when you need to help or configure something</li><li>: Install 1Password, Bitwarden, etc. for automatic authentication</li><li>: Install programs and they stay available for future tasks</li></ul><pre><code>\"Go to Wikipedia and create a summary of quantum computing\"\n\"Research flights from NYC to London and create a comparison document\"\n\"Take screenshots of the top 5 news websites\"\n</code></pre><pre><code>\"Read the uploaded contracts.pdf and extract all payment terms and deadlines\"\n\"Process these 50 invoice PDFs and create a summary report\"\n\"Analyze this financial report and answer: What were the key risks mentioned?\"\n</code></pre><h3>Multi-Application Workflows</h3><pre><code>\"Download last month's bank statements from our three banks and consolidate them\"\n\"Check all our vendor portals for new invoices and create a summary report\"\n\"Log into our CRM, export the customer list, and update records in the ERP system\"\n</code></pre><pre><code>import requests\n\n# Simple task\nresponse = requests.post('http://localhost:9991/tasks', json={\n    'description': 'Download the latest sales report and create a summary'\n})\n\n# Task with file upload\nfiles = {'files': open('contracts.pdf', 'rb')}\nresponse = requests.post('http://localhost:9991/tasks',\n    data={'description': 'Review these contracts for important dates'},\n    files=files\n)\n</code></pre><pre><code># Take a screenshot\ncurl -X POST http://localhost:9990/computer-use \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"action\": \"screenshot\"}'\n\n# Click at specific coordinates\ncurl -X POST http://localhost:9990/computer-use \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"action\": \"click_mouse\", \"coordinate\": [500, 300]}'\n</code></pre><h2>Setting Up Your Desktop Agent</h2><p>Use one of the deployment methods above to get Bytebot running.</p><p>Use the Desktop tab in the UI to:</p><ul><li>Install additional programs you need</li><li>Set up password managers for authentication</li><li>Configure applications with your preferences</li><li>Log into websites you want Bytebot to access</li></ul><p>Create tasks in natural language and watch Bytebot complete them using the configured desktop.</p><h3>Business Process Automation</h3><ul><li>Invoice processing and data extraction</li><li>Multi-system data synchronization</li><li>Report generation from multiple sources</li><li>Compliance checking across platforms</li></ul><ul><li>Cross-browser compatibility checks</li><li>Documentation generation with screenshots</li><li>Code deployment verification</li></ul><ul><li>Competitive analysis across websites</li><li>Data gathering from multiple sources</li><li>Document analysis and summarization</li><li>Market research compilation</li></ul><ul><li>: Ubuntu 22.04 with XFCE, Firefox, VS Code, and other tools</li><li>: NestJS service that coordinates AI and desktop actions</li><li>: Next.js application for task management</li><li>: Works with Anthropic Claude, OpenAI GPT, Google Gemini</li><li>: Docker containers for easy self-hosting</li></ul><ul><li>: Everything runs on your infrastructure</li><li>: Customize the desktop environment as needed</li><li>: Use your own AI API keys without platform restrictions</li><li>: Install any software, access any systems</li></ul><ul></ul><p>Deploy on Kubernetes with Helm:</p><pre><code># Clone the repository\ngit clone https://github.com/bytebot-ai/bytebot.git\ncd bytebot\n\n# Install with Helm\nhelm install bytebot ./helm \\\n  --set agent.env.ANTHROPIC_API_KEY=sk-ant-...\n</code></pre><p>We welcome contributions! Whether it's:</p><ul><li>ğŸ“š Documentation improvements</li></ul><ol><li>Open an issue to discuss major changes</li><li>Submit PRs with clear descriptions</li></ol><p>Bytebot is open source under the Apache 2.0 license.</p><div align=\"center\"><p><strong>Give your AI its own computer. See what it can do.</strong></p></div>","contentLength":5740,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"immich-app/immich","url":"https://github.com/immich-app/immich","date":1755570875,"author":"","guid":231871,"unread":true,"content":"<p>High performance self-hosted photo and video management solution.</p><h3 align=\"center\">High performance self-hosted photo and video management solution</h3><a href=\"https://immich.app\"><img src=\"https://raw.githubusercontent.com/immich-app/immich/main/design/immich-screenshots.png\" title=\"Main Screenshot\"></a><ul><li>âš ï¸ The project is under  development.</li><li>âš ï¸ Expect bugs and breaking changes.</li><li>âš ï¸ <strong>Do not use the app as the only way to store your photos and videos.</strong></li><li>âš ï¸ Always follow <a href=\"https://www.backblaze.com/blog/the-3-2-1-backup-strategy/\">3-2-1</a> backup plan for your precious photos and videos!</li></ul><blockquote><p>[!NOTE] You can find the main documentation, including installation guides, at <a href=\"https://immich.app/\">https://immich.app/</a>.</p></blockquote><p>Access the demo <a href=\"https://demo.immich.app\">here</a>. For the mobile app, you can use  for the .</p><table><tbody><tr><td align=\"left\">Upload and view videos and photos</td></tr><tr><td align=\"left\">Auto backup when the app is opened</td></tr><tr><td align=\"left\">Prevent duplication of assets</td></tr><tr><td align=\"left\">Selective album(s) for backup</td></tr><tr><td align=\"left\">Download photos and videos to local device</td></tr><tr></tr><tr><td align=\"left\">Scrubbable/draggable scrollbar</td></tr><tr></tr><tr><td align=\"left\">Metadata view (EXIF, map)</td></tr><tr><td align=\"left\">Search by metadata, objects, faces, and CLIP</td></tr><tr><td align=\"left\">Administrative functions (user management)</td></tr><tr><td align=\"left\">LivePhoto/MotionPhoto backup and playback</td></tr><tr><td align=\"left\">Support 360 degree image display</td></tr><tr><td align=\"left\">User-defined storage structure</td></tr><tr></tr><tr><td align=\"left\">Facial recognition and clustering</td></tr><tr></tr></tbody></table><p>Read more about translations <a href=\"https://immich.app/docs/developer/translations\">here</a>.</p><a href=\"https://hosted.weblate.org/engage/immich/\"><img src=\"https://hosted.weblate.org/widget/immich/immich/multi-auto.svg?sanitize=true\" alt=\"Translation status\"></a><a href=\"https://star-history.com/#immich-app/immich&amp;Date\"></a><a href=\"https://github.com/alextran1502/immich/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=immich-app/immich\" width=\"100%\"></a>","contentLength":1000,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"rasbt/LLMs-from-scratch","url":"https://github.com/rasbt/LLMs-from-scratch","date":1755570875,"author":"","guid":231872,"unread":true,"content":"<p>Implement a ChatGPT-like LLM in PyTorch from scratch, step by step</p><p>In <a href=\"http://mng.bz/orYv\"><em>Build a Large Language Model (From Scratch)</em></a>, you'll learn and understand how large language models (LLMs) work from the inside out by coding them from the ground up, step by step. In this book, I'll guide you through creating your own LLM, explaining each stage with clear text, diagrams, and examples.</p><p>The method described in this book for training and developing your own small-but-functional model for educational purposes mirrors the approach used in creating large-scale foundational models such as those behind ChatGPT. In addition, this book includes code for loading the weights of larger pretrained models for finetuning.</p><p>To download a copy of this repository, click on the <a href=\"https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip\">Download ZIP</a> button or execute the following command in your terminal:</p><pre><code>git clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git\n</code></pre><p>Please note that this  file is a Markdown () file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven't installed a Markdown editor yet, <a href=\"https://ghostwriter.kde.org\">Ghostwriter</a> is a good free option.</p><blockquote><p> If you're seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the <a href=\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/README.md\">README.md</a> file located in the <a href=\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup\">setup</a> directory.</p></blockquote><p>The mental model below summarizes the contents covered in this book.</p><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg\" width=\"650px\"><p>The most important prerequisite is a strong foundation in Python programming. With this knowledge, you will be well prepared to explore the fascinating world of LLMs and understand the concepts and code examples presented in this book.</p><p>If you have some experience with deep neural networks, you may find certain concepts more familiar, as LLMs are built upon these architectures.</p><p>This book uses PyTorch to implement the code from scratch without using any external LLM libraries. While proficiency in PyTorch is not a prerequisite, familiarity with PyTorch basics is certainly useful. If you are new to PyTorch, Appendix A provides a concise introduction to PyTorch. Alternatively, you may find my book, <a href=\"https://sebastianraschka.com/teaching/pytorch-1h/\">PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs</a>, helpful for learning about the essentials.</p><p>The code in the main chapters of this book is designed to run on conventional laptops within a reasonable timeframe and does not require specialized hardware. This approach ensures that a wide audience can engage with the material. Additionally, the code automatically utilizes GPUs if they are available. (Please see the <a href=\"https://github.com/rasbt/LLMs-from-scratch/raw/main/setup/README.md\">setup</a> doc for additional recommendations.)</p><p><a href=\"https://www.manning.com/livevideo/master-and-build-large-language-models\">A 17-hour and 15-minute companion video course</a> where I code through each chapter of the book. The course is organized into chapters and sections that mirror the book's structure so that it can be used as a standalone alternative to the book or complementary code-along resource.</p><p>Each chapter of the book includes several exercises. The solutions are summarized in Appendix C, and the corresponding code notebooks are available in the main chapter folders of this repository (for example, <a href=\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb\">./ch02/01_main-chapter-code/exercise-solutions.ipynb</a>.</p><p>Several folders contain optional materials as a bonus for interested readers:</p><h2>Questions, Feedback, and Contributing to This Repository</h2><p>I welcome all sorts of feedback, best shared via the <a href=\"https://livebook.manning.com/forum?product=raschka&amp;page=1\">Manning Forum</a> or <a href=\"https://github.com/rasbt/LLMs-from-scratch/discussions\">GitHub Discussions</a>. Likewise, if you have any questions or just want to bounce ideas off others, please don't hesitate to post these in the forum as well.</p><p>Please note that since this repository contains the code corresponding to a print book, I currently cannot accept contributions that would extend the contents of the main chapter code, as it would introduce deviations from the physical book. Keeping it consistent helps ensure a smooth experience for everyone.</p><p>If you find this book or code useful for your research, please consider citing it.</p><blockquote><p>Raschka, Sebastian. <em>Build A Large Language Model (From Scratch)</em>. Manning, 2024. ISBN: 978-1633437166.</p></blockquote><pre><code>@book{build-llms-from-scratch-book,\n  author       = {Sebastian Raschka},\n  title        = {Build A Large Language Model (From Scratch)},\n  publisher    = {Manning},\n  year         = {2024},\n  isbn         = {978-1633437166},\n  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},\n  github       = {https://github.com/rasbt/LLMs-from-scratch}\n}\n</code></pre>","contentLength":4400,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"aliasrobotics/cai","url":"https://github.com/aliasrobotics/cai","date":1755488034,"author":"","guid":230762,"unread":true,"content":"<p>Cybersecurity AI (CAI), an open Bug Bounty-ready Artificial Intelligence</p><p>A lightweight, ergonomic framework for building bug bounty-ready Cybersecurity AIs (CAIs).</p><blockquote><p>[!WARNING]  CAI is in active development, so don't expect it to work flawlessly. Instead, contribute by raising an issue or <a href=\"https://github.com/aliasrobotics/cai/pulls\">sending a PR</a>.</p><p>Access to this library and the use of information, materials (or portions thereof), is <strong>, and is , where such access or use violates applicable laws or regulations</strong>. By no means the authors encourage or promote the unauthorized tampering with running systems. This can cause serious human harm and material damages.</p><p><em>By no means the authors of CAI encourage or promote the unauthorized tampering with compute systems. Please don't use the source code in here for cybercrime. </em>. By downloading, using, or modifying this source code, you agree to the terms of the <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/LICENSE\"></a> and the limitations outlined in the <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/DISCLAIMER\"></a> file.</p></blockquote><p>The cybersecurity landscape is undergoing a dramatic transformation as AI becomes increasingly integrated into security operations. <strong>We predict that by 2028, AI-powered security testing tools will outnumber human pentesters</strong>. This shift represents a fundamental change in how we approach cybersecurity challenges. <em>AI is not just another tool - it's becoming essential for addressing complex security vulnerabilities and staying ahead of sophisticated threats. As organizations face more advanced cyber attacks, AI-enhanced security testing will be crucial for maintaining robust defenses.</em></p><p>This work builds upon prior efforts[^4] and similarly, we believe that democratizing access to advanced cybersecurity AI tools is vital for the entire security community. That's why we're releasing Cybersecurity AI () as an open source framework. Our goal is to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools. By making these capabilities openly available, we aim to level the playing field and ensure that cutting-edge security AI technology isn't limited to well-funded private companies or state actors.</p><p>Bug Bounty programs have become a cornerstone of modern cybersecurity, providing a crucial mechanism for organizations to identify and fix vulnerabilities in their systems before they can be exploited. These programs have proven highly effective at securing both public and private infrastructure, with researchers discovering critical vulnerabilities that might have otherwise gone unnoticed. CAI is specifically designed to enhance these efforts by providing a lightweight, ergonomic framework for building specialized AI agents that can assist in various aspects of Bug Bounty hunting - from initial reconnaissance to vulnerability validation and reporting. Our framework aims to augment human expertise with AI capabilities, helping researchers work more efficiently and thoroughly in their quest to make digital systems more secure.</p><h3>Ethical principles behind CAI</h3><p>You might be wondering if releasing CAI  given its capabilities and security implications is ethical. Our decision to open-source this framework is guided by two core ethical principles:</p><ol><li><p><strong>Democratizing Cybersecurity AI</strong>: We believe that advanced cybersecurity AI tools should be accessible to the entire security community, not just well-funded private companies or state actors. By releasing CAI as an open source framework, we aim to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools, leveling the playing field in cybersecurity.</p></li><li><p><strong>Transparency in AI Security Capabilities</strong>: Based on our research results, understanding of the technology, and dissection of top technical reports, we argue that current LLM vendors are undermining their cybersecurity capabilities. This is extremely dangerous and misleading. By developing CAI openly, we provide a transparent benchmark of what AI systems can actually do in cybersecurity contexts, enabling more informed decisions about security postures.</p></li></ol><p>CAI is built on the following core principles:</p><ul><li><strong>Cybersecurity oriented AI framework</strong>: CAI is specifically designed for cybersecurity use cases, aiming at semi- and fully-automating offensive and defensive security tasks.</li><li><strong>Open source, free for research</strong>: CAI is open source and free for research purposes. We aim at democratizing access to AI and Cybersecurity. For professional or commercial use, including on-premise deployments, dedicated technical support and custom extensions <a href=\"mailto:research@aliasrobotics.com\">reach out</a> to obtain a license.</li><li>: CAI is designed to be fast, and easy to use.</li><li><strong>Modular and agent-centric design</strong>: CAI operates on the basis of agents and agentic patterns, which allows flexibility and scalability. You can easily add the most suitable agents and pattern for your cybersecuritytarget case.</li><li>: CAI integrates already built-in tools, and allows the user to integrate their own tools with their own logic easily.</li><li><strong>Logging and tracing integrated</strong>: using <a href=\"https://github.com/Arize-ai/phoenix\"></a>, the open source tracing and logging tool for LLMs. This provides the user with a detailed traceability of the agents and their execution.</li><li>: more than 300 supported and empowered by <a href=\"https://github.com/BerriAI/litellm\">LiteLLM</a>. The most popular providers: \n  <ul><li>: , , , </li><li>: , , , , </li><li>: , </li><li>: , , etc</li></ul></li></ul><h3>Closed-source alternatives</h3><p>Cybersecurity AI is a critical field, yet many groups are misguidedly pursuing it through closed-source methods for pure economic return, leveraging similar techniques and building upon existing closed-source () models. This approach not only squanders valuable engineering resources but also represents an economic waste and results in redundant efforts, as they often end up reinventing the wheel. Here are some of the closed-source initiatives we keep track of and attempting to leverage genAI and agentic frameworks in cybersecurity AI:</p><pre><code>pip install cai-framework\n</code></pre><p>Always create a new virtual environment to ensure proper dependency installation when updating CAI.</p><p>The following subsections provide a more detailed walkthrough on selected popular Operating Systems. Refer to the <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/#development\">Development</a> section for developer-related install instructions.</p><pre><code>brew update &amp;&amp; \\\n    brew install git python@3.12\n\n# Create virtual environment\npython3.12 -m venv cai_env\n\n# Install the package from the local directory\nsource cai_env/bin/activate &amp;&amp; pip install cai-framework\n\n# Generate a .env file and set up with defaults\necho -e 'OPENAI_API_KEY=\"sk-1234\"\\nANTHROPIC_API_KEY=\"\"\\nOLLAMA=\"\"\\nPROMPT_TOOLKIT_NO_CPR=1\\nCAI_STREAM=false' &gt; .env\n\n# Launch CAI\ncai  # first launch it can take up to 30 seconds\n</code></pre><pre><code>sudo apt-get update &amp;&amp; \\\n    sudo apt-get install -y git python3-pip python3.12-venv\n\n# Create the virtual environment\npython3.12 -m venv cai_env\n\n# Install the package from the local directory\nsource cai_env/bin/activate &amp;&amp; pip install cai-framework\n\n# Generate a .env file and set up with defaults\necho -e 'OPENAI_API_KEY=\"sk-1234\"\\nANTHROPIC_API_KEY=\"\"\\nOLLAMA=\"\"\\nPROMPT_TOOLKIT_NO_CPR=1\\nCAI_STREAM=false' &gt; .env\n\n# Launch CAI\ncai  # first launch it can take up to 30 seconds\n</code></pre><pre><code>sudo apt-get update &amp;&amp; \\\n    sudo apt-get install -y software-properties-common\n\n# Fetch Python 3.12\nsudo add-apt-repository ppa:deadsnakes/ppa &amp;&amp; sudo apt update\nsudo apt install python3.12 python3.12-venv python3.12-dev -y\n\n# Create the virtual environment\npython3.12 -m venv cai_env\n\n# Install the package from the local directory\nsource cai_env/bin/activate &amp;&amp; pip install cai-framework\n\n# Generate a .env file and set up with defaults\necho -e 'OPENAI_API_KEY=\"sk-1234\"\\nANTHROPIC_API_KEY=\"\"\\nOLLAMA=\"\"\\nPROMPT_TOOLKIT_NO_CPR=1\\nCAI_STREAM=false' &gt; .env\n\n# Launch CAI\ncai  # first launch it can take up to 30 seconds\n</code></pre><p>From Powershell write: wsl --install</p><pre><code>\nsudo apt-get update &amp;&amp; \\\n    sudo apt-get install -y git python3-pip python3-venv\n\n# Create the virtual environment\npython3 -m venv cai_env\n\n# Install the package from the local directory\nsource cai_env/bin/activate &amp;&amp; pip install cai-framework\n\n# Generate a .env file and set up with defaults\necho -e 'OPENAI_API_KEY=\"sk-1234\"\\nANTHROPIC_API_KEY=\"\"\\nOLLAMA=\"\"\\nPROMPT_TOOLKIT_NO_CPR=1\\nCAI_STREAM=false' &gt; .env\n\n# Launch CAI\ncai  # first launch it can take up to 30 seconds\n</code></pre><p>We recommend having at least 8 GB of RAM:</p><pre><code># Get new apt keys\nwget http://http.kali.org/kali/pool/main/k/kali-archive-keyring/kali-archive-keyring_2024.1_all.deb\n\n# Install new apt keys\nsudo dpkg -i kali-archive-keyring_2024.1_all.deb &amp;&amp; rm kali-archive-keyring_2024.1_all.deb\n\n# Update APT repository\nsudo apt-get update\n\n# CAI requieres python 3.12, lets install it (CAI for kali in Android)\nsudo apt-get update &amp;&amp; sudo apt-get install -y git python3-pip build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev pkg-config\nwget https://www.python.org/ftp/python/3.12.4/Python-3.12.4.tar.xz\ntar xf Python-3.12.4.tar.xz\ncd ./configure --enable-optimizations\nsudo make altinstall # This command takes long to execute\n\n# Clone CAI's source code\ngit clone https://github.com/aliasrobotics/cai &amp;&amp; cd cai\n\n# Create virtual environment\npython3.12 -m venv cai_env\n\n# Install the package from the local directory\nsource cai_env/bin/activate &amp;&amp; pip3 install -e .\n\n# Generate a .env file and set up\ncp .env.example .env  # edit here your keys/models\n\n# Launch CAI\ncai\n</code></pre><p>CAI leverages the  file to load configuration at launch. To facilitate the setup, the repo provides an exemplary <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/.env.example\"></a> file provides a template for configuring CAI's setup and your LLM API keys to work with desired LLM models.</p><p>CAI does NOT provide API keys for any model by default. Don't ask us to provide keys, use your own or host your own models.</p><p>If you are using alias0 model, make sure that CAI is &gt;0.4.0 version and here you have an .env example to be able to use it.</p><pre><code>OPENAI_API_KEY=\"sk-1234\"\nOLLAMA=\"\"\nALIAS_API_KEY=\"&lt;sk-your-key&gt;\"  # note, add yours\nCAI_STEAM=False\n</code></pre><h3>ğŸ”¹ Custom OpenAI Base URL Support</h3><p>CAI supports configuring a custom OpenAI API base URL via the  environment variable. This allows users to redirect API calls to a custom endpoint, such as a proxy or self-hosted OpenAI-compatible service.</p><p>Example  entry configuration:</p><pre><code>OLLAMA_API_BASE=\"https://custom-openai-proxy.com/v1\"\n</code></pre><p>Or directly from the command line:</p><pre><code>OLLAMA_API_BASE=\"https://custom-openai-proxy.com/v1\" cai\n</code></pre><p>CAI focuses on making cybersecurity agent  and  lightweight, highly controllable, and useful for humans. To do so it builds upon 7 pillars: s, , , , ,  and .</p><pre><code>                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                  â”‚      HITL     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Turns   â”‚\n                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                          â”‚\n                          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Patterns â”‚â—€â”€â”€â”€â”€â”€â–¶â”‚  Handoffs â”‚â—€â”€â”€â”€â”€â–¶ â”‚   Agents  â”‚â—€â”€â”€â”€â”€â–¶â”‚    LLMs   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                          â”‚                   â”‚\n                          â”‚                   â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Extensions â”‚â—€â”€â”€â”€â”€â”€â–¶â”‚  Tracing  â”‚       â”‚   Tools   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                              â”‚\n                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                          â–¼             â–¼          â–¼             â–¼\n                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                    â”‚ LinuxCmd  â”‚â”‚ WebSearch â”‚â”‚    Code    â”‚â”‚ SSHTunnel â”‚\n                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</code></pre><p>If you want to dive deeper into the code, check the following files as a start point for using CAI:</p><ul><li><a href=\"https://github.com/aliasrobotics/cai/raw/main/src/cai/cli.py\">cli.py</a> - entrypoint for command line interface</li><li><a href=\"https://github.com/aliasrobotics/cai/raw/main/src/cai/internal\">internal</a> - CAI internal functions (endpoints, metrics, logging, etc.)</li><li><a href=\"https://github.com/aliasrobotics/cai/raw/main/src/cai/repl\">repl</a> - CLI aesthetics and commands</li></ul><p>At its core, CAI abstracts its cybersecurity behavior via  and agentic . An Agent in <em>an intelligent system that interacts with some environment</em>. More technically, within CAI we embrace a robotics-centric definition wherein an agent is anything that can be viewed as a system perceiving its environment through sensors, reasoning about its goals and and acting accordingly upon that environment through actuators ( from Russel &amp; Norvig, AI: A Modern Approach). In cybersecurity, an  interacts with systems and networks, using peripherals and network interfaces as sensors, reasons accordingly and then executes network actions as if actuators. Correspondingly, in CAI, s implement the  (Reasoning and Action) agent model[^3]. For more information, see the <a href=\"https://github.com/aliasrobotics/cai/raw/main/examples/basic/hello_world.py\">example here</a> for the full execution code, and refer to this <a href=\"https://github.com/aliasrobotics/cai/raw/main/fluency/my-first-hack/my_first_hack.ipynb\">jupyter notebook</a> for a tutorial on how to use it.</p><pre><code>from cai.sdk.agents import Agent, Runner, OpenAIChatCompletionsModel\n\nimport os\nfrom openai import AsyncOpenAI\nfrom dotenv import load_dotenv\nload_dotenv()\n\nagent = Agent(\n      name=\"Custom Agent\",\n      instructions=\"\"\"You are a Cybersecurity expert Leader\"\"\",\n      model=OpenAIChatCompletionsModel(\n          model=os.getenv('CAI_MODEL', \"openai/gpt-4o\"),\n          openai_client=AsyncOpenAI(),\n          )\n      )\n\nmessage = \"Tell me about recursion in programming.\"\nresult = await Runner.run(agent, message)\n</code></pre><p> let cybersecurity agents take actions by providing interfaces to execute system commands, run security scans, analyze vulnerabilities, and interact with target systems and APIs - they are the core capabilities that enable CAI agents to perform security tasks effectively; in CAI, tools include built-in cybersecurity utilities (like LinuxCmd for command execution, WebSearch for OSINT gathering, Code for dynamic script execution, and SSHTunnel for secure remote access), function calling mechanisms that allow integration of any Python function as a security tool, and agent-as-tool functionality that enables specialized security agents (such as reconnaissance or exploit agents) to be used by other agents, creating powerful collaborative security workflows without requiring formal handoffs between agents. For more information, please refer to the <a href=\"https://github.com/aliasrobotics/cai/raw/main/examples/basic/tools.py\">example here</a> for the complete configuration of custom functions.</p><pre><code>from cai.sdk.agents import Agent, Runner, OpenAIChatCompletionsModel\nfrom cai.tools.reconnaissance.exec_code import execute_code\nfrom cai.tools.reconnaissance.generic_linux_command import generic_linux_command\n\nimport os\nfrom openai import AsyncOpenAI\nfrom dotenv import load_dotenv\nload_dotenv()\n\nagent = Agent(\n      name=\"Custom Agent\",\n      instructions=\"\"\"You are a Cybersecurity expert Leader\"\"\",\n      tools= [\n        generic_linux_command,\n        execute_code\n      ],\n      model=OpenAIChatCompletionsModel(\n          model=os.getenv('CAI_MODEL', \"openai/gpt-4o\"),\n          openai_client=AsyncOpenAI(),\n          )\n      )\n\nmessage = \"Tell me about recursion in programming.\"\nresult = await Runner.run(agent, message)\n</code></pre><p>You may find different <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/tools\">tools</a>. They are grouped in 6 major categories inspired by the security kill chain [^2]:</p><ol><li>Reconnaissance and weaponization -  (crypto, listing, etc)</li><li>Exploitation - </li><li>Privilege escalation - </li><li>Lateral movement - </li><li>Data exfiltration - </li><li>Command and control - </li></ol><p> allow an  to delegate tasks to another agent, which is crucial in cybersecurity operations where specialized expertise is needed for different phases of an engagement. In our framework,  are implemented as tools for the LLM, where a <strong>handoff/transfer function</strong> like <code>transfer_to_flag_discriminator</code> enables the  to pass control to the  once it believes it has found the flag. This creates a security validation chain where the first agent handles exploitation and flag discovery, while the second agent specializes in flag verification, ensuring proper segregation of duties and leveraging specialized capabilities of different models for distinct security tasks. For more information, please refer to the <a href=\"https://github.com/aliasrobotics/cai/raw/main/examples/cai/agent_patterns/handoffs.py\">example here</a> for the full execution code.</p><pre><code>from cai.sdk.agents import function_tool\nfrom cai.tools.common import run_command\nfrom cai.sdk.agents import Agent, OpenAIChatCompletionsModel, HandoffInputData, Runner, function_tool, handoff, trace\nfrom cai.sdk.agents.extensions import handoff_filters\n\nimport os\nfrom openai import AsyncOpenAI\nfrom dotenv import load_dotenv\nload_dotenv()\n\n@function_tool\ndef execute_cli_command(command: str) -&gt; str:\n    return run_command(command)\n\nflag_discriminator = Agent(\n    name=\"Flag discriminator\",\n    description=\"Agent focused on extracting the flag from the output\",\n    instructions=\"You are an agent tailored to extract the flag from a given output.\",\n    model=OpenAIChatCompletionsModel(\n        model=os.getenv('CAI_MODEL', \"qwen2.5:14b\"),\n        openai_client=AsyncOpenAI(),\n    ) \n)\n\nctf_agent = Agent(\n    name=\"CTF agent\",\n    description=\"Agent focused on conquering security challenges\",\n    instructions=\"You are a Cybersecurity expert Leader facing a CTF\",\n    tools=[\n        execute_cli_command,\n    ],\n    model=OpenAIChatCompletionsModel(\n        model= os.getenv('CAI_MODEL', \"qwen2.5:14b\"),\n        openai_client=AsyncOpenAI(),\n    ), \n    handoffs = [flag_discriminator]\n)\n</code></pre><p>An agentic  is a <em>structured design paradigm</em> in artificial intelligence systems where autonomous or semi-autonomous agents operate within a defined  (the pattern) to achieve a goal. These  specify the organization, coordination, and communication methods among agents, guiding decision-making, task execution, and delegation.</p><p>An agentic pattern () can be formally defined as a tuple:</p><p>\\[ AP = (A, H, D, C, E) \\]</p><ul><li> A set of autonomous entities, \\( A = \\{a_1, a_2, ..., a_n\\} \\), each with defined roles, capabilities, and internal states.</li><li> A function \\( H: A \\times T \\to A \\) that governs how tasks \\( T \\) are transferred between agents based on predefined logic (e.g., rules, negotiation, bidding).</li><li><strong>\\(D\\) (Decision Mechanism):</strong> A decision function \\( D: S \\to A \\) where \\( S \\) represents system states, and \\( D \\) determines which agent takes action at any given time.</li><li><strong>\\(C\\) (Communication Protocol):</strong> A messaging function \\( C: A \\times A \\to M \\), where \\( M \\) is a message space, defining how agents share information.</li><li> A function \\( E: A \\times I \\to O \\) where \\( I \\) is the input space and \\( O \\) is the output space, defining how agents perform tasks.</li></ul><p>When building , we generall y classify them among one of the following categories, though others exist:</p><table><thead><tr></tr></thead><tbody><tr><td>Agents share tasks and self-assign responsibilities without a central orchestrator. Handoffs occur dynamically. <em>An example of a peer-to-peer agentic pattern is the , which involves a team of agents working together to solve a CTF challenge with dynamic handoffs.</em></td></tr><tr><td>A top-level agent (e.g., \"PlannerAgent\") assigns tasks via structured handoffs to specialized sub-agents. Alternatively, the structure of the agents is harcoded into the agentic pattern with pre-defined handoffs.</td></tr><tr><td> (Sequential Workflow)</td><td>A structured pipeline where Agent A produces an output, hands it to Agent B for reuse or refinement, and so on. Handoffs follow a linear sequence. <em>An example of a chain-of-thought agentic pattern is the , which involves a Reasoning-type LLM that provides context to the main agent to solve a CTF challenge with a linear sequence.</em>[^1]</td></tr><tr><td> (Competitive Allocation)</td><td>Agents \"bid\" on tasks based on priority, capability, or cost. A decision agent evaluates bids and hands off tasks to the best-fit agent.</td></tr><tr><td>A single agent continuously refines its own output, treating itself as both executor and evaluator, with handoffs (internal or external) to itself. <em>An example of a recursive agentic pattern is the  (when used as a recursive agent), which continuously refines its own output by executing code and updating its own instructions.</em></td></tr></tbody></table><p>For more information and examples of common agentic patterns, see the <a href=\"https://github.com/aliasrobotics/cai/raw/main/examples/agent_patterns/README.md\">examples folder</a>.</p><p>During the agentic flow (conversation), we distinguish between  and .</p><ul><li> are sequential exchanges between one or multiple agents. Each agent executing its logic corresponds with one . Since an  in CAI generally implements the  agent model[^3], each  consists of 1) a reasoning step via an LLM inference and 2) act by calling zero-to-n . This is defined in in <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py\">core.py</a>.</li><li>: A turn represents a cycle of one ore more  which finishes when the  (or ) executing returns , judging there're no further actions to undertake. This is defined in , see <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py\">core.py</a>.</li></ul><blockquote><p>[!NOTE] CAI Agents are not related to Assistants in the Assistants API. They are named similarly for convenience, but are otherwise completely unrelated. CAI is entirely powered by the Chat Completions API and is hence stateless between calls.</p></blockquote><p>CAI implements AI observability by adopting the OpenTelemetry standard and to do so, it leverages <a href=\"https://github.com/Arize-ai/phoenix\">Phoenix</a> which provides comprehensive tracing capabilities through OpenTelemetry-based instrumentation, allowing you to monitor and analyze your security operations in real-time. This integration enables detailed visibility into agent interactions, tool usage, and attack vectors throughout penetration testing workflows, making it easier to debug complex exploitation chains, track vulnerability discovery processes, and optimize agent performance for more effective security assessments.</p><h3>ğŸ”¹ Human-In-The-Loop (HITL)</h3><pre><code>                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                      â”‚                                 â”‚\n                      â”‚      Cybersecurity AI (CAI)     â”‚\n                      â”‚                                 â”‚\n                      â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\n                      â”‚       â”‚  Autonomous AI  â”‚       â”‚\n                      â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\n                      â”‚                â”‚                â”‚\n                      â”‚                â”‚                â”‚\n                      â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n                      â”‚       â”‚ HITL Interaction â”‚      â”‚\n                      â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n                      â”‚                â”‚                â”‚\n                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                       â”‚\n                                       â”‚ Ctrl+C (cli.py)\n                                       â”‚\n                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                           â”‚   Human Operator(s)   â”‚\n                           â”‚  Expertise | Judgment â”‚\n                           â”‚    Teleoperation      â”‚\n                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</code></pre><p>CAI delivers a framework for building Cybersecurity AIs with a strong emphasis on  operation, as the reality is that  cybersecurity systems remain premature and face significant challenges when tackling complex tasks. While CAI explores autonomous capabilities, we recognize that effective security operations still require human teleoperation providing expertise, judgment, and oversight in the security process.</p><p>Accordingly, the Human-In-The-Loop () module is a core design principle of CAI, acknowledging that human intervention and teleoperation are essential components of responsible security testing. Through the  interface, users can seamlessly interact with agents at any point during execution by simply pressing . This is implemented across <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py\">core.py</a> and also in the REPL abstractions <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl\">REPL</a>.</p><p>To start CAI after installing it, just type  in the CLI:</p><pre><code>â””â”€# cai\n\n          CCCCCCCCCCCCC      ++++++++   ++++++++      IIIIIIIIII\n       CCC::::::::::::C  ++++++++++       ++++++++++  I::::::::I\n     CC:::::::::::::::C ++++++++++         ++++++++++ I::::::::I\n    C:::::CCCCCCCC::::C +++++++++    ++     +++++++++ II::::::II\n   C:::::C       CCCCCC +++++++     +++++     +++++++   I::::I\n  C:::::C                +++++     +++++++     +++++    I::::I\n  C:::::C                ++++                   ++++    I::::I\n  C:::::C                 ++                     ++     I::::I\n  C:::::C                  +   +++++++++++++++   +      I::::I\n  C:::::C                    +++++++++++++++++++        I::::I\n  C:::::C                     +++++++++++++++++         I::::I\n   C:::::C       CCCCCC        +++++++++++++++          I::::I\n    C:::::CCCCCCCC::::C         +++++++++++++         II::::::II\n     CC:::::::::::::::C           +++++++++           I::::::::I\n       CCC::::::::::::C             +++++             I::::::::I\n          CCCCCCCCCCCCC               ++              IIIIIIIIII\n\n                      Cybersecurity AI (CAI), vX.Y.Z\n                          Bug bounty-ready AI\n\nCAI&gt;\n</code></pre><p>That should initialize CAI and provide a prompt to execute any security task you want to perform. The navigation bar at the bottom displays important system information. This information helps you understand your environment while working with CAI.</p><p>Here's a quick <a href=\"https://asciinema.org/a/zm7wS5DA2o0S9pu1Tb44pnlvy\">demo video</a> to help you get started with CAI. We'll walk through the basic steps â€” from launching the tool to running your first AI-powered task in the terminal. Whether you're a beginner or just curious, this guide will show you how easy it is to begin using CAI.</p><p>From here on, type on  and start your security exercise. Best way to learn is by example:</p><p>For using private models, you are given a <a href=\"https://raw.githubusercontent.com/aliasrobotics/cai/main/.env.example\"></a> file. Copy it and rename it as . Fill in your corresponding API keys, and you are ready to use CAI.</p><p>The Cybersecurity AI (CAI) platform offers seamless integration with OpenRouter, a unified interface for Large Language Models (LLMs). This integration is crucial for users who wish to leverage advanced AI capabilities in their cybersecurity tasks. OpenRouter acts as a bridge, allowing CAI to communicate with various LLMs, thereby enhancing the flexibility and power of the AI agents used within CAI.</p><p>To enable OpenRouter support in CAI, you need to configure your environment by adding specific entries to your  file. This setup ensures that CAI can interact with the OpenRouter API, facilitating the use of sophisticated models like Meta-LLaMA. Hereâ€™s how you can configure it:</p><pre><code>CAI_AGENT_TYPE=redteam_agent\nCAI_MODEL=openrouter/meta-llama/llama-4-maverick\nOPENROUTER_API_KEY=&lt;sk-your-key&gt;  # note, add yours\nOPENROUTER_API_BASE=https://openrouter.ai/api/v1\n</code></pre><p>CAI supports the Model Context Protocol (MCP) for integrating external tools and services with AI agents. MCP is supported via two transport mechanisms:</p><ol><li> - For web-based servers that push updates over HTTP connections:</li></ol><pre><code>CAI&gt;/mcp load http://localhost:9876/sse burp\n</code></pre><ol start=\"2\"><li><strong>STDIO (Standard Input/Output)</strong> - For local inter-process communication:</li></ol><pre><code>CAI&gt;/mcp load stdio myserver python mcp_server.py\n</code></pre><p>Once connected, you can add the MCP tools to any agent:</p><pre><code>CAI&gt;/mcp add burp redteam_agent\nAdding tools from MCP server 'burp' to agent 'Red Team Agent'...\n                                 Adding tools to Red Team Agent\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ Tool                              â”ƒ Status â”ƒ Details                                         â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ send_http_request                 â”‚ Added  â”‚ Available as: send_http_request                 â”‚\nâ”‚ create_repeater_tab               â”‚ Added  â”‚ Available as: create_repeater_tab               â”‚\nâ”‚ send_to_intruder                  â”‚ Added  â”‚ Available as: send_to_intruder                  â”‚\nâ”‚ url_encode                        â”‚ Added  â”‚ Available as: url_encode                        â”‚\nâ”‚ url_decode                        â”‚ Added  â”‚ Available as: url_decode                        â”‚\nâ”‚ base64encode                      â”‚ Added  â”‚ Available as: base64encode                      â”‚\nâ”‚ base64decode                      â”‚ Added  â”‚ Available as: base64decode                      â”‚\nâ”‚ generate_random_string            â”‚ Added  â”‚ Available as: generate_random_string            â”‚\nâ”‚ output_project_options            â”‚ Added  â”‚ Available as: output_project_options            â”‚\nâ”‚ output_user_options               â”‚ Added  â”‚ Available as: output_user_options               â”‚\nâ”‚ set_project_options               â”‚ Added  â”‚ Available as: set_project_options               â”‚\nâ”‚ set_user_options                  â”‚ Added  â”‚ Available as: set_user_options                  â”‚\nâ”‚ get_proxy_http_history            â”‚ Added  â”‚ Available as: get_proxy_http_history            â”‚\nâ”‚ get_proxy_http_history_regex      â”‚ Added  â”‚ Available as: get_proxy_http_history_regex      â”‚\nâ”‚ get_proxy_websocket_history       â”‚ Added  â”‚ Available as: get_proxy_websocket_history       â”‚\nâ”‚ get_proxy_websocket_history_regex â”‚ Added  â”‚ Available as: get_proxy_websocket_history_regex â”‚\nâ”‚ set_task_execution_engine_state   â”‚ Added  â”‚ Available as: set_task_execution_engine_state   â”‚\nâ”‚ set_proxy_intercept_state         â”‚ Added  â”‚ Available as: set_proxy_intercept_state         â”‚\nâ”‚ get_active_editor_contents        â”‚ Added  â”‚ Available as: get_active_editor_contents        â”‚\nâ”‚ set_active_editor_contents        â”‚ Added  â”‚ Available as: set_active_editor_contents        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nAdded 20 tools from server 'burp' to agent 'Red Team Agent'.\nCAI&gt;/agent 13\nCAI&gt;Create a repeater tab\n</code></pre><p>You can list all active MCP connections and their transport types:</p><p>Development is facilitated via VS Code dev. environments. To try out our development environment, clone the repository, open VS Code and enter de dev. container mode:</p><p>If you want to contribute to this project, use <a href=\"https://pre-commit.com/\"></a> before your MR</p><pre><code>pip install pre-commit\npre-commit # files staged\npre-commit run --all-files # all files\n</code></pre><h3>Optional Requirements: caiextensions</h3><p>Currently, the extensions are not publicly available as the engineering endeavour to maintain them is significant. Instead, we're making selected custom caiextensions available for partner companies across collaborations.</p><p>CAI is provided free of charge for researchers. To improve CAIâ€™s detection accuracy and publish open security research, instead of payment for research use cases, we ask you to contribute to the CAI community by allowing usage data collection. This data helps us identify areas for improvement, understand how the framework is being used, and prioritize new features. Legal basis of data collection is under Art. 6 (1)(f) GDPR â€” CAIâ€™s legitimate interest in maintaining and improving security tooling, with Art. 89 safeguards for research. The collected data includes:</p><ul><li>Basic system information (OS type, Python version)</li><li>Username and IP information</li><li>Tool usage patterns and performance metrics</li><li>Model interactions and token usage statistics</li></ul><p>We take your privacy seriously and only collect what's needed to make CAI better. For further info, reach out to researchï¼ aliasrobotics.com. You can disable some of the data collection features via the  environment variable but we encourage you to keep it enabled and contribute back to research:</p><h3>Reproduce CI-Setup locally</h3><p>To simulate the CI/CD pipeline, you can run the following in the Gitlab runner machines:</p><pre><code>docker run --rm -it \\\n  --privileged \\\n  --network=exploitflow_net \\\n  --add-host=\"host.docker.internal:host-gateway\" \\\n  -v /cache:/cache \\\n  -v /var/run/docker.sock:/var/run/docker.sock:rw \\\n  registry.gitlab.com/aliasrobotics/alias_research/cai:latest bash\n</code></pre><p>If you want to cite our work, please use the following:</p><pre><code>@misc{mayoralvilches2025caiopenbugbountyready,\n      title={CAI: An Open, Bug Bounty-Ready Cybersecurity AI},\n      author={VÃ­ctor Mayoral-Vilches and Luis Javier Navarrete-Lozano and MarÃ­a Sanz-GÃ³mez and Lidia Salas Espejo and MartiÃ±o Crespo-Ãlvarez and Francisco Oca-Gonzalez and Francesco Balassone and Alfonso Glera-PicÃ³n and Unai Ayucar-Carbajo and Jon Ander Ruiz-Alcalde and Stefan Rass and Martin Pinzger and Endika Gil-Uriarte},\n      year={2025},\n      eprint={2504.06017},\n      archivePrefix={arXiv},\n      primaryClass={cs.CR},\n      url={https://arxiv.org/abs/2504.06017},\n}\n</code></pre><pre><code>@misc{mayoralvilches2025cybersecurityaidangerousgap,\n      title={Cybersecurity AI: The Dangerous Gap Between Automation and Autonomy}, \n      author={VÃ­ctor Mayoral-Vilches},\n      year={2025},\n      eprint={2506.23592},\n      archivePrefix={arXiv},\n      primaryClass={cs.CR},\n      url={https://arxiv.org/abs/2506.23592}, \n}\n</code></pre><p>CAI was initially developed by <a href=\"https://aliasrobotics.com\">Alias Robotics</a> and co-funded by the European EIC accelerator project RIS (GA 101161136) - HORIZON-EIC-2023-ACCELERATOR-01 call. The original agentic principles are inspired from OpenAI's <a href=\"https://github.com/openai/swarm\"></a> library and translated into newer prototypes. This project also makes use of other relevant open source building blocks including <a href=\"https://github.com/BerriAI/litellm\"></a>, and <a href=\"https://github.com/Arize-ai/phoenix\"></a></p><p>[^1]: Arguably, the Chain-of-Thought agentic pattern is a special case of the Hierarchical agentic pattern. [^2]: Kamhoua, C. A., Leslie, N. O., &amp; Weisman, M. J. (2018). Game theoretic modeling of advanced persistent threat in internet of things. Journal of Cyber Security and Information Systems. [^3]: Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., &amp; Cao, Y. (2023, January). React: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR). [^4]: Deng, G., Liu, Y., Mayoral-Vilches, V., Liu, P., Li, Y., Xu, Y., ... &amp; Rass, S. (2024). {PentestGPT}: Evaluating and harnessing large language models for automated penetration testing. In 33rd USENIX Security Symposium (USENIX Security 24) (pp. 847-864).</p>","contentLength":35191,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MotiaDev/motia","url":"https://github.com/MotiaDev/motia","date":1755488034,"author":"","guid":230763,"unread":true,"content":"<p>Modern Backend Framework that unifies APIs, background jobs, workflows, and AI Agents into a single core primitive with built-in observability and state management.</p><a href=\"https://motia.dev\"><img src=\"https://raw.githubusercontent.com/MotiaDev/motia/main/assets/github-readme-banner.png\" alt=\"Motia Banner\" width=\"100%\"></a><p align=\"center\"><strong>ğŸ”¥ The Unified Backend Framework That Eliminates Runtime Fragmentation ğŸ”¥</strong></p><p align=\"center\"><em>APIs, background jobs, workflows, and AI agents in one system. JavaScript, TypeScript, Python, and more in one codebase.</em></p><p><strong>Motia solves backend fragmentation.</strong></p><p>Modern software engineering is splintered â€“ APIs live in one framework, background jobs in another, queues have their own tooling, and AI agents are springing up in yet more isolated runtimes. <strong>This fragmentation demands a unified system.</strong></p><p>Motia unifies APIs, background jobs, workflows, and AI agents into a  with shared observability and developer experience. Similar to how React simplified frontend development where everything is a component, <strong>Motia simplifies backend development where everything is a Step</strong>.</p><p>Write <strong>JavaScript, TypeScript, Python, and more</strong> in the same workflow. <strong>What used to take 5 frameworks to build now comes out of the box with Motia.</strong></p><p>Get Motia project up and running in :</p><h3>1. Bootstrap a New Motia Project</h3><pre><code>npx motia@latest create -i   # runs the interactive terminal\n</code></pre><p>Follow the prompts to pick a template, project name, and language. <img src=\"https://raw.githubusercontent.com/MotiaDev/motia/main/assets/motia-terminal.gif\" alt=\"motia-terminal\"></p><p>Inside your new project folder, launch the dev server:</p><pre><code>npx motia dev # âœ http://localhost:3000\n</code></pre><ul><li>âœ… REST APIs with validation</li><li>âœ… Visual debugger &amp; tracing</li><li>âœ… Event-driven architecture</li></ul><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>A complete chess platform benchmarking LLM performance with real-time evaluation.</p><blockquote></blockquote><p><strong>Built from scratch to production deployment, featuring:</strong></p><ul><li>ğŸ” <strong>Authentication &amp; user management</strong></li><li>ğŸ¤– <strong>Multi-agent LLM evaluation</strong> (OpenAI, Claude, Gemini, Grok)</li><li>ğŸ <strong>Python engine integration</strong> (Stockfish chess evaluation)</li><li>ğŸ“Š  with live move updates and scoring</li><li>ğŸ¨  with interactive chess boards</li><li>ğŸ”„  connecting TypeScript APIs to Python processors</li><li>ğŸ“ˆ  with move-by-move quality scoring</li><li>ğŸš€  on Motia Cloud</li></ul><p> Multi-language workflows â€¢ Real-time streaming â€¢ AI integration â€¢ Production deployment</p><table><tbody></tbody></table><p>We have a public roadmap for Motia, you can view it <a href=\"https://github.com/orgs/MotiaDev/projects/2/views/4\">here</a>.</p><p>Feel free to add comments to the issues, or create a new issue if you have a feature request.</p><table><thead><tr></tr></thead><tbody><tr><td>Add support for Python types</td></tr><tr></tr><tr><td>Add support for Workbench UI</td></tr><tr><td>Add support for Queue Strategies</td></tr><tr><td>Add support for Reactive Steps</td></tr><tr><td>Add support for Point in time triggers</td></tr><tr><td>Add support for Workbench plugins</td></tr><tr><td>Rewrite our Core in either Go or Rust</td><td>Rewrite our Core in either Go or Rust</td></tr><tr></tr><tr><td>Built-in database support</td><td>Add support for built-in database</td></tr></tbody></table>","contentLength":2478,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DataExpert-io/data-engineer-handbook","url":"https://github.com/DataExpert-io/data-engineer-handbook","date":1755488034,"author":"","guid":230764,"unread":true,"content":"<p>This is a repo with links to everything you'd ever want to learn about data engineering</p><p>This repo has all the resources you need to become an amazing data engineer!</p><p>For more applied learning:</p><ul><li>Check out the <a href=\"https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/projects.md\">projects</a> section for more hands-on examples!</li><li>Check out the <a href=\"https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/interviews.md\">interviews</a> section for more advice on how to pass data engineering interviews!</li><li>Check out the <a href=\"https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/books.md\">books</a> section for a list of high quality data engineering books</li><li>Check out the <a href=\"https://raw.githubusercontent.com/DataExpert-io/data-engineer-handbook/main/communities.md\">communities</a> section for a list of high quality data engineering communities to join</li></ul><p>Top 3 must read books are:</p><p>Top must-join communities for DE:</p><p>Top must-join communities for ML:</p><h3>Data Engineering blogs of companies:</h3><h3>Data Engineering Whitepapers:</h3><p>Here's the mostly comprehensive list of data engineering creators: <strong>(You have to have at least 5k followers somewhere to be added!)</strong></p><p>Top must follow newsletters for data engineering:</p>","contentLength":849,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"clash-verge-rev/clash-verge-rev","url":"https://github.com/clash-verge-rev/clash-verge-rev","date":1755488034,"author":"","guid":230765,"unread":true,"content":"<p>A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience</p><h3 align=\"center\"> A Clash Meta GUI based on <a href=\"https://github.com/tauri-apps/tauri\">Tauri</a>. </h3><p>è¯·åˆ°å‘å¸ƒé¡µé¢ä¸‹è½½å¯¹åº”çš„å®‰è£…åŒ…ï¼š<a href=\"https://github.com/clash-verge-rev/clash-verge-rev/releases\">Release page</a> Go to the <a href=\"https://github.com/clash-verge-rev/clash-verge-rev/releases\">Release page</a> to download the corresponding installation package Supports Windows (x64/x86), Linux (x64/arm64) and macOS 10.15+ (intel/apple).</p><ul><li>é«˜æ€§èƒ½æµ·å¤–æœºåœºï¼Œå…è´¹è¯•ç”¨ï¼Œä¼˜æƒ å¥—é¤ï¼Œè§£é”æµåª’ä½“ï¼Œå…¨çƒé¦–å®¶æ”¯æŒ Hysteria åè®®ã€‚</li><li>ä½¿ç”¨ Clash Verge ä¸“å±é‚€è¯·é“¾æ¥æ³¨å†Œé€ 3 å¤©ï¼Œæ¯å¤© 1G æµé‡å…è´¹è¯•ç”¨ï¼š<a href=\"https://verge.dginv.click/#/register?code=oaxsAGo6\">ç‚¹æ­¤æ³¨å†Œ</a></li><li>Clash Verge ä¸“å± 8 æŠ˜ä¼˜æƒ ç : verge20 (ä»…æœ‰ 500 ä»½)</li><li>ä¼˜æƒ å¥—é¤æ¯æœˆä»…éœ€ 15.8 å…ƒï¼Œ160G æµé‡ï¼Œå¹´ä»˜ 8 æŠ˜</li><li>é›†ç¾¤è´Ÿè½½å‡è¡¡è®¾è®¡ï¼Œé«˜é€Ÿä¸“çº¿(å…¼å®¹è€å®¢æˆ·ç«¯)ï¼Œæä½å»¶è¿Ÿï¼Œæ— è§†æ™šé«˜å³°ï¼Œ4K ç§’å¼€</li><li>å…¨çƒé¦–å®¶ Hysteria åè®®æœºåœºï¼Œç°å·²ä¸Šçº¿æ›´å¿«çš„  åè®®(Clash Verge å®¢æˆ·ç«¯æœ€ä½³æ­é…)</li></ul><h4>æœ¬é¡¹ç›®çš„æ„å»ºä¸å‘å¸ƒç¯å¢ƒç”± <a href=\"https://yxvm.com/aff.php?aff=827\">YXVM</a> ç‹¬ç«‹æœåŠ¡å™¨å…¨åŠ›æ”¯æŒï¼Œ</h4><p>æ„Ÿè°¢æä¾› ç‹¬äº«èµ„æºã€é«˜æ€§èƒ½ã€é«˜é€Ÿç½‘ç»œ çš„å¼ºå¤§åç«¯ç¯å¢ƒã€‚å¦‚æœä½ è§‰å¾—ä¸‹è½½å¤Ÿå¿«ã€ä½¿ç”¨å¤Ÿçˆ½ï¼Œé‚£æ˜¯å› ä¸ºæˆ‘ä»¬ç”¨äº†å¥½æœåŠ¡å™¨ï¼</p><ul><li>ğŸ§  é€‚åˆè·‘ä»£ç†ã€æ­å»º WEB ç«™ CDN ç«™ ã€æ CI/CD æˆ–ä»»ä½•é«˜è´Ÿè½½åº”ç”¨</li><li>ğŸ’¡ æ”¯æŒå³å¼€å³ç”¨ï¼Œå¤šæœºæˆ¿é€‰æ‹©ï¼ŒCN2 / IEPL å¯é€‰</li></ul><ul><li>åŸºäºæ€§èƒ½å¼ºåŠ²çš„ Rust å’Œ Tauri 2 æ¡†æ¶</li><li>ç®€æ´ç¾è§‚çš„ç”¨æˆ·ç•Œé¢ï¼Œæ”¯æŒè‡ªå®šä¹‰ä¸»é¢˜é¢œè‰²ã€ä»£ç†ç»„/æ‰˜ç›˜å›¾æ ‡ä»¥åŠ ã€‚</li><li>é…ç½®æ–‡ä»¶ç®¡ç†å’Œå¢å¼ºï¼ˆMerge å’Œ Scriptï¼‰ï¼Œé…ç½®æ–‡ä»¶è¯­æ³•æç¤ºã€‚</li></ul><p>To run the development server, execute the following commands after all prerequisites for  are installed:</p><blockquote><p>[!NOTE] <strong>If you are using a Windows ARM device, you additionally need to install <a href=\"https://github.com/llvm/llvm-project/releases\">LLVM</a> (including clang) and set the environment variable.</strong></p><p>Because the  crate is compiled based on  under Windows ARM.</p></blockquote><pre><code>pnpm i\npnpm run prebuild\npnpm dev\n</code></pre><p>Clash Verge rev was based on or inspired by these projects and so on:</p>","contentLength":1881,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenBB-finance/OpenBB","url":"https://github.com/OpenBB-finance/OpenBB","date":1755488034,"author":"","guid":230766,"unread":true,"content":"<p>Financial data platform for analysts, quants and AI agents.</p><img src=\"https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only\" alt=\"OpenBB Platform logo\" width=\"600\"><img src=\"https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only\" alt=\"OpenBB Platform logo\" width=\"600\"><p>The first financial Platform that is open source.</p><p>The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.</p><p>Get started with: </p><pre><code>from openbb import obb\noutput = obb.equity.price.historical(\"AAPL\")\ndf = output.to_dataframe()\n</code></pre><p>You can sign up to the <a href=\"https://my.openbb.co/login\">OpenBB Hub</a> to get the most out of the OpenBB ecosystem.</p><p>While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.</p><p>If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at <a href=\"https://pro.openbb.co\">https://pro.openbb.co</a>.</p><a href=\"https://pro.openbb.co\"></a><h3>Integrating OpenBB Platform to the OpenBB Workspace</h3><p>Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.</p><h4>Run OpenBB Platform backend</h4><pre><code>pip install \"openbb[all]\"\n</code></pre><ul><li>Start the API server over localhost.</li></ul><p>This will launch a FastAPI server, via Uvicorn, at .</p><h4>Integrate OpenBB Platform backend to OpenBB Workspace</h4><ol><li>Click on \"Connect backend\"</li><li>Click on \"Test\". You should get a \"Test successful\" with the number of apps found.</li></ol><p>The OpenBB Platform can be installed as a <a href=\"https://pypi.org/project/openbb/\">PyPI package</a> by running </p><p>or by cloning the repository directly with <code>git clone https://github.com/OpenBB-finance/OpenBB.git</code>.</p><h3>OpenBB Platform CLI installation</h3><p>The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.</p><p>It can be installed by running </p><p>or by cloning the repository directly with <code>git clone https://github.com/OpenBB-finance/OpenBB.git</code>.</p><p>There are three main ways of contributing to this project. (Hopefully you have starred the project by now â­ï¸)</p><p>Before creating a ticket make sure the one you are creating doesn't exist already <a href=\"https://github.com/OpenBB-finance/OpenBB/issues\">here</a></p><p>Distributed under the AGPLv3 License. See <a href=\"https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE\">LICENSE</a> for more information.</p><p>Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.</p><p>Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.</p><p>The data contained in the OpenBB Platform is not necessarily accurate.</p><p>OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.</p><p>All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.</p><p>Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.</p><p>If you have any questions about the platform or anything OpenBB, feel free to email us at </p><p>If you want to say hi, or are interested in partnering with us, feel free to reach us at </p><p>This is a proxy of our growth and that we are just getting started.</p><p>OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.</p><a href=\"https://github.com/OpenBB-finance/OpenBB/graphs/contributors\"><img src=\"https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB\" width=\"800\"></a>","contentLength":3508,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"emcie-co/parlant","url":"https://github.com/emcie-co/parlant","date":1755398530,"author":"","guid":230474,"unread":true,"content":"<p>LLM agents built for control. Designed for real-world use. Deployed in minutes.</p><h2>ğŸ¯ The Problem Every AI Developer Faces</h2><p>You build an AI agent. It works great in testing. Then real users start talking to it and...</p><ul><li>âŒ It ignores your carefully crafted system prompts</li><li>âŒ It hallucinates responses in critical moments</li><li>âŒ It can't handle edge cases consistently</li><li>âŒ Each conversation feels like a roll of the dice</li></ul><p> You're not alone. This is the #1 pain point for developers building production AI agents.</p><h2>âš¡ The Solution: Teach Principles, Not Scripts</h2><p>Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, .</p><pre><code># Traditional approach: Cross your fingers ğŸ¤\nsystem_prompt = \"You are a helpful assistant. Please follow these 47 rules...\"\n\n# Parlant approach: Guaranteed compliance âœ…\nawait agent.create_guideline(\n    condition=\"Customer asks about refunds\",\n    action=\"Check order status first to see if eligible\",\n    tools=[check_order_status],\n)\n</code></pre><div align=\"center\"><h2>ğŸš€ Get Your Agent Running in 60 Seconds</h2></div><pre><code>import parlant.sdk as p\n\n@p.tool\nasync def get_weather(context: p.ToolContext, city: str) -&gt; p.ToolResult:\n    # Your weather API logic here\n    return p.ToolResult(f\"Sunny, 72Â°F in {city}\")\n\nasync def main():\n    async with p.Server() as server:\n        agent = await server.create_agent(\n            name=\"WeatherBot\",\n            description=\"Helpful weather assistant\"\n        )\n\n        # Define behavior with natural language\n        await agent.create_guideline(\n            condition=\"User asks about weather\",\n            action=\"Get current weather and provide a friendly response with suggestions\",\n            tools=[get_weather]\n        )\n\n        # ğŸ‰ Test playground ready at http://localhost:8800\n        # Integrate the official React widget into your app,\n        # or follow the tutorial to build your own frontend!\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n</code></pre><p> Your agent is running with guaranteed rule-following behavior.</p><img alt=\"Parlant Demo\" src=\"https://github.com/emcie-co/parlant/raw/develop/docs/demo.gif?raw=true\" width=\"100%\"><h2>ğŸ”¥ Why Developers Are Switching to Parlant</h2><table width=\"100%\"><tbody><tr><td width=\"50%\"><h3>ğŸ—ï¸ <strong>Traditional AI Frameworks</strong></h3></td></tr><tr><td width=\"50%\"><ul><li>Write complex system prompts</li><li>Hope the LLM follows them</li><li>Debug unpredictable behaviors</li><li>Scale by prompt engineering</li><li>Cross fingers for reliability</li></ul></td><td width=\"50%\"><ul><li>Define rules in natural language</li><li> rule compliance</li><li>Predictable, consistent behavior</li><li>Scale by adding guidelines</li><li>Production-ready from day one</li></ul></td></tr></tbody></table><h2>ğŸ¯ Perfect For Your Use Case</h2><div align=\"center\"><table><thead><tr></tr></thead><tbody><tr><td align=\"center\">Customer service at scale</td></tr><tr><td align=\"center\">Order processing automation</td><td align=\"center\">Document review assistance</td></tr></tbody></table></div><h2>ğŸ› ï¸ Enterprise-Grade Features</h2><ul><li><strong>ğŸ§­ Conversational Journeys</strong> - Lead the customer step-by-step to a goal</li><li><strong>ğŸ¯ Dynamic Guideline Matching</strong> - Context-aware rule application</li><li><strong>ğŸ”§ Reliable Tool Integration</strong> - APIs, databases, external services</li><li> - Deep insights into agent behavior</li><li> - Continuously improve agent responses</li><li> - Prevent hallucination and off-topic responses</li><li> - Understand every decision your agent makes</li></ul><h2>ğŸ“ˆ Join 5,000+ Developers Building Better AI</h2><div align=\"center\"><p><em>Financial institutions â€¢ Healthcare providers â€¢ Legal firms â€¢ E-commerce platforms</em></p></div><h2>ğŸŒŸ What Developers Are Saying</h2><blockquote><p><em>\"By far the most elegant conversational AI framework that I've come across! Developing with Parlant is pure joy.\"</em><strong>â€” Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase</strong></p></blockquote><p>Apache 2.0 - Use it anywhere, including commercial projects.</p>","contentLength":3282,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"IBM/mcp-context-forge","url":"https://github.com/IBM/mcp-context-forge","date":1755398530,"author":"","guid":230475,"unread":true,"content":"<p>A Model Context Protocol (MCP) Gateway &amp; Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).</p><blockquote><p>Model Context Protocol gateway &amp; proxy - unify REST, MCP, and A2A with federation, virtual servers, retries, security, and an optional admin UI.</p></blockquote><p>ContextForge MCP Gateway is a feature-rich gateway, proxy and MCP Registry that federates MCP and REST services - unifying discovery, auth, rate-limiting, observability, virtual servers, multi-transport protocols, and an optional Admin UI into one clean endpoint for your AI clients. It runs as a fully compliant MCP server, deployable via PyPI or Docker, and scales to multi-cluster environments on Kubernetes with Redis-backed federation and caching.</p><p> is a gateway, registry, and proxy that sits in front of any <a href=\"https://modelcontextprotocol.io\">Model Context Protocol</a> (MCP) server or REST API-exposing a unified endpoint for all your AI clients.</p><p>: The current release (0.5.0) is considered alpha / early beta. It is not production-ready and should only be used for local development, testing, or experimentation. Features, APIs, and behaviors are subject to change without notice.  deploy in production environments without thorough security review, validation and additional security mechanisms. Many of the features required for secure, large-scale, or multi-tenant production deployments are still on the <a href=\"https://ibm.github.io/mcp-context-forge/architecture/roadmap/\">project roadmap</a> - which is itself evolving.</p><ul><li>Federation across multiple MCP and REST services</li><li>Virtualization of legacy APIs as MCP-compliant tools and servers</li><li>Transport over HTTP, JSON-RPC, WebSocket, SSE (with configurable keepalive), stdio and streamable-HTTP</li><li>An Admin UI for real-time management, configuration, and log monitoring</li><li>Built-in auth, retries, and rate-limiting</li><li><strong>OpenTelemetry observability</strong> with Phoenix, Jaeger, Zipkin, and other OTLP backends</li><li>Scalable deployments via Docker or PyPI, Redis-backed caching, and multi-cluster federation</li></ul><p>: MCP Gateway is not a standalone product - it is an open source component with  from IBM or its affiliates that can be integrated into your own solution architecture. If you choose to use it, you are responsible for evaluating its fit, securing the deployment, and managing its lifecycle. See <a href=\"https://raw.githubusercontent.com/IBM/mcp-context-forge/main/SECURITY.md\">SECURITY.md</a> for more details.</p><p>MCP Gateway is published on <a href=\"https://pypi.org/project/mcp-contextforge-gateway/\">PyPI</a> as .</p><p>: (single command using <a href=\"https://docs.astral.sh/uv/\">uv</a>)</p><pre><code>BASIC_AUTH_PASSWORD=pass \\\nMCPGATEWAY_UI_ENABLED=true \\\nMCPGATEWAY_ADMIN_API_ENABLED=true \\\nuvx --from mcp-contextforge-gateway mcpgateway --host 0.0.0.0 --port 4444\n</code></pre><h3>1 - Install &amp; run (copy-paste friendly)</h3><pre><code># 1ï¸âƒ£  Isolated env + install from pypi\nmkdir mcpgateway &amp;&amp; cd mcpgateway\npython3 -m venv .venv &amp;&amp; source .venv/bin/activate\npip install --upgrade pip\npip install mcp-contextforge-gateway\n\n# 2ï¸âƒ£  Launch on all interfaces with custom creds &amp; secret key\n# Enable the Admin API endpoints (true/false) - disabled by default\nexport MCPGATEWAY_UI_ENABLED=true\nexport MCPGATEWAY_ADMIN_API_ENABLED=true\n\nBASIC_AUTH_PASSWORD=pass JWT_SECRET_KEY=my-test-key \\\n  mcpgateway --host 0.0.0.0 --port 4444 &amp;   # admin/pass\n\n# 3ï¸âƒ£  Generate a bearer token &amp; smoke-test the API\nexport MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token \\\n    --username admin --exp 10080 --secret my-test-key)\n\ncurl -s -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     http://127.0.0.1:4444/version | jq\n</code></pre><p>Use the official OCI image from GHCR with .</p><pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e MCPGATEWAY_UI_ENABLED=true \\\n  -e MCPGATEWAY_ADMIN_API_ENABLED=true \\\n  -e HOST=0.0.0.0 \\\n  -e JWT_SECRET_KEY=my-test-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  -e AUTH_REQUIRED=true \\\n  -e DATABASE_URL=sqlite:///./mcp.db \\\n  ghcr.io/ibm/mcp-context-forge:0.5.0\n\n# Tail logs (Ctrl+C to quit)\ndocker logs -f mcpgateway\n\n# Generating an API key\ndocker run --rm -it ghcr.io/ibm/mcp-context-forge:0.5.0 \\\n  python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 0 --secret my-test-key\n</code></pre><h4>2 - Persist the SQLite database</h4><pre><code>mkdir -p $(pwd)/data\n\ntouch $(pwd)/data/mcp.db\n\nsudo chown -R :docker $(pwd)/data\n\nchmod 777 $(pwd)/data\n\ndocker run -d --name mcpgateway \\\n  --restart unless-stopped \\\n  -p 4444:4444 \\\n  -v $(pwd)/data:/data \\\n  -e MCPGATEWAY_UI_ENABLED=true \\\n  -e MCPGATEWAY_ADMIN_API_ENABLED=true \\\n  -e DATABASE_URL=sqlite:////data/mcp.db \\\n  -e HOST=0.0.0.0 \\\n  -e JWT_SECRET_KEY=my-test-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  ghcr.io/ibm/mcp-context-forge:0.5.0\n</code></pre><p>SQLite now lives on the host at .</p><h4>3 - Local tool discovery (host network)</h4><pre><code>mkdir -p $(pwd)/data\n\ntouch $(pwd)/data/mcp.db\n\nsudo chown -R :docker $(pwd)/data\n\nchmod 777 $(pwd)/data\n\ndocker run -d --name mcpgateway \\\n  --network=host \\\n  -e MCPGATEWAY_UI_ENABLED=true \\\n  -e MCPGATEWAY_ADMIN_API_ENABLED=true \\\n  -e HOST=0.0.0.0 \\\n  -e PORT=4444 \\\n  -e DATABASE_URL=sqlite:////data/mcp.db \\\n  -v $(pwd)/data:/data \\\n  ghcr.io/ibm/mcp-context-forge:0.5.0\n</code></pre><h3>ğŸ¦­ Podman (rootless-friendly)</h3><pre><code>podman run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e HOST=0.0.0.0 \\\n  -e DATABASE_URL=sqlite:///./mcp.db \\\n  ghcr.io/ibm/mcp-context-forge:0.5.0\n</code></pre><pre><code>mkdir -p $(pwd)/data\n\ntouch $(pwd)/data/mcp.db\n\nsudo chown -R :docker $(pwd)/data\n\nchmod 777 $(pwd)/data\n\npodman run -d --name mcpgateway \\\n  --restart=on-failure \\\n  -p 4444:4444 \\\n  -v $(pwd)/data:/data \\\n  -e DATABASE_URL=sqlite:////data/mcp.db \\\n  ghcr.io/ibm/mcp-context-forge:0.5.0\n</code></pre><h4>3 - Host networking (rootless)</h4><pre><code>mkdir -p $(pwd)/data\n\ntouch $(pwd)/data/mcp.db\n\nsudo chown -R :docker $(pwd)/data\n\nchmod 777 $(pwd)/data\n\npodman run -d --name mcpgateway \\\n  --network=host \\\n  -v $(pwd)/data:/data \\\n  -e DATABASE_URL=sqlite:////data/mcp.db \\\n  ghcr.io/ibm/mcp-context-forge:0.5.0\n</code></pre><h2>Testing  by hand:</h2><p>Because the wrapper speaks JSON-RPC over stdin/stdout, you can interact with it using nothing more than a terminal or pipes.</p><pre><code># Start the MCP Gateway Wrapper\nexport MCP_AUTH_TOKEN=${MCPGATEWAY_BEARER_TOKEN}\nexport MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/YOUR_SERVER_UUID\npython3 -m mcpgateway.wrapper\n</code></pre><h3>ğŸ§© Running from an MCP Client ()</h3><p>The  exposes everything your Gateway knows about over , so any MCP client that  (or ) open an authenticated SSE stream still gets full tool-calling power.</p><blockquote><p> to substitute your real Gateway URL (and server ID) for <code>http://localhost:4444/servers/UUID_OF_SERVER_1</code>. When inside Docker/Podman, that often becomes <code>http://host.docker.internal:4444/servers/UUID_OF_SERVER_1</code> (macOS/Windows) or the gateway container's hostname (Linux).</p></blockquote><h3>ğŸš€ Using with Claude Desktop (or any GUI MCP client)</h3><ol><li> â†’ <code>File â–¸ Settings â–¸ Developer â–¸ Edit Config</code></li><li>Paste one of the JSON blocks above (Docker / pipx / uvx).</li><li>Restart the app so the new stdio server is spawned.</li><li>Open logs in the same menu to verify  started and listed your tools.</li></ol><h2>ğŸš€ Quick Start: VS Code Dev Container</h2><p>Spin up a fully-loaded dev environment (Python 3.11, Docker/Podman CLI, all project dependencies) in just two clicks.</p><h2>Quick Start (manual install)</h2><ul><li> (optional, but all common workflows are available as Make targets)</li><li>Optional:  for containerized runs</li></ul><ol><li>Creates / activates a  in your home folder </li><li>Installs the gateway and necessary dependencies</li></ol><p>For development, you can use:</p><pre><code>make install-dev # Install development dependencies, ex: linters and test harness\nmake lint          # optional: run style checks (ruff, mypy, etc.)\n</code></pre><h3>Containerized (self-signed TLS)</h3><h2>Container Runtime Support</h2><p>This project supports both Docker and Podman. The Makefile automatically detects which runtime is available and handles image naming differences.</p><pre><code>make container-build  # Uses podman if available, otherwise docker\n\n&gt; You can use docker or podman, ex:\n\n```bash\nmake podman            # build production image\nmake podman-run-ssl    # run at https://localhost:4444\n# or listen on port 4444 on your host directly, adds --network=host to podman\nmake podman-run-ssl-host\n</code></pre><pre><code>curl -k -sX GET \\\n     -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://localhost:4444/tools | jq\n</code></pre><p>You should receive  until you register a tool.</p><pre><code>make venv install          # create .venv + install deps\nmake serve                 # gunicorn on :4444\n</code></pre><pre><code>uv venv &amp;&amp; source .venv/bin/activate\nuv pip install -e '.[dev]' # IMPORTANT: in zsh, quote to disable glob expansion!\n</code></pre><pre><code>python3 -m venv .venv &amp;&amp; source .venv/bin/activate\npip install -e \".[dev]\"\n</code></pre><h3>Optional (PostgreSQL adapter)</h3><p>You can configure the gateway with SQLite, PostgreSQL (or any other compatible database) in .env.</p><p>When using PostgreSQL, you need to install  driver.</p><pre><code>uv pip install psycopg2-binary   # dev convenience\n# or\nuv pip install psycopg2          # production build\n</code></pre><pre><code>docker run --name mcp-postgres \\\n  -e POSTGRES_USER=postgres \\\n  -e POSTGRES_PASSWORD=mysecretpassword \\\n  -e POSTGRES_DB=mcp \\\n  -p 5432:5432 -d postgres\n</code></pre><p>A  target is provided along with a <a href=\"https://raw.githubusercontent.com/IBM/mcp-context-forge/main/docker-compose.yml\">docker-compose.yml</a> file to make this process simpler.</p><h2>Configuration ( or env vars)</h2><blockquote><p>âš ï¸ If any required  variable is missing or invalid, the gateway will fail fast at startup with a validation error via Pydantic.</p></blockquote><p>You can get started by copying the provided <a href=\"https://raw.githubusercontent.com/IBM/mcp-context-forge/main/.env.example\">.env.example</a> to  and making the necessary edits to fit your environment.</p><pre><code> make serve               # Run production Gunicorn server on\n make serve-ssl           # Run Gunicorn behind HTTPS on :4444 (uses ./certs)\n</code></pre><p>To run the development (uvicorn) server:</p><pre><code>make dev\n# or\n./run.sh --reload --log debug --workers 2\n</code></pre><blockquote><p> is a wrapper around  that loads , supports reload, and passes arguments to the server.</p></blockquote><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><pre><code>uvicorn mcpgateway.main:app --host 0.0.0.0 --port 4444 --workers 4\n</code></pre><pre><code># Generate a JWT token using JWT_SECRET_KEY and export it as MCPGATEWAY_BEARER_TOKEN\n# Note that the module needs to be installed. If running locally use:\nexport MCPGATEWAY_BEARER_TOKEN=$(JWT_SECRET_KEY=my-test-key python3 -m mcpgateway.utils.create_jwt_token)\n\n# Use the JWT token in an API call\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/tools\n</code></pre><h2>â˜ï¸ AWS / Azure / OpenShift</h2><p>Deployment details can be found in the GitHub Pages.</p><h2>â˜ï¸ IBM Cloud Code Engine Deployment</h2><p>This project supports deployment to <a href=\"https://cloud.ibm.com/codeengine\">IBM Cloud Code Engine</a> using the  CLI and the IBM Container Registry.</p><p>You can test the API endpoints through curl, or Swagger UI, and check detailed documentation on ReDoc:</p><p>Generate an API Bearer token, and test the various API endpoints.</p><pre><code>make test            # Run unit tests\nmake lint            # Run lint tools\n</code></pre><p>MCP Context Forge implements comprehensive doctest coverage to ensure all code examples in documentation are tested and verified:</p><pre><code>make doctest         # Run all doctests\nmake doctest-verbose # Run with detailed output\nmake doctest-coverage # Generate coverage report\nmake doctest-check   # Check coverage percentage\n</code></pre><ul><li>âœ… : 100% (base, stdio, SSE, WebSocket, streamable HTTP)</li><li>âœ… : 100% (slug generation, JWT tokens, validation)</li><li>âœ… : 100% (settings, environment variables)</li><li>ğŸ”„ : ~60% (in progress)</li><li>ğŸ”„ : ~40% (in progress)</li></ul><ul><li>All documented examples are automatically tested</li><li>Documentation stays accurate and up-to-date</li><li>Developers can run examples directly from docstrings</li><li>Regression prevention through automated verification</li></ul><p>This project offer the following Makefile targets. Type  in the project root to show all targets.</p><ol><li>Fork the repo, create a feature branch.</li><li>Run  and fix any issues.</li><li>Keep  green and 100% coverage.</li><li>Open a PR - describe your changes clearly.</li></ol><p>Licensed under the  - see <a href=\"https://raw.githubusercontent.com/IBM/mcp-context-forge/main/LICENSE\">LICENSE</a></p><h2>Core Authors and Maintainers</h2><p>Special thanks to our contributors for helping us improve ContextForge MCP Gateway:</p><a href=\"https://github.com/ibm/mcp-context-forge/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=ibm/mcp-context-forge&amp;max=100&amp;anon=0&amp;columns=10\"></a><h2>Star History and Project Activity</h2>","contentLength":11622,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Shubhamsaboo/awesome-llm-apps","url":"https://github.com/Shubhamsaboo/awesome-llm-apps","date":1755398530,"author":"","guid":230476,"unread":true,"content":"<p>Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p><p>A curated collection of <strong>Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.</strong> This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.</p><ul><li>ğŸ’¡ Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.</li><li>ğŸ”¥ Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp; RAG.</li><li>ğŸ“ Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.</li></ul><h3>ğŸ® Autonomous Game Playing Agents</h3><h3>ğŸ“€ RAG (Retrieval Augmented Generation)</h3><h3>ğŸ’¾ LLM Apps with Memory Tutorials</h3><h3>ğŸ”§ LLM Fine-tuning Tutorials</h3><h3>ğŸ§‘â€ğŸ« AI Agent Framework Crash Course</h3><ul><li><a href=\"https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/ai_agent_framework_crash_course/google_adk_crash_course/\">Google ADK Crash Course</a><ul><li>Starter agent; modelâ€‘agnostic (OpenAI, Claude)</li><li>Structured outputs (Pydantic)</li><li>Tools: builtâ€‘in, function, thirdâ€‘party, MCP tools</li><li>Memory; callbacks; Plugins</li><li>Simple multiâ€‘agent; Multiâ€‘agent patterns</li></ul></li></ul><ol><li><pre><code>git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git \n</code></pre></li><li><p><strong>Navigate to the desired project directory</strong></p><pre><code>cd awesome-llm-apps/starter_ai_agents/ai_travel_agent\n</code></pre></li><li><p><strong>Install the required dependencies</strong></p><pre><code>pip install -r requirements.txt\n</code></pre></li><li><p><strong>Follow the project-specific instructions</strong> in each project's  file to set up and run the app.</p></li></ol><h2>ğŸ¤ Contributing to Open Source</h2><p>Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new <a href=\"https://github.com/Shubhamsaboo/awesome-llm-apps/issues\">GitHub Issue</a> or submit a pull request. Make sure to follow the existing project structure and include a detailed  for each new app.</p><h3>Thank You, Community, for the Support! ğŸ™</h3><p>ğŸŒŸ <strong>Donâ€™t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.</strong></p>","contentLength":1965,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"jaywcjlove/awesome-mac","url":"https://github.com/jaywcjlove/awesome-mac","date":1755398530,"author":"","guid":230477,"unread":true,"content":"<p>ï£¿ Now we have become very big, Different from the original idea. Collect premium software in various categories.</p><p>This project is now very large, and is very different from the original idea. Here, we collect awesome macOS software and arrange them into various categories. Feel free to  and .</p><p><img src=\"https://jaywcjlove.github.io/sb/ico/min-oss.svg?sanitize=true\" alt=\"Open-Source Software\" title=\"Open Source Software\"> means . click the icon to see the item's repository;<img src=\"https://jaywcjlove.github.io/sb/ico/min-free.svg?sanitize=true\" alt=\"Freeware\" title=\"Freeware\"> means  to use, or  personal license;<img src=\"https://jaywcjlove.github.io/sb/ico/min-app-store.svg?sanitize=true\" alt=\"App Store\" title=\"App Store Software\"> means  hyperlink;<img src=\"https://jaywcjlove.github.io/sb/ico/min-awesome.svg?sanitize=true\" alt=\"Awesome List\" title=\"Awesome List\"> means hyperlink to a corresponding  for the item;</p><h2>Reading and Writing Tools</h2><p><em>Applications to edit text, I suggest the open-source editors</em></p><h3>Regular Expression Editors</h3><ul><li><a href=\"https://motionobj.com/regex/\">Regex</a> - Regular expression testing tool with an emphasis on simplicity.</li><li><a href=\"http://www.mactechnologies.com/index.php?page=downloads#regexrx\">RegExRX</a> - Development tool for regular expressions.</li><li><a href=\"https://apps.apple.com/app/6479819388\">RegexMate</a> - A regular expression testing tool with a built-in quick reference guide.</li></ul><h3>API Development and Analysis</h3><h3>Frameworks For Hybrid Applications</h3><h3>Prototyping and Mind-Mapping Tools</h3><h3>Collaboration and Team Tools</h3><h2>Download Management Tools</h2><p><em>I recommend using online storage with Mac clients</em></p><p><em>(Or you could just use the Mac OS built-in dictionary)</em></p><h3>Quality of Life Improvements</h3><blockquote></blockquote><p>If you come across websites offering pirated software or cracks, please post <a href=\"https://github.com/jaywcjlove/awesome-mac/issues/17\">HERE</a>. We love apps, but only authentic ones. :)</p><ul><li><a href=\"https://setapp.sjv.io/c/6018600/343321/5114\">Setapp</a> - The best free and paid apps (like CleanShot, Bartender, Paste, TablePlus, etc.) in one suite for only 10$/month!</li></ul><p><em>Here are some of the major software download sites, there are a number of OSX Mac software sites</em></p><p><em>Here are some of the major software download sites, there are a number of OSX Mac software sites</em></p><ul><li><a href=\"http://alternativeto.net/\">alternativeTo</a> - Also a very nice community. If you are looking for some alternative apps  Windows or another platform, check this site.</li><li><a href=\"https://www.slant.co\">Slant</a> - I personally recommend this. This is a platform where you can compare apps side-by-side, you might get an idea by seeing other users recommendations. Please contribute if you find an application from this list!</li><li><a href=\"https://buyoncesoftware.com/\">Buy software, once</a> - The place to find all the software you can buy one time, and own for a lifetime.</li><li><a href=\"https://openalternative.co/\">Open Alternative</a> - Discover Open Source Alternatives to Popular Software. A curated collection of the best open source alternatives to everyday SaaS products. Save money with reliable tools hand-picked for you.</li></ul><h3>Pirated software download site blocklist</h3><p><em>Refuse piracy from me. Software vendors can go to these places rights.</em></p><ul><li>AppKedï¼š</li><li>Softasmï¼š</li><li>Appstorrentï¼š</li></ul><p>This project exists thanks to all the people who contribute.</p>","contentLength":2352,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LMCache/LMCache","url":"https://github.com/LMCache/LMCache","date":1755398530,"author":"","guid":230478,"unread":true,"content":"<p>Supercharge Your LLM with the Fastest KV Cache Layer</p><p>ğŸ”¥ <strong>NEW: For enterprise-scale deployment of LMCache and vLLM, please check out vLLM <a href=\"https://github.com/vllm-project/production-stack\">Production Stack</a>. LMCache is also officially supported in <a href=\"https://github.com/llm-d/llm-d/\">llm-d</a> and <a href=\"https://github.com/kserve/kserve\">KServe</a>!</strong></p><p>LMCache is an  serving engine extension to  and , especially under long-context scenarios. By storing the KV caches of reusable texts across various locations, including (GPU, CPU DRAM, Local Disk), LMCache reuses the KV caches of  reused text (not necessarily prefix) in  serving engine instance. Thus, LMCache saves precious GPU cycles and reduces user response delay.</p><p>By combining LMCache with vLLM, developers achieve 3-10x delay savings and GPU cycle reduction in many LLM use cases, including multi-round QA and RAG.</p><p>To use LMCache, simply install  from your package manager, e.g. pip:</p><p>Works on Linux NVIDIA GPU platform.</p><p>More <a href=\"https://docs.lmcache.ai/getting_started/installation\">detailed installation instructions</a> are available in the docs, particularly if you are not using the latest stable version of vllm or using another serving engine with different dependencies. Any \"undefined symbol\" or torch mismatch versions can be resolved in the documentation.</p><p>Go hands-on with our <a href=\"https://github.com/LMCache/LMCache/tree/dev/examples\">examples</a>, demonstrating how to address different use cases with LMCache.</p><h2>Interested in Connecting?</h2><p>We keep notes from each meeting on this <a href=\"https://docs.google.com/document/d/1_Fl3vLtERFa3vTH00cezri78NihNBtSClK-_1tSrcow\">document</a> for summaries of standups, discussion, and action items.</p><p>We welcome and value all contributions and collaborations. Please check out <a href=\"https://raw.githubusercontent.com/LMCache/LMCache/dev/CONTRIBUTING.md\">Contributing Guide</a> on how to contribute.</p><p>If you use LMCache for your research, please cite our papers:</p><pre><code>@inproceedings{liu2024cachegen,\n  title={Cachegen: Kv cache compression and streaming for fast large language model serving},\n  author={Liu, Yuhan and Li, Hanchen and Cheng, Yihua and Ray, Siddhant and Huang, Yuyang and Zhang, Qizheng and Du, Kuntai and Yao, Jiayi and Lu, Shan and Ananthanarayanan, Ganesh and others},\n  booktitle={Proceedings of the ACM SIGCOMM 2024 Conference},\n  pages={38--56},\n  year={2024}\n}\n\n@article{cheng2024large,\n  title={Do Large Language Models Need a Content Delivery Network?},\n  author={Cheng, Yihua and Du, Kuntai and Yao, Jiayi and Jiang, Junchen},\n  journal={arXiv preprint arXiv:2409.13761},\n  year={2024}\n}\n\n@inproceedings{10.1145/3689031.3696098,\n  author = {Yao, Jiayi and Li, Hanchen and Liu, Yuhan and Ray, Siddhant and Cheng, Yihua and Zhang, Qizheng and Du, Kuntai and Lu, Shan and Jiang, Junchen},\n  title = {CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion},\n  year = {2025},\n  url = {https://doi.org/10.1145/3689031.3696098},\n  doi = {10.1145/3689031.3696098},\n  booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},\n  pages = {94â€“109},\n}\n</code></pre><p>The LMCache codebase is licensed under Apache License 2.0. See the <a href=\"https://raw.githubusercontent.com/LMCache/LMCache/dev/LICENSE\">LICENSE</a> file for details.</p>","contentLength":2764,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PixiEditor/PixiEditor","url":"https://github.com/PixiEditor/PixiEditor","date":1755398530,"author":"","guid":230479,"unread":true,"content":"<p>PixiEditor is a Universal Editor for all your 2D needs</p><h3>Toolsets for any scenario</h3><p>PixiEditor 2.0 comes by default with 3 toolsets:</p><ul><li> - it contains tool suited for pixel-perfect scenarios</li><li> - basic painting tools, soft brushes, anti aliased shapes</li><li> - shapes and paths for creating vectors</li></ul><p>All <strong>toolsets can be used on one canvas</strong>. Mix vector with raster. Export to png, jpg, svg, gif, mp4 and more!</p><p>Version 2.0 comes with a timeline and animation capabilities. You can create frame by frame animations or use nodes to animate your custom shaders. Key frame animations with vectors are on our roadmap.</p><p>Node render system is what powers such extensive capabilities. All layers, effects and the layer structure are nodes or a result of its connections. PixiEditor exposes node graph for every document, so you are free to customize your image however you want and create procedural art/animations!</p><p>Got stuck? We are here to <a href=\"https://pixieditor.net/help\">Help</a></p>","contentLength":910,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"dtyq/magic","url":"https://github.com/dtyq/magic","date":1755398530,"author":"","guid":230480,"unread":true,"content":"<p>Super Magic (è¶…çº§éº¦å‰). The first open-source all-in-one AI productivity platform (Generalist AI Agent + Workflow Engine + IM + Online collaborative office system)</p><p>Magic aims to help enterprises of all sizes quickly build and deploy AI applications to achieve a 100x increase in productivity.</p><p>Magic is the first <strong>\"open-source all-in-one AI productivity platform\"</strong>, not a single AI product, but a comprehensive product matrix with rich capabilities.</p><ul><li> - A  designed for complex task scenarios</li><li> - An enterprise-grade instant messaging system that integrates AI Agent conversations with internal enterprise communication</li><li> - A powerful visual AI workflow orchestration system</li><li> (Coming soon) - An enterprise-grade online collaborative office system</li></ul><p>In addition to the above AI products, we have also open-sourced some of the infrastructure we used to build these products:</p><ul><li> - A language-first AI Agent Framework for building AI agents with natural language (currently available in Python version, TypeScript version coming soon)</li><li> - A powerful and flexible HTML to Markdown conversion tool that uses an extensible rule system to accurately convert complex HTML documents to concise Markdown format</li><li> (Coming soon) - A revolutionary browser operation tool specifically designed for AI Agents</li><li> (Coming soon) - A new static content hosting management system specifically designed for AI Agents</li><li> (Coming soon) - A powerful sandbox system for AI Agent runtime</li></ul><p>A powerful  specially designed for complex task scenarios. Through a multi-agent design system and rich tool capabilities, Super Magic supports intelligent abilities such as <strong>autonomous task understanding</strong>, , , and <strong>autonomous error correction</strong>. It can understand natural language instructions, execute various business processes, and deliver final target results. As the flagship product of the Magic product matrix, Super Magic provides powerful secondary development capabilities through open source, allowing enterprises to quickly build and deploy intelligent assistants that meet specific business needs, greatly improving decision-making efficiency and quality.</p><p>Magic Flow is a powerful visual AI workflow orchestration system that allows users to build complex AI Agent workflows on a free canvas. It has the following core features:</p><ul><li>: Intuitive drag-and-drop interface allows designing complex AI workflows without coding, easily implementing various functional combinations through node connections.</li><li>: Built-in variety of preset components, including text processing, image generation, code execution modules, meeting diverse business needs.</li><li><strong>Comprehensive Model Support</strong>: Compatible with any large model following the OpenAI API protocol, flexibly choosing AI capabilities suitable for business scenarios.</li><li><strong>System Integration Capability</strong>: Seamless integration with Magic IM and other third-party IM systems (WeCom, DingTalk, Feishu), enabling cross-platform collaboration.</li><li>: Support for custom tool node development to meet specific business scenario requirements.</li><li><strong>Real-time Debugging and Monitoring</strong>: Providing comprehensive debugging and monitoring functions to help quickly identify and solve problems in workflows, ensuring stable operation of AI applications.</li></ul><p>As an important component of the Magic product matrix, Magic Flow can be seamlessly integrated with other Magic products to create a complete enterprise-level AI application ecosystem.</p><p>Magic IM is an enterprise-grade AI Agent conversation system designed specifically for internal knowledge management and intelligent customer service scenarios. It provides rich conversational capabilities, supporting multi-turn dialogues, context understanding, knowledge base retrieval, and other functions, allowing enterprises to quickly build intelligent customer service, knowledge assistants, and other applications.</p><p>Magic IM has the following core features:</p><ul><li><strong>Knowledge Base Management</strong>: Powerful knowledge base management functions, supporting import of various document formats, automatic indexing, and semantic retrieval, ensuring AI answers based on authentic enterprise knowledge.</li><li>: Comprehensive conversation management, supporting topic distinction for different conversation content, enabling both AI Agent conversations and communication with people within the organization.</li><li>: Powerful group chat functionality, supporting real-time collaborative discussions among multiple people, with AI intelligently participating in group chats and providing instant answers, promoting efficient team communication and knowledge sharing.</li><li><strong>Multi-organizational Architecture</strong>: Support for multi-organization deployment and strict organizational data isolation, with each organization having independent data space and access permissions.</li><li>: Strict data isolation and access control mechanisms, multi-level permission management, safeguarding sensitive enterprise information and ensuring no data leakage between organizations.</li></ul><p>Teamshare OS is a modern enterprise-grade collaborative office platform designed to enhance team collaboration efficiency and knowledge management. As an important component of the Magic product matrix, Teamshare deeply integrates AI capabilities into daily office scenarios, achieving intelligent workflows and knowledge management.</p><p>Teamshare OS has the following core features:</p><ul><li><strong>Intelligent Document Management</strong>: Support for online editing, collaboration, and version control of various document formats, AI-assisted content generation and optimization, making team document management more efficient.</li><li>: Powerful multi-dimensional data management tool, supporting custom field types, diverse views, and automated workflows, combined with AI capabilities to achieve intelligent data processing, meeting diverse data management needs.</li><li><strong>Project Collaboration Management</strong>: Intuitive project boards and task management, supporting custom workflows, combined with AI intelligent analysis to provide project progress forecasting and resource optimization suggestions.</li><li>: Powerful knowledge consolidation and retrieval system, automatically structuring internal enterprise documents to form sustainable accumulated enterprise knowledge assets.</li><li><strong>Comprehensive Integration Capability</strong>: Seamless integration with Magic product matrix, while supporting connection with mainstream office software and enterprise applications, creating a unified work platform.</li></ul><p>We provide <a href=\"https://www.letsmagic.ai\">cloud services</a> for <a href=\"https://www.letsmagic.ai\">Super Magic</a>, <a href=\"https://www.letsmagic.ai\">Magic IM</a>, and <a href=\"https://www.letsmagic.ai\">Magic Flow</a>, allowing anyone to start trying and using them with zero setup, providing all features of the open-source version. <em>Currently, an invitation code is required for access, which can be applied for online and granted for trial use after approval.</em></p><h3>Magic for Enterprises/Organizations</h3><p>We provide more powerful management capabilities and features for teams and enterprises. <a href=\"mailto:bd@dtyq.com?subject=%5BGitHub%5DBusiness%20License%20Inquiry\">Send us an email</a> to discuss enterprise needs.</p><h3>Self-hosted Community Edition</h3><ul></ul><h4>Start the System Using Docker</h4><pre><code># Clone repository\ngit clone https://github.com/dtyq/magic.git\ncd magic\n\n# Start service in foreground\n./bin/magic.sh start\n</code></pre><pre><code># Start service in background\n./bin/magic.sh daemon\n\n# Check service status\n./bin/magic.sh status\n\n# View logs\n./bin/magic.sh logs\n</code></pre><h5>Configure Environment Variables</h5><pre><code># Configure Magic environment variables, must configure at least one large language model's environment variables to use Magic normally\ncp .env.example .env\n\n# Configure Super Magic environment variables, must configure any large language model that supports OpenAI format to use it normally\n./bin/magic.sh status\ncp config/.env_super_magic.example .env_super_magic\n</code></pre><p>For those who want to contribute code, please refer to our <a href=\"https://github.com/dtyq/magic/raw/master/CONTRIBUTING.md\">Contribution Guide</a>. Also, please consider supporting Magic through social media, events, and conferences. The development of Magic relies on your support.</p><p>If you discover a security vulnerability in Magic, please send an email to the Magic official team at <a href=\"mailto:team@dtyq.com\">team@dtyq.com</a>. All security vulnerabilities will be promptly addressed.</p><p>Thanks to all developers who have contributed to Magic!</p>","contentLength":7962,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"coleam00/Archon","url":"https://github.com/coleam00/Archon","date":1755398530,"author":"","guid":230481,"unread":true,"content":"<p>Beta release of Archon OS - the knowledge and task management backbone for AI coding assistants.</p><p align=\"center\"><em>Power up your AI coding assistants with your own custom knowledge base and task management as an MCP server</em></p><blockquote><p>Archon is currently in beta! Expect things to not work 100%, and please feel free to share any feedback and contribute with fixes/new features! Thank you to everyone for all the excitement we have for Archon already, as well as the bug reports, PRs, and discussions. It's a lot for our small team to get through but we're committed to addressing everything and making Archon into the best tool it possibly can be!</p></blockquote><p>Archon is the  for AI coding assistants. For you, it's a sleek interface to manage knowledge, context, and tasks for your projects. For the AI coding assistant(s), it's a <strong>Model Context Protocol (MCP) server</strong> to collaborate on and leverage the same knowledge, context, and tasks. Connect Claude Code, Kiro, Cursor, Windsurf, etc. to give your AI agents access to:</p><ul><li> (crawled websites, uploaded PDFs/docs)</li><li><strong>Smart search capabilities</strong> with advanced RAG strategies</li><li> integrated with your knowledge base</li><li> as you add new content and collaborate with your coding assistant on tasks</li><li> coming soon to build Archon into an integrated environment for all context engineering</li></ul><p>This new vision for Archon replaces the old one (the agenteer). Archon used to be the AI agent that builds other agents, and now you can use Archon to do that and more.</p><blockquote><p>It doesn't matter what you're building or if it's a new/existing codebase - Archon's knowledge and task management capabilities will improve the output of  AI driven coding.</p></blockquote><ol><li><pre><code>git clone https://github.com/coleam00/archon.git\n</code></pre></li><li><p><strong>Environment Configuration</strong>:</p><pre><code>cp .env.example .env\n# Edit .env and add your Supabase credentials:\n# SUPABASE_URL=https://your-project.supabase.co\n# SUPABASE_SERVICE_KEY=your-service-key-here\n</code></pre><p>NOTE: Supabase introduced a new type of service key but use the legacy one (the longer one).</p><p>OPTIONAL: If you want to enable the reranking RAG strategy, uncomment lines 20-22 in <code>python\\requirements.server.txt</code>. This will significantly increase the size of the Archon Server container which is why it's off by default.</p></li><li><p>: In your <a href=\"https://supabase.com/dashboard\">Supabase project</a> SQL Editor, copy, paste, and execute the contents of <code>migration/complete_setup.sql</code></p></li><li><pre><code>docker-compose up --build -d\n</code></pre><p>This starts the core microservices:</p><ul><li>: Core API and business logic (Port: 8181)</li><li>: Protocol interface for AI clients (Port: 8051)</li><li>: AI operations and streaming (Port: 8052)</li><li>: Web interface (Port: 3737)</li></ul><p>Ports are configurable in your .env as well!</p></li><li><ul><li>Go to  â†’ Select your LLM/embedding provider and set the API key (OpenAI is default)</li><li>Test by uploading a document or crawling a website</li></ul></li></ol><h2>ğŸ”„ Database Reset (Start Fresh if Needed)</h2><p>If you need to completely reset your database and start fresh:</p><p>Once everything is running:</p><ol><li>: Knowledge Base â†’ Upload a PDF</li><li>: Projects â†’ Create a new project and add tasks</li><li><strong>Integrate with your AI coding assistant</strong>: MCP Dashboard â†’ Copy connection config for your AI coding assistant</li></ol><ul><li>: Automatically detects and crawls entire documentation sites, sitemaps, and individual pages</li><li>: Upload and process PDFs, Word docs, markdown files, and text documents with intelligent chunking</li><li>: Automatically identifies and indexes code examples from documentation for enhanced search</li><li>: Advanced semantic search with contextual embeddings for precise knowledge retrieval</li><li>: Organize knowledge by source, type, and tags for easy filtering</li></ul><ul><li><strong>Model Context Protocol (MCP)</strong>: Connect any MCP-compatible client (Claude Code, Cursor, even non-AI coding assistants like Claude Desktop)</li><li>: Comprehensive yet simple set of tools for RAG queries, task management, and project operations</li><li>: Works with OpenAI, Ollama, and Google Gemini models</li><li>: Hybrid search, contextual embeddings, and result reranking for optimal AI responses</li><li>: Live responses from AI agents with progress tracking</li></ul><h3>ğŸ“‹ Project &amp; Task Management</h3><ul><li>: Organize work with projects, features, and tasks in a structured workflow</li><li>: Generate project requirements and tasks using integrated AI agents</li><li>: Version-controlled documents with collaborative editing capabilities</li><li>: Real-time updates and status management across all project activities</li></ul><h3>ğŸ”„ Real-time Collaboration</h3><ul><li>: Live progress tracking for crawling, processing, and AI operations</li><li>: Collaborative knowledge building and project management</li><li>: Asynchronous operations that don't block the user interface</li><li>: Built-in service health checks and automatic reconnection</li></ul><p>Archon uses true microservices architecture with clear separation of concerns:</p><pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Frontend UI   â”‚    â”‚  Server (API)   â”‚    â”‚   MCP Server    â”‚    â”‚ Agents Service  â”‚\nâ”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚\nâ”‚  React + Vite   â”‚â—„â”€â”€â–ºâ”‚    FastAPI +    â”‚â—„â”€â”€â–ºâ”‚    Lightweight  â”‚â—„â”€â”€â–ºâ”‚   PydanticAI    â”‚\nâ”‚  Port 3737      â”‚    â”‚    SocketIO     â”‚    â”‚    HTTP Wrapper â”‚    â”‚   Port 8052     â”‚\nâ”‚                 â”‚    â”‚    Port 8181    â”‚    â”‚    Port 8051    â”‚    â”‚                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚                        â”‚                        â”‚                        â”‚\n         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                  â”‚                        â”‚\n                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n                         â”‚    Database     â”‚               â”‚\n                         â”‚                 â”‚               â”‚\n                         â”‚    Supabase     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                         â”‚    PostgreSQL   â”‚\n                         â”‚    PGVector     â”‚\n                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</code></pre><table><thead><tr></tr></thead><tbody><tr><td>Web interface and dashboard</td><td>React, TypeScript, TailwindCSS, Socket.IO client</td></tr><tr><td>Core business logic and APIs</td><td>FastAPI, service layer, Socket.IO broadcasts, all ML/AI operations</td></tr><tr><td>Lightweight HTTP wrapper, 10 MCP tools, session management</td></tr><tr><td>Document and RAG agents, streaming responses</td></tr></tbody></table><ul><li>: All inter-service communication uses HTTP APIs</li><li>: Real-time updates from Server to Frontend</li><li>: AI clients connect to MCP Server via SSE or stdio</li><li>: Services are truly independent with no shared code dependencies</li></ul><h3>Key Architectural Benefits</h3><ul><li>: Each service contains only required dependencies</li><li>: Services can be scaled independently based on load</li><li>: Teams can work on different services without conflicts</li><li>: Each service uses the best tools for its specific purpose</li></ul><h2>ğŸ”§ Configuring Custom Ports &amp; Hostname</h2><p>By default, Archon services run on the following ports:</p><ul><li>: 3838 (optional)</li></ul><p>To use custom ports, add these variables to your  file:</p><pre><code># Service Ports Configuration\nARCHON_UI_PORT=3737\nARCHON_SERVER_PORT=8181\nARCHON_MCP_PORT=8051\nARCHON_AGENTS_PORT=8052\nARCHON_DOCS_PORT=3838\n</code></pre><p>Example: Running on different ports:</p><pre><code>ARCHON_SERVER_PORT=8282\nARCHON_MCP_PORT=8151\n</code></pre><p>By default, Archon uses  as the hostname. You can configure a custom hostname or IP address by setting the  variable in your  file:</p><pre><code># Hostname Configuration\nHOST=localhost  # Default\n\n# Examples of custom hostnames:\nHOST=192.168.1.100     # Use specific IP address\nHOST=archon.local      # Use custom domain\nHOST=myserver.com      # Use public domain\n</code></pre><ul><li>Running Archon on a different machine and accessing it remotely</li><li>Using a custom domain name for your installation</li><li>Deploying in a network environment where  isn't accessible</li></ul><p>After changing hostname or ports:</p><ol><li>Restart Docker containers: <code>docker-compose down &amp;&amp; docker-compose up -d</code></li><li>Access the UI at: <code>http://${HOST}:${ARCHON_UI_PORT}</code></li><li>Update your AI client configuration with the new hostname and MCP port</li></ol><p>For development with hot reload:</p><pre><code># Backend services (with auto-reload)\ndocker-compose up archon-server archon-mcp archon-agents --build\n\n# Frontend (with hot reload)\ncd archon-ui-main &amp;&amp; npm run dev\n\n# Documentation (with hot reload)\ncd docs &amp;&amp; npm start\n</code></pre><p>: The backend services are configured with  flag in their uvicorn commands and have source code mounted as volumes for automatic hot reloading when you make changes.</p><p>Archon Community License (ACL) v1.2 - see <a href=\"https://raw.githubusercontent.com/coleam00/Archon/main/LICENSE\">LICENSE</a> file for details.</p><p>: Archon is free, open, and hackable. Run it, fork it, share it - just don't sell it as-a-service without permission.</p>","contentLength":8912,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"farhanashrafdev/90DaysOfCyberSecurity","url":"https://github.com/farhanashrafdev/90DaysOfCyberSecurity","date":1755398530,"author":"","guid":230482,"unread":true,"content":"<p>This repository contains a 90-day cybersecurity study plan, along with resources and materials for learning various cybersecurity concepts and technologies. The plan is organized into daily tasks, covering topics such as Network+, Security+, Linux, Python, Traffic Analysis, Git, ELK, AWS, Azure, and Hacking. The repository also includes a `LEARN.md</p><p>Welcome to the  challenge! This repository provides a structured, 90-day self-paced study plan designed to help learners build a strong foundation in cybersecurity. Whether you're a beginner looking to break into the field or a professional aiming to sharpen your skills, this roadmap offers a wide range of curated resources, hands-on tasks, and learning materials.</p><p>The daily modules cover essential and advanced topics, including:</p><ul><li>Networking fundamentals (Network+)</li><li>Security principles (Security+)</li><li>Linux basics and shell scripting</li><li>Python programming for security tasks</li><li>Traffic analysis and packet inspection</li><li>SIEM tools and log analysis using the ELK stack</li><li>Cloud security with GCP, AWS and Azure</li><li>Penetration testing and ethical hacking</li></ul><p>Each day is designed with actionable tasks, tutorials, and reading materials to help you stay on track. For a full list of resources, refer to <a href=\"https://raw.githubusercontent.com/farhanashrafdev/90DaysOfCyberSecurity/main/LEARN.md\"></a>.</p><p>The primary goal of this 90-day plan is to help learners:</p><ul><li>Build a solid foundation in core cybersecurity concepts and practices.</li><li>Gain hands-on experience through daily exercises and real-world tools.</li><li>Develop the technical skills necessary for certifications such as CompTIA Network+ and Security+.</li><li>Explore key domains including network security, system hardening, cloud security, scripting, and ethical hacking.</li><li>Cultivate a consistent learning habit over 90 days to support long-term retention and growth.</li></ul><p>By the end of this journey, you should feel confident navigating a variety of cybersecurity tools, concepts, and techniques.</p><p>This repository is ideal for:</p><ul><li><strong>Aspiring cybersecurity professionals</strong> preparing for entry-level roles or certifications.</li><li> transitioning into a security-focused career.</li><li> studying computer science, information systems, or network engineering.</li><li> seeking a structured and comprehensive study plan.</li><li><strong>Developers and DevOps engineers</strong> looking to better understand secure infrastructure and threat detection.</li><li> about how cybersecurity works in real-world environments.</li></ul><p>No prior experience is required, though basic familiarity with computers, networks, or programming will be helpful.</p><ul><li>Complete any related practice questions or exercises.</li></ul><h3>Strongly Recommend Professor Messer's:</h3><h3>Another Alternative You Can Use:</h3><ul><li>Complete any related practice questions or exercises.</li></ul><h2>Day 43-56: Traffic Analysis</h2><h2>Day 71-77: Cloud Platforms</h2><h2>Any one of them works fine.</h2><h2>Day 91-92: One Page Resume</h2><h2>Day 93-95: Where and How to Apply</h2><p>Thank you for being a part of the 90DaysOfCyberSecurity community! We appreciate everyone who helps improve our content.</p><ul><li>: Improve or add to the study material and guides.</li><li>: Create or enhance tutorials explaining complex concepts.</li><li>: Recommend useful tools, articles, books, or other resources.</li><li>: Suggest new topics to be added to the learning materials.</li><li>: Provide feedback on existing materials and suggest improvements.</li><li>: Answer questions and help others in discussions or issues.</li><li>: Add quizzes, challenges, or tests to check learning progress.</li><li>: Share real-life examples or case studies of cybersecurity practices.</li><li>: Help others with study advice, tips, or hosting study sessions.</li></ul><p>Thank you to all contributors for your amazing work! ğŸ‰</p><p>Thanks goes to these wonderful people (<a href=\"https://allcontributors.org/docs/en/emoji-key\">emoji key</a>):</p><p>This project follows the <a href=\"https://github.com/all-contributors/all-contributors\">all-contributors</a> specification. Contributions of any kind welcome!</p>","contentLength":3593,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"codecrafters-io/build-your-own-x","url":"https://github.com/codecrafters-io/build-your-own-x","date":1755398530,"author":"","guid":230483,"unread":true,"content":"<p><em>What I cannot create, I do not understand â€” Richard Feynman.</em></p>","contentLength":62,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"tsoding/nob.h","url":"https://github.com/tsoding/nob.h","date":1755398530,"author":"","guid":230484,"unread":true,"content":"<p>Header only library for writing build recipes in C.</p><p>This library is the next generation of the NoBuild idea. \"nob\" stands for \"nobuild\", but it's shorter and more suitable as a prefix for a library.</p><p>The idea is that you should not need anything but a C compiler to build a C project. No make, no cmake, no shell, no cmd, no PowerShell etc. Only C compiler. So with the C compiler you bootstrap your build system and then you use the build system to build everything else.</p><h2>This is an Experimental Project</h2><p>I'm not sure if this is even a good idea myself. This is why I'm implementing it. This is a research project. I'm not making any claims about suitability of this approach to any project.</p><h2>It's likely Not Suitable for Your Project</h2><p>If you are using <a href=\"https://cmake.org/\">cmake</a> with tons of modules to manage and find tons of dependencies you probably don't want to use this tool. (But in that case I personally think you have much bigger problem than a build system). NoBuild is more like writting shell scripts but in C.</p><ul><li>Extremely portable builds across variety of systems including (but not limited to) Linux, MacOS, Windows, FreeBSD, etc. This is achieved by reducing the amount of dependencies to just a C compiler, which exists pretty much for any platform these days.</li><li>You end up using the same language for developing and building your project. Which may enable some interesting code reusage strategies. The build system can use the code of the project itself directly and the project can use the code of the build system also directly.</li></ul><ul><li>You need to be comfortable with C and implementing things yourself. As mentioned above this is like writing shell scripts but in C.</li><li>It probably does not make any sense outside of C/C++ projects.</li></ul><h2>Why is it called \"nobuild\" when it's clearly a build tool?</h2><p>You know all these BS movements that supposedly remove the root cause of your problems? Things like <a href=\"https://en.wikipedia.org/wiki/NoSQL\">NoSQL</a>, <a href=\"https://en.wikipedia.org/wiki/No-code_development_platform\">No-code</a>, <a href=\"https://en.wikipedia.org/wiki/Serverless_computing\">Serverless</a>, etc. This is the same logic. I had too many problems with the process of building C projects. So there is nobuild anymore.</p><h2>How to use the library in your own project</h2><p>The only file you need from here is <a href=\"https://raw.githubusercontent.com/tsoding/nob.h/refs/heads/main/nob.h\">nob.h</a>. Just copy-paste it to your project and start using it. See <a href=\"https://raw.githubusercontent.com/tsoding/nob.h/main/how_to/\">how_to/</a> folder for examples.</p><h2>NoBuild in Other Languages</h2><p>This is obviously applicable not only to C. You can implement the same kind of approach for other languages (apart from the languages that support this natively, of course). Here is few examples in the wild:</p><p><em>Feel free to contribute more</em></p>","contentLength":2447,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["trending"]}