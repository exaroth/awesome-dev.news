{"id":"KWcVEiwEzuiDsTqLn6LojC9X2yBX45N36DRtYHsFby6oiM4t597YhKBSdxr5wqMdj8kvSgDuiUuV6yvogw","title":"GitHub All Languages Daily Trending","displayTitle":"Github Trending","url":"https://mshibanami.github.io/GitHubTrendingRSS/daily/all.xml","feedLink":"http://mshibanami.github.io/GitHubTrendingRSS","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":28,"items":[{"title":"Shubhamsaboo/awesome-llm-apps","url":"https://github.com/Shubhamsaboo/awesome-llm-apps","date":1739759302,"author":"","guid":861,"unread":true,"content":"<p>Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p><p>A curated collection of awesome LLM apps built with RAG and AI agents. This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.</p><ul><li>üí° Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.</li><li>üî• Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with RAG and AI Agents.</li><li>üéì Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.</li></ul><h3>RAG (Retrieval Augmented Generation)</h3><h3>Advanced Tools and Frameworks</h3><ol><li><pre><code>git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git \n</code></pre></li><li><p><strong>Navigate to the desired project directory</strong></p><pre><code>cd awesome-llm-apps/chat_with_X_tutorials/chat_with_gmail\n</code></pre></li><li><p><strong>Install the required dependencies</strong></p><pre><code>pip install -r requirements.txt\n</code></pre></li><li><p><strong>Follow the project-specific instructions</strong> in each project's  file to set up and run the app.</p></li></ol><h2>ü§ù Contributing to Open Source</h2><p>Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new <a href=\"https://github.com/Shubhamsaboo/awesome-llm-apps/issues\">GitHub Issue</a> or submit a pull request. Make sure to follow the existing project structure and include a detailed  for each new app.</p><h3>Thank You, Community, for the Support! üôè</h3><p>üåü <strong>Don‚Äôt miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.</strong></p>","contentLength":1566,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"yt-dlp/yt-dlp","url":"https://github.com/yt-dlp/yt-dlp","date":1739759302,"author":"","guid":862,"unread":true,"content":"<p>A feature-rich command-line audio/video downloader</p><p>You can install yt-dlp using <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files\">the binaries</a>, <a href=\"https://pypi.org/project/yt-dlp\">pip</a> or one using a third-party package manager. See <a href=\"https://github.com/yt-dlp/yt-dlp/wiki/Installation\">the wiki</a> for detailed instructions</p><table><tbody><tr><td align=\"left\">Platform-independent <a href=\"https://docs.python.org/3/library/zipimport.html\">zipimport</a> binary. Needs Python (recommended for )</td></tr><tr><td align=\"left\">Windows (Win8+) standalone x64 binary (recommended for )</td></tr><tr><td align=\"left\">Universal MacOS (10.15+) standalone executable (recommended for )</td></tr></tbody></table><p>The public key that can be used to verify the GPG signatures is <a href=\"https://github.com/yt-dlp/yt-dlp/raw/master/public.key\">available here</a> Example usage:</p><pre><code>curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import\ngpg --verify SHA2-256SUMS.sig SHA2-256SUMS\ngpg --verify SHA2-512SUMS.sig SHA2-512SUMS\n</code></pre><p>: The manpages, shell completion (autocomplete) files etc. are available inside the <a href=\"https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz\">source tarball</a></p><p>If you <a href=\"https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip\">installed with pip</a>, simply re-run the same command that was used to install the program</p><p>For other third-party package managers, see <a href=\"https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers\">the wiki</a> or refer to their documentation</p><p>There are currently three release channels for binaries: ,  and .</p><ul><li> is the default channel, and many of its changes have been tested by users of the  and  channels.</li><li>The  channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project's new patches and changes. This is the <strong>recommended channel for regular users</strong> of yt-dlp. The  releases are available from <a href=\"https://github.com/yt-dlp/yt-dlp-nightly-builds/releases\">yt-dlp/yt-dlp-nightly-builds</a> or as development releases of the  PyPI package (which can be installed with pip's  flag).</li><li>The  channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from <a href=\"https://github.com/yt-dlp/yt-dlp-master-builds/releases\">yt-dlp/yt-dlp-master-builds</a>.</li></ul><p>When using /, a release binary will only update to its current channel.  can be used to switch to a different channel when a newer version is available. <code>--update-to [CHANNEL@]TAG</code> can also be used to upgrade or downgrade to specific tags from a channel.</p><p>You may also use  () to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.</p><ul><li><code>yt-dlp --update-to master</code> switch to the  channel and update to its latest release</li><li><code>yt-dlp --update-to stable@2023.07.06</code> upgrade/downgrade to release to  channel tag </li><li><code>yt-dlp --update-to 2023.10.07</code> upgrade/downgrade to tag  if it exists on the current channel</li><li><code>yt-dlp --update-to example/yt-dlp@2023.09.24</code> upgrade/downgrade to the release from the  repository, tag </li></ul><p>: Any user experiencing an issue with the  release should install or update to the  release before submitting a bug report:</p><pre><code># To update to nightly from stable executable/binary:\nyt-dlp --update-to nightly\n\n# To install nightly with pip:\npython3 -m pip install -U --pre \"yt-dlp[default]\"\n</code></pre><p>Python versions 3.9+ (CPython) and 3.10+ (PyPy) are supported. Other versions and implementations may or may not work correctly.</p><p>While all the other dependencies are optional,  and  are highly recommended</p><p>The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.</p><ul><li><a href=\"https://github.com/lexiforest/curl_cffi\"></a> (recommended) - Python binding for <a href=\"https://github.com/lexiforest/curl-impersonate\">curl-impersonate</a>. Provides impersonation targets for Chrome, Edge and Safari. Licensed under <a href=\"https://github.com/lexiforest/curl_cffi/raw/main/LICENSE\">MIT</a><ul><li>Can be installed with the  group, e.g. <code>pip install \"yt-dlp[default,curl-cffi]\"</code></li><li>Currently included in ,  and  builds</li></ul></li></ul><ul><li><a href=\"https://github.com/mitya57/secretstorage\"></a>* - For  to access the  keyring while decrypting cookies of -based browsers on . Licensed under <a href=\"https://github.com/mitya57/secretstorage/raw/master/LICENSE\">BSD-3-Clause</a></li><li>Any external downloader that you want to use with </li></ul><p>To use or redistribute the dependencies, you must agree to their respective licensing terms.</p><p>The standalone release binaries are built with the Python interpreter and the packages marked with  included.</p><p>If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the  output</p><h3>Standalone PyInstaller Builds</h3><p>To build the standalone executable, you must have Python and  (plus any of yt-dlp's <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies\">optional dependencies</a> if needed). The executable will be built for the same CPU architecture as the Python used.</p><p>You can run the following commands:</p><pre><code>python3 devscripts/install_deps.py --include pyinstaller\npython3 devscripts/make_lazy_extractors.py\npython3 -m bundle.pyinstaller\n</code></pre><p>On some systems, you may need to use  or  instead of .</p><p><code>python -m bundle.pyinstaller</code> accepts any arguments that can be passed to , such as  or , which is further <a href=\"https://pyinstaller.org/en/stable/usage.html#what-to-generate\">documented here</a>.</p><p>: Pyinstaller versions below 4.4 <a href=\"https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms\">do not support</a> Python installed from the Windows store without using a virtual environment.</p><p>: Running  directly  using <code>python -m bundle.pyinstaller</code> is  officially supported. This may or may not work correctly.</p><h3>Platform-independent Binary (UNIX)</h3><p>You will need the build tools  (3.9+), ,  (GNU), * and *.</p><p>After installing these, simply run .</p><p>You can also run  instead to compile only the binary without updating any of the additional files. (The build tools marked with  are not needed for this)</p><ul><li><strong><code>devscripts/install_deps.py</code></strong> - Install dependencies for yt-dlp.</li><li><strong><code>devscripts/update-version.py</code></strong> - Update the version number based on the current date.</li><li><strong><code>devscripts/set-variant.py</code></strong> - Set the build variant of the executable.</li><li><strong><code>devscripts/make_changelog.py</code></strong> - Create a markdown changelog using short commit messages and update  file.</li><li><strong><code>devscripts/make_lazy_extractors.py</code></strong> - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable  to something nonempty to forcefully disable lazy extractor loading.</li></ul><p>Note: See their  for more info.</p><p>If you fork the project on GitHub, you can run your fork's <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/build.yml\">build workflow</a> to automatically build the selected version(s) as artifacts. Alternatively, you can run the <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release.yml\">release workflow</a> or enable the <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release-nightly.yml\">nightly workflow</a> to create full (pre-)releases.</p><pre><code>yt-dlp [OPTIONS] [--] URL [URL...]\n</code></pre><pre><code>-h, --help                      Print this help text and exit\n--version                       Print program version and exit\n-U, --update                    Update this program to the latest version\n--no-update                     Do not check for updates (default)\n--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.\n                                CHANNEL can be a repository as well. CHANNEL\n                                and TAG default to \"stable\" and \"latest\"\n                                respectively if omitted; See \"UPDATE\" for\n                                details. Supported channels: stable,\n                                nightly, master\n-i, --ignore-errors             Ignore download and postprocessing errors.\n                                The download will be considered successful\n                                even if the postprocessing fails\n--no-abort-on-error             Continue with next video on download errors;\n                                e.g. to skip unavailable videos in a\n                                playlist (default)\n--abort-on-error                Abort downloading of further videos if an\n                                error occurs (Alias: --no-ignore-errors)\n--dump-user-agent               Display the current user-agent and exit\n--list-extractors               List all supported extractors and exit\n--extractor-descriptions        Output descriptions of all supported\n                                extractors and exit\n--use-extractors NAMES          Extractor names to use separated by commas.\n                                You can also use regexes, \"all\", \"default\"\n                                and \"end\" (end URL matching); e.g. --ies\n                                \"holodex.*,end,youtube\". Prefix the name\n                                with a \"-\" to exclude it, e.g. --ies\n                                default,-generic. Use --list-extractors for\n                                a list of extractor names. (Alias: --ies)\n--default-search PREFIX         Use this prefix for unqualified URLs. E.g.\n                                \"gvsearch2:python\" downloads two videos from\n                                google videos for the search term \"python\".\n                                Use the value \"auto\" to let yt-dlp guess\n                                (\"auto_warning\" to emit a warning when\n                                guessing). \"error\" just throws an error. The\n                                default value \"fixup_error\" repairs broken\n                                URLs, but emits an error if this is not\n                                possible instead of searching\n--ignore-config                 Don't load any more configuration files\n                                except those given to --config-locations.\n                                For backward compatibility, if this option\n                                is found inside the system configuration\n                                file, the user configuration is not loaded.\n                                (Alias: --no-config)\n--no-config-locations           Do not load any custom configuration files\n                                (default). When given inside a configuration\n                                file, ignore all previous --config-locations\n                                defined in the current file\n--config-locations PATH         Location of the main configuration file;\n                                either the path to the config or its\n                                containing directory (\"-\" for stdin). Can be\n                                used multiple times and inside other\n                                configuration files\n--plugin-dirs PATH              Path to an additional directory to search\n                                for plugins. This option can be used\n                                multiple times to add multiple directories.\n                                Note that this currently only works for\n                                extractor plugins; postprocessor plugins can\n                                only be loaded from the default plugin\n                                directories\n--flat-playlist                 Do not extract a playlist's URL result\n                                entries; some entry metadata may be missing\n                                and downloading may be bypassed\n--no-flat-playlist              Fully extract the videos of a playlist\n                                (default)\n--live-from-start               Download livestreams from the start.\n                                Currently only supported for YouTube\n                                (Experimental)\n--no-live-from-start            Download livestreams from the current time\n                                (default)\n--wait-for-video MIN[-MAX]      Wait for scheduled streams to become\n                                available. Pass the minimum number of\n                                seconds (or range) to wait between retries\n--no-wait-for-video             Do not wait for scheduled streams (default)\n--mark-watched                  Mark videos watched (even with --simulate)\n--no-mark-watched               Do not mark videos watched (default)\n--color [STREAM:]POLICY         Whether to emit color codes in output,\n                                optionally prefixed by the STREAM (stdout or\n                                stderr) to apply the setting to. Can be one\n                                of \"always\", \"auto\" (default), \"never\", or\n                                \"no_color\" (use non color terminal\n                                sequences). Use \"auto-tty\" or \"no_color-tty\"\n                                to decide based on terminal support only.\n                                Can be used multiple times\n--compat-options OPTS           Options that can help keep compatibility\n                                with youtube-dl or youtube-dlc\n                                configurations by reverting some of the\n                                changes made in yt-dlp. See \"Differences in\n                                default behavior\" for details\n--alias ALIASES OPTIONS         Create aliases for an option string. Unless\n                                an alias starts with a dash \"-\", it is\n                                prefixed with \"--\". Arguments are parsed\n                                according to the Python string formatting\n                                mini-language. E.g. --alias get-audio,-X\n                                \"-S=aext:{0},abr -x --audio-format {0}\"\n                                creates options \"--get-audio\" and \"-X\" that\n                                takes an argument (ARG0) and expands to\n                                \"-S=aext:ARG0,abr -x --audio-format ARG0\".\n                                All defined aliases are listed in the --help\n                                output. Alias options can trigger more\n                                aliases; so be careful to avoid defining\n                                recursive options. As a safety measure, each\n                                alias may be triggered a maximum of 100\n                                times. This option can be used multiple times\n</code></pre><pre><code>--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To\n                                enable SOCKS proxy, specify a proper scheme,\n                                e.g. socks5://user:pass@127.0.0.1:1080/.\n                                Pass in an empty string (--proxy \"\") for\n                                direct connection\n--socket-timeout SECONDS        Time to wait before giving up, in seconds\n--source-address IP             Client-side IP address to bind to\n--impersonate CLIENT[:OS]       Client to impersonate for requests. E.g.\n                                chrome, chrome-110, chrome:windows-10. Pass\n                                --impersonate=\"\" to impersonate any client.\n                                Note that forcing impersonation for all\n                                requests may have a detrimental impact on\n                                download speed and stability\n--list-impersonate-targets      List available clients to impersonate.\n-4, --force-ipv4                Make all connections via IPv4\n-6, --force-ipv6                Make all connections via IPv6\n--enable-file-urls              Enable file:// URLs. This is disabled by\n                                default for security reasons.\n</code></pre><pre><code>--geo-verification-proxy URL    Use this proxy to verify the IP address for\n                                some geo-restricted sites. The default proxy\n                                specified by --proxy (or none, if the option\n                                is not present) is used for the actual\n                                downloading\n--xff VALUE                     How to fake X-Forwarded-For HTTP header to\n                                try bypassing geographic restriction. One of\n                                \"default\" (only when known to be useful),\n                                \"never\", an IP block in CIDR notation, or a\n                                two-letter ISO 3166-2 country code\n</code></pre><pre><code>-I, --playlist-items ITEM_SPEC  Comma separated playlist_index of the items\n                                to download. You can specify a range using\n                                \"[START]:[STOP][:STEP]\". For backward\n                                compatibility, START-STOP is also supported.\n                                Use negative indices to count from the right\n                                and negative STEP to download in reverse\n                                order. E.g. \"-I 1:3,7,-5::2\" used on a\n                                playlist of size 15 will download the items\n                                at index 1,2,3,7,11,13,15\n--min-filesize SIZE             Abort download if filesize is smaller than\n                                SIZE, e.g. 50k or 44.6M\n--max-filesize SIZE             Abort download if filesize is larger than\n                                SIZE, e.g. 50k or 44.6M\n--date DATE                     Download only videos uploaded on this date.\n                                The date can be \"YYYYMMDD\" or in the format \n                                [now|today|yesterday][-N[day|week|month|year]].\n                                E.g. \"--date today-2weeks\" downloads only\n                                videos uploaded on the same day two weeks ago\n--datebefore DATE               Download only videos uploaded on or before\n                                this date. The date formats accepted are the\n                                same as --date\n--dateafter DATE                Download only videos uploaded on or after\n                                this date. The date formats accepted are the\n                                same as --date\n--match-filters FILTER          Generic video filter. Any \"OUTPUT TEMPLATE\"\n                                field can be compared with a number or a\n                                string using the operators defined in\n                                \"Filtering Formats\". You can also simply\n                                specify a field to match if the field is\n                                present, use \"!field\" to check if the field\n                                is not present, and \"&amp;\" to check multiple\n                                conditions. Use a \"\\\" to escape \"&amp;\" or\n                                quotes if needed. If used multiple times,\n                                the filter matches if at least one of the\n                                conditions is met. E.g. --match-filters\n                                !is_live --match-filters \"like_count&gt;?100 &amp;\n                                description~='(?i)\\bcats \\&amp; dogs\\b'\" matches\n                                only videos that are not live OR those that\n                                have a like count more than 100 (or the like\n                                field is not available) and also has a\n                                description that contains the phrase \"cats &amp;\n                                dogs\" (caseless). Use \"--match-filters -\" to\n                                interactively ask whether to download each\n                                video\n--no-match-filters              Do not use any --match-filters (default)\n--break-match-filters FILTER    Same as \"--match-filters\" but stops the\n                                download process when a video is rejected\n--no-break-match-filters        Do not use any --break-match-filters (default)\n--no-playlist                   Download only the video, if the URL refers\n                                to a video and a playlist\n--yes-playlist                  Download the playlist, if the URL refers to\n                                a video and a playlist\n--age-limit YEARS               Download only videos suitable for the given\n                                age\n--download-archive FILE         Download only videos not listed in the\n                                archive file. Record the IDs of all\n                                downloaded videos in it\n--no-download-archive           Do not use archive file (default)\n--max-downloads NUMBER          Abort after downloading NUMBER files\n--break-on-existing             Stop the download process when encountering\n                                a file that is in the archive supplied with\n                                the --download-archive option\n--no-break-on-existing          Do not stop the download process when\n                                encountering a file that is in the archive\n                                (default)\n--break-per-input               Alters --max-downloads, --break-on-existing,\n                                --break-match-filters, and autonumber to\n                                reset per input URL\n--no-break-per-input            --break-on-existing and similar options\n                                terminates the entire download queue\n--skip-playlist-after-errors N  Number of allowed failures until the rest of\n                                the playlist is skipped\n</code></pre><pre><code>-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative\n                                video that should be downloaded concurrently\n                                (default is 1)\n-r, --limit-rate RATE           Maximum download rate in bytes per second,\n                                e.g. 50K or 4.2M\n--throttled-rate RATE           Minimum download rate in bytes per second\n                                below which throttling is assumed and the\n                                video data is re-extracted, e.g. 100K\n-R, --retries RETRIES           Number of retries (default is 10), or\n                                \"infinite\"\n--file-access-retries RETRIES   Number of times to retry on file access\n                                error (default is 3), or \"infinite\"\n--fragment-retries RETRIES      Number of retries for a fragment (default is\n                                10), or \"infinite\" (DASH, hlsnative and ISM)\n--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds\n                                (optionally) prefixed by the type of retry\n                                (http (default), fragment, file_access,\n                                extractor) to apply the sleep to. EXPR can\n                                be a number, linear=START[:END[:STEP=1]] or\n                                exp=START[:END[:BASE=2]]. This option can be\n                                used multiple times to set the sleep for the\n                                different retry types, e.g. --retry-sleep\n                                linear=1::2 --retry-sleep fragment:exp=1:20\n--skip-unavailable-fragments    Skip unavailable fragments for DASH,\n                                hlsnative and ISM downloads (default)\n                                (Alias: --no-abort-on-unavailable-fragments)\n--abort-on-unavailable-fragments\n                                Abort download if a fragment is unavailable\n                                (Alias: --no-skip-unavailable-fragments)\n--keep-fragments                Keep downloaded fragments on disk after\n                                downloading is finished\n--no-keep-fragments             Delete downloaded fragments after\n                                downloading is finished (default)\n--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K\n                                (default is 1024)\n--resize-buffer                 The buffer size is automatically resized\n                                from an initial value of --buffer-size\n                                (default)\n--no-resize-buffer              Do not automatically adjust the buffer size\n--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP\n                                downloading, e.g. 10485760 or 10M (default\n                                is disabled). May be useful for bypassing\n                                bandwidth throttling imposed by a webserver\n                                (experimental)\n--playlist-random               Download playlist videos in random order\n--lazy-playlist                 Process entries in the playlist as they are\n                                received. This disables n_entries,\n                                --playlist-random and --playlist-reverse\n--no-lazy-playlist              Process videos in the playlist only after\n                                the entire playlist is parsed (default)\n--xattr-set-filesize            Set file xattribute ytdl.filesize with\n                                expected file size\n--hls-use-mpegts                Use the mpegts container for HLS videos;\n                                allowing some players to play the video\n                                while downloading, and reducing the chance\n                                of file corruption if download is\n                                interrupted. This is enabled by default for\n                                live streams\n--no-hls-use-mpegts             Do not use the mpegts container for HLS\n                                videos. This is default when not downloading\n                                live streams\n--download-sections REGEX       Download only chapters that match the\n                                regular expression. A \"*\" prefix denotes\n                                time-range instead of chapter. Negative\n                                timestamps are calculated from the end.\n                                \"*from-url\" can be used to download between\n                                the \"start_time\" and \"end_time\" extracted\n                                from the URL. Needs ffmpeg. This option can\n                                be used multiple times to download multiple\n                                sections, e.g. --download-sections\n                                \"*10:15-inf\" --download-sections \"intro\"\n--downloader [PROTO:]NAME       Name or path of the external downloader to\n                                use (optionally) prefixed by the protocols\n                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to\n                                use it for. Currently supports native,\n                                aria2c, avconv, axel, curl, ffmpeg, httpie,\n                                wget. You can use this option multiple times\n                                to set different downloaders for different\n                                protocols. E.g. --downloader aria2c\n                                --downloader \"dash,m3u8:native\" will use\n                                aria2c for http/ftp downloads, and the\n                                native downloader for dash/m3u8 downloads\n                                (Alias: --external-downloader)\n--downloader-args NAME:ARGS     Give these arguments to the external\n                                downloader. Specify the downloader name and\n                                the arguments separated by a colon \":\". For\n                                ffmpeg, arguments can be passed to different\n                                positions using the same syntax as\n                                --postprocessor-args. You can use this\n                                option multiple times to give different\n                                arguments to different downloaders (Alias:\n                                --external-downloader-args)\n</code></pre><pre><code>-a, --batch-file FILE           File containing URLs to download (\"-\" for\n                                stdin), one URL per line. Lines starting\n                                with \"#\", \";\" or \"]\" are considered as\n                                comments and ignored\n--no-batch-file                 Do not read URLs from batch file (default)\n-P, --paths [TYPES:]PATH        The paths where the files should be\n                                downloaded. Specify the type of file and the\n                                path separated by a colon \":\". All the same\n                                TYPES as --output are supported.\n                                Additionally, you can also provide \"home\"\n                                (default) and \"temp\" paths. All intermediary\n                                files are first downloaded to the temp path\n                                and then the final files are moved over to\n                                the home path after download is finished.\n                                This option is ignored if --output is an\n                                absolute path\n-o, --output [TYPES:]TEMPLATE   Output filename template; see \"OUTPUT\n                                TEMPLATE\" for details\n--output-na-placeholder TEXT    Placeholder for unavailable fields in\n                                --output (default: \"NA\")\n--restrict-filenames            Restrict filenames to only ASCII characters,\n                                and avoid \"&amp;\" and spaces in filenames\n--no-restrict-filenames         Allow Unicode characters, \"&amp;\" and spaces in\n                                filenames (default)\n--windows-filenames             Force filenames to be Windows-compatible\n--no-windows-filenames          Sanitize filenames only minimally\n--trim-filenames LENGTH         Limit the filename length (excluding\n                                extension) to the specified number of\n                                characters\n-w, --no-overwrites             Do not overwrite any files\n--force-overwrites              Overwrite all video and metadata files. This\n                                option includes --no-continue\n--no-force-overwrites           Do not overwrite the video, but overwrite\n                                related files (default)\n-c, --continue                  Resume partially downloaded files/fragments\n                                (default)\n--no-continue                   Do not resume partially downloaded\n                                fragments. If the file is not fragmented,\n                                restart download of the entire file\n--part                          Use .part files instead of writing directly\n                                into output file (default)\n--no-part                       Do not use .part files - write directly into\n                                output file\n--mtime                         Use the Last-modified header to set the file\n                                modification time (default)\n--no-mtime                      Do not use the Last-modified header to set\n                                the file modification time\n--write-description             Write video description to a .description file\n--no-write-description          Do not write video description (default)\n--write-info-json               Write video metadata to a .info.json file\n                                (this may contain personal information)\n--no-write-info-json            Do not write video metadata (default)\n--write-playlist-metafiles      Write playlist metadata in addition to the\n                                video metadata when using --write-info-json,\n                                --write-description etc. (default)\n--no-write-playlist-metafiles   Do not write playlist metadata when using\n                                --write-info-json, --write-description etc.\n--clean-info-json               Remove some internal metadata such as\n                                filenames from the infojson (default)\n--no-clean-info-json            Write all fields to the infojson\n--write-comments                Retrieve video comments to be placed in the\n                                infojson. The comments are fetched even\n                                without this option if the extraction is\n                                known to be quick (Alias: --get-comments)\n--no-write-comments             Do not retrieve video comments unless the\n                                extraction is known to be quick (Alias:\n                                --no-get-comments)\n--load-info-json FILE           JSON file containing the video information\n                                (created with the \"--write-info-json\" option)\n--cookies FILE                  Netscape formatted file to read cookies from\n                                and dump cookie jar in\n--no-cookies                    Do not read/dump cookies from/to file\n                                (default)\n--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]\n                                The name of the browser to load cookies\n                                from. Currently supported browsers are:\n                                brave, chrome, chromium, edge, firefox,\n                                opera, safari, vivaldi, whale. Optionally,\n                                the KEYRING used for decrypting Chromium\n                                cookies on Linux, the name/path of the\n                                PROFILE to load cookies from, and the\n                                CONTAINER name (if Firefox) (\"none\" for no\n                                container) can be given with their\n                                respective separators. By default, all\n                                containers of the most recently accessed\n                                profile are used. Currently supported\n                                keyrings are: basictext, gnomekeyring,\n                                kwallet, kwallet5, kwallet6\n--no-cookies-from-browser       Do not load cookies from browser (default)\n--cache-dir DIR                 Location in the filesystem where yt-dlp can\n                                store some downloaded information (such as\n                                client ids and signatures) permanently. By\n                                default ${XDG_CACHE_HOME}/yt-dlp\n--no-cache-dir                  Disable filesystem caching\n--rm-cache-dir                  Delete all filesystem cache files\n</code></pre><pre><code>--write-thumbnail               Write thumbnail image to disk\n--no-write-thumbnail            Do not write thumbnail image to disk (default)\n--write-all-thumbnails          Write all thumbnail image formats to disk\n--list-thumbnails               List available thumbnails of each video.\n                                Simulate unless --no-simulate is used\n</code></pre><h2>Internet Shortcut Options:</h2><pre><code>--write-link                    Write an internet shortcut file, depending\n                                on the current platform (.url, .webloc or\n                                .desktop). The URL may be cached by the OS\n--write-url-link                Write a .url Windows internet shortcut. The\n                                OS caches the URL based on the file path\n--write-webloc-link             Write a .webloc macOS internet shortcut\n--write-desktop-link            Write a .desktop Linux internet shortcut\n</code></pre><h2>Verbosity and Simulation Options:</h2><pre><code>-q, --quiet                     Activate quiet mode. If used with --verbose,\n                                print the log to stderr\n--no-quiet                      Deactivate quiet mode. (Default)\n--no-warnings                   Ignore warnings\n-s, --simulate                  Do not download the video and do not write\n                                anything to disk\n--no-simulate                   Download the video even if printing/listing\n                                options are used\n--ignore-no-formats-error       Ignore \"No video formats\" error. Useful for\n                                extracting metadata even if the videos are\n                                not actually available for download\n                                (experimental)\n--no-ignore-no-formats-error    Throw error when no downloadable video\n                                formats are found (default)\n--skip-download                 Do not download the video but write all\n                                related files (Alias: --no-download)\n-O, --print [WHEN:]TEMPLATE     Field name or output template to print to\n                                screen, optionally prefixed with when to\n                                print it, separated by a \":\". Supported\n                                values of \"WHEN\" are the same as that of\n                                --use-postprocessor (default: video).\n                                Implies --quiet. Implies --simulate unless\n                                --no-simulate or later stages of WHEN are\n                                used. This option can be used multiple times\n--print-to-file [WHEN:]TEMPLATE FILE\n                                Append given template to the file. The\n                                values of WHEN and TEMPLATE are the same as\n                                that of --print. FILE uses the same syntax\n                                as the output template. This option can be\n                                used multiple times\n-j, --dump-json                 Quiet, but print JSON information for each\n                                video. Simulate unless --no-simulate is\n                                used. See \"OUTPUT TEMPLATE\" for a\n                                description of available keys\n-J, --dump-single-json          Quiet, but print JSON information for each\n                                URL or infojson passed. Simulate unless\n                                --no-simulate is used. If the URL refers to\n                                a playlist, the whole playlist information\n                                is dumped in a single line\n--force-write-archive           Force download archive entries to be written\n                                as far as no errors occur, even if -s or\n                                another simulation option is used (Alias:\n                                --force-download-archive)\n--newline                       Output progress bar as new lines\n--no-progress                   Do not print progress bar\n--progress                      Show progress bar, even if in quiet mode\n--console-title                 Display progress in console titlebar\n--progress-template [TYPES:]TEMPLATE\n                                Template for progress outputs, optionally\n                                prefixed with one of \"download:\" (default),\n                                \"download-title:\" (the console title),\n                                \"postprocess:\",  or \"postprocess-title:\".\n                                The video's fields are accessible under the\n                                \"info\" key and the progress attributes are\n                                accessible under \"progress\" key. E.g.\n                                --console-title --progress-template\n                                \"download-title:%(info.id)s-%(progress.eta)s\"\n--progress-delta SECONDS        Time between progress output (default: 0)\n-v, --verbose                   Print various debugging information\n--dump-pages                    Print downloaded pages encoded using base64\n                                to debug problems (very verbose)\n--write-pages                   Write downloaded intermediary pages to files\n                                in the current directory to debug problems\n--print-traffic                 Display sent and read HTTP traffic\n</code></pre><pre><code>--encoding ENCODING             Force the specified encoding (experimental)\n--legacy-server-connect         Explicitly allow HTTPS connection to servers\n                                that do not support RFC 5746 secure\n                                renegotiation\n--no-check-certificates         Suppress HTTPS certificate validation\n--prefer-insecure               Use an unencrypted connection to retrieve\n                                information about the video (Currently\n                                supported only for YouTube)\n--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,\n                                separated by a colon \":\". You can use this\n                                option multiple times\n--bidi-workaround               Work around terminals that lack\n                                bidirectional text support. Requires bidiv\n                                or fribidi executable in PATH\n--sleep-requests SECONDS        Number of seconds to sleep between requests\n                                during data extraction\n--sleep-interval SECONDS        Number of seconds to sleep before each\n                                download. This is the minimum time to sleep\n                                when used along with --max-sleep-interval\n                                (Alias: --min-sleep-interval)\n--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only\n                                be used along with --min-sleep-interval\n--sleep-subtitles SECONDS       Number of seconds to sleep before each\n                                subtitle download\n</code></pre><pre><code>-f, --format FORMAT             Video format code, see \"FORMAT SELECTION\"\n                                for more details\n-S, --format-sort SORTORDER     Sort the formats by the fields given, see\n                                \"Sorting Formats\" for more details\n--format-sort-force             Force user specified sort order to have\n                                precedence over all fields, see \"Sorting\n                                Formats\" for more details (Alias: --S-force)\n--no-format-sort-force          Some fields have precedence over the user\n                                specified sort order (default)\n--video-multistreams            Allow multiple video streams to be merged\n                                into a single file\n--no-video-multistreams         Only one video stream is downloaded for each\n                                output file (default)\n--audio-multistreams            Allow multiple audio streams to be merged\n                                into a single file\n--no-audio-multistreams         Only one audio stream is downloaded for each\n                                output file (default)\n--prefer-free-formats           Prefer video formats with free containers\n                                over non-free ones of the same quality. Use\n                                with \"-S ext\" to strictly prefer free\n                                containers irrespective of quality\n--no-prefer-free-formats        Don't give any special preference to free\n                                containers (default)\n--check-formats                 Make sure formats are selected only from\n                                those that are actually downloadable\n--check-all-formats             Check all formats for whether they are\n                                actually downloadable\n--no-check-formats              Do not check that the formats are actually\n                                downloadable\n-F, --list-formats              List available formats of each video.\n                                Simulate unless --no-simulate is used\n--merge-output-format FORMAT    Containers that may be used when merging\n                                formats, separated by \"/\", e.g. \"mp4/mkv\".\n                                Ignored if no merge is required. (currently\n                                supported: avi, flv, mkv, mov, mp4, webm)\n</code></pre><pre><code>--write-subs                    Write subtitle file\n--no-write-subs                 Do not write subtitle file (default)\n--write-auto-subs               Write automatically generated subtitle file\n                                (Alias: --write-automatic-subs)\n--no-write-auto-subs            Do not write auto-generated subtitles\n                                (default) (Alias: --no-write-automatic-subs)\n--list-subs                     List available subtitles of each video.\n                                Simulate unless --no-simulate is used\n--sub-format FORMAT             Subtitle format; accepts formats preference\n                                separated by \"/\", e.g. \"srt\" or \"ass/srt/best\"\n--sub-langs LANGS               Languages of the subtitles to download (can\n                                be regex) or \"all\" separated by commas, e.g.\n                                --sub-langs \"en.*,ja\" (where \"en.*\" is a\n                                regex pattern that matches \"en\" followed by\n                                0 or more of any character). You can prefix\n                                the language code with a \"-\" to exclude it\n                                from the requested languages, e.g. --sub-\n                                langs all,-live_chat. Use --list-subs for a\n                                list of available language tags\n</code></pre><pre><code>-u, --username USERNAME         Login with this account ID\n-p, --password PASSWORD         Account password. If this option is left\n                                out, yt-dlp will ask interactively\n-2, --twofactor TWOFACTOR       Two-factor authentication code\n-n, --netrc                     Use .netrc authentication data\n--netrc-location PATH           Location of .netrc authentication data;\n                                either the path or its containing directory.\n                                Defaults to ~/.netrc\n--netrc-cmd NETRC_CMD           Command to execute to get the credentials\n                                for an extractor.\n--video-password PASSWORD       Video-specific password\n--ap-mso MSO                    Adobe Pass multiple-system operator (TV\n                                provider) identifier, use --ap-list-mso for\n                                a list of available MSOs\n--ap-username USERNAME          Multiple-system operator account login\n--ap-password PASSWORD          Multiple-system operator account password.\n                                If this option is left out, yt-dlp will ask\n                                interactively\n--ap-list-mso                   List all supported multiple-system operators\n--client-certificate CERTFILE   Path to client certificate file in PEM\n                                format. May include the private key\n--client-certificate-key KEYFILE\n                                Path to private key file for client\n                                certificate\n--client-certificate-password PASSWORD\n                                Password for client certificate private key,\n                                if encrypted. If not provided, and the key\n                                is encrypted, yt-dlp will ask interactively\n</code></pre><pre><code>-x, --extract-audio             Convert video files to audio-only files\n                                (requires ffmpeg and ffprobe)\n--audio-format FORMAT           Format to convert the audio to when -x is\n                                used. (currently supported: best (default),\n                                aac, alac, flac, m4a, mp3, opus, vorbis,\n                                wav). You can specify multiple rules using\n                                similar syntax as --remux-video\n--audio-quality QUALITY         Specify ffmpeg audio quality to use when\n                                converting the audio with -x. Insert a value\n                                between 0 (best) and 10 (worst) for VBR or a\n                                specific bitrate like 128K (default 5)\n--remux-video FORMAT            Remux the video into another container if\n                                necessary (currently supported: avi, flv,\n                                gif, mkv, mov, mp4, webm, aac, aiff, alac,\n                                flac, m4a, mka, mp3, ogg, opus, vorbis,\n                                wav). If the target container does not\n                                support the video/audio codec, remuxing will\n                                fail. You can specify multiple rules; e.g.\n                                \"aac&gt;m4a/mov&gt;mp4/mkv\" will remux aac to m4a,\n                                mov to mp4 and anything else to mkv\n--recode-video FORMAT           Re-encode the video into another format if\n                                necessary. The syntax and supported formats\n                                are the same as --remux-video\n--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.\n                                Specify the postprocessor/executable name\n                                and the arguments separated by a colon \":\"\n                                to give the argument to the specified\n                                postprocessor/executable. Supported PP are:\n                                Merger, ModifyChapters, SplitChapters,\n                                ExtractAudio, VideoRemuxer, VideoConvertor,\n                                Metadata, EmbedSubtitle, EmbedThumbnail,\n                                SubtitlesConvertor, ThumbnailsConvertor,\n                                FixupStretched, FixupM4a, FixupM3u8,\n                                FixupTimestamp and FixupDuration. The\n                                supported executables are: AtomicParsley,\n                                FFmpeg and FFprobe. You can also specify\n                                \"PP+EXE:ARGS\" to give the arguments to the\n                                specified executable only when being used by\n                                the specified postprocessor. Additionally,\n                                for ffmpeg/ffprobe, \"_i\"/\"_o\" can be\n                                appended to the prefix optionally followed\n                                by a number to pass the argument before the\n                                specified input/output file, e.g. --ppa\n                                \"Merger+ffmpeg_i1:-v quiet\". You can use\n                                this option multiple times to give different\n                                arguments to different postprocessors.\n                                (Alias: --ppa)\n-k, --keep-video                Keep the intermediate video file on disk\n                                after post-processing\n--no-keep-video                 Delete the intermediate video file after\n                                post-processing (default)\n--post-overwrites               Overwrite post-processed files (default)\n--no-post-overwrites            Do not overwrite post-processed files\n--embed-subs                    Embed subtitles in the video (only for mp4,\n                                webm and mkv videos)\n--no-embed-subs                 Do not embed subtitles (default)\n--embed-thumbnail               Embed thumbnail in the video as cover art\n--no-embed-thumbnail            Do not embed thumbnail (default)\n--embed-metadata                Embed metadata to the video file. Also\n                                embeds chapters/infojson if present unless\n                                --no-embed-chapters/--no-embed-info-json are\n                                used (Alias: --add-metadata)\n--no-embed-metadata             Do not add metadata to file (default)\n                                (Alias: --no-add-metadata)\n--embed-chapters                Add chapter markers to the video file\n                                (Alias: --add-chapters)\n--no-embed-chapters             Do not add chapter markers (default) (Alias:\n                                --no-add-chapters)\n--embed-info-json               Embed the infojson as an attachment to\n                                mkv/mka video files\n--no-embed-info-json            Do not embed the infojson as an attachment\n                                to the video file\n--parse-metadata [WHEN:]FROM:TO\n                                Parse additional metadata like title/artist\n                                from other fields; see \"MODIFYING METADATA\"\n                                for details. Supported values of \"WHEN\" are\n                                the same as that of --use-postprocessor\n                                (default: pre_process)\n--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE\n                                Replace text in a metadata field using the\n                                given regex. This option can be used\n                                multiple times. Supported values of \"WHEN\"\n                                are the same as that of --use-postprocessor\n                                (default: pre_process)\n--xattrs                        Write metadata to the video file's xattrs\n                                (using Dublin Core and XDG standards)\n--concat-playlist POLICY        Concatenate videos in a playlist. One of\n                                \"never\", \"always\", or \"multi_video\"\n                                (default; only when the videos form a single\n                                show). All the video files must have the\n                                same codecs and number of streams to be\n                                concatenable. The \"pl_video:\" prefix can be\n                                used with \"--paths\" and \"--output\" to set\n                                the output filename for the concatenated\n                                files. See \"OUTPUT TEMPLATE\" for details\n--fixup POLICY                  Automatically correct known faults of the\n                                file. One of never (do nothing), warn (only\n                                emit a warning), detect_or_warn (the\n                                default; fix the file if we can, warn\n                                otherwise), force (try fixing even if the\n                                file already exists)\n--ffmpeg-location PATH          Location of the ffmpeg binary; either the\n                                path to the binary or its containing directory\n--exec [WHEN:]CMD               Execute a command, optionally prefixed with\n                                when to execute it, separated by a \":\".\n                                Supported values of \"WHEN\" are the same as\n                                that of --use-postprocessor (default:\n                                after_move). The same syntax as the output\n                                template can be used to pass any field as\n                                arguments to the command. If no fields are\n                                passed, %(filepath,_filename|)q is appended\n                                to the end of the command. This option can\n                                be used multiple times\n--no-exec                       Remove any previously defined --exec\n--convert-subs FORMAT           Convert the subtitles to another format\n                                (currently supported: ass, lrc, srt, vtt).\n                                Use \"--convert-subs none\" to disable\n                                conversion (default) (Alias: --convert-\n                                subtitles)\n--convert-thumbnails FORMAT     Convert the thumbnails to another format\n                                (currently supported: jpg, png, webp). You\n                                can specify multiple rules using similar\n                                syntax as \"--remux-video\". Use \"--convert-\n                                thumbnails none\" to disable conversion\n                                (default)\n--split-chapters                Split video into multiple files based on\n                                internal chapters. The \"chapter:\" prefix can\n                                be used with \"--paths\" and \"--output\" to set\n                                the output filename for the split files. See\n                                \"OUTPUT TEMPLATE\" for details\n--no-split-chapters             Do not split video based on chapters (default)\n--remove-chapters REGEX         Remove chapters whose title matches the\n                                given regular expression. The syntax is the\n                                same as --download-sections. This option can\n                                be used multiple times\n--no-remove-chapters            Do not remove any chapters from the file\n                                (default)\n--force-keyframes-at-cuts       Force keyframes at cuts when\n                                downloading/splitting/removing sections.\n                                This is slow due to needing a re-encode, but\n                                the resulting video may have fewer artifacts\n                                around the cuts\n--no-force-keyframes-at-cuts    Do not force keyframes around the chapters\n                                when cutting/splitting (default)\n--use-postprocessor NAME[:ARGS]\n                                The (case-sensitive) name of plugin\n                                postprocessors to be enabled, and\n                                (optionally) arguments to be passed to it,\n                                separated by a colon \":\". ARGS are a\n                                semicolon \";\" delimited list of NAME=VALUE.\n                                The \"when\" argument determines when the\n                                postprocessor is invoked. It can be one of\n                                \"pre_process\" (after video extraction),\n                                \"after_filter\" (after video passes filter),\n                                \"video\" (after --format; before\n                                --print/--output), \"before_dl\" (before each\n                                video download), \"post_process\" (after each\n                                video download; default), \"after_move\"\n                                (after moving the video file to its final\n                                location), \"after_video\" (after downloading\n                                and processing all formats of a video), or\n                                \"playlist\" (at end of playlist). This option\n                                can be used multiple times to add different\n                                postprocessors\n</code></pre><p>Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the <a href=\"https://sponsor.ajay.app\">SponsorBlock API</a></p><pre><code>--sponsorblock-mark CATS        SponsorBlock categories to create chapters\n                                for, separated by commas. Available\n                                categories are sponsor, intro, outro,\n                                selfpromo, preview, filler, interaction,\n                                music_offtopic, poi_highlight, chapter, all\n                                and default (=all). You can prefix the\n                                category with a \"-\" to exclude it. See [1]\n                                for descriptions of the categories. E.g.\n                                --sponsorblock-mark all,-preview\n                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories\n--sponsorblock-remove CATS      SponsorBlock categories to be removed from\n                                the video file, separated by commas. If a\n                                category is present in both mark and remove,\n                                remove takes precedence. The syntax and\n                                available categories are the same as for\n                                --sponsorblock-mark except that \"default\"\n                                refers to \"all,-filler\" and poi_highlight,\n                                chapter are not available\n--sponsorblock-chapter-title TEMPLATE\n                                An output template for the title of the\n                                SponsorBlock chapters created by\n                                --sponsorblock-mark. The only available\n                                fields are start_time, end_time, category,\n                                categories, name, category_names. Defaults\n                                to \"[SponsorBlock]: %(category_names)l\"\n--no-sponsorblock               Disable both --sponsorblock-mark and\n                                --sponsorblock-remove\n--sponsorblock-api URL          SponsorBlock API location, defaults to\n                                https://sponsor.ajay.app\n</code></pre><pre><code>--extractor-retries RETRIES     Number of retries for known extractor errors\n                                (default is 3), or \"infinite\"\n--allow-dynamic-mpd             Process dynamic DASH manifests (default)\n                                (Alias: --no-ignore-dynamic-mpd)\n--ignore-dynamic-mpd            Do not process dynamic DASH manifests\n                                (Alias: --no-allow-dynamic-mpd)\n--hls-split-discontinuity       Split HLS playlists to different formats at\n                                discontinuities such as ad breaks\n--no-hls-split-discontinuity    Do not split HLS playlists into different\n                                formats at discontinuities such as ad breaks\n                                (default)\n--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.\n                                See \"EXTRACTOR ARGUMENTS\" for details. You\n                                can use this option multiple times to give\n                                arguments for different extractors\n</code></pre><p>You can configure yt-dlp by placing any supported command line option in a configuration file. The configuration is loaded from the following locations:</p><ol><li><ul><li>The file given to </li></ul></li><li><p>: (Recommended for portable installations)</p><ul><li>If using a binary,  in the same directory as the binary</li><li>If running from source-code,  in the parent directory of </li></ul></li><li><ul><li> in the home path given to </li><li>If  is not given, the current directory is searched</li></ul></li><li><ul><li><code>${XDG_CONFIG_HOME}/yt-dlp.conf</code></li><li><code>${XDG_CONFIG_HOME}/yt-dlp/config</code> (recommended on Linux/macOS)</li><li><code>${XDG_CONFIG_HOME}/yt-dlp/config.txt</code></li><li> (recommended on Windows)</li><li><code>${APPDATA}/yt-dlp/config.txt</code></li></ul></li><li><ul></ul></li></ol><p>E.g. with the following configuration file, yt-dlp will always extract the audio, not copy the mtime, use a proxy and save all videos under  directory in your home directory:</p><pre><code># Lines starting with # are comments\n\n# Always extract audio\n-x\n\n# Do not copy the mtime\n--no-mtime\n\n# Use this proxy\n--proxy 127.0.0.1:3128\n\n# Save all videos under YouTube directory in your home directory\n-o ~/YouTube/%(title)s.%(ext)s\n</code></pre><p>: Options in a configuration file are just the same options aka switches used in regular command line calls; thus there  after  or , e.g.  or  but not  or . They must also be quoted when necessary, as if it were a UNIX shell.</p><p>You can use  if you want to disable all configuration files for a particular yt-dlp run. If  is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if  is found inside the system configuration file, the user configuration is not loaded.</p><h3>Configuration file encoding</h3><p>The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.</p><p>If you want your file to be decoded differently, add  to the beginning of the file (e.g. ). There must be no characters before that, even spaces or BOM.</p><h3>Authentication with netrc</h3><p>You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with  and ) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a <a href=\"https://stackoverflow.com/tags/.netrc/info\"> file</a> on a per-extractor basis. For that, you will need to create a  file in  and restrict permissions to read/write by only you:</p><pre><code>touch ${HOME}/.netrc\nchmod a-rwx,u+rw ${HOME}/.netrc\n</code></pre><p>After that, you can add credentials for an extractor in the following format, where  is the name of the extractor in lowercase:</p><pre><code>machine &lt;extractor&gt; login &lt;username&gt; password &lt;password&gt;\n</code></pre><pre><code>machine youtube login myaccount@gmail.com password my_youtube_password\nmachine twitch login my_twitch_account_name password my_twitch_password\n</code></pre><p>To activate authentication with the  file you should pass  to yt-dlp or place it in the <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration\">configuration file</a>.</p><p>The default location of the .netrc file is  (see below).</p><p>As an alternative to using the  file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the  parameter, it shall output the credentials in the netrc format and return  on success, other values will be treated as an error.  in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.</p><p>E.g. To use an encrypted  file stored as </p><pre><code>yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' 'https://www.youtube.com/watch?v=BaW_jenozKc'\n</code></pre><h3>Notes about environment variables</h3><ul><li>Environment variables are normally specified as / on UNIX and  on Windows; but is always shown as  in this documentation</li><li>yt-dlp also allows using UNIX-style variables on Windows for path-like options; e.g. , </li><li>If unset,  defaults to  and  to </li><li>On Windows,  points to  if present; or,  or  otherwise</li><li>On Windows,  generally points to  and  to <code>${USERPROFILE}\\AppData\\Roaming</code></li></ul><p>The  option is used to indicate a template for the output file names while  option is used to specify the path each type of file should be saved to.</p><p>The simplest usage of  is not to set any template arguments when downloading a single file, like in <code>yt-dlp -o funny_video.flv \"https://some/video\"</code> (hard-coding file extension like this is  recommended and could break some post-processing).</p><p>It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to <a href=\"https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting\">Python string formatting operations</a>, e.g.  or . To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.</p><p>The field names themselves (the part inside the parenthesis) can also have some special formatting:</p><ol><li><p>: The dictionaries and lists available in metadata can be traversed by using a dot  separator; e.g. , . You can do Python slicing with colon ; E.g. , , . Curly braces  can be used to build dictionaries with only specific keys; e.g. <code>%(formats.:.{format_id,height})#j</code>. An empty field name  refers to the entire infodict; e.g. . Note that all the fields that become available using this method are not listed below. Use  to see such fields</p></li><li><p>: Simple arithmetic can be done on numeric fields using ,  and . E.g. , <code>%(n_entries+1-playlist_index)d</code></p></li><li><p>: Date/time fields can be formatted according to <a href=\"https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\">strftime formatting</a> by specifying it separated from the field name using a . E.g. , , </p></li><li><p>: Alternate fields can be specified separated with a . E.g. <code>%(release_date&gt;%Y,upload_date&gt;%Y|Unknown)s</code></p></li><li><p>: A replacement value can be specified using a  separator according to the <a href=\"https://docs.python.org/3/library/string.html#format-specification-mini-language\"> mini-language</a>. If the field is  empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if  of the alternative fields is  empty. E.g. <code>%(chapters&amp;has chapters|no chapters)s</code>, <code>%(title&amp;TITLE={:&gt;20}|NO TITLE)s</code></p></li><li><p>: A literal default value can be specified for when the field is empty using a  separator. This overrides . E.g. </p></li><li><p>: In addition to the normal format types , yt-dlp additionally supports converting to  = ytes,  = son (flag  for pretty-printing,  for Unicode),  = HTML escaping,  = a comma separated ist (flag  for  newline-separated),  = a string uoted for the terminal (flag  to split a list into different arguments),  = add ecimal suffixes (e.g. 10M) (flag  to use 1024 as factor), and  = anitize as filename (flag  for restricted)</p></li><li><p>: The format type  can be used for NFC <a href=\"https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize\">Unicode normalization</a>. The alternate form flag () changes the normalization to NFD and the conversion flag  can be used for NFKC/NFKD compatibility equivalence normalization. E.g.  is NFKC</p></li></ol><p>To summarize, the general syntax for a field is:</p><pre><code>%(name[.keys][addition][&gt;strf][,alternate][&amp;replacement][|default])[flags][width][.precision][length]type\n</code></pre><p>Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon . The different file types supported are , , ,  (deprecated), , , , , , , . E.g. <code>-o \"%(title)s.%(ext)s\" -o \"thumbnail:%(title)s\\%(title)s.%(ext)s\"</code> will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. <code>--write-thumbnail -o \"thumbnail:\"</code> will write thumbnails only for playlists and not for video.</p><p>: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use <code>--print after_move:filepath</code> to get the name after all post-processing is complete.</p><p>The available fields are:</p><ul><li> (string): Video identifier</li><li> (string): Video title</li><li> (string): Video title ignoring live timestamp and generic title</li><li> (string): Video filename extension</li><li> (string): A secondary title of the video</li><li> (string): The description of the video</li><li> (string): An alternative identifier for the video</li><li> (string): Full name of the video uploader</li><li> (string): Nickname or id of the video uploader</li><li> (string): URL to the video uploader's profile</li><li> (string): License name the video is licensed under</li><li> (list): The creators of the video</li><li> (string): The creators of the video; comma-separated</li><li> (numeric): UNIX timestamp of the moment the video became available</li><li> (string): Video upload date in UTC (YYYYMMDD)</li><li> (numeric): UNIX timestamp of the moment the video was released</li><li> (string): The date (YYYYMMDD) when the video was released in UTC</li><li> (numeric): Year (YYYY) when the video or album was released</li><li> (numeric): UNIX timestamp of the moment the video was last modified</li><li> (string): The date (YYYYMMDD) when the video was last modified in UTC</li><li> (string): Full name of the channel the video is uploaded on</li><li> (string): Id of the channel</li><li> (string): URL of the channel</li><li> (numeric): Number of followers of the channel</li><li> (boolean): Whether the channel is verified on the platform</li><li> (string): Physical location where the video was filmed</li><li> (numeric): Length of the video in seconds</li><li> (string): Length of the video (HH:mm:ss)</li><li> (numeric): How many users have watched the video on the platform</li><li> (numeric): How many users are currently watching the video on the platform.</li><li> (numeric): Number of positive ratings of the video</li><li> (numeric): Number of negative ratings of the video</li><li> (numeric): Number of reposts of the video</li><li> (numeric): Average rating given by users, the scale used depends on the webpage</li><li> (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)</li><li> (numeric): Age restriction for the video (years)</li><li> (string): One of \"not_live\", \"is_live\", \"is_upcoming\", \"was_live\", \"post_live\" (was live, but VOD is not yet processed)</li><li> (boolean): Whether this video is a live stream or a fixed-length video</li><li> (boolean): Whether this video was originally a live stream</li><li> (string): Whether this video is allowed to play in embedded players on other sites</li><li> (string): Whether the video is \"private\", \"premium_only\", \"subscriber_only\", \"needs_auth\", \"unlisted\" or \"public\"</li><li> (string): The type of media as classified by the site, e.g. \"episode\", \"clip\", \"trailer\"</li><li> (numeric): Time in seconds where the reproduction should start, as specified in the URL</li><li> (numeric): Time in seconds where the reproduction should end, as specified in the URL</li><li> (string): Name of the extractor</li><li> (string): Key name of the extractor</li><li> (numeric): Unix epoch of when the information extraction was completed</li><li> (numeric): Number that will be increased with each download, starting at , padded with leading zeros to 5 digits</li><li> (numeric): Number that will be increased with each video</li><li> (numeric): Total number of extracted items in the playlist</li><li> (string): Identifier of the playlist that contains the video</li><li> (string): Name of the playlist that contains the video</li><li> (string):  if available or else </li><li> (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted</li><li> (numeric): Index of the video in the playlist padded with leading zeros according the final index</li><li> (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist</li><li> (string): Full name of the playlist uploader</li><li> (string): Nickname or id of the playlist uploader</li><li> (string): Display name of the channel that uploaded the playlist</li><li> (string): Identifier of the channel that uploaded the playlist</li><li> (string): URL of the playlist webpage</li><li> (string): A URL to the video webpage which, if given to yt-dlp, should yield the same result again</li><li> (string): The basename of the webpage URL</li><li> (string): The domain of the webpage URL</li><li> (string): The URL given by the user (or the same as  for playlist entries)</li><li> (list): List of categories the video belongs to</li><li> (list): List of tags assigned to the video</li><li> (list): List of cast members</li></ul><p>Available for the video that belongs to some logical chapter or section:</p><ul><li> (string): Name or title of the chapter the video belongs to</li><li> (numeric): Number of the chapter the video belongs to</li><li> (string): Id of the chapter the video belongs to</li></ul><p>Available for the video that is an episode of some series or program:</p><ul><li> (string): Title of the series or program the video episode belongs to</li><li> (string): Id of the series or program the video episode belongs to</li><li> (string): Title of the season the video episode belongs to</li><li> (numeric): Number of the season the video episode belongs to</li><li> (string): Id of the season the video episode belongs to</li><li> (string): Title of the video episode</li><li> (numeric): Number of the video episode within a season</li><li> (string): Id of the video episode</li></ul><p>Available for the media that is a track or a part of a music album:</p><ul><li> (string): Title of the track</li><li> (numeric): Number of the track within an album or a disc</li><li> (string): Id of the track</li><li> (list): Artist(s) of the track</li><li> (string): Artist(s) of the track; comma-separated</li><li> (list): Genre(s) of the track</li><li> (string): Genre(s) of the track; comma-separated</li><li> (list): Composer(s) of the piece</li><li> (string): Composer(s) of the piece; comma-separated</li><li> (string): Title of the album the track belongs to</li><li> (string): Type of the album</li><li> (list): All artists appeared on the album</li><li> (string): All artists appeared on the album; comma-separated</li><li> (numeric): Number of the disc or other physical medium the track belongs to</li></ul><p>Available only when using  and for  prefix when using  for videos with internal chapters:</p><ul><li> (string): Title of the chapter</li><li> (numeric): Number of the chapter within the file</li><li> (numeric): Start time of the chapter in seconds</li><li> (numeric): End time of the chapter in seconds</li></ul><p>Available only when used in :</p><ul><li> (string): The URLs of all requested formats, one in each line</li><li> (table): The video format table as printed by </li><li> (table): The thumbnail format table as printed by </li><li> (table): The subtitle format table as printed by </li><li> (table): The automatic subtitle format table as printed by </li></ul><p>Available only after the video is downloaded (/):</p><ul><li>: Actual path of downloaded video file</li></ul><p>Available only in <code>--sponsorblock-chapter-title</code>:</p><ul><li> (numeric): Start time of the chapter in seconds</li><li> (numeric): End time of the chapter in seconds</li><li> (string): The smallest SponsorBlock category the chapter belongs to</li><li> (list): Friendly names of the categories</li><li> (string): Friendly name of the smallest category</li></ul><p>Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for <code>-o %(title)s-%(id)s.%(ext)s</code> and an mp4 video with title  and id , this will result in a <code>yt-dlp test video-BaW_jenozKc.mp4</code> file created in the current directory.</p><p>: Some of the sequences are not guaranteed to be present, since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with  ( by default).</p><p>: Look at the  output to identify which fields are available for the particular URL</p><p>For numeric sequences, you can use <a href=\"https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting\">numeric related formatting</a>; e.g.  will result in a string with view count padded with zeros up to 5 characters, like in .</p><p>Output templates can also contain arbitrary hierarchical path, e.g. <code>-o \"%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\"</code> which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.</p><p>To use percent literals in an output template use . To output to stdout use .</p><p>The current default template is <code>%(title)s [%(id)s].%(ext)s</code>.</p><p>In some cases, you don't want special characters such as ‰∏≠, spaces, or &amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the  flag to get a shorter title.</p><pre><code>$ yt-dlp --print filename -o \"test video.%(ext)s\" BaW_jenozKc\ntest video.webm    # Literal name with correct extension\n\n$ yt-dlp --print filename -o \"%(title)s.%(ext)s\" BaW_jenozKc\nyoutube-dl test video ''_√§‚Ü≠ùïê.webm    # All kinds of weird characters\n\n$ yt-dlp --print filename -o \"%(title)s.%(ext)s\" BaW_jenozKc --restrict-filenames\nyoutube-dl_test_video_.webm    # Restricted file name\n\n# Download YouTube playlist videos in separate directory indexed by video order in a playlist\n$ yt-dlp -o \"%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\"\n\n# Download YouTube playlist videos in separate directories according to their uploaded year\n$ yt-dlp -o \"%(upload_date&gt;%Y)s/%(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\"\n\n# Prefix playlist index with \" - \" separator, but only if it is available\n$ yt-dlp -o \"%(playlist_index&amp;{} - |)s%(title)s.%(ext)s\" BaW_jenozKc \"https://www.youtube.com/user/TheLinuxFoundation/playlists\"\n\n# Download all playlists of YouTube channel/user keeping each playlist in separate directory:\n$ yt-dlp -o \"%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/user/TheLinuxFoundation/playlists\"\n\n# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home\n$ yt-dlp -u user -p password -P \"~/MyVideos\" -o \"%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s\" \"https://www.udemy.com/java-tutorial\"\n\n# Download entire series season keeping each series and each season in separate directory under C:/MyVideos\n$ yt-dlp -P \"C:/MyVideos\" -o \"%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s\" \"https://videomore.ru/kino_v_detalayah/5_sezon/367617\"\n\n# Download video as \"C:\\MyVideos\\uploader\\title.ext\", subtitles as \"C:\\MyVideos\\subs\\uploader\\title.ext\"\n# and put all temporary files in \"C:\\MyVideos\\tmp\"\n$ yt-dlp -P \"C:/MyVideos\" -P \"temp:tmp\" -P \"subtitle:subs\" -o \"%(uploader)s/%(title)s.%(ext)s\" BaW_jenozKc --write-subs\n\n# Download video as \"C:\\MyVideos\\uploader\\title.ext\" and subtitles as \"C:\\MyVideos\\uploader\\subs\\title.ext\"\n$ yt-dlp -P \"C:/MyVideos\" -o \"%(uploader)s/%(title)s.%(ext)s\" -o \"subtitle:%(uploader)s/subs/%(title)s.%(ext)s\" BaW_jenozKc --write-subs\n\n# Stream the video being downloaded to stdout\n$ yt-dlp -o - BaW_jenozKc\n</code></pre><p>By default, yt-dlp tries to download the best available quality if you  pass any options. This is generally equivalent to using <code>-f bestvideo*+bestaudio/best</code>. However, if multiple audiostreams is enabled (), the default format changes to <code>-f bestvideo+bestaudio/best</code>. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to  (), the default becomes <code>-f best/bestvideo+bestaudio</code>.</p><p>: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to  similar to normal downloads. If you want to preserve the  setting, it is recommended to explicitly specify it in the configuration options.</p><p>The general syntax for format selection is  (or ) where  is a , i.e. an expression that describes format or formats you would like to download.</p><p>The simplest case is requesting a specific format; e.g. with  you can download the format with format code equal to 22. You can get the list of available format codes for particular video using  or . Note that these format codes are extractor specific.</p><p>You can also use a file extension (currently , , , , , , , ,  are supported) to download the best quality format of a particular file extension served as a single file, e.g.  will download the best quality format with the  extension served as a single file.</p><p>You can use  to interactively provide the format selector </p><p>You can also use special names to select particular edge case formats:</p><ul><li>: Select  separately</li><li>: Select and  (Must be used with ,  or both)</li><li>, : Select the best quality format that  a video or an audio or both (i.e.; <code>vcodec!=none or acodec!=none</code>)</li><li>, : Select the best quality format that  video and audio. Equivalent to <code>best*[vcodec!=none][acodec!=none]</code></li><li>, : Select the best quality  format. Equivalent to </li><li>, : Select the best quality format that . It may also contain audio. Equivalent to </li><li>, : Select the best quality  format. Equivalent to </li><li>, : Select the best quality format that . It may also contain video. Equivalent to  (<a href=\"https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354\">Do not use!</a>)</li><li>, : Select the worst quality format that contains either a video or an audio</li><li>, : Select the worst quality format that contains both video and audio. Equivalent to <code>worst*[vcodec!=none][acodec!=none]</code></li><li>, : Select the worst quality video-only format. Equivalent to </li><li>, : Select the worst quality format that contains video. It may also contain audio. Equivalent to </li><li>, : Select the worst quality audio-only format. Equivalent to </li><li>, : Select the worst quality format that contains audio. It may also contain video. Equivalent to </li></ul><p>For example, to download the worst quality video-only format you can use . It is, however, recommended not to use  and related options. When your format selector is , the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use  or more rigorously,  instead of . See <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats\">Sorting Formats</a> for more details.</p><p>You can select the n'th best format of a type by using . For example,  will select the 2nd best combined format. Similarly,  will select the 3rd best format that contains a video stream.</p><p>If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g.  will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.</p><p>If you want to download several formats of the same video use a comma as a separator, e.g.  will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: <code>-f 136/137/mp4/bestvideo,140/m4a/bestaudio</code>.</p><p>You can merge the video and audio of multiple formats into a single file using <code>-f &lt;format1&gt;+&lt;format2&gt;+...</code> (requires ffmpeg installed); e.g.  will download the best video-only format, the best audio-only format and mux them together with ffmpeg.</p><p>: Since the  described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video</p><p>Unless  is used, all formats with a video stream except the first one are ignored. Similarly, unless  is used, all formats with an audio stream except the first one are ignored. E.g. <code>-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams</code> will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But <code>-f bestvideo+best+bestaudio --no-video-multistreams</code> will download and merge only  and .  is ignored since another format containing a video stream () has already been selected. The order of the formats is therefore important. <code>-f best+bestaudio --no-audio-multistreams</code> will download only  while <code>-f bestaudio+best --no-audio-multistreams</code> will ignore  and download only .</p><p>You can also filter the video formats by putting a condition in brackets, as in  (or  since filters without a selector are interpreted as ).</p><p>The following numeric meta fields can be used with comparisons , , , ,  (equals),  (not equals):</p><ul><li>: The number of bytes, if known in advance</li><li>: An estimate for the number of bytes</li><li>: Width of the video, if known</li><li>: Height of the video, if known</li><li>: Aspect ratio of the video, if known</li><li>: Average bitrate of audio and video in <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#%23\" title=\"1000 bits/sec\">kbps</a></li><li>: Average audio bitrate in <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#%23\" title=\"1000 bits/sec\">kbps</a></li><li>: Average video bitrate in <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#%23\" title=\"1000 bits/sec\">kbps</a></li><li>: Audio sampling rate in Hertz</li><li>: The number of audio channels</li><li>:  of the video's pixels, if not square</li></ul><p>Also filtering work for comparisons  (equals),  (starts with),  (ends with),  (contains),  (matches regex) and following string meta fields:</p><ul><li>: Name of the audio codec in use</li><li>: Name of the video codec in use</li><li>: Name of the container format</li><li>: The protocol that will be used for the actual download, lower-case (, , , , , , , , , , or )</li><li>: The dynamic range of the video</li><li>: A short description of the format</li><li>: A human-readable description of the format</li><li>: Additional info about the format</li><li>: Textual description of width and height</li></ul><p>Any string comparison may be prefixed with negation  in order to produce an opposite comparison, e.g.  (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than .</p><p>: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by the particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.</p><p>Formats for which the value is not known are excluded unless you put a question mark () after the operator. You can combine format filters, so <code>-f \"bv[height&lt;=?720][tbr&gt;500]\"</code> selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 kbps. You can also use the filters with  to download all formats that satisfy the filter, e.g.  selects all audio-only formats.</p><p>Format selectors can also be grouped using parentheses; e.g. <code>-f \"(mp4,webm)[height&lt;480]\"</code> will download the best pre-merged mp4 and webm formats with a height lower than 480.</p><p>You can change the criteria for being considered the  by using  (). The general format for this is <code>--format-sort field1,field2...</code>.</p><p>The available fields are:</p><ul><li>: Gives priority to formats that have a video stream</li><li>: Gives priority to formats that have an audio stream</li><li>: The format preference</li><li>: The language preference</li><li>: The quality of the format</li><li>: The preference of the source</li><li>: Protocol used for download (/ &gt; / &gt; / &gt; &gt;  &gt; / &gt; /)</li><li>: Video Codec ( &gt;  &gt;  &gt;  &gt;  &gt;  &gt;  &gt;  &gt; other)</li><li>: Audio Codec (/ &gt; / &gt;  &gt;  &gt;  &gt;  &gt;  &gt;  &gt;  &gt;  &gt;  &gt; other)</li><li>: Equivalent to </li><li>: Video Extension ( &gt;  &gt;  &gt;  &gt; other). If  is used,  is preferred.</li><li>: Audio Extension ( &gt;  &gt;  &gt;  &gt;  &gt;  &gt; other). If  is used, the order changes to  &gt;  &gt;  &gt;  &gt;  &gt; </li><li>: Equivalent to </li><li>: Exact filesize, if known in advance</li><li>: Approximate filesize</li><li>: Exact filesize if available, otherwise approximate filesize</li><li>: Video resolution, calculated as the smallest dimension.</li><li>: The dynamic range of the video ( &gt;  &gt;  &gt;  &gt;  &gt; )</li><li>: The number of audio channels</li><li>: Total average bitrate in <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#%23\" title=\"1000 bits/sec\">kbps</a></li><li>: Average video bitrate in <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#%23\" title=\"1000 bits/sec\">kbps</a></li><li>: Average audio bitrate in <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#%23\" title=\"1000 bits/sec\">kbps</a></li><li>: Average bitrate in <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#%23\" title=\"1000 bits/sec\">kbps</a>, //</li><li>: Audio sample rate in Hz</li></ul><p>: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.</p><p>All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a . E.g.  prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a . E.g.  prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For  and , you can provide two preferred values, the first for video and the second for audio. E.g.  (equivalent to ) sets the video codec preference to  &gt;  &gt;  &gt;  &gt;  &gt;  &gt;  &gt;  and audio codec preference to  &gt;  &gt;  &gt;  &gt;  &gt;  &gt; . You can also make the sorting prefer the nearest values to the provided by using  as the delimiter. E.g.  prefers the format with filesize closest to 1 GiB.</p><p>The fields  and  are always given highest priority in sorting, irrespective of the user-defined order. This behavior can be changed by using . Apart from these, the default order used is: <code>lang,quality,res,fps,hdr:12,vcodec,channels,acodec,size,br,asr,proto,ext,hasaud,source,id</code>. The extractors may override this default order, but they cannot override the user-provided order.</p><p>Note that the default for hdr is ; i.e. Dolby Vision is not preferred. This choice was made since DV formats are not yet fully compatible with most devices. This may be changed in the future.</p><p>If your format selector is , the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use <code>-f best -S +size,+br,+res,+fps</code>.</p><p>: You can use the  to see how the formats have been sorted (worst to best).</p><h2>Format Selection examples</h2><pre><code># Download and merge the best video-only format and the best audio-only format,\n# or download the best combined format if video-only format is not available\n$ yt-dlp -f \"bv+ba/b\"\n\n# Download best format that contains video,\n# and if it doesn't already have an audio stream, merge it with best audio-only format\n$ yt-dlp -f \"bv*+ba/b\"\n\n# Same as above\n$ yt-dlp\n\n# Download the best video-only format and the best audio-only format without merging them\n# For this case, an output template should be used since\n# by default, bestvideo and bestaudio will have the same file name.\n$ yt-dlp -f \"bv,ba\" -o \"%(title)s.f%(format_id)s.%(ext)s\"\n\n# Download and merge the best format that has a video stream,\n# and all audio-only formats into one file\n$ yt-dlp -f \"bv*+mergeall[vcodec=none]\" --audio-multistreams\n\n# Download and merge the best format that has a video stream,\n# and the best 2 audio-only formats into one file\n$ yt-dlp -f \"bv*+ba+ba.2\" --audio-multistreams\n\n\n# The following examples show the old method (without -S) of format selection\n# and how to use -S to achieve a similar but (generally) better result\n\n# Download the worst video available (old method)\n$ yt-dlp -f \"wv*+wa/w\"\n\n# Download the best video available but with the smallest resolution\n$ yt-dlp -S \"+res\"\n\n# Download the smallest video available\n$ yt-dlp -S \"+size,+br\"\n\n\n\n# Download the best mp4 video available, or the best video if no mp4 available\n$ yt-dlp -f \"bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b\"\n\n# Download the best video with the best extension\n# (For video, mp4 &gt; mov &gt; webm &gt; flv. For audio, m4a &gt; aac &gt; mp3 ...)\n$ yt-dlp -S \"ext\"\n\n\n\n# Download the best video available but no better than 480p,\n# or the worst video if there is no video under 480p\n$ yt-dlp -f \"bv*[height&lt;=480]+ba/b[height&lt;=480] / wv*+ba/w\"\n\n# Download the best video available with the largest height but no better than 480p,\n# or the best video with the smallest resolution if there is no video under 480p\n$ yt-dlp -S \"height:480\"\n\n# Download the best video available with the largest resolution but no better than 480p,\n# or the best video with the smallest resolution if there is no video under 480p\n# Resolution is determined by using the smallest dimension.\n# So this works correctly for vertical videos as well\n$ yt-dlp -S \"res:480\"\n\n\n\n# Download the best video (that also has audio) but no bigger than 50 MB,\n# or the worst video (that also has audio) if there is no video under 50 MB\n$ yt-dlp -f \"b[filesize&lt;50M] / w\"\n\n# Download the largest video (that also has audio) but no bigger than 50 MB,\n# or the smallest video (that also has audio) if there is no video under 50 MB\n$ yt-dlp -f \"b\" -S \"filesize:50M\"\n\n# Download the best video (that also has audio) that is closest in size to 50 MB\n$ yt-dlp -f \"b\" -S \"filesize~50M\"\n\n\n\n# Download best video available via direct link over HTTP/HTTPS protocol,\n# or the best video available via any protocol if there is no such video\n$ yt-dlp -f \"(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)\"\n\n# Download best video available via the best protocol\n# (https/ftps &gt; http/ftp &gt; m3u8_native &gt; m3u8 &gt; http_dash_segments ...)\n$ yt-dlp -S \"proto\"\n\n\n\n# Download the best video with either h264 or h265 codec,\n# or the best video if there is no such video\n$ yt-dlp -f \"(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)\"\n\n# Download the best video with best codec no better than h264,\n# or the best video with worst codec if there is no such video\n$ yt-dlp -S \"codec:h264\"\n\n# Download the best video with worst codec no worse than h264,\n# or the best video with best codec if there is no such video\n$ yt-dlp -S \"+codec:h264\"\n\n\n\n# More complex examples\n\n# Download the best video no better than 720p preferring framerate greater than 30,\n# or the worst video (still preferring framerate greater than 30) if there is no such video\n$ yt-dlp -f \"((bv*[fps&gt;30]/bv*)[height&lt;=720]/(wv*[fps&gt;30]/wv*)) + ba / (b[fps&gt;30]/b)[height&lt;=720]/(w[fps&gt;30]/w)\"\n\n# Download the video with the largest resolution no better than 720p,\n# or the video with the smallest resolution available if there is no such video,\n# preferring larger framerate for formats with the same resolution\n$ yt-dlp -S \"res:720,fps\"\n\n\n\n# Download the video with smallest resolution no worse than 480p,\n# or the video with the largest resolution available if there is no such video,\n# preferring better codec and then larger total bitrate for the same resolution\n$ yt-dlp -S \"+res:480,codec,br\"\n</code></pre><p>The metadata obtained by the extractors can be modified by using  and </p><p>The general syntax of  is to give the name of a field or an <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template\">output template</a> to extract data from, and the format to interpret it as, separated by a colon . Either a <a href=\"https://docs.python.org/3/library/re.html#regular-expression-syntax\">Python regular expression</a> with named capture groups, a single field name, or a similar syntax to the <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template\">output template</a> (only  formatting is supported) can be used for . The option can be used multiple times to parse and modify various fields.</p><p>Note that these options preserve their relative order, allowing replacements to be made in parsed fields and vice versa. Also, any field thus created can be used in the <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template\">output template</a> and will also affect the media file's metadata added when using .</p><p>This option also has a few special uses:</p><ul><li><p>You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field  to the URL that you want to download. E.g. <code>--parse-metadata \"description:(?P&lt;additional_urls&gt;https?://www\\.vimeo\\.com/\\d+)\"</code> will download the first vimeo video found in the description</p></li><li><p>You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a  prefix. For example, any value you set to  field will be added to the  field in the file - you can use this to set a different \"description\" and \"synopsis\". To modify the metadata of individual streams, use the  prefix (e.g. ). Any value set to the  field will overwrite all default values.</p></li></ul><p>: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.</p><p>For reference, these are the fields yt-dlp adds by default to the file metadata:</p><table><tbody><tr></tr><tr><td align=\"left\">, , , ,  or </td></tr><tr></tr><tr><td align=\"left\"> or </td></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>: The file format may not support some of these fields</p><h2>Modifying metadata examples</h2><pre><code># Interpret the title as \"Artist - Title\"\n$ yt-dlp --parse-metadata \"title:%(artist)s - %(title)s\"\n\n# Regex example\n$ yt-dlp --parse-metadata \"description:Artist - (?P&lt;artist&gt;.+)\"\n\n# Set title as \"Series name S01E05\"\n$ yt-dlp --parse-metadata \"%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s\"\n\n# Prioritize uploader as the \"artist\" field in video metadata\n$ yt-dlp --parse-metadata \"%(uploader|)s:%(meta_artist)s\" --embed-metadata\n\n# Set \"comment\" field in video metadata using description instead of webpage_url,\n# handling multiple lines correctly\n$ yt-dlp --parse-metadata \"description:(?s)(?P&lt;meta_comment&gt;.+)\" --embed-metadata\n\n# Do not set any \"synopsis\" in the video metadata\n$ yt-dlp --parse-metadata \":(?P&lt;meta_synopsis&gt;)\"\n\n# Remove \"formats\" field from the infojson by setting it to an empty string\n$ yt-dlp --parse-metadata \"video::(?P&lt;formats&gt;)\" --write-info-json\n\n# Replace all spaces and \"_\" in title and uploader with a `-`\n$ yt-dlp --replace-in-metadata \"title,uploader\" \"[ _]\" \"-\"\n\n</code></pre><p>Some extractors accept additional arguments which can be passed using <code>--extractor-args KEY:ARGS</code>.  is a  (semicolon) separated string of . E.g. <code>--extractor-args \"youtube:player-client=tv,mweb;formats=incomplete\" --extractor-args \"twitter:api=syndication\"</code></p><p>Note: In CLI,  can use  instead of ; e.g.  becomes </p><p>The following extractors use this feature:</p><ul><li>: Prefer translated metadata (,  etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to  translated. See <a href=\"https://github.com/yt-dlp/yt-dlp/raw/c26f9b991a0681fd3ea548d535919cec1fbbd430/yt_dlp/extractor/youtube.py#L381-L390\">youtube.py</a> for list of supported content language codes</li><li>: One or more of ,  or  to skip extraction of the m3u8 manifests, dash manifests and <a href=\"https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032\">auto-translated subtitles</a> respectively</li><li>: Clients to extract video data from. The main clients are ,  and , with variants  and  (e.g. ); and , , , ,  and  with no variants. By default,  is used, or  is used when authenticating with cookies. The  client is added for  URLs when logged-in cookies are used. The  and  clients are added for age-restricted videos if account age-verification is required. Some clients, such as  and , require a  for their formats to be downloadable. Some clients, such as the  variants, will only work with authentication. Not all clients support authentication via cookies. You can use  for the default clients, or you can use  for all clients (not recommended). You can prefix a client with  to exclude it, e.g. <code>youtube:player_client=default,-ios</code></li><li>: Skip some network requests that are generally needed for robust extraction. One or more of  (skip client configs),  (skip initial webpage),  (skip js player). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause some issues. See <a href=\"https://github.com/yt-dlp/yt-dlp/pull/860\">#860</a> for more details</li><li>: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.</li><li>:  or  (default) - choose comment sorting mode (on YouTube's side)</li><li>: Limit the amount of comments to gather. Comma-separated list of integers representing <code>max-comments,max-parents,max-replies,max-replies-per-thread</code>. Default is <ul><li>E.g.  will get a maximum of 1000 replies total, with up to 10 replies per thread.  will get a maximum of 1000 comments, with a maximum of 100 replies total</li></ul></li><li>: Change the types of formats to return.  (convert HTTP to DASH),  (identical content but different URLs or protocol; includes ),  (cannot be downloaded completely - live dash and post-live m3u8),  (include formats that require a PO Token but are missing one)</li><li>: Innertube API host to use for all API requests; e.g. , . Note that cookies exported from one subdomain will not work on others</li><li>: Innertube API key to use for all API requests. By default, no API key is used</li><li>:  raises an error instead of reporting a warning</li><li>: Overrides the account Data Sync ID used in Innertube API requests. This may be needed if you are using an account with <code>youtube:player_skip=webpage,configs</code> or </li><li>: Overrides the Visitor Data used in Innertube API requests. This should be used with <code>player_skip=webpage,configs</code> and without cookies. Note: this may have adverse effects if used improperly. If a session from a browser is wanted, you should pass cookies instead (which contain the Visitor ID)</li><li>: Proof of Origin (PO) Token(s) to use. Comma seperated list of PO Tokens in the format , e.g. <code>youtube:po_token=web.gvs+XXX,web.player=XXX,web_safari.gvs+YYY</code>. Context can be either  (Google Video Server URLs) or  (Innertube player request)</li></ul><h4>youtubetab (YouTube playlists, channels, feeds, etc.)</h4><ul><li>: One or more of  (skip initial webpage download),  (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see <a href=\"https://github.com/yt-dlp/yt-dlp/pull/1122\">#1122</a> for more details)</li><li>: Extract approximate  and  in flat-playlist. This may cause date-based filters to be slightly off</li></ul><ul><li>: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as . Note that if the stream has an HLS AES-128 key, then the query parameters will be passed to the key URI as well, unless the  extractor-arg is passed, or unless an external key URI is provided via the  extractor-arg. Does not apply to ffmpeg</li><li>: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as </li><li>: Passthrough the master m3u8 URL query to its HLS AES-128 decryption key URI if no value is provided, or else apply the query string given as . Note that this will have no effect if the key URI is provided via the  extractor-arg. Does not apply to ffmpeg</li><li>: An HLS AES-128 key URI  key (as hex), and optionally the IV (as hex), in the form of ; e.g. <code>generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321</code>. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist</li><li>: Bypass live HLS detection and manually set  - a value of  will set , any other value (or no value) will set </li><li>: Target(s) to try and impersonate with the initial webpage request; e.g. <code>generic:impersonate=safari,chrome-110</code>. Use  to impersonate any available target, and use <code>generic:impersonate=false</code> to disable impersonation (default)</li></ul><ul><li>: Types of videos to download - one or more of , , , </li></ul><ul><li>: Segment duration in milliseconds for HLS-DMC formats. Use it at your own risk since this feature <strong>may result in your account termination.</strong></li></ul><ul><li>: Try to check more at the cost of more requests. One or more of , </li></ul><ul><li>:  (default),  (cookies needed), ,  - choose comment sorting mode (on GameJolt's side)</li></ul><ul><li>: resolution to ignore - one or more of , , </li><li>: vcodec to ignore - one or more of , , </li><li>: dynamic range to ignore - one or more of , , </li></ul><ul><li>: Maximum number of comments to extract - default is </li></ul><ul><li>: Hostname to use for mobile API calls, e.g. <code>api22-normal-c-alisg.tiktokv.com</code></li><li>: Default app name to use with mobile API calls, e.g. </li><li>: Default app version to use with mobile API calls - should be set along with , e.g. </li><li>: Default numeric app version to use with mobile API calls, e.g. </li><li>: Default app ID to use with mobile API calls, e.g. </li><li>: Enable mobile API extraction with one or more app info strings in the format of <code>&lt;iid&gt;/[app_name]/[app_version]/[manifest_app_version]/[aid]</code>, where  is the unique app install ID.  is the only required value; all other values and their  separators can be omitted, e.g. <code>tiktok:app_info=1234567890123456789</code> or <code>tiktok:app_info=123,456/trill///1180,789//34.0.1/340001</code></li><li>: Enable mobile API extraction with a genuine device ID to be used with mobile API calls. Default is a random 19-digit string</li></ul><ul><li>: Which tab to download - one of , , , , , </li></ul><ul><li>: Select one of  (default),  or  as the API for tweet extraction. Has no effect if logged in</li></ul><h4>stacommu, wrestleuniverse</h4><ul><li>: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage</li></ul><ul><li>: Client ID value to be sent with GraphQL requests, e.g. <code>twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko</code></li></ul><h4>nhkradirulive (NHK „Çâ„Åò„Çã‚òÖ„Çâ„Åò„Çã LIVE)</h4><ul><li>: Which regional variation to extract. Valid areas are: , , , , , , , . Defaults to </li></ul><ul><li>: Type(s) of game replays to extract. Valid types are: , ,  and . You can use  to extract all available replay types, which is the default</li></ul><ul><li>: The  UUID from browser local storage can be passed to extend the life of your login session when logging in with  as username and the  from browser local storage as password</li></ul><ul><li>: Audio bitrates to request. One or more of , , , , . Default is </li></ul><ul><li>: One or more CDN IDs to use with the API call for stream URLs, e.g. , , , </li></ul><ul><li>: Formats to request from the API. Requested values should be in the format of , e.g. . The  character functions as a wildcard, e.g. , and can be passed by itself to request all formats. Known protocols include ,  and ; known codecs include ,  and . Original  formats are always extracted. Default is <code>http_aac,hls_aac,http_opus,hls_opus,http_mp3,hls_mp3</code></li></ul><ul><li>: Prefer a playlist of program segments instead of a single complete video when available. If individual segments are desired, use <code>--concat-playlist never --extractor-args \"orfon:prefer_segments_playlist\"</code></li></ul><ul><li>: Prefer extracting flv formats over mp4 for older videos that still provide legacy formats</li></ul><ul><li>: Episode sort order for series extraction - one of  (ascending, oldest first) or  (descending, newest first). Default is </li></ul><p>: These options may be changed/removed in the future without concern for backward compatibility</p><p>Note that  plugins are imported even if not invoked, and that  performed on plugin code. <strong>Use plugins at your own risk and only if you trust the code!</strong></p><p>Plugins can be of s  or .</p><ul><li>Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.</li><li>Extractor plugins take priority over built-in extractors.</li><li>Postprocessor plugins can be invoked using .</li></ul><p>Plugins are loaded from the namespace packages  and <code>yt_dlp_plugins.postprocessor</code>.</p><p>In other words, the file structure on the disk looks something like:</p><pre><code>    yt_dlp_plugins/\n        extractor/\n            myplugin.py\n        postprocessor/\n            myplugin.py\n</code></pre><p>yt-dlp looks for these  namespace folders in many locations (see below) and loads in plugins from  of them. Set the environment variable  to something nonempty to disable loading plugins entirely.</p><p>Plugins can be installed using various methods and locations.</p><ol><li><p><strong>Configuration directories</strong>: Plugin packages (containing a  namespace folder) can be dropped into the following standard <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration\">configuration locations</a>:</p><ul><li><ul><li><code>${XDG_CONFIG_HOME}/yt-dlp/plugins/&lt;package name&gt;/yt_dlp_plugins/</code> (recommended on Linux/macOS)</li><li><code>${XDG_CONFIG_HOME}/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li><li><code>${APPDATA}/yt-dlp/plugins/&lt;package name&gt;/yt_dlp_plugins/</code> (recommended on Windows)</li><li><code>${APPDATA}/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li><li><code>~/.yt-dlp/plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li><li><code>~/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li></ul></li><li><ul><li><code>/etc/yt-dlp/plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li><li><code>/etc/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li></ul></li></ul></li><li><p>: Plugin packages can similarly be installed in a  directory under the executable location (recommended for portable installations):</p><ul><li>Binary: where , <code>&lt;root-dir&gt;/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li><li>Source: where <code>&lt;root-dir&gt;/yt_dlp/__main__.py</code>, <code>&lt;root-dir&gt;/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li></ul></li><li><p><strong>pip and other locations in </strong></p><ul><li>Plugin packages can be installed and managed using . See <a href=\"https://github.com/yt-dlp/yt-dlp-sample-plugins\">yt-dlp-sample-plugins</a> for an example. \n    <ul><li>Note: plugin files between plugin packages installed with pip must have unique filenames.</li></ul></li><li>Any path in  is searched in for the  namespace folder. \n    <ul><li>Note: This does not apply for Pyinstaller builds.</li></ul></li></ul></li></ol><p>,  and  archives containing a  namespace folder in their root are also supported as plugin packages.</p><ul><li>e.g. <code>${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip</code> where  contains <code>yt_dlp_plugins/&lt;type&gt;/myplugin.py</code></li></ul><p>Run yt-dlp with  to check if the plugin has been loaded.</p><p>All public classes with a name ending in / are imported from each file for extractors and postprocessors respectively. This respects underscore prefix (e.g.  is private) and . Modules can similarly be excluded by prefixing the module name with an underscore (e.g. ).</p><p>To replace an existing extractor with a subclass of one, set the  class keyword argument (e.g. <code>class MyPluginIE(ABuiltInIE, plugin_name='myplugin')</code> will replace  with ). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.</p><p>If you are a plugin author, add <a href=\"https://github.com/topics/yt-dlp-plugins\">yt-dlp-plugins</a> as a topic to your repository for discoverability.</p><p>yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.</p><p>Your program should avoid parsing the normal stdout since they may change in future versions. Instead, they should use options such as , , ,  etc to create console output that you can reliably reproduce and parse.</p><p>From a Python program, you can embed yt-dlp in a more powerful fashion, like this:</p><pre><code>from yt_dlp import YoutubeDL\n\nURLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']\nwith YoutubeDL() as ydl:\n    ydl.download(URLS)\n</code></pre><p>Most likely, you'll want to use various options. For a list of options available, have a look at <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/yt_dlp/YoutubeDL.py#L183\"></a> or  in a Python shell. If you are already familiar with the CLI, you can use <a href=\"https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py\"></a> to translate any CLI switches to  params.</p><p>: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of  to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through  as shown in the <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extracting-information\">example below</a></p><pre><code>import json\nimport yt_dlp\n\nURL = 'https://www.youtube.com/watch?v=BaW_jenozKc'\n\n# ‚ÑπÔ∏è See help(yt_dlp.YoutubeDL) for a list of available options and public functions\nydl_opts = {}\nwith yt_dlp.YoutubeDL(ydl_opts) as ydl:\n    info = ydl.extract_info(URL, download=False)\n\n    # ‚ÑπÔ∏è ydl.sanitize_info makes the info json-serializable\n    print(json.dumps(ydl.sanitize_info(info)))\n</code></pre><h4>Download using an info-json</h4><pre><code>import yt_dlp\n\nINFO_FILE = 'path/to/video.info.json'\n\nwith yt_dlp.YoutubeDL() as ydl:\n    error_code = ydl.download_with_info_file(INFO_FILE)\n\nprint('Some videos failed to download' if error_code\n      else 'All videos successfully downloaded')\n</code></pre><pre><code>import yt_dlp\n\nURLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']\n\nydl_opts = {\n    'format': 'm4a/bestaudio/best',\n    # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n    'postprocessors': [{  # Extract audio using ffmpeg\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'm4a',\n    }]\n}\n\nwith yt_dlp.YoutubeDL(ydl_opts) as ydl:\n    error_code = ydl.download(URLS)\n</code></pre><pre><code>import yt_dlp\n\nURLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']\n\ndef longer_than_a_minute(info, *, incomplete):\n    \"\"\"Download only videos longer than a minute (or with unknown duration)\"\"\"\n    duration = info.get('duration')\n    if duration and duration &lt; 60:\n        return 'The video is too short'\n\nydl_opts = {\n    'match_filter': longer_than_a_minute,\n}\n\nwith yt_dlp.YoutubeDL(ydl_opts) as ydl:\n    error_code = ydl.download(URLS)\n</code></pre><h4>Adding logger and progress hook</h4><pre><code>import yt_dlp\n\nURLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']\n\nclass MyLogger:\n    def debug(self, msg):\n        # For compatibility with youtube-dl, both debug and info are passed into debug\n        # You can distinguish them by the prefix '[debug] '\n        if msg.startswith('[debug] '):\n            pass\n        else:\n            self.info(msg)\n\n    def info(self, msg):\n        pass\n\n    def warning(self, msg):\n        pass\n\n    def error(self, msg):\n        print(msg)\n\n\n# ‚ÑπÔ∏è See \"progress_hooks\" in help(yt_dlp.YoutubeDL)\ndef my_hook(d):\n    if d['status'] == 'finished':\n        print('Done downloading, now post-processing ...')\n\n\nydl_opts = {\n    'logger': MyLogger(),\n    'progress_hooks': [my_hook],\n}\n\nwith yt_dlp.YoutubeDL(ydl_opts) as ydl:\n    ydl.download(URLS)\n</code></pre><h4>Add a custom PostProcessor</h4><pre><code>import yt_dlp\n\nURLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']\n\n# ‚ÑπÔ∏è See help(yt_dlp.postprocessor.PostProcessor)\nclass MyCustomPP(yt_dlp.postprocessor.PostProcessor):\n    def run(self, info):\n        self.to_screen('Doing stuff')\n        return [], info\n\n\nwith yt_dlp.YoutubeDL() as ydl:\n    # ‚ÑπÔ∏è \"when\" can take any value in yt_dlp.utils.POSTPROCESS_WHEN\n    ydl.add_post_processor(MyCustomPP(), when='pre_process')\n    ydl.download(URLS)\n</code></pre><h4>Use a custom format selector</h4><pre><code>import yt_dlp\n\nURLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']\n\ndef format_selector(ctx):\n    \"\"\" Select the best video and the best audio that won't result in an mkv.\n    NOTE: This is just an example and does not handle all cases \"\"\"\n\n    # formats are already sorted worst to best\n    formats = ctx.get('formats')[::-1]\n\n    # acodec='none' means there is no audio\n    best_video = next(f for f in formats\n                      if f['vcodec'] != 'none' and f['acodec'] == 'none')\n\n    # find compatible audio extension\n    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]\n    # vcodec='none' means there is no video\n    best_audio = next(f for f in formats if (\n        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))\n\n    # These are the minimum required fields for a merged format\n    yield {\n        'format_id': f'{best_video[\"format_id\"]}+{best_audio[\"format_id\"]}',\n        'ext': best_video['ext'],\n        'requested_formats': [best_video, best_audio],\n        # Must be + separated list of protocols\n        'protocol': f'{best_video[\"protocol\"]}+{best_audio[\"protocol\"]}'\n    }\n\n\nydl_opts = {\n    'format': format_selector,\n}\n\nwith yt_dlp.YoutubeDL(ydl_opts) as ydl:\n    ydl.download(URLS)\n</code></pre><ul><li><p>: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using . This allows for much easier format selection than what is possible by simply using  (<a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples\">examples</a>)</p></li><li><p><strong>Merged with animelover1984/youtube-dl</strong>: You get most of the features and improvements from <a href=\"https://github.com/animelover1984/youtube-dl\">animelover1984/youtube-dl</a> including , , , Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. Note that NicoNico livestreams are not available. See <a href=\"https://github.com/yt-dlp/yt-dlp/pull/31\">#31</a> for details.</p></li><li><ul><li>Supports Clips, Stories (), Search (including filters), YouTube Music Search, Channel-specific search, Search prefixes (, ), Mixes, and Feeds (, , , , , )</li><li>Download livestreams from the start using  ()</li><li>Channel URLs download all uploads of the channel, including shorts and live</li></ul></li><li><p>: Cookies can be automatically extracted from all major web browsers using <code>--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]</code></p></li><li><p>: Videos can be downloaded partially based on either timestamps or chapters using </p></li><li><p>: Videos can be split into multiple files based on chapters using </p></li><li><p><strong>Multi-threaded fragment downloads</strong>: Download multiple fragments of m3u8/mpd videos in parallel. Use  () option to set the number of threads used</p></li><li><p>: You can use  as the external downloader for DASH(mpd) and HLS(m3u8) formats</p></li><li><p>: Philo, Spectrum, SlingTV, Cablevision, RCN etc.</p></li><li><p><strong>Subtitle extraction from manifests</strong>: Subtitles can be extracted from streaming media manifests. See <a href=\"https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f\">commit/be6202f</a> for details</p></li><li><p><strong>Multiple paths and output templates</strong>: You can give different <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template\">output templates</a> and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using  ()</p></li><li><p>: Configuration files are automatically loaded from the home and root directories. See <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration\">CONFIGURATION</a> for details</p></li><li><p><strong>Output template improvements</strong>: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template\">output template</a> for details. Even more advanced operations can also be done with the help of  and </p></li><li><p>: Many new options have been added such as , , , , , , , , ,  etc</p></li><li><p>: Regex and other operators in /, multiple  and , faster archive checking, more <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection\">format selection options</a>, merge multi-video/audio, multiple ,  at different stages, etc</p></li><li><p>: Extractors and PostProcessors can be loaded from an external file. See <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins\">plugins</a> for details</p></li><li><p>: The releases can be updated using , and downgraded using  if required</p></li></ul><p>Features marked with a  have been back-ported to youtube-dl</p><h3>Differences in default behavior</h3><p>Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:</p><ul><li>The options  (),  () and  (), no longer work. See <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#Removed\">removed options</a> for details</li><li> is not supported as an alternative to </li><li>yt-dlp stores config files in slightly different locations to youtube-dl. See <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration\">CONFIGURATION</a> for a list of correct locations</li><li>The default <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template\">output template</a> is <code>%(title)s [%(id)s].%(ext)s</code>. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to . Instead, you may use <code>--compat-options filename</code></li><li>The default <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats\">format sorting</a> is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the  option to change this to any order you prefer, or use <code>--compat-options format-sort</code> to use youtube-dl's sorting order. Older versions of yt-dlp preferred VP9 due to its broader compatibility; you can use <code>--compat-options prefer-vp9-sort</code> to revert to that format sorting preference. These two compat options cannot be used together</li><li>The default format selector is . This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use  or <code>--compat-options format-spec</code> to revert this</li><li>Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of ). If needed, this feature must be enabled using  and . You can also use <code>--compat-options multistreams</code> to enable both</li><li> is enabled by default. Use  or <code>--compat-options abort-on-error</code> to abort on errors instead</li><li>When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use <code>--no-write-playlist-metafiles</code> or <code>--compat-options no-playlist-metafiles</code> to not write these files</li><li> attaches the  to  files in addition to writing the metadata when used with . Use  or <code>--compat-options no-attach-info-json</code> to revert this</li><li>Some metadata are embedded into different fields when using  as compared to youtube-dl. Most notably,  field contains the  and  contains the . You can <a href=\"https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata\">use </a> to modify this to your liking or use <code>--compat-options embed-metadata</code> to revert this</li><li> behaves differently when used with options like  and . See <a href=\"https://github.com/yt-dlp/yt-dlp/issues/302\">#302</a> for details. You can use <code>--compat-options playlist-index</code> if you want to keep the earlier behavior</li><li>The output of  is listed in a new format. Use <code>--compat-options list-formats</code> to revert this</li><li>Live chats (if available) are considered as subtitles. Use <code>--sub-langs all,-live_chat</code> to download all subtitles except live chat. You can also use <code>--compat-options no-live-chat</code> to prevent any live chat/danmaku from downloading</li><li>YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also,  URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use <code>--compat-options no-youtube-channel-redirect</code> to revert all these redirections</li><li>Unavailable videos are also listed for YouTube playlists. Use <code>--compat-options no-youtube-unavailable-videos</code> to remove this</li><li>The upload dates extracted from YouTube are in UTC <a href=\"https://github.com/yt-dlp/yt-dlp/raw/89e4d86171c7b7c997c77d4714542e0383bf0db0/yt_dlp/extractor/youtube.py#L3898-L3900\">when available</a>. Use <code>--compat-options no-youtube-prefer-utc-upload-date</code> to prefer the non-UTC upload date.</li><li>If  is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use <code>--compat-options no-direct-merge</code> to revert this</li><li>Thumbnail embedding in  is done with mutagen if possible. Use <code>--compat-options embed-thumbnail-atomicparsley</code> to force the use of AtomicParsley instead</li><li>Some internal metadata such as filenames are removed by default from the infojson. Use  or <code>--compat-options no-clean-infojson</code> to revert this</li><li>When  and  are used together, the subtitles are written to disk and also embedded in the media file. You can use just  to embed the subs and automatically delete the separate file. See <a href=\"https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460\">#630 (comment)</a> for more info. <code>--compat-options no-keep-subs</code> can be used to revert this</li><li> will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use <code>--compat-options no-certifi</code></li><li>yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use <code>--compat-options filename-sanitization</code> to revert to youtube-dl's behavior</li><li>yt-dlp versions between 2021.09.01 and 2023.01.02 applies  to nested playlists. This was an unintentional side-effect of <a href=\"https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88\">8f18ac</a> and is fixed in <a href=\"https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80\">d7b460</a>. Use <code>--compat-options playlist-match-filter</code> to revert this</li><li>yt-dlp versions between 2021.11.10 and 2023.06.21 estimated  values for fragmented/manifest formats. This was added for convenience in <a href=\"https://github.com/yt-dlp/yt-dlp/commit/f2fe69c7b0d208bdb1f6292b4ae92bc1e1a7444a\">f2fe69</a>, but was reverted in <a href=\"https://github.com/yt-dlp/yt-dlp/commit/0dff8e4d1e6e9fb938f4256ea9af7d81f42fd54f\">0dff8e</a> due to the potentially extreme inaccuracy of the estimated values. Use <code>--compat-options manifest-filesize-approx</code> to keep extracting the estimated values</li><li>yt-dlp uses modern http client backends such as . Use <code>--compat-options prefer-legacy-http-handler</code> to prefer the legacy http handler () to be used for standard http requests.</li><li>The sub-modules ,  are removed.</li><li>Passing  (or calling  with ) no longer alters the default format selection. See <a href=\"https://github.com/yt-dlp/yt-dlp/issues/9843\">#9843</a> for details.</li></ul><p>For ease of use, a few more compat options are available:</p><ul><li>: Use all compat options ()</li><li><code>--compat-options youtube-dl</code>: Same as <code>--compat-options all,-multistreams,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort</code></li><li><code>--compat-options youtube-dlc</code>: Same as <code>--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort</code></li><li>: Same as <code>--compat-options 2022,no-certifi,filename-sanitization,no-youtube-prefer-utc-upload-date</code></li><li>: Same as <code>--compat-options 2023,playlist-match-filter,no-external-downloader-progress,prefer-legacy-http-handler,manifest-filesize-approx</code></li><li>: Same as <code>--compat-options prefer-vp9-sort</code>. Use this to enable all future compat options</li></ul><p>The following compat options restore vulnerable behavior from before security patches:</p><ul><li><p><code>--compat-options allow-unsafe-ext</code>: Allow files with any extension (including unsafe ones) to be downloaded (<a href=\"https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j\">GHSA-79w7-vh3h-8g4j</a>)</p><blockquote><p> Only use if a valid file download is rejected because its extension is detected as uncommon</p></blockquote></li></ul><p>These are all the deprecated options and the current alternative to achieve the same effect</p><p>While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant</p><pre><code>-j, --dump-json                  --print \"%()j\"\n-F, --list-formats               --print formats_table\n--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table\n--list-subs                      --print automatic_captions_table --print subtitles_table\n</code></pre><p>While these options are redundant, they are still expected to be used due to their ease of use</p><pre><code>--get-description                --print description\n--get-duration                   --print duration_string\n--get-filename                   --print filename\n--get-format                     --print format\n--get-id                         --print id\n--get-thumbnail                  --print thumbnail\n-e, --get-title                  --print title\n-g, --get-url                    --print urls\n--match-title REGEX              --match-filters \"title ~= (?i)REGEX\"\n--reject-title REGEX             --match-filters \"title !~= (?i)REGEX\"\n--min-views COUNT                --match-filters \"view_count &gt;=? COUNT\"\n--max-views COUNT                --match-filters \"view_count &lt;=? COUNT\"\n--break-on-reject                Use --break-match-filters\n--user-agent UA                  --add-headers \"User-Agent:UA\"\n--referer URL                    --add-headers \"Referer:URL\"\n--playlist-start NUMBER          -I NUMBER:\n--playlist-end NUMBER            -I :NUMBER\n--playlist-reverse               -I ::-1\n--no-playlist-reverse            Default\n--no-colors                      --color no_color\n</code></pre><p>While these options still work, their use is not recommended since there are other alternatives to achieve the same</p><pre><code>--force-generic-extractor        --ies generic,default\n--exec-before-download CMD       --exec \"before_dl:CMD\"\n--no-exec-before-download        --no-exec\n--all-formats                    -f all\n--all-subs                       --sub-langs all --write-subs\n--print-json                     -j --no-simulate\n--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d\n--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s\n--id                             -o \"%(id)s.%(ext)s\"\n--metadata-from-title FORMAT     --parse-metadata \"%(title)s:FORMAT\"\n--hls-prefer-native              --downloader \"m3u8:native\"\n--hls-prefer-ffmpeg              --downloader \"m3u8:ffmpeg\"\n--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)\n--list-formats-as-table          --compat-options -list-formats [Default] (Alias: --no-list-formats-old)\n--youtube-skip-dash-manifest     --extractor-args \"youtube:skip=dash\" (Alias: --no-youtube-include-dash-manifest)\n--youtube-skip-hls-manifest      --extractor-args \"youtube:skip=hls\" (Alias: --no-youtube-include-hls-manifest)\n--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)\n--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)\n--geo-bypass                     --xff \"default\"\n--no-geo-bypass                  --xff \"never\"\n--geo-bypass-country CODE        --xff CODE\n--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK\n</code></pre><p>These options are not intended to be used by the end-user</p><pre><code>--test                           Download only part of video for testing extractors\n--load-pages                     Load pages dumped by --write-pages\n--youtube-print-sig-code         For testing youtube signatures\n--allow-unplayable-formats       List unplayable formats also\n--no-allow-unplayable-formats    Default\n</code></pre><p>These are aliases that are no longer documented for various reasons</p><pre><code>--avconv-location                --ffmpeg-location\n--clean-infojson                 --clean-info-json\n--cn-verification-proxy URL      --geo-verification-proxy URL\n--dump-headers                   --print-traffic\n--dump-intermediate-pages        --dump-pages\n--force-write-download-archive   --force-write-archive\n--load-info                      --load-info-json\n--no-clean-infojson              --no-clean-info-json\n--no-split-tracks                --no-split-chapters\n--no-write-srt                   --no-write-subs\n--prefer-unsecure                --prefer-insecure\n--rate-limit RATE                --limit-rate RATE\n--split-tracks                   --split-chapters\n--srt-lang LANGS                 --sub-langs LANGS\n--trim-file-names LENGTH         --trim-filenames LENGTH\n--write-srt                      --write-subs\n--yes-overwrites                 --force-overwrites\n</code></pre><p>Support for <a href=\"https://github.com/faissaloo/SponSkrub\">SponSkrub</a> has been deprecated in favor of the  options</p><pre><code>--sponskrub                      --sponsorblock-mark all\n--no-sponskrub                   --no-sponsorblock\n--sponskrub-cut                  --sponsorblock-remove all\n--no-sponskrub-cut               --sponsorblock-remove -all\n--sponskrub-force                Not applicable\n--no-sponskrub-force             Not applicable\n--sponskrub-location             Not applicable\n--sponskrub-args                 Not applicable\n</code></pre><p>These options may no longer work as intended</p><pre><code>--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)\n--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)\n-C, --call-home                  Not implemented\n--no-call-home                   Default\n--include-ads                    No longer supported\n--no-include-ads                 Default\n--write-annotations              No supported site has annotations now\n--no-write-annotations           Default\n--compat-options seperate-video-versions  No longer needed\n--compat-options no-youtube-prefer-utc-upload-date  No longer supported\n</code></pre><p>These options were deprecated since 2014 and have now been entirely removed</p><pre><code>-A, --auto-number                -o \"%(autonumber)s-%(id)s.%(ext)s\"\n-t, -l, --title, --literal       -o \"%(title)s-%(id)s.%(ext)s\"\n</code></pre><p>See the <a href=\"https://github.com/yt-dlp/yt-dlp/wiki\">Wiki</a> for more information</p>","contentLength":127463,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"mongodb-developer/GenAI-Showcase","url":"https://github.com/mongodb-developer/GenAI-Showcase","date":1739759302,"author":"","guid":863,"unread":true,"content":"<p>Welcome to MongoDB's Generative AI Showcase Repository!</p><p>Whether you are just starting out on your Generative AI journey, or looking to build advanced GenAI applications, we've got you covered. This repository has an exhaustive list of examples and sample applications that cover Retrieval-Augmented Generation (RAG), AI Agents, and industry-specific use cases.</p><p>Discover how MongoDB integrates into RAG pipelines and AI Agents, serving as a vector database, operational database, and memory provider.</p><p>This repo mainly contains:</p><ul><li>Jupyter notebooks examples for RAG, agentic applications, evaluations etc. under .</li><li>Javascipt and Python apps and demos under .</li><li>Contributions from our AI partners under .</li></ul><p>You will need to connect to a MongoDB cluster to run any of the apps or examples in this repo. Follow these steps to get set up:</p><p>As you work through these examples, if you encounter any problems, please <a href=\"https://github.com/mongodb-developer/GenAI-Showcase/issues/new\">open a new issue</a>.</p>","contentLength":909,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"cordx56/rustowl","url":"https://github.com/cordx56/rustowl","date":1739759302,"author":"","guid":864,"unread":true,"content":"<p>Visualize Ownership and Lifetimes in Rust</p><div align=\"center\"><p> Visualize ownership and lifetimes in Rust for debugging and optimization </p></div><p>RustOwl visualizes ownership movement and lifetimes of variables. When you save Rust source code, it is analyzed, and the ownership and lifetimes of variables are visualized when you hover over a variable or function call.</p><p>RustOwl visualizes those by using underlines:</p><ul><li>üü© green: variable's actual lifetime</li><li>üü¶ blue: immutable borrowing</li><li>üü™ purple: mutable borrowing</li><li>üüß orange: value moved / function call</li><li>üü• red: lifetime error - diff of lifetime between actual and expected</li></ul><p>Currently, we offer VSCode extension, Neovim plugin and Emacs package. For these editors, move the text cursor over the variable or function call you want to inspect and wait for 2 seconds to visualize the information. We implemented LSP server  with an extended protocol. So, RustOwl can be used easily from other editor.</p><p>Here we describe how to start using RustOwl with VSCode.</p><ul><li>,  and  installed</li><li>Visual Studio Code (VSCode) installed</li></ul><p>We tested this guide on macOS Sequoia 15.2 on arm64 architecture with VSCode 1.96.4 and  1.27.1.</p><p>We also tested this guide on Ubuntu 25.04 on arm64 architecture with VSCode 1.96.4 and  1.27.1. On Ubuntu, you need to run <code>apt install build-essential</code> before installing.</p><p>After installation, the extension will automatically run RustOwl when you save any Rust program in cargo workspace. The initial analysis may take some time, but from the second run onward, compile caching is used to reduce the analysis time.</p><p>We tested on Windows 11 Education 23H2 on amd64 architecture. For Windows, please clone this repository and build RustOwl manually.</p><p>To install RustOwl command, run the command below.</p><pre><code>curl -L \"https://github.com/cordx56/rustowl/releases/download/v0.1.1/install.sh\" | sh\n</code></pre><p>You can install VSCode extension from <a href=\"https://marketplace.visualstudio.com/items?itemName=cordx56.rustowl-vscode\">this link</a>.</p><p>Also, you can download VSCode extension file (  ) from <a href=\"https://github.com/cordx56/rustowl/releases/download/v0.1.1/rustowl-vscode-0.1.1.vsix\">this link</a>.</p><p>We support Neovim and Emacs. You can also create your own LSP client.</p><pre><code>{ \"cordx56/rustowl\", dependencies = { \"neovim/nvim-lspconfig\" } }\n</code></pre><pre><code>(elpaca\n  (rustowlsp\n    :host github\n    :repo \"cordx56/rustowl\"\n    :files (:defaults \"emacs/*\")))\n</code></pre><p>Here, we describe manual install instructions from source code.</p><ul><li> and  installed \n  <ul><li>You need to set up the  environment variable. To do this, follow the instructions provided by the  installer. For example, in bash, run <code>export PATH=$HOME/.cargo/bin:$PATH</code>.</li></ul></li></ul><p>RustOwl has been tested on macOS Sequoia 15.2 on arm64 architecture with  1.27.1. We have not tested the installation of dependencies from other package repositories, such as Homebrew. You may need to uninstall any Rust-related packages installed through those repositories first. Other dependencies are locked in the configuration files and will be installed automatically.</p><p>We have also tested this on Ubuntu 25.04 on arm64 architecture with  1.27.1. Additional dependencies may be required. We have confirmed that running <code>apt install build-essential</code> is necessary on a freshly installed Ubuntu for linking.</p><pre><code>cd rustowl\ncargo install --path . --locked\ncargo owlsp\n</code></pre><ul><li>VSCode installed \n  </li><li> installed \n  <ul><li>After installing Node.js, You can install  by running .</li></ul></li></ul><p>VSCode extension has been tested on macOS Sequoia 15.2 on arm64 architecture with Visual Studio Code 1.96.4, Node.js v20.16.0, and  1.22.22. Other dependencies are locked in the configuration files and will be installed automatically.</p><p>First, install the dependencies.</p><pre><code>cd vscode\nyarn install --frozen-lockfile\n</code></pre><p>Then open  directory in VSCode.</p><p>A notification to install the recommended VSCode extension will appear in the bottom right corner of VSCode. Click the install button, wait for the installation to finish, and then restart VSCode.</p><p>Open  directory again, and press the  key in the VSCode window. A new VSCode window with the extension enabled will appear.</p><p>Open cargo workspace directory in the new VSCode window.</p><p>When you save Rust files, decoration indicating the movement of ownership and lifetimes will appear in the editor.</p><p>In this tool, due to the limitations of VSCode's decoration specifications, characters with descenders, such as g or parentheses, may occasionally not display underlines properly. Additionally, we observed that the  macro sometimes produces extra output, though this does not affect usability in any significant way.</p>","contentLength":4291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"unionlabs/union","url":"https://github.com/unionlabs/union","date":1739759302,"author":"","guid":865,"unread":true,"content":"<p>The trust-minimized, zero-knowledge bridging protocol, designed for censorship resistance, extremely high security, and usage in decentralized finance.</p><p>Union is the hyper-efficient zero-knowledge infrastructure layer for general message passing, asset transfers, NFTs, and DeFi. It‚Äôs based on <a href=\"https://union.build/docs/concepts/consensus-verification/\">Consensus Verification</a> and has no dependencies on trusted third parties, oracles, multi-signatures, or MPC. It implements <a href=\"https://github.com/cosmos/ibc\" title=\"cosmos/ibc\">IBC</a> for compatibility with <a href=\"https://cosmos.network\">Cosmos</a> chains and connects to EVM chains like <a href=\"https://ethereum.org\">Ethereum</a>, <a href=\"https://github.com/berachain/beacon-kit\">Berachain (beacon-kit)</a>, <a href=\"https://github.com/OffchainLabs/arbitrum\">Arbitrum</a>, and more.</p><p>The upgradability of contracts on other chains, connections, token configurations, and evolution of the protocol will all be controlled by decentralized governance, aligning the priorities of Union with its users, validators, and operators.</p><pre><code>curl --proto '=https' --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install\n</code></pre><p><em>(Note that some components can only be built on Linux. If you are using macOS, we recommend using <a href=\"https://orbstack.dev/\">OrbStack</a> to easily set up a <a href=\"https://nixos.org\">NixOS</a> VM within two minutes. Most Union developers use macOS with <a href=\"https://orbstack.dev/\">OrbStack</a>, and there is no need to install Nix inside of the <a href=\"https://nixos.org\">NixOS</a> VM.)</em></p><p>You can now  build any of Union's components from source:</p><pre><code>nix build .#uniond -L\nnix build .#voyager -L\nnix build .#app -L\n\n# to see all packages, run:\nnix flake show\n</code></pre><p>The result of whatever you build will be in </p><p>You can now also enter our dev shell, which has all of the dependencies (, , , , etc.) you need to work on any component: <em>(Don't worry, this will not affect your system outside of this repo)</em></p><p>Run the following to format the entire repo and check your spelling before each PR:</p><p>Check the  channel on <a href=\"https://discord.union.build\">Union's discord</a> if you need any help with this.</p><p>The official docs are hosted <a href=\"https://docs.union.build\" title=\"Official Union Docs\">here</a>. Each individual component also has accompanying developer documentation for contributors, which you can find in each .</p>","contentLength":1847,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"microsoft/OmniParser","url":"https://github.com/microsoft/OmniParser","date":1739759302,"author":"","guid":866,"unread":true,"content":"<p>A simple screen parsing tool towards pure vision based GUI agent</p><p> is a comprehensive method for parsing user interface screenshots into structured and easy-to-understand elements, which significantly enhances the ability of GPT-4V to generate actions that can be accurately grounded in the corresponding regions of the interface.</p><ul><li>[2025/2] We introduce OmniTool: Control a Windows 11 VM with OmniParser + your vision model of choice. OmniTool supports out of the box the following large language models - OpenAI (4o/o1/o3-mini), DeepSeek (R1), Qwen (2.5VL) or Anthropic Computer Use. <a href=\"https://1drv.ms/v/c/650b027c18d5a573/EehZ7RzY69ZHn-MeQHrnnR4BCj3by-cLLpUVlxMjF4O65Q?e=8LxMgX\">Watch Video</a></li><li>[2025/1] V2 is coming. We achieve new state of the art results 39.5% on the new grounding benchmark <a href=\"https://github.com/likaixin2000/ScreenSpot-Pro-GUI-Grounding/tree/main\">Screen Spot Pro</a> with OmniParser v2 (will be released soon)! Read more details <a href=\"https://github.com/microsoft/OmniParser/tree/master/docs/Evaluation.md\">here</a>.</li><li>[2024/11] We release an updated version, OmniParser V1.5 which features 1) more fine grained/small icon detection, 2) prediction of whether each screen element is interactable or not. Examples in the demo.ipynb.</li><li>[2024/10] OmniParser was the #1 trending model on huggingface model hub (starting 10/29/2024).</li><li>[2024/10] Feel free to checkout our demo on <a href=\"https://huggingface.co/spaces/microsoft/OmniParser\">huggingface space</a>! (stay tuned for OmniParser + Claude Computer Use)</li><li>[2024/10] Both Interactive Region Detection Model and Icon functional description model are released! <a href=\"https://huggingface.co/microsoft/OmniParser\">Hugginface models</a></li></ul><pre><code>conda create -n \"omni\" python==3.12\nconda activate omni\npip install -r requirements.txt\n</code></pre><p>Ensure you have the V2 weights downloaded in weights folder (ensure caption weights folder is called icon_caption_florence). If not download them with:</p><pre><code>   rm -rf weights/icon_detect weights/icon_caption weights/icon_caption_florence \n   for f in icon_detect/{train_args.yaml,model.pt,model.yaml} icon_caption/{config.json,generation_config.json,model.safetensors}; do huggingface-cli download microsoft/OmniParser-v2.0 \"$f\" --local-dir weights; done\n   mv weights/icon_caption weights/icon_caption_florence\n</code></pre><p>We put together a few simple examples in the demo.ipynb.</p><p>To run gradio demo, simply run:</p><p>For the model checkpoints on huggingface model hub, please note that icon_detect model is under AGPL license since it is a license inherited from the original yolo model. And icon_caption_blip2 &amp; icon_caption_florence is under MIT license. Please refer to the LICENSE file in the folder of each model: <a href=\"https://huggingface.co/microsoft/OmniParser\">https://huggingface.co/microsoft/OmniParser</a>.</p><p>Our technical report can be found <a href=\"https://arxiv.org/abs/2408.00203\">here</a>. If you find our work useful, please consider citing our work:</p><pre><code>@misc{lu2024omniparserpurevisionbased,\n      title={OmniParser for Pure Vision Based GUI Agent}, \n      author={Yadong Lu and Jianwei Yang and Yelong Shen and Ahmed Awadallah},\n      year={2024},\n      eprint={2408.00203},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2408.00203}, \n}\n</code></pre>","contentLength":2768,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stirling-Tools/Stirling-PDF","url":"https://github.com/Stirling-Tools/Stirling-PDF","date":1739759302,"author":"","guid":867,"unread":true,"content":"<p>#1 Locally hosted web application that allows you to perform various operations on PDF files</p><p><a href=\"https://www.stirlingpdf.com\">Stirling-PDF</a> is a robust, locally hosted web-based PDF manipulation tool using Docker. It enables you to carry out various operations on PDF files, including splitting, merging, converting, reorganizing, adding images, rotating, compressing, and more. This locally hosted web application has evolved to encompass a comprehensive set of features, addressing all your PDF requirements.</p><p>All files and PDFs exist either exclusively on the client side, reside in server memory only during task execution, or temporarily reside in a file solely for the execution of the task. Any file downloaded by the user will have been deleted from the server by that point.</p><ul><li>Parallel file processing and downloads</li><li>Custom 'Pipelines' to run multiple features in a automated queue</li><li>API for integration with external scripts</li><li>Optional Login and Authentication support (see <a href=\"https://docs.stirlingpdf.com/Advanced%20Configuration/System%20and%20Security\">here</a> for documentation)</li><li>Database Backup and Import (see <a href=\"https://docs.stirlingpdf.com/Advanced%20Configuration/DATABASE\">here</a> for documentation)</li><li>Enterprise features like SSO see <a href=\"https://docs.stirlingpdf.com/Enterprise%20Edition\">here</a></li></ul><ul><li>View and modify PDFs - View multi-page PDFs with custom viewing, sorting, and searching. Plus, on-page edit features like annotating, drawing, and adding text and images. (Using PDF.js with Joxit and Liberation fonts)</li><li>Full interactive GUI for merging/splitting/rotating/moving PDFs and their pages</li><li>Merge multiple PDFs into a single resultant file</li><li>Split PDFs into multiple files at specified page numbers or extract all pages as individual files</li><li>Reorganize PDF pages into different orders</li><li>Rotate PDFs in 90-degree increments</li><li>Multi-page layout (format PDFs into a multi-paged page)</li><li>Scale page contents size by set percentage</li><li>Auto-split PDF (with physically scanned page dividers)</li><li>Convert PDF to a single page</li><li>Overlay PDFs on top of each other</li></ul><ul><li>Convert PDFs to and from images</li><li>Convert any common file to PDF (using LibreOffice)</li><li>Convert PDF to Word/PowerPoint/others (using LibreOffice)</li></ul><ul><li>Change/set PDF permissions</li></ul><ul><li>Add/generate/write signatures</li><li>Detect and remove blank pages</li><li>Compare two PDFs and show differences in text</li><li>Compress PDFs to decrease their filesize (using qpdf)</li><li>Extract images from scans</li><li>Auto-rename files by detecting PDF header text</li><li>OCR on PDF (using Tesseract OCR)</li><li>PDF/A conversion (using LibreOffice)</li><li>Get all information on a PDF to view or export as JSON</li><li>Show/detect embedded JavaScript</li></ul><ul><li>Installation guides for all platforms</li></ul><p>Stirling-PDF currently supports 39 languages!</p><p>Stirling PDF offers an Enterprise edition of its software. This is the same great software but with added features, support and comforts. Check out our <a href=\"https://docs.stirlingpdf.com/Enterprise%20Edition\">Enterprise docs</a></p>","contentLength":2574,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"catchorg/Catch2","url":"https://github.com/catchorg/Catch2","date":1739672933,"author":"","guid":489,"unread":true,"content":"<p>A modern, C++-native, test framework for unit-tests, TDD and BDD - using C++14, C++17 and later (C++11 support is in v2.x branch, and C++03 on the Catch1.x branch)</p><p>Catch2 is mainly a unit testing framework for C++, but it also provides basic micro-benchmarking features, and simple BDD macros.</p><p>Catch2's main advantage is that using it is both simple and natural. Test names do not have to be valid identifiers, assertions look like normal C++ boolean expressions, and sections provide a nice and local way to share set-up and tear-down code in tests.</p><pre><code>#include &lt;catch2/catch_test_macros.hpp&gt;\n\n#include &lt;cstdint&gt;\n\nuint32_t factorial( uint32_t number ) {\n    return number &lt;= 1 ? number : factorial(number-1) * number;\n}\n\nTEST_CASE( \"Factorials are computed\", \"[factorial]\" ) {\n    REQUIRE( factorial( 1) == 1 );\n    REQUIRE( factorial( 2) == 2 );\n    REQUIRE( factorial( 3) == 6 );\n    REQUIRE( factorial(10) == 3'628'800 );\n}\n</code></pre><pre><code>#include &lt;catch2/catch_test_macros.hpp&gt;\n#include &lt;catch2/benchmark/catch_benchmark.hpp&gt;\n\n#include &lt;cstdint&gt;\n\nuint64_t fibonacci(uint64_t number) {\n    return number &lt; 2 ? number : fibonacci(number - 1) + fibonacci(number - 2);\n}\n\nTEST_CASE(\"Benchmark Fibonacci\", \"[!benchmark]\") {\n    REQUIRE(fibonacci(5) == 5);\n\n    REQUIRE(fibonacci(20) == 6'765);\n    BENCHMARK(\"fibonacci 20\") {\n        return fibonacci(20);\n    };\n\n    REQUIRE(fibonacci(25) == 75'025);\n    BENCHMARK(\"fibonacci 25\") {\n        return fibonacci(25);\n    };\n}\n</code></pre><p><em>Note that benchmarks are not run by default, so you need to run it explicitly with the  tag.</em></p><h2>Catch2 v3 has been released!</h2><p>You are on the  branch, where the v3 version is being developed. v3 brings a bunch of significant changes, the big one being that Catch2 is no longer a single-header library. Catch2 now behaves as a normal library, with multiple headers and separately compiled implementation.</p><p>The documentation is slowly being updated to take these changes into account, but this work is currently still ongoing.</p><p>For migrating from the v2 releases to v3, you should look at <a href=\"https://raw.githubusercontent.com/catchorg/Catch2/devel/docs/migrate-v2-to-v3.md#top\">our documentation</a>. It provides a simple guidelines on getting started, and collects most common migration problems.</p><p>This documentation comprises these three parts:</p>","contentLength":2190,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"block/goose","url":"https://github.com/block/goose","date":1739672933,"author":"","guid":490,"unread":true,"content":"<p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p><p align=\"center\"><strong>an open-source, extensible AI agent that goes beyond code suggestionsinstall, execute, edit, and test with any LLM</strong></p>","contentLength":231,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"pointfreeco/swift-composable-architecture","url":"https://github.com/pointfreeco/swift-composable-architecture","date":1739672933,"author":"","guid":491,"unread":true,"content":"<p>A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.</p><p>The Composable Architecture (TCA, for short) is a library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind. It can be used in SwiftUI, UIKit, and more, and on any Apple platform (iOS, macOS, iPadOS, visionOS, tvOS, and watchOS).</p><h2>What is the Composable Architecture?</h2><p>This library provides a few core tools that can be used to build applications of varying purpose and complexity. It provides compelling stories that you can follow to solve many problems you encounter day-to-day when building applications, such as:</p><ul><li><p> How to manage the state of your application using simple value types, and share state across many screens so that mutations in one screen can be immediately observed in another screen.</p></li><li><p> How to break down large features into smaller components that can be extracted to their own, isolated modules and be easily glued back together to form the feature.</p></li><li><p> How to let certain parts of the application talk to the outside world in the most testable and understandable way possible.</p></li><li><p> How to not only test a feature built in the architecture, but also write integration tests for features that have been composed of many parts, and write end-to-end tests to understand how side effects influence your application. This allows you to make strong guarantees that your business logic is running in the way you expect.</p></li><li><p> How to accomplish all of the above in a simple API with as few concepts and moving parts as possible.</p></li></ul><p>The Composable Architecture was designed over the course of many episodes on <a href=\"https://www.pointfree.co\">Point-Free</a>, a video series exploring functional programming and the Swift language, hosted by <a href=\"https://twitter.com/mbrandonw\">Brandon Williams</a> and <a href=\"https://twitter.com/stephencelis\">Stephen Celis</a>.</p><p>You can watch all of the episodes <a href=\"https://www.pointfree.co/collections/composable-architecture\">here</a>, as well as a dedicated, <a href=\"https://www.pointfree.co/collections/tours/composable-architecture-1-0\">multipart tour</a> of the architecture from scratch.</p><a href=\"https://www.pointfree.co/collections/tours/composable-architecture-1-0\"><img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0243.jpeg\" width=\"600\"></a><p>This repo comes with  of examples to demonstrate how to solve common and complex problems with the Composable Architecture. Check out <a href=\"https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples\">this</a> directory to see them all, including:</p><p>Looking for something more substantial? Check out the source code for <a href=\"https://github.com/pointfreeco/isowords\">isowords</a>, an iOS word search game built in SwiftUI and the Composable Architecture.</p><p>To build a feature using the Composable Architecture you define some types and values that model your domain:</p><ul><li>: A type that describes the data your feature needs to perform its logic and render its UI.</li><li>: A type that represents all of the actions that can happen in your feature, such as user actions, notifications, event sources and more.</li><li>: A function that describes how to evolve the current state of the app to the next state given an action. The reducer is also responsible for returning any effects that should be run, such as API requests, which can be done by returning an  value.</li><li>: The runtime that actually drives your feature. You send all user actions to the store so that the store can run the reducer and effects, and you can observe state changes in the store so that you can update UI.</li></ul><p>The benefits of doing this are that you will instantly unlock testability of your feature, and you will be able to break large, complex features into smaller domains that can be glued together.</p><p>As a basic example, consider a UI that shows a number along with \"+\" and \"‚àí\" buttons that increment and decrement the number. To make things interesting, suppose there is also a button that when tapped makes an API request to fetch a random fact about that number and displays it in the view.</p><p>To implement this feature we create a new type that will house the domain and behavior of the feature, and it will be annotated with the  macro:</p><pre><code>import ComposableArchitecture\n\n@Reducer\nstruct Feature {\n}\n</code></pre><p>In here we need to define a type for the feature's state, which consists of an integer for the current count, as well as an optional string that represents the fact being presented:</p><pre><code>@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable {\n    var count = 0\n    var numberFact: String?\n  }\n}\n</code></pre><blockquote><p>[!Note] We've applied the  macro to  in order to take advantage of the observation tools in the library.</p></blockquote><p>We also need to define a type for the feature's actions. There are the obvious actions, such as tapping the decrement button, increment button, or fact button. But there are also some slightly non-obvious ones, such as the action that occurs when we receive a response from the fact API request:</p><pre><code>@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action {\n    case decrementButtonTapped\n    case incrementButtonTapped\n    case numberFactButtonTapped\n    case numberFactResponse(String)\n  }\n}\n</code></pre><p>And then we implement the  property, which is responsible for composing the actual logic and behavior for the feature. In it we can use the  reducer to describe how to change the current state to the next state, and what effects need to be executed. Some actions don't need to execute effects, and they can return  to represent that:</p><pre><code>@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action { /* ... */ }\n\n  var body: some Reducer&lt;State, Action&gt; {\n    Reduce { state, action in\n      switch action {\n      case .decrementButtonTapped:\n        state.count -= 1\n        return .none\n\n      case .incrementButtonTapped:\n        state.count += 1\n        return .none\n\n      case .numberFactButtonTapped:\n        return .run { [count = state.count] send in\n          let (data, _) = try await URLSession.shared.data(\n            from: URL(string: \"http://numbersapi.com/\\(count)/trivia\")!\n          )\n          await send(\n            .numberFactResponse(String(decoding: data, as: UTF8.self))\n          )\n        }\n\n      case let .numberFactResponse(fact):\n        state.numberFact = fact\n        return .none\n      }\n    }\n  }\n}\n</code></pre><p>And then finally we define the view that displays the feature. It holds onto a  so that it can observe all changes to the state and re-render, and we can send all user actions to the store so that state changes:</p><pre><code>struct FeatureView: View {\n  let store: StoreOf&lt;Feature&gt;\n\n  var body: some View {\n    Form {\n      Section {\n        Text(\"\\(store.count)\")\n        Button(\"Decrement\") { store.send(.decrementButtonTapped) }\n        Button(\"Increment\") { store.send(.incrementButtonTapped) }\n      }\n\n      Section {\n        Button(\"Number fact\") { store.send(.numberFactButtonTapped) }\n      }\n      \n      if let fact = store.numberFact {\n        Text(fact)\n      }\n    }\n  }\n}\n</code></pre><p>It is also straightforward to have a UIKit controller driven off of this store. You can observe state changes in the store in , and then populate the UI components with data from the store. The code is a bit longer than the SwiftUI version, so we have collapsed it here:</p><p>Once we are ready to display this view, for example in the app's entry point, we can construct a store. This can be done by specifying the initial state to start the application in, as well as the reducer that will power the application:</p><pre><code>import ComposableArchitecture\n\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n</code></pre><p>And that is enough to get something on the screen to play around with. It's definitely a few more steps than if you were to do this in a vanilla SwiftUI way, but there are a few benefits. It gives us a consistent manner to apply state mutations, instead of scattering logic in some observable objects and in various action closures of UI components. It also gives us a concise way of expressing side effects. And we can immediately test this logic, including the effects, without doing much additional work.</p><blockquote><p>[!Note] For more in-depth information on testing, see the dedicated <a href=\"https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/testing\">testing</a> article.</p></blockquote><p>To test use a , which can be created with the same information as the , but it does extra work to allow you to assert how your feature evolves as actions are sent:</p><pre><code>@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature()\n  }\n}\n</code></pre><p>Once the test store is created we can use it to make an assertion of an entire user flow of steps. Each step of the way we need to prove that state changed how we expect. For example, we can simulate the user flow of tapping on the increment and decrement buttons:</p><pre><code>// Test that tapping on the increment/decrement buttons changes the count\nawait store.send(.incrementButtonTapped) {\n  $0.count = 1\n}\nawait store.send(.decrementButtonTapped) {\n  $0.count = 0\n}\n</code></pre><p>Further, if a step causes an effect to be executed, which feeds data back into the store, we must assert on that. For example, if we simulate the user tapping on the fact button we expect to receive a fact response back with the fact, which then causes the  state to be populated:</p><pre><code>await store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = ???\n}\n</code></pre><p>However, how do we know what fact is going to be sent back to us?</p><p>Currently our reducer is using an effect that reaches out into the real world to hit an API server, and that means we have no way to control its behavior. We are at the whims of our internet connectivity and the availability of the API server in order to write this test.</p><p>It would be better for this dependency to be passed to the reducer so that we can use a live dependency when running the application on a device, but use a mocked dependency for tests. We can do this by adding a property to the  reducer:</p><pre><code>@Reducer\nstruct Feature {\n  let numberFact: (Int) async throws -&gt; String\n  // ...\n}\n</code></pre><p>Then we can use it in the  implementation:</p><pre><code>case .numberFactButtonTapped:\n  return .run { [count = state.count] send in \n    let fact = try await self.numberFact(count)\n    await send(.numberFactResponse(fact))\n  }\n</code></pre><p>And in the entry point of the application we can provide a version of the dependency that actually interacts with the real world API server:</p><pre><code>@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature(\n            numberFact: { number in\n              let (data, _) = try await URLSession.shared.data(\n                from: URL(string: \"http://numbersapi.com/\\(number)\")!\n              )\n              return String(decoding: data, as: UTF8.self)\n            }\n          )\n        }\n      )\n    }\n  }\n}\n</code></pre><p>But in tests we can use a mock dependency that immediately returns a deterministic, predictable fact:</p><pre><code>@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature(numberFact: { \"\\($0) is a good number Brent\" })\n  }\n}\n</code></pre><p>With that little bit of upfront work we can finish the test by simulating the user tapping on the fact button, and then receiving the response from the dependency to present the fact:</p><pre><code>await store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = \"0 is a good number Brent\"\n}\n</code></pre><p>We can also improve the ergonomics of using the  dependency in our application. Over time the application may evolve into many features, and some of those features may also want access to , and explicitly passing it through all layers can get annoying. There is a process you can follow to ‚Äúregister‚Äù dependencies with the library, making them instantly available to any layer in the application.</p><blockquote><p>[!Note] For more in-depth information on dependency management, see the dedicated <a href=\"https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement\">dependencies</a> article.</p></blockquote><p>We can start by wrapping the number fact functionality in a new type:</p><pre><code>struct NumberFactClient {\n  var fetch: (Int) async throws -&gt; String\n}\n</code></pre><p>And then registering that type with the dependency management system by conforming the client to the  protocol, which requires you to specify the live value to use when running the application in simulators or devices:</p><pre><code>extension NumberFactClient: DependencyKey {\n  static let liveValue = Self(\n    fetch: { number in\n      let (data, _) = try await URLSession.shared\n        .data(from: URL(string: \"http://numbersapi.com/\\(number)\")!\n      )\n      return String(decoding: data, as: UTF8.self)\n    }\n  )\n}\n\nextension DependencyValues {\n  var numberFact: NumberFactClient {\n    get { self[NumberFactClient.self] }\n    set { self[NumberFactClient.self] = newValue }\n  }\n}\n</code></pre><p>With that little bit of upfront work done you can instantly start making use of the dependency in any feature by using the  property wrapper:</p><pre><code> @Reducer\n struct Feature {\n-  let numberFact: (Int) async throws -&gt; String\n+  @Dependency(\\.numberFact) var numberFact\n   \n   ‚Ä¶\n\n-  try await self.numberFact(count)\n+  try await self.numberFact.fetch(count)\n }\n</code></pre><p>This code works exactly as it did before, but you no longer have to explicitly pass the dependency when constructing the feature's reducer. When running the app in previews, the simulator or on a device, the live dependency will be provided to the reducer, and in tests the test dependency will be provided.</p><p>This means the entry point to the application no longer needs to construct dependencies:</p><pre><code>@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n</code></pre><p>And the test store can be constructed without specifying any dependencies, but you can still override any dependency you need to for the purpose of the test:</p><pre><code>let store = TestStore(initialState: Feature.State()) {\n  Feature()\n} withDependencies: {\n  $0.numberFact.fetch = { \"\\($0) is a good number Brent\" }\n}\n\n// ...\n</code></pre><p>That is the basics of building and testing a feature in the Composable Architecture. There are  more things to be explored, such as composition, modularity, adaptability, and complex effects. The <a href=\"https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples\">Examples</a> directory has a bunch of projects to explore to see more advanced usages.</p><p>The documentation for releases and  are available here:</p><p>There are a number of articles in the documentation that you may find helpful as you become more comfortable with the library:</p><p>If you want to discuss the Composable Architecture or have a question about how to use it to solve a particular problem, there are a number of places you can discuss with fellow <a href=\"http://www.pointfree.co\">Point-Free</a> enthusiasts:</p><p>You can add ComposableArchitecture to an Xcode project by adding it as a package dependency.</p><ol><li>From the  menu, select <strong>Add Package Dependencies...</strong></li><li>Depending on how your project is structured: \n  <ul><li>If you have a single application target that needs access to the library, then add  directly to your application.</li><li>If you want to use this library from multiple Xcode targets, or mix Xcode targets and SPM targets, you must create a shared framework that depends on  and then depend on that framework in all of your targets. For an example of this, check out the <a href=\"https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/Examples/TicTacToe\">Tic-Tac-Toe</a> demo application, which splits lots of features into modules and consumes the static library in this fashion using the  Swift package.</li></ul></li></ol><p>The Composable Architecture is built with extensibility in mind, and there are a number of community-supported libraries available to enhance your applications:</p><p>If you'd like to contribute a library, please <a href=\"https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md\">open a PR</a> with a link to it!</p><p>The following translations of this README have been contributed by members of the community:</p><p>If you'd like to contribute a translation, please <a href=\"https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md\">open a PR</a> with a link to a <a href=\"https://gist.github.com\">Gist</a>!</p><p>We have a <a href=\"https://pointfreeco.github.io/swift-composable-architecture/main/documentation/composablearchitecture/faq\">dedicated article</a> for all of the most frequently asked questions and comments people have concerning the library.</p><p>The following people gave feedback on the library at its early stages and helped make the library what it is today:</p><p>Paul Colton, Kaan Dedeoglu, Matt Diephouse, Josef Dole≈æal, Eimantas, Matthew Johnson, George Kaimakas, Nikita Leonov, Christopher Liscio, Jeffrey Macko, Alejandro Martinez, Shai Mishali, Willis Plummer, Simon-Pierre Roy, Justin Price, Sven A. Schmidt, Kyle Sherman, Petr ≈†√≠ma, Jasdev Singh, Maxim Smirnov, Ryan Stone, Daniel Hollis Tavares, and all of the <a href=\"https://www.pointfree.co\">Point-Free</a> subscribers üòÅ.</p><p>Special thanks to <a href=\"https://twitter.com/liscio\">Chris Liscio</a> who helped us work through many strange SwiftUI quirks and helped refine the final API.</p><p>And thanks to <a href=\"https://github.com/freak4pc\">Shai Mishali</a> and the <a href=\"https://github.com/CombineCommunity/CombineExt/\">CombineCommunity</a> project, from which we took their implementation of , which we use in  to help bridge delegate and callback-based APIs, making it much easier to interface with 3rd party frameworks.</p><p>The Composable Architecture was built on a foundation of ideas started by other libraries, in particular <a href=\"https://elm-lang.org\">Elm</a> and <a href=\"https://redux.js.org/\">Redux</a>.</p><p>There are also many architecture libraries in the Swift and iOS community. Each one of these has their own set of priorities and trade-offs that differ from the Composable Architecture.</p><p>This library is released under the MIT license. See <a href=\"https://raw.githubusercontent.com/pointfreeco/swift-composable-architecture/main/LICENSE\">LICENSE</a> for details.</p>","contentLength":16689,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"nocodb/nocodb","url":"https://github.com/nocodb/nocodb","date":1739672933,"author":"","guid":492,"unread":true,"content":"<p>üî• üî• üî• Open Source Airtable Alternative</p><p align=\"center\"> NocoDB is the fastest and easiest way to build databases online. </p><img src=\"https://static.scarf.sh/a.png?x-pxid=c12a77cc-855e-4602-8a0f-614b2d0da56a\"><a href=\"https://discord.gg/5RgZmkW\" target=\"_blank\"><img src=\"https://discordapp.com/api/guilds/661905455894888490/widget.png?style=banner3\" alt=\"\"></a><pre><code>docker run -d \\\n  --name noco \\\n  -v \"$(pwd)\"/nocodb:/usr/app/data/ \\\n  -p 8080:8080 \\\n  nocodb/nocodb:latest\n</code></pre><pre><code>docker run -d \\\n  --name noco \\\n  -v \"$(pwd)\"/nocodb:/usr/app/data/ \\\n  -p 8080:8080 \\\n  -e NC_DB=\"pg://host.docker.internal:5432?u=root&amp;p=password&amp;d=d1\" \\\n  -e NC_AUTH_JWT_SECRET=\"569a1821-0a93-45e8-87ab-eb857f20a010\" \\\n  nocodb/nocodb:latest\n</code></pre><pre><code>nix run github:nocodb/nocodb\n</code></pre><p>To use NocoDB as a NixOS module, a flake.nix would be as follows:</p><pre><code>{\n  description = \"Bane's NixOS configuration\";\n\n  inputs = {\n    nixpkgs.url = \"github:nixos/nixpkgs/nixos-unstable\";\n    nocodb.url = \"github:nocodb/nocodb\";\n  };\n\n  outputs = inputs@{ nixpkgs, nocodb, ... }: {\n    nixosConfigurations = {\n      hostname = nixpkgs.lib.nixosSystem {\n        system = \"x86_64-linux\";\n        modules = [\n          ./configuration.nix\n          nocodb.nixosModules.nocodb\n\n          {\n            services.nocodb.enable = true;\n          }\n        ];\n      };\n    };\n  };\n}\n</code></pre><p>Auto-upstall is a single command that sets up NocoDB on a server for production usage. Behind the scenes it auto-generates docker-compose for you.</p><pre><code>bash &lt;(curl -sSL http://install.nocodb.com/noco.sh) &lt;(mktemp)\n</code></pre><p>Auto-upstall does the following: üïä</p><ul><li>üê≥ Automatically installs all pre-requisites like docker, docker-compose</li><li>üöÄ Automatically installs NocoDB with PostgreSQL, Redis, Minio, Traefik gateway using Docker Compose. üêò üóÑÔ∏è üåê</li><li>üîÑ Automatically upgrades NocoDB to the latest version when you run the command again.</li><li>üîí Automatically setups SSL and also renews it. Needs a domain or subdomain as input while installation.</li></ul><blockquote><p>Binaries are only for quick testing locally.</p></blockquote><table><thead><tr></tr></thead><tbody><tr><td><code>curl http://get.nocodb.com/macos-arm64 -o nocodb -L &amp;&amp; chmod +x nocodb &amp;&amp; ./nocodb</code></td></tr><tr><td><code>curl http://get.nocodb.com/macos-x64 -o nocodb -L &amp;&amp; chmod +x nocodb &amp;&amp; ./nocodb</code></td></tr><tr><td><code>curl http://get.nocodb.com/linux-arm64 -o nocodb -L &amp;&amp; chmod +x nocodb &amp;&amp; ./nocodb</code></td></tr><tr><td><code>curl http://get.nocodb.com/linux-x64 -o nocodb -L &amp;&amp; chmod +x nocodb &amp;&amp; ./nocodb</code></td></tr><tr><td><code>iwr http://get.nocodb.com/win-arm64.exe -OutFile Noco-win-arm64.exe &amp;&amp; .\\Noco-win-arm64.exe</code></td></tr><tr><td><code>iwr http://get.nocodb.com/win-x64.exe -OutFile Noco-win-x64.exe &amp;&amp; .\\Noco-win-x64.exe</code></td></tr></tbody></table><p>For more installation methods, please refer to <a href=\"https://docs.nocodb.com/category/installation\">our docs</a></p><h3>Rich Spreadsheet Interface</h3><ul><li>‚ö° &nbsp;Basic Operations: Create, Read, Update and Delete Tables, Columns, and Rows</li><li>‚ö° &nbsp;Fields Operations: Sort, Filter, Group, Hide / Unhide Columns</li><li>‚ö° &nbsp;Multiple Views Types: Grid (By default), Gallery, Form, Kanban and Calendar View</li><li>‚ö° &nbsp;View Permissions Types: Collaborative Views, &amp; Locked Views</li><li>‚ö° &nbsp;Share Bases / Views: either Public or Private (with Password Protected)</li><li>‚ö° &nbsp;Variant Cell Types: ID, Links, Lookup, Rollup, SingleLineText, Attachment, Currency, Formula, User, etc</li><li>‚ö° &nbsp;Access Control with Roles: Fine-grained Access Control at different levels</li></ul><h3>App Store for Workflow Automations</h3><p>We provide different integrations in three main categories. See <a href=\"https://docs.nocodb.com/account-settings/oss-specific-details/#app-store\" target=\"_blank\">App Store</a> for details.</p><ul><li>‚ö° &nbsp;Chat: Slack, Discord, Mattermost, and etc</li><li>‚ö° &nbsp;Email: AWS SES, SMTP, MailerSend, and etc</li><li>‚ö° &nbsp;Storage: AWS S3, Google Cloud Storage, Minio, and etc</li></ul><p>We provide the following ways to let users programmatically invoke actions. You can use a token (either JWT or Social Auth) to sign your requests for authorization to NocoDB.</p><ul></ul><p>Most internet businesses equip themselves with either spreadsheet or a database to solve their business needs. Spreadsheets are used by Billion+ humans collaboratively every single day. However, we are way off working at similar speeds on databases which are way more powerful tools when it comes to computing. Attempts to solve this with SaaS offerings have meant horrible access controls, vendor lock-in, data lock-in, abrupt price changes &amp; most importantly a glass ceiling on what's possible in the future.</p><p>Our mission is to provide the most powerful no-code interface for databases that is open source to every single internet business in the world. This would not only democratise access to a powerful computing tool but also bring forth a billion+ people who will have radical tinkering-and-building abilities on the internet.</p><p> This project is licensed under <a href=\"https://raw.githubusercontent.com/nocodb/nocodb/develop/LICENSE\">AGPLv3</a>. </p><p>Thank you for your contributions! We appreciate all the contributions from the community.</p><a href=\"https://github.com/nocodb/nocodb/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=nocodb/nocodb\"></a>","contentLength":4299,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"vercel/ai-chatbot","url":"https://github.com/vercel/ai-chatbot","date":1739672933,"author":"","guid":493,"unread":true,"content":"<p>A full-featured, hackable Next.js AI chatbot built by Vercel</p><a href=\"https://chat.vercel.ai/\"><img alt=\"Next.js 14 and App Router-ready AI chatbot.\" src=\"https://raw.githubusercontent.com/vercel/ai-chatbot/main/app/(chat)/opengraph-image.png\"></a><p align=\"center\"> An Open-Source AI Chatbot Template Built With Next.js and the AI SDK by Vercel. </p><ul><li><a href=\"https://nextjs.org\">Next.js</a> App Router \n  <ul><li>Advanced routing for seamless navigation and performance</li><li>React Server Components (RSCs) and Server Actions for server-side rendering and increased performance</li></ul></li><li><a href=\"https://sdk.vercel.ai/docs\">AI SDK</a><ul><li>Unified API for generating text, structured objects, and tool calls with LLMs</li><li>Hooks for building dynamic chat and generative user interfaces</li><li>Supports OpenAI (default), Anthropic, Cohere, and other model providers</li></ul></li></ul><p>You can deploy your own version of the Next.js AI Chatbot to Vercel with one click:</p><blockquote><p>Note: You should not commit your  file or it will expose secrets that will allow others to control access to your various OpenAI and authentication provider accounts.</p></blockquote><ol><li>Install Vercel CLI: </li><li>Link local instance with Vercel and GitHub accounts (creates  directory): </li><li>Download your environment variables: </li></ol>","contentLength":916,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"datawhalechina/llm-cookbook","url":"https://github.com/datawhalechina/llm-cookbook","date":1739672933,"author":"","guid":494,"unread":true,"content":"<p>Èù¢ÂêëÂºÄÂèëËÄÖÁöÑ LLM ÂÖ•Èó®ÊïôÁ®ãÔºåÂê¥ÊÅ©ËææÂ§ßÊ®°ÂûãÁ≥ªÂàóËØæÁ®ã‰∏≠ÊñáÁâà</p><p>Êú¨È°πÁõÆÊòØ‰∏Ä‰∏™Èù¢ÂêëÂºÄÂèëËÄÖÁöÑÂ§ßÊ®°ÂûãÊâãÂÜåÔºåÈíàÂØπÂõΩÂÜÖÂºÄÂèëËÄÖÁöÑÂÆûÈôÖÈúÄÊ±ÇÔºå‰∏ªÊâì LLM ÂÖ®Êñπ‰ΩçÂÖ•Èó®ÂÆûË∑µ„ÄÇÊú¨È°πÁõÆÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏àÂ§ßÊ®°ÂûãÁ≥ªÂàóËØæÁ®ãÂÜÖÂÆπÔºåÂØπÂéüËØæÁ®ãÂÜÖÂÆπËøõË°åÁ≠õÈÄâ„ÄÅÁøªËØë„ÄÅÂ§çÁé∞ÂíåË∞É‰ºòÔºåË¶ÜÁõñ‰ªé Prompt Engineering Âà∞ RAG ÂºÄÂèë„ÄÅÊ®°ÂûãÂæÆË∞ÉÁöÑÂÖ®ÈÉ®ÊµÅÁ®ãÔºåÁî®ÊúÄÈÄÇÂêàÂõΩÂÜÖÂ≠¶‰π†ËÄÖÁöÑÊñπÂºèÔºåÊåáÂØºÂõΩÂÜÖÂºÄÂèëËÄÖÂ¶Ç‰ΩïÂ≠¶‰π†„ÄÅÂÖ•Èó® LLM Áõ∏ÂÖ≥È°πÁõÆ„ÄÇ</p><p>ÈíàÂØπ‰∏çÂêåÂÜÖÂÆπÁöÑÁâπÁÇπÔºåÊàë‰ª¨ÂØπÂÖ±ËÆ° 11 Èó®Âê¥ÊÅ©ËææËÄÅÂ∏àÁöÑÂ§ßÊ®°ÂûãËØæÁ®ãËøõË°å‰∫ÜÁøªËØëÂ§çÁé∞ÔºåÂπ∂ÁªìÂêàÂõΩÂÜÖÂ≠¶‰π†ËÄÖÁöÑÂÆûÈôÖÊÉÖÂÜµÔºåÂØπ‰∏çÂêåËØæÁ®ãËøõË°å‰∫ÜÂàÜÁ∫ßÂíåÊéíÂ∫èÔºåÂàùÂ≠¶ËÄÖÂèØ‰ª•ÂÖàÁ≥ªÁªüÂ≠¶‰π†Êàë‰ª¨ÁöÑÂøÖ‰øÆÁ±ªËØæÁ®ãÔºåÊéåÊè°ÂÖ•Èó® LLM ÊâÄÊúâÊñπÂêëÈÉΩÈúÄË¶ÅÊéåÊè°ÁöÑÂü∫Á°ÄÊäÄËÉΩÂíåÊ¶ÇÂøµÔºåÂÜçÈÄâÊã©ÊÄßÂú∞Â≠¶‰π†Êàë‰ª¨ÁöÑÈÄâ‰øÆÁ±ªËØæÁ®ãÔºåÂú®Ëá™Â∑±ÊÑüÂÖ¥Ë∂£ÁöÑÊñπÂêë‰∏ä‰∏çÊñ≠Êé¢Á¥¢ÂíåÂ≠¶‰π†„ÄÇ</p><p>Â¶ÇÊûúÊúâ‰Ω†ÈùûÂ∏∏ÂñúÊ¨¢‰ΩÜÊàë‰ª¨ËøòÊ≤°ÊúâËøõË°åÂ§çÁé∞ÁöÑÂê¥ÊÅ©ËææËÄÅÂ∏àÂ§ßÊ®°ÂûãËØæÁ®ãÔºåÊàë‰ª¨Ê¨¢ËøéÊØè‰∏Ä‰ΩçÂºÄÂèëËÄÖÂèÇËÄÉÊàë‰ª¨Â∑≤ÊúâËØæÁ®ãÁöÑÊ†ºÂºèÂíåÂÜôÊ≥ïÊù•ÂØπËØæÁ®ãËøõË°åÂ§çÁé∞Âπ∂Êèê‰∫§ PRÔºåÂú® PR ÂÆ°Ê†∏ÈÄöËøáÂêéÔºåÊàë‰ª¨‰ºöÊ†πÊçÆËØæÁ®ãÂÜÖÂÆπÂ∞ÜËØæÁ®ãËøõË°åÂàÜÁ∫ßÂêàÂπ∂„ÄÇÊ¨¢ËøéÊØè‰∏Ä‰ΩçÂºÄÂèëËÄÖÁöÑË¥°ÁåÆÔºÅ</p><p>LLM Ê≠£Âú®ÈÄêÊ≠•ÊîπÂèò‰∫∫‰ª¨ÁöÑÁîüÊ¥ªÔºåËÄåÂØπ‰∫éÂºÄÂèëËÄÖÔºåÂ¶Ç‰ΩïÂü∫‰∫é LLM Êèê‰æõÁöÑ API Âø´ÈÄü„ÄÅ‰æøÊç∑Âú∞ÂºÄÂèë‰∏Ä‰∫õÂÖ∑Â§áÊõ¥Âº∫ËÉΩÂäõ„ÄÅÈõÜÊàêLLM ÁöÑÂ∫îÁî®ÔºåÊù•‰æøÊç∑Âú∞ÂÆûÁé∞‰∏Ä‰∫õÊõ¥Êñ∞È¢ñ„ÄÅÊõ¥ÂÆûÁî®ÁöÑËÉΩÂäõÔºåÊòØ‰∏Ä‰∏™ÊÄ•ÈúÄÂ≠¶‰π†ÁöÑÈáçË¶ÅËÉΩÂäõ„ÄÇ</p><p>Áî±Âê¥ÊÅ©ËææËÄÅÂ∏à‰∏é OpenAI Âêà‰ΩúÊé®Âá∫ÁöÑÂ§ßÊ®°ÂûãÁ≥ªÂàóÊïôÁ®ãÔºå‰ªéÂ§ßÊ®°ÂûãÊó∂‰ª£ÂºÄÂèëËÄÖÁöÑÂü∫Á°ÄÊäÄËÉΩÂá∫ÂèëÔºåÊ∑±ÂÖ•ÊµÖÂá∫Âú∞‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïÂü∫‰∫éÂ§ßÊ®°Âûã API„ÄÅLangChain Êû∂ÊûÑÂø´ÈÄüÂºÄÂèëÁªìÂêàÂ§ßÊ®°ÂûãÂº∫Â§ßËÉΩÂäõÁöÑÂ∫îÁî®„ÄÇÂÖ∂‰∏≠Ôºå„ÄäPrompt Engineering for Developers„ÄãÊïôÁ®ãÈù¢ÂêëÂÖ•Èó® LLM ÁöÑÂºÄÂèëËÄÖÔºåÊ∑±ÂÖ•ÊµÖÂá∫Âú∞‰ªãÁªç‰∫ÜÂØπ‰∫éÂºÄÂèëËÄÖÔºåÂ¶Ç‰ΩïÊûÑÈÄ† Prompt Âπ∂Âü∫‰∫é OpenAI Êèê‰æõÁöÑ API ÂÆûÁé∞ÂåÖÊã¨ÊÄªÁªì„ÄÅÊé®Êñ≠„ÄÅËΩ¨Êç¢Á≠âÂ§öÁßçÂ∏∏Áî®ÂäüËÉΩÔºåÊòØÂÖ•Èó® LLM ÂºÄÂèëÁöÑÁªèÂÖ∏ÊïôÁ®ãÔºõ„ÄäBuilding Systems with the ChatGPT API„ÄãÊïôÁ®ãÈù¢ÂêëÊÉ≥Ë¶ÅÂü∫‰∫é LLM ÂºÄÂèëÂ∫îÁî®Á®ãÂ∫èÁöÑÂºÄÂèëËÄÖÔºåÁÆÄÊ¥ÅÊúâÊïàËÄåÂèàÁ≥ªÁªüÂÖ®Èù¢Âú∞‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïÂü∫‰∫é ChatGPT API ÊâìÈÄ†ÂÆåÊï¥ÁöÑÂØπËØùÁ≥ªÁªüÔºõ„ÄäLangChain for LLM Application Development„ÄãÊïôÁ®ãÁªìÂêàÁªèÂÖ∏Â§ßÊ®°ÂûãÂºÄÊ∫êÊ°ÜÊû∂ LangChainÔºå‰ªãÁªç‰∫ÜÂ¶Ç‰ΩïÂü∫‰∫é LangChain Ê°ÜÊû∂ÂºÄÂèëÂÖ∑Â§áÂÆûÁî®ÂäüËÉΩ„ÄÅËÉΩÂäõÂÖ®Èù¢ÁöÑÂ∫îÁî®Á®ãÂ∫èÔºå„ÄäLangChain Chat With Your Data„ÄãÊïôÁ®ãÂàôÂú®Ê≠§Âü∫Á°Ä‰∏äËøõ‰∏ÄÊ≠•‰ªãÁªç‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî® LangChain Êû∂ÊûÑÁªìÂêà‰∏™‰∫∫ÁßÅÊúâÊï∞ÊçÆÂºÄÂèë‰∏™ÊÄßÂåñÂ§ßÊ®°ÂûãÂ∫îÁî®Ôºõ„ÄäBuilding Generative AI Applications with Gradio„Äã„ÄÅ„ÄäEvaluating and Debugging Generative AI„ÄãÊïôÁ®ãÂàÜÂà´‰ªãÁªç‰∫Ü‰∏§‰∏™ÂÆûÁî®Â∑•ÂÖ∑ Gradio ‰∏é W&amp;BÔºåÊåáÂØºÂºÄÂèëËÄÖÂ¶Ç‰ΩïÁªìÂêàËøô‰∏§‰∏™Â∑•ÂÖ∑Êù•ÊâìÈÄ†„ÄÅËØÑ‰º∞ÁîüÊàêÂºè AI Â∫îÁî®„ÄÇ</p><p>‰∏äËø∞ÊïôÁ®ãÈùûÂ∏∏ÈÄÇÁî®‰∫éÂºÄÂèëËÄÖÂ≠¶‰π†‰ª•ÂºÄÂêØÂü∫‰∫é LLM ÂÆûÈôÖÊê≠Âª∫Â∫îÁî®Á®ãÂ∫è‰πãË∑Ø„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨Â∞ÜËØ•Á≥ªÂàóËØæÁ®ãÁøªËØë‰∏∫‰∏≠ÊñáÔºåÂπ∂Â§çÁé∞ÂÖ∂ËåÉ‰æã‰ª£Á†ÅÔºå‰πü‰∏∫ÂÖ∂‰∏≠‰∏Ä‰∏™ËßÜÈ¢ëÂ¢ûÂä†‰∫Ü‰∏≠ÊñáÂ≠óÂπïÔºåÊîØÊåÅÂõΩÂÜÖ‰∏≠ÊñáÂ≠¶‰π†ËÄÖÁõ¥Êé•‰ΩøÁî®Ôºå‰ª•Â∏ÆÂä©‰∏≠ÊñáÂ≠¶‰π†ËÄÖÊõ¥Â•ΩÂú∞Â≠¶‰π† LLM ÂºÄÂèëÔºõÊàë‰ª¨‰πüÂêåÊó∂ÂÆûÁé∞‰∫ÜÊïàÊûúÂ§ßËá¥Áõ∏ÂΩìÁöÑ‰∏≠Êñá PromptÔºåÊîØÊåÅÂ≠¶‰π†ËÄÖÊÑüÂèó‰∏≠ÊñáËØ≠Â¢É‰∏ã LLM ÁöÑÂ≠¶‰π†‰ΩøÁî®ÔºåÂØπÊØîÊéåÊè°Â§öËØ≠Ë®ÄËØ≠Â¢É‰∏ãÁöÑ Prompt ËÆæËÆ°‰∏é LLM ÂºÄÂèë„ÄÇÊú™Êù•ÔºåÊàë‰ª¨‰πüÂ∞ÜÂä†ÂÖ•Êõ¥Â§ö Prompt È´òÁ∫ßÊäÄÂ∑ßÔºå‰ª•‰∏∞ÂØåÊú¨ËØæÁ®ãÂÜÖÂÆπÔºåÂ∏ÆÂä©ÂºÄÂèëËÄÖÊéåÊè°Êõ¥Â§ö„ÄÅÊõ¥Â∑ßÂ¶ôÁöÑ Prompt ÊäÄËÉΩ„ÄÇ</p><p>ÊâÄÊúâÂÖ∑Â§áÂü∫Á°Ä Python ËÉΩÂäõÔºåÊÉ≥Ë¶ÅÂÖ•Èó® LLM ÁöÑÂºÄÂèëËÄÖ„ÄÇ</p><p>„ÄäChatGPT Prompt Engineering for Developers„Äã„ÄÅ„ÄäBuilding Systems with the ChatGPT API„ÄãÁ≠âÊïôÁ®ã‰Ωú‰∏∫Áî±Âê¥ÊÅ©ËææËÄÅÂ∏à‰∏é OpenAI ËÅîÂêàÊé®Âá∫ÁöÑÂÆòÊñπÊïôÁ®ãÔºåÂú®ÂèØÈ¢ÑËßÅÁöÑÊú™Êù•‰ºöÊàê‰∏∫ LLM ÁöÑÈáçË¶ÅÂÖ•Èó®ÊïôÁ®ãÔºå‰ΩÜÊòØÁõÆÂâçËøòÂè™ÊîØÊåÅËã±ÊñáÁâà‰∏îÂõΩÂÜÖËÆøÈóÆÂèóÈôêÔºåÊâìÈÄ†‰∏≠ÊñáÁâà‰∏îÂõΩÂÜÖÊµÅÁïÖËÆøÈóÆÁöÑÊïôÁ®ãÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâÔºõÂêåÊó∂ÔºåGPT ÂØπ‰∏≠Êñá„ÄÅËã±ÊñáÂÖ∑Êúâ‰∏çÂêåÁöÑÁêÜËß£ËÉΩÂäõÔºåÊú¨ÊïôÁ®ãÂú®Â§öÊ¨°ÂØπÊØî„ÄÅÂÆûÈ™å‰πãÂêéÁ°ÆÂÆö‰∫ÜÊïàÊûúÂ§ßËá¥Áõ∏ÂΩìÁöÑ‰∏≠Êñá PromptÔºåÊîØÊåÅÂ≠¶‰π†ËÄÖÁ†îÁ©∂Â¶Ç‰ΩïÊèêÂçá ChatGPT Âú®‰∏≠ÊñáËØ≠Â¢É‰∏ãÁöÑÁêÜËß£‰∏éÁîüÊàêËÉΩÂäõ„ÄÇ</p><p>Êú¨ÊïôÁ®ãÈÄÇÁî®‰∫éÊâÄÊúâÂÖ∑Â§áÂü∫Á°Ä Python ËÉΩÂäõÔºåÊÉ≥Ë¶ÅÂÖ•Èó® LLM ÁöÑÂºÄÂèëËÄÖ„ÄÇ</p><ol><li>Ëá≥Â∞ë‰∏Ä‰∏™ LLM APIÔºàÊúÄÂ•ΩÊòØ OpenAIÔºåÂ¶ÇÊûúÊòØÂÖ∂‰ªñ APIÔºå‰Ω†ÂèØËÉΩÈúÄË¶ÅÂèÇËÄÉ<a href=\"https://github.com/datawhalechina/llm-universe\">ÂÖ∂‰ªñÊïôÁ®ã</a>ÂØπ API Ë∞ÉÁî®‰ª£Á†ÅËøõË°å‰øÆÊîπÔºâ</li><li>ËÉΩÂ§ü‰ΩøÁî® Python Jupyter Notebook</li></ol><p>Êú¨ÊïôÁ®ãÂÖ±ÂåÖÊã¨ 11 Èó®ËØæÁ®ãÔºåÂàÜ‰∏∫ÂøÖ‰øÆÁ±ª„ÄÅÈÄâ‰øÆÁ±ª‰∏§‰∏™Á±ªÂà´„ÄÇÂøÖ‰øÆÁ±ªËØæÁ®ãÊòØÊàë‰ª¨ËÆ§‰∏∫ÊúÄÈÄÇÂêàÂàùÂ≠¶ËÄÖÂ≠¶‰π†‰ª•ÂÖ•Èó® LLM ÁöÑËØæÁ®ãÔºåÂåÖÊã¨‰∫ÜÂÖ•Èó® LLM ÊâÄÊúâÊñπÂêëÈÉΩÈúÄË¶ÅÊéåÊè°ÁöÑÂü∫Á°ÄÊäÄËÉΩÂíåÊ¶ÇÂøµÔºåÊàë‰ª¨‰πüÈíàÂØπÂøÖ‰øÆÁ±ªËØæÁ®ãÂà∂‰Ωú‰∫ÜÈÄÇÂêàÈòÖËØªÁöÑÂú®Á∫øÈòÖËØªÂíå PDF ÁâàÊú¨ÔºåÂú®Â≠¶‰π†ÂøÖ‰øÆÁ±ªËØæÁ®ãÊó∂ÔºåÊàë‰ª¨Âª∫ËÆÆÂ≠¶‰π†ËÄÖÊåâÁÖßÊàë‰ª¨ÂàóÂá∫ÁöÑÈ°∫Â∫èËøõË°åÂ≠¶‰π†ÔºõÈÄâ‰øÆÁ±ªËØæÁ®ãÊòØÂú®ÂøÖ‰øÆÁ±ªËØæÁ®ã‰∏äÁöÑÊãìÂ±ïÂª∂‰º∏ÔºåÂåÖÊã¨‰∫Ü RAG ÂºÄÂèë„ÄÅÊ®°ÂûãÂæÆË∞É„ÄÅÊ®°ÂûãËØÑ‰º∞Á≠âÂ§ö‰∏™ÊñπÈù¢ÔºåÈÄÇÂêàÂ≠¶‰π†ËÄÖÂú®ÊéåÊè°‰∫ÜÂøÖ‰øÆÁ±ªËØæÁ®ã‰πãÂêéÈÄâÊã©Ëá™Â∑±ÊÑüÂÖ¥Ë∂£ÁöÑÊñπÂêëÂíåËØæÁ®ãËøõË°åÂ≠¶‰π†„ÄÇ</p><ol><li>Èù¢ÂêëÂºÄÂèëËÄÖÁöÑ Prompt Engineering„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäChatGPT Prompt Engineering for Developers„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÈù¢ÂêëÂÖ•Èó® LLM ÁöÑÂºÄÂèëËÄÖÔºåÊ∑±ÂÖ•ÊµÖÂá∫Âú∞‰ªãÁªç‰∫ÜÂØπ‰∫éÂºÄÂèëËÄÖÔºåÂ¶Ç‰ΩïÊûÑÈÄ† Prompt Âπ∂Âü∫‰∫é OpenAI Êèê‰æõÁöÑ API ÂÆûÁé∞ÂåÖÊã¨ÊÄªÁªì„ÄÅÊé®Êñ≠„ÄÅËΩ¨Êç¢Á≠âÂ§öÁßçÂ∏∏Áî®ÂäüËÉΩÔºåÊòØÂÖ•Èó® LLM ÂºÄÂèëÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇ</li><li>Êê≠Âª∫Âü∫‰∫é ChatGPT ÁöÑÈóÆÁ≠îÁ≥ªÁªü„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäBuilding Systems with the ChatGPT API„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÊåáÂØºÂºÄÂèëËÄÖÂ¶Ç‰ΩïÂü∫‰∫é ChatGPT Êèê‰æõÁöÑ API ÂºÄÂèë‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂÖ®Èù¢ÁöÑÊô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªü„ÄÇÈÄöËøá‰ª£Á†ÅÂÆûË∑µÔºåÂÆûÁé∞‰∫ÜÂü∫‰∫é ChatGPT ÂºÄÂèëÈóÆÁ≠îÁ≥ªÁªüÁöÑÂÖ®ÊµÅÁ®ãÔºå‰ªãÁªç‰∫ÜÂü∫‰∫éÂ§ßÊ®°ÂûãÂºÄÂèëÁöÑÊñ∞ËåÉÂºèÔºåÊòØÂ§ßÊ®°ÂûãÂºÄÂèëÁöÑÂÆûË∑µÂü∫Á°Ä„ÄÇ</li><li>‰ΩøÁî® LangChain ÂºÄÂèëÂ∫îÁî®Á®ãÂ∫è„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäLangChain for LLM Application Development„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÂØπ LangChain Â±ïÂºÄÊ∑±ÂÖ•‰ªãÁªçÔºåÂ∏ÆÂä©Â≠¶‰π†ËÄÖ‰∫ÜËß£Â¶Ç‰Ωï‰ΩøÁî® LangChainÔºåÂπ∂Âü∫‰∫é LangChain ÂºÄÂèëÂÆåÊï¥ÁöÑ„ÄÅÂÖ∑Â§áÂº∫Â§ßËÉΩÂäõÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇ</li><li>‰ΩøÁî® LangChain ËÆøÈóÆ‰∏™‰∫∫Êï∞ÊçÆ„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäLangChain Chat with Your Data„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÊ∑±ÂÖ•ÊãìÂ±ï LangChain Êèê‰æõÁöÑ‰∏™‰∫∫Êï∞ÊçÆËÆøÈóÆËÉΩÂäõÔºåÊåáÂØºÂºÄÂèëËÄÖÂ¶Ç‰Ωï‰ΩøÁî® LangChain ÂºÄÂèëËÉΩÂ§üËÆøÈóÆÁî®Êà∑‰∏™‰∫∫Êï∞ÊçÆ„ÄÅÊèê‰æõ‰∏™ÊÄßÂåñÊúçÂä°ÁöÑÂ§ßÊ®°ÂûãÂ∫îÁî®„ÄÇ</li></ol><ol><li>‰ΩøÁî® Gradio Êê≠Âª∫ÁîüÊàêÂºè AI Â∫îÁî®„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäBuilding Generative AI Applications with Gradio„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÊåáÂØºÂºÄÂèëËÄÖÂ¶Ç‰Ωï‰ΩøÁî® Gradio ÈÄöËøá Python Êé•Âè£Á®ãÂ∫èÂø´ÈÄü„ÄÅÈ´òÊïàÂú∞‰∏∫ÁîüÊàêÂºè AI ÊûÑÂª∫Áî®Êà∑ÁïåÈù¢„ÄÇ</li><li>ËØÑ‰º∞ÊîπËøõÁîüÊàêÂºè AI„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäEvaluating and Debugging Generative AI„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÁªìÂêà wandbÔºåÊèê‰æõ‰∏ÄÂ•óÁ≥ªÁªüÂåñÁöÑÊñπÊ≥ïÂíåÂ∑•ÂÖ∑ÔºåÂ∏ÆÂä©ÂºÄÂèëËÄÖÊúâÊïàÂú∞Ë∑üË∏™ÂíåË∞ÉËØïÁîüÊàêÂºè AI Ê®°Âûã„ÄÇ</li><li>ÂæÆË∞ÉÂ§ßËØ≠Ë®ÄÊ®°Âûã„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäFinetuning Large Language Model„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÁªìÂêà lamini Ê°ÜÊû∂ÔºåËÆ≤Ëø∞Â¶Ç‰Ωï‰æøÊç∑È´òÊïàÂú∞Âú®Êú¨Âú∞Âü∫‰∫é‰∏™‰∫∫Êï∞ÊçÆÂæÆË∞ÉÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°Âûã„ÄÇ</li><li>Â§ßÊ®°Âûã‰∏éËØ≠‰πâÊ£ÄÁ¥¢„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäLarge Language Models with Semantic Search„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÈíàÂØπÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºåËÆ≤Ëø∞‰∫ÜÂ§öÁßçÈ´òÁ∫ßÊ£ÄÁ¥¢ÊäÄÂ∑ß‰ª•ÂÆûÁé∞Êõ¥ÂáÜÁ°Æ„ÄÅÈ´òÊïàÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫ LLM ÁîüÊàêÊïàÊûú„ÄÇ</li><li>Âü∫‰∫é Chroma ÁöÑÈ´òÁ∫ßÊ£ÄÁ¥¢„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäAdvanced Retrieval for AI with Chroma„ÄãËØæÁ®ãÊâìÈÄ†ÔºåÊó®Âú®‰ªãÁªçÂü∫‰∫é Chroma ÁöÑÈ´òÁ∫ßÊ£ÄÁ¥¢ÊäÄÊúØÔºåÊèêÂçáÊ£ÄÁ¥¢ÁªìÊûúÁöÑÂáÜÁ°ÆÊÄß„ÄÇ</li><li>Êê≠Âª∫ÂíåËØÑ‰º∞È´òÁ∫ß RAG Â∫îÁî®„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäBuilding and Evaluating Advanced RAG Applications„ÄãËØæÁ®ãÊâìÈÄ†Ôºå‰ªãÁªçÊûÑÂª∫ÂíåÂÆûÁé∞È´òË¥®ÈáèRAGÁ≥ªÁªüÊâÄÈúÄÁöÑÂÖ≥ÈîÆÊäÄÊúØÂíåËØÑ‰º∞Ê°ÜÊû∂„ÄÇ</li><li>LangChain ÁöÑ Functions„ÄÅTools Âíå Agents„ÄÇÂü∫‰∫éÂê¥ÊÅ©ËææËÄÅÂ∏à„ÄäFunctions, Tools and Agents with LangChain„ÄãËØæÁ®ãÊâìÈÄ†Ôºå‰ªãÁªçÂ¶Ç‰ΩïÂü∫‰∫é LangChain ÁöÑÊñ∞ËØ≠Ê≥ïÊûÑÂª∫ Agent„ÄÇ</li><li>Prompt È´òÁ∫ßÊäÄÂ∑ß„ÄÇÂåÖÊã¨ CoT„ÄÅËá™Êàë‰∏ÄËá¥ÊÄßÁ≠âÂ§öÁßç Prompt È´òÁ∫ßÊäÄÂ∑ßÁöÑÂü∫Á°ÄÁêÜËÆ∫‰∏é‰ª£Á†ÅÂÆûÁé∞„ÄÇ</li></ol><pre><code>contentÔºöÂü∫‰∫éÂéüËØæÁ®ãÂ§çÁé∞ÁöÑÂèåËØ≠Áâà‰ª£Á†ÅÔºåÂèØËøêË°åÁöÑ NotebookÔºåÊõ¥Êñ∞È¢ëÁéáÊúÄÈ´òÔºåÊõ¥Êñ∞ÈÄüÂ∫¶ÊúÄÂø´„ÄÇ\n\ndocsÔºöÂøÖ‰øÆÁ±ªËØæÁ®ãÊñáÂ≠óÊïôÁ®ãÁâàÂú®Á∫øÈòÖËØªÊ∫êÁ†ÅÔºåÈÄÇÂêàÈòÖËØªÁöÑ md„ÄÇ\n\nfiguresÔºöÂõæÁâáÊñá‰ª∂„ÄÇ\n</code></pre><ul><li><a href=\"https://github.com/0-yy-0\">È´òÁ´ã‰∏ö</a>ÔºàÂÜÖÂÆπÂàõ‰ΩúËÄÖ-DataWhaleÊàêÂëò-ÁÆóÊ≥ïÂ∑•Á®ãÂ∏àÔºâ</li><li><a href=\"https://github.com/6forwater29\">ÈôàÈÄ∏Ê∂µ</a> (ÂÜÖÂÆπÂàõ‰ΩúËÄÖ-DatawhaleÊÑèÂêëÊàêÂëò-AIÁà±Â•ΩËÄÖ)</li><li><a href=\"https://yetingyun.blog.csdn.net\">ÊõæÊµ©Èæô</a>ÔºàÂÜÖÂÆπÂàõ‰ΩúËÄÖ-Datawhale ÊÑèÂêëÊàêÂëò-JLU AI Á†îÁ©∂ÁîüÔºâ</li></ul><a href=\"https://datawhalechina.github.io/llm-cookbook/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=datawhalechina/llm-cookbook\"></a><div align=\"center\"><img src=\"https://raw.githubusercontent.com/datawhalechina/llm-cookbook/main/figures/qrcode.jpeg\" width=\"180\" height=\"180\"></div> Datawhale ÊòØ‰∏Ä‰∏™‰∏ìÊ≥®‰∫éÊï∞ÊçÆÁßëÂ≠¶‰∏é AI È¢ÜÂüüÁöÑÂºÄÊ∫êÁªÑÁªáÔºåÊ±áÈõÜ‰∫Ü‰ºóÂ§öÈ¢ÜÂüüÈô¢Ê†°ÂíåÁü•Âêç‰ºÅ‰∏öÁöÑ‰ºòÁßÄÂ≠¶‰π†ËÄÖÔºåËÅöÂêà‰∫Ü‰∏ÄÁæ§ÊúâÂºÄÊ∫êÁ≤æÁ•ûÂíåÊé¢Á¥¢Á≤æÁ•ûÁöÑÂõ¢ÈòüÊàêÂëò„ÄÇÂæÆ‰ø°ÊêúÁ¥¢ÂÖ¨‰ºóÂè∑DatawhaleÂèØ‰ª•Âä†ÂÖ•Êàë‰ª¨„ÄÇ \n","contentLength":8557,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FujiwaraChoki/MoneyPrinterV2","url":"https://github.com/FujiwaraChoki/MoneyPrinterV2","date":1739672933,"author":"","guid":495,"unread":true,"content":"<p>Automate the process of making money online.</p><p>An Application that automates the process of making money online. MPV2 (MoneyPrinter Version 2) is, as the name suggests, the second version of the MoneyPrinter project. It is a complete rewrite of the original project, with a focus on a wider range of features and a more modular architecture.</p><blockquote><p> MPV2 needs Python 3.9 to function effectively. Watch the YouTube video <a href=\"https://youtu.be/wAZ_ZSuIqfk\">here</a></p></blockquote><p>MoneyPrinter has different versions for multiple languages developed by the community for the community. Here are some known versions:</p><p>If you would like to submit your own version/fork of MoneyPrinter, please open an issue describing the changes you made to the fork.</p><blockquote><p>‚ö†Ô∏è If you are planning to reach out to scraped businesses per E-Mail, please first install the <a href=\"https://golang.org/\">Go Programming Language</a>.</p></blockquote><pre><code>git clone https://github.com/FujiwaraChoki/MoneyPrinterV2.git\n\ncd MoneyPrinterV2\n# Copy Example Configuration and fill out values in config.json\ncp config.example.json config.json\n\n# Create a virtual environment\npython -m venv venv\n\n# Activate the virtual environment - Windows\n.\\venv\\Scripts\\activate\n\n# Activate the virtual environment - Unix\nsource venv/bin/activate\n\n# Install the requirements\npip install -r requirements.txt\n</code></pre><pre><code># Run the application\npython src/main.py\n</code></pre><p>All relevant document can be found <a href=\"https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/docs/\">here</a>.</p><p>For easier usage, there are some scripts in the  directory, that can be used to directly access the core functionality of MPV2, without the need of user interaction.</p><p>All scripts need to be run from the root directory of the project, e.g. <code>bash scripts/upload_video.sh</code>.</p><p>Please read <a href=\"https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for details on our code of conduct, and the process for submitting pull requests to us. Check out <a href=\"https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/docs/Roadmap.md\">docs/Roadmap.md</a> for a list of features that need to be implemented.</p><p>Please read <a href=\"https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/CODE_OF_CONDUCT.md\">CODE_OF_CONDUCT.md</a> for details on our code of conduct, and the process for submitting pull requests to us.</p><p>MoneyPrinterV2 is licensed under <code>Affero General Public License v3.0</code>. See <a href=\"https://raw.githubusercontent.com/FujiwaraChoki/MoneyPrinterV2/main/LICENSE\">LICENSE</a> for more information.</p><p>This project is for educational purposes only. The author will not be responsible for any misuse of the information provided. All the information on this website is published in good faith and for general information purpose only. The author does not make any warranties about the completeness, reliability, and accuracy of this information. Any action you take upon the information you find on this website (FujiwaraChoki/MoneyPrinterV2), is strictly at your own risk. The author will not be liable for any losses and/or damages in connection with the use of our website.</p>","contentLength":2565,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"wger-project/wger","url":"https://github.com/wger-project/wger","date":1739672933,"author":"","guid":496,"unread":true,"content":"<p>Self hosted FLOSS fitness/workout, nutrition and weight tracker</p><img src=\"https://raw.githubusercontent.com/wger-project/wger/master/wger/core/static/images/logos/logo.png\" width=\"100\" height=\"100\" alt=\"wger logo\"><p>wger (Ààv…õ…°…ê) Workout Manager is a free, open source web application that helps you manage your personal workouts, weight and diet plans and can also be used as a simple gym management utility. It offers a REST API as well, for easy integration with other projects and tools.</p><h3>Production with docker compose</h3><p>If you want to host your own instance, take a look at the provided docker compose file. This config will persist your database and uploaded images:</p><p>If you just want to try it out:</p><pre><code>    docker run -ti --name wger.demo --publish 8000:80 wger/demo\n</code></pre><p>Please note that this image will not persist any data and overwrite your database when you pull a new version, it is only intended as an easy to setup demo</p><p>Feel free to contact us if you found this useful or if there was something that didn't behave as you expected. We can't fix what we don't know about, so please report liberally. If you're not sure if something is a bug or not, feel free to file a bug anyway.</p><p>All the code and the content is available on github:</p><p>Translate the app to your language on <a href=\"https://hosted.weblate.org/engage/wger/\">Weblate</a>.</p><p>The application is licensed under the Affero GNU General Public License 3 or later (AGPL 3+).</p><p>The initial exercise and ingredient data is licensed additionally under one of the Creative Commons licenses, see the individual exercises for more details.</p><p>The documentation is released under a CC-BY-SA: either version 4 of the License, or (at your option) any later version.</p><p>Some images were taken from Wikipedia, see the SOURCES file in their respective folders for more details.</p>","contentLength":1597,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"souzatharsis/podcastfy","url":"https://github.com/souzatharsis/podcastfy","date":1739672933,"author":"","guid":497,"unread":true,"content":"<p>An Open Source Python alternative to NotebookLM's podcast feature: Transforming Multimodal Content into Captivating Multilingual Audio Conversations with GenAI</p><p>Podcastfy is an open-source Python package that transforms multi-modal content (text, images) into engaging, multi-lingual audio conversations using GenAI. Input content includes websites, PDFs, images, YouTube videos, as well as user provided topics.</p><p>Unlike closed-source UI-based tools focused primarily on research synthesis (e.g. NotebookLM ‚ù§Ô∏è), Podcastfy focuses on open source, programmatic and bespoke generation of engaging, conversational content from a multitude of multi-modal sources, enabling customization and scale.</p><blockquote><p>\"Love that you casually built an open source version of the most popular product Google built in the last decade\"</p></blockquote><blockquote><p>\"Loving this initiative and the best I have seen so far especially for a 'non-techie' user.\"</p></blockquote><blockquote><p>\"Your library was very straightforward to work with. You did Amazing work brother üôè\"</p></blockquote><blockquote><p>\"I think it's awesome that you were inspired/recognize how hard it is to beat NotebookLM's quality, but you did an  job with this! It sounds incredible, and it's open-source! Thank you for being amazing!\"</p></blockquote><p>Sample 1: Senecio, 1922 (Paul Klee) and Connection of Civilizations (2017) by Gheorghe Virtosu</p><p>Sample 2: The Great Wave off Kanagawa, 1831 (Hokusai) and Takiyasha the Witch and the Skeleton Spectre, c. 1844 (Kuniyoshi)</p><p>Sample 3: Pop culture icon Taylor Swift and Mona Lisa, 1503 (Leonardo da Vinci)</p><table><tbody><tr><td>Lex Fridman Podcast: 5h interview with Dario Amodei Anthropic's CEO</td></tr><tr><td>Benjamin Franklin's Autobiography</td></tr></tbody></table><table><thead><tr></tr></thead><tbody><tr><td>Election polls in S√£o Paulo</td></tr></tbody></table><ul><li> (for audio processing)</li></ul><ol><li><p>Install from PyPI </p></li></ol><pre><code>from podcastfy.client import generate_podcast\n\naudio_file = generate_podcast(urls=[\"&lt;url1&gt;\", \"&lt;url2&gt;\"])\n</code></pre><pre><code>python -m podcastfy.client --url &lt;url1&gt; --url &lt;url2&gt;\n</code></pre><p>Podcastfy offers a range of customization options to tailor your AI-generated podcasts:</p><ul><li>Generate conversational content from multiple sources and formats (images, text, websites, YouTube, and PDFs).</li><li>Generate shorts (2-5 minutes) or longform (30+ minutes) podcasts.</li><li>Customize transcript and audio generation (e.g., style, language, structure).</li><li>Generate transcripts using 100+ LLM models (OpenAI, Anthropic, Google etc).</li><li>Leverage local LLMs for transcript generation for increased privacy and control.</li><li>Integrate with advanced text-to-speech models (OpenAI, Google, ElevenLabs, and Microsoft Edge).</li><li>Provide multi-language support for global content creation.</li><li>Integrate seamlessly with CLI and Python packages for automated workflows.</li></ul><ul><li>Released new Multi-Speaker TTS model (is it the one NotebookLM uses?!?)</li><li>Generate short or longform podcasts</li><li>Generate podcasts from input topic using grounded real-time web search</li><li>Integrate with 100+ LLM models (OpenAI, Anthropic, Google etc) for transcript generation</li></ul><p>This software is licensed under <a href=\"https://raw.githubusercontent.com/souzatharsis/podcastfy/main/LICENSE\">Apache 2.0</a>. See <a href=\"https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/license-guide.md\">instructions</a> if you would like to use podcastfy in your software.</p><p>We welcome contributions! See <a href=\"https://raw.githubusercontent.com/souzatharsis/podcastfy/main/GUIDELINES.md\">Guidelines</a> for more details.</p><ul><li><p> can use  to convert blog posts, articles, or multimedia content into podcast-style audio, enabling them to reach broader audiences. By transforming content into an audio format, creators can cater to users who prefer listening over reading.</p></li><li><p> can transform lecture notes, presentations, and visual materials into audio conversations, making educational content more accessible to students with different learning preferences. This is particularly beneficial for students with visual impairments or those who have difficulty processing written information.</p></li><li><p> can convert research papers, visual data, and technical content into conversational audio. This makes it easier for a wider audience, including those with disabilities, to consume and understand complex scientific information. Researchers can also create audio summaries of their work to enhance accessibility.</p></li><li><p> can use  to promote digital accessibility by providing a tool that converts multimodal content into auditory formats. This helps individuals with visual impairments, dyslexia, or other disabilities that make it challenging to consume written or visual content.</p></li></ul><a href=\"https://github.com/souzatharsis/podcastfy/graphs/contributors\"><img alt=\"contributors\" src=\"https://contrib.rocks/image?repo=souzatharsis/podcastfy\"></a>","contentLength":4093,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"tpn/pdfs","url":"https://github.com/tpn/pdfs","date":1739672933,"author":"","guid":498,"unread":true,"content":"<p>Technically-oriented PDF Collection (Papers, Specs, Decks, Manuals, etc)</p>","contentLength":72,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"go-playground/validator","url":"https://github.com/go-playground/validator","date":1739657072,"author":"","guid":391,"unread":true,"content":"<p>üíØGo Struct and Field validation, including Cross Field, Cross Struct, Map, Slice and Array diving</p><p>Package validator implements value validations for structs and individual fields based on tags.</p><p>It has the following  features:</p><ul><li>Cross Field and Cross Struct validations by using validation tags or custom validators.</li><li>Slice, Array and Map diving, which allows any or all levels of a multidimensional field to be validated.</li><li>Ability to dive into both map keys and values for validation</li><li>Handles type interface by determining it's underlying type prior to validation.</li><li>Handles custom field types such as sql driver Valuer see <a href=\"https://golang.org/src/database/sql/driver/types.go?s=1210:1293#L29\">Valuer</a></li><li>Alias validation tags, which allows for mapping of several validations to a single tag for easier defining of validations on structs</li><li>Extraction of custom defined Field Name e.g. can specify to extract the JSON name while validating and have it available in the resulting FieldError</li><li>Customizable i18n aware error messages.</li><li>Default validator for the <a href=\"https://github.com/gin-gonic/gin\">gin</a> web framework; upgrading from v8 to v9 in gin see <a href=\"https://github.com/go-playground/validator/tree/master/_examples/gin-upgrading-overriding\">here</a></li></ul><p>Please read the discussiong started <a href=\"https://github.com/go-playground/validator/discussions/1330\">here</a> if you are interested in contributing/helping maintain this package.</p><pre><code>go get github.com/go-playground/validator/v10\n</code></pre><p>Then import the validator package into your own code.</p><pre><code>import \"github.com/go-playground/validator/v10\"\n</code></pre><p>Validation functions return type error</p><p>They return type error to avoid the issue discussed in the following, where err is always != nil:</p><p>Validator returns only InvalidValidationError for bad validation input, nil or ValidationErrors as type error; so, in your code all you need to do is check if the error returned is not nil, and if it's not check if error is InvalidValidationError ( if necessary, most of the time it isn't ) type cast it to type ValidationErrors like so:</p><pre><code>err := validate.Struct(mystruct)\nvalidationErrors := err.(validator.ValidationErrors)\n</code></pre><ul><li>If new to using validator it is highly recommended to initialize it using the <code>WithRequiredStructEnabled</code> option which is opt-in to new behaviour that will become the default behaviour in v11+. See documentation for more details.</li></ul><pre><code>validate := validator.New(validator.WithRequiredStructEnabled())\n</code></pre><table><tbody><tr><td>Field Equals Another Field (relative)</td></tr><tr><td>Field Equals Another Field</td></tr><tr><td>Check the indicated characters are present in the Field</td></tr><tr><td>Check the indicated characters are not present in the field</td></tr><tr><td>Field Greater Than Another Relative Field</td></tr><tr><td>Field Greater Than or Equal To Another Relative Field</td></tr><tr><td>Field Greater Than or Equal To Another Field</td></tr><tr><td>Field Greater Than Another Field</td></tr><tr><td>Less Than Another Relative Field</td></tr><tr><td>Less Than or Equal To Another Relative Field</td></tr><tr><td>Less Than or Equal To Another Field</td></tr><tr></tr><tr><td>Field Does Not Equal Another Field (relative)</td></tr><tr><td>Field Does Not Equal Another Field</td></tr></tbody></table><table><tbody><tr><td>Classless Inter-Domain Routing CIDR</td></tr><tr><td>Classless Inter-Domain Routing CIDRv4</td></tr><tr><td>Classless Inter-Domain Routing CIDRv6</td></tr><tr><td>Full Qualified Domain Name (FQDN)</td></tr><tr></tr><tr><td>Internet Protocol Address IP</td></tr><tr><td>Internet Protocol Address IPv4</td></tr><tr><td>Internet Protocol Address IPv6</td></tr><tr><td>Internet Protocol Address IP</td></tr><tr><td>Internet Protocol Address IPv4</td></tr><tr><td>Internet Protocol Address IPv6</td></tr><tr><td>Media Access Control Address MAC</td></tr><tr><td>Transmission Control Protocol Address TCPv4</td></tr><tr><td>Transmission Control Protocol Address TCPv6</td></tr><tr><td>Transmission Control Protocol Address TCP</td></tr><tr><td>User Datagram Protocol Address UDPv4</td></tr><tr><td>User Datagram Protocol Address UDPv6</td></tr><tr><td>User Datagram Protocol Address UDP</td></tr><tr><td>Unix domain socket end point Address</td></tr><tr></tr></tbody></table><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><table><tbody><tr></tr><tr></tr><tr><td>Business Identifier Code (ISO 9362)</td></tr><tr></tr><tr><td>Bitcoin Bech32 Address (segwit)</td></tr><tr></tr><tr><td>mongodb_connection_string</td><td>MongoDB Connection String</td></tr><tr><td>SpiceDb ObjectID/Permission/Type</td></tr><tr><td>e164 formatted phone number</td></tr><tr></tr><tr><td>International Standard Book Number</td></tr><tr><td>International Standard Book Number 10</td></tr><tr><td>International Standard Book Number 13</td></tr><tr><td>International Standard Serial Number</td></tr><tr><td>Two-letter country code (ISO 3166-1 alpha-2)</td></tr><tr><td>Three-letter country code (ISO 3166-1 alpha-3)</td></tr><tr><td>Numeric country code (ISO 3166-1 numeric)</td></tr><tr><td>Country subdivision code (ISO 3166-2)</td></tr><tr></tr><tr><td>Luhn Algorithm Checksum (for strings and (u)int)</td></tr><tr></tr><tr><td>postcode_iso3166_alpha2_field</td></tr><tr><td>Social Security Number SSN</td></tr><tr><td>Universally Unique Identifier UUID</td></tr><tr><td>Universally Unique Identifier UUID v3</td></tr><tr><td>Universally Unique Identifier UUID v3 RFC4122</td></tr><tr><td>Universally Unique Identifier UUID v4</td></tr><tr><td>Universally Unique Identifier UUID v4 RFC4122</td></tr><tr><td>Universally Unique Identifier UUID v5</td></tr><tr><td>Universally Unique Identifier UUID v5 RFC4122</td></tr><tr><td>Universally Unique Identifier UUID RFC4122</td></tr><tr><td>Semantic Versioning 2.0.0</td></tr><tr><td>Universally Unique Lexicographically Sortable Identifier ULID</td></tr><tr><td>Common Vulnerabilities and Exposures Identifier (CVE id)</td></tr></tbody></table><table><tbody><tr></tr><tr></tr></tbody></table><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><table><tbody><tr><td>hexcolor|rgb|rgba|hsl|hsla</td></tr><tr><td>iso3166_1_alpha2|iso3166_1_alpha3|iso3166_1_alpha_numeric</td></tr></tbody></table><h6>Run on MacBook Pro Max M3</h6><pre><code>go version go1.23.3 darwin/arm64\ngoos: darwin\ngoarch: arm64\ncpu: Apple M3 Max\npkg: github.com/go-playground/validator/v10\nBenchmarkFieldSuccess-16                                                42461943                27.88 ns/op            0 B/op          0 allocs/op\nBenchmarkFieldSuccessParallel-16                                        486632887                2.289 ns/op           0 B/op          0 allocs/op\nBenchmarkFieldFailure-16                                                 9566167               121.3 ns/op           200 B/op          4 allocs/op\nBenchmarkFieldFailureParallel-16                                        17551471                83.68 ns/op          200 B/op          4 allocs/op\nBenchmarkFieldArrayDiveSuccess-16                                        7602306               155.6 ns/op            97 B/op          5 allocs/op\nBenchmarkFieldArrayDiveSuccessParallel-16                               20664610                59.80 ns/op           97 B/op          5 allocs/op\nBenchmarkFieldArrayDiveFailure-16                                        4659756               252.9 ns/op           301 B/op         10 allocs/op\nBenchmarkFieldArrayDiveFailureParallel-16                                8010116               152.9 ns/op           301 B/op         10 allocs/op\nBenchmarkFieldMapDiveSuccess-16                                          2834575               421.2 ns/op           288 B/op         14 allocs/op\nBenchmarkFieldMapDiveSuccessParallel-16                                  7179700               171.8 ns/op           288 B/op         14 allocs/op\nBenchmarkFieldMapDiveFailure-16                                          3081728               384.4 ns/op           376 B/op         13 allocs/op\nBenchmarkFieldMapDiveFailureParallel-16                                  6058137               204.0 ns/op           377 B/op         13 allocs/op\nBenchmarkFieldMapDiveWithKeysSuccess-16                                  2544975               464.8 ns/op           288 B/op         14 allocs/op\nBenchmarkFieldMapDiveWithKeysSuccessParallel-16                          6661954               181.4 ns/op           288 B/op         14 allocs/op\nBenchmarkFieldMapDiveWithKeysFailure-16                                  2435484               490.7 ns/op           553 B/op         16 allocs/op\nBenchmarkFieldMapDiveWithKeysFailureParallel-16                          4249617               282.0 ns/op           554 B/op         16 allocs/op\nBenchmarkFieldCustomTypeSuccess-16                                      14943525                77.35 ns/op           32 B/op          2 allocs/op\nBenchmarkFieldCustomTypeSuccessParallel-16                              64051954                20.61 ns/op           32 B/op          2 allocs/op\nBenchmarkFieldCustomTypeFailure-16                                      10721384               107.1 ns/op           184 B/op          3 allocs/op\nBenchmarkFieldCustomTypeFailureParallel-16                              18714495                69.77 ns/op          184 B/op          3 allocs/op\nBenchmarkFieldOrTagSuccess-16                                            4063124               294.3 ns/op            16 B/op          1 allocs/op\nBenchmarkFieldOrTagSuccessParallel-16                                   31903756                41.22 ns/op           18 B/op          1 allocs/op\nBenchmarkFieldOrTagFailure-16                                            7748558               146.8 ns/op           216 B/op          5 allocs/op\nBenchmarkFieldOrTagFailureParallel-16                                   13139854                92.05 ns/op          216 B/op          5 allocs/op\nBenchmarkStructLevelValidationSuccess-16                                16808389                70.25 ns/op           16 B/op          1 allocs/op\nBenchmarkStructLevelValidationSuccessParallel-16                        90686955                14.47 ns/op           16 B/op          1 allocs/op\nBenchmarkStructLevelValidationFailure-16                                 5818791               200.2 ns/op           264 B/op          7 allocs/op\nBenchmarkStructLevelValidationFailureParallel-16                        11115874               107.5 ns/op           264 B/op          7 allocs/op\nBenchmarkStructSimpleCustomTypeSuccess-16                                7764956               151.9 ns/op            32 B/op          2 allocs/op\nBenchmarkStructSimpleCustomTypeSuccessParallel-16                       52316265                30.37 ns/op           32 B/op          2 allocs/op\nBenchmarkStructSimpleCustomTypeFailure-16                                4195429               277.2 ns/op           416 B/op          9 allocs/op\nBenchmarkStructSimpleCustomTypeFailureParallel-16                        7305661               164.6 ns/op           432 B/op         10 allocs/op\nBenchmarkStructFilteredSuccess-16                                        6312625               186.1 ns/op           216 B/op          5 allocs/op\nBenchmarkStructFilteredSuccessParallel-16                               13684459                93.42 ns/op          216 B/op          5 allocs/op\nBenchmarkStructFilteredFailure-16                                        6751482               171.2 ns/op           216 B/op          5 allocs/op\nBenchmarkStructFilteredFailureParallel-16                               14146070                86.93 ns/op          216 B/op          5 allocs/op\nBenchmarkStructPartialSuccess-16                                         6544448               177.3 ns/op           224 B/op          4 allocs/op\nBenchmarkStructPartialSuccessParallel-16                                13951946                88.73 ns/op          224 B/op          4 allocs/op\nBenchmarkStructPartialFailure-16                                         4075833               287.5 ns/op           440 B/op          9 allocs/op\nBenchmarkStructPartialFailureParallel-16                                 7490805               161.3 ns/op           440 B/op          9 allocs/op\nBenchmarkStructExceptSuccess-16                                          4107187               281.4 ns/op           424 B/op          8 allocs/op\nBenchmarkStructExceptSuccessParallel-16                                 15979173                80.86 ns/op          208 B/op          3 allocs/op\nBenchmarkStructExceptFailure-16                                          4434372               264.3 ns/op           424 B/op          8 allocs/op\nBenchmarkStructExceptFailureParallel-16                                  8081367               154.1 ns/op           424 B/op          8 allocs/op\nBenchmarkStructSimpleCrossFieldSuccess-16                                6459542               183.4 ns/op            56 B/op          3 allocs/op\nBenchmarkStructSimpleCrossFieldSuccessParallel-16                       41013781                37.95 ns/op           56 B/op          3 allocs/op\nBenchmarkStructSimpleCrossFieldFailure-16                                4034998               292.1 ns/op           272 B/op          8 allocs/op\nBenchmarkStructSimpleCrossFieldFailureParallel-16                       11348446               115.3 ns/op           272 B/op          8 allocs/op\nBenchmarkStructSimpleCrossStructCrossFieldSuccess-16                     4448528               267.7 ns/op            64 B/op          4 allocs/op\nBenchmarkStructSimpleCrossStructCrossFieldSuccessParallel-16            26813619                48.33 ns/op           64 B/op          4 allocs/op\nBenchmarkStructSimpleCrossStructCrossFieldFailure-16                     3090646               384.5 ns/op           288 B/op          9 allocs/op\nBenchmarkStructSimpleCrossStructCrossFieldFailureParallel-16             9870906               129.5 ns/op           288 B/op          9 allocs/op\nBenchmarkStructSimpleSuccess-16                                         10675562               109.5 ns/op             0 B/op          0 allocs/op\nBenchmarkStructSimpleSuccessParallel-16                                 131159784                8.932 ns/op           0 B/op          0 allocs/op\nBenchmarkStructSimpleFailure-16                                          4094979               286.6 ns/op           416 B/op          9 allocs/op\nBenchmarkStructSimpleFailureParallel-16                                  7606663               157.9 ns/op           416 B/op          9 allocs/op\nBenchmarkStructComplexSuccess-16                                         2073470               576.0 ns/op           224 B/op          5 allocs/op\nBenchmarkStructComplexSuccessParallel-16                                 7821831               161.3 ns/op           224 B/op          5 allocs/op\nBenchmarkStructComplexFailure-16                                          576358              2001 ns/op            3042 B/op         48 allocs/op\nBenchmarkStructComplexFailureParallel-16                                 1000000              1171 ns/op            3041 B/op         48 allocs/op\nBenchmarkOneof-16                                                       22503973                52.82 ns/op            0 B/op          0 allocs/op\nBenchmarkOneofParallel-16                                                8538474               140.4 ns/op             0 B/op          0 allocs/op\n</code></pre><p>Here is a list of software that complements using this library either pre or post validation.</p><ul><li><a href=\"https://github.com/go-playground/form\">form</a> - Decodes url.Values into Go value(s) and Encodes Go value(s) into url.Values. Dual Array and Full map support.</li><li><a href=\"https://github.com/go-playground/mold\">mold</a> - A general library to help modify or set data within data structures and other objects</li></ul><h2>Maintenance and support for SDK major versions</h2><p>See prior discussion <a href=\"https://github.com/go-playground/validator/discussions/1342\">here</a> for more details.</p><p>This package is aligned with the <a href=\"https://go.dev/doc/devel/release\">Go release policy</a> in that support is guaranteed for the two most recent major versions.</p><p>This does not mean the package will not work with older versions of Go, only that we reserve the right to increase the MSGV(Minimum Supported Go Version) when the need arises to address Security issues/patches, OS issues &amp; support or newly introduced functionality that would greatly benefit the maintenance and/or usage of this package.</p><p>If and when the MSGV is increased it will be done so in a minimum of a  release bump.</p><p>Distributed under MIT License, please see license file within the code for more details.</p><p>This project has grown large enough that more than one person is required to properly support the community. If you are interested in becoming a maintainer please reach out to me <a href=\"https://github.com/deankarn\">https://github.com/deankarn</a></p>","contentLength":14908,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Oliveriver/5d-diplomacy-with-multiverse-time-travel","url":"https://github.com/Oliveriver/5d-diplomacy-with-multiverse-time-travel","date":1739657072,"author":"","guid":392,"unread":true,"content":"<p>5D Diplomacy With Multiverse Time Travel</p><p>A new standard in measuring how galaxy-brained you are, 5D Diplomacy With Multiverse Time Travel combines the classic game of pure negotiation with the modern classic game of pure disorientation. Can you convince your opponent to support an attack in the present while simultaneously backstabbing them five years ago and seven timelines over?</p><p>Inspired by and indebted to the board game <a href=\"https://instructions.hasbro.com/en-us/instruction/avalon-hill-diplomacy-cooperative-strategy-board-game\">Diplomacy</a> and the video game <a href=\"https://www.5dchesswithmultiversetimetravel.com/\">5D Chess With Multiverse Time Travel</a>. Both are excellent in their own right, so we recommend picking up a copy of each to understand the rules for 5D Diplomacy.</p><p> is a trademark of Avalon Hill. <em>5D Chess With Multiverse Time Travel</em> is a trademark of Thunkspace, LLC. <em>5D Diplomacy With Multiverse Time Travel</em> and its creators are not affiliated with either  or <em>5D Chess With Multiverse Time Travel</em>.</p><p>If you find a bug, please raise an <a href=\"https://github.com/Oliveriver/5d-diplomacy-with-multiverse-time-travel/issues\">issue</a>.</p><p>Note that official development of new features has come to an end. Issues requesting new or modified gameplay features will probably be rejected. Only bug fixes, performance improvements, and quality of life adjustments are likely to be accepted as suggestions.</p><p>Feel free to fork this repo and modify the code there if you wish to experiment with more radical changes to the rules or UI. Visit the <a href=\"https://discord.gg/g7TvjPfkVu\">5D Diplomacy Discord server</a> to discuss new rules and theory with others.</p><p>There are currently two options for installing 5D Diplomacy. Use quick installation if you just want to play the game. Use manual installation if you want to make code changes.</p><ul><li>The correct version of <a href=\"https://docker.com/\">Docker</a> for your operating system.</li></ul><ul><li>Open Docker and leave it running.</li><li>Open the CLI for your operating system and navigate inside the folder where you've downloaded this repository. If you don't know how to do this, <a href=\"https://www.freecodecamp.org/news/how-to-use-the-cli-beginner-guide/\">use this tutorial</a>.</li><li>Via the CLI, run the command <code>docker compose build frontend backend</code> and wait for it to complete.</li><li>Via the CLI, run the command  and wait for it to complete.</li><li>Wait an extra few seconds for the server to start up. If you experience errors creating a game in the next step, try waiting longer.</li></ul><p>If you ever update the code (manually or via a pull from this repository), you will need to run <code>docker compose down --rmi local</code>, then run through the steps above again. Note that this may result in the database being wiped.</p><p>To read server logs, run <code>docker compose logs -f backend</code>.</p><p>The game consists of two components, found in the  and  directories. You must set up and run both to play 5D Diplomacy, unless you're connecting to someone else's server or have implemented a custom client.</p><p>The  directory contains the original proof of concept from 2021. None of its contents are required for running the latest version of 5D Diplomacy.</p><ul><li>Navigate to the  directory.</li><li>(Optional) If you want to connect to a custom database, copy  to create a new file in the same directory called <code>appsettings.Development.json</code>. Add your database's connection string as the value for the appropriate provider under , then set the value for  to match the name of the connection string.</li><li>Run one of the following commands, depending on your configuration: \n  <ul><li>If you aren't using a custom database, i.e. if you didn't follow the optional step above, run <code>dotnet ef database update --context SqliteGameContext</code>.</li><li>If you're using a custom SQLite database, run <code>dotnet ef database update --context SqliteGameContext</code>.</li><li>If you're using a custom SQL Server database, run <code>dotnet ef database update --context SqlServerGameContext</code>.</li></ul></li><li>Run  to start the server.</li><li>The server will print its address to the console, likely <a href=\"http://localhost:5000\">http://localhost:5000</a> but it may be different. Note this down for later.</li></ul><p>Note that if you ever update the code with changes that affect the database schema (e.g. if you pull a change from this repository that includes a new migration), you will have to run the appropriate <code>dotnet ef database update</code> command again.</p><ul><li>Navigate to the  directory.</li><li>Copy  to create a new file in the same directory called .</li><li>Inside , replace  with the address of the server noted earlier.</li><li>Run  to start the client in the default browser.</li></ul><p>First see installation instructions above. 5D Diplomacy can be set to run normal games (where seven players join and enter orders individually) or sandbox games (where a single user enters all orders).</p><p>If you wish to play a normal game or let other people see one of your sandbox games, you'll need to expose the domains of your client and/or server (if everyone has set up the client themselves, only a server needs to be exposed). There are various ways to do this, although this guide does not cover them.</p><p>If you modify the code and host a game that others interact with, <strong>you must provide a link to your modified source code to comply with the terms of the AGPL license.</strong> We suggest updating the link to the source code in <code>client/src/components/pages/LandingPage.tsx</code>.</p><p>To create a normal game, one player must choose the new game option from the main menu. They must choose the adjacency setting (see game rules below). After a game has been created, the initiating player enters the game and sees the game ID in the top left corner, which they must copy and send to other players.</p><p>Other players can then use the join game option from the main menu to join with the supplied game ID.</p><p>Note that 5D Diplomacy has no in-built messaging system. Unless you want to play without press, you require a separate program to send and receive press, e.g. a messaging app or voice calls.</p><p>A possible exploit exists when playing multiplayer games. Since 5D Diplomacy has no user logins or verification, a player can join as someone else and enter their orders before them. The alternative - allowing each nation to join only once - would mean players can't rejoin after a break or connection issues. While Diplomacy is a game about breaking trust, you'll simply have to trust players not to be quite this devious.</p><p>To create a sandbox game, select new game from the main menu and choose the sandbox option. Also set the adjacency setting (see game rules below).</p><p>In sandbox mode, turns advance after submission whether all nations have orders or not.</p><p>The rules of 5D Diplomacy generally extend the rules of regular Diplomacy. This guide covers only deviations from the rules of the base game.</p><p>The game world consists of a grid of Diplomacy boards. Each row is a timeline, and each timeline progresses with boards following the standard Diplomacy turns (Spring 1901, then Fall 1901, then Winter 1901, then Spring 1902, etc.).</p><p>At a given time, only units on the active boards (those furthest to the right in each timeline) can have new orders assigned. Other units are locked into their pre-existing orders, which can't be changed, though their resolution can.</p><p>Units in spring or fall turns can be given hold, move, support or convoy orders. These are validated against standard Diplomacy adjacency rules, with extra possibilities for multiverse travel. The adjacency strictness setting (chosen when a new game is created) determines how units can move through the multiverse.</p><p>With strict adjacencies, a unit can move/support/convoy to:</p><ul><li>Any adjacent region on its own board.</li><li>The same region on a different board exactly one timeline up or down, e.g. moving from Paris in Timeline 2 to Paris in Timeline 1.</li><li>The same region on a different board exactly one board in the past, e.g. moving from Berlin in Fall 1901 to Berlin in Spring 1901. Note that moving to winter boards is forbidden and these are skipped when determining board adjacencies, so Spring 1902 is adjacent to Fall 1901.</li><li>Any region it is successfully convoyed to (see below).</li></ul><p>With loose adjacencies, a unit can move/support/convoy to:</p><ul><li>Any adjacent region on its own board.</li><li>The same region on a different board exactly one timeline up or down, or any region adjacent to that region within its board, e.g. moving from Paris in Timeline 2 to Gascony in Timeline 1.</li><li>The same region on a different board exactly one board in the past, or any region adjacent to that region within its board, e.g. moving from Berlin in Fall 1901 to Kiel in Spring 1901. Winter boards are still ignored.</li><li>Any region it is successfully convoyed to (see below).</li></ul><p>In either case, note in particular that movement one board diagonally is not permitted (without a convoy).</p><p>Convoys extend the quirk of standard Diplomacy that allows armies to move an arbitrary distance in a single turn if a chain of convoying fleets exists. Providing each fleet is adjacent to the next and all are ordered to perform the same convoy, an army could go almost anywhere.</p><p>Units are however forbidden from moving into boards that don't exist yet, even with convoys. Convoys and supports though can anticipate a future unit moving back in time, so the player can use the ghost board to enter supports/convoys via an arbitrary location in the multiverse.</p><p>Any units in (spring or fall) boards not assigned orders are given a hold order by default.</p><p>The rule of thumb for adjudication: each time all orders for a turn are submitted, all orders in the entire world are adjudicated together, as if in a single enormous Diplomacy board.</p><p>In particular, new orders could affect a prior resolution of existing orders, e.g. a unit that bounced now has support and so moves successfully. This extends to supports/convoys across time, e.g. convoys that were previously invalid may become valid if the future army appears and performs the expected move.</p><ul><li>If the new resolution matches an existing child board that spawned from this one, then no new timeline splits. So if two units bounced and both receive one new support from their relative future next turn, they still bounce and no new board is created (assuming no other changes elsewhere on this board).</li><li>If the new resolution does not match an existing child board that spawned from this one, a new timeline appears. New timelines always appear below all existing timelines, and are always created in a canonical order (earliest board first; if boards are of equal age, lowest timeline number first).</li></ul><p>Note that this is different to 5D Chess where boards can spawn above or below existing timelines, potentially changing the coordinates of existing boards. There's no concept of a turn belonging to a player in Diplomacy (instead, they belong to everyone simultaneously) and 5D Diplomacy extends this thinking, so timelines spawn in only one direction. Board coordinates also never change.</p><p>Main turns (spring and fall) and winter boards adjudicate simultaneously if all are at the end of their respective timelines. So a player may be creating builds on one board and creating moves on another in the same turn. Though of course these must be kept separate, so building is not permitted on movement boards and vice versa.</p><p>Build/disband counts are per board. If a player controls fewer centres than they have units in one timeline but more in another, the difference does not cancel out: they must disband in the former and may build only in the latter. If they fail to enter enough disbands on a given board, units are removed from that board at random.</p><p>If any board requires retreats, adjudication pauses for all boards without retreats. Retreats may only move to an adjacent region on the same board.</p><p>A player achieves victory under one of the following conditions:</p><ul><li>They are the only player to control at least 18 unique supply centres across all active boards. Unique here means unique by region name, so controlling Serbia in Timeline 1 and Serbia in Timeline 2 counts as only one supply centre.</li><li>If more than one player controls more than 18 unique supply centres, they are the only one with a clear majority. It's possible for two players to reach 18 centres in the same turn, e.g. if they have targeted different timelines.</li></ul><p>As with regular Diplomacy, it's possible for 5D Diplomacy to feature variant maps with completely different region arrangements. Other variants, such as variants with new rules, are not supported.</p><p>Modifying the server to adjudicate custom variants in 5D is simple. First, edit the list of nations in . Then edit the JSON files in the folder  to match the intended board. Any subsequent run of the server will use those to create and adjudicate worlds.</p><ul><li>Modify  to change supply centres and starting/home centres.</li><li>Modify  to change connections between regions.</li><li>Modify  to change regions.</li><li>Modify  to change starting units.</li></ul><p>Modifying the client is tricker as it is much more tied to this particular Diplomacy board. While <code>client/src/data/regions.ts</code> contains the list of regions and associated data, you will also need to replace the SVG files in  and then reference them in <code>client/src/hooks/useRegionSvg.tsx</code>.</p>","contentLength":12562,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"juspay/hyperswitch","url":"https://github.com/juspay/hyperswitch","date":1739657072,"author":"","guid":393,"unread":true,"content":"<p>An open source payments switch written in Rust to make payments fast, reliable and affordable</p><div align=\"center\">\n  Single API to access the payments ecosystem and its features \n</div><a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/#introduction\"></a> Juspay, founded in 2012, is a global leader in payment orchestration and checkout solutions, trusted by 400+ leading enterprises and brands worldwide. Hyperswitch is Juspay's new generation of composable, commercial open-source payments platform for merchant and brands. It is an enterprise-grade, transparent and modular payments platform designed to provide digital businesses access to the best payments infrastructure. \n<p>Here are the key components of Hyperswitch that deliver the whole solution:</p><ul><li><p><a href=\"https://github.com/juspay/hyperswitch\">Hyperswitch Backend</a>: Hyperswitch backend enables seamless payment processing with comprehensive support for various payment flows - authorization, authentication, void and capture workflows along with robust management of post-payment processes like refunds and chargeback handling. Additionally, Hyperswitch supports non-payment use cases by enabling connections with external FRM or authentication providers as part of the payment flow. The backend optimizes payment routing with customizable workflows, including success rate-based routing, rule-based routing, volume distribution, fallback handling, and intelligent retry mechanisms for failed payments based on specific error codes.</p></li><li><p><a href=\"https://github.com/juspay/hyperswitch-web\">SDK (Frontend)</a>: The SDK, available for web, <a href=\"https://github.com/juspay/hyperswitch-client-core\">Android, and iOS</a>, unifies the payment experience across various methods such as cards, wallets, BNPL, bank transfers, and more, while supporting the diverse payment flows of underlying PSPs. When paired with the locker, it surfaces the user's saved payment methods.</p></li><li><p><a href=\"https://github.com/juspay/hyperswitch-control-center\">Control Center</a>: The Control Center enables users to manage the entire payments stack without any coding. It allows the creation of workflows for routing, payment retries, and defining conditions to invoke 3DS, fraud risk management (FRM), and surcharge modules. The Control Center provides access to transaction, refund, and chargeback operations across all integrated PSPs, transaction-level logs for initial debugging, and detailed analytics and insights into payment performance.</p></li></ul><a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview\"></a><img src=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/features.png\"><img src=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/non-functional-features.png\"><img src=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-architecture-v1.png\"><a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/#try-hyperswitch\"></a><p>You can run Hyperswitch on your system using Docker compose after cloning this repository.</p><pre><code>git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch\ncd hyperswitch\ndocker compose up -d\n</code></pre><p>Check out the <a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/try_local_system.md\">local setup guide</a> for a more details on setting up the entire stack or component wise. This takes 15-mins and gives the following output</p><pre><code>[+] Running 2/2\n‚úî hyperswitch-control-center Pulled 2.9s\n‚úî hyperswitch-server Pulled 3.0s\n[+] Running 6/0\n\n‚úî Container hyperswitch-pg-1 Created 0.0s\n‚úî Container hyperswitch-redis-standalone-1 Created 0.0s\n‚úî Container hyperswitch-migration_runner-1 Created 0.0s\n‚úî Container hyperswitch-hyperswitch-server-1 Created 0.0s\n‚úî Container hyperswitch-hyperswitch-web-1 Created 0.0s\n‚úî Container hyperswitch-hyperswitch-control-center-1 Created 0.0s\n\nAttaching to hyperswitch-control-center-1, hyperswitch-server-1, hyperswitch-web-1, migration_runner-1, pg-1, redis-standalone-1\n</code></pre><p>The fastest and easiest way to try Hyperswitch on AWS is via our CDK scripts</p><ol><li><p>Click on the following button for a quick standalone deployment on AWS, suitable for prototyping. No code or setup is required in your system and the deployment is covered within the AWS free-tier setup.</p></li><li><p>Sign-in to your AWS console.</p></li><li><p>Follow the instructions provided on the console to successfully deploy Hyperswitch. This takes 30-45mins and gives the following output</p></li></ol><table><tbody><tr><td><code>http://hyperswitch-&lt;host-id.region&gt;.elb.amazonaws.com</code></td></tr><tr><td><code>http://&lt;cloudfront.host-id&gt;/0.103.1/v0/HyperLoader.js</code></td></tr><tr><td>Control center server running on</td><td><code>http://hyperswitch-control-center-&lt;host-id.region&gt;.elb.amazonaws.com</code>, Login with Email: </td></tr><tr><td>Hyperswitch Demo Store running on</td><td><code>http://hyperswitch-sdk-demo-&lt;host-id.region&gt;.elb.amazonaws.com</code></td></tr><tr><td><code>http://hyperswitch-logs-&lt;host-id.region&gt;.elb.amazonaws.com</code>, Login with username: , password: </td></tr></tbody></table><p>We support deployment on GCP and Azure via Helm charts which takes 30-45mins. You can read more at <a href=\"https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm\">Hyperswitch docs</a>.</p><p>You can experience the product by signing up for our <a href=\"https://app.hyperswitch.io/\">hosted sandbox</a>. The signup process accepts any email ID and provides access to the entire Control Center. You can set up connectors, define workflows for routing and retries, and even try payments from the dashboard.</p><a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/support-feature-requests\"><h2>Support, Feature requests &amp; Bugs</h2></a><p>For any support, join the conversation in <a href=\"https://join.slack.com/t/hyperswitch-io/shared_invite/zt-2jqxmpsbm-WXUENx022HjNEy~Ark7Orw\">Slack</a></p><p>For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our <a href=\"https://github.com/juspay/hyperswitch/discussions\">GitHub Discussions</a></p><a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/our-vision\"></a><p>Payments are evolving rapidly worldwide, with hundreds of processors, fraud detection systems, authentication modules, and new payment methods and flows emerging. Businesses building or managing their own payment stacks often face similar challenges, struggle with comparable issues, and find it hard to innovate at the desired pace.</p><p>Hyperswitch serves as a well-architected designed reference platform, built on best-in-class design principles, empowering businesses to own and customize their payment stack. It provides a reusable core payments stack that can be tailored to specific requirements while relying on the Hyperswitch team for enhancements, support, and continuous innovation.</p><ol><li>Embrace Payments Diversity: It will drive innovation in the ecosystem in multiple ways.</li><li>Make it Open Source: Increases trust; Improves the quality and reusability of software.</li><li>Be community driven: It enables participatory design and development.</li><li>Build it like Systems Software: This sets a high bar for Reliability, Security and Performance SLAs.</li><li>Maximise Value Creation: For developers, customers &amp; partners.</li></ol><p>This project is being created and maintained by <a href=\"https://juspay.io\">Juspay</a></p><a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning\"></a><a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license\"></a><a href=\"https://raw.githubusercontent.com/juspay/hyperswitch/main/team-behind-hyperswitch\"></a><p>The core team of 150+ engineers building Hyperswitch. Keep up the great work! ü•Ç</p><a href=\"https://github.com/juspay/hyperswitch/graphs/contributors\"><img src=\"https://contributors-img.web.app/image?repo=juspay/hyperswitch\" alt=\"Contributors\"></a>","contentLength":5742,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GitHubDaily/GitHubDaily","url":"https://github.com/GitHubDaily/GitHubDaily","date":1739657072,"author":"","guid":394,"unread":true,"content":"<p>ÂùöÊåÅÂàÜ‰∫´ GitHub ‰∏äÈ´òË¥®Èáè„ÄÅÊúâË∂£ÂÆûÁî®ÁöÑÂºÄÊ∫êÊäÄÊúØÊïôÁ®ã„ÄÅÂºÄÂèëËÄÖÂ∑•ÂÖ∑„ÄÅÁºñÁ®ãÁΩëÁ´ô„ÄÅÊäÄÊúØËµÑËÆØ„ÄÇA list cool, interesting projects of GitHub.</p><p>Â§öÂπ¥‰ª•ÂâçÔºåÊàëÊõæÁúãÂà∞ GitHub ÂºÄÊ∫êÈ°πÁõÆ‰ΩúËÄÖ„ÄÅÂÖ®Ê†àÂ∑•Á®ãÂ∏à TJ Holowaychunk ËØ¥ËøáËøô‰πà‰∏ÄÂè•ËØùÔºö</p><p>\"I don't read books, never went to school, I just read other people's code and always wonder how things work\"„ÄÇ</p><p>‰ªéÈÇ£Êó∂Ëµ∑ÔºåÊàë‰æøËÆ§‰∏∫ÔºåÈÄöËøáÈòÖËØªÊ∫êÁ†ÅÔºåÁ´ôÂú®ÂâçËæàÁöÑËßíÂ∫¶‰∏äÔºåÂéªÊÄùËÄÉ‰ª£Á†ÅÊû∂ÊûÑ‰∏éÁ®ãÂ∫èÈÄªËæëÔºå‰πÉÊòØÊèêÂçáÁºñÁ®ãÊäÄÂ∑ßÊúÄÂ•ΩÁöÑÊñπÂºè„ÄÇ</p><p>Âõ†Ê≠§ÔºåGitHub ‰πüËá™ÁÑ∂ËÄåÁÑ∂ÁöÑÔºåÊàê‰∏∫ÊàëÊúÄÂñúÁà±ÁöÑÂºÄÂèëËÄÖÂπ≥Âè∞„ÄÇ</p><p>ÁßâÁùÄÊåñÊéòÂºÄÊ∫ê‰ª∑ÂÄºÁöÑÂàùË°∑ÔºåGitHubDaily Ëá™ 2015 Âπ¥ 10 Êúà 10 Êó•Ê≠£ÂºèÊàêÁ´ã„ÄÇ</p><p>Êàë‰ª¨Â∏åÊúõËÉΩÈÄöËøáËøô‰∏Ä‰∏æÊé™ÔºåÂ∏ÆÂä©ÂºÄÂèëËÄÖ‰ª¨ÂèëÁé∞ÂΩì‰∏ãÊúÄÁÅ´ÁöÑÂºÄÊ∫êÈ°πÁõÆÔºåÊéåÊéßÊúÄÊñ∞ÊäÄÊúØÂä®ÊÄÅ, Êâ©Â§ßÊäÄÊúØËßÜÈáé, Âπ∂‰ªéÂºÄÊ∫êÈ°πÁõÆÁöÑÂ≠¶‰π†‰∏≠Ëé∑ÂæóÁºñÁ®ãËÉΩÂäõÁöÑÊèêÂçá„ÄÇ</p><p>ÁõÆÂâçÔºåGitHubDaily Â∑≤Á¥ØÁßØÂàÜ‰∫´Ë∂ÖËøá 8000 ‰∏™ÂºÄÊ∫êÈ°πÁõÆÔºåÂÜÖÂÆπÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫é GitHub ‰∏äÁöÑÂºÄÊ∫êÊäÄÊúØËµÑÊñô„ÄÅÂºÄÂèëËÄÖÂ∑•ÂÖ∑„ÄÅÁºñÁ®ãÁΩëÁ´ô‰ª•ÂèäÊàêÁÜüÂ∫îÁî®„ÄÇ</p><p>Èô§‰∫Ü GitHub ‰πãÂ§ñÔºåÊàë‰ª¨‰πüÂºÄÂßãÂú®‰∏ãÈù¢Â§ö‰∏™Á§æ‰∫§Â™í‰ΩìÂπ≥Âè∞ÔºåÂ∏ÆÂä©ÂºÄÂèëËÄÖ‰º†Êí≠‰∏éÂàÜ‰∫´‰ºòË¥®ÂºÄÊ∫êÈ°πÁõÆÔºåÊåñÊéòÂÖ∂Êú™Êù•ÁöÑÊäÄÊúØÂ∫îÁî®ÂâçÊôØ„ÄÇ</p><p>Â¶ÇÊûú‰Ω†ÊÉ≥Êé•Êî∂ÊúÄÊñ∞ÁöÑ GitHub ÂºÄÊ∫êÈ°πÁõÆËµÑËÆØÔºåÂèØ‰ª•ÂÖ≥Ê≥®‰∏Ä‰∏ãüëá</p><blockquote><p>Êúâ‰∏çÈîôÁöÑÂºÄÊ∫êÈ°πÁõÆÔºå‰πüÊ¨¢ËøéÂà∞Êú¨‰ªìÂ∫ìÁöÑ <a href=\"https://github.com/GitHubDaily/GitHubDaily/issues/new\">issues</a> Êé®ËçêÊàñËá™ËçêÈ°πÁõÆÔºåÊàë‰ª¨ÊúüÂæÖ‰Ω†ÁöÑÂàÜ‰∫´„ÄÇ</p></blockquote><p>‰∏ãÈù¢ÊòØÂØπ GitHubDaily Âú® 2024 Âπ¥ÊâÄÊé®ËçêÁöÑÈ°πÁõÆËøõË°åÂàÜÁ±ªÊï¥ÁêÜÔºåÊñπ‰æøÂ§ßÂÆ∂Êü•Êâæ‰ª•ÂæÄÂàÜ‰∫´ËøáÁöÑÂÜÖÂÆπ„ÄÇ</p>","contentLength":1556,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"cypress-io/cypress","url":"https://github.com/cypress-io/cypress","date":1739657072,"author":"","guid":395,"unread":true,"content":"<p>Fast, easy and reliable testing for anything that runs in a browser.</p><h3 align=\"center\"> The web has evolved. Finally, testing has too. </h3><p align=\"center\"> Fast, easy and reliable testing for anything that runs in a browser. </p><p>Install Cypress for Mac, Linux, or Windows, then <a href=\"https://on.cypress.io/install\">get started</a>.</p><pre><code>npm install cypress --save-dev\n</code></pre><pre><code>pnpm add cypress --save-dev\n</code></pre><p>This project is licensed under the terms of the <a href=\"https://raw.githubusercontent.com/cypress-io/cypress/develop/LICENSE\">MIT license</a>.</p><p>Configure a badge for your project's README to show your test status or test count in the <a href=\"https://www.cypress.io/cloud\">Cypress Cloud</a>.</p><p>Or let the world know your project is using Cypress with the badge below.</p><pre><code>[![Cypress.io](https://img.shields.io/badge/tested%20with-Cypress-04C38E.svg)](https://www.cypress.io/)\n</code></pre>","contentLength":647,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"microsoft/markitdown","url":"https://github.com/microsoft/markitdown","date":1739657072,"author":"","guid":396,"unread":true,"content":"<p>Python tool for converting files and office documents to Markdown.</p><blockquote><p>[!IMPORTANT] MarkItDown 0.0.2 alpha 1 (0.0.2a1) introduces a plugin-based architecture. As much as was possible, command-line and Python interfaces have remained the same as 0.0.1a3 to support backward compatibility. Please report any issues you encounter. Some interface changes may yet occur as we continue to refine MarkItDown to a first non-alpha release.</p></blockquote><p>MarkItDown is a utility for converting various files to Markdown (e.g., for indexing, text analysis, etc). It supports:</p><ul><li>Images (EXIF metadata and OCR)</li><li>Audio (EXIF metadata and speech transcription)</li><li>Text-based formats (CSV, JSON, XML)</li><li>ZIP files (iterates over contents)</li></ul><p>To install MarkItDown, use pip: . Alternatively, you can install it from the source:</p><pre><code>git clone git@github.com:microsoft/markitdown.git\ncd markitdown\npip install -e packages/markitdown\n</code></pre><pre><code>markitdown path-to-file.pdf &gt; document.md\n</code></pre><p>Or use  to specify the output file:</p><pre><code>markitdown path-to-file.pdf -o document.md\n</code></pre><p>You can also pipe content:</p><pre><code>cat path-to-file.pdf | markitdown\n</code></pre><p>MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:</p><pre><code>markitdown --list-plugins\n</code></pre><pre><code>markitdown --use-plugins path-to-file.pdf\n</code></pre><p>To find available plugins, search GitHub for the hashtag . To develop a plugin, see <code>packages/markitdown-sample-plugin</code>.</p><h3>Azure Document Intelligence</h3><p>To use Microsoft Document Intelligence for conversion:</p><pre><code>markitdown path-to-file.pdf -o document.md -d -e \"&lt;document_intelligence_endpoint&gt;\"\n</code></pre><p>More information about how to set up an Azure Document Intelligence Resource can be found <a href=\"https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0\">here</a></p><pre><code>from markitdown import MarkItDown\n\nmd = MarkItDown(enable_plugins=False) # Set to True to enable plugins\nresult = md.convert(\"test.xlsx\")\nprint(result.text_content)\n</code></pre><p>Document Intelligence conversion in Python:</p><pre><code>from markitdown import MarkItDown\n\nmd = MarkItDown(docintel_endpoint=\"&lt;document_intelligence_endpoint&gt;\")\nresult = md.convert(\"test.pdf\")\nprint(result.text_content)\n</code></pre><p>To use Large Language Models for image descriptions, provide  and :</p><pre><code>from markitdown import MarkItDown\nfrom openai import OpenAI\n\nclient = OpenAI()\nmd = MarkItDown(llm_client=client, llm_model=\"gpt-4o\")\nresult = md.convert(\"example.jpg\")\nprint(result.text_content)\n</code></pre><pre><code>docker build -t markitdown:latest .\ndocker run --rm -i markitdown:latest &lt; ~/your-file.pdf &gt; output.md\n</code></pre><p>This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit <a href=\"https://cla.opensource.microsoft.com\">https://cla.opensource.microsoft.com</a>.</p><p>When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.</p><p>You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are ofcourse just suggestions and you are welcome to contribute in any way you like.</p><ul><li><p>Navigate to the MarkItDown package:</p></li><li><p>Install  in your environment and run tests:</p><pre><code>pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/\nhatch shell\nhatch test\n</code></pre><p>(Alternative) Use the Devcontainer which has all the dependencies installed:</p><pre><code># Reopen the project in Devcontainer and run:\nhatch test\n</code></pre></li><li><p>Run pre-commit checks before submitting a PR: <code>pre-commit run --all-files</code></p></li></ul><h3>Contributing 3rd-party Plugins</h3><p>You can also contribute by creating and sharing 3rd party plugins. See <code>packages/markitdown-sample-plugin</code> for more details.</p><p>This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow <a href=\"https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general\">Microsoft's Trademark &amp; Brand Guidelines</a>. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.</p>","contentLength":4183,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"codecrafters-io/build-your-own-x","url":"https://github.com/codecrafters-io/build-your-own-x","date":1739657072,"author":"","guid":397,"unread":true,"content":"<p><em>What I cannot create, I do not understand ‚Äî Richard Feynman.</em></p>","contentLength":62,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"zaidmukaddam/scira","url":"https://github.com/zaidmukaddam/scira","date":1739657072,"author":"","guid":398,"unread":true,"content":"<p>Scira (Formerly MiniPerplx) is a minimalistic AI-powered search engine that helps you find information on the internet. Powered by Vercel AI SDK! Search with models like Grok 2.0.</p><p>A minimalistic AI-powered search engine that helps you find information on the internet.</p><ul><li><a href=\"https://tavily.com\">Tavily AI</a> - For search grounding and web search capabilities</li></ul><ul><li>: Get answers to your questions using Anthropic's Models.</li><li>: Search the web using Tavily's API.</li><li>: Get information from a specific URL.</li><li>: Get the current weather for any location using OpenWeather's API.</li><li>: Run code snippets in multiple languages using E2B's API.</li><li>: Get the location of any place using Google Maps API, Mapbox API, and TripAdvisor API.</li><li>: Track flights using AviationStack's API.</li><li><strong>Trending Movies and TV Shows</strong>: Get information about trending movies and TV shows.</li><li>: Get information about any movie or TV show.</li></ul><h2>Set Scira as your default search engine</h2><ol><li><p><strong>Open the Chrome browser settings</strong>:</p><ul><li>Click on the three vertical dots in the upper right corner of the browser.</li><li>Select \"Settings\" from the dropdown menu.</li></ul></li><li><p><strong>Go to the search engine settings</strong>:</p><ul><li>In the left sidebar, click on \"Search engine.\"</li><li>Then select \"Manage search engines and site search.\"</li></ul></li><li><ul><li>Click on \"Add\" next to \"Site search.\"</li></ul></li><li><p><strong>Set the search engine name</strong>:</p><ul><li>Enter  in the \"Search engine\" field.</li></ul></li><li><p><strong>Set the search engine URL</strong>:</p><ul><li>Enter  in the \"URL with %s in place of query\" field.</li></ul></li><li><p><strong>Set the search engine shortcut</strong>:</p><ul><li>Enter  in the \"Shortcut\" field.</li></ul></li><li><ul><li>Click on the three dots next to the search engine you just added.</li><li>Select \"Make default\" from the dropdown menu.</li></ul></li></ol><p>After completing these steps, you should be able to use Scira as your default search engine in Chrome.</p><p>The application can be run using Docker in two ways:</p><h5>Using Docker Compose (Recommended)</h5><ol><li>Make sure you have Docker and Docker Compose installed on your system</li><li>Create a  file based on  with your API keys</li><li>Run the following command in the project root: </li><li>The application will be available at </li></ol><ol><li>Create a  file based on  with your API keys</li><li>Build the Docker image: <pre><code>docker build -t scira.app .\n</code></pre></li><li>Run the container: <pre><code>docker run --env-file .env -p 3000:3000 scira.app\n</code></pre></li></ol><p>The application uses a multi-stage build process to minimize the final image size and implements security best practices. The production image runs on Node.js LTS with Alpine Linux for a minimal footprint.</p><p>To run the application locally without Docker:</p><ol><li>Sign up for accounts with the required AI providers: \n  <ul><li>Tavily (required for web search feature)</li></ul></li><li>Copy  to  and fill in your API keys</li><li>Install dependencies: </li><li>Start the development server: </li><li>Open  in your browser</li></ol><p>This project is licensed under the MIT License - see the <a href=\"https://raw.githubusercontent.com/zaidmukaddam/scira/main/LICENSE\">LICENSE</a> file for details.</p>","contentLength":2591,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"kuchin/awesome-cto","url":"https://github.com/kuchin/awesome-cto","date":1739657072,"author":"","guid":399,"unread":true,"content":"<p>‚Äî Hello, my name is Dima and I'm a CTO</p>","contentLength":40,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"golang/go","url":"https://github.com/golang/go","date":1739657072,"author":"","guid":400,"unread":true,"content":"<p>The Go programming language</p><p>Go is an open source programming language that makes it easy to build simple, reliable, and efficient software.</p><p>Unless otherwise noted, the Go source files are distributed under the BSD-style license found in the LICENSE file.</p><p>If a binary distribution is not available for your combination of operating system and architecture, visit <a href=\"https://go.dev/doc/install/source\">https://go.dev/doc/install/source</a> for source installation instructions.</p><p>Go is the work of thousands of contributors. We appreciate your help!</p><p>Note that the Go project uses the issue tracker for bug reports and proposals only. See <a href=\"https://go.dev/wiki/Questions\">https://go.dev/wiki/Questions</a> for a list of places to ask questions about the Go language.</p>","contentLength":677,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Zipstack/unstract","url":"https://github.com/Zipstack/unstract","date":1739657072,"author":"","guid":401,"unread":true,"content":"<p>No-code LLM Platform to launch APIs and ETL Pipelines to structure unstructured documents</p><p>Prompt Studio's primary reason for existence is so you can develop the necessary prompts for document data extraction super efficiently. It is a purpose-built environment that makes this not just easy for you‚Äîbut, lot of fun! The document sample, its variants, the prompts you're developing, outputs from different LLMs, the schema you're developing, costing details of the extraction and various tools that let you measure the effectiveness of your prompts are just a click away and easily accessible. Prompt Studio is designed for effective and high speed development and iteration of prompts for document data extraction. Welcome to IDP 2.0!</p><h2>üßò‚Äç‚ôÄÔ∏è Three step nirvana with Workflow Studio</h2><p>Automate critical business processes that involve complex documents with a human in the loop. Go beyond RPA with the power of Large Language Models.</p><p>üåü : Add documents to no-code Prompt Studio and do prompt engineering to extract required fields  üåü : Configure Prompt Studio project as API deployment or configure input source and output destination for ETL Pipeline üåü : Deploy Workflows as unstructured data APIs or unstructured data ETL Pipelines!</p><ul><li>Linux or MacOS (Intel or M-series)</li><li>Docker Compose (if you need to install it separately)</li></ul><p>Next, either download a release or clone this repo and do the following:</p><p>That's all there is to it!</p><p>Follow <a href=\"https://raw.githubusercontent.com/Zipstack/unstract/main/backend/README.md#authentication\">these steps</a> to change the default username and password. See <a href=\"https://docs.unstract.com/unstract/unstract_platform/user_guides/run_platform\">user guide</a> for more details on managing the platform.</p><p>Another really quick way to experience Unstract is by signing up for our <a href=\"https://us-central.unstract.com/\">hosted version</a>. It comes with a 14 day free trial!</p><p>Unstract comes well documented. You can get introduced to the <a href=\"https://docs.unstract.com/unstract/\">basics of Unstract</a>, and <a href=\"https://docs.unstract.com/unstract/unstract_platform/setup_accounts/whats_needed\">learn how to connect</a> various systems like LLMs, Vector Databases, Embedding Models and Text Extractors to it. The easiest way to wet your feet is to go through our <a href=\"https://docs.unstract.com/unstract/unstract_platform/quick_start\">Quick Start Guide</a> where you actually get to do some prompt engineering in Prompt Studio and launch an API to structure varied credit card statements!</p><p>Contributions are welcome! Please see <a href=\"https://raw.githubusercontent.com/Zipstack/unstract/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> for further details to get started easily.</p><h2>üëã Join the LLM-powered automation community</h2><p>Do copy the value of  config in either  or  file to a secure location.</p><p>Adapter credentials are encrypted by the platform using this key. Its loss or change will make all existing adapters inaccessible!</p><p>In full disclosure, Unstract integrates Posthog to track usage analytics. As you can inspect the relevant code here, we collect the minimum possible metrics. Posthog can be disabled if desired by setting  to  in the frontend's .env file.</p>","contentLength":2651,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["trending"]}