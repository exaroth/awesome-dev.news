{"id":"7caSwCnanpF82DyESN","title":"Official News","displayTitle":"Official News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":5,"items":[{"title":"How to debug code with GitHub Copilot","url":"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/","date":1740157249,"author":"Jeimy Ruiz","guid":8822,"unread":true,"content":"<p>Debugging is an essential part of a developer’s workflow—but it’s also one of the most time consuming. What if AI could streamline the process, helping you analyze, fix, and document code faster? Enter GitHub Copilot, your AI-powered coding assistant.</p><p>GitHub Copilot isn’t just for writing code—it’s also a powerful tool for debugging. Whether you’re troubleshooting in your IDE, using Copilot Chat’s slash commands like , or reviewing pull requests (PR) on github.com, GitHub Copilot offers flexible, intelligent solutions to speed up your debugging process. And with the <a href=\"https://github.com/features/copilot?utm_source=how_to_debug_blog_&amp;utm_medium=blog&amp;utm_campaign=copilot_free_feb_&amp;utm_content=topgraf\">free version of GitHub Copilot</a>, available to all personal GitHub accounts, you can start exploring these features today.</p><p>In this guide, we’ll explore how to debug code with GitHub Copilot, where to use it in your workflow, and best practices to get the most out of its capabilities. Whether you’re new to GitHub Copilot or looking to deepen your skills, this guide has something for you.</p><h2>Debugging code with GitHub Copilot: surfaces and workflows<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#debugging-code-with-github-copilot-surfaces-and-workflows\" aria-label=\"Debugging code with GitHub Copilot: surfaces and workflows\"></a></h2><p>Debugging code with GitHub Copilot can help you tackle issues faster while enhancing your understanding of the codebase. Whether you’re fixing syntax errors, refactoring inefficient code, or troubleshooting unexpected behavior, GitHub Copilot can provide valuable insights in your debugging journey.</p><p>So, how exactly does this work? “GitHub Copilot is recognizing patterns and suggesting solutions based on what it has learned,” says Christopher Harrison, Senior Developer Advocate. “Once you’ve identified the problem area, you can turn to GitHub Copilot and ask, ‘I’m giving this input but getting this output—what’s wrong?’ That’s where GitHub Copilot really shines.”</p><p>Let’s explore how GitHub Copilot can help you debug your code across different surfaces, from your IDE to github.com and even pull requests.</p><p>Copilot Chat acts as an interactive AI assistant, helping you debug issues with natural language queries. And with Copilot Free, you get 50 chat messages per month. With Copilot Chat, you can:</p><ul><li><strong>Get real-time explanations:</strong> Ask <em>“Why is this function throwing an error?”</em> and Copilot Chat will analyze the code and provide insights.  </li><li><strong>Use slash commands for debugging:</strong> Try  to generate a potential solution or  for a step-by-step breakdown of a complex function. (More on this later!)   </li><li><strong>Refactor code for efficiency:</strong> If your implementation is messy or inefficient, Copilot Chat can suggest cleaner alternatives. Christopher explains, “Refactoring improves the readability of code, making it easier for both developers and GitHub Copilot to understand. And if code is easier to understand, it’s easier to debug and spot problems.”  </li><li><strong>Walk through errors interactively:</strong> Describe your issue in chat and get tailored guidance without ever having to leave your IDE. </li></ul><p>When working in popular IDEs like VS Code or JetBrains, GitHub Copilot offers real-time suggestions as you type. It helps by:</p><ul><li> For example, if you declare a variable but forget to initialize it, GitHub Copilot can suggest a correction.  </li><li> Encounter a syntax error? GitHub Copilot can suggest a fix in seconds, ensuring your code stays error-free.  </li><li> By analyzing your workspace, GitHub Copilot provides solutions tailored to your codebase and project structure.</li></ul><p>GitHub Copilot extends beyond your IDE, offering debugging assistance directly on github.com via Copilot Chat, particularly in repositories and discussions. With this feature, you can:</p><ul><li><strong>Troubleshoot code in repositories:</strong> Open a file, highlight a problematic section, and use Copilot Chat to analyze it.  </li><li> If you’re unsure how to verify a function, GitHub Copilot can suggest test cases based on existing code.  </li><li><strong>Understand unfamiliar code:</strong> Reviewing an open-source project or a teammate’s PR? Ask GitHub Copilot to summarize a function or explain its logic.</li></ul><h3>4. For pull request assistance<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#4-for-pull-request-assistance\" aria-label=\"4. For pull request assistance\"></a></h3><p>GitHub Copilot can also streamline debugging within PRs, ensuring code quality before merging.</p><ul><li><strong>Suggest improvements in PR comments:</strong> GitHub Copilot can review PRs and propose fixes directly in the conversation.  </li><li> Struggling to describe your changes? Greg Larkin, Senior Service Delivery Engineer, says, “I use GitHub Copilot in the PR creation process to generate a summary of the changes in my feature branch compared to the branch I’m merging into. That can be really helpful when I’m struggling to figure out a good description, so that other people understand what I did.”  </li><li> Not sure why a change was made? Ask GitHub Copilot to summarize what’s different between commits.  </li><li><strong>Catch edge cases before merging:</strong> Use  to identify potential issues and  to generate missing test cases.  </li><li> If a PR contains redundant or inefficient code, GitHub Copilot can suggest optimized alternatives.</li></ul><p>By integrating Copilot into your PR workflow, you can speed up code reviews while maintaining high-quality standards. Just be sure to pair it with peer expertise for the best results.</p><p>Slash commands turn GitHub Copilot into an on-demand debugging assistant, helping you solve issues faster, get more insights, and improve your code quality. Here are some of the most useful slash commands for debugging:</p><h3>1. Use /help to get guidance on using GitHub Copilot effectively<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#1-use-help-to-get-guidance-on-using-github-copilot-effectively\" aria-label=\"1. Use /help to get guidance on using GitHub Copilot effectively\"></a></h3><p>The  slash command provides guidance on how to interact with GitHub Copilot effectively, offering tips on structuring prompts, using slash commands, and maximizing GitHub Copilot’s capabilities.</p><ul><li>: Type  in Copilot Chat to receive suggestions on your current task, whether it’s debugging, explaining code, or generating test cases.  </li><li>: Need a refresher on what GitHub Copilot can do? Use  to access a quick guide to slash commands like  and .</li></ul><h3>2. Use /fix to suggest and apply fixes<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#2-use-fix-to-suggest-and-apply-fixes\" aria-label=\"2. Use /fix to suggest and apply fixes\"></a></h3><p>The  command is a go-to tool for resolving code issues by allowing you to highlight a block of problematic code or describe an error.</p><ul><li> Select the code causing issues, type , and let Copilot Chat generate suggestions.  </li><li> If you have a broken API call, use  to get a corrected version with appropriate headers or parameters.</li></ul><h3>3. Use /explain to understand code and errors<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#3-use-explain-to-understand-code-and-errors\" aria-label=\"3. Use /explain to understand code and errors\"></a></h3><p>The  command breaks down complex code or cryptic error messages into simpler, more digestible terms.</p><ul><li> Highlight the code or error message you want clarified, type , and Copilot Chat will provide an explanation. It will explain the function’s purpose, how it processes the data, potential edge cases, and any possible bugs or issues.   </li><li> Encounter a “NullPointerException”? Use  to understand why it occurred and how to prevent it.</li></ul><h3>4. Use /tests to generate tests<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#4-use-tests-to-generate-tests\" aria-label=\"4. Use /tests to generate tests\"></a></h3><p>Testing is key to identifying bugs, and the  command helps by generating test cases based on your code.</p><ul><li> Use  on a function or snippet, and Copilot Chat will generate relevant test cases.  </li><li> Apply  to a sorting function, and Copilot Chat might generate unit tests for edge cases like empty arrays or null inputs.</li></ul><h3>5. Use /doc to generate or improve documentation<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#5-use-doc-to-generate-or-improve-documentation\" aria-label=\"5. Use /doc to generate or improve documentation\"></a></h3><p>There are long-term benefits to having good text documentation—for developers and GitHub Copilot, which can draw context from it—because it makes your codebase that much more searchable. By using the  command with Copilot Free, you can even ask GitHub Copilot to write a summary of specific code blocks within your IDE.</p><p>The  command helps you create or refine documentation for your code, which is critical when debugging or collaborating with others. Clear documentation provides context for troubleshooting, speeds up issue resolution, and helps fellow developers understand your code faster.</p><ul><li> Highlight a function, class, or file, type  and right-click to see the context menu, and Copilot Chat will generate comprehensive comments or documentation.  </li><li> Apply  to a function, and Copilot Chat will generate inline comments detailing its purpose, parameters, and expected output.</li></ul><p>By mastering these commands, you can streamline your debugging workflow and resolve issues faster without switching between tools or wasting time on manual tasks.</p><h2>Best practices for debugging code with GitHub Copilot<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#best-practices-for-debugging-code-with-github-copilot\" aria-label=\"Best practices for debugging code with GitHub Copilot\"></a></h2><h3>Provide clear context for better results<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#provide-clear-context-for-better-results\" aria-label=\"Provide clear context for better results\"></a></h3><p>Providing the right context helps GitHub Copilot generate even more relevant debugging suggestions. As Christopher explains, “The better that Copilot is able to understand what you’re trying to do and how you’re trying to do it, the better the responses are that it’s able to give to you.”</p><p>Since GitHub Copilot analyzes your code within the surrounding scope, ensure your files are well structured and that relevant dependencies are included. If you’re using Copilot Chat, reference specific functions, error messages, or logs to get precise answers instead of generic suggestions.</p><p> Working across multiple files? Use the  command to point GitHub Copilot in the right direction and give it more context for your prompt and intended goal.</p><h3>Ask, refine, and optimize in real time<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#ask-refine-and-optimize-in-real-time\" aria-label=\"Ask, refine, and optimize in real time\"></a></h3><p>Instead of treating GitHub Copilot as a one-and-done solution, refine its suggestions by engaging in a back-and-forth process. Greg says, “I find it useful to ask GitHub Copilot for three or four different options on how to fix a problem or to analyze for performance. The more detail you provide about what you’re after—whether it’s speed, memory efficiency, or another constraint—the better the result.”</p><p>This iterative approach can help you explore alternative solutions you might not have considered, leading to more robust and efficient code.</p><h3>Master the art of specific prompts<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#master-the-art-of-specific-prompts\" aria-label=\"Master the art of specific prompts\"></a></h3><p>The more specific your prompt, the better GitHub Copilot’s response. Instead of asking <em>“What’s wrong with this function?”</em> try <em>“Why is this function returning undefined when the input is valid?”</em> GitHub Copilot performs best when given clear, detailed queries—this applies whether you’re requesting a fix, asking for an explanation, or looking for test cases to verify your changes.</p><p>By crafting precise prompts and testing edge cases, you can use GitHub Copilot to surface potential issues before they become production problems.</p><h3>Try a structured approach with progressive debugging<a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-debug-code-with-github-copilot/#try-a-structured-approach-with-progressive-debugging\" aria-label=\"Try a structured approach with progressive debugging\"></a></h3><p>Next, try a step-by-step approach to your debugging process! Instead of immediately applying fixes, use GitHub Copilot’s commands to first understand the issue, analyze potential causes, and then implement a solution. This structured workflow—known as —helps you gain deeper insights into your code while ensuring that fixes align with the root cause of the problem.</p><ol><li>Start with the slash command  on a problematic function to understand the issue.  </li><li>Use the slash command  to help with configuring interactive debugging.  </li><li>Finally, apply the slash command  to generate possible corrections.</li></ol><p>📌  If a function in your React app isn’t rendering as expected, start by running  on the relevant JSX or state logic, then use  to identify mismanaged props, and finally, apply  for a corrected implementation.</p><p>Some issues require multiple levels of debugging and refinement. By combining commands, you can move from diagnosis to resolution even faster.</p><ul><li>Use  to understand and resolve issues quickly.  </li><li>Apply  to find failing tests and generate new ones.</li></ul><ul><li><strong>Fixing a broken function:</strong> Run the slash command  to understand why it fails, then use the slash command  to generate a corrected version.  </li><li> Use the slash command  to identify and fix failing tests, then use the slash command  to generate additional unit tests for the highlighted code. </li></ul><p>Remember, slash commands are most effective when they’re used in the appropriate context, combined with clear descriptions of the problem, are part of a systematic debugging approach, and followed up with verification and testing.</p><p>GitHub Copilot is a powerful tool that enhances your workflow, but it doesn’t replace the need for human insight, critical thinking, and collaboration. As Greg points out, “GitHub Copilot can essentially act as another reviewer, analyzing changes and providing comments. Even so, it doesn’t replace human oversight. Having multiple perspectives on your code is crucial, as different reviewers will spot issues that others might miss.”</p><p>By combining GitHub Copilot’s suggestions with human expertise and rigorous testing, you can debug more efficiently while maintaining high-quality, reliable code.</p>","contentLength":12181,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Engaging with the developer community on our approach to content moderation","url":"https://github.blog/news-insights/policy-news-and-insights/engaging-with-the-developer-community-on-our-approach-to-content-moderation/","date":1740070822,"author":"Margaret Tucker","guid":7279,"unread":true,"content":"<p>At GitHub, we’re committed to keeping our community informed about how we govern our platform. That means being transparent about content moderation and involving users in the development of our <a href=\"https://docs.github.com/en/site-policy\">site policies</a>. Today we’re announcing that our <a href=\"https://transparencycenter.github.com/\">Transparency Center</a> and <a href=\"https://github.com/github/transparency\">repo</a> have been updated with data for all of 2024.</p><p>Our developer-first approach to content moderation is adapted to the unique environment of code collaboration and has evolved to meet specific needs through a suite of content moderation tools. We’ve discussed the <a href=\"https://tsjournal.org/index.php/jots/article/view/213\">nuances and challenges of moderating a code collaboration platform</a> in the <em>Journal of Online Trust and Safety</em> in an effort to be transparent about our own practices and contribute to the research base of platform studies.</p><p>We want to bring this discussion directly to the developers that make GitHub what it is. Recently, we attended <a href=\"https://fosdem.org/2025/\">FOSDEM</a>, Europe’s largest free and open source developer conference. We connected with developers and presented a deep dive into how our approach to platform moderation has been informed by the values of the FOSS community. You can watch the <a href=\"https://fosdem.org/2025/schedule/event/fosdem-2025-6120-code-is-different-how-the-norms-and-nuances-of-the-foss-developer-community-drive-content-moderation-on-code-collaboration-platforms/\">video of the talk here</a>. We’ll also be <a href=\"https://www.socallinuxexpo.org/scale/22x/presentations/nuances-and-challenges-moderating-code-collaboration-platform\">presenting this talk</a> on March 8 at <a href=\"https://www.socallinuxexpo.org/scale/22x\">SCaLE 22x</a>, the 22nd Annual Southern California Linux Expo in Pasadena, CA. We don’t want to just share our own work—we want to hear directly from developers and maintainers about the challenges you’re facing.</p><p>Developers are an important stakeholder in how we moderate our platform, and we want to hear from you. Check out our <a href=\"https://github.com/github/site-policy\">site-policy repo</a> to contribute constructive ideas, questions, and feedback to make our policies better. We also welcome participation in our <a href=\"https://github.com/github/developer-policy\">developer-policy repo</a> where you can share public policy opportunities and challenges to advance developers’ rights to innovation, collaboration, and equal opportunity.</p>","contentLength":1825,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Announcing Rust 1.85.0 and Rust 2024","url":"https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html","date":1740009600,"author":"The Rust Release Team","guid":7312,"unread":true,"content":"<p>The Rust team is happy to announce a new version of Rust, 1.85.0. This stabilizes the 2024 edition as well.\nRust is a programming language empowering everyone to build reliable and efficient software.</p><p>If you have a previous version of Rust installed via , you can get 1.85.0 with:</p><p>If you'd like to help us out by testing future releases, you might consider updating locally to use the beta channel () or the nightly channel (). Please <a href=\"https://github.com/rust-lang/rust/issues/new/choose\">report</a> any bugs you might come across!</p><p>We are excited to announce that the Rust 2024 Edition is now stable!\nEditions are a mechanism for opt-in changes that may otherwise pose a backwards compatibility risk. See <a href=\"https://doc.rust-lang.org/edition-guide/editions/index.html\">the edition guide</a> for details on how this is achieved, and detailed instructions on how to migrate.</p><p>This is the largest edition we have released. The <a href=\"https://doc.rust-lang.org/edition-guide/rust-2024/index.html\">edition guide</a> contains detailed information about each change, but as a summary, here are all the changes:</p><p>The guide includes migration instructions for all new features, and in general\n<a href=\"https://doc.rust-lang.org/edition-guide/editions/transitioning-an-existing-project-to-a-new-edition.html\">transitioning an existing project to a new edition</a>.\nIn many cases  can automate the necessary changes. You may even find that no changes in your code are needed at all for 2024!</p><p>Note that automatic fixes via  are very conservative to avoid ever changing the semantics of your code. In many cases you may wish to keep your code the same and use the new semantics of Rust 2024; for instance, continuing to use the  macro matcher, and ignoring the conversions of conditionals because you want the new 2024 drop order semantics. The result of  should not be considered a recommendation, just a conservative conversion that preserves behavior.</p><p> people came together to create this edition. We'd like to thank them all for their hard work!</p><p>Rust now supports asynchronous closures like  which return futures when called. This works like an  which can also capture values from the local environment, just like the difference between regular closures and functions. This also comes with 3 analogous traits in the standard library prelude: , , and .</p><p>In some cases, you could already approximate this with a regular closure and an asynchronous block, like . However, the future returned by such an inner block is not able to borrow from the closure captures, but this does work with  closures:</p><pre><code>let mut vec: Vec&lt;String&gt; = vec![];\n\nlet closure = async || {\n    vec.push(ready(String::from(\"\")).await);\n};\n</code></pre><p>It also has not been possible to properly express higher-ranked function signatures with the  traits returning a , but you can write this with the  traits:</p><pre><code>use core::future::Future;\nasync fn f&lt;Fut&gt;(_: impl for&lt;'a&gt; Fn(&amp;'a u8) -&gt; Fut)\nwhere\n    Fut: Future&lt;Output = ()&gt;,\n{ todo!() }\n\nasync fn f2(_: impl for&lt;'a&gt; AsyncFn(&amp;'a u8))\n{ todo!() }\n\nasync fn main() {\n    async fn g(_: &amp;u8) { todo!() }\n    f(g).await;\n    //~^ ERROR mismatched types\n    //~| ERROR one type is more general than the other\n\n    f2(g).await; // ok!\n}\n</code></pre><h3><a href=\"https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html#hiding-trait-implementations-from-diagnostics\" aria-hidden=\"true\"></a>Hiding trait implementations from diagnostics</h3><p>The new <code>#[diagnostic::do_not_recommend]</code> attribute is a hint to the compiler to not show the annotated trait implementation as part of a diagnostic message. For library authors, this is a way to keep the compiler from making suggestions that may be unhelpful or misleading. For example:</p><pre><code>pub trait Foo {}\npub trait Bar {}\n\nimpl&lt;T: Foo&gt; Bar for T {}\n\nstruct MyType;\n\nfn main() {\n    let _object: &amp;dyn Bar = &amp;MyType;\n}\n</code></pre><pre><code>error[E0277]: the trait bound `MyType: Bar` is not satisfied\n --&gt; src/main.rs:9:29\n  |\n9 |     let _object: &amp;dyn Bar = &amp;MyType;\n  |                             ^^^^ the trait `Foo` is not implemented for `MyType`\n  |\nnote: required for `MyType` to implement `Bar`\n --&gt; src/main.rs:4:14\n  |\n4 | impl&lt;T: Foo&gt; Bar for T {}\n  |         ---  ^^^     ^\n  |         |\n  |         unsatisfied trait bound introduced here\n  = note: required for the cast from `&amp;MyType` to `&amp;dyn Bar`\n</code></pre><p>For some APIs, it might make good sense for you to implement , and get  indirectly by that blanket implementation. For others, it might be expected that most users should implement  directly, so that  suggestion is a red herring. In that case, adding the diagnostic hint will change the error message like so:</p><pre><code>#[diagnostic::do_not_recommend]\nimpl&lt;T: Foo&gt; Bar for T {}\n</code></pre><pre><code>error[E0277]: the trait bound `MyType: Bar` is not satisfied\n  --&gt; src/main.rs:10:29\n   |\n10 |     let _object: &amp;dyn Bar = &amp;MyType;\n   |                             ^^^^ the trait `Bar` is not implemented for `MyType`\n   |\n   = note: required for the cast from `&amp;MyType` to `&amp;dyn Bar`\n</code></pre><h3><a href=\"https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html#fromiterator-and-extend-for-tuples\" aria-hidden=\"true\"></a> and  for tuples</h3><p>Earlier versions of Rust implemented convenience traits for iterators of  tuple pairs to behave like , with  in 1.56 and  in 1.79. These have now been  to more tuple lengths, from singleton  through to 12 items long, . For example, you can now use  to fanout into multiple collections at once:</p><pre><code>use std::collections::{LinkedList, VecDeque};\nfn main() {\n    let (squares, cubes, tesseracts): (Vec&lt;_&gt;, VecDeque&lt;_&gt;, LinkedList&lt;_&gt;) =\n        (0i32..10).map(|i| (i * i, i.pow(3), i.pow(4))).collect();\n    println!(\"{squares:?}\");\n    println!(\"{cubes:?}\");\n    println!(\"{tesseracts:?}\");\n}\n</code></pre><pre><code>[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]\n[0, 1, 16, 81, 256, 625, 1296, 2401, 4096, 6561]\n</code></pre><h3><a href=\"https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html#updates-to-stdenvhome_dir\" aria-hidden=\"true\"></a>Updates to </h3><p> has been deprecated for years, because it can give surprising results in some Windows configurations if the  environment variable is set (which is not the normal configuration on Windows). We had previously avoided changing its behavior, out of concern for compatibility with code depending on this non-standard configuration. Given how long this function has been deprecated, we're now updating its behavior as a bug fix, and a subsequent release will remove the deprecation for this function.</p><p>These APIs are now stable in const contexts</p><p>Many people came together to create Rust 1.85.0. We couldn't have done it without all of you. <a href=\"https://thanks.rust-lang.org/rust/1.85.0/\">Thanks!</a></p>","contentLength":5852,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Testing concurrent code with testing/synctest","url":"https://go.dev/blog/synctest","date":1739923200,"author":"Damien Neil","guid":5901,"unread":true,"content":"<p>\n      Damien Neil\n      19 February 2025\n      </p><p>One of Go’s signature features is built-in support for concurrency.\nGoroutines and channels are simple and effective primitives for\nwriting concurrent programs.</p><p>However, testing concurrent programs can be difficult and error prone.</p><p>In Go 1.24, we are introducing a new, experimental\n<a href=\"https://go.dev/pkg/testing/synctest\"></a> package\nto support testing concurrent code. This post will explain the motivation behind\nthis experiment, demonstrate how to use the synctest package, and discuss its potential future.</p><p>In Go 1.24, the  package is experimental and\nnot subject to the Go compatibility promise.\nIt is not visible by default.\nTo use it, compile your code with  set in your environment.</p><h2>Testing concurrent programs is difficult</h2><p>To begin with, let us consider a simple example.</p><p>The <a href=\"https://go.dev/pkg/context#AfterFunc\"></a> function\narranges for a function to be called in its own goroutine after a context is canceled.\nHere is a possible test for :</p><pre><code>func TestAfterFunc(t *testing.T) {\n    ctx, cancel := context.WithCancel(context.Background())\n\n    calledCh := make(chan struct{}) // closed when AfterFunc is called\n    context.AfterFunc(ctx, func() {\n        close(calledCh)\n    })\n\n    // TODO: Assert that the AfterFunc has not been called.\n\n    cancel()\n\n    // TODO: Assert that the AfterFunc has been called.\n}\n</code></pre><p>We want to check two conditions in this test:\nThe function is not called before the context is canceled,\nand the function  called after the context is canceled.</p><p>Checking a negative in a concurrent system is difficult.\nWe can easily test that the function has not been called ,\nbut how do we check that it  be called?</p><p>A common approach is to wait for some amount of time before\nconcluding that an event will not happen.\nLet’s try introducing a helper function to our test which does this.</p><pre><code>// funcCalled reports whether the function was called.\nfuncCalled := func() bool {\n    select {\n    case &lt;-calledCh:\n        return true\n    case &lt;-time.After(10 * time.Millisecond):\n        return false\n    }\n}\n\nif funcCalled() {\n    t.Fatalf(\"AfterFunc function called before context is canceled\")\n}\n\ncancel()\n\nif !funcCalled() {\n    t.Fatalf(\"AfterFunc function not called after context is canceled\")\n}\n</code></pre><p>This test is slow:\n10 milliseconds isn’t a lot of time, but it adds up over many tests.</p><p>This test is also flaky:\n10 milliseconds is a long time on a fast computer,\nbut it isn’t unusual to see pauses lasting several seconds\non shared and overloaded\n<a href=\"https://en.wikipedia.org/wiki/Continuous_integration\" rel=\"noreferrer\" target=\"_blank\">CI</a>\nsystems.</p><p>We can make the test less flaky at the expense of making it slower,\nand we can make it less slow at the expense of making it flakier,\nbut we can’t make it both fast and reliable.</p><h2>Introducing the testing/synctest package</h2><p>The  package solves this problem.\nIt allows us to rewrite this test to be simple, fast, and reliable,\nwithout any changes to the code being tested.</p><p>The package contains only two functions:  and .</p><p> calls a function in a new goroutine.\nThis goroutine and any goroutines started by it\nexist in an isolated environment which we call a .\n waits for every goroutine in the current goroutine’s bubble\nto block on another goroutine in the bubble.</p><p>Let’s rewrite our test above using the  package.</p><pre><code>func TestAfterFunc(t *testing.T) {\n    synctest.Run(func() {\n        ctx, cancel := context.WithCancel(context.Background())\n\n        funcCalled := false\n        context.AfterFunc(ctx, func() {\n            funcCalled = true\n        })\n\n        synctest.Wait()\n        if funcCalled {\n            t.Fatalf(\"AfterFunc function called before context is canceled\")\n        }\n\n        cancel()\n\n        synctest.Wait()\n        if !funcCalled {\n            t.Fatalf(\"AfterFunc function not called after context is canceled\")\n        }\n    })\n}\n</code></pre><p>This is almost identical to our original test,\nbut we have wrapped the test in a  call\nand we call  before asserting that the function has been called or not.</p><p>The  function waits for every goroutine in the caller’s bubble to block.\nWhen it returns, we know that the context package has either called the function,\nor will not call it until we take some further action.</p><p>This test is now both fast and reliable.</p><p>The test is simpler, too:\nwe have replaced the  channel with a boolean.\nPreviously we needed to use a channel to avoid a data race between\nthe test goroutine and the  goroutine,\nbut the  function now provides that synchronization.</p><p>The race detector understands  calls,\nand this test passes when run with .\nIf we remove the second  call,\nthe race detector will correctly report a data race in the test.</p><p>Concurrent code often deals with time.</p><p>Testing code that works with time can be difficult.\nUsing real time in tests causes slow and flaky tests,\nas we have seen above.\nUsing fake time requires avoiding  package functions,\nand designing the code under test to work with\nan optional fake clock.</p><p>The  package makes it simpler to test code that uses time.</p><p>Goroutines in the bubble started by  use a fake clock.\nWithin the bubble, functions in the  package operate on the\nfake clock. Time advances in the bubble when all goroutines are\nblocked.</p><p>To demonstrate, let’s write a test for the\n<a href=\"https://go.dev/pkg/context#WithTimeout\"></a> function.\n creates a child of a context,\nwhich expires after a given timeout.</p><pre><code>func TestWithTimeout(t *testing.T) {\n    synctest.Run(func() {\n        const timeout = 5 * time.Second\n        ctx, cancel := context.WithTimeout(context.Background(), timeout)\n        defer cancel()\n\n        // Wait just less than the timeout.\n        time.Sleep(timeout - time.Nanosecond)\n        synctest.Wait()\n        if err := ctx.Err(); err != nil {\n            t.Fatalf(\"before timeout, ctx.Err() = %v; want nil\", err)\n        }\n\n        // Wait the rest of the way until the timeout.\n        time.Sleep(time.Nanosecond)\n        synctest.Wait()\n        if err := ctx.Err(); err != context.DeadlineExceeded {\n            t.Fatalf(\"after timeout, ctx.Err() = %v; want DeadlineExceeded\", err)\n        }\n    })\n}\n</code></pre><p>We write this test just as if we were working with real time.\nThe only difference is that we wrap the test function in ,\nand call  after each  call to wait for the context\npackage’s timers to finish running.</p><p>A key concept in  is the bubble becoming .\nThis happens when every goroutine in the bubble is blocked,\nand can only be unblocked by another goroutine in the bubble.</p><p>When a bubble is durably blocked:</p><ul><li>If there is an outstanding  call, it returns.</li><li>Otherwise, time advances to the next time that could unblock a goroutine, if any.</li><li>Otherwise, the bubble is deadlocked and  panics.</li></ul><p>A bubble is not durably blocked if any goroutine is blocked\nbut might be woken by some event from outside the bubble.</p><p>The complete list of operations which durably block a goroutine is:</p><ul><li>a send or receive on a nil channel</li><li>a send or receive blocked on a channel created within the same bubble</li><li>a select statement where every case is durably blocking</li></ul><p>Operations on a  are not durably blocking.</p><p>It is common for functions to acquire a global mutex.\nFor example, a number of functions in the reflect package\nuse a global cache guarded by a mutex.\nIf a goroutine in a synctest bubble blocks while acquiring\na mutex held by a goroutine outside the bubble,\nit is not durably blocked—it is blocked, but will be unblocked\nby a goroutine from outside its bubble.</p><p>Since mutexes are usually not held for long periods of time,\nwe simply exclude them from ’s consideration.</p><p>Channels created within a bubble behave differently from ones created outside.</p><p>Channel operations are durably blocking only if the channel is bubbled\n(created in the bubble).\nOperating on a bubbled channel from outside the bubble panics.</p><p>These rules ensure that a goroutine is durably blocked only when\ncommunicating with goroutines within its bubble.</p><p>External I/O operations, such as reading from a network connection,\nare not durably blocking.</p><p>Network reads may be unblocked by writes from outside the bubble,\npossibly even from other processes.\nEven if the only writer to a network connection is also in the same bubble,\nthe runtime cannot distinguish between a connection waiting for more data to arrive\nand one where the kernel has received data and is in the process of delivering it.</p><p>Testing a network server or client with synctest will generally\nrequire supplying a fake network implementation.\nFor example, the <a href=\"https://go.dev/pkg/net#Pipe\"></a> function\ncreates a pair of s that use an in-memory network connection\nand can be used in synctest tests.</p><p>The  function starts a goroutine in a new bubble.\nIt returns when every goroutine in the bubble has exited.\nIt panics if the bubble is durably blocked\nand cannot be unblocked by advancing time.</p><p>The requirement that every goroutine in the bubble exit before Run returns\nmeans that tests must be careful to clean up any background goroutines\nbefore completing.</p><p>Let’s look at another example, this time using the \npackage to test a networked program.\nFor this example, we’ll test the  package’s handling of\nthe 100 Continue response.</p><p>An HTTP client sending a request can include an “Expect: 100-continue”\nheader to tell the server that the client has additional data to send.\nThe server may then respond with a 100 Continue informational response\nto request the rest of the request,\nor with some other status to tell the client that the content is not needed.\nFor example, a client uploading a large file might use this feature to\nconfirm that the server is willing to accept the file before sending it.</p><p>Our test will confirm that when sending an “Expect: 100-continue” header\nthe HTTP client does not send a request’s content before the server\nrequests it, and that it does send the content after receiving a\n100 Continue response.</p><p>Often tests of a communicating client and server can use a\nloopback network connection. When working with ,\nhowever, we will usually want to use a fake network connection\nto allow us to detect when all goroutines are blocked on the network.\nWe’ll start this test by creating an  (an HTTP client) that uses\nan in-memory network connection created by <a href=\"https://go.dev/pkg/net#Pipe\"></a>.</p><pre><code>func Test(t *testing.T) {\n    synctest.Run(func() {\n        srvConn, cliConn := net.Pipe()\n        defer srvConn.Close()\n        defer cliConn.Close()\n        tr := &amp;http.Transport{\n            DialContext: func(ctx context.Context, network, address string) (net.Conn, error) {\n                return cliConn, nil\n            },\n            // Setting a non-zero timeout enables \"Expect: 100-continue\" handling.\n            // Since the following test does not sleep,\n            // we will never encounter this timeout,\n            // even if the test takes a long time to run on a slow machine.\n            ExpectContinueTimeout: 5 * time.Second,\n        }\n</code></pre><p>We send a request on this transport with the “Expect: 100-continue” header set.\nThe request is sent in a new goroutine, since it won’t complete until the end of the test.</p><pre><code>        body := \"request body\"\n        go func() {\n            req, _ := http.NewRequest(\"PUT\", \"http://test.tld/\", strings.NewReader(body))\n            req.Header.Set(\"Expect\", \"100-continue\")\n            resp, err := tr.RoundTrip(req)\n            if err != nil {\n                t.Errorf(\"RoundTrip: unexpected error %v\", err)\n            } else {\n                resp.Body.Close()\n            }\n        }()\n</code></pre><p>We read the request headers sent by the client.</p><pre><code>        req, err := http.ReadRequest(bufio.NewReader(srvConn))\n        if err != nil {\n            t.Fatalf(\"ReadRequest: %v\", err)\n        }\n</code></pre><p>Now we come to the heart of the test.\nWe want to assert that the client will not send the request body yet.</p><p>We start a new goroutine copying the body sent to the server into a ,\nwait for all goroutines in the bubble to block, and verify that we haven’t read anything\nfrom the body yet.</p><p>If we forget the  call, the race detector will correctly complain\nabout a data race, but with the  this is safe.</p><pre><code>        var gotBody strings.Builder\n        go io.Copy(&amp;gotBody, req.Body)\n        synctest.Wait()\n        if got := gotBody.String(); got != \"\" {\n            t.Fatalf(\"before sending 100 Continue, unexpectedly read body: %q\", got)\n        }\n</code></pre><p>We write a “100 Continue” response to the client and verify that it now sends the\nrequest body.</p><pre><code>        srvConn.Write([]byte(\"HTTP/1.1 100 Continue\\r\\n\\r\\n\"))\n        synctest.Wait()\n        if got := gotBody.String(); got != body {\n            t.Fatalf(\"after sending 100 Continue, read body %q, want %q\", got, body)\n        }\n</code></pre><p>And finally, we finish up by sending the “200 OK” response to conclude the request.</p><p>We have started several goroutines during this test.\nThe  call will wait for all of them to exit before returning.</p><pre><code>        srvConn.Write([]byte(\"HTTP/1.1 200 OK\\r\\n\\r\\n\"))\n    })\n}\n</code></pre><p>This test can be easily extended to test other behaviors,\nsuch as verifying that the request body is not sent if the server does not ask for it,\nor that it is sent if the server does not respond within a timeout.</p><p>We are introducing <a href=\"https://go.dev/pkg/testing/synctest\"></a>\nin Go 1.24 as an  package.\nDepending on feedback and experience\nwe may release it with or without amendments,\ncontinue the experiment,\nor remove it in a future version of Go.</p><p>The package is not visible by default.\nTo use it, compile your code with  set in your environment.</p><p>We want to hear your feedback!\nIf you try out ,\nplease report your experiences, positive or negative,\non <a href=\"https://go.dev/issue/67434\">go.dev/issue/67434</a>.</p>","contentLength":13215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Protecting user data through source code analysis at scale","url":"https://engineering.fb.com/2025/02/18/security/protecting-user-data-through-source-code-analysis/","date":1739910649,"author":"","guid":4410,"unread":true,"content":"<p><a href=\"https://about.fb.com/news/2021/04/how-we-combat-scraping/\" target=\"_blank\" rel=\"noopener\"></a><a href=\"https://engineering.fb.com/2022/11/16/culture/meta-code-review-time-improving/\" target=\"_blank\" rel=\"noopener\"></a><b>detect potential scraping vectors</b></p><p><a href=\"https://about.fb.com/news/2021/04/how-we-combat-scraping/\" target=\"_blank\" rel=\"noopener\"></a><a href=\"https://about.fb.com/news/2021/04/how-we-combat-scraping/\" target=\"_blank\" rel=\"noopener\"></a></p><p><a href=\"https://about.fb.com/news/2021/04/how-we-combat-scraping/\" target=\"_blank\" rel=\"noopener\"></a></p><p><b>turning our attack vector criteria into static analysis rules</b><a href=\"https://engineering.fb.com/2019/08/15/security/zoncolan/\" target=\"_blank\" rel=\"noopener\"></a><a href=\"https://engineering.fb.com/2020/08/07/security/pysa/\" target=\"_blank\" rel=\"noopener\"></a></p><h2></h2><p><a href=\"https://engineering.fb.com/2019/08/15/security/zoncolan/\" target=\"_blank\" rel=\"noopener\"></a><a href=\"https://engineering.fb.com/2020/08/07/security/pysa/\" target=\"_blank\" rel=\"noopener\"></a></p><ul></ul><h2></h2><pre><code># views/followers.py\nasync def get_followers(request: HttpRequest) -&gt; HttpResponse:\n\tviewer = request.GET['viewer_id']\ntarget = request.GET['target_id']\n\tcount = request.GET['count']\n\tif(can_see(viewer, target)):\n\t\tfollowers = load_followers(target, count)\n\t\treturn followers\n\n# controller/followers.py\nasync def load_followers(target_id: int, count: int):\n\t...</code></pre><pre><code># views/followers.py\nasync def get_followers(request: HttpRequest) -&gt; HttpResponse:\n\tviewer = request.Get['viewer_id']\n\ttarget = request.GET['target_id']\n\tcount = min(request.GET['count'], MAX_FOLLOWERS_RESULTS)\n\tif(can_see(viewer, target)):\n\t    followers = load_followers(target, count)\n\t\treturn followers\n\n# controller/followers.py\nasync def load_followers(target_id: int, count: int):\n\t...</code></pre><h2></h2><p><a href=\"https://about.fb.com/news/2021/04/how-we-combat-scraping/\" target=\"_blank\" rel=\"noopener\"></a></p>","contentLength":848,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["official"]}