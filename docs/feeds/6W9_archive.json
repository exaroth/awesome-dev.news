{"id":"6W9","title":"HN","displayTitle":"HN","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":76,"items":[{"title":"Ugandan runner Jacob Kiplimo completes first ever sub-57 minute half marathon","url":"https://www.cnn.com/2025/02/16/sport/jacob-kiplimo-smashes-half-marathon-record-spt-intl/index.html","date":1739759391,"author":"mooreds","guid":1655,"unread":true,"content":"<p data-uri=\"cms.cnn.com/_components/paragraph/instances/cm77s57xc00ar2bqhb8xh8fk1@published\" data-editable=\"text\" data-component-name=\"paragraph\" data-article-gutter=\"true\">\n            Jacob Kiplimo shattered the half marathon <a href=\"https://www.cnn.com/2025/02/15/sport/grant-fisher-two-indoor-world-records-spt-intl/index.html\">world record</a> with a blistering run on Sunday.\n    </p><p data-uri=\"cms.cnn.com/_components/paragraph/instances/cm77s5ka00002356m2hbzgndc@published\" data-editable=\"text\" data-component-name=\"paragraph\" data-article-gutter=\"true\">\n            The 24-year-old Ugandan was competing in the Barcelona half marathon where he became the first person ever to complete the distance in under 57 minutes, per World Athletics, which added that the record would be subject to its usual ratification procedure.\n    </p><p data-uri=\"cms.cnn.com/_components/paragraph/instances/cm77s5ka10003356mh4e4rcn2@published\" data-editable=\"text\" data-component-name=\"paragraph\" data-article-gutter=\"true\">\n            Kiplimo finished the race with a time of 56:42 and smashed the previous world <a href=\"https://www.cnn.com/2025/02/14/sport/jakob-ingebrigtsen-mile-1500m-records-spt-intl/index.html\">record</a> by 48 seconds, the biggest ever single improvement on the men’s half marathon world record. Prior to Kiplimo’s incredible run, Ethiopian athlete Yomif Kejelcha held the record with a time of 57:30.\n    </p><p data-uri=\"cms.cnn.com/_components/paragraph/instances/cm77s5ka10004356m9d2ckdot@published\" data-editable=\"text\" data-component-name=\"paragraph\" data-article-gutter=\"true\">\n            “It has been the perfect race,” Kiplimo said after his run, per World Athletics. “Ideal temperature, no wind at all, fantastic circuit - everything went better than expected.\n    </p><p data-uri=\"cms.cnn.com/_components/paragraph/instances/cm77s5ka10005356m0j1t2njt@published\" data-editable=\"text\" data-component-name=\"paragraph\" data-article-gutter=\"true\">\n            “The pacemaker set the agreed 2:45 pace but I found myself full of energy and decided to inject a brisker rhythm from the third kilometre, but I never imagined to perform under the 57 minute barrier, that’s astonishing.”\n    </p><p data-uri=\"cms.cnn.com/_components/paragraph/instances/cm77s5ka10006356mde99ya9h@published\" data-editable=\"text\" data-component-name=\"paragraph\" data-article-gutter=\"true\">\n            Kiplimo ran at an average speed of 22.3 kilometers-per-hour on his way to breaking the record and finished more than two minutes ahead of Kenya’s Geoffrey Kamworor in second. Samwel Mailu, also from Kenya, finished another 56 seconds back in third.\n    </p><p data-uri=\"cms.cnn.com/_components/paragraph/instances/cm77s5ka10007356m8hsspl7x@published\" data-editable=\"text\" data-component-name=\"paragraph\" data-article-gutter=\"true\">\n            Kiplomo now has his sights set on the marathon, and said he will be resting until the London Marathon in April where he will be making his debut at the distance.\n    </p><p data-uri=\"cms.cnn.com/_components/paragraph/instances/cm77sk5tv0000356m1sr7dpge@published\" data-editable=\"text\" data-component-name=\"paragraph\" data-article-gutter=\"true\">\n            Meanwhile, Kenya’s Joyciline Jepkosgei set a course record in the women’s race, finishing in 1:04:13 to fend off her compatriot Gladys Chepkurui in second and Ethiopia’s Alemtsehay Zerihun in third.\n    </p>","contentLength":1793,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43074347"},{"title":"Did the Windows 95 setup team forget that MS-DOS can do graphics?","url":"https://devblogs.microsoft.com/oldnewthing/20250211-00/?p=110862","date":1739756728,"author":"zinekeller","guid":1654,"unread":true,"content":"<p>One of the reactions to my discussion of <a title=\"Why did Windows 95 setup use three operating systems?\" href=\"https://devblogs.microsoft.com/oldnewthing/20241112-00/?p=110507\"> why Windows 95 setup used three operating systems</a> (and oh there were many) was my explanation that an MS-DOS based setup program would be text-mode. But c’mon, MS-DOS could do graphics! Are you just a bunch of morons?</p><p>Yes, MS-DOS could do graphics, in the sense that it didn’t actively prevent you from doing graphics. You were still responsible for everything yourself, though. There were no graphics primitives aside from a BIOS call to plot a single pixel. Everything else was on you, and you didn’t want to use the BIOS call to plot pixels anyway because it was slow. If you wanted any modicum of performance, you had to access the frame buffer directly.</p><p>Okay, so now you have to write a graphics library for drawing things fancier than a single pixel. Fortunately, Windows 95 required a VGA video card at a minimum, so didn’t have to worry about CGA or EGA. Mind you, the VGA adapter required you to deal with planar modes, so that was annoying. Fortunately, you have a team of folks expert in VGA planar modes sitting down the hall working on Windows video drivers who can help you out.</p><p>But the setup program needs more than just pixels. It also wants dialog boxes, so you’ll have to write a window manager to sit on top of your graphics library so you can show dialog boxes with a standard GUI dialog interface, which includes keyboard support for tabbing between elements and assigning hotkeys to fields.</p><p>You’ll also have to add support for typing characters in non-alphabetic languages like Japanese. Fortunately, you have a team of folks expert in Japanese input sitting in the Tokyo office working on Windows input methods who can help you out, though the time zone difference between Tokyo and Redmond is going to slow you down.</p><p>You also want to <a title=\"A wrinkle in how Windows 95 setup bootstrapped its initial GUI step\" href=\"https://devblogs.microsoft.com/oldnewthing/20241119-00/?p=110543\"> take advantage of those fancy new controls</a> that the UI team has been making, so maybe you can walk down the hall and ask them if they could port their controls library to your custom UI framework.</p><p>The setup program also wants to do simple animations, so you’ll need a scheduler that can trigger events based on the system hardware timer.</p><p>So now you’re going to write all this code for your setup program, none of which is actually involved in setting up Windows 95, but is just the infrastructure needed to run the setup program at all! There’s a lot of stuff here, and you probably won’t be able to cram all of it into 640KB of memory. So now you need to write a protected mode manager (also known as an MS-DOS extender) so you can take advantage of the larger address space afforded by protected mode.</p><p>An operating system with exactly one application: Windows 95 Setup.</p><p>What if I told you that Microsoft already had an operating system that did all the things you are trying to do, and it’s fully debugged, with video drivers, a graphics library, a dialog manager, a scheduler, a protected mode manager, and input methods. And it has a fully staffed support team. And that operating system has withstood years of real-world usage? And Microsoft fully owns the rights to it, so you don’t have to worry about royalties or licensing fees? And it’s a well-known system that even has books written about how to program it, so it’ll be easier to hire new people to join your team, since you don’t have to spend a month teaching them how to code for your new custom Setup UI miniature operating system.</p><p>Go and grab a copy of the Windows 3.1 runtime.</p><p>: If you committed to the custom operating system route, you’d have to make sure your miniature operating system could run in a Windows 3.1 MS-DOS session in case somebody wanted to install Windows 95 as an upgrade from Windows 3.1, and in a Windows 95 MS-DOS session in case somebody wants to do a repair install of Windows 95. And then you’d have this weird setup experience where Windows 95 setup is running inside an MS-DOS session.</p><p>: Windows setup still follows this pattern of installing a miniature operating system to bootstrap the setup program. But today, the miniature operating system is Windows PE, the Windows Preinstallation Environment.</p>","contentLength":4120,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43073992"},{"title":"All Kindles can now be jailbroken","url":"https://kindlemodding.org/jailbreaking/WinterBreak/","date":1739756532,"author":"lumerina","guid":890,"unread":true,"content":"<main><blockquote><p>After all, all devices have their dangers. The discovery of speech introduced communication – and lies.  - Isaac Asimov</p></blockquote><p>WinterBreak is a jailbreak which was released on New Year’s Day 2025 by <a href=\"https://www.mobileread.com/forums/member.php?u=330416\">HackerDude</a></p><blockquote><p>Special thanks to Marek, NiLuJe, Katadelos and all the beta-testers during the development of this jailbreak.</p><p>RIP bricked Kindles during beta-testing  RIP the original deadlines</p></blockquote><ul><li>Your Kindle must be registered</li><li>Your Kindle must have a valid, internet-connected WiFi network saved to it that it can connect to during steps 8 to 10 (inclusive)</li></ul><div><div><div><h2><a href=\"https://kindlemodding.org/jailbreaking/WinterBreak/#installation-guide\" aria-labelledby=\"installation-guide\"></a> Download the latest WinterBreak release: </h2></div><div><div><p>Turn on airplane mode on your Kindle</p><img src=\"https://kindlemodding.org/jailbreaking/WinterBreak/airplane_mode.png\"></div></div><div><div><p>Plug the Kindle into your computer and extract the contents of the `WinterBreak.tar.gz` file to your Kindle</p><p> For Linux/MacOS users, ENSURE the hidden folder `.active_content_sandbox` has been copied to your Kindle </p><img src=\"https://kindlemodding.org/jailbreaking/WinterBreak/file_list.png\"></div></div><div><div><p>Eject your Kindle from your computer and reboot it</p><img src=\"https://kindlemodding.org/jailbreaking/WinterBreak/reboot.png\"></div></div><div><div><p>Open the Kindle Store on your Kindle</p><p>When prompted, click `yes` to turn off airplane mode</p><img src=\"https://kindlemodding.org/jailbreaking/WinterBreak/store_aeroplane.png\"></div></div><div><div><p>Click on the WinterBreak icon when it loads:</p><img src=\"https://kindlemodding.org/jailbreaking/WinterBreak/winterbreak_launcher.png\"></div></div><div><div><p>Wait around 30 seconds, and your Kindle will say something along the lines of \"Now you are ready to install the hotfix\"</p><p>Once it does, you can move onto the post-jailbreak stage!</p><img src=\"https://kindlemodding.org/jailbreaking/WinterBreak/winterbreak_run.png\"></div></div></div></div><h2><a href=\"https://kindlemodding.org/jailbreaking/WinterBreak/#kindle-store-encountered-an-unexpected-error\" aria-labelledby=\"kindle-store-encountered-an-unexpected-error\"></a> Kindle store encountered an unexpected error </h2><p>If an  occurs when you try to log in to the Kindle Store or <strong>only the Kindle Store home page</strong> is displayed, try the following solution:</p><ol><li>Before registering your Kindle/logging into your account - plug your Kindle into your PC, move the WinterBreak files to the root of your storage space</li><li>Log in account and enter airplane mode as soon as possible</li><li>Connect Kindle to PC and delete the cache directory at the path .active_content_sandbox/store/resource/LocalStorage (Skip this step if the LocalStorage directory does not exist)</li><li>Open the Kindle Store on your Kindle</li><li>When prompted, click  to turn off airplane mode</li></ol><ul><li>Crystals (Bricked their PW4 testing)</li><li>mergen3107 (Came up with the “WinterBreak” name)</li></ul></main>","contentLength":1925,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43073969"},{"title":"YouTube asks channel owner to verify phone, permanently overwrites personal info","url":"https://old.reddit.com/r/VirtualYoutubers/comments/1iqmul1/if_you_have_a_moment_i_need_your_help/","date":1739755546,"author":"Tijdreiziger","guid":889,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43073836"},{"title":"Homemade polarimetric synthetic aperture radar drone","url":"https://hforsten.com/homemade-polarimetric-synthetic-aperture-radar-drone.html","date":1739755369,"author":"picture","guid":1653,"unread":true,"content":"<div><img src=\"https://hforsten.com/img/sar_fmcw/xdrone_snow.jpg.pagespeed.ic.bjRrZXGlcV.jpg\" width=\"1494\" height=\"883\"><p>Radar drone ready to take off from snow.</p></div><p>I have made several homebuilt radars and done some <a href=\"https://hforsten.com/backprojection-backpropagation.html\">synthetic aperture imaging\ntesting</a> with them on the ground. I have wanted for a long time to put a radar on\na drone and capture synthetic aperture images from air. When I last looked at\nthis few years ago, medium sized drones with payload capability were\naround 1,000 EUR and up. For example in <a href=\"https://pure-oai.bham.ac.uk/ws/portalfiles/portal/136457382/Final_Version_TGRS.pdf\">Low-Cost, High-Resolution, Drone-Borne SAR\nImaging</a>\npaper by A. Bekar, M. Antoniou and C. J. Baker, the imaging results look\nexcellent. They used DJI S900 drone with a list price of about 1,000 EUR. The\nprice for the whole system is quoted to be £15,000, which is a way too\nhigh for my personal budget even just for the price of the drone. Many other\npapers use similar style medium sized drones designed for carrying cameras and\nthey are usually equipped with RTK-GPS for accurate positioning.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xaliexpress.png.pagespeed.ic.AesXyTMvHM.png\" width=\"1031\" height=\"504\"><p>One of many cheap Chinese FPV kits.</p></div><p>Recently small FPV drone prices have dropped a lot. Small 5 and 7 inch propeller\nquadcopters can be bought for about 100 EUR from China (not including battery\nand RC controller). Despite their small size they are able to lift about 1 kg or\neven heavier payload which is plenty for a small radar.</p><p>I bought the cheapest Chinese no-name 7-inch FPV kit and a small GPS+compass\nmodule to support autonomous flying with the goal of making a light weight\nsynthetic aperture radar system that it can carry.</p><p>A single-channel radar can only measure the distance to a target and is unable\nto detect the angle of the target. When multiple receiver channels are arranged\nin a line, the signal travels slightly different distances to each receiver\nbased on the target's angle, causing phase shifts in the received signals. These\nphase shifts allows calculating the angle of the target.</p><p>Angular resolution () of antenna depends on its size\napproximately as: , where  is the\nwavelength, and  is the diameter of the antenna. For example to have\n1 m resolution at 1 km distance requires 0.03° angular resolution with 6 GHz RF\nfrequency. This would require antenna size to be about 100 meters.</p><p>Instead of making a single large antenna, it's possible to move a single radar\nand take multiple measurements at different positions. If the scene remains\nstatic, this approach yields the same results as having one many channel radar\nsystem with big antenna. With synthetic aperture radar it's possible to attach\na single-channel radar to a drone, fly it while making measurements, creating\na large synthetic aperture that provides exceptional angular resolution.</p><p>The design goal for the radar is to get the best imaging performance while being\nable to fit into the FPV drone and achieving it with minimal budget (&lt;500 EUR).\nThe budget limitation rules out using any low-loss RF materials and both\nelectronics and antennas should be implemented with lossy FR4 PCB material.</p><p>The drone is quite small and this limits the maximum size of the radar. The\nwidth of the frame is about 40 mm and propeller tip-to-tip distance is 50 mm\nacross the frame. Length is about 170 mm, which is much more than width and\nmeans that ideally the radar is skinny. For example Raspberry Pi is 56 x 85 mm\nwhich is too wide. The small size severely limits on what the radar can include.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/fmcw_vs_pulse.svg\" width=\"1360\" height=\"450\"><p>Block diagrams of FMCW (left) and pulse radar\n    (right).</p></div><p>There are several possible architectures for the radar. I previously made <a href=\"https://hforsten.com/homemade-6-ghz-pulse-compression-radar.html\">pulse\nradar</a> that is about 64 x 132 mm. That's little too\nwide for the drone, but I believe it would be possible to shrink it a little.\nIssue with that radar is that the maximum bandwidth is about 100 MHz and it's\nlimited by the ADC sampling rate. This corresponds to a range resolution of 1.5\nm, which isn't quite high enough for a detailed image. It's hard to get much\nlarger ADC bandwidth on a reasonable budget and fitting high speed ADCs on the\nlimited space is also an issue. There's also a variation of pulse radar that has\ntwo ramp generators, one for RX and one for TX. This results in low frequency IF\nsignal like with FMCW radar. This is an architecture that is often used on SAR\nradars as it allows for high RF bandwidth without requiring high speed ADC.</p><p>Since pulse radar with switched antenna can't transmit and receive at the same\ntime, pulsed radar maximum pulse length is limited by the time it takes for the\npulse to travel to the target and back. With for example 100 m minimum distance,\nthe maximum pulse length to not miss any part of the pulse is only 670 ns.\nBecause pulse radar needs to divide measurement time between transmission and\nreception it reduces the average transmit power and decreases the\nsignal-to-noise ratio. Large number of very short pulses also complicates the\nimage formation. Time taken by the SAR image formation scales with the number of\npulses and very short maximum pulse length requires transmitting very large\nnumber of them for a good SNR image.</p><p>FMCW radar can transmit and receive at the same time and which improves the\nsignal-to-noise ratio. The maximum sweep length is only limited by the synthetic\naperture sampling speed requirements but it can be hundreds of µs. Unlike pulse\nradar, there is also a minimum sweep length requirement, since reflected signal\nis mixed to the transmitted signal it needs to be received while the sweep is\nstill being transmitted. Long sweep length allows collecting much more reflected\npower per one sweep. Pulse radar could also use separate TX and RX antennas so\nthat this wouldn't be an issue, but that removes its advantages compared to\ncheaper to implement FMCW radar. Separate transmit and receive antennas require\nmore space, but due to large maximum length it should be possible to fit two\nsmall antennas side-by-side under the drone.</p><p>In general FMCW radar has advantage for short range and slow moving platform\napplications. Pulse radar is required when long range (more than few km) is needed.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/sar_fmcw_block.svg\" width=\"690\" height=\"339\"></div><p>Above is the block diagram of the RF parts of the FMCW radar with dual-polarized\nantennas. The sweep is generated by PLL, it's passed through a variable\nattenuator and then amplified by the power amplifier. Most of it is passed to\nthe transmit antenna, polarization switch controls whether vertically or\nhorizontally polarized antenna is used. Part of the transmitted signal is\ncoupled to the receiver mixer, where it's mixed together with the received\nreflected signal that has been amplified by the LNA. Receiver also has\na polarization switch, together with the transmit switch it allows the radar to\nreceiver and transmit any of the four combinations of polarizations. The mixer\noutputs a low frequency signal that is amplified and then digitized by the ADC.\nSome filtering is needed in the receiver to avoid large out of band signals and\nADC aliasing.</p><p>DAC or DDS based sweep generation would likely be better than PLL. DDS phase\nnoise is often better and it can change frequencies essentially instantly\ncompared to PLL, but PLL is chosen because it's cheaper and requires less space. </p><p>RF frequency is going to be around 6 GHz as this is the maximum frequency where\nthere are many cheap RF components for consumer applications. The highest output\npower cheap power amplifiers at this frequency output around 30 dBm. Low noise\namplifiers for the receiver with 1 - 2 dB noise figure can also be obtained\ncheaply.</p><p>Receiver is direct conversion architecture and the mixer does not have any image\nrejection. This causes both frequencies above and below the transmitted signal\nto be converted to the same output frequency. This is not ideal as noise below\nand above the instantaneous sweep frequency is received increasing the noise\nfloor by 3 dB. IQ sampling receiver that could reject the other sideband would\nneed two mixers and ADCs. For only 3 dB increase in the signal to noise\nratio, I didn't think it was worth the cost and PCB space.</p><p>Polarization switches allow choosing which polarization is used to transmit and\nreceive. H is horizontal and V is vertical polarization. This allows measuring\nfour polarizations: HH, HV, VH and VV, where the first letter denotes TX\npolarization and the second RX. Some targets reflect some polarizations more\nthan others and it is used in remote sensing to determine properties of\nreflected targets. For example many smooth targets often reflect the same\npolarization with shape of the target determining if it reflects more HH or VV\ncomponents. Forest and vegetation usually has higher cross-polarized HV and VH\ncomponent reflection compared to roads and bare ground due to multiple\nreflections inside the vegetation.</p><p>Although H and V antennas are drawn separately in the block diagram, this\ndoesn't mean that the system requires four antennas. It's possible to design\nantenna with two ports, one which radiates H and the other V polarization. Dual\npolarized antenna doesn't necessarily need any more space than single polarized\nantenna.</p><p>It would be possible to receive both H and V at the same time if the radar would\nhave two receivers. This would have some advantages, it would allow removing the\nRX polarization switch which would decrease the losses and only the TX should be\nswitched allowing more time for each measurement which would also increase SNR.\nIt would also allow transmitting sweeps faster as there isn't need to multiplex\nthe receiver polarization switch. However, I didn't consider it being worth the\ncost.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/tx_rx_leakage.svg\" width=\"530\" height=\"469\"><p>TX-RX leakage can saturate the receiver on high\n    powered FMCW radar if the leakage is too high.</p></div><p>More RF power generally improves the signal-to-noise ratio, but since FMCW radar\ntransmits and receives at the same time, it's important to consider the TX-RX\nleakage signal. The receiver must be sensitive enough to be able to detect\nthe thermal noise floor at -174 dBm/Hz without saturating due to leaked\nRF power from the transmitter antenna. Typical maximum input power that\nsaturates the LNA is around -20 dBm. With +30 dBm transmitted power more than 50\ndB isolation is needed between transmitter and receiver to prevent the receiver\nsaturation. Even more isolation might be required if some other receiver\ncomponent, such as ADC, saturates first. The variable attenuator before PA can be used to\ndecrease the transmit power in case high enough isolation antennas don't fit in\nthe drone. It also affects the receiver mixer's LO power, but mixers LO input\npower range should be large enough for it to not be an issue.</p><p>The equation for the received power at the receiver input can be written as:</p><div>$$P_r = \\frac{P_t G^2 \\lambda^2 \\sigma}{(4\\pi)^3 r^4}$$</div><p>where  is the transmitter power,  is the antenna gain,  is\nwavelength,  is radar cross section of the target, and  is range to\nthe target. This is the received power from one pulse. Synthetic aperture is\nformed by sending multiple pulses while moving and these can all be coherently\nsummed together to increase the signal to noise ratio. If image is formed from\n pulses, the received power can be multiplied by  to get the received\npower in the whole image.</p><p>Radar cross section  of the target depends on the resolution of the\nradar and radar reflectivity of the ground patch. Target radar cross section\ncan be written as: , where  is\nthe resolution in the range direction,  is resolution in cross-range\ndirection, and  is reflectivity of the ground patch per square meter.\nIn this case , depending on the radar\nparameters, range and imaging geometry. Reflectivity of the ground patch\ndepends on the material of the ground patch and the angle of illumination.\nReflectivity of ground is generally higher when it's illuminated at 90 degree\nangle (in direction of the ground normal vector). This causes the specular\nreflection to reflect back to the radar. At smaller angles there is still some\nreflection back to the radar, but it decreases as the look angle decreases.\nTypical ground reflectivity is around -20 to 0 dBsm (decibels square meter) with\nmoderate look angle.</p><p>The minimum detectable power is limited by thermal noise of the receiver. It\ncan be written as , where  is <a href=\"https://en.wikipedia.org/wiki/Johnson%E2%80%93Nyquist_noise#Derivation\">Boltzmann\nconstant</a>,\n is receiver temperature,  is the noise bandwidth and  is noise figure\nof the receiver. It's a common mistake to confuse the noise bandwidth \nwith RF bandwidth, but they are not related to each other. Noise bandwidth is\nthe minimum bandwidth where receiver can separate noise and signal from each other.\nBy taking Fourier transform of the input signal, we can discard all the\nfrequency bins that are beyond the signal we are currently looking at, and\nnoise at those discarded frequencies won't affect the detection capabilities of\nthe receiver. FFT resolution resolution is equal to , where  is the\nsweep length.</p><p>Setting the received power  equal to noise power and solving for\n we get noise equivalent sigma zero (NESZ) that is value often used\nfor comparing synthetic aperture radars.</p><div>$$\n\\text{NESZ} = \\frac{(4 \\pi)^3 r^4 k F T}{n \\delta x \\delta y G^2 \\lambda^2 P_t t_s}\n$$</div><p>The number of pulses in image  could also be written as ,\nwhere  is the measurement time and  is pulse repetition frequency.\nOr equivalently , where  is the length of the flown\ntrack, and  is the velocity of the drone during measurement. If the antenna\npoints at a constant angle during measurement (stripmap image) the number of\npulses in the image depends on the time that ground patch is illuminated by the\nantenna beam and can be much smaller than the previous number if the antenna beam is\nnarrow. Quadcopter can easily fly pointing in arbitrary angle and it's possible to\nconstantly point the antenna at the target (spotlight imaging) and this\nlimitation doesn't necessarily apply in this case.</p><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr><td>Number of pulses in image</td></tr><tr></tr></tbody></table><div><img src=\"https://hforsten.com/img/sar_fmcw/nesz.svg\" width=\"720\" height=\"450\"><p>Noise equivalent sigma zero vs range with above\n    listed parameters.</p></div><p>Plotting the NESZ as a function of range gives the above plot. There are some\nparameters that can be adjusted, mainly sweep length and the number of sweeps in\nimage to slightly improve this figure. The requires NESZ for good quality image\ndepends on the actual reflectivity of the ground, but typically for satellite\nbased SAR NESZ is around -20 dBsm. With these parameters we should expect to see\nto around 1 - 2 km with ok image quality.</p><h2>Pulse repetition frequency</h2><div><img src=\"https://hforsten.com/img/sar_fmcw/prf.svg\" width=\"720\" height=\"450\"><p>Minimum alias-free pulse repetition frequency with\n    6 GHz RF frequency and with different number of time-multiplexed channels.</p></div><p>Radar image formation relies on the phase information of the received signal.\nIf we consider a target that is 90 degrees from the antenna beam center (in the\ndirection of movement) to avoid phase ambiguity, the maximum phase difference\nbetween two adjacent measurements needs to be less than 180 degrees. If the\nmovement is larger than this, there can be multiple targets at different azimuth\nangles that have the same phase difference between measurements causing them to\noverlap in the image. Since both transmitter and receiver antennas move,\na distance of a quarter wavelength between two measurements of the same target\nresults in a half-wavelength difference in the distance traveled by the signal\nand a half-wavelength distance difference corresponds to 180-degree phase\ndifference. At this spacing, targets at ±90 degrees will have the same 180-degree\nphase difference between measurements. If the measurement spacing is increased\nfurther more of the image starts to alias.</p><p>If the antenna is very directive then it's possible to use larger measurement\nspacing. Directive antenna won't radiate to large angles that would alias, and\nthe more directive the antenna is, the larger the measurement spacing can be.\nHowever, since the drone is space-limited and antenna directivity is related to\nits size, it might not be possible to design a very directive antenna causing the\nmaximum measurement spacing to be around quarter wavelength.</p><p>The common flying speed for a quadcopter is around 10 m/s, but flying speed can easily\nbe decreased if needed. With 6 GHz RF frequency, the quarter wavelength is 12.5\nmm (0.5 inches) and 10 m/s flying speed means that pulse repetition frequency\nneeds to be at least 800 Hz. Since we have time multiplexed four different\npolarizations, we need to be able to measure all of them in this time.</p><p>PRF sets the requirement for maximum sweep length. With 4 * 800 Hz = 3.2 kHz\nPRF requirement this leaves maximum of 312.5 µs per sweep. However, some time\nneeds to be reserved for time between sweeps due to limited locking time of the\nPLL. The locking time of the PLL is around 20 - 30 µs, leaving 280 µs for the\nmaximum sweep length.</p><h2>Required ADC sampling frequency</h2><div><img src=\"https://hforsten.com/img/sar_fmcw/xadc_fs.png.pagespeed.ic.v9nfqHZoTN.png\" width=\"826\" height=\"470\"><p>Required ADC sampling rate vs maximum range and RF\n    bandwidth for FMCW radar with 250 µs sweep length.</p></div><p>FMCW radar mixes the received signal with a copy of the transmitted sweep,\nresulting in a sine wave signal at the mixer output with frequency depending on\nthe range to the target. If the target is at distance , the IF frequency \ncan be calculated as: , where  is the bandwidth of\nthe RF sweep,  is the speed of light, and  is the sweep length. The\nrange resolution depends on the RF bandwidth  as .\nFor example, 150 MHz bandwidth is required for 1 m resolution, and 300 MHz\nbandwidth results in 0.5 m resolution.</p><p>If we have 300 MHz of RF bandwidth (0.5 m range resolution) and  is 280 µs\nas calculated earlier, then we can calculate the required ADC sampling speed\ngiven the maximum target range we want to detect. For example, with 2 km\nmaximum range, the IF signal frequency is 14 MHz. The ADC sampling frequency\nneeds to be at least double this due to Nyquist sampling requirement, and some\nadditional margin is needed for the anti-alias filter roll-off. This results in\na minimum ADC sampling frequency of about 35 MHz. I chose to use 50 MHz\nsampling frequency.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/sar_fmcw_digital.svg\" width=\"920\" height=\"739\"><p>Block diagram of digital parts.</p></div><p>The amount of data and strict timing requirements of the sweep generation make\nit difficult to handle with microcontroller and FPGA is necessary.\nMicrocontroller is useful for more complicated tasks such as communication with the\ndrone flight controller and ground station, configuring the radar, and writing\nthe data to a filesystem. I decided to use Zynq 7020 FPGA, the same one\nI used in my <a href=\"https://hforsten.com/homemade-6-ghz-pulse-compression-radar.html\">previous pulse radar</a>. It has FPGA fabric \nand a dual-core ARM processor in the same package. This FPGA is nominally 150 EUR\nfrom ordinary distributors, but is available for fraction of that from Chinese\ndistributors.</p><p>The drawback of this FPGA is that the microcontroller doesn't have many high\nspeed connections. For example SD-card and EMMC interfaces are limited to 25\nMB/s, which is below the data rate of the ADC. It does have 1 Gbps Ethernet, but\nusing that would require adding a Raspberry Pi or similar computer, which\nisn't possible due to size constraints. For instance, newer Ultrascale+ FPGAs\nsupport SD-cards with 52 MB/s and EMMC at 200 MB/s speeds, but they cost around\n500 EUR and are not available from Chinese low cost distributors.</p><p>Zynq can have external DDR3 DRAM, but due to space limitations, it's not\npossible to fit enough DRAM to store the whole measurement in memory. With\nlimitation of only one DDR3 module, the memory is limited to 1 GB, while size of\nthe measurement can be several gigabytes.</p><p>This leaves only the option of implementing fast enough external communication\ninterface in the programmable logic side of the FPGA. Luckily <a href=\"https://zipcpu.com/\">Dan Gisselquist\n(ZipCPU)</a> has made GPL3-licensed <a href=\"https://github.com/ZipCPU/sdspi\">SD-card and EMMC\ncontroller</a> that supports faster high-speed\ncommunication modes than the hard IP included with the ARM processor.</p><p>At the time, sdspi controller hadn't been tested with real hardware at the\nspeeds I required. To make sure I have something working if I'm unable to get\nthe sdspi core working I connected the SD-card to the ARM processor's\nintegrated controller, which is limited to 25 MB/s, and EMMC memory to the\nprogrammable logic side that is used with the sdspi controller. This way I'm\nable to at least use the SD-card with the integrated controller if the sdspi\ncore isn't suitable, but this turned out to be unnecessary and the sdspi\ncontroller worked fine. In future versions, it would be better to also connect\nthe SD-card to PL side using sdspi core for faster SD-card speeds.</p><p>I also added FT600 USB3 bridge IC that can be used to connect FPGA to PC. This\nis not needed for drone usage, but allows real-time connection to PC for other\napplications.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/sar_fmcw_fpga.svg\" width=\"939\" height=\"699\"><p>FPGA program block diagram.</p></div><p>FPGA functionality is quite simple at the block diagram level. The design\nprimarily consists of a few independent blocks wired with either DMA or AXI bus\nto the processor. For radar operation, the radar timer block is important as it\nswitches internal and external signals during the measurement. It needs to be\nimplemented in the FPGA fabric to ensure that the timing is clock cycle accurate\nto achieve phase-stable radar measurements. AXI bus is memory-mapped on the\nprocessor side, allowing the radar to be controlled by writing values to fixed\nmemory addresses.</p><p>A decimating FIR filter after ADC data input can be used to change the sample\nrate of the ADC data. It can decimate by 1, 2, or 4. For long-range\nmeasurements, the decimation should be disabled for the maximum IF\nbandwidth. But for shorter-range measurements it makes sense to use higher\ndecimation value to decrease the amount of data that needs to be stored.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xpcb_blocks.png.pagespeed.ic.BoVtjckcn0.jpg\" width=\"1605\" height=\"747\"><p>Labeled PCB 3D model in KiCad. Some 3D models are missing.</p></div><p>The PCB has six layers and is designed to be as compact as possible, with\ncomponents placed closely together to minimize size. Since one-sided assembly\nis cheaper than assembling both sides, the bottom side is empty except for one\nSD-card connector that I will solder myself.</p><p>As with many of my previous radars, the RF part is a relatively small part of\nthe PCB and the overall design effort. Digital electronics and voltage regulators\ntake up the majority of the PCB space.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xpcb_complete2.jpg.pagespeed.ic.md_AJUvoQK.jpg\" width=\"1600\" height=\"695\"></div><p>The radar is designed to accept input voltage from 12 to 30 V and connect\ndirectly to the drone's battery eliminating the need for an external DC/DC\nregulator.</p><p>Due to space constraints, there wasn't enough space to fit four SMA connectors\nand I didn't want to use any miniature RF connectors. The top two connectors\nare switchable TX outputs for H and V polarization antenna inputs, while the\nbottom third one is RX input. The RX polarization switch is located on an\nexternal PCB and connects to one of the three four-pin JST connectors on the\nbottom right of the PCB. Another JST connectors is for flight controller's\nserial port, and the third connector is currently unused, but it could be used to\nconnect for example GPS.</p><p>There are two USB-C connectors: one for JTAG programming and\ndebugging of the FPGA, and the other connects to USB3 to FIFO bridge chip that enables\nfast data transfer to PC. It isn't needed in drone use, but it's useful for\ntesting and other applications.</p><p>PCB dimensions are 113 x 48 mm. Width is just skinny enough to fit on the drone,\nwhile it could have been slightly longer.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xmouser.png.pagespeed.ic.DpWMzE2OOX.png\" width=\"755\" height=\"467\"><p>This component is not sale for individuals.</p></div><p>After ordering the PCB I made an order for the components from Mouser. The order\nseemed to succeed fine and they accepted my money but I got the above email\nafterwards telling me that they can't sell me one of the components. Reason\nseems to be that the supplier of the component has forbidden them for selling it\nto individuals. This was very frustrating as there was absolutely no warnings on\nthe website and I had already ordered the PCBs. I was unable to order this\ncomponent from anywhere, but I did find older obsolete PE43204 pin compatible IC\nfrom obsolete component reseller. It's specified only for maximum of 4 GHz when\nthe original was up to 6 GHz but it does seems to have low enough loss at 6 GHz\nto not cause too large issues.</p><p>After <a href=\"https://www.reddit.com/r/rfelectronics/comments/1dubvj7/psemi_forbidding_resellers_from_selling_to/\">asking on\nreddit</a>\nthe reason is probably that the manufacturer of the component wants to know who\nthey are selling to, to avoid their components ending up in defense\napplications. That's fine, but it would have been nice to know that in advance.</p><div><img src=\"https://hforsten.com/img/sd_fix/xsoldered.jpg.pagespeed.ic.RUxbq7RJf_.jpg\" width=\"1600\" height=\"1105\"></div><p>I did make one mistake: SD-card pins are connected to 1.8 V I/O pins, while they\nshould be connected to 3.3 V I/O and SD-card didn't work with this lower voltage.\nThe radar could be used without SD-card by storing the data into EMMC instead\nand then reading it through USB, but SD-card would be much easier to use.\nI really didn't want to order another PCB to just fix this one mistake and\nI managed to fix it by designing a small interposer PCB with level shifter that\nI soldered on top of the previous SD-card footprint. I wrote about it in more\ndetail in a <a href=\"https://hforsten.com/fixing-incorrectly-wired-sd-card-connector-with-interposer-pcb.html\">previous post</a>.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xheatsink.jpg.pagespeed.ic.sB05RnfhPq.jpg\" width=\"1500\" height=\"1125\"><p>Aluminium PCB heatsink under the radar PCB.</p></div><p>Power amplifier can get quite hot if the transmit duty cycle is high. To keep it\ncool I ordered custom aluminium substrate PCB that I bolted under the radar PCB.\nSolder mask is removed under the PA and thermal pad is placed between the PCB\nand heatsink. This cost only $4 for 5 pieces and works very well.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xfc.jpg.pagespeed.ic.uKdKPYdZai.jpg\" width=\"1600\" height=\"1200\"><p>Speedybee F405 V3 flight controller.</p></div><p>Flight controller came with the drone kit. The included flight controller is\n<a href=\"https://www.speedybee.com/speedybee-f405-v3-bls-50a-30x30-fc-esc-stack/\">Speedybee F405\nV3</a>.\nThis is a cheap low-end flight controller with 1 MB of flash. It does the job,\nbut I would recommend getting a little bit better flight controller with\n2 MB of flash, the price difference isn't very large.</p><p>There are several possible flight controller softwares. The three most used for\nFPV drones are: <a href=\"https://betaflight.com/\">Betaflight</a>,\n<a href=\"https://github.com/iNavFlight/inav\">Inav</a>, and\n<a href=\"https://ardupilot.org/\">ArduPilot</a>. The main differences of them are:\nBetaflight focuses on fast-response manual flying and doesn't have autonomous\nflight support, Inav shares lot of code with Betaflight and it includes some\nautonomous flight support, and ArduPilot has the most advanced autonomous flight\ncapability with lot of features but it's more challenging to configure.</p><p>I chose to use Ardupilot and found it to be excellent for this purpose. It has\nvery good IMU and GPS sensor fusion algorithm that is very helpful for\nimproving the position accuracy. The flight controller can communicate with the\nradar through a serial port allowing it to enable and disable the radar during\nautonomous mission and provide position information for the radar.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xgps.jpg.pagespeed.ic.-CwnL_WoYm.jpg\" width=\"1600\" height=\"1200\"><p>GPS with integrated compass. It needs to be\n    mounted far away from the battery leads to avoid magnetic fields causing issues\n    with the compass.</p></div><p>SAR imaging needs very accurate position information for proper image focusing.\nPosition information should be accurate within to a fraction of wavelength,\nthis is just few cm (1 - 2 inches) at this frequency. Many commercial SAR\nimaging drones use RTK GPS with a second stationary GPS receiver on the ground\nit's possible to obtain about 1 cm accurate positioning. The drawback\nis that it's much more costly than regular GPS and RTK GPS receivers are\nusually much larger than ordinary GPS receivers which makes it very difficult\nto fit it in this drone.</p><p>Good non-RTK GPS might be accurate to about 1 m accuracy. This large\npositioning errors cause significant errors in the image if not corrected.\nLuckily, it's possible to solve for position error from the radar data which is\ncalled autofocusing. With drawback of needing more processing during the image\nformation for autofocusing, it's possible to use regular GPS. Sensor fusion\nwith inertial measurement unit (IMU) can be used to improve accuracy of the\npositioning and obtain position updates faster than the maximum of about 4 Hz that\nis possible with only GPS.</p><p>For autonomous flying the drone's flight computer also needs GPS, IMU and\ncompass. It would be a waste of space to have a second GPS and IMU for just the\nradar and instead I'm relying on the flight computer to output its position\nestimate to the radar through a serial interface.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/sar_fmcw_drone.svg\" width=\"930\" height=\"360\"></div><p>The drone is controlled with a radio controller. I use\n<a href=\"https://www.expresslrs.org/\">ExpressLRS</a> radio link, which is very common with\nFPV drones. The drone also has a radio link to the ground control software\nrunning on PC. This is needed for programming the autonomous mission parameters,\nchanging drone settings, it can be used to control the drone, and it displays\ntelemetry during the flight. Ground station can also be used to send messages to\nradar through the flight controller and this allows programming the radar\nparameters from the laptop.</p><p>Typically Ardupilot has required using two radios. One for radio controller and\nother for telemetry, but ELRS recently added <a href=\"https://www.expresslrs.org/software/mavlink/\">Mavlink\nsupport</a> that allows using\na single radio for both purposes. This is very convenient in this application.</p><p>In theory, the wider the antenna beam width is, the better the resolution of\nSAR image is. <a href=\"https://topex.ucsd.edu/rs/sar_summary.pdf\">A famous result in SAR imaging</a> is that the best possible\ncross-range resolution in strip mode SAR (fixed antenna angle and straight\nbaseline) is , where  is the length of the antenna. However, in\npractice wider antenna beam isn't often better. Wider antenna beam means lower\ngain which decreases the signal to noise ratio and limits the maximum range.\nAntenna gain is squared in the link budget so halving the antenna gain, means\nthat number of pulses need to be quadrupled to get the same SNR.</p><p>The cross-range resolution depends on the length of the baseline where the\ntarget is visible and the wider the antenna beam is the longer this is. With\nspotlight imaging, where antenna tracks the target, cross-range resolution is\nnot limited by the antenna beam width and spotlight imaging is easy with drone.\nWith drone SAR the maximum possible baseline length is often the limiting\nfactor for resolution as it's hard to fly very long track when limited by\nvisual line of sight.</p><p>The azimuth angle resolution in spotlight imaging mode (or in stripmap mode\nwhere antenna beam always covers the target) can be approximated as: , where  is wavelength and  is the length\nof the track. Cross-range resolution can be obtained with: , where  is distance to the target.</p><p>With drone SAR a big issue is how to fit large enough antennas on the drone.\nSince the radar is FMCW, separate transmitter and receiver antennas are needed\nfurther decreasing the space per antenna and low TX-RX leakage requires having\nsome distance between them.</p><p>I have previously used <a href=\"https://hforsten.com/horn-antenna-for-radar.html\">self-made horn antennas</a>\nwith my radars, but they are too big to fit on drone. The whole length of the\nhorn antenna is 100 mm, and even just the coaxial-to-waveguide transition is 25\nmm long. This size makes it impossible to fit on the drone, which has only 50 mm\nspacing between propeller tips. My previous horn antenna isn't dual-polarized,\nbut horn can be made dual-polarized easily by adding two feeds 90 degree apart.</p><p>Patch antenna can be made much smaller since they are just copper on a PCB. They\ncan also be made dual-polarized with two feeds 90 degree apart. However,\na simple patch on 1.6 mm thick FR4 PCB has poor bandwidth, FR4 dielectric\ninaccuracy can cause frequency shift, and the gain isn't very high. Gain can be\nimproved by making an array of patches, but with FR4 substrate the losses in\nfeeding network increase quickly.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/stacked_patch.svg\" width=\"700\" height=\"220\"><p>Stacked aperture coupled patch antenna. Side (left) and top (right) views.</p></div><p>Neither horn nor patch antenna seemed suitable. After reading some scientific\npapers I found this <a href=\"https://digital-library.theiet.org/doi/10.1049/el%3A20010828\">dual-polarized slot-fed stacked patch\nantenna</a> paper. It\nconsists of patch antenna that is fed by microstrip lines that couple to patch\nthrough H-shaped slots in the ground plane. Two feed lines and slots 90 degree\napart can be used to make it dual-polarized. A second patch is suspended few mm\naway from the first patch with air in between them. This structure can achieve\nmuch wider bandwidth than a single patch making it tolerant to frequency shift\ncaused by inaccuracy of FR4 permittivity. The second patch also slightly\nincreases the gain.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xantenna_front.jpg.pagespeed.ic.rIaN34zEdw.jpg\" width=\"1600\" height=\"1200\"><p>TX and RX patch fed horn antennas.</p></div><p>However, more gain would be good to have for improving the signal-to-noise\nratio. Sidelobes at 90 degree angle should also be lower to decrease TX-RX\nleakage. To solve this I added a sheet metal horn structure around the antenna,\nmaking it a stacked patch fed horn antenna. The horn increases the height by 10\nmm, but even just a sheet metal wrapped around the patch gap increases the gain\nand decreases sidelobes without increasing the height. I haven't found\na similar structure in any publications, but it wouldn't surprise me if some\nexist, as it does seem straightforward.</p><p>A pyramidal horn with filled-in corners would likely offer slightly higher gain\nand be mechanically stiffer than this four-flap design. However, this was\neasier for me to manufacture. I cut the copper sheet by hand with scissors and\nsoldered it to keep it together.</p><p>This antenna has everything I wanted. It's dual-polarized, has very wide\nbandwidth, good gain, isn't as tall as similar gain horn antenna fed with\ncoaxial-to-waveguide transition, and it's cheap to manufacture requiring just\ntwo FR4 PCBs, some copper sheet and few bolts and spacers. FR4 is lossy and gain\nwould likely be around 0.5 - 1.0 dB higher if a proper low loss RF material was\nused, but the cost would be about 100x higher in prototype quantities and it\ndoesn't make sense for me to spend so much more for so little improvement.</p><p>Between the antennas is a small 0.25 x 0.5 wavelength wall that decreases TX-RX\ncoupling. I tested few different size walls and this small wall is more\neffective than no wall and also more effective than taller walls.</p><p>Not counting the SMA connectors, the height of the antenna is 18 mm, of which 10\nmm is the height of the horn above the suspended patch. Total height including\nthe SMA connector is 28 mm. Patch substrate dimension is 45 x 45 mm and the horn\naperture is 65 x 65 mm.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xantenna_back.jpg.pagespeed.ic.lqa6vy_OIa.jpg\" width=\"1600\" height=\"1200\"><p>Backside of the antennas. Each antenna has two SMA\n    connectors, one for H and other for V polarization.</p></div><p>Backside of the antennas is covered by copper sheet to decrease the backwards\nradiation. This is needed because antennas are mounted right on top of the radar\nPCB which doesn't have any shielding. Without shielding TX antenna backwards\nradiation would increase the TX-RX coupling. Copper sheet is also inserted into\nthe wall between antennas and the tape keeps it in place. </p><div><img src=\"https://hforsten.com/img/sar_fmcw/antenna_gain.svg\" width=\"720\" height=\"450\"><p>Simulated radiation pattern of the antenna.</p></div><p>The simulated -3 dB beamwidth is 50/60 degrees in 0/90 degree angles. H and\nV feed slots are rotated 90 degrees and the radiation pattern from the other\nport is similar but rotated 90 degrees. Simulated peak gain is 10.0 dB.</p><p>Sidelobe to 90 degree direction is about -10 dB. It's important for this to be\nlow to minimize TX-RX leakage.</p><p>Since the antenna radiation pattern isn't quite symmetrical, mounting the other\nantenna at a 90-degree rotation compared to the first one ensures good antenna\npattern matching between HH and VV polarizations. If the TX antenna transmits\nH polarization from the first port, RX antenna receives H polarization from the\nother port, and other way around for V, causing the two-way antenna pattern to\nmatch between the both cases. However, HV and VH antenna patterns don't match\nthe HH and VV patterns, since in the cross-polarization case the same port is\nused to transmit and receive on both antennas.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/antenna_sp.svg\" width=\"720\" height=\"450\"><p>Measured S-parameters of the antenna.</p></div><p>There is a slight difference in the H and V port matching due to their slightly\ndifferent coupling slot sizes. Antenna useable bandwidth is from about 4.5 GHz\nto 6.2 GHz which is more than enough for this application.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xblender.png.pagespeed.ic.NqxqsjpHF0.jpg\" width=\"1227\" height=\"703\"><p>Drone mechanical model in Blender.</p></div><p>The drone needs some mechanical parts to hold the radar on the drone frame.  The\nflight controller is mounted inside the frame, but there isn't enough room\ninside it for the radar, so I designed a 3D printed mount that holds the radar\nPCB under the drone frame. This mounting position also requires landing legs so\nthat the drone doesn't land on the radar. I designed it in Blender since I don't\nknow any mechanical CAD programs. It works just fine for these simple parts.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xassembly_radar_attached.jpg.pagespeed.ic.zvjKnRgfp_.jpg\" width=\"1600\" height=\"1151\"><p>Radar attached under the drone.</p></div><p>The radar mount holds the radar PCB on the drone frame. It would be a good idea\nto have some sort of weather proof enclosure for it, but I haven't got around it\nyet. I added some material over the PCB to protect it in case the landing legs\nfail.</p><p>Radar holder attaches with four screws to the drone. Drone radio controller\nantenna is visible at the bottom left. Propellers are collapsible, these make it\nmuch easier to transport the drone as with these it fits in a backpack.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xassembly_switch.jpg.pagespeed.ic.yCmbx9kxzj.jpg\" width=\"1600\" height=\"1173\"><p>Receiver polarization switch PCB.</p></div><p>Antenna board is held with two bolts that allow its angle to be changed. Flight\ncontroller serial port is attached to one of the JST connectors. There also\nother JST connector from flight controller that is currently unused and just\nheld with tape in place.</p><p>Transmitter has polarization switch and two SMA connectors on the PCB, but the\nreceiver polarization switch is on a separate PCB due to lack of space. I had\na mounting holes for it on the radar holder part, but the SMA cables are stiff\nenough that I found it easier to just leave it hanging there. Polarization\nswitch connects to the radar PCB with another JST connector.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xassembly_legs.jpg.pagespeed.ic.jsm1QEk8ZH.jpg\" width=\"1600\" height=\"1200\"></div><p>Landing legs are 10 cm diameter carbon tubes with 3D printed TPU caps. Smaller\ndiameter tube would have likely been fine, these are very stiff and something\nelse would fail before them if they are stressed too much in landing.</p><p>Radar is powered directly from the drone battery. XT60 splitter is used to\nconnect both flight controller and radar to the same battery.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xassembly_weight.jpg.pagespeed.ic.AvMr3hfOmK.jpg\" width=\"1600\" height=\"1353\"><p>Drone balanced on a kitchen scale.</p></div><p>Weight of the drone without battery is just 752 grams (1.66 lbs). I have two six\ncell LiPo batteries, the smaller 1300 mAh capacity battery weights 196 grams and\nthe bigger 2200 mAh battery weights 322 grams. With the smaller battery the total\nweight of the whole system is just 948 grams.</p><p>Radar measures the distance and phase of each target. To convert these\nmeasurements into a radar image, matched filtering can be used. For each pixel\nin the image, generate a reference signal corresponding to what a target at that\nposition would reflect. Multiply the measured signal with the complex conjugate\nof the reference signal for each measurement, then sum these products over\nall measurements. When the measured signal closely matches the reference signal,\ntheir product becomes large because the phases align. If it doesn't match,\nthe result of the multiplication is a complex number with a random phase, and summing\nrandom complex numbers will average out generating a low response.</p><p>The image formation can be written as:</p><div>$$I = \\sum_{p \\in \\mathcal{P}} \\sum_{n=1}^N S_n(d(p,x_n)) \\cdot H(d(p,x_n))^* $$</div><p>, where  is the set of pixels in the image,  is the number of\nradar measurements,  is Fourier transformed measured IF signal ,\n is the distance to location of pixel  from radar position at that\nmeasurement , and  is complex conjugate of the reference function of\nwhat target at that position in the image should look like (Fourier transform of\nthe radar IF signal from target at that position in the image).</p><p>This is called backprojection algorithm. It's simple and doesn't make any\napproximations or assumptions about flight geometry, but it's very demanding to\ncalculate. For example with 1 km x 1 km image with 0.3 m resolution and 10,000\nradar sweeps, calculating the image needs  backprojections. This means over 100 billion complex exponentials and\nsquare root calculations is needed for one image, and image size and number of\nsweeps can be even larger in practice. There are some clever algorithms that can\nbe used to speed this up, but they often have approximations or only work with\nlinear flight tracks. One easy improvement that can be made without many\ndrawbacks, is to use polar coordinates instead of Cartesian coordinates, as that\nrequires less pixels in the image since angular resolution is constant while\ncross-range resolution is better closer to the radar. Polar coordinate image can\nthen be afterwards interpolated to Cartesian grid.</p><div><table><tbody><tr><td><div><pre></pre></div></td><td><div><pre><code></code></pre></div></td></tr></tbody></table></div><p>Some years ago this would have been unbelievable amount of compute, but with\nmodern GPU this can be calculated in under a second. This problem is especially\nwell suited for GPU implementation since every pixel can be calculated\nindependently in parallel. Very straightforward CUDA kernel is able to calculate\n220 Billion backprojections per second on RTX 3090 Ti GPU. This is very\nrespectable speed considering that each backprojection requires square root and\ncomplex exponential (which can be calculated with just sin and cos). I'm sure\nthat someone experienced with CUDA programming could make this even faster as\nthis doesn't have any optimizations or approximations and is just the direct\nalgorithm implementation.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/autofocus.svg\" width=\"639\" height=\"879\"></div><p>Positioning accuracy of the GPS and IMU isn't good enough to form a high-quality\nimage. Ideally, the position should be known to a fraction of the wavelength,\nbut accuracy of the GPS isn't good enough. To achieve good image quality, an\nautofocus algorithm is necessary to focus the radar image using information from\nthe radar data.</p><p>The most commonly used autofocus algorithm is <a href=\"https://ieeexplore.ieee.org/abstract/document/303752\">phase gradient\nautofocus</a>. It's simple\nand fast autofocus algorithm that works by taking an unfocused radar image as an\ninput and solving for a phase vector that when multiplied with the azimuth FFT\nof the image gives a focused image. However, it doesn't work well in this case\nsince the azimuth beam is wide and the radar baseline is long causing the\nfocusing errors to be spatially dependent.</p><p>I updated my <a href=\"https://hforsten.com/backprojection-backpropagation.html\">previous backpropagation autofocus</a> to\nuse PyTorch and made some improvements. This autofocus algorithm works by\nforming the radar image, calculating the gradient of the input velocity, and \nclipping the learning rate to limit the maximum position change to a predefined\nvalue. The input velocity is then updated using a gradient descent optimizer.\nI found that using a 3D position doesn't work well, as it often tends to just nudge\neach position in random directions. Instead, using velocity and integrating it\nto position seems to yield much better results. A small regularization term is\nalso included to minimize the distance between the optimized and original\npositions, favoring smaller updates.</p><p>Adjusting the learning rate based on the maximum position change makes it easier\nto set the optimizer meta parameters. Instead of setting the learning rate\ndirectly, maximum position update is given which is used to set the learning\nrate.</p><p>This is very general autofocus algorithm that makes no assumptions about the\nradar system, scene, or the flight track. The obvious disadvantage is that it\nrequires forming the radar image many times making the already slow image\nformation many times slower. Without the fast GPU image formation this would be\ntoo slow to be useful.</p><p>The autofocus algorithm is available on\n<a href=\"https://github.com/Ttl/torchbp\">Github</a>.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xmission_planner.jpg.pagespeed.ic.dhNylMMORO.jpg\" width=\"1209\" height=\"1040\"><p>Configuring the mission in ArduPilot Mission\n    Planner.</p></div><p>The mission is programmed beforehand with the ArduPilot Mission Planner. The\ndrone will automatically fly the programmed waypoints, there are also commands\nto set the ROI (region of interest) so that antenna always points towards it,\nand the radar measurement is started with digicam configure command in the\nmission. It's originally meant for configuring ordinary camera, but\nI programmed the radar microcontroller to listen to it. Using an existing\ncommand makes it easy to make the radar work with the existing ArduPilot software.</p><p>Setting ROI, which is needed for spotlight imaging, needs a patch to ArduPilot\nfirmware. By default drone's front will always point towards the ROI and there\nisn't a way to configure it to point the antenna towards ROI instead. The patch\nis available on the <a href=\"https://github.com/ArduPilot/ardupilot/pull/28486\">ArduPilot Github as a pull request</a>.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xaction.jpg.pagespeed.ic.W_4RucSliH.jpg\" width=\"1800\" height=\"1910\"></div><p>The scene is a wide open field. There's about 1.5 km distance to the forest at\nthe antenna pointing direction. The drone flies at 110 m altitude in a straight\nline for about 500 m at 5 m/s velocity. The radar was configured to transmit\nonly VV polarization with 400 µs long sweep, 500 MHz bandwidth, and 1 kHz\npulse repetition frequency.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xraw_data.png.pagespeed.ic.3MAaZDezzS.png\" width=\"826\" height=\"470\"><p>Range compressed raw data.</p></div><p>The range compressed (Fourier transformed) captured data doesn't look very\nimpressive. It doesn't look anything like an image since due to the wide\nantenna beam at each sweep many targets at different angles are captured.</p><p>At the zero distance there is a large response from the TX-RX leakage, then the\nnext reflection is at 100 m distance from the ground. Even though the antenna\ngain at directly below is much smaller than at the beam center, due to the angle\nof the reflection and close distance, the reflection from directly below is very\nlarge. At large distances reflections are mostly below the noise floor of\nindividual sweeps, but during image formation many sweeps are integrated\nimproving the signal to noise ratio. Some large individual objects are visible\nand their distance to the radar changes as the drone moves.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar2_scatter.png.pagespeed.ic.VbD8wZkpX6.png\" width=\"826\" height=\"470\"><p>Recorded drone position and antenna pointing\n    vector from GPS and IMU. Note the unequal axes scale.</p></div><p>Ideally the track should have been a straight line but there\nis some disturbances due to for example wind. The drone is very light and even\na slight wind can easily affect it. The ROI was set quite far away there is only\nfew degree of change in the antenna pointing direction during the measurement.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar_img2_polar.jpg.pagespeed.ic.D5PO668zBU.jpg\" width=\"1579\" height=\"848\"><p>SAR image without autofocus.</p></div><p>Above is the processed SAR image without autofocus in pseudo-polar coordinates\nthat the image formation uses internally. It's pseudo-polar because angle axis\nis in sine of radians instead of just radians, this is slightly more efficient\nthan ordinary polar coordinates. Image size is 6k x 20k pixels using 51,200\nsweeps.</p><p>Compared to the raw data it's a night and day. Various geographical features can\nbe now identified, but polar format makes it hard to compare to the map.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar_img2_no_opt.jpg.pagespeed.ic.KS5LQogwyn.jpg\" width=\"962\" height=\"843\"><p>SAR image without autofocus.</p></div><p>Cartesian coordinate image can be obtained by projecting the pseudo-polar image\nto Cartesian grid. This is very fast operation compared forming the image\ndirectly on the Cartesian grid. The image is also aligned so that north points\nup using the drone's electronic compass measurements. Left corner is missing\na small patch of data due to the rotation.</p><p>The resulting image is still quite blurry. Clearly only relying on the GPS and\nIMU positioning isn't good enough and autofocus is needed to get a sharply\nfocused image.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar_img2_opt_cart.jpg.pagespeed.ic.qsHkmEQMW8.jpg\" width=\"962\" height=\"843\"></div><p>After applying 30 iterations of the minimum entropy gradient optimization\nautofocus, the image quality is much better. Five iterations would have been\nprobably enough, but using more iterations does improve the quality slightly.\nThis does take several minutes since each iteration requires calculating forward\nand backwards pass of the backprojection.</p><p>Due to the low look angle, tall structures such as trees cast long shadows. The\nimage amplitude isn't normalized, which is why it's brighter closer to the\norigin.  The antenna radiation pattern can be also visualized in the image. The\nbeam center is tilted slightly to the right, and the antenna gain at the left\nside of the image is much smaller due to it being farther from the beam center,\ncausing it to be dimmer.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar2_img_detail_comparison.jpg.pagespeed.ic.6LSaGzsHo3.jpg\" width=\"1478\" height=\"726\"><p>SAR image detail comparison. Without autofocus\n    (left) and with minimum entropy optimization autofocus (right).</p></div><p>There is quite lot of detail in the resulting radar image when zooming in.\nComparing a 300 x 300 m patch, the autofocused image reveals surface details of\nthe field that was just blur in the image without autofocus.</p><p>I also tried using phase gradient autofocus, but it doesn't work well in this\ncase. <a href=\"https://hforsten.com/img/sar_fmcw/sar2_pga_detail.jpg\">The result</a> is very similar to\nthe image without autofocus.</p><p>The three lines at the bottom left are power lines. They seem to be only visible\nin the image when the radar is looking at them at 90 degree angle, at other angles\nthe reflectivity is so low that they are invisible.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar2_v_opt.png.pagespeed.ic.PlTlyyA2yG.png\" width=\"826\" height=\"470\"><p>Original and optimized velocity.</p></div><p>Comparing the drone velocity before and after optimization the changes aren't\nvery large. Along the track and range direction velocity components are both\nadjusted slightly and height direction velocity component is basically\nunchanged.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar3_map_1100.jpg.pagespeed.ic.N65ySzsgck.jpg\" width=\"693\" height=\"650\"><p>Google maps screenshot of the SAR imaging area.</p></div><p>I also made another measurement at other location using all four polarizations.\nThe radar flies a linear track autonomously as before, but now the radar quickly\nswitches between each of the four polarization switch states. Sweep length was\nreduced to 200 µs, pulse repetition frequency is 715 Hz for each\npolarization, and other parameters are kept the same. Number of sweeps in the\nimage is the same 51,200.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar3_x4.jpg.pagespeed.ic.HQkjidC97p.jpg\" width=\"721\" height=\"705\"><p>Four SAR images with different polarizations.</p></div><p>The four polarizations look very similar. The main differences are that\ncross-polarization images (HV and VH) have weaker amplitude due to\ncross-polarization component in general being smaller than the reflection of the\nsame polarization.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar3_pol_1100.jpg.pagespeed.ic.sZ46cglYon.jpg\" width=\"905\" height=\"854\"><p>Polarized SAR image with autofocus.</p></div><p>Instead of looking at four different images for each polarization, it's common\nto use RGB color channels for different polarizations in the same image. In this\ncolored image it's easier to visualize how each target reflects specific\npolarizations. The ground is tinted purple, indicating that it\nreflects VV and HH polarization better than the cross-polarized components. The same\ncan be seen on the buildings and in the light poles along the road. Forest areas\nare colored white as they reflect all polarizations about equally. However,\nsince the effects of the antenna radiation pattern and possibly slightly\ndifferent losses for different polarization switch states are not calibrated\nsome of the observed differences could be attributed to the hardware. Better\naccuracy measurements would require calibration.</p><p>The area with bunch of points around (200, 500) meters is a some kind of garden\nof small trees each surrounded with a metal wire mesh.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xsar3_scene.jpg.pagespeed.ic.sIO6ntsoPj.jpg\" width=\"1200\" height=\"900\"><p>Picture at the ground at (-50, -80) m coordinates\n    in the SAR image looking towards negative Y-axis.</p></div><p>There was slight amount of snow on the ground during the measurements. The\nvisible picture is from the top of the SAR image looking down. The small forest\non the left is the small patch of trees in the middle of the image.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/xvideosar_mission.jpg.pagespeed.ic.WxdiRT0GqX.jpg\" width=\"824\" height=\"773\"><p>Drone waypoints for the octagonal flight path. Red\n    marker is the region-of-interest where drone points the antenna.</p></div><p>The previous measurements synthesized one high-resolution image from a long\nbaseline. It's also possible to synthesize many images with small baselines from\none long measurement, and these many images can then be turned into a video.</p><p>For the backprojection algorithm, the flight track doesn't need to be linear and for\nthis case I programmed the drone to fly octagonal track while pointing the\nantenna at the octagon's center.</p><p>Each frame has 1024 radar sweeps with 512 of them overlapping with the previous\nframe.  Since each frame has less sweeps than the previous full images, the\nframes are noisier and have worse angular resolution. The video is sped up by\nabout 10x. All four polarizations are used, and the image colorization is the\nsame as in the previous polarized SAR image.</p><p>Frames are autofocused separately and there isn't any alignment of adjacent\nframes, which causes the frames slightly wobble or jump around occasionally. Corners\nof the octagon are especially challenging for the image formation since both\nalong- and cross-range positions need to be solved accurately for a good-quality\nimage. Angular resolution can also vary between frames as the baseline\nlength between the frames can vary, as only the number of sweeps is the same\nbetween the frames.</p><p>Natural targets such as the ground and forest look very similar at different frames,\nbut at several points in the video large reflections can be seen for example at\nbridge and power lines when they are oriented at a 90-degree angle to the radar.\nThe bright spot that looks like it's moving at the bridge is just glint from the\nrailing. The mismatch between antenna patterns of different polarizations is\nalso visible as the same target can have slightly different color at the beam\ncenter or at the edge.</p><div><img src=\"https://hforsten.com/img/sar_fmcw/look_angle.svg\" width=\"720\" height=\"450\"><p>Radar look angle with 120 m flying height.</p></div><p>Without special permits, it's allowed to fly the drone at a maximum altitude of\n120 m. Usually, for SAR imaging, the look angle is around 10 to 50 degrees. If the\nlook angle is close to 90 degrees (i.e., looking straight down at the ground), the\nreflected power is high, but the range resolution is poor as the distance to the\nradar is almost the same for nearby locations. For low look angles the range\nresolution is good, but due to the low grazing angle the reflected power back to\nthe radar is low. With extremely low look angle the reflected power can be about\n10 to 20 dB lower than it would be compared to more usual around 45 degree look\nangle reducing the maximum distance the radar can see.</p><p>Another issue is shadowing caused by tall objects.  For instance, when flying at\n120 m height, the grazing angle at 2 km distance is only 3.4 degrees. A 10\nm tall tree casts 170 m long shadow at this low angle, making it impossible to\nsee any reflections from the ground after the tall object. This is clearly\nvisible in all of the measurements. Especially in the full-polarization\nmeasurement only the tops of the buildings are visible at long distances.</p><div><a href=\"https://hforsten.com/img/sar_fmcw/sar_fmcw.pdf\" target=\"_blank\"><img src=\"https://hforsten.com/img/sar_fmcw/xschematic_top.png.pagespeed.ic.lsgycncoqY.png\" width=\"805\" height=\"565\" border=\"2\"></a><p>Schematic of the radar (click to open).</p></div><p>The synthetic aperture radar drone can image at least up to 1.5 km and likely\neven farther if flown higher. It weighs under 1 kg including the radar, drone,\nand battery. The system can capture HH, HV, VH, and VV polarizations.\nA gradient-based minimum entropy autofocus algorithm is capable of producing\ngood good-quality images with a wide antenna beam using only non-RTK GPS and IMU\nsensor information. The total cost of the drone was about 200 EUR, 600 EUR for\ntwo radar PCBs, and about 10 months of my free-time after work. I'm very happy\nwith the performance of the system considering its low cost.</p>","contentLength":53379,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43073808"},{"title":"San Francisco homelessness: Park ranger helps one person at a time","url":"https://sfstandard.com/2025/02/08/golden-gate-park-ranger-homelessness/","date":1739751350,"author":"NaOH","guid":888,"unread":true,"content":"<div><p>Barrows found him in the park a few days later, with the catheter still in place. He’d been using it to inject crystal meth. He walked away from her, then veered into the street, directly into the path of a truck. It skidded to a stop, missing him by inches.&nbsp;</p></div><div><p>“What are you doing, dude?” Barrows yelled. Morrisette continued across the street. “He flashes,” she says of his now-familiar state of agitation. “It’s almost like he’s just blinded by rage or emotions or upset. And you can’t really do much other than watch, because if you try to forcibly intervene, it escalates.”&nbsp;</p></div><div><p>Two days later, Morrisette suffered an overdose from fentanyl. By then he was living in an encampment of RVs and tents on the Lower Great Highway, next to the park.&nbsp;Barrows and one of the RV residents administered Narcan and CPR until an ambulance arrived. The incident shook her deeply. She feared if Morrisette didn’t change his life soon, he would die, either deliberately or accidentally.&nbsp;</p></div><div><p>In early 2024, after a punishing series of storms, Barrows helped Morrisette and another resident of the encampment secure placement in a double room in transitional housing. To get the slot, they decided to lie and say they were same-sex partners, even though they were barely friends. But the arrangement didn’t last long. The man got sick and was hospitalized, and a stranger was moved into the room. Morrisette got into a fight with the guy and was kicked out of the facility. He returned to the Lower Great Highway.</p></div><div><p>To Barrows, the fault was in the placement, not in Morrisette. “Ronnie was always very clear about his needs. He knows he’s a volatile person. He doesn’t want to be in a shared room, especially with a stranger,” she said.</p></div><div><p>Still, his setbacks, and those of Barrows’ other clients, were taking a toll on her. Some days, she admitted, she felt burned out by all the distress she had to witness. “This can be just so exhausting to try to show up fully for so many people every day. And then be a container for all this brokenness.”</p></div>","contentLength":2057,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43073292"},{"title":"Does or did COBOL default to 1875-05-20 for corrupt or missing dates?","url":"https://retrocomputing.stackexchange.com/questions/31288/does-or-did-cobol-default-to-1875-05-20-for-corrupt-or-missing-dates","date":1739750176,"author":"SeenNotHeard","guid":1652,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43073149"},{"title":"Javier Milei backtracks on $4.4B memecoin after 'insiders' pocket $87M","url":"https://www.coindesk.com/business/2025/02/15/javier-milei-backtracks-on-usd4-4b-memecoin-after-insiders-pocket-usd87m","date":1739747759,"author":"techlover14159","guid":858,"unread":true,"content":"<p>Argentina's president Javier Milei has backtracked on a tweet promoting a memecoin called Libra, which rose to a $4.4 billion market cap before plunging by more than 95%.</p><p>In a now-deleted tweet, Milei initially wrote: \"This is a private project dedicated to encouraging the growth of the Argentine economy,\" along with a Solana contract address linked to the Libra token.</p><p>Libra rose by more than 2,000% in a 40-minute span following the tweet, only to tumble rapidly as a group of early holders began to cash out. </p><p>X account KobeissiLetter shared a series of BubbleMaps screenshots showing that alleged \"insiders\" liquidate tokens by adding one-sided liquidity pools on Metora with only Libra, allowing them to remove SOL and stablecoins.</p><p>Trading volume for Libra hit $1.1 billion after launch, although it appeared that purchases and sales were skewed; there were 74,500 individual buy orders and 28,900 sales - indicating that larger sell orders flattened the flurry of retail activity.</p><p>Milei later addressed the botched memecoin on X, stating that he \"was not aware of the details of the project.\" </p><p>\"A few hours ago I posted a tweet, as I have so many other times, supporting a supposed private enterprise with which I obviously have no connection whatsoever,\" Milei wrote. \"I was not aware of the details of the project and after having become aware of it I decided not to continue spreading the word (that is why I deleted the tweet).\"</p><p>The sell-off in Libra rippled across the wider memecoin market, with TRUMP losing $500 million from its market cap, <a href=\"https://www.coindesk.com/price/trump\">according to market data</a>, in a 30-minute period after Libra began to tumble.</p>","contentLength":1626,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43072790"},{"title":"Uchū – Color palette for internet lovers","url":"https://uchu.style/","date":1739744560,"author":"NetOpWibby","guid":826,"unread":true,"content":"<li><p>oklch(68.5% 0.136 303.78)</p></li><li><p>oklch(58.47% 0.181 302.06)</p></li><li><p>oklch(49.39% 0.215 298.31)</p></li><li><p>oklch(46.11% 0.198 298.4)</p></li><li><p>oklch(42.77% 0.181 298.49)</p></li><li><p>oklch(39.46% 0.164 298.29)</p></li><li><p>oklch(36.01% 0.145 298.35)</p></li>","contentLength":180,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43072338"},{"title":"Show HN: Air traffic control radio and chill music for focus","url":"https://www.chillyatc.com/","date":1739741781,"author":"usernameis42","guid":823,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43071934"},{"title":"Critics say new Google rules put profits over privacy","url":"https://www.bbc.com/news/articles/cm21g0052dno","date":1739738730,"author":"latexr","guid":857,"unread":true,"content":"<div data-component=\"text-block\"><p>Privacy campaigners have called Google's new rules on tracking people online \"a blatant disregard for user privacy.\"</p><p>Changes which come in on Sunday permit so-called \"fingerprinting\", which allows online advertisers to collect more data about users including their IP addresses and information about their devices.</p><p>Google says this data is already widely used by other companies, and it continues to encourage responsible data use.</p><p>However the company had previously come out strongly against this kind of data collection, saying <a target=\"_blank\" href=\"https://blog.google/products/chrome/building-a-more-private-web/\">in a 2019 blog</a> that fingerprinting \"subverts user choice and is wrong.\"</p></div><div data-component=\"text-block\"><p>But in a <a target=\"_blank\" href=\"https://support.google.com/marketingplatform/answer/15732590?hl=en\">post</a> announcing the new rule changes, Google said the way people used the internet - such as devices like smart TVs and consoles - meant it was harder to target ads to users using conventional data collection, which users control with cookie consent.</p><p>It also says more privacy options provide safety to users.</p><p>Google told the BBC in a statement: \"Privacy-enhancing technologies offer new ways for our partners to succeed on emerging platforms... without compromising on user privacy.\"</p><p>But opponents to the change say fingerprinting and IP address collection are a blow to privacy because it is harder for users to control what data is collected about them. </p><p>\"By allowing fingerprinting, Google has given itself - and the advertising industry it dominates - permission to use a form of tracking that people can't do much to stop,\" said Martin Thomson, distinguished engineer at Mozilla, a rival to Google.</p></div><div data-component=\"text-block\"><p>Fingerprinting collects information about a person's device and browser and puts it together to create a profile of that person. </p><p>The information is not explicitly collected in order to advertise to people, but it can be used to target specific ads based on that user's data.</p><p>For example, a person's screen size or language settings are legitimately needed in order to display a website properly. </p><p>But when that is combined with their time zone, browser type, battery level - and many other data points - it can create a unique combination of settings which makes it easier to work out who is using a web service.</p><p>These details along with someone's IP address - the unique identifier used by internet devices - were previously prohibited by Google for ad targeting. </p><p>Privacy campaigners say that unlike cookies, which are small files stored on a local device, users have little control over whether they send fingerprinting information to advertisers.</p><p>\"By explicitly allowing a tracking technique that they previously described as incompatible with user control, Google highlights its ongoing prioritisation of profits over privacy,\" said Lena Cohen, staff technologist at the Electronic Frontier Foundation. </p><p>\"The same tracking techniques that Google claims are essential for online advertising also expose individuals' sensitive information to data brokers, surveillance companies, and law enforcement,\" she added.</p></div><div data-component=\"text-block\"><p>\"My argument would be that fingerprinting sits in a little bit of a grey area,\" says Pete Wallace, from advertising technology company GumGum. </p><p>\"Should people feel comfortable staying in a grey area of privacy? I'd say no,\" he adds.</p><p>GumGum, which has worked with the BBC on ad campaigns before, relies on something called contextual advertising, which uses other data points to target adverts to online users, such as keywords on the website they are on - rather than their personal data.</p><p>Mr Wallace says allowing fingerprinting represents a shift in the industry.</p><p>\"Fingerprinting feels like it's taking a much more business-centric approach to the use of consumer data rather than a consumer-centric approach,\" he says.</p><p>\"This sort of flip-flopping is, in my opinion, detrimental to that route that the industry seemed to be taking towards this idea of really putting consumer privacy at the forefront.\"</p><p>He adds that he hopes ad tech companies conclude \"that it isn't the appropriate way to use consumer data,\" but expects them to look at fingerprinting as an option in order to better target adverts.</p><p>Advertising is the lifeblood of the internet business model, and allow many websites to be freely available to users without them having to directly pay to access them. </p><p>But in return, users often have to give up private information about themselves so that advertisers can show them relevant adverts.</p><p>The UK's data watchdog, the Information Commissioner's Office (ICO), says \"fingerprinting is not a fair means of tracking users online because it is likely to reduce people's choice and control over how their information is collected.\"</p><p>In a <a target=\"_blank\" href=\"https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/12/our-response-to-google-s-policy-change-on-fingerprinting/\">blog post</a> in December, the ICO's Executive Director of Regulatory Risk Stephen Almond wrote: \"We think this change is irresponsible.\"</p><p>He added that advertisers and businesses which decide to use this technology will have to demonstrate how they are staying within data and privacy laws in the UK. </p><p>\"Based on our understanding of how fingerprinting techniques are currently used for advertising this is a high bar to meet,\" he wrote.</p><p>Google said in a statement: \"We look forward to further discussions with the ICO about this policy change. </p><p>\"We know that data signals like IP addresses are already commonly used by others in the industry today, and Google has been using IP responsibly to fight fraud for years.\"</p><p>A spokesperson added: \"We continue to give users choice whether to receive personalised ads, and will work across the industry to encourage responsible data use.\" </p></div>","contentLength":5422,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43071506"},{"title":"Kindle is removing download and transfer option on Feb 26th","url":"https://old.reddit.com/r/kindle/comments/1inr9uy/fyi_amazon_is_removing_download_transfer_option/","date":1739729601,"author":"andyjohnson0","guid":751,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43070155"},{"title":"Caddy – The Ultimate Server with Automatic HTTPS","url":"https://caddyserver.com/","date":1739728575,"author":"huang_chung","guid":750,"unread":true,"content":"<div><a href=\"https://doi.org/10.1145/3319535.3363192\"><img src=\"https://caddyserver.com/resources/images/cites/aas.png\"></a><p>\n\t\t\t\t\t\t\t\t\"Servers running Caddy exhibit nearly ubiquitous HTTPS deployment and use modern TLS configurations. ... We hope to see other popular server software follow Caddy's lead.\"\n\t\t\t\t\t\t\t</p><p>\n\t\t\t\t\t\t\t\t—<b>Josh Aas, Richard Barnes, Benton Case, Zakir Durumeric, Peter Eckersley, Alan Flores-López, J. Alex Halderman, Jacob Hoffman-Andrews, James Kasten, Eric Rescorla, Seth Schoen, and Brad Warren.</b> 2019. <i>Let's Encrypt: An Automated Certificate Authority to Encrypt the Entire Web.</i> In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19). Association for Computing Machinery, New York, NY, USA, 2473–2487. <a href=\"https://doi.org/10.1145/3319535.3363192\">https://doi.org/10.1145/3319535.3363192</a></p></div><div><a href=\"https://doi.org/10.1145/2987443.2987480\"><img src=\"https://caddyserver.com/resources/images/cites/springall.png\"></a><p>\n\t\t\t\t\t\t\t\t\"No popular server software does [session ticket key rotation], with the exception of Caddy.\"\n\t\t\t\t\t\t\t</p><p>\n\t\t\t\t\t\t\t\t—<b>Drew Springall, Zakir Durumeric, and J. Alex Halderman.</b> 2016. <i>Measuring the Security Harm of TLS Crypto Shortcuts.</i> In Proceedings of the 2016 Internet Measurement Conference (IMC '16), Association for Computing Machinery, Santa Monica, California, USA, 33-47. <a href=\"https://doi.org/10.1145/2987443.2987480\">https://doi.org/10.1145/2987443.2987480</a></p></div>","contentLength":1106,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43070025"},{"title":"IPv6 Is Hard","url":"https://techlog.jenslink.net/posts/ipv6-is-hard/","date":1739725449,"author":"miyuru","guid":825,"unread":true,"content":"<p>Yesterday I read this <a href=\"https://chaos.social/@goetz/114001310396231712\">toot (German)</a> over on mastodon\nwhich starts with “IPv6 is hard.”</p><p><strong>No it’s not. It’s different.</strong></p><p>I ran across this multiple times: There is an A and an AAAA-record for a FQDN, but the\nweb server is only reachable via IPv4. You can easily test this with <a href=\"https://curl.se/\">curl</a></p><div><pre tabindex=\"0\"><code data-lang=\"shell\">$ curl -4  https://github.com -o /dev/null\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  273k      273k      3417k       --:--:-- --:--:-- --:--:-- 3553k\n$ curl -6  https://github.com -o /dev/null\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n   --:--:-- --:--:-- --:--:--     \ncurl: 7 Couldnt connect to server\n</code></pre></div><p>When using IPv4 273k are “saved” to /dev/null, using IPv6 we get an error message “Couldn’t connect to server”</p><p> that I’m using GitHub here because it is a well known example for not\noffering IPv6 as a time of writing, and it probably will have not IPv6 soon.</p><p>So in the case of the toot mentioned above there is an AAAA for the FQDN. But the connection doesn’t work. But the end user\ndoesn’t notice. Because there is a browser feature called <a href=\"https://datatracker.ietf.org/doc/html/rfc8305\">Happy Eyeballs (HE)</a>.\nBasically: A browser tries both protocols and uses the\nfaster on. In case of non-working IPv6 IPv4 is always faster.</p><p>HE can have some funny side effects. In a project a connection to a development web server sometimes worked and sometimes\ndidn’t. The solution was quite simple. The customer used a split VPN tunnel. IPv4 was routed via the VPN tunnel and those\nIPv4 addresses were allowed in the web servers access list. IPv6 was routed via the normal Internet connection and those\naddresses weren’t allowed.</p><p>But back to the original problem: In another toot we learn that a support ticket\nwas opened four weeks ago and that traceroute\nwas prohibited. But there is always the option to use the  option for traceroute or . This use tcp instead\nof UDP (standard traceroute) or ICMP (Windows tracert).</p><p>When you run traceroute -T for both IPv4 and IPv6 you’ll see that in this case IPv6 ends one hop earlier than IPv4. Or\nin this case the last hop loops back to itself.</p><p>This could mean that there is a missing firewall rule allowing traffic to the server or there is a routing issue on the\nfirewall.</p><p>But we can learn much more from this:</p><ul><li>If browser wouldn’t do happy eyeballs, the support hotline would have been exploded</li><li>There is no external monitoring, at least not for IPv6</li><li>There is no automation or at least no complete automation</li></ul><p>So please: If you do IPv6 take it seriously. If you don’t take it seriously,\ndon’t do IPv6. That leaves to people thinking that\nIPv6 is hard and can not be done.</p><p>Some notes: I’ll cover traceroute and co. in a future blog post and regarding\nGitHub check out this\n<a href=\"https://github.com/orgs/community/discussions/151477\">link</a>.</p>","contentLength":2898,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43069533"},{"title":"Half-Life 2 and Dishonored art lead Viktor Antonov has died","url":"https://www.eurogamer.net/half-life-2-and-dishonored-art-lead-viktor-antonov-dies-aged-just-52","date":1739725294,"author":"Trasmatta","guid":749,"unread":true,"content":"<p>Former Valve writer Marc Laidlaw revealed the news on social media, saying he had no details of Antonov's death, but he had had it confirmed that the \"visionary art lead\" had died.</p><p>\"I didn't want to say much till I felt it was confirmed, but I learned today that Viktor Antonov, our visionary art lead on HL2, has died,\" Laidlaw said.</p><p>\"I don't have details. Just sadness. Brilliant and original. Made everything better.\"</p><p>Antonov moved from Bulgaria to Paris when he was just 17 and went on to work or consult on a number of notable games, including Half-Life 2, Counter-Strike: Source, Half-Life 2: Lost Coast, Dishonored. Dishonored: Dunwall City Trials, <a data-keyword=\"true\" href=\"https://www.eurogamer.net/games/wolfenstein-the-new-order\">Wolfenstein: The New Order</a>, <a data-keyword=\"true\" href=\"https://www.eurogamer.net/fallout-4-walkthrough-and-guide-4019\">Fallout 4</a>, <a data-keyword=\"true\" href=\"https://www.eurogamer.net/games/dishonored-2\">Dishonored 2</a>, Doom, and Prey.</p>","contentLength":721,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43069514"},{"title":"United States Power Outage Map","url":"https://poweroutage.us/","date":1739724326,"author":"jonbaer","guid":715,"unread":true,"content":"<div><div>Electric customerswithout power:</div></div><div><div>Electric customerswithout power:</div></div><div><div>Electric customers </div></div><div>\n            Electric customers without power:</div>","contentLength":129,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43069399"},{"title":"Vim after Bram: a core maintainer on how they've kept it going","url":"https://thenewstack.io/vim-after-bram-a-core-maintainer-on-how-theyve-kept-it-going/","date":1739720645,"author":"MilnerRoute","guid":693,"unread":true,"content":"<p>Its community performed a quietly heroic effort to make sure his project stayed alive.</p><p>“What you can see is basically that the development did not stop,” Brabandt told his audience in Tokyo.</p><p>Every day there are fresh pull requests and issues to review, so “It’s still quite active. There’s a lot of activity going on on GitHub.”</p><p>And in January of 2024, they released Vim 9.1 — and dedicated it to Moolenaar.</p><h2>‘The Development Did Not Stop’</h2><p>Platform consultant <a href=\"https://github.com/chrisbra\" rel=\"external \" onclick=\"this.target='_blank';\">Christian Brabandt</a> had been active in the Vim community since 2006, contributing bug reports, fixes and a few new features. He’d worked on things like Vim’s regular expression handling and its support for encryption, as well as helping build its daily Appimage and “moving the home page around.” And then suddenly in August of 2023, “I became one of the main maintainers of Vim.”</p><p>The news of Moolenaar’s death was “quite shocking for all of us,” even though Vim’s mailing list had gone “pretty quiet” in the weeks before, and “people already started to wonder what happened with Bram? Where is he?”</p><p>“We had to decide what we were going to do.”</p><p>Brabandt first acknowledged that they “lost a lot of knowledge” — and not just Moolenaar’s test scripts.</p><p>Moolenaar started Vim 30 years ago, and he carried in his head “a lot of knowledge on the original Vim of all the features he wanted to have.” But more than that, Moolenaar was also the project’s leader. “He basically determined the strategy — where he wanted the project to go and what he wanted to be included and what he didn’t like.”</p><p>“We had to restructure and find ways to continue.”</p><p>And right from the beginning, there was one essential crisis. When it came to Vim’s GitHub account, “Bram was the owner. That means only he could make certain decisions — final decisions like setting up roles and permissions for other maintainers… We needed to have this power to continue working and invite other maintainers to the project.”</p><p>Fortunately, GitHub actually has a “<a href=\"https://docs.github.com/en/site-policy/other-site-policies/github-deceased-user-policy\" rel=\"external \" onclick=\"this.target='_blank';\">deceased user” policy</a>, including “<a href=\"https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-personal-account-on-github/managing-access-to-your-personal-repositories/maintaining-ownership-continuity-of-your-personal-accounts-repositories\" rel=\"external \" onclick=\"this.target='_blank';\">pre-designated successors</a>.” But unfortunately, Brabandt told his audience, using that policy “is not as easy as it sounds,” since after the paperwork is filled out, the GitHub account “becomes basically deactivated. Which wasn’t the best thing for us, since Bram’s family was able to access his account, and I didn’t want them to lose this ability.” Instead, Moolenaar’s family changed the permissions so that other maintainers could be invited.</p><p>Shortly after Moolenaar’s death, “Quite a few pull requests” started accumulating on GitHub, Brabandt said. “So I started going through those and importing them.” And when another long-time contributor and core maintainer, Charles Campbell, decided to retire, “I decided to invite a few more maintainers… mainly people who have been long-time contributors to Vim.”</p><p>But besides the source code, they also had to manage the project’s other infrastructure, and unfortunately, there were no documented processes, “so I had to find out all of this — how this is managed — basically, the hard way.”</p><p>And it seems like everything that could go wrong did.</p><ul><li>The site handling Vim’s vulnerability reports was <a href=\"https://www.businesswire.com/news/home/20230808746694/en/Protect-AI-Acquires-huntr-Launches-World%E2%80%99s-First-Artificial-Intelligence-and-Machine-Learning-Bug-Bounty-Platform\" rel=\"external \" onclick=\"this.target='_blank';\">acquired by an AI-security company</a> that Brabandt says “just wanted to concentrate on AI and only on AI… Open source vulnerability reporting was basically shut down almost immediately.” So the project turned to GitHub Security Advisory.</li><li>Brabandt learned the basic code of Vim’s home page hasn’t changed in 20 years. It still included PHP 7 code — though support for Php 7 <a href=\"https://www.php.net/releases/index.php\" rel=\"external \" onclick=\"this.target='_blank';\">ended in November of 2022</a>.</li><li>The service hosting their home page was acquired by Open Source China in July of 2023, and soon began serving visitors database errors, while support tickets went unanswered. So in the middle of restructuring the Vim project, the project team had to also find a new host for Vim’s home page — but, “Unfortunately, this also meant that we had to upgrade the home page from PHP 7 to at least PHP 8 support.”</li><li>The FTP server was still being run by the <a href=\"https://en.wikipedia.org/wiki/NLUUG\" rel=\"external \" onclick=\"this.target='_blank';\">Dutch Unix User Group</a>. “This was fine in the ’90s and maybe early 2000s,” Brabandt said, but “Nowadays I think people typically just download everything from GitHub or from the home page!” The Dutch Unix User Group was also reluctant to give Brabrandt access, and “It’s fine…” he said, “because we then decided to retire the old FTP server. And if a download needs to be done, it can be done via the Vim home page.”</li></ul><p>And since retiring FTP access, Brabandt says he hasn’t heard a single complaint.</p><p>It wasn’t until late 2024 that they realized the help pages still mentioned email addresses that were forwarding to Moolenaar’s old email account. “Just two weeks ago or so, I changed those, so now they have been forwarded to my address,” Brabandt told his audience in November.</p><p>Vim famously urges its users to contribute to Moolenaar’s favorite charity, the <a href=\"https://iccf-holland.org/\" rel=\"external \" onclick=\"this.target='_blank';\">International Child Care Fund Holland</a>, and Brabandt says the Moolenaar family is still maintaining <a href=\"https://www.paypal.com/donate?token=GuL3qWPYJL3FgOkjPAvH6zDTpScmwWX1L-e_6b58Oj-7yKhpaM9KeyMMGzfgTsICdLw2HDRrLssfR9sS\" rel=\"external \" onclick=\"this.target='_blank';\">Bram’s Paypal account for those donations</a> (still linked to from <a href=\"https://www.vim.org/\" rel=\"external \" onclick=\"this.target='_blank';\">Vim.org</a>). After Moolenaar passed a lot of people donated to the ICCF, with another 90,000 euros donated in 2024. Brabandt is also committed to making sure those donations go through as intended — and says he’s not planning to create any Vim sponsorships any time in the near future.</p><p>There was one change made: Bram Moolenaar’s feature which allowed ICCF donors to vote on future Vim features was shut down. It was hard to figure out which ICCF donations should be linked back to Vim.org users. (“I’m not sure how Bram did it in the past,” Brabandt says, and “the other people from the ICCF weren’t able to tell me!”) But in reality, it turns out that most of the new enhancement requests and issues are already coming from other sources like GitHub and Vim’s own to-do list.</p><p>So what does the future hold? Vim plans “a bit more potentially controversial changes” for the upcoming release of Vim 9.2, Brabandt told the audience. These include supporting the XDG specification’s <a href=\"https://www.freedesktop.org/wiki/Specifications/basedir-spec/\" rel=\"external \" onclick=\"this.target='_blank';\">base-directory specifications</a> (“The community has been wishing for it at least maybe 10 years.”) and better support for <a href=\"https://en.wikipedia.org/wiki/Wayland_(protocol)\" rel=\"external \" onclick=\"this.target='_blank';\">Wayland</a>. There are a few new options and plugins and some inevitable bug fixes.</p><p>So while changes are being made, this led Brabandt to a quietly momentous statement on the future of Vim. “However, currently I would say Vim is more or less in maintenance mode. I don’t think any of the maintainers can perform full-time work on Vim or bigger features.” As an example, he’s aware the Neovim community has been making big changes like support for parsing library <a href=\"https://tree-sitter.github.io/tree-sitter/\" rel=\"external \" onclick=\"this.target='_blank';\">Tree-sitter</a>, but adding that to Vim would take a “tremendous effort… I’m not quite sure we can achieve it, at least not in the near-term.”</p><p>But Brabandt announced another worthy goal: making sure that the community is healthy. And this means welcoming new contributors and making it easy for them to start contributing code. Brabandt has even imported some automatic code-formatting tools, since before Vim’s source code used an idiosyncratic formatting style that Brabandt called “strange. It’s basically Bram’s style of working, which is okay, but it doesn’t help new users.”</p><p>A later slide suggested things people could work on include “Tree-Sitter integration?” along with a GTK-version of Vim’s GUI interface and more advanced terminal features. Vim’s spell-checking code, for instance, “hasn’t been touched for a few years.”</p><p>“If you’re looking for big new features in the future, we do depend on the community to help us with this,” Brabandt said. But he always advises new contributors to “start small” while they’re first getting familiar with the codebase.</p><p>And for right now, “most of the changes that have been merged are relatively self-contained, small-feature sets, which can be easily tested and don’t have that much impact on other parts of the code.”</p><h2>Testing, Refactoring and Maybe Retiring That Python 2 Interface</h2><p>They’re still using “defensive and safe” C coding — Brabandt says refactoring everything into a modern programming language like Rust just isn’t an option right now. There’s a comprehensive suite of tests that he’s running over all changes — and every day they run the code-analyzing tool <a href=\"https://en.wikipedia.org/wiki/Coverity\" rel=\"external \" onclick=\"this.target='_blank';\">Coverity</a>. And going forward, they’ll refactor parts of the code “which are quite long and lengthy and complex and hard-to-understand.” (Does Vim really still need an external interface to Python 2? Since the Python community moved on to Python 3 years ago, Brabandt believes it’s an example of one of the outdated interfaces that could be retired “at some point in the future.”)</p><p>A big policy goal is making sure to continue Vim’s backward compatibility. And of course, learning from the past, Brabandt put up a slide titled “The new Vim Project — future,” which included a key “policy” bullet point: “Better documentation of (internal) processes.”</p><p>Brabandt said he came up with these policy principles while going through Moolenaar’s backlog of outstanding pull requests.</p><p>But another improvement he’d like to see is just a better understanding of Vim’s community — and he’s even considering a user survey. Toward the end of his talk, Brabandt told the audience what he’s learned since Moolenaar’s passing: that maintaining Vim is  — and that it’s a full-time job. “It’s not only about writing code; it’s about managing the community.” And that means  to that community — “Listening to their requests, fixing bugs that come up and making sure that we can keep up and do what the community wants.”</p><p>“It’s an open-source project — that means the community can contribute and should contribute and also help us steer the project into the future.”</p><p>And Brabandt said there’s already a clear signal of that <a href=\"https://thenewstack.io/open-source/\">healthy community</a>: the Vim conference itself.</p><div><svg width=\"68px\" height=\"31px\" viewBox=\"0 0 68 31\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></svg></div>","contentLength":10069,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43068884"},{"title":"Flea-Scope: $18 Source Available USB Oscilloscope, Logic Analyzer and More [pdf]","url":"https://rtestardi.github.io/usbte/flea-scope.pdf","date":1739718511,"author":"burgerone","guid":692,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43068585"},{"title":"Finding Flow: Escaping digital distractions through deep work and slow living","url":"https://www.ssp.sh/blog/finding-flow/","date":1739706024,"author":"articsputnik","guid":673,"unread":true,"content":"<p>Johann Hari says in <a href=\"https://www.goodreads.com/book/show/57933306-stolen-focus\" target=\"_blank\" rel=\"noopener noreffer\">Stolen Focus</a> that rats and pigeons can be manipulated as we want. Just give them food whenever they do what you want them to. And shortly after, they will repeat that over and over again.</p><p>This made me think. In times when Instagram and other apps give us likes, hearts, and views on things we post, how much does big tech influence our behavior?</p><p>Aren’t they the same as the researcher, feeding us with dopamine to tell us to do what they want? Are they doing the same as the researcher who feeds the rats or pigeons?</p><p>This question, and recent improvements and tinkering with my flow as I started working for myself, made me ask how we can control the addiction and the influence and find a better way to slow living.</p><p>Johann continues that people who don’t follow the above dopamine flow are artists and painters.</p><p>Instead of sharing or selling them immediately and getting rewarded, they draw the next one. The drawing, the way to the end, is the reward, not the likes or selling the art. After hundreds of interviews, <a href=\"https://en.m.wikipedia.org/wiki/Mihaly_Csikszentmihalyi\" target=\"_blank\" rel=\"noopener noreffer\">Mihaly Csikszentmihalyi</a> said all artists mentioned something like a Flow State.  that they just tried to be there.</p><p>This is also what I find most rewarding and experienced as an author: writing in the flow state, as I’m writing these words right now when I am merely in control, but the words flow out of my fingers. I guide them, but I do not write or choose the words.</p><p>This flow and the outcome of what the article looks like after are just magical.</p><p>I have rediscovered the effects of the environment lately when working for myself when I had to find productivity in my everyday work without a boss telling me what to do. At home, I wasn’t always focused enough. I had all the distractions. Going to the library usually produces my best work.  Focused without distractions. But always going there, sometimes it’s open late, or closed. Another great way to write and be creative is to use coffee shops, specifically <strong>moving to the next every 1.5 to 2.5 hours</strong>. It’s the sweet spot for me between being creative and getting distracted. And interestingly enough, the same for <a href=\"https://www.youtube.com/cgpgrey\" target=\"_blank\" rel=\"noopener noreffer\">CGP Grey</a> in his <a href=\"https://share.snipd.com/episode/6d03cf6a-1744-412d-a158-57aef1097f5b\" target=\"_blank\" rel=\"noopener noreffer\">Redundant Office</a> podcast, he said the same.</p><p>Music, especially non-vocal music on repeat or dedicated <a href=\"https://www.ssp.sh/brain/music-that-keeps-you-focused/\" target=\"_blank\" rel=\"noopener noreffer\">Music that keeps you focused</a>, helps you stay in the flow longer. It’s another way of signaling an environment to the brain, like “Now is work time”. I also use a dedicated browser; for example, I use Zen browser for work and Brave for everything else. Zen, the work browser, has no extensions. No password manager to automatically log in and no history to quickly choose the latest website distraction. These little obstacles make it harder to distract, whereas my Brave has all the convenience at one tab away.</p><p>Another huge benefit of my writing work is that all my files are offline in my <a href=\"https://www.ssp.sh/brain/obsidian\" target=\"_blank\" rel=\"noopener noreffer\">Obsidian</a> Vault. No need to go online or log in to a web app to get going. It’s just there to start writing, brainstorming, and getting into the flow. Another way to stay in the flow is to use Markdown files and <a href=\"https://www.ssp.sh/brain/vim-language-and-motions/\" target=\"_blank\" rel=\"noopener noreffer\">Vim motions</a>. The Markdown files are simple text files that can be easily accessed and moved around. The key here is that the text’s formatting allows me to move and restructure entire chapters or ideas without friction. Adding the vim motions, I can do everything in the comfort of my keyboard. As I use them daily, they are muscle memory, and I can write at the speed of thought.</p><div><div><div><a href=\"https://brain.ssp.sh\" target=\"_blank\" rel=\"noopener noreffer\">My second brain</a>, offline notes in my Obsidian vault, allows me to create connections, observe the graph, and see connected or relevant notes that could influence my thinking on the topic I am writing. A note on a book I wrote 10 years ago, with some insight that didn’t touch much back then, but connected to the current thought, with more knowledge, can make all the difference.</div></div></div><p>One crucial ingredient that is mostly overlooked is breaks. Small drinking breaks and walking around as observed with the 1.5-2.5h sweet spot. But much more, long periods off, vacations where you don’t think of work or related. Your brain has time to wander. Good sleep to a certain extent is also a form of break. The more we learn about sleep (see <a href=\"https://www.goodreads.com/work/quotes/55587034-why-we-sleep-unlocking-the-power-of-sleep-and-dreams\" target=\"_blank\" rel=\"noopener noreffer\">Why We Sleep by Matthew Walker</a>), the more prevalent it is how important it is. I also notice to myself. If I sleep, the chances of being productive in the morning, achieving my goals early, and getting a sense of calm throughout the rest of my day are much higher. As we process primarily during sleep, especially with the <a href=\"https://en.wikipedia.org/wiki/Rapid_eye_movement_sleep\" target=\"_blank\" rel=\"noopener noreffer\">REM (Rapid Eye Movement)</a> sleep that we usually get only after sleeping for 7-8 hours, is where the brain is cleansing itself, and making it ready for the next day.</p><p>I am on vacation writing this article, and I haven’t written for a couple of days. I am enjoying time on vacation, nature, and with family, letting my brain drift and follow its thoughts. These ideas, connections, and words basically flow themselves, as my brain is super relaxed. While being offline and taking a break, the brain makes sense of things in the subconscious.</p><div><div>There Are Different Kinds of Rest</div><div><div><p>To unblock, you can unblock or rest in different types of rest:</p><ul></ul></div></div></div><p>Another way of taking breaks is small . I explored these in my <a href=\"https://www.ssp.sh/brain/pathless-path/\" target=\"_blank\" rel=\"noopener noreffer\">Pathless Path</a>. These are like Sabbaticals. I did many of these early in my life, and they heavily influenced who I am today and how my life unfolded. But more on this in <a href=\"https://ssp.sh/blog/finding-my-pathless-path/\" target=\"_blank\" rel=\"noopener noreffer\">Finding My Pathless Path</a>.</p><h2>Slowing down, Slow Living</h2><p>Slowing down, and just , is another essential concept. Slowing down, being more present. As Cal Newport says in his book <a href=\"https://www.goodreads.com/book/show/197773418-slow-productivity\" target=\"_blank\" rel=\"noopener noreffer\">Slow Productivity</a>, his main points are:</p><ol></ol><p>If we apply this to life, we get a <a href=\"https://www.ssp.sh/brain/deep-life\" target=\"_blank\" rel=\"noopener noreffer\">Deeper Life</a>. One that is more fulfilled and present. It is about finding the balance between the important and the urgent.</p><p>Turning off the phone, without the pressure or the urge to check if someone has messaged you, if you got a like on social media, your brain starts wondering. You start getting ideas and thoughts to ponder. But these don’t start immediately. If you have been distracted, living a fast life, are constantly on the go, and have no time to think about anything, without defined <a href=\"https://www.ssp.sh/brain/principles\" target=\"_blank\" rel=\"noopener noreffer\">principles</a> to work towards, without <a href=\"https://www.ssp.sh/brain/clarity/\" target=\"_blank\" rel=\"noopener noreffer\">clarity</a>, your brain can’t just switch, and be . But practicing it, like meditation or yoga, is undoubtedly worth it.</p><div><div><div>Another book by Cal Newport is Digital Minimalism, which goes in the same direction—trying to use fewer digital mediums, less social media, and less distraction. I thoroughly recommend it, too.</div></div></div><div><div>The basics: Food, Sleep, and Smartphones</div><div><div>The basis on top of these, is also a good sleep, nutritious food. And the phone needs to be away on do not disturb mode, or best in another room.</div></div></div><h3>Shallow vs. Deep Happiness</h3><p>These can also be summarized into what I call shallow happiness versus deep happiness. Buying something new, eating fast food, having another coffee, or watching a YouTube video all give us pleasure, but only in the . Writing an article or learning something hard, like coding or vim motions, is initially hard. But the reward is long-term. We get  from being in the flow and perfecting something we have learned and perfected over a long time.</p><p>Maybe that’s the secret of a <a href=\"https://www.ssp.sh/brain/deep-life\" target=\"_blank\" rel=\"noopener noreffer\">Deep Life</a>? Not reading news, journaling, praying, meditating, or following a Stoic practice. Reading books is a similar thing; it’s hard to listen to or read an entire book, but when we do, especially if we learn something new, without distractions, in a format the author spent a year or more to curate and put into its format, is so calming and almost peaceful. In fact,   is known to be the biggest and most common version of flow.</p><p>There’s much more to dig into, which I might in another article about “Why we are here on earth?”. This article has been cooking over many months and years already. It will go much deeper and more philosophical about why we even do what we do. It will be connected and even strengthen the flow more if we have clear principles, a clear path, and a passion for why we do something.</p><p>But now, instead, I want to focus on how to get into a flow state or how to unblock us when we feel stressed and not in the mood to do the <a href=\"https://www.ssp.sh/brain/deep-work\" target=\"_blank\" rel=\"noopener noreffer\">Deep Work</a>. If we easily get distracted.</p><p>These are all based on personal experience and books I read. They don’t always work, but one variation usually does the trick by iterating on them.</p><p>These are more pointers related to this article’s topic, thoughts, or steps I followed, some of which are already on my <a href=\"https://brain.ssp.sh\" target=\"_blank\" rel=\"noopener noreffer\">Second Brain</a>.</p><p>Walk every day; nature is tiding our thoughts, just like naps and sleep. Walking, or going outside, is suitable for mental, spiritual, and physical health. When I start walking, the ideas flow, my brain calms down, and I slowly begin to think and process anything I am pondering. It’s best when done in . Nature in itself is a remedy for calming down. It has helped all the big thinkers before our time and will help many after ours.</p><p>Like our inner monkeys or daemons, they don’t want us to go out of bed or get fresh air. Walking frees us from them—the opposite of what social media or smartphones do.</p><div><div><div>Sometimes, bring a paper notebook or camera to capture ideas or thoughts. But other times, go deliberately without.</div></div></div><p>Try to change the medium. If writing on a computer does not work, try pen or paper. Or try talking. As Jonny Miller said:</p><blockquote>There is no talking block, only writer's block.</blockquote><p>Interestingly, if we change the medium, we can unblock it:</p><ul><li>Change environment, physically as well as digitally:\n<ul><li>: Go to another room, a coffee shop, or what works best for me, Libraries.</li><li>: Also, changing your computer environment, e.g., changing from dark to light mode or changing the theme, can give you a sense of change and fresh energy.</li></ul></li><li>Timebox yourself, also called <a href=\"https://en.wikipedia.org/wiki/Pomodoro_Technique\" target=\"_blank\" rel=\"noopener noreffer\">Pomodoro Technique</a>. It has the same effect and works in the train with only the battery. The urge to finish before you run out of battery will give you focus and added clarity.</li><li>Change between Text and Visual: I use a lot of MindMap on paper, but <a href=\"https://obsidian.md/canvas\" target=\"_blank\" rel=\"noopener noreffer\">Obsidian Canvas</a>, Draw with ExaliDraw, and others work as well.</li><li>Try to get into the same habit when working (same place, same music, etc.). Your brain will know it needs to write before you even start.\n<ul><li>Check <a href=\"https://youtu.be/snAhsXyO3Ck?feature=shared\" target=\"_blank\" rel=\"noopener noreffer\">Spaceship You</a> by CGP Grey, showcasing how designated space helped during the pandemic, but also for clarity.</li></ul></li></ul><h3>How I get into Deep Work — Flow</h3><p>The above strategies to unblock are also related to <a href=\"https://www.ssp.sh/brain/deep-work/\" target=\"_blank\" rel=\"noopener noreffer\">Deep Work</a> and how I get into deep work:</p><ol><li>Journal before bed what 1-2 tasks you must/want to achieve tomorrow.</li><li>Go to bed early (you usually don’t achieve much at night).</li><li>Get up before the kids :) (don’t turn on the phone).</li><li>Later, take a walk in nature.</li><li>Change environment/room if stuck.</li></ol><ul><li>Clear some time in your calendar.</li><li>Get rid of distractions: Turn off notifications, close Slack, and put your phone out of reach.&nbsp;</li><li>Clear your space and your mind. Put on concentration music, and get rid of any clutter around.&nbsp;</li><li>Get to work on a specific task, taking periodic short breaks.</li><li>Deeper: Acknowledge your fears, write from authenticity and a place of .\n<ul><li> is stored in our body (not in our mind)</li><li> are like a GPS, help us to find truth and navigate around</li></ul></li></ul><p>Also, like , add boundaries and constraints like no internet, use another browser for searching the web, and suddenly ideas flow. Unlimited freedom is super-blocking, especially for creativity. Great read on the topic: <a href=\"https://sashachapin.substack.com/p/if-you-have-writers-block-maybe-you\" target=\"_blank\" rel=\"noopener noreffer\">If You Have Writer’s Block, Maybe You Should Stop Lying</a>.</p><div><div><div>When I don’t have inspiration or I have a block, I do nothing. . And it’s absolutely because of the deeper inspiration that I’m blessed to feel. I feel it’s been cultivated. I’m connected to it, and I know it’s real, and it doesn’t have to greet me every day. I know it’s there.—</div></div></div><h3>Turn Off, Shut Down, and Re-Energize for a Happy Life</h3><p>Something that is easy to say but hard to do. I enjoy  or a long bicycle ride. It does not matter what you do, but that you do something without distraction. I was listening to books on the walks for a long time, but this always felt like more work. Sure, if you have a great book, listening can be fun too, but I did my best to calm down when going without any decision—just me and nature.</p><p>From the book “The Well-Lived Life: A 102-Year-Old Doctor’s Six Secrets to Health and Happiness at Every Age”, a <a href=\"https://www.goodreads.com/book/show/62918481-the-well-lived-life\" target=\"_blank\" rel=\"noopener noreffer\">comment</a> by Liong on Goodreads says the six secrets may help us live a <strong>long, happy, and healthy life</strong>:</p><ol><li>Let go of the past (Forget the past regrets and anger).</li><li>Live in the present moment. (Live now; don’t stay in your history and worry about your future).</li><li>Connect with nature. (Read and find out yourself).</li><li>Eat a healthy diet. (Choose and be aware of what you eat daily).</li><li>Get regular exercise. (Try exercise every day).</li><li>Find your purpose. (Having a purpose is vital to living longer).</li></ol><h3>Nature: How It Flourishes Creativity</h3><p>Take inspiration from nature. Nature is so powerful.</p><p>For example, watching a tree through the four seasons: In summer, it is green with many leaves; in autumn, it loses them all; in winter, it looks dead. But instead, it builds and prepares its strength for the spring. Where the colorful flowers sprout, it’s calming and inspiring.</p><p>Take gardening; it takes so much patience to grow those three. It puts time into different perspectives. Threes  houses and plants are harvested over many years. If you sell a home, things might have been there long before the house.</p><p>I like to get inspiration from nature. I think of my <strong>creative process as gardening</strong>. Things inside us build up , but great things will come out with constant nurturing: Art, a thought, an idea, anything. It doesn’t matter which day. It’s seasonal, similar to creativity; we can’t be creative all year.</p><p>I hope any of these helped you; more so, it helped me to clarify focus in connection with the ever-growing (primarily digital) distractions to find a better life worth living—A slower and deeper life could be possible.</p><p>Books and related reads I recommend that gave me lots of inspiration:</p>","contentLength":13861,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43067303"},{"title":"“A calculator app? Anyone could make that”","url":"https://chadnauseam.com/coding/random/calculator-app","date":1739701009,"author":"pie_flavor","guid":611,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43066953"},{"title":"50 Years of Travel Tips","url":"https://kk.org/thetechnium/50-years-of-travel-tips/","date":1739698262,"author":"marban","guid":672,"unread":true,"content":"<p>I’ve been seriously traveling for more than 50 years, and I’ve learned a lot.</p><p>I’ve traveled solo, and I’ve led a tour group of 40 friends. I’ve slept in dormitories and I’ve stayed in presidential suites with a butler. I’ve hitchhiked penniless for months, and I’ve flown by private jet. I’ve traveled months with siblings, and with total strangers. I’ve gone by slow boat and I’ve ridden my bicycle across America, twice. I’ve been to the largest gathering of humans on the planet, and trekked into remotest areas on the planet on my own. I’ve paid for luxury tours, and I’ve done my own self-guided tours. I regularly travel for business, and once I went to Hawaii on a door-prize award. I’ve circumnavigated the globe in only 48 hours, and I traveled uninterrupted for 9 months. I’ve gone first class and third class, sometimes on the same trip. So far I’ve visited half the world’s countries, and usually manage to get far from the capital city when I do. Here is what I know about how to travel.</p><p>There are two modes of travel; retreat or engage. People often travel to escape the routines of work, to recharge, relax, reinvigorate, and replenish themselves— R&amp;R. In this mode you travel to remove yourself from your routines, or to get the pampering and attention you don’t ordinarily get, and ideally to do fun things instead of work things. So you travel to where it is easy. This is called a vacation, or R&amp;R.&nbsp;</p><p>The other mode is engagement and experience, or E&amp;E. In this mode you travel to discover new things, to have new experiences, to lean into an adventure whose outcome is not certain, to meet otherness. You move to find yourself by encountering pleasures and challenges you don’t encounter at home. This kind of travel is a type of learning, and of the two modes, it is the one I favor in these tips.</p><p>Organize your travel around passions instead of destinations. An itinerary based on obscure cheeses, or naval history, or dinosaur digs, or jazz joints will lead to far more adventures, and memorable times than a grand tour of famous places. It doesn’t even have to be your passions; it could be a friend’s, family member’s, or even one you’ve read about. The point is to get away from the expected into the unexpected.</p><p>If you hire a driver, or use a taxi, offer to pay the driver to take you to visit their mother. They will ordinarily jump at the chance. They fulfill their filial duty and you will get easy entry into a local’s home, and a very high chance to taste some home cooking. Mother, driver, and you leave happy. This trick rarely fails.</p><p>Make no assumptions about whether something will be open. There are other norms at work. If possible check at the last minute, if not, have a plan B.</p><p>Crash a wedding. You are not a nuisance; you are the celebrity guest! The easiest way to do this is to find the local wedding hall where weddings happen on schedule and approach a wedding party with a request to attend. They will usually feel honored. You can offer the newlyweds a small token gift of cash if you want. You will be obliged to dance. Take photos of them; they will take photos of you. It will make your day and theirs. (I’ve crashed a wedding in most of the countries I have visited.)</p><p>Don’t balk at the spendy price of admission for a museum or performance. It will be a tiny fraction of your trip’s total cost and you invested too much and have come too far to let those relative minor fees stop you from seeing what you came to see.</p><p>Google maps will give you very detailed and reliable directions for taking public transit, including where to make transfers in most cities.</p><p>When visiting a foreign city for the first time, take a street food tour. Depending on the region, the tour will include food carts, food trucks, food courts, or smaller eateries. It will last a few hours, and the cost will include the food. You’ll get some of the best food available, and usually the host will also deliver a great introduction to the culture. Google “street food tour for city X.”</p><p>The most significant criteria to use when selecting travel companions is: do they complain or not, even when complaints are justified? No complaining! Complaints are for the debriefing afterwards when travel is over.</p><p>As in any art, constraints breed creativity. Give your travel creative constraints: Try traveling by bicycle, or with only a day bag for luggage, or below the minimum budget, or sleep only on overnight trains. Mix it up. Even vagabonding can become a rut.</p><p>Renting a car is easier than ever today, even in developing countries, and oftentimes the best bet for getting around if you are headed for many places outside of cities. It is an option worth considering, especially if you are 2 to 3 people traveling. On the other hand, there are still plenty of places where you don’t want to drive because of chaotic roads, lawless attitudes, and unfavorable liabilities. In those places hiring a driver plus car for a multi-day trip is often a surprisingly appealing bargain—especially if you have 2 to 3 people to split the costs. The total could be less than taking trains and taxis, and you get door to door service, and often a built-in guide who knows the local roads and also local festivities and best places to eat. They will be at least 2x the cost of renting a car, but for some kinds of travel 2x as good. If you are a spontaneous traveler, a hired driver is by far the best option allowing you to change your itinerary immediately as mood, weather, or lucky timing dictate. I usually find drivers by searching travel forums for recommendations. I score candidates primarily by their communication skills.</p><p>If you are fortunate, a fantastic way to share your fortune is to gift a friend the cost of travel with you. You both will have a great time.</p><p>Go to a cemetery. Look for sacred places. People live authentically there. Don’t just visit the markets, but also go to small workshops, hardware stores and pharmacies –&nbsp; places with easy access to local practices. See how it’s different and the same all at once.</p><p><a href=\"https://www.flightaware.com/\">FlightAware</a> is the best free phone app for the status of your flight. It will often tell you about delays hours before the airline will. Tip: use FlightAware to check whether your plane has even arrived at your departure airport.</p><p>Sketchy travel plans and travel to sketchy places are ok. Take a chance. If things fall apart, your vacation has just turned into an adventure. Perfection is for watches. Trips should be imperfect. There are no stories if nothing goes amiss.&nbsp;</p><p>Your enjoyment of a trip will be inversely related to the weight of your luggage. Counterintuitively, the longer your trip, the less stuff you should haul. Travelers still happy on a 6-week trip will only have carry-on luggage. That maximizes your flexibility, enabling you to lug luggage up stairs when there is no elevator, or to share a tuk-tuk, to pack and unpack efficiently, and to not lose stuff. Furthermore, when you go light you intentionally reduce what you take in order to increase your experience of living. And the reality of today is that you can almost certainly buy whatever you are missing on the road.</p><p>Getting an inside tour is the ultimate travel treat. How about a factory tour, a visit to an Amish home, or backstage at an opera? When I travel for business I will sometimes ask for inside access to an uncommon place in lieu of a speaking fee. You are aiming for experiences that simple money can’t buy. Good ones will take planning ahead.</p><p>It is always colder at night than you think it should be, especially in the tropics. Pack a layer no matter what.</p><p>Planning your itinerary: You want to see it all and you are likely to never return, so the temptation is to pile it on, maximize your visit. Since we are in X, and Y and Z&nbsp; are so close, we might as well see Y and Z….. Paradoxically when you are traveling you should minimize the amount of time you spend in transit—once you arrive. The hard-to-accept truth is that it is far better to spend more time in a few places than a little time in a bunch of places.&nbsp;</p><p>To book a train anywhere in the world outside your home country, your first stop should be <a href=\"https://www.seat61.com/\">The Man in Seat 61</a>, a sprawling website which will conveniently help you book the train you want.&nbsp;</p><p>In 53 years of travelling with all kinds of people, I’ve seen absolutely no correlation between where you eat and whether you have intestinal problems, so to maximize the enjoyment of local foods, my rule of thumb is to eat wherever healthy-looking locals eat.</p><p>The list of most coveted cities to visit have one striking thing in common—they are pedestrian centric. They reward walking.Better online hotel sites like<a href=\"http://booking.com\"> Booking.com</a> have map interfaces which allow you to select hotels by their location. Whenever possible I book my hotel near to where it is best to walk, so I can stroll out the door and begin to wander.&nbsp;</p><p>For a truly memorable trip, go without reservations, just winging it along the way. If you like somewhere, stay a day longer, or if you don’t, split a day earlier. If the train is full, take a bus. That freedom can be liberating.</p><p>The <a href=\"https://apps.apple.com/tr/app/google-translate/id414706506\">Google Translate app</a> for your phone is seriously good, and free. It will translate voice, text, or script to and from 250 languages. Use for deciphering menus, signs, talking with clerks, etc. It is often a lifesaver.</p><p>Large-scale luxury cruises have no appeal to me, yet a small boat cruise is an entirely different species and a valid option worth considering. The advantage of a cruise is that your hotel travels with you, so you unpack only once. It is especially useful for small groups because it eliminates the eternal negotiation of deciding where to eat. (You always eat on the boat.) The advantages of a small boat cruise over a huge boat are several: you disembark very quickly, very often, at smaller more intimate places than large boats can do. And the options for activities are more active than just shopping: such as snorkeling, kayaking, bicycling, hiking, visiting local families and communities. Overall you spend far more time doing things off the boat than on. I define a small boat as 40 passengers or fewer. The per day cost is high, but almost every minute of it is quality time, unlike a series of bus rides. Examples of places I’ve loved a small boat cruise; The Galapagos, Alaska inland passageway, Mekong River, Coast of Turkey, and Kerala, India.</p><p>The rate you go is not determined by how fast you walk, bike or drive, but by how long your breaks are. Slow down. Take lots of breaks. The most memorable moments—conversations with amazing strangers, an invite inside, a hidden artwork—will usually happen when you are not moving.</p><p>I generally find “professional” tour guides uninteresting, and too scripted. They are mostly repeating what can be found in guide books. So I rarely hire them. I much prefer to have a friend or local acquaintance show me what interests them in an ad hoc way, with no script. Let friends know you are coming to their area.</p><p>A few <a href=\"https://amzn.to/4gKbKAV\">laundry detergent sheets</a> in a tiny ziplock bag weigh nothing and won’t spill and are perfect for emergency laundry washing in the sink or shower.&nbsp;</p><p>These days it is mandatory that you are connected. You need cell coverage as well as wifi. You’ll want robust mobile coverage for navigation, translation apps, ride shares and a digital wallet for payments. Best option is to use a carrier with “free” international plans (such as T-Mobile or <a href=\"https://fi.google.com/about/\">Google Fi</a>) so you need to do nothing. Second best is to get either a sim card or e-sim for your phone for your visiting country. E-sim apps (such <a href=\"https://www.airalo.com/\">Airalo</a>) can be loaded by yourself virtually. Sims and e-sims are also sold at most international airports when you exit. Most are reputable. One tip, turn off your photo and video cloud backup while on the sim to reduce data usage.&nbsp;</p><p>People in other places are not saints. You might get cheated, swindled, or taken advantage of. Paradoxically, the best way to avoid that is to give strangers your trust and treat them well. Being good to them brings out their good. If you are on your best behavior, they will be on their best behavior. And vice versa. To stay safe, smile. Be humble and minimize your ego. I don’t know why that works everywhere in the world—even places with “bad” reputations—but it does.</p><p>You can get an inexpensive and authentic meal near a famous tourist spot simply by walking at least five blocks away from the epicenter.&nbsp;</p><p>Digital wallets on your phone are displacing local currencies in many places. For instance I did not use any cash on my last trips to the UK and China. And in places where it has not completely eliminated cash you can reduce your cash needs by half with mobile payments. Set up your Apple pay, Google Pay or Alipay before you leave. There is no need to exchange money anywhere, especially at airports. Get any cash you need at local ATMs, which are now everywhere. Use a card that does not charge, or reimburses, a foreign fee.&nbsp;</p><p>If you detect slightly more people moving in one direction over another, follow them. If you keep following this “gradient” of human movement, you will eventually land on something interesting—a market, a parade, a birthday party, an outdoor dance, a festival.&nbsp;</p><p>Splurge in getting the most recent version of a guidebook to your destination. It is worth the price of a lunch to get the latest, most helpful, reliable information. I supplement the latest guidebook research with recommendations suggested in travel forums online. Guidebooks have depth and breadth, while forums offer speed—results from a week ago.&nbsp;</p><p>If you are starting out and have seen little of the world, you can double the time you spend traveling by heading to the places it is cheapest to travel. If you stay at the budget end, you can travel twice as long for half price. Check out <a href=\"https://www.cheapestdestinationsblog.com/\">The Cheapest Destination Blog</a>. In my experience, these off-beat destinations are usually worth visiting.</p><p>In many parts of the world today motorcycles play the role of cars. That means you can hire a moto-taxi to take you on the back seat, or to summon a moto-taxi with an uber-like app, or to take a motorcycle tour with a guide doing the driving. In areas where motorcycles dominate they will be ten times more efficient than slowly going by car.</p><p>Even if you never go to McDonalds at home, visit the McDonalds on your travels. Surprisingly, their menus are very localized and reflect different cuisines in a fun and easy way, with unexpected versions of familiar things. Very illuminating!</p><p>Put inexpensive <a href=\"https://amzn.to/4hxt9y4\">Apple AirTags</a> into your bags, so you can track them when they are out of your sight. More and more airlines are integrating AirTags into their system to help find wayward bags. The tags work for luggage left in hotel storage, or stashed beneath the bus, or pieces you need to forward.&nbsp;</p><p>For the best travel experiences you need either a lot of money, or a lot of time. Of the two modes, it is far better to have more time than money. Although it tries, money cannot buy what time delivers. You have enough time to attend the rare festival, to learn some new words, to understand what the real prices are, to wait out the weather, or to get to that place that takes a week in a jeep. Time is the one resource you can give yourself, so take advantage of this if you are young without money.</p><p>Being beautiful, or well crafted, or cheap is not enough for a souvenir. It should have some meaning from the trip. A good question you may want to ask yourself when buying a souvenir is where will this live when I get home?</p><p>The best souvenirs from a trip are your memories of the trip so find a way to memorialize them; keep a journal, send updates to a friend, take a sketchbook, post some observations, make a photo book.&nbsp;</p><p>When asking someone for a restaurant recommendation, don’t ask them where is a good place you should eat; ask them where they eat. Where did they eat the last time they ate out?</p><p>Here in brief is the method I’ve honed to optimize a two-week vacation: When you arrive in a new country, immediately proceed to the farthest, most remote, most distant place you intend to reach during the trip. If there is a small village, remote spa, a friend’s farm, or a wild place you plan on seeing on the trip, go there immediately. Do not stop near the airport. Do not rest overnight in the arrival city. Do not pause to acclimate. If at all possible proceed by plane, bus, jeep, car directly to the furthest point without interruption. Make it an overnight journey if you have to. Then once you reach your furthest point, unpack, explore, and work your way slowly back to the big city, wherever your international departure airport is.</p><p>In other words you make a laser-straight rush for the end, and then meander back. Laser out, meander back. This method is somewhat contrary to many people’s first instincts, which are to immediately get acclimated to the culture in the landing city before proceeding to the hinterlands. The thinking is: get a sense of what’s going on, stock up, size up the joint. Then slowly work up to the more challenging, more remote areas. That’s reasonable, but not optimal because most big cities around the world are more similar than different. All big cities these days feel same-same on first arrival. In Laser-Back travel what happens is that you are immediately thrown into Very Different Otherness, the maximum difference that you will get on this trip. You go from your home to extreme differences so fast it is almost like the dissolve effect in a slide show. Bam! Your eyes are wide open. You are on your toes. All ears. And there at the end of the road (but your beginning), your inevitable mistakes are usually cheaper, easier to recover from, and more fun. You take it slower, no matter what country you are in. Then you use the allotted time to head back to the airport city, at whatever pace is your pace. But, when you arrive in the city after a week or so traveling in this strangeness, and maybe without many of the luxuries you are used to, you suddenly see the city the same way the other folks around you do. After eight days in less fancy digs, the bright lights, and smooth shopping streets, and late-night eateries dazzle you, and you embrace the city with warmth and eagerness. It all seems so … civilized and ingenious. It’s brilliant! The hustle and bustle are less annoying and almost welcomed. And the attractions you notice are the small details that natives appreciate. You see the city more like a native and less like a jaded tourist in a look-alike urban mall. You leave having enjoyed both the remote and the adjacent, the old and new, the slow and the fast, the small and the big. </p><p>We’ve also learned that this intensity works best if we aim for 12 days away from home. That means 10 days for in-country experience, plus a travel day (or two) on each end. We’ve found from doing this many times, with many travelers of all ages and interests, 14 days on the ground is two days too many. There seems to be a natural lull at about 10 days of intense kinetic travel. People start to tune out a bit. So we cut it there and use the other days to come and go and soften the transitions. On the other hand 8 days feels like the momentum is cut short. So 10 days of intensity, and 12 days in a country is what we aim for. Laser-back travel is not foolproof, nor always possible, but on average it tends to work better than the other ways I’ve tried.</p><p>If you work while you travel, or work remotely, you may enjoy our newsletter <a href=\"https://nomadico.substack.com/\">Nomadico</a>, which is a weekly one-pager with four brief travel tips. It’s free.&nbsp;</p><p>(Thanks to early readers, Craig Mod, Derek Sivers, Chris Michel and Will Milne.)</p>","contentLength":19756,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43066720"},{"title":"US government struggles to rehire nuclear safety staff it laid off days ago","url":"https://www.bbc.com/news/articles/c4g3nrx1dq5o","date":1739691949,"author":"niuzeta","guid":519,"unread":true,"content":"<p>US media reported that more than 300 NNSA staff were let go, citing sources with knowledge of the matter.</p><p>That number was disputed by a spokesperson for the Department of Energy, who told CNN that \"less than 50 people\" were dismissed from NNSA.</p><p>The Thursday layoffs included staff stationed at facilities where weapons are built, according to CNN. </p><p>The Trump administration has since tried to reverse their terminations, according to media outlets, but has reportedly struggled to reach the people that were fired after they were locked out of their federal email accounts.</p><p>A memo sent to NNSA employees on Friday and obtained by NBC News read: \"The termination letters for some NNSA probationary employees are being rescinded, but we do not have a good way to get in touch with those personnel.\"</p><p>\"Please work with your supervisors to send this information (once you get it) to people's personal contact emails,\" the memo added.</p><p>Last week, nearly 10,000 federal workers were let go across several agencies, according to multiple US outlets. </p><p>That figure was in addition to the estimated 75,000 workers who have accepted an offer from the White House to leave voluntarily in the autumn. </p><p>Trump is working to slash spending across the board, abroad and at home, and going so far as to call for eliminating the education department. </p><p>He is getting help from the world's richest man, Elon Musk, who, through an effort called Department of Government Efficiency (Doge), has sent workers to comb through data at federal agencies and helped implement the \"buyout\" offer.</p><p>Last week, the Trump administration ordered agencies to fire nearly all probationary employees, those who had generally been in their positions for less than a year and not yet earned job protection. That included the NNSA staff members.</p><p>Altogether, the move could potentially affect hundreds of thousands of people. </p><p>Several of the Trump administration's efforts to shrink the government's size and spending have been met with legal challenges. </p><p>More than 60 lawsuits have been filed against the Trump administration since the president was inaugurated on 20 January.</p>","contentLength":2119,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43066182"},{"title":"Gixy: Nginx Configuration Static Analyzer","url":"https://github.com/dvershinin/gixy","date":1739678764,"author":"mmsc","guid":610,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43065217"},{"title":"How Medical Research Cuts Would Hit Colleges and Hospitals in Every State","url":"https://www.nytimes.com/interactive/2025/02/13/upshot/nih-trump-funding-cuts.html","date":1739671645,"author":"erickhill","guid":509,"unread":true,"content":"<p>A proposal by the Trump administration to <a href=\"https://www.nytimes.com/2025/02/07/us/politics/medical-research-funding-cuts-university-budgets.html\">reduce the size of grants</a> for institutions conducting medical research would have far-reaching effects, and not just for elite universities and the coastal states where many are located.</p><p>Also at risk could be grants from the National Institutes of Health to numerous hospitals that conduct clinical research on major diseases, and to state universities across the country. North Carolina, Missouri and Pennsylvania could face disproportionate losses, because of the concentration of medical research in those states.</p><figure><div><div><div><p>Based on spending in the 2024 fiscal year.</p></div></div></div></figure><p>In the 2024 fiscal year, the N.I.H. spent at least $32 billion on nearly 60,000 grants, including medical research in areas like cancer, genetics and infectious disease. Of that, $23 billion went to “direct” research costs, such as microscopes and researchers’ salaries, according to an Upshot analysis of <a href=\"https://report.nih.gov/award/index.cfm?ot=&amp;fy=2024\">N.I.H. grant data</a>.</p><p>The other $9 billion went to the institutions’ overhead, or “indirect costs,” which can include laboratory upkeep, utility bills, administrative staff and access to hazardous materials disposal, all of which research institutions say is essential to making research possible.</p><p>The <a href=\"https://grants.nih.gov/grants/guide/notice-files/NOT-OD-25-068.html\">N.I.H. proposal</a>, which has been <a href=\"https://www.nytimes.com/2025/02/11/health/nih-research-funding-lawsuit-injunction.html\">put on hold by a federal court</a>, aims to reduce funding for those indirect costs to a set 15 percent rate that the administration says would save <a href=\"https://x.com/NIH/status/1888004759396958263\">about $4 billion a year</a>. The Upshot analysis estimates that a 15 percent rate would have reduced funding for the grants that received N.I.H. support in 2024 by at least $5 billion. The White House said the savings would be reinvested in more research, but the rate cuts would open up sizable budget holes in most projects at research institutions.</p><p>It is not clear whether those organizations can fill the gaps with other funding sources or by shifting how they apply for grants. Instead, many officials at universities and hospitals have said that they may have to pull back on medical or scientific research.</p><p>“It’s not an overstatement to say that a slash this drastic in total research funding slows research,” said Heather Pierce, senior director for science policy at the Association of American Medical Colleges, which has <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.mad.280609/gov.uscourts.mad.280609.1.0.pdf\">sued along with other education and hospital associations</a> to block the policy. And slower scientific progress, she said, would affect anyone who depends on the development of new treatments, medical interventions and diagnostic tools.</p><p>We estimate that virtually all universities and hospitals would see fewer funds on similar projects in the future. The 10 institutions that receive the most money from N.I.H. stand to lose more than $100 million per year on average.</p><p>To understand how the change would work, let’s look at <a href=\"https://reporter.nih.gov/search/JbRgAtchAUKHOoW2X1vObQ/projects/map/project-details/10821480\">one grant for about $600,000</a> sent last year to the University of Alabama at Birmingham to study whether exercise can improve memory for people with epilepsy.</p><p>The calculation above, which we have repeated for every grant paid last year, is a bit simplified. In reality, the researchers would lose even more money than we’ve shown, because of the way indirect funding is calculated (see our methodology at the bottom of this article).</p><p>Our analysis also makes some other conservative assumptions given the policy’s uncertainty. We assume, for instance, that the new 15 percent rate is a flat rate that all grantees would receive, and not a maximum rate (a distinction left unclear in the N.I.H. guidance). We also assume that the change applies not just to institutions of higher education, but also to all kinds of grantees, including hospitals.</p><p>In a statement, the White House indicated it would reserve any savings for additional research grants. “Contrary to the hysteria, redirecting billions of allocated N.I.H. spending away from administrative bloat means there will be more money and resources available for legitimate scientific research, not less,” said Kush Desai, a White House spokesman.</p><p>The N.I.H. announcement, however, coincides with the Trump administration’s moves to cut spending across the government, and with the N.I.H.’s withholding of funding for grants — their direct and indirect costs alike — in <a href=\"https://www.nytimes.com/2025/01/31/us/trump-freeze-blocked.html\">apparent conflict</a><a href=\"https://www.nytimes.com/2025/01/28/us/politics/states-lawsuit-trump-federal-grants-pause.html\">with separate court orders</a>.</p><p>The N.I.H. <a href=\"https://grants.nih.gov/grants/guide/notice-files/NOT-OD-25-068.html\">guidance document</a> includes a number of conflicting statements and statistics the Upshot could not reconcile. The N.I.H. also declined to answer questions about the policy and about its public-facing data tracking grant spending.</p><p>The N.I.H. since 1950 has provided these overhead funds in a formulaic way, and since 1965, the government has used a rate individually calculated for each institution. Federal officials review cost summaries, floor plans and other information to determine that rate. That number can be higher for institutions in more expensive parts of the country, or for those that use more energy-intensive equipment. The proposal from the Trump administration would set aside those differences in standardizing the rate at 15 percent for every grantee.</p><p>The lists below estimate what would have happened to the 10 universities and hospitals that received the most N.I.H. grant money in the 2024 fiscal year, if the formula change had been in effect then.</p><figure><div><div><div><h3>Largest N.I.H. grant recipients among colleges, universities and medical schools</h3></div></div></div><div><div><div><table><thead data-svelte-h=\"svelte-1s18ww\"><tr></tr></thead><tbody><tr><td><div>University of California, San Francisco</div></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td><div>University of Pennsylvania</div></td></tr><tr><td></td></tr><tr><td><div>Columbia University Health Sciences</div></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr></tbody></table></div></div></div><div><div><div><p>Source: National Institutes of Health</p><p>Based on spending in the 2024 fiscal year.</p></div></div></div></figure><figure><div><div><div><h3>Largest N.I.H. grant recipients among hospitals</h3></div></div></div><div><div><div><table><thead data-svelte-h=\"svelte-1s18ww\"><tr></tr></thead><tbody><tr><td><div>Massachusetts General Hospital</div></td></tr><tr><td><div>Vanderbilt University Medical Center</div></td></tr><tr><td><div>Brigham and Women’s Hospital</div></td></tr><tr><td><div>Boston Children’s Hospital</div></td></tr><tr><td><div>University of Texas MD Anderson Cancer Center</div></td></tr><tr><td><div>Children’s Hospital of Philadelphia</div></td></tr><tr><td><div>Dana-Farber Cancer Institute</div></td></tr><tr><td><div>Cincinnati Childrens Hospital Medical Center</div></td></tr><tr><td><div>Beth Israel Deaconess Medical Center</div></td></tr><tr><td><div>Cedars-Sinai Medical Center</div></td></tr></tbody></table></div></div></div><div><div><div><p>Source: National Institutes of Health</p><p>Based on spending in the 2024 fiscal year, which extends from Oct. 1 to Sept. 30.</p></div></div></div></figure><p>If courts allow the change to move forward, some of its consequences are hard to predict.</p><p>Advocates for the policy change note that these organizations receive numerous other federal subsidies. Most universities and research hospitals are nonprofits that pay no federal taxes, for example. The N.I.H. announcement also noted that these same institutions often accept grants from charitable foundations that offer much lower overhead rates than the federal government, a signal that universities and hospitals willingly pursue research opportunities with less supplemental funding.</p><p>Because the indirect payments are based on broad formulas and not specific line items, critics say institutions may be diverting these federal dollars into unaccountable funds to pay for programs that taxpayers can’t see, such as the kinds of diversity, equity and inclusion programs targeted by the Trump administration.</p><p>“That’s how you get things like the ability of administrators to use larger overhead pools of money to build out D.E.I. bureaucracies, or to fund Ph.D. programs in the humanities,” said Jay Greene, a senior research fellow in the Center for Education Policy at the Heritage Foundation, a conservative research group. Mr. Greene was the coauthor of <a href=\"https://www.heritage.org/education/report/indirect-costs-how-taxpayers-subsidize-university-nonsense\">a 2022 article</a> urging the N.I.H. to cut or eliminate indirect grant funding. But he did not have specific examples to cite of research funds being spent in this way.</p><p>Researchers say the indirect funds have a branding problem, but are a necessary component of research.</p><p>“The term ‘indirect costs’ or the alternative term ‘overhead’ sounds dangerously close to ‘slush fund’ to some people,” said Jeremy Berg, who was the director of the National Institute of General Medical Sciences at the N.I.H. from 2003 to 2011. “There are real costs somebody has to pay for, and heating and cooling university laboratory buildings is a real cost.”</p><p>Some grant recipients already receive low overhead payments, but a large majority of them currently receive more than 15 percent, meaning they will need to make budgetary changes to absorb the loss. Among the 2024 grants that we analyzed, institutions that received more than $1 million in N.I.H. support got an average of 40 cents of indirect funding for every dollar of direct funding.</p><figure aria-label=\"graphic\"><div><div><div><h3>Distribution of overhead funding at N.I.H.-funded institutions in 2024</h3><p>As a share of direct funding</p></div></div></div><div><div><div><p>Source: National Institutes of Health</p><p>Calculated for 613 institutions that received at least $1 million in funding in fiscal year 2024. Federally negotiated rates are higher than these.</p></div></div></div></figure><p>Universities and hospitals may adjust their overall budgets to keep supporting medical research by cutting back on other things they do. Some might be able to raise money from donors to fill the shortfalls, though most universities are already raising as much philanthropic money as they can.</p><p>But many research institutions have said they would adjust by simply doing less medical research, because they would not be able to afford to do as much with less government help.</p><p>Universities and hospitals might also shift the kinds of research they do, avoiding areas that require more lab space, regulatory compliance or high-tech equipment, and focusing on types of research that will require them to provide less overhead funding themselves. That may mean disproportionate reductions in complex areas of research like genetics.</p><p>Those effects may be spread unevenly across the research landscape, as some organizations find a way to adjust, while others abandon medical research altogether.</p><p>We’ve compiled a list of institutions that received at least $1 million in N.I.H. funding in the 2024 fiscal year, along with our estimates of how much less they would have gotten under the new policy. Most of these institutions are universities or hospitals, but there are also some private companies and nonprofit research groups. Our numbers tend to be underestimates of the cuts.</p><figure><div><div><div><p>To estimate changes in funding, we relied on data from RePORT, the N.I.H.’s online <a href=\"https://report.nih.gov/award/index.cfm?ot=&amp;fy=2024\">registry</a> of grants and projects. We limited our analysis to grants listed within the 50 U.S. states, the District of Columbia or Puerto Rico. We also limited it to grants where the amount of indirect funding was known and where the combined indirect and direct funding was within five percent of the listed total funding. These filters resulted in removing many grants to private organizations such as domestic for-profits.</p><p>We calculated how much indirect funding each grant would have received under the new guidance by multiplying the listed direct funding amount by 15 percent. We then compared that number to the listed indirect funding amount for each great to estimate the impact of the policy.</p><p>There are two reasons our calculations are most likely conservative estimates of true reductions in funding. First, only a portion of the direct funding for each grant is considered to be “eligible” for the purposes of calculating indirect funding. For example, laboratory equipment and graduate student tuition reimbursements are deducted from the direct costs before applying the negotiated overhead rate, whereas our calculations assumed 100 percent of the listed direct costs would be eligible. We performed a more accurate version of our calculations for the 10 universities and 10 hospitals receiving the most N.I.H. funds by inferring their eligible direct costs from their reported negotiated rates. When we did this, we saw an additional increase in losses of about 20 percent.</p><p>Second, we applied a 15 percent rate to all grants in the database, including those with an initial indirect rate  15 percent. An <a href=\"https://jamessmurphy.com/2025/02/09/the-impact-of-an-nih-15-indirect-cost-rate/\">analysis by James Murphy</a> helped inform this approach. According to our analysis, then, some grants would actually receive more money under the new guidance. If the new rate operated more like a cap — and grants with rates currently below 15 percent did not change — the overall reductions in funding would be larger, as the reductions would no longer be offset by some small number of funding increases.</p></div></div></div></figure>","contentLength":12025,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43064637"},{"title":"The Sims Game Design Documents (1997)","url":"https://donhopkins.com/home/TheSimsDesignDocuments/","date":1739667971,"author":"krykp","guid":508,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43064273"},{"title":"Show HN: Blunderchess.net – blunder for your opponent every five moves","url":"https://blunderchess.net/","date":1739665321,"author":"eviledamame","guid":514,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43063970"},{"title":"Create a QubesOS Gaming HVM with GPU PCI passthrough (2023)","url":"https://forum.qubes-os.org/t/create-a-gaming-hvm/19000","date":1739659736,"author":"transpute","guid":609,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43063239"},{"title":"Jellyfin: The Free Software Media System","url":"https://jellyfin.org/","date":1739659159,"author":"doener","guid":480,"unread":true,"content":"<div><p>Jellyfin is Free Software, licensed under the GNU GPL. You can use it, study it, modify it, build it, and distribute it for free, as long as your changes are licensed the same way.</p></div><div><p>The project relies entirely on contributions from volunteers. Want to help out? There’s lots of ways to do so, and you don’t even have to code! See our <a href=\"https://jellyfin.org/contribute\">contribution guide</a> for more details.</p></div><div><p>The Jellyfin server and official clients are free to download, now and always. There are no costs, hidden or otherwise, to use Jellyfin, either for yourself, for your friends, or for your company. All our incidental costs are paid through donations from users like you.</p></div><div><p>Jellyfin has no tracking, phone-home, or central servers collecting your data. We believe in keeping our software open and transparent. We’re also not in the media business, so the only media you see is your own.</p></div>","contentLength":855,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43063167"},{"title":"Watt The Fox?","url":"https://h.43z.one/blog/2025-02-12/","date":1739655133,"author":"h43z","guid":507,"unread":true,"content":"<p>It's not nothing—about 1.5 Watt more.</p><p>So, with a heavy heart, I decided to disable email notifications—even though I really wanted to keep them—but eliminating the white noise was my priority.</p><p>I thought I had “fixed” the problem. Of course, I blamed Microsoft, right?</p><p>But the red sound indicator on my i3 status bar kept lighting up occasionally.<p>\n    And it turned out other websites were also triggering the white noise.</p></p><p>For instance, as soon as I clicked anywhere on <a href=\"https://x.com\" target=\"_blank\">x.com</a>, the noise started. Similarly, whenever I listened to a translation on <a href=\"https://translate.google.com\" target=\"_blank\">translate.google.com</a>, there was the noise.</p><p>So now I was really curious. What is going on here.</p><p>I started to look up how you can play audio with HTML/JavaScript.\n    There seem to be two ways: Either with the  tag or the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API\" target=\"_blank\">WebAudio API</a>.</p><p>As Outlook plays sound dynamically, I knew it must use the WebAudio API.\n    And to do anything with audio, you first have to create an .</p><pre><code>const audioCtx = new AudioContext();</code></pre><p>And already here I realized the problem. Just creating this AudioContext makes my speakers play white noise.</p><p>The MDN article is pretty clear about it.</p><pre><code>AudioContext.suspend()\nSuspends the progression of time in the audio context, temporarily halting audio hardware access and reducing CPU/battery usage in the process.\n\nAudioContext.resume()\nResumes the progression of time in an audio context that has previously</code></pre><p>Yet, most websites never bother suspending the AudioContext and create one without the immediate need for playing sound.</p><p>Chrome stops the battery/CPU waste automatically afte some time. Firefox not. It just keeps playing the whitenoise.</p><p>I understand that the websites are to blame here.</p><p>But still, Cmon Firefox, protect me from this resource theft?!</p><p>Oh and btw I suspect this also wastes my bluetooth headphones battery if they are connected?! Once I do a click on x.com the sending of white noise starts.</p><p>To address this total mess, I created an extension that automatically suspends the AudioContext while also\ntries to resume it if the websites wants to play sound.</p><p>It's not perfect as resuming takes a little bit of time and it\n  may not always resume, as there are multiple paths to starting audio. But it's good enough for me.</p><p>Some Relevant Bugzilla reports</p>\n\nMore fun stuff at <a href=\"https://h.43z.one\">h.43z.one</a>.\nUnshadow ban me at <a href=\"https://x.com/h43z\">𝕏</a>","contentLength":2276,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43062546"},{"title":"The European Vat Is Not a Discriminatory Tax Against US Exports","url":"https://taxfoundation.org/blog/trump-reciprocal-tariffs-eu-vat-discriminatory/","date":1739654434,"author":"dzogchen","guid":469,"unread":true,"content":"<p>The <a href=\"https://taxfoundation.org/research/federal-tax/trump-administration-tax-proposals/\">Trump</a> administration has once again floated the idea of “reciprocal” <a href=\"https://taxfoundation.org/research/all/federal/trump-tariffs-trade-war/\">tariffs</a> on foreign countries. While it is unclear what formula the administration will use to determine what is “reciprocal,” the intention of responding to foreign charges—real and perceived—is clear enough.</p><p>In the past, the administration has made general assertions about different  and nontariff barriers that American exporters face that should be rectified by “reciprocal” US tariffs. Trump commonly <a href=\"https://www.politico.eu/article/european-carmakers-crossfire-united-states-europe-trade-war/\">mentions</a> that the EU charges a 10 percent import  on US vehicles while the US only levies a 2.5 percent tariff on European cars coming into the US. Though one can certainly find examples of higher trade barriers abroad, the <a href=\"https://www.cato.org/commentary/tariff-myths-debunked?gad_source=1&amp;gclid=CjwKCAiAqrG9BhAVEiwAaPu5zgSuxH-XwbT7Kgb7FE6uvM7OAkMDDekbiXjFKgJwJ802UUqtLUJabhoC4ukQAvD_BwE\">overall tariff gap</a> between the US and its trading partners is <a href=\"https://www.linkedin.com/posts/fernando-mart%C3%ADn-711a5790_us-export-coverages-activity-7295353938608820224-aT4M?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAA_TE_ABEkKJ4JUzvJbx21NNIBaNIUkAoX8\">relatively minor</a>—and any increase in US tariffs will ultimately be paid by US businesses and consumers.  </p><p>However, when discussing trade with the EU specifically, White House deputy chief of staff, Stephen Miller, <a href=\"https://www.realclearpolitics.com/video/2025/02/09/miller_trump_trade_action_against_europe_will_offset_eu_regulations_and_vat_taxes_on_american_products.html\" rel=\"nofollow\">added</a> a new policy grievance to the mix: <a href=\"https://taxfoundation.org/taxedu/glossary/value-added-tax-vat/\">value-added taxes (VAT)</a>.  </p><p>“Did you know when you ship a car from the US to Europe, if they let it in at all because they have many nontariff barriers, between the VAT and duties, that car is taxed at 30%? The German car—or a European car sent the America is taxed at 2.5%—or basically 0.”</p><p>His statement assumes that a VAT discriminates against American car exports like a tariff, and conversely, that the VAT rebate provided to European car producers exporting to the US constitutes a subsidy and the car then simply faces a tariff and no VAT. (It is worth noting that both a domestic automobile and a European car sold in the US would face US state .) </p><p> may seem like a compelling political argument to justify across-the-board tariffs on the EU, it instead reflects a complete misunderstanding of what a VAT is and how it works. Worse, it misplaces the blame for a lack of US competitiveness on the European VAT instead of reevaluating the flaws of both the US federal and state tax systems.  </p><h2><strong>What is VAT and how does it work for exported goods?</strong></h2><p><a href=\"https://taxfoundation.org/taxedu/glossary/value-added-tax-vat/\">VATs</a> are border-adjusted, meaning they rebate tax on exports and impose tax on imports. Despite the appearance of subsidizing exports and punishing imports, however, a border-adjusted VAT is trade neutral. A border adjusted tax leads to currency appreciation for the imposing country, which would make it cheaper to import goods, more expensive to export goods, and thus would cancel out the apparent benefits of the tax on imports and the rebate on exports.</p><p>If there is a complaint to be made about tax policy and implications for US competitiveness in Europe, it is about uncompetitive state sales tax structures in the US system that yield what is known as “.”</p><h2><strong>What is US sales tax and how does it work for exported goods? </strong></h2><p>Unlike most countries, the <a href=\"https://taxfoundation.org/location/united-states/\">United States</a> does not impose a broad-based  at the national (federal) level, and state-level consumption taxes are designed as general sales taxes rather than value-added taxes. Whereas a VAT is imposed on the incremental increase in value of a good or service at each stage of production, a <a href=\"https://taxfoundation.org/taxedu/glossary/sales-tax/\">sales tax</a> is imposed on the total transaction price of any taxed good or service.</p><p>If a sales tax is imposed exclusively on final consumption, then VATs and sales taxes are economically identical. However, when the sales tax is applied to some intermediate transactions (“business inputs”), it results in tax pyramiding, where the tax is embedded in the price multiple times over.</p><p>Consider the following example of a 5 percent VAT and two versions of a 5 percent sales tax—one which only applies to final consumption, and one which applies to certain intermediate transactions as well.</p><h4>VATs and Ideal Sales Taxes are Economically Identical</h4><h5><em>A 5% VAT compared to a 5% ideal sales tax and a 5% sales tax with business input taxation</em></h5><p>Note that, while a VAT is imposed at every stage of the process, the net effect is to apply the rate one time to the final sales price. The tax is collected in increments (on the “value added” at each stage), but unlike with a pyramiding sales tax, it does not double tax inputs. The VAT and ideal sales tax share an identical  and, if imposed at the same rates, yield identical collections.</p><p>US sales taxes are typically destination-based, meaning that the tax is owed where the product is received or consumed. If a European resident orders from a US retailer, they do not pay US sales tax, just like a US consumer can obtain a VAT rebate on purchases of European products. Neither is a subsidy. These are simply consumption taxes falling on the consumer.</p><p>In practice, however, US sales taxes diverge sharply from the ideal. More than 40 percent of US sales tax revenue comes from intermediate transactions, which impose costs on US producers. This design flaw is not present in VATs, which do not double-tax intermediate transactions. Consequently, the sales tax imposes a penalty on domestic production that a VAT (or a better designed sales tax) would not. European VATs aren’t subsidizing anything—US states are just shooting themselves in the foot.</p><p>Crucially, this is true in domestic as well as international sales. If a state’s sales tax only applied to final consumption, it would never put in-state businesses at a disadvantage against rivals in other states, because consumers elsewhere are subject to their own state’s sales tax. A <a href=\"https://taxfoundation.org/location/maryland/\">Maryland</a> resident pays 6 percent sales tax on whatever she orders (that’s subject to Maryland’s sales tax), regardless of whether she buys from a retailer in Maryland, or <a href=\"https://taxfoundation.org/location/delaware/\">Delaware</a> (with no sales tax), or <a href=\"https://taxfoundation.org/location/louisiana/\">Louisiana</a> (with an average rate north of 10 percent). But when Maryland taxes business inputs, that imposes a cost on Maryland businesses that could be mitigated if businesses operated in lower-tax states or in states which include fewer inputs in their tax base.</p><p>The disadvantages created by the sales tax, therefore, aren’t unique to goods exported abroad. They aren’t the consequence of trade policy, but of poor tax policy. Europe’s VATs are not tariffs and are not subsidizing European exports. Instead, US states’ poorly-designed sales taxes are harming their own businesses’ competitiveness—whether they’re selling down the street, across state lines, or around the world.</p><h2><strong>What competitiveness issues remain with the US federal tax system?</strong></h2><p>Just like state sales tax systems can create a competitive disadvantage for producers, certain elements of the federal income tax system harm incentives to invest domestically. Despite progress made by the 2017 Tax Cuts and Jobs Act, the US maintains long  schedules for structures investment, now requires amortization for research and development expenses, and is phasing out  for machinery and equipment investment. The absence of full, immediate deductions for investment increases the cost of capital, and thus discourages investment and wage growth.</p><p>Rather than focus on raising tariffs, which i<a href=\"https://taxfoundation.org/testimony/tariffs-alternatives-boost-us-competitiveness/\">ncrease the cost</a> of operating in the United States and <a href=\"https://taxfoundation.org/testimony/tariffs-alternatives-boost-us-competitiveness/\">reduce total output and productivity</a>, fiscal policy reforms to improve the structure of the federal income tax system can better boost competitiveness of the US manufacturing sector.</p><p>Countries have many reasons why they apply different tariff rates to different products. In the case of the United States, some tariffs date back to the 1930s Smoot-Hawley tariff schedule, while other US trade barriers take on non-tariff forms. The Trump administration appears to be moving in a “reciprocal” policy direction despite the significant negative economic consequences for American consumers of across-the-board tariffs on goods coming into the US. However, the EU’s VAT system should not be used as a justification for retaliatory tariffs. </p><div data-id=\"1\"><h2>Stay informed on the tax policies impacting you.</h2><p>Subscribe to get insights from our trusted experts delivered straight to your inbox.</p><a href=\"https://taxfoundation.org/tax-newsletter\">Subscribe</a></div>","contentLength":7923,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43062457"},{"title":"NASA has a list of 10 rules for software development","url":"https://www.cs.otago.ac.nz/cosc345/resources/nasa-10-rules.htm","date":1739651053,"author":"vyrotek","guid":479,"unread":true,"content":"<h2>NASA has a list of 10 rules for software development</h2><p>Those rules were written from the point of view of people writing\nembedded software for extremely expensive spacecraft, where tolerating\na lot of programming pain is a good tradeoff for not losing a mission.\nI do not know why someone in that situation does not use the SPARK\nsubset of Ada, which subset was explicitly designed for verification,\nand is simply a better starting point for embedded programming than C.\n</p><p>I am criticising them from the point of view of people writing\nprogramming language processors (compilers, interpreters, editors)\nand application software.\n</p><p>We are supposed to teach critical thinking.  This is an example.\n</p><ul><li>How have Gerard J. Holzmann's and my different contexts affected\nour judgement?\n</li><li>Can you blindly follow his advice without considering \ncontext?\n</li><li>Can you blindly follow  advice without considering\nyour context?\n</li><li>Would these rules necessarily apply to a different/better\nprogramming language?  What if <a href=\"https://www.cs.otago.ac.nz/cosc345/resources/nasa-10-rules.htm#ppar\">function pointers\nwere tamed</a>?  What if the language provided opaque abstract\ndata types as Ada does?\n</li></ul><h3>1. Restrict all code to very simple control flow constructs —\ndo not use  statements,\n or  constructs,\nand direct or indirect .</h3><p>Note that  and \nare how C does exception handling, so this rule bans any use\nof exception handling.\n\n</p><p>It is true that banning recursion and jumps and loops without\nexplicit bounds means that you  your program is\ngoing to terminate.  It is also true that recursive functions\ncan be proven to terminate about as often as loops can, with\nreasonably well-understood methods.  What's more important here is\nthat “sure to terminate” does not imply\n“sure to terminate in my lifetime”:\n</p><pre>    int const N = 1000000000;\n    for (x0 = 0; x0 != N; x0++)\n    for (x1 = 0; x1 != N; x1++)\n    for (x2 = 0; x2 != N; x2++)\n    for (x3 = 0; x3 != N; x3++)\n    for (x4 = 0; x4 != N; x4++)\n    for (x5 = 0; x5 != N; x5++)\n    for (x6 = 0; x6 != N; x6++)\n    for (x7 = 0; x7 != N; x7++)\n    for (x8 = 0; x8 != N; x8++)\n    for (x9 = 0; x9 != N; x9++)\n        -- do something --;\n</pre><p>This does a bounded number of iterations.  The bound is N.\nIn this case, that's 10.  If each iteration of the loop body\ntakes 1 nsec, that's 10 seconds, or about 7.9×10\nyears.  What is the  difference between “will stop\nin 7,900,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000\nyears” and “will never stop”?\n\n</p><p>Worse still, taking a problem that is  expressed\nusing recursion and contorting it into something that manipulates an\nexplicit stack, while possible, turns clear maintainable code into\nbuggy spaghetti.  (I've done it, several times.  There's an example\non this web site.  It is  a good idea.)\n\n</p><h3>2. All loops must have a fixed upper-bound.  It must be trivially\npossible for a checking tool to prove statically that a preset\nupper-bound on the number of iterations of a loop cannot be exceeded.\nIf the loop-bound cannot be proven statically, the rule is considered\nviolated.</h3><p>This is an old idea.  As the example above shows, it is not enough\nby itself to be of any practical use.  You have to try to make the\nbounds reasonably , and you have to regard hitting an\nartificial bound as a run-time error.\n\n</p><p>By the way, note that putting depth bounds on recursive procedures\nmakes them every bit as safe as loops with fixed bounds.\n\n</p><h3>3. Do not use dynamic memory allocation after initialization.</h3><p>This is also a very old idea.  Some languages designed for embedded\nwork don't even  dynamic memory allocation.  The big\nthing, of course, is that embedded applications have a fixed amount of\nmemory to work with, are never going to get any more, and should not\ncrash because they couldn't handle another record.\n\n</p><p>Note that the rationale actually supports a much stronger rule:\ndon't even  dynamic memory allocation.  You can of\ncourse manage your own storage pool:\n</p><pre>    typedef struct Foo_Record *foo;\n    struct Foo_Record {\n\tfoo next;\n\t...\n    };\n    #define MAX_FOOS ...\n    static struct Foo_Record foo_zone[MAX_FOOS];\n    foo foo_free_list = 0;\n\n    void init_foo_free_list() {\n\tfor (int i = MAX_FOOS - 1; i &gt;= 0; i--) {\n\t    foo_zone[i].next = foo_free_list;\n\t    foo_free_list = &amp;foo_zone[i];\n\t}\n    }\n\n    foo malloc_foo() {\n\tfoo r = foo_free_list;\n\tif (r == 0) report_error();\n\tfoo_free_list = r-&gt;next;\n\treturn r;\n    }\n\n    void free_foo(foo x) {\n\tx-&gt;next = foo_free_list;\n\tfoo_free_list = x;\n    }\n</pre><p>This  satisfies the rule, but it\nviolates the  of the rule.  Simulating malloc()\nand free() this way is  than using the real\nthing, because the memory in foo_zone is permanently tied up\nfor Foo_Records, even if we don't need any of those at the\nmoment but do desperately need the memory for something else.\n\n</p><p>What you really need to do is to use a memory allocator\nwith known behaviour, and to prove that the amount of memory\nin use at any given time (data bytes + headers) is bounded\nby a known value.\n\n</p><p>Note also that SPlint can verify at compile time that\nthe errors NASA speak of do not occur.\n\n</p><p>One of the reasons given for the ban is that the performance\nof malloc() and free() is unpredictable.  Are these the only\nfunctions we use with unpredictable performance?  Is there\nanything about malloc() and free() which makes them\n unpredictable?  The existence of\nhard-real-time garbage collectors suggests not.\n\n</p><p>The rationale for this rule says that\n</p><blockquote>\nNote that the only way\nto dynamically claim memory in the absence of memory allocation from the\nheap is to use stack memory.  In the absence of recursion (Rule 1), an\nupper bound on the use of stack memory can derived statically, thus\nmaking it possible to prove that an application will always live within\nits pre-allocated memory means.\n</blockquote><p>Unfortunately, the sunny optimism shown here is unjustified.  Given\nthe ISO C standard (any version, C89, C99, or C11) it is \nto determine an upper bound on the use of stack memory.  There is not even\nany standard way to determine how much memory a compiler will use for the\nstack frame of a given function.  (There could have been.  There just isn't.)\nThere isn't even any requirement that two invocations of the same function\nwith the same arguments will use the same amount of memory.\nSuch a bound can only be calculated for a  version of a\nspecific compiler with specific options.  Here's a trivial example:\n</p><pre>void f() {\n    char a[100000];\n}\n</pre><p>How much memory will that take on the stack?  Compiled for debugging,\nit might take a full stack frame (however big that is) plus traceback\ninformation plus a million bytes for a[].  Compiled with optimisation,\nthe compiler might notice that a[] isn't used, and might even compile\ncalls to f() inline so that they generate no code and take no space.\nThat's an extreme example, but not really unfair.  If you want bounds\nyou can rely on, you had better  what your compiler does,\nand recheck every time anything about the compiler changes.\n\n</p><h3>4.  No function should be longer than what can be printed on\na single sheet of paper in a standard reference format with one line per\nstatement and one line per declaration.  Typically, this means no more\nthan about 60 lines of code per function.</h3><p>Since programmers these days typically read their code on-screen,\nnot on paper, it's not clear why the size of a sheet of paper is\nrelevant any longer.\n\n</p><p>The rule is arguably stated about the wrong thing.  The thing that\nneeds to be bounded is not the size of a function, but the size of a\nchunk that a programmer needs to read and comprehend.\n\n</p><p>There are also question marks about how to interpret this if you\nare using a sensible language (like Algol 60, Simula 67, Algol 68,\nPascal, Modula2, Ada, Lisp, functional languages like ML, O'CAML,\nF#, Clean, Haskell, or Fortran) that allows nested procedures.\nSuppose you have a folding editor that presents a procedure to\nyou like this:\n</p><pre>function Text_To_Floating(S: string, E: integer): Double;\n   � variables �\n   � procedure Mul(Carry: integer) �\n   � function Evaluate: Double �\n\n   Base, Sign, Max, Min, Point, Power := 10, 0, 0, 1, 0, 0;\n   for N := 1 to S.length do begin\n       C := S[N];\n       if C = '.' then begin\n          Point := -1\n       end else\n       if C = '_' then begin\n          Base := Round(Evaluate);\n          Max, Min, Power := 0, 1, 0\n       end else\n       if Char ≠ ' ' then begin\n          Q := ord(C) - ord('0');\n          if Q &gt; 9 then Q := ord(C) - ord('A') + 10\n          Power := Point + Point\n          Mul(Q)\n       end\n    end;\n    Power := Power + Exp;\n    Value := Evaluate;\n    if Sign &lt; 0 then Value := -Value;\nend;\n</pre><p>which would be much bigger if the declarations\nwere expanded out instead of being hidden behind �folds�.\nWhich size do we count?  The folded size or the unfolded size?\n</p><p>I was using a folding editor called Apprentice on the Classic Mac\nback in the 1980s.  It was written by Peter McInerny and was lightning\nfast.\n\n</p><h3>5.  The  of the code should average to a minimum of\ntwo assertions per function.</h3><p>Assertions are wonderful documentation and the very best debugging tool\nI know of.  I have never seen any real code that had too many assertions.\n\n</p><p>The example here is one of the ugliest pieces of code I've seen in a while.\n</p><pre>if (!c_assert(p &gt;= 0) == true) {\n    return ERROR;\n}\n</pre><p>It should, of course, just be\n</p><pre>if (!c_assert(p &gt;= 0)) {\n    return ERROR;\n}\n</pre><p>Better still, it should be something like\n</p><pre>#ifdef NDEBUG\n#define check(e, c) (void)0\n#else\n#define check(e, c) if (!(c)) return bugout(c), (e)\n#ifdef NDEBUG_LOG\n#define bugout(c) (void)0\n#else\n#define bugout(c) \\\n    fprintf(stderr, \"%s:%d: assertion '%s' failed.\\n\", \\\n    __FILE__, __LINE__, #s)\n#endif\n#endif\n</pre><p>Ahem.  The more interesting part is the required density.\nI just checked an open source project from a large telecoms\ncompany, and 23 out of 704 files (not functions) contained\nat least one assertion.  I just checked my own Smalltalk\nsystem and one SLOC out of every 43 was an assertion, but\nthe average Smalltalk “function” is only a few\nlines.  If the biggest function allowed is 60 lines, then\nlet's suppose the average function is about 36 lines, so\nthis rule requires 1 assertion per 18 lines.\n</p><p>Assertions are good, but what they are especially good\nfor is expressing the requirements on data that come\nfrom outside the function.  I suggest then that\n</p><ul><li>Every argument whose validity is not guaranteed by\nits typed should have an assertion to check it.\n</li><li>Every datum that is obtained from an external\nsource (file, data base, message) whose validity is\nnot guaranteed by its type should have an assertion\nto check it.\n</li></ul><p>The NASA 10 rules are written for embedded systems, where\nreading stuff from sensors is fairly common.\n\n</p><h3>6.  Data objects must be declared at the smallest possible level of\nscope.</h3><p>This is excellent advice, but why limit it to data objects?\nOh yeah, the rules were written for crippled languages where you\n declare functions in the right place.\n\n</p><p>People using Ada, Pascal (Delphi), JavaScript, or functional\nlanguages should also declare types and functions as locally as\npossible.\n\n</p><h3>7.  The return value of non-void functions must be checked by each\ncalling function, and the validity of parameters must be checked inside\neach function.</h3><p>This again is mainly about C, or any other language that indicates\nfailure by returning special values.  “Standard libraries\nfamously violate this rule”?  No, the  library does.\n\n</p><p>You have to be reasonable about this: it simply isn't practical\nto check  aspect of validity for \nargument.  Take the C function\n</p><pre>void *bsearch(\n    void const *key  /* what we are looking for */,\n    void const *base /* points to an array of things like that */,\n    size_t      n    /* how many elements base has */,\n    size_t      size /* the common size of key and base's elements */\n    int (*      cmp)(void const *, void const *)\n);\n</pre><p>This does a binary search in an array.  We must have key≠0,\nbase≠0, size≠0, cmp≠0, cmp(key,key)=0, and for all\n1&lt;i&lt;n,\n</p><pre>cmp((char*)base+size*(i-1), (char*)base+size*i) &lt;= 0\n</pre><p>Checking the validity in full would mean checking\nthat [key..key+size) is a range of readable addresses,\n[base..base+size*n) is a range of readable addresses,\nand doing n calls to cmp.  But the whole point of binary\nsearch is to do O(log(n)) calls to cmp.\n\n</p><p>The fundamental rules here are\n</p><ul><li>Don't let run-time errors go un-noticed, and\n</li><li>any check is safer than no check.\n</li></ul><h3>8. The use of the preprocessor must be limited to the inclusion of\nheader files and simple macro definitions.  Token pasting, variable\nargument lists (ellipses), and recursive macro calls are not allowed.</h3><p>Recursive macro calls don't really work in C, so no quarrel there.\nVariable argument lists were introduced into macros in\nC99 so that you could write code like\n</p><pre>#define err_printf(level, ...) \\\n    if (debug_level &gt;= level) fprintf(stderr, __VA_ARGS__)\n...\n    err_printf(HIGH, \"About to frob %d\\n\", control_index);\n</pre><p>This is a  thing; conditional tracing like this is a\npowerful debugging aid.  It should be , not banned.\n\n</p><p>The rule goes on to ban macros that expand into things that are\nnot complete syntactic units.  This would, for example, prohibit\nsimulating try-catch blocks with macros.  (Fair enough, an earlier rule\nbanned exception handling anyway.)  Consider this code fragment, from\nan actual program.\n</p><pre>    row_flag = border;     \n    if (row_flag) printf(\"\\\\hline\");\n    for_each_element_child(e0, i, j, e1)\n        printf(row_flag ? \"\\\\\\\\\\n\" : \"\\n\");\n        row_flag = true;  \n        col_flag = false;\n        for_each_element_child(e1, k, l, e2)\n            if (col_flag) printf(\" &amp; \");\n            col_flag = true;\n            walk_paragraph(\"\", e2, \"\");\n        end_each_element_child\n    end_each_element_child\n    if (border) printf(\"\\\\\\\\\\\\hline\");\n    printf(\"\\n\\\\end{tabular}\\n\");\n</pre><p>It's part of a program converting slides written in something like HTML\ninto another notation for formatting.  The \n…  loops walk over a tree.  Using\nthese macros means that the programmer has no need to know and no reason to\ncare how the tree is represented and how the loop actually works.\nYou can easily see that  must have at\nleast one unmatched { and  must have at least one\nunmatched }.  That's the kind of macro that's banned by requiring\ncomplete syntactic units.  Yet the readability and maintainability of\nthe code is  improved by these macros.\n\n</p><p>One thing the rule covers, but does not at the beginning stress, is\n“no  macro processing”.  That is,\nno #if.  The argument against it is, I'm afraid, questionable.  If there\nare 10 conditions, there are 2 combinations to test,\nwhether they are expressed as compile-time conditionals or run-time\nconditionals.\n\n</p><p>In particular, the rule against conditional macro processing\nwould prevent you defining your own <a href=\"https://www.cs.otago.ac.nz/cosc345/resources/nasa-10-rules.htm#check\">assertion macros</a>.\nIt is not obvious that that's a good idea.\n\n</p><h3>9.  The use of pointers should be restricted.  Specifically, no more\nthan one level of dereferencing is allowed.  Pointer dereference\noperations may not be hidden in macro definitions or inside typedef\ndeclarations.  Function pointers are not permitted.</h3><p>Let's look at the last point first.\n\n</p><pre>double integral(double (*f)(double), double lower, double upper, int n) {\n    // Compute the integral of f from lower to upper \n    // using Simpson's rule with n+1 points.\n    double const h = (upper - lower) / n;\n    double       s;\n    double       t;\n    int          i;\n    \n    s = 0.0;\n    for (i = 0; i &lt; n; i++) s += f((lower + h/2.0) + h*i);\n    t = 0.0;\n    for (i = 1; i &lt; n; i++) t += f(lower + h*i);\n    return (f(lower) + f(upper) + s*4.0 + t*2.0) * (h/6.0);\n}\n</pre><p>This kind of code has been important in numerical calculations since\nthe very earliest days.  Pascal could do it.  Algol 60 could do it.\nIn the 1950s, Fortran could do it.  And NASA would ban it, because in\nC,  is a function pointer.\n\n</p><p>Now it's important to write functions like this once and only once.\nFor example, the code has at least one error.  The comment says n+1\npoints, but the function is actually evaluated at 2n+1 points.  If we\nneed to bound the number of calls to f in order to meet a deadline,\nhaving that number off by a factor of two will not help.\n</p><p>It's nice to have just one place to fix.\nPerhaps I should not have copied that code from a well-known source (:-).\nCertainly I should not have more than one copy!\n\n</p><p>What can we do if we're not allowed to use function pointers?\nSuppose there are four functions foo, bar, ugh, and zoo that we need\nto integrate.  Now we can write\n</p><pre>enum Fun {FOO, BAR, UGH, ZOO};\n\ndouble call(enum Fun which, double what) {\n    switch (which) {\n        case FOO: return foo(what);\n        case BAR: return bar(what);\n        case UGH: return ugh(what);\n        case ZOO: return zoo(what);\n    }\n}\n\ndouble integral(enum Fun which, double lower, double upper, int n) {\n    // Compute the integral of a function from lower to upper \n    // using Simpson's rule with n+1 points.\n    double const h = (upper - lower) / n;\n    double       s;\n    double       t;\n    int          i;\n    \n    s = 0.0;\n    for (i = 0; i &lt; n; i++) s += call(which, (lower + h/2.0) + h*i);\n    t = 0.0;\n    for (i = 1; i &lt; n; i++) t += call(which, lower + h*i);\n    return (call(which, lower) + call(which, upper) + s*4.0 + t*2.0) * (h/6.0);\n}\n</pre><p>Has obeying NASA's rule made the code more reliable?  No, it has made\nthe code  to understand,  maintainable, and\n that it wasn't before.  Here's a call\nillustrating the mistake:\n</p><pre>x = integral(4, 0.0, 1.0, 10);</pre><p>I have checked this with two C compilers and a static checker at their\nhighest settings, and they are completely silent about this.\n\n</p><p>So there are legitimate uses for function pointers, and simulating\nthem makes programs , not better.\n\n</p><p>Now  in Fortran,\nAlgol 60, or Pascal.  Those languages had procedure \nbut not procedure . You could pass a subprogram name as\na parameter, and such a parameter could be passed on, but you could not\nstore them in variables.  You could have a  of C which\nallowed function pointer parameters, but made all function pointer\nvariables read-only.  That would give you a statically checkable subset\nof C that allowed integral().\n\n</p><p>The other use of function pointers is simulating object-orientation.\nImagine for example\n</p><pre>struct Channel {\n    void (*send)(struct Channel *, Message const *);\n    bool (*recv)(struct Channel *, Message *);\n    ...\n};\ninline void send(struct Channel *c, Message const *m) {\n    c-&gt;send(c, m);\n}\ninline bool recv(struct Channel *c, Message *m) {\n    return c-&gt;recv(c, m);\n}\n</pre><p>This lets us use a common interface for sending and receiving\nmessages on different kinds of channels.  This approach has been\nused extensively in operating systems (at least as far back as\nthe Burroughs MCP in the 1960s) to decouple the code that uses\na device from the actual device driver.     I would expect any\nprogram that controls more than one hardware device to do something\nlike this.  It's one of our key tools for controlling complexity.\n</p><p>Again, we can simulate this, but it makes adding a new kind of\nchannel harder than it should be, and the code is \nwhen we do it, not better.\n\n</p><p>The rule against more than one level of dereferencing is also\nan assault on good programming.  One of the key ideas that was\ndeveloped in the 1960s is the idea of ;\nthe idea that it should be possible for one module to define a\ndata type and operations on it and another module to use instances\nof that data type and its operations <em>without having to know\nanything about what the data type is</em>.\n</p><p>One of the things I detest about Java is that it spits in the\nface of the people who worked out that idea.  Yes, Java (now) has\ngeneric type parameters, and that's good, but you cannot use a\n type without knowing what that type is.\n\n</p><p>Suppose I have a module that offers operations\n</p><ul></ul><p>And suppose that I have two interfaces in mind.  One of them\nuses integers as tokens.\n</p><pre>// stasher.h, version 1.\ntypedef int token;\nextern token stash(item);\nextern item  recall(token);\nextern void  delete(token);\n</pre><p>Another uses pointers as tokens.\n</p><pre>// stasher.h, version 2.\ntypedef struct Hidden *token;\nextern  token stash(item);\nextern  item  recall(token);\nextern  void  delete(token);\n</pre><pre>void snoo(token *ans, item x, item y) {\n    if (better(x, y)) {\n\t*ans = stash(x);\n    } else {\n\t*ans = stash(y);\n    }\n}\n</pre><p>By the NASA rule, the function snoo() would not be accepted or rejected on\nits own merits.  With stasher.h, version 1, it would be accepted.\nWith stasher.h, version 2, it would be rejected.\n\n</p><p>One reason to prefer version 2 to version 1 is that version 2 gets\nmore use out of type checking.  There are ever so many ways to get an\nint in C.  Ask yourself if it ever makes sense to do\n</p><pre>token t1 = stash(x);\ntoken t2 = stash(y);\ndelete(t1*t2);\n</pre><p>I really do not like the idea of banning abstract data types.\n\n</p><h3>10.  All code must be compiled, from the first day of development,\nwith all compiler warnings enabled at the compiler’s\nmost pedantic setting.  All code must compile with these setting without\nany warnings.  All code must be checked daily with at least one, but\npreferably more than one, state-of-the-art static source code analyzer\nand should pass the analyses with zero warnings.</h3><p>This one is good advice.  Rule 9 is really about making your code\nworse in order to get more benefit from limited static checkers.  (Since\nC has no standard way to construct new functions at run time, the set of\nfunctions that a particular function pointer  point to can\nbe determined by a fixed-point data flow analysis, at least for most\nprograms.)  So is rule 1.  \n\n\n\n</p>","contentLength":21484,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43061977"},{"title":"Perplexity Deep Research","url":"https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research","date":1739650059,"author":"vinni2","guid":506,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43061827"},{"title":"My Life in Weeks","url":"https://weeks.ginatrapani.org/","date":1739648069,"author":"bookofjoe","guid":468,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43061498"},{"title":"New SF public health chief was part of McKinsey opioid-marketing operation","url":"https://sfstandard.com/2025/02/14/san-francisco-department-public-health-daniel-tsai-opioids-mckinsey/","date":1739647936,"author":"iancmceachern","guid":467,"unread":true,"content":"<div><p>Dr. David Juurlink, an expert on tramadol, called the drug a “minor player in the opioid crisis, but a player nevertheless.”</p></div><div><p>He added, “To the extent that McKinsey helped advertise it as a notionally safer opioid, I think they did a disservice in doing so. The main reason I say tramadol is a minor player is because it wasn’t prescribed like candy, like OxyContin was.”</p></div><div><p>McKinsey’s method of targeting high-volume prescribers was part of its playbook to juice opioid sales, despite mounting evidence that the drugs could be highly addictive. In other emails uncovered in the McKinsey documents, employees wrote excitedly about finding doctors who were willing to write opioid prescriptions. <a href=\"https://www.industrydocuments.ucsf.edu/opioids/docs/#id=hlmn0255\">In one instance</a> in 2015, a McKinsey partner wrote, “The challenge which we need to start working on is to identify the sweet spot of docs so we can do targeting. … Fun be[g]ins on Monday!”</p></div><div><p>San Francisco’s fentanyl crisis is part of a broader trend of opioid overdoses <a href=\"https://www.cdc.gov/overdose-prevention/about/understanding-the-opioid-overdose-epidemic.html\">that traces back to the 1990s,</a> when prescription opioids became popular among doctors for chronic pain management. Companies such as Purdue Pharma, which manufactured OxyContin, brought in consulting firms like McKinsey to help with sales strategies. After a Department of Justice probe and settlement, McKinsey <a href=\"https://www.justice.gov/usao-ma/media/1380236/dl\">acknowledged that it knew</a> the dangers of OxyContin but continued working with Purdue Pharma — even after several of the drugmaker’s executives pled guilty in 2007 to misrepresenting addiction risks.&nbsp;</p></div><div><p>McKinsey, along with a slew of drug companies and pharmacies, agreed to pay billions in settlement funds over their roles in fueling opioid addiction. California received <a href=\"https://oag.ca.gov/news/press-releases/attorney-general-becerra-announces-573-million-nationwide-settlement-mckinsey\">roughly $60 million</a> from the 2021 McKinsey settlement. San Francisco, <a href=\"https://www.sfcityattorney.org/2023/05/17/san-francisco-city-attorney-announces-230-million-settlement-with-walgreens-after-victory-in-opioid-litigation/\">under the 2023 settlement</a> of an opioid-related lawsuit, was expected to receive about $230 million from Walgreens.</p></div><div><p>In both instances, the funds were slated to be used for opioid recovery efforts.</p></div><div><p>In 2019, McKinsey said it would no longer work on opioid-related businesses.&nbsp;Last year, McKinsey formally apologized for its Purdue Pharma work, <a href=\"https://www.mckinsey.com/about-us/opioidfacts\">saying it was “deeply sorry”</a> for its role in selling OxyContin. “This terrible public health crisis and our past work for opioid manufacturers will always be a source of profound regret for our firm,” the company said in a statement.</p></div><div><p>At the San Francisco Department of Public Health, Tsai replaced Dr. Grant Colfax, who took the reins in 2019 and led the city through the pandemic <a href=\"https://sfstandard.com/2025/01/16/grant-colfax-resign-san-francisco-public-health/\">before stepping down in January</a>. The role paid $546,133 in 2024, one of the highest city salaries.&nbsp;&nbsp;</p></div><div><p>On Monday, the San Francisco Health Commission unanimously nominated Tsai as director of Public Heath. Dr. Laurie Green, president of the commission, said the governing body conducted a “multi-hour” interview.</p></div>","contentLength":2776,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43061482"},{"title":"Schemesh: Fusion between Unix shell and Lisp REPL","url":"https://github.com/cosmos72/schemesh","date":1739646038,"author":"cosmos0072","guid":505,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43061183"},{"title":"Multiple Russian Threat Actors Targeting Microsoft Device Code Authentication","url":"https://www.volexity.com/blog/2025/02/13/multiple-russian-threat-actors-targeting-microsoft-device-code-authentication/","date":1739645979,"author":"ChrisArchitect","guid":466,"unread":true,"content":"<h2>Multiple Russian Threat Actors Targeting Microsoft Device Code Authentication</h2><p>by Charlie Gardner, Steven Adair, Tom Lancaster</p><ul><li><em>Volexity has observed multiple Russian threat actors conducting social-engineering and spear-phishing campaigns targeting organizations with the ultimate goal of compromising Microsoft 365 accounts via Device Code Authentication phishing.</em></li><li><em>Device Code Authentication phishing follows an atypical workflow to that expected by users, meaning users may not recognize it as phishing.</em></li><li><em>Recent campaigns observed have been politically themed, particularly around the new administration in the United States and the changes this might mean for nations around the world.</em></li></ul><p>Starting in mid-January 2025, Volexity identified several social-engineering and spear-phishing campaigns by Russian threat actors aimed at compromising Microsoft 365 (M365) accounts. These attack campaigns were highly targeted and carried out in a variety of ways. The majority of these attacks originated via spear-phishing emails with different themes. In one case, the eventual breach began with highly tailored outreach via Signal.</p><p>Through its investigations, Volexity discovered that Russian threat actors were impersonating a variety of individuals in order to socially engineer targets, including impersonating individuals from the following:</p><ul><li>United States Department of State</li><li>Ukrainian Ministry of Defence</li><li>European Union Parliament</li><li>Prominent research institutions</li></ul><p>Communications carried a variety of different themes and messages, but they all ultimately resulted in the attacker inviting the targeted user to one of the following:</p><ul><li>Microsoft Teams Meeting / Video Conference</li><li>Access to applications and data as an external M365 user</li><li>Join a chatroom on a secure chat application</li></ul><p>When these attacks were successful and the attackers gained access to accounts, the post-exploitation phase often had unique characteristics in each case:</p><ul><li>The way the attackers accessed material from compromised organizations (scripts versus native applications)</li><li>The infrastructure used to access stolen accounts</li></ul><p>Despite the differences, Volexity found the attacks had one thing in common: they were all <strong>Device Code Authentication</strong> attacks. While this attack method is not new, it is one that is definitely lesser known and not commonly leveraged by nation-state actors. Details on the social-engineering and spear-phishing campaigns, along with how Device Code Authentication attacks work, will be covered further in this blog post. What Volexity has observed is that this method has been more effective at successfully compromising accounts than most other targeted spear-phishing campaigns.</p><p>Volexity assesses with high confidence that the series of attacks described in this blog post are from Russia-based threat actors. At this time, Volexity is tracking this activity under three different threat actors and assesses with medium confidence that at least one of them is  (overlapping with DarkHalo, APT29, Midnight Blizzard, CozyDuke). Volexity is tracking the remaining activity under  and . It is possible that all the activity described in this blog post is a single threat actor, but despite the similar targeting, timing, and attack method, other observed components of the operations are different enough to be tracked separately, for now.</p><h3>From Secure Chat to Insecure Authentication</h3><p>The discovery of this threat activity started toward the end of January 2025, when Volexity uncovered a highly targeted attack that had successfully compromised the M365 account of one of its customers. This breach was discovered after Volexity identified suspicious sign-in activity to the account, which was followed by a rapid download of files from the user's OneDrive. All authentication and download events came from virtual private server (VPS) and Tor IP addresses, which is not the most subtle way to access an account. Volexity noted this activity was likely scripted, as the User-Agent string for later access and file downloads was the Python User-Agent string .</p><p>Volexity then performed a detailed investigation into this incident, in an effort to identify how the account was compromised. A review of login activity showed the legitimate user had logged in and approved a multi-factor authentication (MFA) request. However, subsequent access was not from the legitimate user's IP address. This caused Volexity to initially suspect a phishing attack involving an adversary-in-the-middle (AiTM) framework. As a result, Volexity reviewed emails to the user leading up the time of the authentication event. This review identified a suspicious email just moments before the login activity from an email address purporting to be from someone with the name of a high-ranking official from the Ukrainian Ministry of Defence. The email was structured to look like a meeting invite for a chatroom on the messaging application, <a href=\"https://element.io/\">Element</a>. Element is another encrypted messaging application that offers the ability for users to self-host a server with functionality that includes group video chats. The “invitation” email sent is shown below .</p><p>Microsoft <a href=\"https://learn.microsoft.com/en-us/entra/identity-platform/v2-oauth2-device-code\">describes</a> the purpose of this workflow as allowing <em>'\"users to sign in to input-constrained devices such as a smart TV, IoT device, or a printer.</em>” However, in this case, it means if an attacker can convince a user to enter a specific code into this dialogue (and log in), they are granted long-term access to the user’s account.</p><p>After working with its customer more closely, Volexity learned that the victim had been contacted on Signal by an individual purporting to be from the Ukrainian Ministry of Defence. This individual then requested the victim move off Signal to another secure chat application called Element. The attacker then had the victim join an Element server they controlled under the domain . This allowed the attacker to further communicate with the victim in real time and inform them they needed to click a link from an email to join a secure chat room. This is where the email Volexity had discovered came into play. The message was a ploy to fool the user into thinking they were being invited into a secure chat, when in reality they were giving the attacker access to their account. The generated Device Codes are only valid for 15 minutes once they are created. As a result, the real-time communication with the victim, and having them expect the \"invitation\", served to ensure the phish would succeed through timely coordination.</p><p>The diagram below s</p><p>Volexity tracks the threat actor behind this campaign as . Through research conducted on the custom domain used by UTA0304 to operate its own Element server, Volexity was able to pivot and discover additional infrastructure it believes is likely operated by the group. The table below represents the list of infrastructure that Volexity has tied to this threat actor.</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr><td width=\"246\"><code>chromeelevationservice[.]com</code></td></tr><tr></tr></tbody></table><h3>Spoofing the United States Department of State</h3><p>In early February 2025, Volexity observed multiple spear-phishing campaigns targeting users with fake Microsoft invitations purporting to be from the United States (US) Department of State. These emails were themed as invitations to join the US Department of State’s Microsoft tenant as an external user, or as invitations to a Microsoft Teams chat named “<em><strong>Measuring Influence Operations</strong>\".</em></p><p>Similar to the campaign conducted by UTA0304, these fake US Department of State emails were targeting users with a <a href=\"https://learn.microsoft.com/en-us/entra/identity-platform/v2-oauth2-device-code\">Device Code OAuth</a> phishing workflow. Each email was aimed at convincing the user to accept the invitation and enter a unique code provided in the phishing email. The link in the invitations would direct users to the Microsoft Device Code <a href=\"https://login.microsoftonline.com/common/oauth2/deviceauth\">authentication page</a>. If the user entered the code provided in the phishing email, the authentication page would subsequently authorize the threat actor to access to the user’s account. However, it is worth noting that this campaign was sent out of the blue, with no precursor or build up to the emails, so users would not be expecting these messages. Even if they were to fall for the campaign, they would have to have done it within 15 minutes of receiving the email. This dramatically decreased the likelihood that this attack would be successful.</p><p>After reviewing various parts of the attack, Volexity assesses with medium confidence that the Russian threat actor CozyLarch (aka APT29 or Midnight Blizzard) was behind these US Department of State themed spear-phishing campaigns. Additional details on each campaign are described in the sections that follow.</p><h4>Campaign 1: M365 Tenant External User Invitation</h4><p>CozyLarch sent invitations to several users, inviting them to access applications within the M365 tenant for the US Department of State. The invitation email was designed to look like a real invitation that would be sent from Microsoft, as shown below.</p><p>The redirect link takes the user to the Microsoft Device Code OAuth workflow, and it is the same URL that UTA0304 directly embedded in their phishing campaign. However, unlike UTA0304, CozyLarch opted to use the redirect URL rather than the final login URL, perhaps because it may look even more recognizable to a discerning user, given that it is hosted on the main Microsoft domain. If the user entered the code provided from the email and continued through the authentication process, the attacker was granted access to the user’s M365 account.</p><h4>Campaign 2: M365 Teams Chat Invitation</h4><p>CozyLarch launched a second campaign, in which they targeted users with a fake invitation to join a Microsoft Teams chat named “<strong><em>Measuring Influence Operations</em></strong>”. The email made it appear as though there were already 37 other members in the chat. &nbsp;A screenshot of one of the observed spear-phishing messages is shown below.</p><p>The “Sign in to Microsoft Teams” button in the email body is a hyperlink that leads to the same <a href=\"https://www.microsoft.com/devicelogin\">https://www.microsoft.com/devicelogin</a> URL observed in the other campaign. The attack flow and end goal are the same, with only a small difference in the theme of the emails.</p><p>The emails are designed to appear as though they come from Microsoft. The messages used mixed encoding in the “friendly” name that make the address difficult to discern. An example of the full “from” header used in one phishing email is given below:</p><blockquote><p><code>\\\"Mic\\udb40\\udc30\\udb40\\udc30\\udb40\\udc30\\u200br\\udb40\\udc30\\udb40\\udc30o\\udb40\\udc30\\udb40\\udc30soft Invitations on behal f of US Dep\\udb40\\udc30\\udb40\\udc30\\udb40\\udc30artme\\udb40\\udc30\\udb40\\udc30\\udb40\\udc30nt of St\\udb40\\udc30\\udb40\\udc30\\udb40\\udc30 ate \\uff1cinvites\\uff20mic\\udb40\\udc30\\udb40\\udc30\\udb40\\udc30\\u200br\\udb40\\udc30\\udb40\\udc30o\\udb40\\udc30\\udb40\\udc30soft.co m\\uff1e\\u180e\\u3000\\u180e\\u3000\\u180e \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e \\u180e\\u3000\\u180e \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e \\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e&nbsp; \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000\\u180e\\u3000 \\u180e\\u3000\\u180e\\u3000\\u180e \\u061c Cc:\\\" &lt;<a href=\"https://www.volexity.com/cdn-cgi/l/email-protection\" data-cfemail=\"64170c010d080905030a011010240309050d084a070b09\">[email&nbsp;protected]</a>&gt;</code></p></blockquote><p>The attacker attempted to make it appear as if the emails were from , and also set the  header as . However, the true address could be seen at the end of the  field; all messages were sent via Google Gmail accounts. Volexity observed the following Gmail accounts as the actual senders of the messages observed:</p><ul><li><code>kaylassammers@gmail[.]com</code></li><li><code>kendisggibson@gmail[.]com</code></li><li><code>leslytthomson@gmail[.]com</code></li></ul><p>These addresses are believed to be controlled by CozyLarch and can be used to reliably detect phishing emails that may have been sent.</p><h4>Using Wireless Proxy Networks for Email Distribution</h4><p>Volexity also noted that the sending IP address associated with each spear-phishing email was recorded in the headers. Looking at the  header in the messages, it became apparent that the attacker was using Proxy IP addresses based in the US to send messages. Volexity observed nearly a dozen IP addresses belonging to mobile networks in the US (AT&amp;T and Verizon Wireless).</p><h3>European Parliament and Donald Trump</h3><p>Starting in late January through to the publication of this blog (February 13, 2025), Volexity has observed another campaign by a Russian threat actor it tracks as  targeting numerous organizations. UTA0307 created a fake email under the identity of a member of the European Parliament who is on the Committee on Foreign Affairs. The threat actor reached out to numerous individuals with personalized emails requesting a Microsoft Teams meeting to discuss Donald Trump and his impact on relations between the US and the European Union. Volexity also observed a smaller set of campaigns centered on discussing China's foreign policy and China-European Union relations.</p><p>The email subject lines used in these various campaigns are listed below:</p><ul><li><em>Discussion on Eastern Europe and the Caucasus</em></li><li><em>Discussion about Donald Trump's new term</em></li><li><em>Discussion about Trump &amp; US relations with Europe</em></li><li><em>Collaboration on China and East Asia Research</em></li></ul><p>The image below shows an example spear phish that was sent by UTA0307.</p><p>None of the initial emails contained any malicious content or links at the onset. The threat actor was leveraging a tactic that has become commonplace for numerous nation-state actors, where they wait until a conversation has started prior to sending anything malicious. This serves the purpose of knowing they have an engaged target, and that the target's guard is potentially down. In the specific cases of Device Code Authentication phishing, it is especially important to have a responsive target, as the threat actor has only 15 minutes to convince the target to enter the code that has been generated.</p><h4>A Different Device Code OAuth Phishing Technique</h4><p>Volexity actually discovered the operations of UTA0307 following a successful compromise. Similar to the initial discovery of UTA0304, Volexity worked backwards from detecting a breach to identifying the above spear-phishing emails. In this case, the victim had engaged from the initial email and had several messages back and forth with UTA0307 regarding a meeting being set up. They agreed to join a Microsoft Teams meeting, and a fake invitation email was sent. However, this time the link in the email did not go to Microsoft. The target received an email with the subject \"\", and the body of the email, shown below, was designed to look like a real invitation.</p><p>The “Join the meeting now” hyperlink, however, linked to a website controlled by UTA0307 (). This page in turn was set up to automatically generate a new Microsoft Device Code each time it was visited. The website was designed to appear as an official Microsoft interstitial page before the user can join a Microsoft Teams meeting. The message that appears on the landing page (shown below) claims that the victim needs to pass a security check by copying a code and entering it on a subsequent page</p><p>When the user clicks the “Next” button, a new tab is opened with the real Microsoft Device Code Authentication interface that requests an authentication code. If the victim enters the code supplied by the phishing page, they grant UTA0307 access to their M365 account. Interestingly, in the background of the initial phishing page, Volexity noted that the website would continuously poll the domain . It appears this domain was set up to monitor successful Device Code Authentication and, if detected, would redirect the user to a real Microsoft Teams meeting URL in an effort to make the activity appear legitimate.</p><p>The threat actor never joined this Microsoft Teams meeting. However, UTA0307 did add authorization for an authentication application under their control to enable multi-factor authentication when logging into the compromised account. Volexity assesses with medium confidence that this was a requirement of logging into the account, even with the stolen authentication token.</p><p>One benefit of this attack workflow versus other previously observed DeviceID phishing workflows is that, when a DeviceID code is generated, it is only valid for 15 minutes. Having an interstitial page that automatically generates new codes means UTA0307 does not have to worry about their phishing content expiring.</p><h4>UTA0307 Post-compromise Activities, Targeting and Attribution</h4><p>Volexity observed UTA0307 exfiltrating documents from a compromised M365 account that would be of interest to a Russian threat actor. This was determined based on identification of <a href=\"https://learn.microsoft.com/en-us/purview/audit-log-activities\">FileDownloaded operations</a> observed in M365 audit log data. Given this information about the threat actor’s objectives, their targeting, and their use of a highly similar technique to that used in recent days and weeks by CozyLarch and UTA0304, Volexity assesses with medium confidence that UTA0307 is also a Russian threat actor.</p><p>However, the exact implementation of the DeviceID OAuth phishing technique used in this activity differs slightly from those previously documented by Volexity, which provides some evidence that this activity may have been conducted by a separate threat actor. For example, while the previously observed phishing campaigns saw the attacker use the client ID for Microsoft Office when handling Device Code Authentication, this activity instead used the client ID for Microsoft Teams, as shown below (note that Microsoft uses  and  interchangeably in their logs when referring to the ID for an application):</p><blockquote><p><code>\"appDisplayName\": \"Microsoft Teams\",</code></p><p><code>\"appId\": \"1fec8e78-bce4-4aaf-ab1b-5451cc387264\",</code></p></blockquote><p>Another difference between this and the UTA0304 campaign is that in this case, all subsequent access to the compromised account occurred via Mullad VPN exit nodes (versus the other observed VPS and Tor IP addresses). Based on these two factors, Volexity has chosen to track this activity under the UTA0307 alias, rather than CozyLarch or UTA0304.</p><h3>Detecting Device Code Authentication</h3><p>Volexity identified a way to reliably detect this attack through monitoring and analysis of Microsoft Entra ID sign-in logs. When a user enters a device code and subsequently authenticates, it results in a login to the application associated with the generated code. This can be a common application like Microsoft Office that is frequently accessed by users and would not be a reliable indicator. However, the good news is that Device Code Authentications result in the  field being set with the value .</p><p>The line below is what will appear in the JSON data in the Entra ID sign-in logs when a Device Code Authentication occurs:</p><blockquote><p><code>“authenticationProtocol\": \"deviceCode\",</code></p></blockquote><p>Volexity further noted that as authenticated sessions refresh and are kept alive, subsequent sign-ins that initially occurred via a  often do not have anything set for  but they contain the following entry:</p><blockquote><p><code> “originalTransferMethod\": \"deviceCodeFlow\",</code></p></blockquote><p>These values can be searched and filtered on in the Entra Admin center by adding filters for \"Authentications Protocol\" and \"Original Transfer Method\". The latter can be filtered in both  and  sign-ins. The frequency and legitimacy of these values occurring in the sign-in logs for a particular organization may vary, as this is a legitimate Microsoft feature. An organization can evaluate their risk and usage of these workflows, and potentially use this information as a proactive detection mechanism.</p><p>If an organization has the ability to monitor URLs that are being accessed by users or sent in email, there are additional detection opportunities to discover Device Code Authentication attacks. The following official URLs can be monitored for as related to Microsoft Device Code Authentication:</p><ul><li><code>https://login.microsoftonline.com/common/oauth2/deviceauth</code></li><li><code>https://www.microsoft.com/devicelogin</code></li><li><code>https://aka.ms/devicelogin</code></li></ul><p>Organizations can monitor for access to these URLs or for their presence in various communication methods, such as email. Attackers can find other means to redirect users to these URLs, but one of the main advantages of using the list above in phishing attacks is that the URL displayed is hosted on a legitimate Microsoft domain.</p><h3>Preventing Device Code Authentication</h3><p>Volexity believes the most effective way to prevent this potential attack vector is through conditional access policies on an organization's M365 tenant. It is possible for organizations to create a conditional access policy that disallows device code authentication altogether. It is fairly trivial to set up, and Microsoft provides <a href=\"https://learn.microsoft.com/en-us/entra/identity/conditional-access/policy-block-authentication-flows\">online guidance on exactly how to do this</a>. Based on Volexity's own testing, blocking the \"Device code flow\" from \"Authentications flows\" prevents this attack from working.&nbsp; The image below shows what a conditional access policy would look like once it's set up and in place to block this authentication flow.</p><p>Prior to implementing such a policy, organizations should evaluate the use of Device Code Authentication in their environment. This feature is used legitimately, and blocking it could have a negative impact. Volexity's review of its own customers identified several instances of legitimate access to resources via these means. However, at the majority of Volexity's customers, there was either no recent Device Code Authentication activity or there was only activity tied to the attacks described in this blog post.</p><p>Volexity continues to track multiple spear-phishing campaigns targeting Device Code Authentication. This blog post serves to cover a few of the larger and unique campaigns observed. Volexity has observed other similar spear-phishing campaigns in recent weeks targeting Device Code Authentication that it believes are the work of Russian threat actors. Further, it should be noted that it is possible this is the work of a single threat actor running multiple, different campaigns. However, at this time, Volexity believes this activity is sufficiently different enough to warrant tracking this activity under two different unknown threat actors and one it believes is likely CozyLarch.</p><p>While Device Code Authentication attacks are not new, they appear to have been rarely leveraged by nation-state threat actors . Volexity's visibility into targeted attacks indicates this particular method has been far more effective than the combined effort of years of other social-engineering and spear-phishing attacks conducted by the same (or similar) threat actors. It appears that these Russian threat actors have made a concerted effort to launch several campaigns against organizations with a goal of simultaneously abusing this method before the targets catch on and implement countermeasures.</p><p>The detection mechanisms and countermeasures to these attacks have been available for years. However, Volexity believes they are seldom implemented and that most organizations are not even aware of this authentication flow, let alone the means to detect its misuse. These attacks serve as a reminder that threat actors will constantly look for ways to abuse legitimate features, and organizations must continually evaluate and implement methods to detect and prevent such attacks.</p><p>These attacks also serve as a good opportunity to engage with users and remind them to be on the lookout for anything out of the ordinary when it comes to accessing resources when they are asked for login credentials or authorization grants. This phishing workflow has proven useful for an attacker, as many traditional sources of evidence and detection, both for a user and network defenders, are not present. For example:</p><ol><li>There is no “malicious” link or attachment. The only link is to the provider’s infrastructure (in this case, Microsoft). This means users cannot easily identify the link as being suspicious, and automated solutions detecting malicious emails will likely fail to do so for the same reason.</li><li>Users are generally less aware of attacks that leverage legitimate services, and may be even less aware when it comes to those that involve entering a device code rather than their username or password.</li><li>After successful authentication, the logs will show the authenticating application as a legitimate or benign application, reducing signal that can be keyed off of in sign-in logs by detection teams.</li></ol><p>These are items that organizations should look to further train users on and implement technical countermeasures against where possible.</p><p><a href=\"https://github.com/volexity/threat-intel/blob/main/2025/2025-02-13%20Device%20Code%20Phishing/iocs.csv\">Volexity GitHub</a>.</p><p><em>If you believe you have been targeted by a similar attack and want to share details with Volexity for informational purposes, additional investigation, or incident response, please <a href=\"https://www.volexity.com/company/contact/\">contact us</a>.</em></p>","contentLength":25345,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43061173"},{"title":"PAROL6: 3D-printed desktop robotic arm","url":"https://source-robotics.github.io/PAROL-docs/","date":1739644009,"author":"bo0tzz","guid":504,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43060818"},{"title":"Basketball has evolved into a game of calculated decision-making","url":"https://nabraj.com/blog/basketball-solved-sport/","date":1739643670,"author":"nabaraz","guid":503,"unread":true,"content":"<p>Basketball has evolved from a game of unpredictability into a game of calculated decision-making with the use of data and analytics. From a game of points, assists, and rebounds, it has progressed into using thousands of data points to optimize every element of the game.</p><p>All decisions are made based on numbers not intuition. Long-range shooting and layups are preferred over mid-range shooting. Players are no longer do-it-alls; they are now given specialized roles.</p><p>In the last decade, long-range shooting has gone from a secondary option to a primary choice for building offense. Recently, teams have realized three-pointers have higher point value despite their lower scoring percentage. This has led to a revolution in structuring an offense around taking long-range shots. The Golden State Warriors, led by Stephen Curry, probably jump-started this trend with 34 three-pointer attempts per game in the 2018-19 season, twice as much from five years ago. Celtics, this season, have averaged almost 50 three-pointers attempt this season (2024-25 season).</p><p>In the past, the team built its roster around a big name like Shaq. Most of the offense were from the center. This has now changed, with the primary strategy being to stretch the opposition and take long-range shots.</p><p>The 3-and-D model refers to a player, usually a wing player, who is just above average at three-pointers and plays competent defense.  Forget about positions; just get a guy who can do some 3s and Ds.</p><p>Danny Green is probably the father of this model, with his 40% career three-point field goal percentage and he also made into all-defensive team.</p><p>In  recent years, every team has had at least one 3-and-D model player on the roster.</p><p>Gone are the days of an all-around player. There is no longer a need for a player who does everything. Look at players like Kobe Bryant and Lebron James (early career); they not only scored but guarded defense, caught rebounds and played the role of playmakers.</p><p>Now, it’s all about creating lineups with specialized players. A team typically consists of a three-point shooter, a defensive specialist, a playmaker, and rebounders. They all have specific roles assigned to them.</p><p>A catch-all word for statistics, technology has played a pivotal role in shaping this game. </p><p>In addition to data collection, biomechanics and motion cameras track every player’s movement. NBA even brought SportVU from football; it follows the ball and supposedly captures images 25 times per second. Coaches can now use this to analyze the speed, position, form, and motion of each player on the court. </p><p>In the end, it’s all about optimizing every ball possession. </p><p>Basketball might have lost its flair; every move is now predictable and measured. What is the future of basketball, is anyone’s guess? Maybe a rule change is around the corner?</p>","contentLength":2824,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43060769"},{"title":"Jill – a functional programming language for the Nand2Tetris platform","url":"https://github.com/mpatajac/jillc","date":1739642652,"author":"mailgolub","guid":502,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43060603"},{"title":"Alzheimer's biomarkers now visible up to a decade ahead of symptoms","url":"https://newatlas.com/brain/alzheimers-dementia/alzheimers-biomarkers-visible-decade-before-symptoms/","date":1739642537,"author":"01-_-","guid":465,"unread":true,"content":"<p>Researchers at the University of Pittsburgh have devised a biomarker test that can spot small amounts of clumping tau protein in the brain and cerebrospinal fluid, which lead to Alzheimer's disease.</p><p>Catching these clumps early while still in minute quantities can enable effective intervention. This test can help detect the tangled proteins years in advance of them appearing prominently in brain scans – as much as up to a decade.</p><p>That's heartening because Alzheimer's disease not only has devastating impact on patients' lives long term, but is also currently incurable. It begins to show up as forgetfulness, and progresses to confusion and disorientation, delusions, hallucinations, and trouble sleeping. As the condition worsens, patients may experience difficulty eating, moving around, incontinence, loss of speech, and significant memory loss.</p><p>“Early detection is key to more successful therapies for Alzheimer’s disease since trials show that patients with little-to-no quantifiable insoluble tau tangles are more likely to benefit from new treatments than those with a significant degree of tau brain deposits,\" explained Thomas Karikari, senior author of the <a href=\"https://www.nature.com/articles/s41591-024-03400-0\" target=\"_blank\" data-cms-ai=\"0\">paper published in </a> this week.</p><p>Here's a quick bit of context on what's happening in and around the brain. <a href=\"https://www.nih.gov/news-events/nih-research-matters/scientists-build-largest-maps-date-cells-human-brain\" target=\"_blank\" data-cms-ai=\"0\">Humans have some 86 billion nerve cells</a>, and they're connected by what are called synapses. These synapses are supported by 'rail tracks' that enable the flow of essential nutrients and information, and they're called microtubules.</p><p>Tau proteins (abbreviated from tubulin associated unit) stabilize these microtubules, and help keep the brain healthy. These proteins can malfunction, clump together and create tangles – preventing the microtubules from functioning properly.</p><p>Here's where this new biomarker test comes in. The researchers have found an important section of the tau protein that causes it to form harmful tangles in the brain. This section is made up of 111 building blocks (amino acids). Within this section, they discovered two specific spots that, when modified, can tell doctors if tau proteins are starting to clump together. This is important because if doctors can detect these changes early enough, they might be able to treat the problem before it gets worse.</p><p>The two specific spots they found (called p-tau-262 and p-tau-356) work like early warning signals, letting doctors know that tau proteins are beginning to malfunction. This could help identify Alzheimer's disease sooner, when treatments might be more effective.</p>","contentLength":2523,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43060587"},{"title":"More Solar and Battery Storage Added to TX Grid Than Other Power Src Last Year","url":"https://insideclimatenews.org/news/10022025/solar-battery-storage-texas-grid/","date":1739637424,"author":"indigodaddy","guid":464,"unread":true,"content":"<p>As the market for renewables in Texas continues to strengthen and innovate, the power makeup of the state’s electric grid is slated to keep shifting toward adding more renewables. Last year, solar and battery storage installation led capacity growth within Texas’ electric grid, according to <a href=\"https://www.dallasfed.org/research/economics/2025/0114\">research from the Federal Reserve Bank of Dallas</a> published in January.&nbsp;</p><p>Texas added nearly 1,500 megawatts of battery storage to the grid’s summer rated capacities in 2023. That figure almost tripled to 4,374 megawatts added in 2024, according to the report.&nbsp;</p><p>Capacity from solar power added to the grid enjoyed a similar trajectory. In 2023, 4,570 megawatts were added to the grid, while in 2024, nearly 9,700 megawatts were added.&nbsp;</p><p>Given that Texas has its own isolated energy grid, the Electricity Reliability Council of Texas (ERCOT) is responsible for managing the majority of energy for its residents.&nbsp;</p><div><p>Please take a look at the new openings in our newsroom.</p><a href=\"https://insideclimatenews.org/about/jobs/\" target=\"_blank\">See jobs</a></div><p>Historically, ERCOT, which manages 90 percent of the state’s power load, has primarily relied on natural gas. But other energy sources, like wind and solar, have played a critical role in offsetting high demand.&nbsp;</p><p>ERCOT added 3,400 megawatts from natural gas power plants in 2024. That’s after more than 1,000 megawatts of natural gas power were inactive within the grid from 2021 to 2023, according to Dallas Fed data.&nbsp;</p><p>The capacity growth from solar and battery storage allowed the grid to manage another hot Texas summer in 2024, reported Garret Golding, an assistant vice president for energy program at the Dallas Fed.&nbsp;</p><p>Battery storage is relatively new to ERCOT. One of the first battery power storage plants to be connected to ERCOT was in 2021, southeast of Dallas in Kaufman County.&nbsp;</p><p>The 50-megawatt plant run by Enel, one of the largest renewable energy owners and operators in the country, was the first of Enel’s 14 battery projects it has since developed across the state.&nbsp;</p><p>The forecasted power demand in Texas from population growth and heavy load users like data centers, cryptocurrency mining and artificial intelligence, alongside the competitive market for batteries, is dictating the rising use of storage within ERCOT, said Randald Bartlett, a senior director of operations and management for battery energy storage systems at Enel North America.</p><p>Texas’ permitting processes and ability to develop has made it easier to add and build new capacity in comparison to other states with more laborious entryways, Bartlett said.&nbsp;</p><p>Before, there wasn’t really adequate criteria and evidence to forecast what batteries would contribute to the grid, ERCOT CEO Pablo Vegas said during a board of directors meeting on Tuesday.&nbsp;</p><p>Now, the grid operator added battery contribution to its report forecasting future capacity, demand and reserves.&nbsp;</p><p>Battery storage in the ERCOT grid has nearly doubled every year since 2021, Vegas said. At the end of 2024, there were nearly 10,000 megawatts from batteries within ERCOT.</p><p>Vegas said the capacity from batteries made a significant difference in ERCOT during bridge hours, or the winter morning hours when the sun has yet to rise and in the evenings after the sun sets.&nbsp;</p><p>“Batteries made a meaningful contribution to what those shoulder periods look like and how much scarcity we get into during these peak events,” Vegas said when analyzing the grid’s performance during recent winter storms.&nbsp;</p><p>In the spring of 2024, Texas’ installation of utility scale solar outpaced California’s, and jumped from 1,900 megawatts in 2019 to over 20,000 megawatts in 2024. As a result, solar met nearly 50 percent of the state’s peak power demand on some days.&nbsp;</p><p>The state’s quick deployment of utility scale solar didn’t happen overnight. It started in 2005, when the legislature instructed the Public Utility Commission of Texas to create competitive renewable energy zones, where the state planned transmission lines to connect cities to renewable energy sources in west Texas.</p><p>Initially, it was intended to capture wind power but was able to quickly include solar because of the existing infrastructure, said Dustin Mulvaney, an environmental studies professor at San Jose State University and an author of Planning to Build Faster: A Solar Energy Case Study, published in October by the Roosevelt Institute.&nbsp;</p><p>That forward-looking plan is often held up as a model renewable energy advocates and developers say the Federal Energy Regulatory Commission could implement across other regional transmission organizations, by requiring proactive planning and by creating rules of how to pay for transmission systems.&nbsp;</p><p>As the state’s grid continues to experience a rapid shift in the type of generation available to serve demand, the state’s grid operator is looking to build a higher voltage transmission system, upgrading from 345-kilovolt lines to 765-kilovolt lines.&nbsp;</p><p>In 2024, nearly 78 gigawatts of transmission-connected wind, solar and battery energy storage capacity was installed to the grid. And more than 102 gigawatts of transmission-connected renewable capacity is expected to be installed by the end of 2025, according to a December ERCOT report.</p><p>It’s that growth of both demand and renewables connected to the grid that’s led ERCOT to ask the Public Utility Commission to consider upgrading the state’s transmission system rather than expanding its existing one.&nbsp;</p><p>The 765-kV lines would provide significant economic and reliability benefits to the ERCOT system, wrote Kristi Hobbs, ERCOT’s vice president of system planning and weatherization, in the grid operator’s submission of its regional transmission plans to the commission in late January.</p><p>Regardless of which transmission plan is chosen, Hobbs wrote, the explosive growth projected throughout the next six years and beyond will require major public investment.&nbsp;</p><div><div><p>Perhaps you noticed: This story, like all the news we publish, is free to read. That’s because Inside Climate News is a 501c3 nonprofit organization. We do not charge a subscription fee, lock our news behind a paywall, or clutter our website with ads. We make our news on climate and the environment freely available to you and anyone who wants it.</p><p>That’s not all. We also share our news for free with scores of other media organizations around the country. Many of them can’t afford to do environmental journalism of their own. We’ve built bureaus from coast to coast to report local stories, collaborate with local newsrooms and co-publish articles so that this vital work is shared as widely as possible.</p><p>Two of us launched ICN in 2007. Six years later we earned a Pulitzer Prize for National Reporting, and now we run the oldest and largest dedicated climate newsroom in the nation. We tell the story in all its complexity. We hold polluters accountable. We expose environmental injustice. We debunk misinformation. We scrutinize solutions and inspire action.</p><p>Donations from readers like you fund every aspect of what we do. If you don’t already, will you support our ongoing work, our reporting on the biggest crisis facing our planet, and help us reach even more readers in more places? </p><p>Please take a moment to make a tax-deductible donation. Every one of them makes a difference.</p></div></div><div><div><h4>Reporter, Texas Renewables</h4><p>Arcelia Martin is an award-winning journalist at Inside Climate News. She covers renewable energy in Texas from her base in Dallas. Before joining ICN in 2025, Arcelia was a staff writer at The Dallas Morning News and at The Tennessean. Originally from San Diego, California, she’s a graduate of Gonzaga University and Columbia University Graduate School of Journalism.</p></div></div>","contentLength":7659,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43059826"},{"title":"Deepseek R1 Distill 8B Q40 on 4 x Raspberry Pi 5","url":"https://github.com/b4rtaz/distributed-llama/discussions/162","date":1739635889,"author":"b4rtazz","guid":463,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43059579"},{"title":"Carbon capture more costly than switching to renewables, researchers find","url":"https://techxplore.com/news/2025-02-carbon-capture-renewables.html","date":1739631990,"author":"Brajeshwar","guid":462,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058997"},{"title":"Dust from car brakes more harmful than exhaust, study finds","url":"https://e360.yale.edu/digest/brake-pads-lung-damage-study","date":1739631975,"author":"Brajeshwar","guid":461,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058993"},{"title":"Diablo hackers uncovered a speedrun scandal","url":"https://arstechnica.com/gaming/2025/02/the-diablo-hackers-that-debunked-a-record-speedrun/","date":1739628000,"author":"pitwin","guid":460,"unread":true,"content":"<p>But simply splitting a run into segments doesn't explain away all of the problems the TAS team found. Getting Naj's Puzzler on dungeon level 9, for instance, still requires outside modification of a save file, which is specifically prohibited by <a href=\"https://kb.speeddemosarchive.com/Rules\">longstanding Speed Demos Archive rules</a> that \"manually editing/adding/removing game files is generally not allowed.\" Groobo's apparent splicing of multiple game versions and differently seeded save files also seems to go against SDA rules, which say that \"there obviously needs to be continuity between segments in terms of inventory, experience points or whatever is applicable for the individual game.\"</p><p>After being presented with the TAS team's evidence, SDA <a href=\"https://speeddemosarchive.com/\">wrote</a> that \"it has been determined that Groobo's run very likely does not stem from only legitimate techniques, and as such, has itself been banished barring new developments.\" But Groobo's record is <a href=\"https://www.guinnessworldrecords.com/world-records/110580-fastest-completion-of-an-rpg-videogame\">still listed as the \"Fastest completion of an RPG videogame\"</a> by Guinness World Records, which has not offered a substantive response to the team's findings (Guinness has not responded to a request for comment from Ars Technica).</p><figure><div><div>\n      A recent  speedrun on a confirmed legitimate dungeon seed.\n\n          </div></div></figure><p>This might seem like a pretty petty issue to spend weeks of time and attention debunking. But at a recent presentation attended by Ars, Cecil said he was motivated to pursue it because \"it did harm. Groobo's alleged cheating in 2009 completely stopped interest in speedrunning this category [of ]. No one tried, no one could.\"</p><p>Because of Groobo's previously unknown modifications to make an impossible-to-beat run, \"this big running community just stopped trying to run this game in that category,\" Cecil said. \"For more than a decade, this had a chilling impact on that community.\" With Groobo's run out of the way, though, new runners are <a href=\"https://www.youtube.com/watch?v=bXG1vW6VEKA\">setting new records on confirmed legitimate RNG seeds</a>, and <a href=\"https://www.youtube.com/watch?v=F9mn5CpQCFw\">with the aid of TAS tools</a>.</p><p>In the end, Cecil said he hopes the evidence regarding Groobo's run will make people look more carefully at other record submissions. \"Groobo had created a number of well-respected ... speedruns,\" he said. \"[People thought] there wasn't any good reason to doubt him. In other words, there was bias in familiarity. This was a familiar character. Why would they cheat?\"</p>","contentLength":2302,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058522"},{"title":"Show HN: I Built a Reddit-style Bluesky client – still rough, but open to ideas","url":"https://threadsky.app/","date":1739625557,"author":"lakshikag","guid":453,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058285"},{"title":"Show HN: Kreuzberg – Modern async Python library for document text extraction","url":"https://github.com/Goldziher/kreuzberg","date":1739614043,"author":"nhirschfeld","guid":452,"unread":true,"content":"<p>I'm excited to showcase Kreuzberg!</p><p>Kreuzberg is a modern Python library built from the ground up with async/await, type hints, and optimized I/O handling.</p><p>It provides a unified interface for extracting text from documents (PDFs, images, office files) without external API dependencies.</p><p>Key technical features:\n- Built with modern Python best practices (async/await, type hints, functional-first)\n- Optimized async I/O with anyio for multi-loop compatibility\n- Smart worker process pool for CPU-bound tasks (OCR, doc conversion)\n- Efficient batch processing with concurrent extractions\n- Clean error handling with context-rich exceptions</p><p>I built this after struggling with existing solutions that were either synchronous-only, required complex deployments, or had poor async support. The goal was to create something that works well in modern async Python applications, can be easily dockerized or used in serverless contexts, and relies only on permissive OSS.</p><p>Key advantages over alternatives:\n- True async support with optimized I/O\n- Minimal dependencies (much smaller than alternatives)\n- Perfect for serverless and async web apps\n- Local processing without API calls\n- Built for modern Python codebases with rigorous typing and testing</p><p>The library is MIT licensed and open to contributions.</p>","contentLength":1289,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43057375"},{"title":"Jane Street's Figgie card game","url":"https://www.figgie.com/","date":1739613560,"author":"eamag","guid":459,"unread":true,"content":"<p><a href=\"https://www.janestreet.com/\">Jane Street</a>'s fast-paced\n              Figgie game simulates exciting elements of markets and trading. At\n              Jane Street, Figgie is a game we teach and also one we really\n              enjoy playing.\n            </p><p><a href=\"https://www.figgie.com/faqs.html\">Read our FAQs</a>\n              for more. If you have a question that isn’t answered there, we’d\n              like to hear\n              <a href=\"mailto:figgie@janestreet.com\">what’s missing</a> and what\n              would be helpful to know, and we’ll do our best to update FAQs\n              along the way.\n            </p>","contentLength":507,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43057344"},{"title":"The 20 year old PSP can now connect to WPA2 WiFi Networks","url":"https://wololo.net/2025/02/14/the-20-year-old-psp-can-now-connect-to-wpa2-wifi-networks/","date":1739590316,"author":"zdw","guid":458,"unread":true,"content":"<div><img data-recalc-dims=\"1\" fetchpriority=\"high\" decoding=\"async\" aria-describedby=\"caption-attachment-49719\" src=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=848%2C477&amp;ssl=1\" alt=\"\" width=\"848\" height=\"477\" srcset=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?w=848&amp;ssl=1 848w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=768%2C432&amp;ssl=1 768w\" sizes=\"(max-width: 848px) 100vw, 848px\"><p>Screenshot source: Zekiu_ on youtube</p></div><p><a href=\"https://wololo.net/tag/acid_snake\">Acid_Snake</a> and the <a href=\"https://wololo.net/tag/ark-4/\">ARK</a> Development team have released a significant update to the ARK custom Firmware for the Sony PSP. Custom Firmware now allows the Playstation Portable to connect to WPA2 encrypted Wifi networks. This is thanks to the recently released  plugin, created by developer  and published on the PSP Homebrew discord.</p><h2>Playstation Portable gets WPA2 Wifi access</h2><p>The PSP has been out of official support from Sony for years, but lots of enthusiasts keep maintaining this great handheld through homebrew and custom Firmware updates. As technology evolves around us, older devices such as the PlayStation Portable can lose some of their features.</p><p>For example, as WPA2 has become the defacto encryption standard for home wifi networks (WPA3’s adoption rate remains low), older devices such as the PSP, that do not support these new* encryption standards become technically unable to access the internet.</p><p>Wifi access was a very strong feature of the PSP when it was released, and, although it’s probably less important nowadays, losing that feature because newer networks aren’t compatible is a bummer.</p><p>WPA2 support has been a request by many enthusiasts for years on PSP discussion channels, and it seems that the wpa2psp plugin by developer Moment now brings this to life. According to Acid_Snake, the developer was kind enough to provide the source code of the plugin, which allowed the ARK team to embed it into the ARK Custom Firmware for PSP.</p><div><img data-recalc-dims=\"1\" decoding=\"async\" aria-describedby=\"caption-attachment-49720\" src=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=1024%2C321&amp;ssl=1\" alt=\"\" width=\"1024\" height=\"321\" srcset=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=1024%2C321&amp;ssl=1 1024w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=300%2C94&amp;ssl=1 300w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=768%2C241&amp;ssl=1 768w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?w=1124&amp;ssl=1 1124w\" sizes=\"(max-width: 1000px) 100vw, 1000px\"></div><p><a href=\"https://www.reddit.com/r/psphacks/comments/1iimnft/wpa2_now_works_on_psp_thanks_to_a_new_plugin/\">This reddit thread</a> by Nebula_NL covers a lot of details on how to install and use the plugin. But the bottom line is: install the latest release of the ARK CFW on your PSP, and take it from there. (Note that you can also manually install the plugin if you’re using another CFW than ARK)</p><p>This is of course the first iteration of this plugin, and it comes with limitations, specifically:</p><ul><li>2.4 GHz Only\n<ul><li>WPA2 support works with 2.4 GHz WiFi.</li><li>If your router uses a single SSID for both 2.4 GHz and 5 GHz, you may need to separate them and connect your PSP to the 2.4 GHz network.</li></ul></li><li>WPA2 AES Only\n<ul><li>Requires WPA2 with AES (AES-CCMP) encryption.</li><li>TKIP is not supported and will not work.</li></ul></li><li>WEP/WPA Compatibility\n<ul><li>While WPA2 is active, WEP and WPA encryption will not work.</li><li>To use WEP or WPA again, disable WPA2, and they will function normally.</li></ul></li><li>WPA2/WPA3 Mixed Mode\n<ul><li>If your router is set to WPA2/WPA3 mixed mode, your PSP may struggle to obtain an IP address.</li><li>Try manually setting the IP address instead of using DHCP in [AUTO] mode.</li></ul></li></ul><h2>Download and install ARK-4 + enable WPA2 Support for the PSP</h2><p><em>* WPA2 was certified in 2004… It’s “new” from the PSP’s perspective which launched the same year and didn’t “need” to support it at the time. WPA3 launched in 2018 but its adoption is taking time</em></p>","contentLength":2772,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43055671"},{"title":"Show HN: VimLM – A Local, Offline Coding Assistant for Vim","url":"https://github.com/JosefAlbers/VimLM","date":1739576081,"author":"JosefAlbers","guid":451,"unread":true,"content":"<p>VimLM is a local, offline coding assistant for Vim. It’s like Copilot but runs entirely on your machine—no APIs, no tracking, no cloud.</p><p>- Deep Context: Understands your codebase (current file, selections, references).  \n- Conversational: Iterate with follow-ups like \"Add error handling\".  \n- Vim-Native: Keybindings like `Ctrl-l` for prompts, `Ctrl-p` to replace code.  \n- Inline Commands: `!include` files, `!deploy` code, `!continue` long responses.</p><p>Perfect for privacy-conscious devs or air-gapped environments.</p><p>Try it:  \n```\npip install vimlm\nvimlm\n```</p>","contentLength":558,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43054244"},{"title":"A decade later, a decade lost (2024)","url":"https://meyerweb.com/eric/thoughts/2024/06/07/a-decade-later-a-decade-lost/","date":1739574636,"author":"ZeWaka","guid":457,"unread":true,"content":"<p>I woke up this morning about an hour ahead of my alarm, the sky already light, birds calling.&nbsp; After a few minutes, a brief patter of rain swept across the roof and moved on.</p><p>I just lay there, not really thinking.&nbsp; Feeling.&nbsp; Remembering.</p><p>Almost sixteen years to the minute before I awoke, my second daughter was born.&nbsp; Almost ten years to the same minute before, she’d turned six years old, already semi-unconscious, and died not quite twelve hours later.</p><p>So she won’t be taking her first solo car drive today.&nbsp; She won’t be celebrating with dinner at her favorite restaurant in the whole world.&nbsp; She won’t kiss her niece good night or affectionately rag on her siblings.</p><p>Or maybe she wouldn’t have done any of those things anyway, after a decade of growth and changes and paths taken.&nbsp; What would she really be like, at sixteen?</p><p>We will never know.&nbsp; We can’t even guess.&nbsp; All of that, everything she might have been, is lost.</p><p>This afternoon, we’ll visit Rebecca’s grave, and then go to hear her name read in remembrance at one of her very happiest places, <a href=\"https://en.wikipedia.org/wiki/Anshe_Chesed_Fairmount_Temple\">Anshe Chesed Fairmount Temple</a>, for the last time.&nbsp; At the end of the month, the temple will close as part of a merger.&nbsp; Another loss.</p><p>A decade ago, I said that I felt the weight of all the years she would never have, and that they might crush me.&nbsp; Over time, I have come to realize all the things she never saw or did adds to that weight.&nbsp; Even though it seems like it should be the same weight.&nbsp; Somehow, it isn’t.</p><p>I was talking about all of this with a therapist a few days ago, about the time and the losses and their accumulated weight.&nbsp; I said, “I don’t know how to be okay when I failed my child in the most fundamental way possible.”</p><p>“You didn’t fail her,” they said gently.</p><p>“I know that,” I replied. “But I don’t feel it.”</p><p>A decade, it turns out, does not change that.&nbsp; I’m not sure now that any stretch of time ever could.</p>","contentLength":1935,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43054069"},{"title":"We were wrong about GPUs","url":"https://fly.io/blog/wrong-about-gpu/","date":1739572591,"author":"mxstbr","guid":456,"unread":true,"content":"<div><p>We’re building a public cloud, on hardware we own. We raised money to do that, and to place some bets; one of them: GPU-enabling our customers. A progress report: GPUs aren’t going anywhere, but: GPUs aren’t going anywhere.</p></div><p>A Fly Machine is a <a href=\"https://fly.io/blog/docker-without-docker/\">Docker/OCI container</a> running inside a hardware-virtualized virtual machine somewhere on our global fleet of bare-metal worker servers. A GPU Machine is a Fly Machine with a hardware-mapped Nvidia GPU. It’s a Fly Machine that can do fast CUDA.</p><p>Like everybody else in our industry, we were right about the importance of AI/ML. If anything, we underestimated its importance. But the product we came up with probably doesn’t fit the moment. It’s a bet that doesn’t feel like it’s paying off.</p><p><strong>If you’re using Fly GPU Machines, don’t freak out; we’re not getting rid of them.</strong> But if you’re waiting for us to do something bigger with them, a v2 of the product, you’ll probably be waiting awhile.</p><p>GPU Machines were not a small project for us. Fly Machines run on an idiosyncratically small hypervisor (normally Firecracker, but for GPU Machines <a href=\"https://github.com/cloud-hypervisor/cloud-hypervisor\">Intel’s Cloud Hypervisor</a>, a very similar Rust codebase that supports PCI passthrough). The Nvidia ecosystem is not geared to supporting micro-VM hypervisors.</p><p>GPUs <a href=\"https://googleprojectzero.blogspot.com/2020/09/attacking-qualcomm-adreno-gpu.html\">terrified our security team</a>. A GPU is just about the worst case hardware peripheral: intense multi-directional direct memory transfers</p><div><p>(not even bidirectional: in common configurations, GPUs talk to each other)</p></div><p>with arbitrary, end-user controlled computation, all operating outside our normal security boundary.</p><p>We did a couple expensive things to mitigate the risk. We shipped GPUs on dedicated server hardware, so that GPU- and non-GPU workloads weren’t mixed. Because of that, the only reason for a Fly Machine to be scheduled on a GPU machine was that it needed a PCI BDF for an Nvidia GPU, and there’s a limited number of those available on any box. Those GPU servers were drastically less utilized and thus less cost-effective than our ordinary servers.</p><p>We funded two very large security assessments, from <a href=\"https://www.atredis.com/\">Atredis</a> and <a href=\"https://tetrelsec.com/\">Tetrel</a>, to evaluate our GPU deployment. Matt Braun is writing up those assessments now. They were not cheap, and they took time.</p><p>Security wasn’t directly the biggest cost we had to deal with, but it was an indirect cause for a subtle reason.</p><p>We could have shipped GPUs very quickly by doing what Nvidia recommended: standing up a standard K8s cluster to schedule GPU jobs on. Had we taken that path, and let our GPU users share a single Linux kernel, we’d have been on Nvidia’s driver happy-path.</p><p>Alternatively, we could have used a conventional hypervisor. Nvidia suggested VMware (heh). But they could have gotten things working had we used QEMU. We like QEMU fine, and could have talked ourselves into a security story for it, but the whole point of Fly Machines is that they take milliseconds to start. We could not have offered our desired Developer Experience on the Nvidia happy-path.</p><p>Instead, we burned months trying (and ultimately failing) to get Nvidia’s host drivers working to map <a href=\"https://www.nvidia.com/en-us/data-center/virtual-solutions/\">virtualized GPUs</a> into Intel Cloud Hypervisor. At one point, we hex-edited the closed-source drivers to trick them into thinking our hypervisor was QEMU.</p><p>I’m not sure any of this really mattered in the end. There’s a segment of the market we weren’t ever really able to explore because Nvidia’s driver support kept us from thin-slicing GPUs. We’d have been able to put together a really cheap offering for developers if we hadn’t run up against that, and developers love “cheap”, but I can’t prove that those customers are real.</p><p>On the other hand, we’re committed to delivering the Fly Machine DX for GPU workloads. Beyond the PCI/IOMMU drama, just getting an entire hardware GPU working in a Fly Machine was a lift. We needed Fly Machines that would come up with the right Nvidia drivers; our stack was built assuming that the customer’s OCI container almost entirely defined the root filesystem for a Machine. We had to engineer around that in our  orchestrator. And almost everything people want to do with GPUs involves efficiently grabbing huge files full of model weights. Also annoying!</p><p>And, of course, we bought GPUs. A lot of GPUs. Expensive GPUs.</p><p>The biggest problem: developers don’t want GPUs. They don’t even want AI/ML models. They want LLMs.  may have smart, fussy opinions on how to get their models loaded with CUDA, and what the best GPU is. But  don’t care about any of that. When a software developer shipping an app comes looking for a way for their app to deliver prompts to an LLM, you can’t just give them a GPU.</p><p>For those developers, who probably make up most of the market, it doesn’t seem plausible for an insurgent public cloud to compete with OpenAI and Anthropic. Their APIs are fast enough, and developers thinking about performance in terms of “tokens per second” aren’t counting milliseconds.</p><div><p>(you should all feel sympathy for us)</p></div><p>This makes us sad because we really like the point in the solution space we found. Developers shipping apps on Amazon will outsource to other public clouds to get cost-effective access to GPUs. But then they’ll faceplant trying to handle data and model weights, backhauling gigabytes (at significant expense) from S3. We have app servers, GPUs, and object storage all under the same top-of-rack switch. But inference latency just doesn’t seem to matter yet, so the market doesn’t care.</p><p>Past that, and just considering the system engineers who do care about GPUs rather than LLMs: the hardware product/market fit here is really rough.</p><p>People doing serious AI work want galactically huge amounts of GPU compute. A whole enterprise A100 is a compromise position for them; they want an SXM cluster of H100s.</p><div><p>Near as we can tell, MIG gives you a UUID to talk to the host driver, not a PCI device.</p></div><p>We think there’s probably a market for users doing lightweight ML work getting tiny GPUs. <a href=\"https://www.nvidia.com/en-us/technologies/multi-instance-gpu/\">This is what Nvidia MIG does</a>, slicing a big GPU into arbitrarily small virtual GPUs. But for fully-virtualized workloads, it’s not baked; we can’t use it. And I’m not sure how many of those customers there are, or whether we’d get the density of customers per server that we need.</p><p><a href=\"https://fly.io/blog/cutting-prices-for-l40s-gpus-in-half\">That leaves the L40S customers</a>. There are a bunch of these! We dropped L40S prices last year, not because we were sour on GPUs but because they’re the one part we have in our inventory people seem to get a lot of use out of. We’re happy with them. But they’re just another kind of compute that some apps need; they’re not a driver of our core business. They’re not the GPU bet paying off.</p><p>Really, all of this is just a long way of saying that for most software developers, “AI-enabling” their app is best done with API calls to things like Claude and GPT, Replicate and RunPod.</p><p>A very useful way to look at a startup is that it’s a race to learn stuff. So, what’s our report card?</p><p>First off, when we embarked down this path in 2022, we were (like many other companies) operating in a sort of phlogiston era of AI/ML. The industry attention to AI had not yet collapsed around a small number of foundational LLM models. We expected there to be a diversity of  models, the world <a href=\"https://github.com/elixir-nx/bumblebee\" title=\"\">Elixir Bumblebee</a> looks forward to, where people pull different AI workloads off the shelf the same way they do Ruby gems.</p><p>But <a href=\"https://www.cursor.com/\" title=\"\">Cursor happened</a>, and, as they say, how are you going to keep ‘em down on the farm once they’ve seen Karl Hungus? It seems much clearer where things are heading.</p><p>GPUs were a test of a Fly.io company credo: as we think about core features, we design for 10,000 developers, not for 5-6. It took a minute, but the credo wins here: GPU workloads for the 10,001st developer are a niche thing.</p><p>Another way to look at a startup is as a series of bets. We put a lot of chips down here. But the buy-in for this tournament gave us a lot of chips to play with. Never making a big bet of any sort isn’t a winning strategy. I’d rather we’d flopped the nut straight, but I think going in on this hand was the right call.</p><p>A really important thing to keep in mind here, and something I think a lot of startup thinkers sleep on, is the extent to which this bet involved acquiring assets. Obviously, some of our <a href=\"https://fly.io/blog/the-exit-interview-jp/\" title=\"\">costs here aren’t recoverable</a>. But the hardware parts that aren’t generating revenue will ultimately get liquidated; like with <a href=\"https://fly.io/blog/32-bit-real-estate/\" title=\"\">our portfolio of IPv4 addresses</a>, I’m even more comfortable making bets backed by tradable assets with durable value.</p><p>In the end, I don’t think GPU Fly Machines were going to be a hit for us no matter what we did. Because of that, one thing I’m very happy about is that we didn’t compromise the rest of the product for them. Security concerns slowed us down to where we probably learned what we needed to learn a couple months later than we could have otherwise, but we’re scaling back our GPU ambitions without having sacrificed <a href=\"https://fly.io/blog/sandboxing-and-workload-isolation/\" title=\"\">any of our isolation story</a>, and, ironically, GPUs  are making that story a lot more important. The same thing goes for our Fly Machine developer experience.</p><p>We started this company building a Javascript runtime for edge computing. We learned that our customers didn’t want a new Javascript runtime; they just wanted their native code to work. <a href=\"https://news.ycombinator.com/item?id=22616857\" title=\"\">We shipped containers</a>, and no convincing was needed. We were wrong about Javascript edge functions, and I think we were wrong about GPUs. That’s usually how we figure out the right answers:  by being wrong about a lot of stuff.</p>","contentLength":9514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053844"},{"title":"The hardest working font in Manhattan","url":"https://aresluna.org/the-hardest-working-font-in-manhattan/","date":1739569549,"author":"robinhouston","guid":455,"unread":true,"content":"<p>\n\t\tIn 2007, on my first trip to New York City, I grabbed a brand-new DSLR camera and photographed all the fonts I was supposed to love. I admired American Typewriter in all of the I &lt;3 NYC logos, watched Akzidenz Grotesk and Helvetica fighting over the subway signs, and even caught an occasional appearance of the flawlessly-named Gotham, still a year before it skyrocketed in popularity via Barack Obama’s first campaign. \n\t</p><p>\n\t\tBut there was one font I didn’t even notice, even though it was everywhere around me.\n\t</p><p>\t\t\n\t\tLast year in New York, I walked over 100 miles and took thousands of photos of one and one font only.\n\t</p><p>\t\t\n\t\tThe font’s name is Gorton.\n\t</p><p>\t\t\n\t\tIt’s hard to believe today that there was a time before I knew of Gorton and all its quirks and mysteries. The first time I realized the font even existed was some time in 2017, when I was researching for <a target=\"_blank\" href=\"https://shifthappens.site\">my book about the history of typing</a>. \n\t</p><p>\t\t\n\t\tMany keyboards, especially older ones, sported a particular distinctive font on their keycaps. It was unusually square in proportions, and a weird mélange of “mechanical” and “childish.”\n\t</p><p>\t\t \n\t\tThe more I looked at it, the more I realized how bizarre and amateurish it was. The G always felt like it was about to roll away on its side. There was a goofy wavy hook sticking out of Q. P and R were often too wide. &amp; and @ symbols would be laughed away in a type crit, and the endings of C felt like grabbing something next to it – a beginning of a ligature that never came.\n\t</p><p>\t\t\n\t\tThe strangeness extended to the digits. There was a top-flatted 3 resembling a Cyrillic letter, 7 sloping down in a unique way, a very geometric 4, an unusual – perhaps even naïve – symmetry between 6 and 9, and a conflation of O with 0 that would be a fireable offense elsewhere.\n\t</p><p>\t\t\t\n\t\tLooking at just a few keyboards, it was also obvious that it wasn’t just one rigid font. There were always variations, sometimes even on one keyboard. 0 came square, dotted, or slashed. The usually very narrow letter I sometimes sported serifs. The R and the 6 moved their middles higher or lower. There also seemed to be a narrower version of the font, deployed when a keycap needed a word and not just a letter. (Lowercase letters existed too, but not very often.) \n\t</p><p>\t\t\n\t\tMy first thought was: What a mess. Is this how “<a target=\"_blank\" href=\"https://fonts.ilovetypography.com/category/grotesque\">grotesque</a>” fonts got their name?\n\t</p><p>\t\t\n\t\tThen, the second thought: I kind of like it.\n\t</p><figcaption>The most distinctive letterforms of Gorton</figcaption><p>\t\t\n\t\tBut what font was it? What The Font website posited TT Rounds, Identifont suggested it could be Divulge, my early guess was DIN Rounded or something related to road signage. Whatever it was, a flat R clearly separated it from Helvetica, and the shapes were not as round as even the un-rounded Gotham’s.\n\t</p><p>\t\t\n\t\tA few places for keyboard nerds referred to the font as “Gorton,” but that phrase yielded zero results anywhere I typically looked for fonts I could download and install.\n\t</p><p>\t\t\t\t\n\t\tI originally thought this had to do with how keys were made. Only in newer keyboards are the letters printed on top of the keys, or charred from their surface by a laser. In older ones – those from the early 1960s laboratory computers, or the 1980s microcomputers –&nbsp;the way every key was constructed was by first molding the letter from plastic of one color, and then grabbing a different plastic and molding the key around the letter. A Gorton letter was as physical as the key itself. It made the keys virtually indestructible – the legend could not wear off any more than its key – and I imagined required some specialized keyboard-making machinery that came with the “keyboard font” already there.\n\t</p><figcaption>\n\t\tAn example of a “double-shot” key from above and from below\n\t</figcaption><p>\t\t\t\n\t\tBut then, I started seeing Gorton in other places.\n\t</p><p>\t\t\t\t\t\n\t\tHours of looking at close-ups of keys made me sensitive to the peculiar shapes of some of its letters. No other font had a Q, a 9, or a C that looked like this.\n\t</p><p>\t\t\t\t\t\n\t\tOne day, I saw what felt like Gorton on a ferry traversing the waters Bay Area. A few weeks later, I spotted it on a sign in a national park. Then on an intercom. On a street lighting access cover. In an elevator. At my dentist’s office. In an alley. \n\t</p><p>\t\t\t\t\t\t\n\t\tThese had one thing in common. All of the letters were carved into the respective base material – metal, plastic, wood. The removed shapes were often filled in with a different color, but sometimes left alone.\n\t</p><p>\t\t\t\t\t\n\t\tAt one point someone explained to me Gorton must have been a routing font, meant to be carved out by a milling machine rather than painted on top or impressed with an inked press.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome searches quickly led me to George Gorton Machine Co., a Wisconsin-based company which produced various engraving machines. The original model 1 led to model 1A and then 3U and then, half a decade later, P1-2. They were all pantograph engravers: They allowed you to install one or more letter templates and then trace their shape by hand. A matching rotating cutter would mimic your movements, and the specially configured arms would enlarge or reduce the output to the size you wanted.\n\t\t</p><p>\t\t\t\t\t\t\t\n\t\tThis immediately explained both the metaphorical and literal rough edges of Gorton.\n\t</p><p>\t\t\t\t\t\n\t\tA lot of typography has roots in calligraphy – someone holding a brush in their hand and making natural but delicate movements that result in nuanced curves filled with thoughtful interchanges between thin and thick. Most of the fonts you ever saw follow those rules; even the most “mechanical” fonts have surprising humanistic touches if you inspect them close enough.\n\t</p><p>\t\t\t\n\t\tBut not Gorton. Every stroke of Gorton is exactly the same thickness (typographers would call such fonts “monoline”). Every one of its endings is exactly the same rounded point. The italic is merely an oblique, slanted without any extra consideration, and while the condensed version has some changes compared to the regular width, those changes feel almost perfunctory.\n\t</p><p>\t\n\t\tMonoline fonts are not respected highly, because every type designer will tell you: This is not how you design a font. \n\t</p><p>\t\t\n\t\tIt seemed at this point that perhaps P1-2 and its predecessors were a somewhat popular machining product during the 20th century’s middle decades. But casual research through materials preserved by some of George Gorton Machine Company’s fans – including <a target=\"_blank\" href=\"http://gorton-machine.org/\">the grandson of the founder</a> – revealed something even more interesting. Gorton the font was a lot older than I expected. \n\t</p><p>\t\t\n\t\tI found a 1935 catalog showing the very same font. Then one from 1925. And then, there was one all the way from 1902, showing the shapes I was starting to be mildly obsessed with.\n\t</p><p>\t\t\t\n\t\tTo put it in perspective: the font I first assumed was a peer to 1950s Helvetica was already of retirement age the day Helvetica was born. Gorton was older than Gill Sans, Futura, or Johnston’s London Underground font. It was contemporaneous to what today we recognize as the first modern sans serif font, Akzidenz-Grotesk, released but three years before the end of the century.\n\t</p><p>\n\t\tImagine how stripped down and exotic Gorton must have felt right next to George Gorton Machine’s then-current logo!\n\t</p><p>\t\t\t\t\t\n\t\tI started researching Gorton more. Unfortunately, as I already suspected, no one ever wrote “I used Gorton to typeset this,” because Gorton was a tenuous name at best. It was the first font, and perhaps originally the  font that came with the engraver, so it suffered a nameless fate, familiar later to many bespoke bitmap fonts adorning the screens of early computers.\n\t</p><p>\t\t\t\t\t\n\t\tThe difference from these fonts, however, was that Gorton was meant to travel. And so, since searching for it by name was impossible, for months and years I just kept looking around for the now-familiar shapes.\n\t</p><p>\n\t\tGorton wasn’t just on computer keyboards, intercom placards, and sidewalk messages visited by many shoes. Gorton was there on typewriter keyboards, too. And on office signs and airline name tags. On boats, desk placards, rulers, and various home devices from fridges to tape dispensers.\n\t</p><p>\t\t\t\t\t\n\t\tIt was also asked to help in situations other fonts rarely did. I spotted Gorton on overengineered buttons that were put to heavy industrial and military use. I saw it carved into surfaces of traffic control devices, elevators and escalators, locomotives and subway trains, submarines and jet fighters. Gorton made its way to peace- and wartime nuclear facilities, it was there on the elevator at the Kennedy Space Center with labels marked EARTH and SPACE… and it went  and then the Moon, as key legends on Apollo’s onboard computer.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut why? Why would anyone choose this kind of an ugly font where so many nicer fonts have already been around for ages?\n\t</p><p>\t\t\t\t\t\n\t\tSome of it might be the power of the default. Popular engraving equipment comes with a built-in font that’s so standard it reuses the router’s name? Of course you will see it, the same way you saw a lot of Arial in the 1990s, or Calibri today.\n\t</p><p>\n\t\tGorton was also convenient. If your previous engraving work required you do to the routing equivalent of handwriting or lettering – every letter done by hand – then a modern font you could simply  and one designed with “a minimum of sharp corners for rapid tracing with a smooth stroke,” must have felt like a breath of fresh air.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut why engraving to begin with? Because the affordable and casual printing options we enjoy today – the office laser printers and home inkjets, the FedEx Kinko’s, the various cheap labelers – weren’t there. Even things that today feel obsolete, like dot matrix printers, Letraset, and popular letter stencils, were yet to be invented. Often, your only realistic option was the complicated and time-consuming lettering by hand.\n\t</p><p>\t\t\t\n\t\tOn top of that, Gorton’s longevity must have felt attractive. Ink smudges. Paint fades away. Paper can catch fire (quickly) or germs (slowly). Carve something into plastic, on the other hand, and it can survive decades. Substitute plastic for metal, and you just turned decades into centuries. The text is not added atop heavy-duty material. The text  the material.\n\t</p><figcaption>Various items from the 20th century typeset in Gorton</figcaption><p>\t\t\t\t\t\n\t\tI felt good about all my findings: What a strange story of a strange routing font! \n\t</p><p>\n\t\tBut it turns out I was just getting started. Because soon, I noticed Gorton as ink on paper, and as paint on metal.\n\t</p><p>We’re used to the flexibility of fonts today. Fonts as bits inside a computer can become a website, paint on paper, CNC routing, a wall projection, and many other things. But those freedoms weren’t as easy back when fonts were made out of metal. Life’s not as much fun outside of the glamor of a TTF file, and a routing font couldn’t immediately become a regular font – so seeing Gorton being additive and not subtractive was an unexpected discovery.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tIt turns out that there developed a small cottage industry of things that extended Gorton past its engraving origins.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tA company called Keuffel &amp; Esser Co. grabbed Gorton’s machines, and used them to create lettering sets called Leroy. This was Gorton abstracted away – still a pantograph, but cheap, small, completely manual, and a vastly simplified one: no possibility to make things bigger and smaller, and no carving –&nbsp;instead, you’d mount a special pen and draw letters by tracing them.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tAnother company, Wood-Regan Instrument Co., made a similar set called (semi-eponymously) Wrico. But then, they simplified the process even more. Instead of a pantograph, they offered for sale a set of simple lettering guides used to guide your pen directly on paper.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome of the traditional draftspeople pooh-poohed these inventions – one handbook wrote “[Those are] of value chiefly to those who are not skilled in lettering. A professional show-card writer could work better and faster without it. A Leroy or Wrico lettering set permits work that is neat, rapid, and nearly foolproof, if not inspired.”\n\t</p><p>\t\t\t\n\t\tBut the products ended up being popular and influential. Their output appeared in many technical documents, but spread even a bit further than that. Eventually, there were stencils made by Unitech, Lutz, Tacro, Teledyne Post, Tamaya, Tech Graphic, Ridgway’s, Faber Castell, Zephyr, Charvoz, Rotring, Pickett, and probably many more.\n\t</p><p>\t\t\t\n\t\tThen, both EC Comics and All-Star Comics <a target=\"_blank\" href=\"https://kleinletters.com/Blog/wizards-of-leroy-and-wrico-lettering/\">used Leroy in the 1940s and 1950s</a>, most notably in the first comic book that introduced Wonder Woman. This was Gorton spreading further than just technical documents, and inspiring more people.\n\t</p><p>\t\t\t\n\t\tElsewhere silkscreening – a pretty cool technique of applying paint on surfaces through a wet mesh of fabric – took Gorton and Leroy in a different direction, by allowing paint on metal.\n\t</p><p>\t\t\t\n\t\tThere was more. The popular plastic letters attached to felt boards, popularized by restaurants decades ago, and more recently revisited by Instagram mom influencers, also clearly derive from Gorton and Leroy.\n\t</p><p>\n\t\tI also counted at least three different systems of “Gorton movable type” – some where you could assemble physical letters, and some where you could impress them into soft materials using steel types – and I imagine there were probably more.\n\t</p><p>\t\t\t\n\t\tLetraset, a cheap technique of applying a font by rubbing a letter from a provided sheet onto paper, popular throughout the 1960s, introduced first- or second-hand Leroy too – and so did a few competitors.\n\t</p><p>\t\t\t\t\t\n\t\tIn the regulatory space, the U.S. military canonized Gorton in 1968 as a standard called MIL-SPEC-33558 for aircraft and other equipment dials, cancelled it in 1998… then brought it back again in 2007. NATO and STANAG followed. ANSI, American standardization body, made a more rounded Leroy an official font for technical lettering via <a target=\"_blank\" href=\"https://archive.org/details/ansi-y14.2m-1971-line-conventions-and-lettering\">ANSI Y14.2M</a>, and so did institutions like the US National Park Service.\n\t</p><p>\t\t\t\t\n\t\tGorton went on and on and on. The early <a target=\"_blank\" href=\"https://hackaday.com/2021/03/30/hershey-fonts-not-chocolate-the-origin-of-vector-lettering/\">Hershey vector fonts</a>, developed on very early computers and still popular in CAD applications today, were also derived from Gorton/Leroy shapes, simplified so that the already-simple curves weren’t even necessary –&nbsp;any letter could now be drawn by a series of straight lines.\n\t</p><p>\t\t\t\t\t\n\t\tAnd even in the first universe Gorton inhabited things weren’t standing still. \n\t</p><p>\n\t\tAs the engraving industry learned what’s popular and what is not, the offerings started getting more and more sophisticated. A promotional booklet called “The Whereabouts of 230 Engraving Machines” listed Gorton customers ranging from biscuit makers to fire engine constructors. <a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_933/index.html\">Other</a><a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_1370a/index.html\">catalogs</a><a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_2070/index.html\">proudly listed</a> applications like book covers, billiard balls, organ keys, and toothbrushes, as well as “tools making more tools” – using Gorton engravers to create legends for other machines.\n\t</p><p>\t\t\n\t\tAfter you bought your pantograph engraver, you could buy attachments for sometimes surprising use cases:\n\t</p><p>\n\t\tThe original machine-shop pantographs were supplanted by smaller portable units (called Pantoetchers) on one side, and by increasingly complex  devices on the other. First generation of those were still huge room-size endeavors with old-fashioned displays and complex interfaces labeled… in Gorton itself. \n\t</p><p>\n\t\tBut the technology matured quickly and soon more and more early manual “tracer-guided” pantographs that forced the operator to put letters side by side and then trace them by hand, were superseded by <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Numerical_control\">computerized ones</a>, with both the composition and the routing completely automated. They came from George Gorton Machine Co., and from competitors like New Hermes or H.P. Preis.\n\t</p><p>\t\t\t\t\n\t\tYou no longer had to buy the chromium-plated brass alphabets weighing up to 13 pounds, choosing the right size from 3/8´´ to 3´´ ahead of time (pantographs allowed for reductions and enlargements, but only gave you a few steps within a specific range.) \n\t</p><p>\n\t\tNow, fonts came as digits or formulas built into computer memory, or – for a moment in time –&nbsp;as separate cartridges you’d insert in eager slots. (And yes, before you ask:&nbsp;there were <a target=\"_blank\" href=\"https://archive.org/details/gorton-master-copy-type-for-all-pantograph-machines/page/n5/mode/2up\">other routing monoline fonts</a>, too. But I really don’t care about any of them.)\n\t</p><p>\t\t\t\t\t\n\t\tIt was the same story as in word processing right next door, where old-fashioned Gutenberg-era typesetting was being replaced by increasingly smaller and cheaper computers equipped with first-laughable-then-capable software.\n\t</p><p>\t\t\t\t\t\n\t\tAnd automation came for the Leroy branch of the tree as well. A few companies grabbed Leroy lettering templates and abstracted them away once more. They created curious small typewriter/plotter hybrids where typing letters on a keyboard would make the pen draw them on paper for you. (I own one of them, a Max Cadliner. It might be one of the strangest typewriters I’ve seen – a weird combination of a machine pretending to be another machine pretending to be a human hand.)\n\t</p><p>\t\t\t\t\n\t\tIf this was a Gorton typewriter, there were also Gorton , even more sophisticated 1980s machines whose text could be programmed in advance rather than typed one line at a time, and mixed with graphics.\n\t</p><p>\t\t\t\n\t\tI don’t think the – by now 80 years and counting – fractal explosion of Gorton made its original creators rich.\n\t</p><p>\t\t\t\n\t\tCopy protection in the world of typography is complicated. The font’s name can be trademarked and other companies legally prevented from using it, and you can’t just grab matrices or font files and copy them without appropriate licenses. But take any text output using a font and then redraw it – and you are within your right to do so, and even to sell the final result. At least in America, or in some other countries until somewhat recently, the shapes of the letters themselves are not legally protected.\n\t</p><p>\t\t\t\n\t\tThis is why Keuffel &amp; Esser, Wood-Regan Instrument, and Letraset could potentially grab Gorton and claim it their own, as long as they didn’t name it Gorton. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut of course, Gorton was barely named “Gorton” to begin with. In the early days of George Gorton pantographs, as the default pantograph font, it came without a name. (The font sets for purchase were called “standard copies.”) Then, as other fonts were added, it was retroactively named Gorton Normal – the name of the company and the most generic word possible.\n\t</p><p>\t\t\t\t\t\n\t\tLeroy lettering sets started with one font, so similarly to Gorton the font started to be known as “Leroy,” then “Series C,” then “Gothic.” New Hermes called it simply “Block,” Letraset went with “Engineering Standard,” and Rotring – another producer of little computerized plotters&nbsp;– with “Universal.” I’ve also seen “A style,” “Plain Gothic,” and, mysteriously, “Standpoint.” \n\t</p><p>\t\t\t\t\t\t\t\n\t\tI don’t think this was meant to be disrespectful. “Standard,“ “Universal,” “A style” might not have had the connotations of “generic” we associate with them today, but rather meaning “the only one you need,” “approved of by millions,” or “the ultimate.”\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut there  one name that felt somewhat inconsiderate. It appeared in one product in the 1980s, a few decades after the birth of another font whose name became recognizable and distinguished. In that product, Gorton was referred to as “Linetica.”\n\t</p><figcaption>A few rare examples of Gorton Extended in use</figcaption><p>\t\t\t\t\t\t\n\t\tEach of these reappearances made small changes to the shapes of some letters. Leroy’s ampersand was a departure from Gorton’s. Others softened the middle of the digit 3, and Wrico got rid of its distinctive shape altogether. Sometimes the tail of the Q got straightened, the other times K cleaned up. Punctuation –&nbsp;commas, quotes, question marks –&nbsp;was almost always redone. But even without hunting down the proof confirming the purchase of a Gorton’s pantograph or a Leroy template set as a starting point, the lineage of its lines was obvious. (The remixes riffed off of Gorton Condensed or the normal, squareish edition… and at times both. The extended version – not that popular to begin with – was often skipped.)\n\t</p><figcaption>Classic Gorton vs. Gorton Modified</figcaption><p>\t\t\t\t\t\t\n\t\tThe only “official” update to Gorton I know of, and one actually graced with a name, was Gorton Modified. It was made some time in the 1970s by one of the main keyboard keycap manufacturers, Comptec (later Signature Plastics). It was almost a fusion of Gorton and Futura, with more rounded letterforms. Gone was the quirkiness of 3, 7, Q, C, and the strange, tired ampersand. This is the version people might recognize from some of the 1980s computers, or mechanical keyboards today. \n\t</p><p>\n\t\tIt is also that last Gorton that mattered.\n\t</p><figcaption>A collection of movies and TV shows featuring Gorton</figcaption><p>\t\t\t\t\t\t\t\n\t\tMy every walk in Chicago or San Francisco was counting down “time to Gorton” – sometimes mere minutes before I saw a placard or an intercom with the familiar font.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tThis might be embarrassing to admit, but I have never been so happy seeing a font in the wild, particularly as there was almost always some new surprise – a numero, a line going through the Z, a new use, or a new imperfection. And, for a font that didn’t exist, I saw it surprisingly often.\n\t</p><p>\t\t\t\t\t\t\t\t\t\n\t\tI even spotted Gorton a few times in Spain, or the U.K., and didn’t make too much of it, not thinking about the likelihood of machines from George Gorton’s company in a small town of Racine, Wisconsin making it all the way to different continents. In hindsight I should have.\n\t</p><figcaption>Gorton on old British cars, with a particularly delightful Rolls Royce logo made by a simple duplication of the classic Gorton letter R</figcaption><p>\t\t\t\t\t\t\n\t\tIt was only on a trip to Australia where something started connecting. Here, once more, I saw Gorton on the streets, put to work in all sorts of unglamorous situations:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome letterforms in the above photos felt slightly odd, and so did Gorton on the heavy machinery in an abandoned shipyard on an island near Sydney:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tAnd a visit to a naval museum cemented it all:\n\t</p><p>\n\t\tIt was Gorton, although with some consistent quirks: 2, 5, 6, and 9 were shorter, the centers of M and W didn’t stretch all the way across, and the distinctive shape of S was slightly different here.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tFortunately, this time around, a type designer familiar with my now-public obsession with Gorton clued me in. Gorton didn’t actually originate from Racine, Wisconsin in the late 19th century. It started a bit earlier, and quite a bit further away, at a photographic lens maker in the U.K. called Taylor, Taylor &amp; Hobson. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tIn 1894, TT&amp;H needed some way to put markings on their lenses. This being late 19th century, their options were limited to manual engraving, which must have felt tricky given the small font sizes necessary. So the company did what makers sometimes do – instead of searching for a solution that might not have even existed, they made new types of machines to carve out letters, and then designed a font to be used with them.\n\t</p><p>\n\t\tI don’t know how this first proto-Gorton was designed – unfortunately, Taylor, Taylor &amp; Hobson’s history seems sparse and despite personal travels to U.K. archives, I haven’t found anything interesting – but I know simple technical writing standards existed already, and likely influenced the appearance of the newfangled routing font.\n\t</p><figcaption>From a 1895 “Free-hand lettering” book by Frank T. Daniels</figcaption><p>\t\t\t\t\t\n\t\tThis was perhaps the first modern pantograph engraver, and perhaps even the arrival of a concept of an engraving font – the first time technical writing was able to be replicated consistently via the aid of the machine.\n\t</p><p>\t\t\t\n\t\tNo wonder that other companies came knocking. Only a few years later, still deep within the 19th century, Taylor, Taylor &amp; Hobson <a target=\"_blank\" href=\"http://gorton-machine.org/archives/TTH_license_1898/index.html\">licensed their stuff to a fledgling American company</a> named after its founder. Gorton Model 1 was the first U.S. version of the engraver, and the TT&amp;H font must have been slightly adjusted on arrival. \n\t</p><figcaption>A Taylor-Hobson pantograph in use in 1942</figcaption><p>\t\t\t\n\t\tThis adds to the accomplishments of Gorton – the font was actually  than even Akzidenz-Grotesk, and has been used on World War II equipment and later on on British rifles and motorcycles (and 3,775 finger posts in <a target=\"_blank\" href=\"https://www.yorkshiredales.org.uk/behind-the-signs-the-man-and-the-machine/\">one of the UK’s national parks</a>), but it complicates the story of the name even more. Turns out, the font without a name has even less of a name than I suspected.\n\t</p><p>\t\t\t\n\t\tIf the Taylor, Taylor &amp; Hobson (or, Taylor-Hobson, as their engravers were known) “branch” of Gorton were more used, should it usurp the at least somewhat popular Gorton name? Or should it just because it was first and the letterform changes were small? Does it matter? Where does one font end and another begin? (Unsurprisingly, TT&amp;H didn’t properly name the font either, eventually calling it “A style” for regular and “C style” for condensed variants. Google searches for “taylor hobson font” are a lot more sparse than those for Gorton.)  \n\t</p><div><div><div>GortonGorton Condensed</div></div></div><figcaption>The Gorton quasisuperfamily</figcaption><p>\n\t\tIn the end, I’m sticking with Gorton for the whole branch since that feels the most well-known name, but I feel ill-equipped to make that call for everyone. You might choose to call it Gorton, Leroy, TT&amp;H, Taylor-Hobson, or one of the many other names. (Just, ideally, not Linetica.)\n\t</p><figcaption>A comparison of all major editions of Gorton</figcaption><p>\t\t\t\t\t\n\t\tAnd so, throughout the 20th century, Gorton has lived two parallel lives –&nbsp;one originating in the U.K. and later expanding to its colonies and the rest of Europe, and another one in America. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tI am still tracing various appearences of Gorton and perhaps you, dear reader, will help me with that. (<a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Frequency_illusion\">Chances are</a>, you will see Gorton later today!) I’m curious about whether Gorton made it to Eastern Europe, Africa, or Asia. I’m interested in seeing if it appeared in Germany where the objectively better-designed DIN fonts became much more popular in Gorton’s niche.\n\t</p><p>\n\t\tThe history of this strange font spans over a century and I’ve seen it in so many countries by now, used in so many situations. But it’s impossible for me to say Gorton is the most hard-working font in the world.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tTo this title, there are many contenders. Garamond has a head start of 300+ years and has been released in more versions than letters in any alphabet. Helvetica is so famous and used so much that even its ugly copy, Arial, became a household name. Whatever font MS Office or a popular operating system appoint to be “the default” – from Times New Roman through Calibri to Roboto – immediately enjoys the world premiere that any Hollywood movie would be envious of. There is even a 5×7 pixel font originally started by Hitachi that you can see everywhere on cheap electronic displays in cash registers and intercoms.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut there is one place in the world where Gorton pulls triple duty, and I feel confident in saying at least this: Gorton is the hardest working font in Manhattan.\n\t</p><p>\t\t\t\t\t\t\n\t\tIn 2007, on my first trip to New York City, I grabbed my brand-new DSLR camera and photographed all the fonts I was supposed to love: American Typewriter, Helvetica, Gotham. But, in hindsight, I missed the most obvious one.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tGorton is everywhere in Manhattan. It’s there in the elevators, in the subway, on ambulances, in various plaques outside and inside buildings. And god knows it’s there on so, so many intercoms.\n\t</p><p>\t\t\t\t\t\n\t\tI wouldn’t be surprised if there weren’t a single block without any Gorton in a whole of Manhattan.\n\t</p><figcaption>A complete inventory of Gorton outside, near my hotel, between 5th and 7th avenues and 25th and 35th streets. I didn’t have access to the interiors of most buildings.</figcaption><p>\t\n\t\tThe omnipresence of Gorton makes it easy to collect all the type crimes layered on top of the font’s already dubious typographical origins. Walking through Manhattan, you can spot the abominable lowercase that should better be forgotten:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tYou can see all sorts of kerning mistakes:\n\t</p><p>\t\t\t\t\t\t\t\t\t\n\t\tYou will notice the many, many routing imperfections – an unfinished stroke, a shaky hand, or services of a pantograph that never felt the loving touch of regular maintenance:\n\t</p><p>\n\t\tThere are all the strange decisions to haphazardly mix various styles of Gorton, or even to mix Gorton with other fonts:\n\t</p><p>\t\t\t\t\t\t\t\t\t\t\t\n\t\tYou can even spot reappearing strange characters like a weirdly deep 3, or a flattened 4:\n\t</p><p>\n    I wish I understood how they came to be, but I have a hunch. The nature of pantographic reproduction is that Gorton carved into metal is not that far away from the original Gorton font template you started with! So in addition to the George Gorton and Taylor Hobson originals, and the other named and above-the-table copies, they might have been bigger or smaller Gorton . I have one myself, of unknown provenance and even more nameless than I thought possible for an already name-free font.\n  </p><p>\n\t\tBut New York Gorton holds pleasant surprises, too. Despite the simplicity of Gorton itself, the combinations of font sizes, cutter sizes, materials, reproductions, and applications can still yield some striking effects:\n\t\n\t</p><figcaption>\n\t\t\tAll my Gorton walks in Manhattan in 2024\n\t\t</figcaption>\n\n\t\tThis was what made me walk 100 miles. Over and over again, Gorton found ways to make itself interesting. Without hyperbole, I consider the above photos simply beautiful.\n\t<p>\n\t\tIn a city that never sleeps, Gorton wasn’t allowed to sleep, either. Even in the richest and most glamorous neighborhoods of Manhattan, the font would be there, doing the devil’s work without complaining. Gorton made Gotham feel bougie; American Typewriter touristy.\n\t</p><p>\n\t\tAnd once in a while, I’d find Gorton that would wink at me with a story –&nbsp;followed by that aching in the heart as I realized I’d never know what the story was.\n\t</p><p>\t\t\t\n\t\tYou’re not supposed to fall in love with an ugly font. No one collects specimens of Arial. No one gets into eBay fights for artifacts set in Papyrus. No one walks a hundred miles in a hot New York summer, sweating beyond imagination, getting shouted at by security guys, to capture photos of Comic Sans.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSo why do I love Gorton so much? \n\t</p><p>\t\t\t\t\t\t\t\n\t\tThe Occam’s Razor seems sharp on this one. Perhaps I like it because I’m a boy and Gorton is often attached to heavy machinery. \n\t</p><p>\t\t\t\t\n\t\tBut there must be more to it. Perhaps it’s all about the strange contrasts Gorton represents. The font is so ubiquitous, but also profoundly unrecognizable, sporting no designer and no name. Gorton is a decidedly toy-like, amateurish font deployed to for some of the most challenging type jobs: nuclear reactors, power plants, spacecraft. More than most other fonts, Gorton feels it’s been made by machines for machines –&nbsp;but in its use, it’s also the font that allows you to see so many human mistakes and imperfections.\n\t</p><p>\t\t\t\t\n\t\tGorton also feels mistake-friendly. The strange limitations of Gorton mean that some of the transgressions of other fonts don’t apply here. The monoline nature of the font means that messing with the size of Gorton is okay: Shrinking the font for small caps or superscript, for example, gives you still-valid letterforms, almost by accident. \n\t</p><p>\n\t\tStretching or slanting Gorton is not as much a typographical crime as it would be with other fonts because you don’t stretch the tip of the router itself.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tThere are genuinely moments where I felt Gorton gave people freedoms to maul it decades before variable fonts allowed us similar flexibility.\n\t\tAnd on top of that, the simplicity of the letterforms themselves feels compatible with the typical naïveté of Gorton’s typesetting. \n\t</p><figcaption>Various accessories and attachments allowing you to shift Gorton around in a way other fonts would not allow</figcaption><p>\n    Sure, there are really bad renditions that are inexcusable. \n\n\t\tBut most of the time, the imperfections and bad decisions are what makes Gorton come alive. They don’t feel like a profound misunderstandings of typography, typesetting, or Gorton itself. They don’t feel like abuses or aberrations. No, they feel exactly how Gorton was supposed to be used – haphazardly, without much care, to solve a problem and walk away. (Later routing fonts copied Helvetica, but seeing Helvetica in this context with all the same mistakes grates so much more.)\n\t</p><p>\t\t\t\n\t\tThe transgressions are not really transgressions. They all feel honest. The font and its siblings just show up to work without pretense, without ego, without even sporting a nametag. Gorton isn’t meant to be admired, celebrated, treasured. It’s meant to do some hard work and never take credit for it. Gorton feels like it was always a font, and never a typeface. (Depending on how rigid you are with your definitions, some versions of Gorton – especially those without instructions on how letters are positioned against each other – might not even <a target=\"_blank\" href=\"https://mastodon.design/@fhardwig@mastodon.social/113515144112560218\">classify as a font</a>!)\n\t</p><p>\t\t\t\t\t\n\t\tAnd I think I love Gorton because over the years I grew a little tired of the ultra flat displays rendering miniature pixels with immaculate precision. \t\n\t\tWith Gorton, carving into metal or plastic means good-looking fixes are impossible:\n\t</p><p>\n\t\tAnd unsurprising given its roots, Gorton has dimensionality that most fonts cannot ever enjoy: A routing tip picked in the 1980s and a sun coming in from just the right angle forty years later can create a moment that thousands of letterpress cards can only dream of.\n\t</p><p>\n\t\tPerhaps above everything else, Gorton is all about . \n  </p><p>\n    Every kind of engraving has it, of course. But these are not precise submillimeter letters at the bottom of your MacBook Pro or Apple Watch. This is the utilitarian, often harried, sometimes downright  Gorton, carved into steel of a  \n\t\tmid-century intercom and filled in with <a target=\"_blank\" href=\"https://youtu.be/llzdLgMurvw?si=8S7px9gg8iH4iav2&amp;t=101\">special paste or wax</a>, or put on an office placard made out of a special two-layer material made especially so engraving it reveals the second color underneath, without the need for infill. \n\t</p><p>\t\t\t\n\t\t(This is also true when it comes to the original reason I learned of Gorton. Letters on keycaps show the same artifacts – you just have to look very, very closely.)\n\t</p><p>\n\t\tThat’s the last, and perhaps the best thing to fall in love with. \n\t</p><p>\n\t\tYou won’t be able to fully appreciate it here, of course, but maybe this will give an approximation of how beautiful Gorton’s non-beauty can be:\n\t</p><p>\t\t\t\t\t\n\t\tThis has been a strange thing to write. Gorton has been around for over 135 years and used in so many countries for so many reasons, and yet I found no single article about it. \n\t</p><p>\t\t\t\t\t\n\t\tI feel the burden of being an amateur historian, wanting to know and share so much more, but only being able to provide little. I don’t know the full extent of Gorton’s use. I don’t know who designed it. My chronology is rickety and pieced together from a few breadcrumbs. I dream of seeing the original drawings or drafts once laid on the tables of Taylor, Taylor &amp; Hobson offices, or some notes, or some correspondence. I fear they might no longer exist.\n\t</p><p>\t\t\t\t\t\n\t\tAlso, if part of the allure of Gorton is shying away from the limelight and not being admired, am I doing it a disservice by writing about it?\n\t</p><p>\t\t\t\t\t\n\t\tBut mostly, I can’t shake the feeling that we all missed a window. That this essay can’t be just a celebration, but also needs to be the beginnings of a eulogy.\n\t</p><p>\t\t\t\t\t\n\t\tWalking around New York, you get a sense that even Gorton carved into metal can disappear. Some of the signs are rusted or destroyed beyond repair. Others get replaced by more modern, charmless equivalents.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tGorton itself is obsolete. All <a target=\"_blank\" href=\"https://spkeyboards.com/\">the keyboards that use Gorton Modified</a> you can still buy new today are tipping a hat to nostalgia. The omnipresence of Gorton in New York City is already time shifted from its decades of glory, a simple confirmation of what Robert Moses knew so well: that once built, cities don’t change all that much. But few of the new placards use Gorton, and none of the new intercoms do. \n\t</p><p>\n\t\tTaylor, Taylor &amp; Hobson went through multiple splits and mergers and survives as a subsidiary of Ametek, chiefly working on measuring devices. George Gorton Machine Co. from Racine has been bought by Kearny &amp; Trecker, which became Cross &amp; Trecker, was acquired by Giddings &amp; Lewis, and then acquired  by ThyssenKrupp, but not before the Gorton branch was spun off as Lars, and in a sequence of events now resembling a telenovella, eventually bought by Famco in 1987. I do not believe any corporate grandchildren of TT&amp;H and George Gorton’s company are today selling Gorton in any capacity.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tIt will take decades, perhaps even centuries, but one day the last of this font will be gone. The modern recreations (<a target=\"_blank\" href=\"https://aresluna.org/the-hardest-working-font-in-manhattan/the-hardest-working-font-in-manhattan/recreations\">I eventually found quite a few</a>) won’t help. They are perhaps all missing a point, anyway.\n\t</p><p>\n\t\tBut there’s a somewhat silver lining. Yes, when Gorton is carved into fresh metal, there might be nothing more pretty than seeing its depths glistening in the sun.\n\t</p><p>\n\t\tBut fresh, shining metal is at this point rare. Fortunately, the Gorton I love most is the weathered Gorton.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tManhattan’s tired Gorton is the best variant of Gorton: infill cracked by hot summers followed by frigid winters, the surface scratched by keys or worn out by many finger presses, the routing snafus meeting decades of wear and tear. Gorton’s no stranger to water, snow, rust, or dirt.\n\t</p><p>\t\t\n\t\tThis is, perhaps, how you become gortonpilled. You learn to recognize the 7 with a crooked hook, the Q with a swung dash, the strange top-heavy 3, the simple R. You start noticing the endings of each character being consistently circular, rather than occasionally flat. A routing mistake, suspicious kerning, or the absence of lowercase are not a wrongdoing – they’re a .\n\t</p><p>\t\t\t\t\t\t\t\n\t\tYou find yourself enchanted with how this simple font went so very far. And then you touch the letters, just to be sure. If you can  them, chances are this is Gorton.\t\t\n\t</p>","contentLength":38044,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053419"},{"title":"Ask HN: What is the best method for turning a scanned book as a PDF into text?","url":"https://news.ycombinator.com/item?id=43048698","date":1739543575,"author":"resource_waste","guid":824,"unread":true,"content":"I like reading philosophy, particularly from the authors rather than a secondhand account.<p>However I often run into that these come as scanned documents, Discourses on Livy and Politics Among Nations for example.</p><p>I would greatly benefit from turning these into text. I can snipping tool pages and put them in ChatGPT and it turns out perfect. If I used classic methods, it often screws up words. My final goal is to turn these into audiobooks, (or even just make it easier to copypaste for my personal notes)</p><p>Given the state of AI, I'm wondering what my options are. I don't mind paying.</p>","contentLength":584,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43048698"},{"title":"Show HN: Transform your codebase into a single Markdown doc for feeding into AI","url":"https://tesserato.web.app/posts/2025-02-12-CodeWeaver-launch/index.html","date":1739539403,"author":"tesserato","guid":450,"unread":true,"content":"<p>CodeWeaver is a command-line tool designed to weave your codebase into a single, easy-to-navigate Markdown document. It recursively scans a directory, generating a structured representation of your project's file hierarchy and embedding the content of each file within code blocks. This tool simplifies codebase sharing, documentation, and integration with AI/ML code analysis tools by providing a consolidated and readable Markdown output.\nThe output for the current repository can be found <a href=\"https://github.com/tesserato/CodeWeaver/blob/main/codebase.md\">here</a>.</p><ul><li><strong>Comprehensive Codebase Documentation:</strong> Generates a Markdown file that meticulously outlines your project's directory and file structure in a clear, tree-like format.</li><li> Embeds the complete content of each file directly within the Markdown document, enclosed in syntax-highlighted code blocks based on file extensions.</li><li>  Utilize regular expressions to define ignore patterns, allowing you to exclude specific files and directories from the generated documentation (e.g., , build artifacts, specific file types).</li><li> Choose to save lists of included and excluded file paths to separate files for detailed tracking and debugging of your ignore rules.</li><li><strong>Simple Command-Line Interface:</strong>  Offers an intuitive command-line interface with straightforward options for customization.</li></ul><p>If you have Go installed, run <code>go install github.com/tesserato/CodeWeaver@latest</code>to install the latest version of CodeWeaver or <code>go install github.com/tesserato/CodeWeaver@vX.Y.Z</code> to install a specific version.</p><p>Alternatively, download the appropriate pre built executable from the <a href=\"https://github.com/tesserato/CodeWeaver/releases\">releases page</a>.</p><p>If necessary, make the  executable by using the  command:</p><table><thead><tr></tr></thead><tbody><tr><td>The root directory to scan and document.</td></tr><tr><td>The name of the output Markdown file.</td></tr><tr><td><code>-ignore \"&lt;regex patterns&gt;\"</code></td><td>Comma-separated list of regular expression patterns for paths to exclude.</td></tr><tr><td><code>-included-paths-file &lt;filename&gt;</code></td><td>File to save the list of paths that were included in the documentation.</td></tr><tr><td><code>-excluded-paths-file &lt;filename&gt;</code></td><td>File to save the list of paths that were excluded from the documentation.</td></tr><tr><td>Display this help message and exit.</td></tr></tbody></table><h2><strong>Generate documentation for the current directory:</strong></h2><p>This will create a file named  in the current directory, documenting the structure and content of the current directory and its subdirectories (excluding paths matching the default ignore pattern ).</p><h2><strong>Specify a different input directory and output file:</strong></h2><pre><code>./codeweaver -dir=my_project -output=project_docs.md\n</code></pre><p>This command will process the  directory and save the documentation to .</p><h2><strong>Ignore specific file types and directories:</strong></h2><pre><code>./codeweaver -ignore=\"\\.log,temp,build\" -output=detailed_docs.md\n</code></pre><p>This example will generate , excluding any files or directories with names containing , , or . Regular expression patterns are comma-separated.</p><h2><strong>Save lists of included and excluded paths:</strong></h2><pre><code>./codeweaver -ignore=\"node_modules\" -included-paths-file=included.txt -excluded-paths-file=excluded.txt -output=code_overview.md\n</code></pre><p>This command will create  while also saving the list of included paths to  and the list of excluded paths (due to the  ignore pattern) to .</p><p>Contributions are welcome! If you encounter any issues, have suggestions for new features, or want to improve CodeWeaver, please feel free to open an issue or submit a pull request on the project's GitHub repository.</p><p>CodeWeaver is released under the <a href=\"https://tesserato.web.app/posts/2025-02-12-CodeWeaver-launch/LICENSE\">MIT License</a>. See the  file for complete license details.</p>","contentLength":3311,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43048027"},{"title":"Show HN: A New Way to Learn Languages","url":"https://www.langturbo.com/","date":1739534938,"author":"sebnun","guid":449,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43047554"},{"title":"OpenVINO AI effects [denoising and transcription] for Audacity","url":"https://www.audacityteam.org/blog/openvino-ai-effects/","date":1739531946,"author":"wazoox","guid":748,"unread":true,"content":"<div><h2>Introducing OpenVINO AI effects for Audacity</h2></div><p>Intel has built a suite of AI tools for Audacity, useful for spoken word audio and music alike. These AI features run 100% locally on your PC.</p><p>For spoken word content, the OpenVINO effects contain a noise supression and a transcription plugin.</p><p>The  does what it says on the tin - it suppresses noise. As such it behaves similar to Audacity’s built-in Noise Removal effect.</p><p>The  powered by <a href=\"https://github.com/ggerganov/whisper.cpp\">Whisper.cpp</a> can both transcribe and translate words and outputs to a label track. If you want to export these transcriptions, you can do so via File → Export Other → Export Labels.</p><p>For music, both generation and separation plugins are part of the OpenVINO effects.</p><p> and  use Stable Diffusion (and <a href=\"https://github.com/riffusion/riffusion\">Riffusion</a> in particular) to generate new music from a prompt, or based on pre-existing music, respectively.</p><p> can split a song into either it’s vocal and instrumental parts, or into vocals, drums, bass and a combined “anything else” part. This is ideal for creating covers and playalongs.</p><h2>Download and installation</h2><p>Currently, only a Windows version is available for download. The project may be <a href=\"https://github.com/intel/openvino-plugins-ai-audacity/blob/main/doc/build_doc/linux/README.md\">compiled on Linux</a> and macOS, though no instructions are available for the latter yet.</p><p>If you have any questions or comments, feel free to post them to the plugin’s <a href=\"https://github.com/intel/openvino-plugins-ai-audacity/issues\">issue tracker</a>.</p>","contentLength":1307,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43047255"},{"title":"Show HN: SQL Noir – Learn SQL by solving crimes","url":"https://www.sqlnoir.com/","date":1739483356,"author":"chrisBHappy","guid":448,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43041827"},{"title":"AI can interpret animal emotions better than humans","url":"https://www.science.org/content/article/can-ai-read-pain-and-other-emotions-your-dog-s-face","date":1739481396,"author":"marojejian","guid":714,"unread":true,"content":"\n<p>Article URL: <a href=\"https://www.science.org/content/article/can-ai-read-pain-and-other-emotions-your-dog-s-face\">https://www.science.org/content/article/can-ai-read-pain-and-other-emotions-your-dog-s-face</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43041477\">https://news.ycombinator.com/item?id=43041477</a></p>\n<p>Points: 77</p>\n<p># Comments: 33</p>\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bezos' Blue Origin to layoff about 10% across its space, launch business","url":"https://www.cnbc.com/2025/02/13/bezos-blue-origin-to-layoff-about-10percent-across-its-space-launch-business-.html","date":1739463969,"author":"pinewurst","guid":608,"unread":true,"content":"\n<p>Article URL: <a href=\"https://www.cnbc.com/2025/02/13/bezos-blue-origin-to-layoff-about-10percent-across-its-space-launch-business-.html\">https://www.cnbc.com/2025/02/13/bezos-blue-origin-to-layoff-about-10percent-across-its-space-launch-business-.html</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43037652\">https://news.ycombinator.com/item?id=43037652</a></p>\n<p>Points: 86</p>\n<p># Comments: 63</p>\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Explaining my fast 6502 code generator (2023)","url":"https://pubby.games/codegen.html","date":1739460897,"author":"zdw","guid":1651,"unread":true,"content":"\n<p>Article URL: <a href=\"https://pubby.games/codegen.html\">https://pubby.games/codegen.html</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43036903\">https://news.ycombinator.com/item?id=43036903</a></p>\n<p>Points: 81</p>\n<p># Comments: 16</p>\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sri Lanka scrambles to restore power after monkey causes islandwide outage","url":"https://www.reuters.com/world/asia-pacific/sri-lanka-scrambles-restore-power-after-monkey-causes-islandwide-outage-2025-02-13/","date":1739454445,"author":"abe94","guid":501,"unread":true,"content":"\n<p>Article URL: <a href=\"https://www.reuters.com/world/asia-pacific/sri-lanka-scrambles-restore-power-after-monkey-causes-islandwide-outage-2025-02-13/\">https://www.reuters.com/world/asia-pacific/sri-lanka-scrambles-restore-power-after-monkey-causes-islandwide-outage-2025-02-13/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43035760\">https://news.ycombinator.com/item?id=43035760</a></p>\n<p>Points: 152</p>\n<p># Comments: 101</p>\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Beginnings of Roman London discovered in office basement","url":"https://www.bbc.com/news/articles/cx2jdnv0ywyo","date":1739421986,"author":"petethomas","guid":671,"unread":true,"content":"\n<p>Article URL: <a href=\"https://www.bbc.com/news/articles/cx2jdnv0ywyo\">https://www.bbc.com/news/articles/cx2jdnv0ywyo</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43032759\">https://news.ycombinator.com/item?id=43032759</a></p>\n<p>Points: 125</p>\n<p># Comments: 28</p>\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: I made my own OS from scratch because I was bored","url":"https://jotalea.com.ar/misc/jotaleaos/","date":1739393712,"author":"Jotalea","guid":447,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43029686"},{"title":"Show HN: yknotify – Notify when YubiKey needs touch on macOS","url":"https://github.com/noperator/yknotify","date":1739391899,"author":"noperator","guid":446,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43029385"},{"title":"Show HN: A no-build fullstack SSR TypeScript web framework","url":"https://jsr.io/@fullsoak/fullsoak","date":1739390092,"author":"thesephi","guid":445,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43029089"},{"title":"Show HN: Game Bub – open-source FPGA retro emulation handheld","url":"https://eli.lipsitz.net/posts/introducing-gamebub/","date":1739380285,"author":"elipsitz","guid":444,"unread":true,"content":"<p>I’m excited to announce the project I’ve been working on for the last year and a half: , an open-source FPGA based retro emulation handheld, with support for Game Boy, Game Boy Color, and Game Boy Advance games.</p><p>Game Bub can play physical cartridges, as well as emulated cartridges using ROM files loaded from a microSD card. Game Bub also supports the <a href=\"https://en.wikipedia.org/wiki/Game_Link_Cable\">Game Link Cable</a> in both GB and GBA modes for multiplayer games. I designed the hardware with a number of bonus features, like video out (HDMI) via a custom dock, a rumble motor, real-time clock (for certain games). Additionally, the hardware is designed with extensibility in mind, allowing future software improvements to expand its capabilities.</p><p>Game Bub has a custom-designed 6 layer PCB featuring a Xilinx XC7A100T FPGA with integrated memory,  display, speakers, rechargable battery, GB/GBA cartridge slot, all packaged up in a custom 3D-printed enclosure.</p><p>Check out the instructions, code, and design files <a href=\"https://github.com/elipsitz/gamebub\">on GitHub</a>. Note that building a Game Bub unit is fairly complex. If you might be interested in buying a complete Game Bub kit, please <a href=\"https://forms.gle/m1FFUqpCde7x5u5AA\">fill out this form</a> to help me gauge interest.</p><p>I had a lot of fun implementing a Game Boy at the hardware level, and I started thinking about how far I could take the project. I was using a Pynq-Z2 development board, which was definitely the right way to get started, but it came with a lot of limitations.</p><p>I had to use an external monitor for audio/video, and an external gamepad for input, but a real Game Boy, of course, is a portable handheld. I also wanted to add Game Boy Advance support, but the memory architecture of the Pynq-Z2 had access latency that <a href=\"https://eli.lipsitz.net/posts/fpga-gameboy-emulator/#fixing-an-audio-bug-on-the-game-boy-color\">was just barely acceptable for the Game Boy</a>, and would have been completely unacceptable for the Game Boy Advance. I also wanted to make something less “hacky”: a real device that I could play and give to people, not just a bare PCB.</p><p>Furthermore, while there are open-source FPGA retrogaming projects (e.g. <a href=\"https://en.wikipedia.org/wiki/MiSTer\">MiSTer</a>), there doesn’t appear to be anything open-source that supports physical Game Boy and Game Boy Advance cartridges, let alone an open-source handheld device.</p><p>Thus, I somewhat naively set out to design what would become by far my most complex electrical engineering and hardware design project to date.</p><p>I set out some goals for the project:</p><ul><li>Build a standalone, rechargable battery-powered FPGA handheld</li><li>Minimize cost and complexity by using off-the-shelf components wherever possible</li><li>Capable of playing Game Boy, Game Boy Color, and Game Boy Advance games</li><li>Capable of using physical cartridges, or emulating cartridges (reading ROM files off of a microSD card)</li><li>Easy to use: graphical menu and in-game overlay</li><li>Integrated display and speakers, with headphone support</li><li>Integrated peripherals (rumble, real-time clock, accelerometer) for emulated cartridges</li><li>HDMI video output support for playing on a big screen</li><li>Decent looking design with good ergonomics</li><li>Expansion opportunities in the future: support for more systems, Wi-Fi, etc.</li></ul><p>And finally, since I was building this project for fun and learning, I wanted to be able to fully understand every single component of the system. I wanted to use my own emulator cores (e.g. not just port them from <a href=\"https://mister-devel.github.io/MkDocs_MiSTer/\">MiSTer</a>), do my own board design, and write my own drivers to interface with peripherals.</p><h3>A brief rant about FPGA retrogaming<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#a-brief-rant-about-fpga-retrogaming\">#</a></h3><p>There’s a lot of misleading marketing and hype out there around FPGA retrogaming. Some claim that FPGA retrogaming devices are not emulators (because they supposedly “act like [the system] at the gate level”), that they achieve “perfect accuracy”, or that they’re superior to software emulators.</p><p>In my opinion, this is blatantly wrong and actively harmful. FPGA retrogaming devices are emulators: they pretend to be something they’re not. And they’re only as accurate as they’re programmed to be, since they’re recreations. An FPGA can make certain aspects of accuracy easier to achieve, but it doesn’t guarantee it.</p><p>Software emulators can be extremely accurate. Furthermore, perfect accuracy (if it’s even possible) is by no means a requirement to play an entire system’s library of games. Some people claim that FPGA emulators are the only way to “preserve” a system, but I’d argue that software emulators are a significantly more accessible (no special hardware needed!) way to further this goal.</p><p>I believe that FPGA emulators have only one real advantage over software emulators: they can more easily interface with original hardware, such as physical cartridges or other consoles via link cables.</p><p>I did this project not because I think that FPGA emulators are inherently better than software emulators, but because I think they’re interesting and fun to build.</p><p>I began work on the project by doing some initial research and sketching out a high level design.</p><p>My previous FPGA emulator project used a Xilinx Zynq chip, which integrates FPGA fabric (“PL”) with a dual-core ARM processor running Linux (“PS”). I implemented the entire emulator on the FPGA, and used the Linux system to configure the FPGA, render the UI, and load ROM files from the filesystem.</p><p>I decided to keep this same division of responsibilities: using the FPGA to do the core emulation, with a separate processor to do support tasks. However, to make the overall design easier to reason about, I decided to to use an FPGA-only chip (without any hard processor cores), and an external microcontroller (MCU) to do the tasks that the ARM cores did before.</p><p>The FPGA would consume input, directly interface to the game cartridges (through level shifters to support both the 3.3 volt GBA and 5 volt Game Boy), and output audio and video to the speakers and display. The MCU would handle the UI, read ROM files from the microSD card, initialize peripherals (display, DAC, IMU), handle power sequencing, and load the FPGA configuration.</p><p>I wanted to have Wi-Fi and Bluetooth support: Wi-Fi for software updates, and the possibility of emulating the <a href=\"https://en.wikipedia.org/wiki/Game_Boy_Advance_Wireless_Adapter\">Game Boy Advance Wireless Adapter</a>, and Bluetooth to support wireless game controllers (when connected to an external display). To reduce complexity (and avoid the need for careful RF design), I looked only for complete Wi-Fi/Bluetooth modules with integrated antennas.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/early-block-diagram.svg\" alt=\"An early block diagram I sketched out\"><figcaption><p>An early block diagram I sketched out</p></figcaption></figure><p>I also drew out rough sketches of what the final device might look like: placement of buttons, screen, speakers, ports, cartridge slot, and battery. I settled on a vertical Game Boy Color-esque design (as opposed to a horizontal Game Boy Advance-style design), because I felt that this would maximize the space in the back of the device for full-size Game Boy Color cartridges and a battery.</p><p>After sketching out the goals and high level design, I started component selection: picking out each non-trivial component of the system, evaluating features and requirements (e.g. how they communicate, power consumption and voltages needed).</p><p>Since I intended to have this manufactured and assembled at JLCPCB, I strongly preferred parts that were available in their part library. One technique I even used for narrowing down part choices was finding the relevant category in their part search, and sorting by their stock count.</p><p>I initially planned to use an <a href=\"https://en.wikipedia.org/wiki/RP2040\">RP2040</a> microcontroller, with a separate ESP32-WROOM module to support Wi-Fi and Bluetooth.</p><p>The ESP32 supports both Bluetooth Classic and LE, which is essential for supporting a wide range of controllers, and the RP2040 has USB host support, to support wired controllers.</p><p>During the schematic design process, I ended up simplifying the RP2040 + ESP32 combination to just a single ESP32-S3 module for a few reasons:</p><ul><li>I started running out of GPIOs on the RP2040, and I was dedicating 4 of them (2 for UART, 1 for reset, 1 for booting in firmware download mode) to communication with the ESP32. Plus, the ESP32-S3 has more GPIOs overall.</li><li>I wanted to write the MCU firmware in Rust, and the ESP32-S3 had support for the Rust standard library (via ESP-IDF and <a href=\"https://github.com/esp-rs/esp-idf-hal\">esp-idf-hal</a>). This seemed like it would be easier to get the software up and running.</li><li>Fewer components means easier routing and assembly</li><li>The ESP32-S3 has an SDIO module (for interfacing with the microSD card), and FAT filesystem support (via ESP-IDF). It would be possible to do this with the RP2040 PIO, but having a proper peripheral and driver for this makes it a lot easier.</li><li>The ESP32-S3 is more powerful than the RP2040, and would probably be able to render a smoother UI.</li></ul><p>However, the ESP32-S3 has one main disadvantage compared to the original ESP32: it doesn’t have Bluetooth Classic support, only LE. This would greatly limit the range of supported wireless controllers, but I believed the compromise was worth it. I also decided to scrap USB host support, because supporting USB-C dual role (switchable device or host) would have added a lot of additional complexity.</p><p>If the RP2350 microcontroller (the successor to the RP2040) had been available when I started this project, I may very well have chosen it, since it has even more power, PIO blocks, memory, and GPIO pins. I might have paired it with an RM2 radio module for Wi-Fi and Bluetooth.</p><p>I wanted a display that would support integer scaling for the Game Boy Advance, which has a 240x160 pixel screen. I was also looking for a screen roughly on the order of 3.0-3.5 inches wide (diagonal), to be comfortable to hold in the hand.</p><p>I found the ER-TFT035IPS-6 LCD module from <a href=\"https://www.buydisplay.com/\">EastRising</a>, with a 3.5 inch display, and a 320x480 pixel resolution. This allows for a 2x integer scale for the Game Boy Advance (and a 2x scale plus centering for the 160x144 Game Boy display). This checked off almost all of the boxes: integer scaling, a good size, available at a reasonable price, pretty good documentation (for the ILI9488 LCD controller).</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/er-tft035ips-6.jpg\" alt=\"ER-TFT035IPS-6 LCD module\" width=\"1000\" height=\"550\"><figcaption><p>ER-TFT035IPS-6 LCD module</p></figcaption></figure><p>The main issue, which actually ended up being fairly annoying, is that it’s a 320x480 display, not 480x320. Meaning, it’s oriented in portrait mode, not landscape. I rotated the device 90 degrees to fit in a landscape orientation, but this created two issues:</p><ul><li>In landscape orientation, the bottom of the display (containing the LCD driver chip and the flex cable) faces to the left or the right, which means that larger bazels are required on the left and right of the display to center the “active area” of the LCD within the handheld.</li><li>In landscape orientation, the display refreshes from left to right, not top to bottom.</li></ul><p>The problem with refreshing from left to right is that the Game Boy and Game Boy Advance (and almost every other system) refresh from top to bottom. This means that the display can’t be refreshed perfectly in sync with the game (zero buffering), and single buffering leads to unsightly diagonal tearing. Instead, I had to use triple buffering, where the game is writing to one framebuffer, the LCD driver is reading from another buffer, and there’s one spare swap buffer. This increases the amount of memory used – and because it needed to be accessed by both the game and LCD driver simultaneously (dual port), it needed to be stored in internal block RAM in the FPGA, a scarce resource.</p><p>So, even though the Game Boy emulator uses &lt;10% of the total logic resources of the FPGA, and the Game Boy Advance uses around 30%, I had to use a large (more expensive, and power hungry) FPGA so that I had enough block RAM.</p><p>I also stuck a standard size HDMI port into the design, connected directly to the FPGA. HDMI has a few additional, non-video signals that need level shifting from 5V to 3.3V (I opted for discrete transistors), and it requires the source (me!) to supply a small amount of power.</p><p>I had never previously designed anything that used a lithium ion battery, so I had a fair amount of learning to do. <a href=\"https://learn.adafruit.com/li-ion-and-lipoly-batteries/overview\">Adafruit</a> was a helpful resource. I needed a way to charge the battery from USB power, and a way to measure how charged it is.</p><p>Lithium ion batteries can be dangerous if misused. Safely charging a battery is non-trivial, and requires a feedback loop and adjustable voltage sources. A dedicated IC seemed like the best way to do this. A lot of hobbyists use the ultra-cheap TP4056 1A battery charger, but I’d read about a lot of issues it has around safely charging the battery while using it. I decided instead to opt for the <a href=\"https://www.ti.com/lit/ds/symlink/bq24073.pdf\">TI BQ2407x</a> series of battery charger ICs. They seem to be widely used in commercial products, came with a comprehensive datasheet, and had a few critical features: programmable input and charge current limits, safety timers, and “power path management” for safely charging the battery while the device is on.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/lipo-discharge-curve.png\" alt=\"Typical discharge curve for a 3.7V lipo battery (source: Adafruit)\" width=\"579\" height=\"402\"><figcaption><p>Typical discharge curve for a 3.7V lipo battery (source: <a href=\"https://learn.adafruit.com/assets/979\">Adafruit</a>)</p></figcaption></figure><p>There are a few ways to measure the charge level of the battery, which generally relies on the fact that a lithium ion battery’s voltage depends on its charge level. A fully charged battery is about 4.2 volts, a battery with between 80% and 20% charge is about 3.7 volts, and below that a drained battery falls off pretty quickly to under 3.0 volts. If all you want is a coarse estimate of the battery level, you can use an ADC to read the voltage and estimate whether the battery is fully charged or nearly discharged. However, since the voltage curve is nearly flat between 20% and 80% charge (and is also dependent on the load), this can’t give the fine-grained battery percentage that we’re used to on phones and laptops. Instead, I opted for a discrete fuel gauge IC, the <a href=\"https://www.analog.com/en/products/max17048.html\">MAX17048</a>. It’s simple to integrate and inexpensive.</p><p>I decided to use a push button for the main power switch, because I needed to be able to do a graceful shutdown, where the microcontroller could save state (e.g. the current save file for an emulated cartridge) before it actually powered off.</p><p>I briefly considered using an ultra-low power, always on microcontroller to act as a custom <a href=\"https://en.wikipedia.org/wiki/Power_management_integrated_circuit\">PMIC</a> to provide power switch functionality (and perhaps avoid the need for a separate real-time clock IC, and even a battery gauge). While this would have been flexible and really cool, I figured it wasn’t worth the additional complexity.</p><p>The main system power ranges from about 3.4 V when the battery is discharged, to 4.2 V when the battery is fully charged, up to 5.0 V when the device is plugged in with USB.</p><p>The ESP32-S3 module required 3.3 V, and most of the other ICs in the system did too. The main exception is the FPGA, which requires a 1.0 V core power rail, a 1.8 V “auxiliary” power rail, and a 3.3 V power rail for I/O. Moreover, according to the <a href=\"https://docs.amd.com/v/u/en-US/ds181_Artix_7_Data_Sheet\">Xilinx Artix-7 datasheet (DS181)</a>, these power rails need to be powered on in a particular sequence: for my use, this means 1.0 V, then 1.8 V, then 3.3 V. Additionally, I needed a 5.0 V supply to interface with Game Boy / Game Boy Color cartridges.</p><p>There are multi-rail power regulators available, and a lot of FPGA development boards use them. However, they all seemed to be expensive and difficult to purchase in low quantities. Instead, I opted for separate power regulators for each rail. I used <a href=\"https://en.wikipedia.org/wiki/Buck_converter\">buck converters</a> instead of <a href=\"https://en.wikipedia.org/wiki/Linear_regulator\">linear regulators</a> to maximize power efficiency.</p><p>I used the <a href=\"https://www.ti.com/product/TLV62585\">TLV62585</a> converter for the 3.3 V, 1.8 V, and 1.0 V rails. This is a simple, performant buck converter with a “power good” output, which is useful for power sequencing: you can connect the  output of one regulator to the  pin of the next regulator, to power on the rails in the desired order.</p><p>For the 5.0 V rail, I used the <a href=\"https://www.ti.com/product/TPS61022\">TPS61022</a> boost converter. This converter is way overkill for the 5.0 V rail (which might use 75mA ), but it was readily available, and conveniently compatible with the same 1µH inductor as the buck converters.</p><p>According to the FPGA datasheet, the XC7A100T consumes more than 100mW of static power. That is, it consumes that as long as it’s connected to power, even if it’s doing absolutely nothing. I figured I might want to support a low power sleep mode, so I decided to split the FPGA into a separate power domain with an explicit power enable signal from the MCU. I also used an <a href=\"https://www.diodes.com/datasheet/download/AP2191.pdf\">AP2191W</a> load switch for the FPGA’s 3.3 V rail to be able to keep the 1.0 V → 1.8 V → 3.3 V sequencing.</p><p>I wanted the device to have both speakers and a 3.5mm headphone jack. Ultimately, the FPGA generates an <a href=\"https://en.wikipedia.org/wiki/I%C2%B2S\">I2S</a> digital audio signal, and I needed a <a href=\"https://en.wikipedia.org/wiki/Digital-to-analog_converter\">DAC</a> to convert it to an analog audio signal, and then an amplifier to drive the speakers (or headphones). I wanted digital volume control (to support volume buttons, rather than a volume knob or slider), and I needed some way to switch the audio output between speakers and the headphones, depending on whether or not headphones are plugged in. With no real audio experience, this seemed like a daunting task.</p><p>While searching for multiple separate components, I stumbled upon the <a href=\"https://www.ti.com/product/TLV320DAC3101\">TLV320DAC3101</a>. It combines a stereo DAC with a speaker amplifier and a headphone driver. Additionally, it supports digital volume control, and headphone detection. I think this chip is a good example of how thoughtful component selection can simplify the overall design. Looking through the datasheet, it required a 1.8 V core voltage (unlike essentially every other component other than the FPGA) and a fair amount of configuration registers to set over I2C, but it had all of the features I needed.</p><p>I was originally planning to have just a single (mono) speaker, but I figured if I had a stereo DAC, I might as well put two in there. I chose the <a href=\"https://www.sameskydevices.com/product/audio/speakers/miniature-(10-mm~40-mm)/ces-20134-088pmb\">CES-20134-088PMB</a>, an enclosed microspeaker with a JST-SH connector. Having an enclosed speaker simplified audio design, because as it turns out, you can’t just stick a speaker to a board and expect it to sound okay (Same Sky, the manufacturer of that speaker, <a href=\"https://www.sameskydevices.com/blog/how-to-design-a-micro-speaker-enclosure\">has a blog post explaining some of the nuances</a>).</p><p>I prefer the feeling of clicky, tactile buttons (such as those found in the GBA SP, Nintendo DS (original), Nintendo 3DS, Switch) compared to “mushy” membrane buttons (such as those found in the Game Boy Color, original GBA, and Nintendo DS Lite). I learned that the tactile switches used in the GBA SP are a <a href=\"https://tech.alpsalpine.com/e/products/detail/SKRRAAE010/\">widely available off-the-shelf part from Alps Alpine</a>. I used similar, but smaller buttons for the Start/Select/Home buttons, and a right-angle button from the same manufacturer for side volume and power buttons.</p><p>Although I only had plans to support Game Boy and Game Boy Advance (requiring a D-pad, A and B buttons, L and R shoulder buttons, and Start/Select), I opted to add two more “X” and “Y” face buttons to leave the possibility open of supporting more systems in the future.</p><p>The L and R buttons posed an additional challenge – I found numerous right-angle tactile buttons (to be soldered onto the back, facing towards the top). However, none of them seemed to have the actuator (the part of the button you make contact with) far enough away from the PCB to be easily pressed. At first, I thought about making a separate shoulder button board to move them at the correct distance, but then I started looking at what existing devices do for inspiration. The Game Boy Advance SP actually uses a more complex mechanism for the shoulder buttons: rather than a simple actuator like the face buttons, there’s a hinge with a <a href=\"https://en.wikipedia.org/wiki/Torsion_spring\">torsion spring</a> that hits the actuator at an angle. This is actually part of what makes the shoulder buttons pleasant to press: you don’t need to hit them from exactly the right direction, because they pivot. I ended up just going with a standard right-angle tactile button, opting to solve the problem with the mechanism in the enclosure.</p><figure><figcaption><p>GBA SP shoulder button mechanism</p></figcaption></figure><p>One of my main goals was to allow ROM files to be loaded from a microSD card, rather than only being able to be played from a physical cartridge. To do this, I’d need dedicated RAM for the FPGA to hold the game. Game Boy Advance games, typically, are a maximum of 32 MB. They don’t make SRAMs that large (and if they did, they’d be very expensive). Instead, I needed to use <a href=\"https://en.wikipedia.org/wiki/Dynamic_random-access_memory\">DRAM</a>.</p><p>Asynchronous SRAM is very simple: supply a read address to the address pins, and some amount of nanoseconds later, the data you’re reading appears on the data pins. DRAM is more complex: the simplest kind is “single data rate synchronous DRAM” (SDR SDRAM, or just <a href=\"https://en.wikipedia.org/wiki/Synchronous_dynamic_random-access_memory\">SDRAM</a>, distinguishing it from the significantly more complex DDR SDRAM). However, even SDRAM is non-trivial to use. DRAM is organized into banks, rows, and columns, and accessing DRAM requires sending commands to “activate” (open) a row before reading out “columns”, and then “precharging” (closing) a row. Handling all of this requires a DRAM controller (see this <a href=\"https://www.fpga4fun.com/SDRAM2.html\">simple description of the state machine</a> required). This isn’t terribly complex, but I was signing myself up for more work.</p><p>Alternatively, I could have chosen a PSRAM chip (essentially DRAM with an integrated controller to make it have a more SRAM-like interface). However, I couldn’t find a PSRAM part that I was happy with (cost, availability, interface), and so I ended up going with the inexpensive W9825G6KH 32MB 16-bit SDRAM.</p><p>I also decided to stick a 512 KiB SRAM chip in the design in case I ended up needing some more simple memory later, like for emulating the SRAM used for Game Boy cartridge save files. Despite being 1/64 the capacity, this chip was about 3x the cost of the SDRAM. This ended up being a wise decision, since a lot of my internal FPGA block ram was eaten up by the triple buffer for the display (see above).</p><h3>Cartridge and Link Ports<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#cartridge-and-link-ports\">#</a></h3><p>The cartridge slot and link ports are no-name parts from AliExpress, easily available for cheap. These seem to mostly be GBA SP compatible, and are often used as repair parts.</p><p>The Game Boy Advance can play both Game Boy [Color] and Game Boy Advance games. These run at different voltages and use different protocols, so the device needed some way of determining which type of cartridge is inserted.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/gb-vs-gba-cartridge-bottom.jpg\" alt=\"GBA cartridge (top) vs GB cartridge (bottom)\" width=\"1440\" height=\"519\"><figcaption><p>GBA cartridge (top) vs GB cartridge (bottom)</p></figcaption></figure><p>The cartridges are physically different at the bottom: GBA cartridges (the top cartridge in the image) have a notch on either side. The GBA has a  that senses the absence of a notch on an inserted cartridge and switches the device into Game Boy Color mode.</p><p>I measured the size and position of this notch, and searched Digi-Key and Mouser for switches that met these constraints. In the end, I was only able to find a single switch that would work.</p><h3>Miscellaneous peripherals<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#miscellaneous-peripherals\">#</a></h3><p>I used the surprisingly cheap <a href=\"https://www.st.com/en/mems-and-sensors/lsm6ds3tr-c.html\">LSM6DS3TR-C</a> IMU from ST. This tiny IMU has a 3-axis accelerometer and gyroscope, more than sufficient for emulating the few GB/GBA cartridges that have motion controls.</p><p>For keeping track of time even when the device was off, I used the <a href=\"https://www.nxp.com/part/PCF8563T\">PCF8563T</a> real-time clock chip. I chose this because it was 1) I2C (no additional pins required), 2) cheap, and 3) readily available from JLCPCB. Interestingly, all of the real-time clock chips I found count in seconds/minutes/hours/days/months/years. This makes sense for a really simple device with minimal computational power. However, it’s annoying for my purposes, since all I really want is a timestamp I can pass to some other datetime library, and converting between the calendar time and a unix timestamp is non-trivial due to how the chips incompletely handle leap years.</p><p>I picked up a few cheap coin vibration motors to use for vibration support (for the rare cartridge that had a built-in vibration motor).</p><p>I also used a <a href=\"https://www.ti.com/product/TCA9535\">TCA9535</a> I2C I/O expander to connect the face buttons to the MCU. I ran out of pins, and while I  have used the FPGA as a sort of I/O expander, I figured I’d make it simpler for myself (and allow the buttons to be used even if the FPGA was powered off) by letting the MCU read them itself.</p><p>For this project, as with my previous ones, I used <a href=\"https://www.kicad.org/\">KiCad</a> to create my schematic and do PCB layout. I really can’t recommend KiCad enough: it’s a great program, intuitive to use, and it’s free and open source.</p><p>This was a very ambitious project for my level of electrical engineering experience, and creating the schematic took a couple of weeks. I spent a lot of time designing the circuit for each component, because I was afraid I’d do something wrong and end up with a stack of useless boards without the skills needed to debug them. A lot of the component selection actually happened in parallel with schematic design, as I found new requirements or problems and had to change components.</p><p>I gained a lot of experience reading component datasheets. It’s a really valuable skill, both for component selection and for creating designs that use the components. Nearly every datasheet has a “typical application” section, where the manufacturer shows how the component would fit into a circuit. At minimum, this has power supply information (e.g. these voltages to these pins with these decoupling capacitors). For more complex components like the DAC, it also has information about power sequencing, different ways the device could be connected to the rest of the system, a register list, that sort of thing. Some components also included PCB layout recommendations. This information was all really helpful, and gave me a good deal of confidence that my board would work as long as I read through the datasheet and followed the manufacturer’s recommendations.</p><p>Then I got to the FPGA. Nearly every component has a single datasheet. Some of them have an additional application note or two. Particularly complex chips (like the ESP32-S3 microcontroller) have a separate datasheet, reference manual, and hardware design guide. The Xilinx Series 7 FPGAs have . Overviews, packaging and pinout, configuration guides, BGA design rules, power specifications, clocking resources, I/O specifications, PCB layout guides, design checklists… even a 4MB Excel spreadsheet for estimating power consumption! And believe me, Xilinx didn’t just write documentation for fun: there’s so much documentation because the chip  this much documentation.</p><p>Designing with the FPGA was overwhelming, and  beyond my experience level. At several points I genuinely considered dropping the project altogether. Fortunately, I persevered, and gradually internalized a lot of the information. I also read through the schematics of any open-source Artix-7 development board I could get my hands on. Seeing what other people were doing gave me more confidence that I was doing the right thing.</p><p>Eventually, after I placed all of the components, connected them, ensured all of the nets were labeled, and ran KiCad’s electrical rules checker (ERC) to find obvious mistakes, I moved on to layout.</p><p>I did PCB layout at the same time as some of the initial enclosure CAD. The mechanics of how everything fit together influenced the placement of the display connector, cartridge slot, buttons, speakers, and connectors. After I came up with a plausible enclosure design, I placed some of the first key components onto the PCB and locked them into place while I did the rest of the routing.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/early-shell-design.png\" alt=\"Rough enclosure design to help with board layout\" width=\"2000\" height=\"1298\"><figcaption><p>Rough enclosure design to help with board layout</p></figcaption></figure><p>I first focused on components that would be hardest to route. Primarily, the FPGA: the package I was using (CSG324) is a <a href=\"https://en.wikipedia.org/wiki/Ball_grid_array\">BGA</a>, 18x18 with 0.8mm pitch between pins. “Fanning out” all of the I/O signals requires careful routing, and at 0.8mm pitch, it’s difficult to do this routing with cheap PCB manufacturing techniques. I ended up being able to do this routing with a 6-layer PCB (three signal, two ground, one power), with 0.1mm track width and spacing, and 0.4/0.25mm vias. Fortunately, this is all within the realm of JLCPCB’s capabilities.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/bga-fanout.png\" alt=\"BGA fanout with thin traces and small vias\" width=\"1442\" height=\"1102\"><figcaption><p>BGA fanout with thin traces and small vias</p></figcaption></figure><p>As I routed signals out from the FPGA to other parts, I assigned those signals to the FPGA pins. Similarly, with the MCU, I assigned signals to pins in a way that made routing easier. Certain signals had restrictions (e.g. on the FPGA, the main 50 MHz clock signal can only go into certain pins, or the configuration bitstream can only go to certain pins, or certain pins are differential pairs for HDMI output), but overall, I had a lot of flexibility with pin assignment.</p><p>KiCad has a feature where it automatically backs up your project as you work on it. I changed the settings to save every 5 minutes and not delete old backups, which allowed me to generate this timelapse of my layout process:</p><figure><figcaption><p>Revision 1 board layout timelapse</p></figcaption></figure><p>Once I finished placing and routing all of the components, I ran the design rules checker (DRC) and fixed issues. I hesitated for a while before sending the PCB for manufacturing. I re-read the schematics, reviewed the layout, and eventually felt confident enough that I was done. I submitted the order to JLCPCB, and after a few questions by their engineers about component placement, they started manufacturing it.</p><h2>Board testing and bring-up<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#board-testing-and-bring-up\">#</a></h2><p>After two weeks or so, I received the assembled boards in the mail:</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/rev1-initial-boards.jpg\" alt=\"An assembled board and an unassembled board\" width=\"1440\" height=\"1026\"><figcaption><p>An assembled board and an unassembled board</p></figcaption></figure><p>First, I probed the power rail test points with a multimeter to check for shorts. Then, I plugged the boards in for the first time, and pressed the power button. To my delight, the green LED turned on, indicating that the power button circuit, power path, and 3.3V regulator worked. The microcontroller USB enumerated, and I could see that it logged some errors (since I hadn’t flashed anything to it yet).</p><p>I intended to write the MCU firmware in Rust, but I did initial board testing and bring-up with <a href=\"https://micropython.org/\">MicroPython</a>. This would let me interactively type in Python and write basic scripts to communicate with the peripherals on the board and make sure I had connected everything correctly. I didn’t have to worry about writing efficient or well-organized code, and could just focus on functionality.</p><p>I flashed the MicroPython firmware image, and wrote a couple lines of Python to blink the LED. I powered on the FPGA power domain, and checked that the , , and  rails had the correct voltage.</p><p>Next, I wrote a simple bitstream for the FPGA that read the state of the buttons and produced a pattern on the shared signals between the FPGA and the MCU. I wrote simple Python code to configure the FPGA, loaded up the bitstream, and polled the signals from the FPGA. Pressing buttons changed the state, and confirmed that the FPGA was properly powered, and configurable from the MCU.</p><p>After I confirmed the FPGA worked, I started writing a simple display driver to initialize the LCD and push some pixels from the MCU over SPI. The initialization sequence uses a number of LCD-specific parameters (voltages, gamma correction, etc.), that I learned from the LCD manufacturer’s example code.</p><figure><figcaption><p>(Slowly) pushing pixels to the LCD</p></figcaption></figure><p>The LCD module’s controller, an ILI9488, has a few quirks: despite claiming that it supports 16-bit colors over SPI, it actually only supports 18-bit colors. This unfortunately meant that the MCU’s LCD driver would be more inefficient than I expected, since it has to expand 16-bit colors to 18-bit before sending them over the bus. This didn’t end up being a huge issue, however, because the FPGA is the one driving the display most of the time.</p><p>Another quirk (hardware bug?) is that the ILI9488 doesn’t stop driving its SPI output line, even when its chip-select signal is inactive. This means that the chip will interfere with any other communication on the bus… including the FPGA, which sits on the same bus. I never actually needed to read any data back from the LCD (and even if I did, it supports <a href=\"https://en.wikipedia.org/wiki/Serial_Peripheral_Interface#Three-wire\">three-wire SPI</a>), so I just cut the trace between the LCD’s SDO line and the SPI bus.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/lcd-debugging.jpg\" alt=\"Debugging the LCD test code\" width=\"1440\" height=\"954\"><figcaption><p>Debugging the LCD test code</p></figcaption></figure><h3>Trouble with power domains<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#trouble-with-power-domains\">#</a></h3><p>I started trying to communicate with the I2C peripherals (I/O expander, RTC, etc.), and found that nothing was responding. A bit of probing with a logic analyzer revealed that the SCL/SDA lines were being held low, and that powering on the FPGA power domain let the lines be pulled high and communication to happen.</p><p>I deduced that this was due to the DAC, which had its IOVDD powered by , which likely caused its protection diodes to pull the IO lines (SCL and SDA) low:</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/dac-iovdd-issue.png\" alt=\"The problematic portion of the schematic\" width=\"1862\" height=\"656\"><figcaption><p>The problematic portion of the schematic</p></figcaption></figure><p>I tested out this theory by cutting the PCB traces connecting the DAC’s IOVDD and  with a knife. After this, I2C worked even with the FPGA power disabled. Then, I tested a possible fix by adding a wire to power the DAC’s IOVDD from the  rail. I confirmed that I could still talk to the other I2C devices, and once enabling FPGA power, that I could talk to the DAC too.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/dac-iovdd-rework.jpg\" alt=\"DAC IOVDD rework\" width=\"1440\" height=\"1126\"></figure><p>While bringing up the LCD, I saw that the FPGA was also pulling down the shared SPI bus lines while it was unpowered. Not enough to prevent communication with the LCD, but it still wasn’t great. Between this and the DAC issue, I learned an important EE lesson: be careful when connecting components in different power domains together. A tristate buffer, such as the <a href=\"https://www.ti.com/product/SN74LVC1G125\">74LVC1G125</a>, could have helped here to isolate the buses.</p><p>Once I2C was working, I wrote some basic driver code for the fuel gauge, real-time clock, IMU, and I/O expander, just to check that they all worked correctly. I also checked that the MCU could read from and write to the attached microSD card.</p><h4>Audio and video output from the FPGA<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#audio-and-video-output-from-the-fpga\">#</a></h4><p>Next, I updated my testing FPGA bitstream to output a test pattern over the <a href=\"https://hackaday.com/2024/01/25/displays-we-love-hacking-parallel-rgb/\">LCD parallel interface (“DPI”)</a>, and a test tone to the DAC over the I2S interface. Then, I began poking on the MCU side to configure the LCD controller and DAC appropriately.</p><p>With some amount of trial and error, I convinced the LCD to accept input from the FPGA. Most of the trial and error revolved around the rotation of the LCD module. Soon after, I configured the DAC properly, and it played the test tone from the FPGA over the speakers and the headphones.</p><figure><figcaption><p>WIP video output from the FPGA</p></figcaption></figure><p>At this point, much of the board was working, so I soldered on the rest of the components (cartridge slot, cartridge switch, link port, shoulder buttons).</p><p>With the cartridge slot in place, I had everything I needed to port over the Game Boy emulator from my last project. I did a quick-and-dirty port of the emulator, with some hacking around to connect the core to the audio, video, and the physical cartridge. I was able to play the first Game Boy game on the device far sooner than I was expecting:</p><figure><figcaption><p>Pokemon Silver running from cartridge</p></figcaption></figure><p>I spent the next month or so implementing things on the FPGA. I started on the SPI receiver implementation, so that the MCU and FPGA could communicate.</p><p>It was relatively straightforward to write <a href=\"https://github.com/elipsitz/gamebub/blob/handheld/fpga/src/main/scala/platform/handheld/SpiReceiver.scala\">the initial version</a>, which 4x oversampled the SPI signals from the main system clock. For the Game Boy, that was ~8 MHz, for a maximum SPI speed of 2 MHz. The MicroPython ESP32-S3 SPI implementation supported only single SPI, so that allowed for a maximum transfer speed of 256 KB/s. This was sufficient to do most of my initial testing, but I later <a href=\"https://github.com/elipsitz/gamebub/blob/handheld/fpga/src/main/scala/platform/handheld/SpiReceiverFifo.scala\">wrote an improved SPI receiver</a> to run with an internal 200 MHz clock (from a PLL that turned on and off with the chip-select signal to save power), communicating with the rest of the system via a pair of FIFOs. This added a lot of complexity and edge cases, but it greatly improved performance, allowing the bus to run at 40 MHz.</p><p>I wrote the SPI interface to the FPGA with memory-like semantics: each SPI transfer starts with a command byte, encoding whether it’s a read or write transfer, the size of each word in the transfer (8, 16, or 32 bits), and whether the “target address” should autoincrement as the transfer progresses. Then, a 32-bit address, followed by reading or writing the data. Each thing that the MCU might want to access (control registers, blocks of memory) are mapped into the 32-bit address space.</p><p>As with my previous FPGA project, I wrote almost all of the FPGA code in <a href=\"https://www.chisel-lang.org/\">Chisel</a>, a Scala-based HDL. The remaining bits were the top-level Verilog. Chisel made it really simple to parametrize, compose, and test the various modules that I wrote.</p><p>Once I had the SPI receiver working, I wrote controllers for the on-board SRAM and SDRAM. The SRAM was relatively simple (although I still got it slightly wrong at first). The SDRAM was a bit tricky, and even as I write this I’m not quite satisfied with its performance, and intend to rewrite it in the future.</p><p>I exposed the SRAM and SDRAM interfaces to the MCU via SPI, which allowed me to read and write to these pieces of memory from the MCU. I used this a lot for testing: writing patterns into memory and reading them back to ensure that read and write both worked.</p><p>Side note: SDRAM has to be continuously refreshed, otherwise the stored data decays over time. It depends on the chip, but typically each row has to be read and written back (or auto-refreshed, which does the same thing) at least once every 64 milliseconds to avoid losing state. What I found interesting, however, is that the data can actually persist for quite a bit longer. I discovered that when I was reconfiguring the FPGA between tests, most of the test data that I had previously written would still stick around even without being refreshed. In the first few seconds some bits would start flipping, and over the course of a few minutes, most of what was written was completely unintelligible.</p><p>With the SDRAM controller and SPI receiver written, I was then able to implement the “emulated cartridge” part of the Game Boy emulator, where the MCU reads a ROM file off of the microSD card and sends it to the FPGA to be stored in SDRAM. Then, the FPGA “emulates” a cartridge (rather than interfacing with a real physical cartridge). After a few stupid mistakes, I was able to run test ROMs and homebrew. As an added bonus, since I was using my own SDRAM controller directly, I didn’t have any of <a href=\"https://eli.lipsitz.net/posts/fpga-gameboy-emulator/#fixing-an-audio-bug-on-the-game-boy-color\">the performance issues I’d faced before</a> when accessing the ROM stored in memory.</p><h2>Writing the microcontroller firmware in Rust<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#writing-the-microcontroller-firmware-in-rust\">#</a></h2><p>By this point I had tested, in some form or another, all of the different components of the system. I’m really surprised that everything worked in my first board revision – even the rework I did early on wasn’t actually required for functionality.</p><p>I decided now was a good time to start building an interactive GUI. Up until this point, I had just been running commands in the MicroPython REPL. However, I didn’t want to build a whole UI in Python just to throw it away later, so I also started working on the “production” Rust firmware.</p><p>In the last few years, a lot of progress has been made towards making Rust on the ESP32 chips work well, even on the chips that use the Xtensa ISA. I followed the <a href=\"https://docs.esp-rs.org/book/\">Rust on ESP Book</a> and quickly had an environment set up. I opted for the <a href=\"https://docs.esp-rs.org/book/overview/using-the-standard-library.html\">“Rust with the Standard Library”</a> approach, so that I could benefit from <a href=\"https://idf.espressif.com/\">ESP-IDF</a>, especially the built-in support for USB and SD cards with the FAT filesystem.</p><p>I started porting over the drivers I had written in Python. I found embedded Rust to be a bit verbose in some cases, but overall pleasant to use and worth the (little) trouble.</p><p>I starting writing my own minimal GUI framework for basic menus. I poked around with the <a href=\"https://docs.rs/embedded-graphics/latest/embedded_graphics/\"></a> library, but soon found that the typical patterns I was expecting to use weren’t a great fit for Rust. I also started planning out different screens and realized that I probably actually wanted to use a more comprehensive UI framework.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/early-gui-main-menu.png\" alt=\"Early main menu screen\" width=\"480\" height=\"320\"></figure><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/early-gui-rom-select.png\" alt=\"Early rom select screen\" width=\"480\" height=\"320\"></figure><p>Ultimately, I settled on <a href=\"https://github.com/slint-ui/slint\">Slint</a>, a Rust-native declarative GUI framework with excellent support for embedded devices. Slint has a custom DSL to describe the UI and composable components. After a bit of practice I found myself to be really productive with it. I enjoyed using Slint, and I’d use it again in the future. The authors are responsive on GitHub, and the project has steadily improved over the year or so that I’ve been using it.</p><p>There were a few rough edges for my use case, however:</p><ul><li>The built-in GUI elements and examples were all heavily oriented around mouse or touchscreen navigation. Game Bub only has buttons for navigation, however, so I had to make my own widgets (buttons, lists) that worked with key navigation. This involved a few hacks, because Slint’s focus handling was a little bit simplistic.</li><li>The built-in GUI styles looked (in my opinion) bad on a low DPI screen. Text was excessively anti-aliased and hard to read at small sizes. This was also fixed by building my own widgets.</li><li>Slint doesn’t have a great story around supporting different “screens” – I had to build some of my own infrastructure to be able to support navigation between the main menu, games, rom select, settings, etc.</li></ul><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/screenshot-main-menu.png\" alt=\"Main menu\" width=\"480\" height=\"320\"></figure><p>The GUI is rendered on the MCU, and then the rendered framebuffer is sent over to the FPGA. Slint supports partial rendering, where only the parts of the screen that have changed are updated, which improved performance. The FPGA maintains a copy of the framebuffer and ultimately is responsible for driving the display. This has a few advantages over driving the display directly from the MCU:</p><ul><li>Sending a framebuffer at 40 MHz QSPI to the FPGA is 16x faster than sending it to the LCD controller at 10 MHz (the fastest speed supported by the ILI9488)</li><li>The UI is rendered at 240x160 to improve performance and maintain the GBA aesthetic, but the LCD controller doesn’t have a scaler, so the MCU would have to send 4x the pixels. The FPGA can easily scale the UI framebuffer itself.</li><li>The FPGA can composite the emulator output with a semi-transparent “overlay” to support an in-game menu, volume / brightness bars, battery notifications, etc.</li><li>An external display (e.g. monitor or TV) can be driven by the FPGA via HDMI</li></ul><p>I spent some time making a variety of firmware improvements, mostly polish and quality-of-life. I added a settings screen to set the date and time, whether to use Game Boy (DMG) or Game Boy Color (CGB) mode when playing Game Boy games, etc.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/screenshot-settings-early.png\" alt=\"Settings screen\" width=\"480\" height=\"320\"></figure><p>Then I improved the ROM select file browser, and added a battery level indicator.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/screenshot-load-rom.png\" alt=\"Rom select screen\" width=\"480\" height=\"320\"></figure><p>I also got sick of having to take the microSD card out of the device and connect it to my computer through a series of adapters (microSD to SD to USB-A to USB-C), so I implemented a basic utility to expose the microSD card as a USB Mass Storage Device, using <a href=\"https://github.com/hathach/tinyusb\">TinyUSB</a> and the ESP32-S3’s USB-OTG capabilities.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/screenshot-usb-storage.png\" alt=\"USB Mass Storage screen\" width=\"480\" height=\"320\"></figure><p>It was a little bit more difficult than I expected, because USB Mass Storage requires the device to provide raw block access. This means that the filesystem has to be unmounted by the device, otherwise the device and host could conflict and corrupt the filesystem. The ESP32-S3 also only supports USB Full Speed, for a practical maximum transfer speed of ~600KB/sec. It’s really useful for transferring save files or updating the FPGA bitstreams, but less useful for transferring a large number of ROM files.</p><p>Later, I implemented <a href=\"https://gbdev.io/pandocs/MBC7.html\">MBC7</a> support in the Game Boy emulator for Kirby Tilt ’n Tumble, using the on-board accelerometer.</p><p>After I implemented a decent amount of software functionality, I decided to finish the enclosure design. The bare board just wasn’t cutting it anymore, and the taped LCD module/loose speakers/rubber-banded battery contraption was fragile.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/gamebub-without-shell.jpg\" alt=\"Game Bub looking rough without an enclosure\" width=\"1440\" height=\"1724\"><figcaption><p>Game Bub looking rough without an enclosure</p></figcaption></figure><p>I came into this project without any CAD or 3D printing experience. I looked at a few different CAD software packages, and I ultimately settled on <a href=\"https://www.freecad.org/\">FreeCAD</a>, primarily because it was free and open source. I learned how to use the software with some video tutorials. FreeCAD, unfortunately, was a little bit rough around the edges and I ended up running into some annoying issues. Nevertheless, I powered through and finished the design.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/enclosure-rev1-cad.png\" alt=\"FreeCAD view of the enclosure and some buttons\" width=\"2000\" height=\"1524\"><figcaption><p>FreeCAD view of the enclosure and some buttons</p></figcaption></figure><p>I found parametric modeling, where the geometry of the model is defined by constraints and dimensions, to be intuitive. However overall, I found 3D CAD to be very time consuming. I think a large part of this is my inexperience, but thinking in three dimensions is a lot more difficult than, say, a 2D PCB layout. Creating a full assembly was even more difficult: I had to visualize how the front and rear pieces would fit together, where the screws would go, and how the buttons, screen, speaker, cartridge slot, battery, and ports would all fit in. This project definitely pushed the boundaries of my (previously non-existent) product design skills.</p><p>After finishing the design, I printed out the technical drawing at a 1:1 scale and physically placed the board and other components down as a final check. Then, I sent it to JLCPCB for manufacturing. I opted for <a href=\"https://en.wikipedia.org/wiki/Stereolithography\">SLA resin printing</a>, for high precision and a smooth finish.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/shell-rev1-technical-drawing.png\" alt=\"Enclosure technical drawing\" width=\"1440\" height=\"971\"><figcaption><p>Enclosure technical drawing</p></figcaption></figure><p>After a couple weeks, I got the finished enclosure and custom buttons back.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/enclosure-rev1-outside.jpg\" alt=\"Front and rear half, outside\" width=\"1440\" height=\"1009\"><figcaption><p>Front and rear half, outside</p></figcaption></figure><p>I put the buttons, speakers, and screen into the enclosure, screwed on the PCB, and put the whole thing together.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/assembling-front.jpg\" alt=\"Assembling the front side\" width=\"1440\" height=\"1544\"><figcaption><p>Assembling the front side</p></figcaption></figure><figure><figcaption><p>Game Bub, fully assembled and functional</p></figcaption></figure><p>I wasn’t sure how dimensionally accurate the 3D printing would be, so I added a lot of extra clearance around the buttons and ports. As it turned out, the printing was very precise, so the buttons rattled around a little in the oversized button holes.</p><p>It’s a little bit chunky (smaller than an original Game Boy, though!) and the ergonomics aren’t ideal, but I was really happy to finally have an enclosure. It actually started (sort of) looking like a real product, and I wasn’t constantly worried about breaking it anymore.</p><h2>Game Boy Advance support<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#game-boy-advance-support\">#</a></h2><p>I won’t go into all of the details of how I wrote the emulator here (this article is already long enough!). If you’re interested, my <a href=\"https://eli.lipsitz.net/posts/fpga-gameboy-emulator/\">previous article about my Game Boy FPGA emulator</a> goes into detail about the general process of writing an emulator, and for a high-level introduction to the Game Boy Advance (from a technical perspective), I recommend <a href=\"https://www.copetti.org/writings/consoles/game-boy-advance/\">Rodrigo Copetti’s article</a>. In general, I tried to implement the emulator the way it might actually have been implemented in the original hardware: each cycle of the FPGA corresponds to one actual hardware cycle (no cheating!).</p><p>As with the Game Boy, I did nearly all of my development with a simulator backed by <a href=\"https://www.veripool.org/verilator/\">Verilator</a> and <a href=\"https://www.libsdl.org\">SDL</a>. By the end of the development process, the simulator was running at about 8% of the real-time speed (on an M3 MacBook Air with excellent single-core performance), which was a bit painful.</p><p>The Game Boy Advance CPU, the <a href=\"https://en.wikipedia.org/wiki/ARM7#ARM7TDMI\">ARM7TDMI</a>, is significantly more complicated than the Game Boy’s SM83 (a <a href=\"https://en.wikipedia.org/wiki/Zilog_Z80\">Z80</a> / <a href=\"https://en.wikipedia.org/wiki/Intel_8080\">8080</a>-ish hybrid). However, in some ways, it was easier to understand and implement: the ARM7TDMI is much closer to a simple modern processor architecture, and it’s extensively documented by ARM. For example, the <a href=\"https://developer.arm.com/documentation/ddi0210/c/?lang=en\">ARM7TDMI Technical Reference Manual</a> has block diagrams and detailed cycle-by-cycle instruction timing descriptions.</p><p>I had a lot of fun <a href=\"https://github.com/elipsitz/gamebub/tree/handheld/fpga/src/main/scala/gba/cpu\">implementing the CPU</a>. The architecture has a three-stage pipeline (fetch, decode, execute) – a division that feels natural when you implement it in hardware. The ARM7TDMI has two instruction sets: the standard 32-bit ARM instruction set, and the compressed 16-bit THUMB instruction set. I implemented the CPU the way it works in hardware, where the only difference between ARM and THUMB is the decode stage.</p><p>As I was implementing the CPU, I wrote <a href=\"https://github.com/elipsitz/gamebub/blob/handheld/fpga/src/test/scala/gba/cpu/ARM7TDMISpec.scala\">test cases</a> for each instruction. Each test checks the functionality of the instruction: processor state, register values after, as well as the cycle-by-cycle behavior and interaction with the memory bus. This was helpful for catching regressions as I implemented more and more control logic. It was also really satisfying to be able to implement individual instructions, then write the tests, and check that everything worked.</p><p>Chisel made it easy to write out the <a href=\"https://github.com/elipsitz/gamebub/blob/handheld/fpga/src/main/scala/gba/cpu/Control.scala\">CPU control logic</a>. The CPU control logic is a state machine that generates microarchitectural control signals (e.g. bus A should hold the value from the first read register, bus B should hold an immediate value, the memory unit should start fetching the computed address, etc.). Chisel allowed me to collect common functionality into functions (e.g.  to set up the signals to dispatch the next decoded instruction, or  to signal that the pipeline should be flushed and a new instruction should be fetched from the current program counter).</p><p>I found it helpful to draw out timing diagrams with <a href=\"https://wavedrom.com\">WaveDrom</a> when working through instructions, especially to deal with the pipelined memory bus.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/timing-arm7tdmi-branch.svg\" alt=\"My timing diagram of the ARM7TDMI branch instructions\"><figcaption><p>My timing diagram of the ARM7TDMI branch instructions</p></figcaption></figure><p>By mid-May (about a month later), I finished the CPU implementation (with occasional bug fixes after) and moved onto the rest of the system.</p><h3>PPU, MMIO, and everything else<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#ppu-mmio-and-everything-else\">#</a></h3><p>Over the next month and a half, I implemented the majority of the rest of the Game Boy Advance. The CPU interacts with the rest of the system via <a href=\"http://problemkaputt.de/gbatek-gba-i-o-map.htm\">memory-mapped IO (MMIO)</a> registers. Unlike the Game Boy CPU, which can only access memory a single byte at a time, the ARM7TDMI can make 8-bit, 16-bit, and 32-bit accesses. This complicates MMIO, and the different hardware registers and memory regions in the GBA respond to different access widths in different ways.</p><p>I started with the Picture Processing Unit (PPU), which produces the video output. The author of <a href=\"https://github.com/nba-emu/NanoBoyAdvance\">NanoBoyAdvance</a>, fleroviux, had helpfully documented the <a href=\"https://nba-emu.github.io/hw-docs/ppu/ppu.html\">PPU VRAM access patterns</a>, which gave a lot of insight into how the PPU might work internally. <a href=\"https://www.coranac.com/tonc/text/toc.htm\">Tonc</a> was also immensely helpful for implementing the PPU and testing individual pieces of functionality.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/tonc-test.png\" alt=\"(Sort of) running a Tonc PPU demo\" width=\"963\" height=\"699\"><figcaption><p>(Sort of) running a Tonc PPU demo</p></figcaption></figure><p>The PPU took a few weeks, and then I moved onto DMA, followed by hardware timers, and audio. Of course, as I’d try new tests, demos, and games, I’d uncover bugs and fix them.</p><figure><figcaption><p>Kirby  in Dream Land</p></figcaption></figure><p>Game Boy and Game Boy Advance cartridges use the same 32-pin connector. However, they work very differently. The Game Boy cartridge bus is asynchronous: the game outputs the 16-bit address (64 KiB address space) on one set of pins and lowers the  pin. Some time later, the 8-bit read data from the ROM stabilizes on a separate set of pins.</p><p>For the GBA, Nintendo extended the bus data width to 16-bit and the address space to 25-bit (32 MiB). However, they kept roughly the same set of pins, accomplishing this by multiplexing the 24 data/address pins: the console outputs the address (in increments of the data word size of 16-bits, for a 24-bit physical address), then lowers the  signal to “latch” the address in the cartridge. Then, each time the console pulses the  pin, the cartridge increments its latched address and outputs the next data over the same pins. This allows for a continuous read of sequential data without having to send a new address for each access. The GBA also allows games to <a href=\"http://problemkaputt.de/gbatek-gba-system-control.htm\">configure cartridge access timings</a> to support different ROM chips.</p><p>I had to do a lot of my own research here. Software emulators don’t need to care about the precise timing of the cartridge bus, so there wasn’t much documentation. To figure out the exact cycle-accurate timing, I used a <a href=\"https://www.saleae.com/\">Saleae</a> logic analyzer and connected it to the cartridge bus. I wrote a test program for the GBA to do different types of accesses (reads, writes, sequential, non-sequential, DMA) with different timing configurations.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/cartridge-bus-analyzer.jpg\" alt=\"Cartridge bus analysis setup\" width=\"1440\" height=\"1080\"><figcaption><p>Cartridge bus analysis setup</p></figcaption></figure><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/trace-gba-cartridge.png\" alt=\"Portion of a trace\" width=\"2582\" height=\"734\"></figure><p>After coming up with numerous scenarios (especially around the interaction between DMA and the CPU, and starting and stopping burst accesses), I came up with a consistent model for how cartridge accesses worked. I created some timing diagrams to help:</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/cartridge-timing-diagram.svg\" alt=\"Timing diagram of a non-sequential access followed by a sequential access\"><figcaption><p>Timing diagram of a non-sequential access followed by a sequential access</p></figcaption></figure><p>Finally, I started implementing the cartridge controller state machine based on my observations, paired with an emulated cartridge implementation. With the emulated cartridge, I was able to properly run real games in the simulator.</p><p>I quickly implemented physical cartridge support, to be able to finally run it on the actual FPGA. I connected the signals, built a new bitstream, and… it didn’t work at all. The Game Boy Advance boot screen ran, but it didn’t get any further than that. I implemented the emulated cartridge on the FPGA (reading ROM files from the SD card), and it worked! Which was great, but physical cartridges still didn’t.</p><p>I used the logic analyzer to observe how my emulator was interacting with the cartridge compared to how an actual GBA, and found numerous issues.</p><p>One of the first things I noticed was short <a href=\"https://en.wikipedia.org/wiki/Glitch#Electronics_glitch\">glitches</a> on the  line. I knew these had to be glitches (rather than incorrect logic), because they were 8 nanoseconds long, much shorter than the ~59.6ns clock period. Since the cartridge latches the address on a falling edge of , glitches cause it to latch an address when it shouldn’t, screwing up reads.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/cartridge-bus-glitches.png\" alt=\"Glitches on the cartridge bus\" width=\"2177\" height=\"600\"><figcaption><p>Glitches on the cartridge bus</p></figcaption></figure><p>Here, I learned an important lesson in digital design: output signals should come directly from flip-flops, with no logic in between.</p><p>After each flip-flop outputs a new value (on the rising edge of the clock), the signals propagate through the chip. As they propagate, taking different paths of different lengths throughout the chip, the output from each lookup table (LUT) is unstable. These values only stabilize near the end of the clock cycle (assuming the design met timing closure), and then each flip-flop stores the stable value at the next rising edge. If you output a signal from logic, this instability is visible from outside of the chip, manifesting as glitches in the output signal. If you instead output the signal from a flip-flop, it’ll change only on each clock edge, remaining stable in the middle.</p><p>And of course, I had written the cartridge controller without thinking about this, and  of the output signals were generated from logic. I rewrote the controller to output everything from flip-flops, which had a series of cascading changes since all of the signals now had to be computed one clock cycle earlier than I expected.</p><p>There were other issues too – part of the problem was that my emulated cartridge model was too permissive, and didn’t catch some fairly obvious incorrect behavior. After a few days of intensive debugging with the logic analyzer, I got to the point where I could play games from physical cartridges.</p><figure><figcaption><p>Metroid: Zero Mission running from the cartridge</p></figcaption></figure><h4>Cartridge prefetch buffer<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#cartridge-prefetch-buffer\">#</a></h4><p>The ARM7TDMI has a single shared instruction and data memory bus. As a result, a long series of sequential memory accesses is rare. Even a linear piece of code without branches that includes “load” or “store” instructions would produce a series of non-sequential memory accesses, as the CPU fetches an instruction from one location, loads a register from a different location, and then goes back to fetching the next instruction.</p><p>This poses a real performance issue on the GBA, because every non-sequential access from the cartridge incurs a multi-cycle penalty. Nintendo attempted to mitigate this somewhat with the “prefetch buffer” (<a href=\"https://mgba.io/2015/06/27/cycle-counting-prefetch/#game-pak-prefetch\">read this post by endrift, the author of mGBA, for more details</a>) which attempts to keep a cartridge read burst active between CPU accesses. Without emulating the prefetch buffer, some games lag (I noticed this the most in Mario Kart Super Circuit, and some rooms of Metroid: Zero Mission).</p><p>The prefetch buffer, while simple in theory, is not well documented and has a lot of corner cases and weird interactions. Emulator developers often start by taking a shortcut: making all cartridge accesses take a single cycle when the prefetch buffer is enabled. This wouldn’t work for me, since I actually had to interface with the physical cartridge.</p><p>So, I set out to do some more research to figure out exactly how the prefetch buffer worked. After making some educated guesses and tests, I came up with a reasonable model of how it might work.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/prefetch-notes.jpg\" alt=\"Notes about the prefetch state machine\" width=\"1440\" height=\"1744\"><figcaption><p>Notes about the prefetch state machine</p></figcaption></figure><p>Actually implementing it took a lot of work, and I kept stumbling upon more and more corner cases. Eventually I got to the point where all games appeared to run at full speed, and most importantly, didn’t randomly crash. My implementation isn’t perfect: there are still a few <a href=\"https://github.com/mgba-emu/suite\">mGBA test suite</a> timing tests I don’t pass, but it’s certainly sufficient to play games.</p><ul><li>: standard duplex SPI, used for communicating with accessories</li><li>: custom multi-drop UART-like protocol, used to link up to four GBAs together for multiplayer games</li><li>: the Nintendo N64 and GameCube controller protocol, used to connect to a GameCube</li><li>: duplex <a href=\"https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter\">UART</a> with flow control, </li><li>: controlling the four pins individually as <a href=\"https://en.wikipedia.org/wiki/General-purpose_input/output\">GPIO</a>, </li></ul><p>The timing of these isn’t well documented, so I did my own research.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/gba-link-multiplayer-transfer.png\" alt=\"A multiplayer mode transfer with no attached consoles\" width=\"2012\" height=\"558\"><figcaption><p>A  mode transfer with no attached consoles</p></figcaption></figure><p>I did a lot of testing with examples from the <a href=\"https://github.com/afska/gba-link-connection\">gba-link-connection</a> library, intended for homebrew GBA games, but helpful for testing the different transfer modes in a controlled environment.</p><figure><figcaption><p>Multiplayer Mario Kart with Game Bub and a GBA</p></figcaption></figure><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/animal-crossing-gamecube-link.jpg\" alt=\"Game Bub linked to a GameCube playing Animal Crossing\" width=\"1440\" height=\"1801\"><figcaption><p>Game Bub linked to a GameCube playing Animal Crossing</p></figcaption></figure><p>During the emulator development, I had used various test ROMs (mentioned before) to test basic functionality in isolation. As my emulator became mature enough to run commercial games, however, I started to shift some of my focus to accuracy-focused test ROMs.</p><p>These test ROMs (such as the <a href=\"https://github.com/mgba-emu/suite\">mGBA test suite</a>) generally test really specific hardware quirks and timing. For example, they might test what happens when you run an instruction that ARM calls “unpredictable”, or the exact number of cycles it takes to service an interrupt in specific scenarios, or <a href=\"https://bmchtech.github.io/post/multiply/\">the value of the “carry” flag after performing a multiplication</a>. These are the kinds of things that don’t actually matter for playing games, but present a fun challenge and a way to “score” your emulator against others. This also highlights the collaborative nature of the emulation development community: people sharing their research and helping each other out.</p><p>I won’t talk about all of the tests here (for my emulator’s test results, <a href=\"https://github.com/elipsitz/gamebub/blob/handheld/docs/accuracy.md\">see this page</a>). But I do want to mention the <a href=\"https://tcrf.net/AGS_Aging_Cartridge\"></a>. This is an official test cartridge from Nintendo, likely used as part of a factory test or RMA procedure. Apparently, Nintendo has  used it to test their emulators (e.g. their GBA emulator on the Nintendo Switch). This test has generally been considered to be difficult to pass (it tests some specific hardware quirks), but it’s easier now that the tests have been <a href=\"https://github.com/DenSinH/AGSTests/\">thoroughly reverse engineered and documented</a>. Still, passing it is a nice milestone:</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/agb-aging-cartridge.png\" alt=\"Passing the AGB Aging Cartridge\" width=\"964\" height=\"700\"><figcaption><p>Passing the AGB Aging Cartridge</p></figcaption></figure><h2>Second hardware revision<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#second-hardware-revision\">#</a></h2><p>Towards the end of 2024, approximately one year after I originally designed Game Bub, I decided to make a second hardware revision. Over the past year, I had been keeping track of all of the things I would want to change in a future revision. Since the first version of Game Bub miraculously worked without any major issues, this list was primarily minor issues and ergonomics changes.</p><p>I fixed the <a href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#trouble-with-power-domains\">minor I2C power issues</a>, removed the <a href=\"https://en.wikipedia.org/wiki/Reference_designator\">reference designators</a> from the PCB silkscreen (they looked messy with the dense board, and I didn’t use them for anything anyway), and changed around some test points. I improved the rumble circuit to be more responsive, and switched to a PCB-mounted vibration motor.</p><p>The first version of Game Bub was fairly thick, measuring 12.9mm at the top and 21.9mm on the bottom. The thickness of the rear enclosure was dictated by the thickness of Game Boy cartridges, but I made several changes to the front. I moved the  (8.5mm!) link port to the back, and removed the HDMI port (more on that later). I changed the headphone jack (5.0mm tall – no wonder they started getting removed from phones) to a mid-mount one that sunk into the PCB and reduced the overall height.</p><p>I also switched from an  module (3.1mm depth) to an  (2.4mm depth). I should have done this from the beginning, I just didn’t even know the ESP32-S3-MINI existed. This had the side effect of giving me 3 more GPIOs, which allowed me to put the FPGA and LCD on separate SPI busses, avoiding the minor issue of an unpowered FPGA interfering with LCD communication, and allowed for faster boot because the LCD could be configured at the same time as the FPGA.</p><p>I switched the speakers, from the fully-enclosed <a href=\"https://www.sameskydevices.com/product/audio/speakers/miniature-(10-mm~40-mm)/ces-20134-088pmb\">CES-20134-088PMB</a> to the <a href=\"https://www.sameskydevices.com/product/audio/speakers/miniature-(10-mm~40-mm)/cms-160903-18s-x8\">CMS-160903-18S-X8</a>. I made this change primarily for ease of assembly. The first speaker had a wire connector that plugged into the board, and I found it difficult to connect during assembly without having the wire interfere with buttons. The new speaker is smaller and has a spring contact connector, so it just presses against the PCB as the device is assembled. This required some speaker enclosure design – an unenclosed speaker in free air sounds quiet and tinny.</p><p>I reworked the layout of the face buttons and D-pad to match the spacing of the Nintendo DSi. This allowed me to use the silicone membranes from the DSi for an improved button feel and reduced rattling. I was also hoping to use the plastic buttons from the DSi (which were higher quality compared to my 3D printed buttons), but even with the new thinner design, the buttons weren’t quite tall enough to be easily pressed.</p><p>I created another timelapse of my modifications to produce the second version of the PCB:</p><figure><figcaption><p>Revision 2 board layout timelapse</p></figcaption></figure><p>For the second revision of the enclosure, I switched to <a href=\"https://en.wikipedia.org/wiki/Fusion_360\">Fusion 360</a> for the CAD work. While I would have preferred to keep using FreeCAD, I found that it was making it harder for me to be productive. Fusion 360 has a free version for hobbyists (with some limitations that have gradually increased over time), and overall I’ve found it very pleasant to use.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/enclosure-rev2-cad.png\" alt=\"Fusion 360 view of the second enclosure, fully assembled\" width=\"1774\" height=\"1472\"><figcaption><p>Fusion 360 view of the second enclosure, fully assembled</p></figcaption></figure><p>Unlike with the first revision, I waited until I had a final design for both the enclosure and the PCB before getting anything manufactured. This let me go back and forth, making small modifications to each of them as needed.</p><p>I wanted to make the end result look more polished and professional, so I contracted a factory to produce custom LCD cover glass, made out of 0.7mm thick tempered glass with a black silkscreen. It was relatively expensive for a low quantity order, but I’m really happy with how it turned out.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/lcd-cover-glass.jpg\" alt=\"Custom LCD cover glass with adhesive backing\" width=\"1440\" height=\"1369\"><figcaption><p>Custom LCD cover glass with adhesive backing</p></figcaption></figure><h3>Manufacturing and assembly<a hidden=\"\" aria-hidden=\"true\" href=\"https://eli.lipsitz.net/posts/introducing-gamebub/#manufacturing-and-assembly\">#</a></h3><p>I got the PCBs manufactured and assembled, this time with black solder mask to look .</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/pcb-rev-2.jpg\" alt=\"Assembled PCB, revision 2\" width=\"1440\" height=\"1073\"><figcaption><p>Assembled PCB, revision 2</p></figcaption></figure><p>I had two enclosures made. The first was black PA-12 Nylon, printed with <a href=\"https://en.wikipedia.org/wiki/Multi-jet_fusion\">MJF</a>. Nylon is strong and durable, and the MJF 3D printing technology produces a slightly grainy surface that’s really pleasant to hold in your hand.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/nylon-closeup.jpg\" alt=\"Closeup of the nylon grainy texture\" width=\"1440\" height=\"894\"><figcaption><p>Closeup of the nylon grainy texture</p></figcaption></figure><p>The second one was made of transparent resin (SLA, like before). This lets me show off the PCB that I worked so hard on, and evokes the transparent electronics trend from the 90s.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/gamebub-transparent.jpg\" alt=\"Transparent Game Bub\" width=\"1440\" height=\"1920\"></figure><p>Assembly was a lot easier this time around: the silicone membranes held the face buttons in place, the speakers had a spring contact instead of wires, and the shoulder button assembly was better. In the first revision, I had excessively large tolerances because I wasn’t sure how precise the 3D printing would be. In the second version, I was able to shrink these.</p><p>The final product looked and felt a lot better, too. The edges were more rounded, and the device was thinner and easier to hold. The buttons felt  better to press and didn’t rattle around, and the cover glass over the LCD added polish.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/gamebubs-side-by-side.jpg\" alt=\"First revision (left), second revision (center and right)\" width=\"1440\" height=\"742\"><figcaption><p>First revision (left), second revision (center and right)</p></figcaption></figure><p>I previously mentioned that I removed the full-size HDMI port from the first revision. I had first planned to change it to a mini-HDMI or micro-HDMI port to reduce the size, but I was worried about durability.</p><p>What I  wanted to do was output video through the USB-C port, avoiding the need for any HDMI port at all. Unfortunately, I had already concluded earlier that I wouldn’t be able to output <a href=\"https://en.wikipedia.org/wiki/DisplayPort\">DisplayPort</a> video signals from the FPGA, which meant that I couldn’t use the standard USB-C DisplayPort alternate mode.</p><p>However, an idea struck me towards the end of 2024: I didn’t actually  to use the DisplayPort alt-mode. The USB-C connector, in addition to the USB 2.0 D+/D- pins, has four differential pairs (for USB superspeed). Conveniently, HDMI  uses four differential pairs. The USB specification allows for vendor-specific alt-modes, so I could just implement my own, outputting the HDMI signal directly from the FPGA over the additional pins. Then I could build a custom dock that takes those pins and connects them to the data lines of an HDMI port.</p><p>According to the USB specification, alternate modes must be negotiated by both sides first, using the USB-C Power Delivery (USB-PD) protocol, to prevent them from interfering with devices that aren’t expecting them. I don’t actually have a USB-PD controller in Game Bub (too much added complexity), so I took a shortcut: have a microcontroller in the dock communicate with the Game Bub over regular USB and perform a handshake before enabling HDMI output from the FPGA. Once Game Bub detects that it’s been disconnected from the dock, it can just switch back to using the internal display.</p><p>I realized that the dock also presents another opportunity for controller support. I originally wanted to build wireless controller support into the handheld, but the ESP32-S3 only supports Bluetooth Low Energy, and the majority of controllers use Bluetooth Classic. Fortunately, the <a href=\"https://en.wikipedia.org/wiki/Raspberry_Pi#Raspberry_Pi_Pico\">Raspberry Pi Pico W</a> (with an RP2040 MCU) supports both types of Bluetooth, so I just decided to use that as the microcontroller on the dock. Game controllers connect to the dock over Bluetooth, and the Pico sends the controller inputs to the device. I wired up the  and  USB-C pins as a direct connection between the FPGA and the dock for low latency input.</p><p>The RP2040 acts as the USB host, and Game Bub only needs to be a device. I also added a USB hub chip and some additional USB ports on the back of the dock to allow for wired controller support too. Just like with wireless controllers, the dock handles the direct controller communication, and just passes inputs back to the main Game Bub unit.</p><p>Since the dock is so simple (comparatively), it only took about a day to design and lay out.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/dock-pcb.jpg\" alt=\"Assembled dock PCB\" width=\"1440\" height=\"1016\"></figure><p>I had also hoped to use the dock to solve another problem around HDMI output: HDMI sinks (monitors, TVs) pull the HDMI data lines up to 3.3 volts, and can actually backfeed power to the HDMI source. For Game Bub, this meant that a powered-off unit would turn itself on when connected over HDMI. I used a HDMI buffer chip in the dock to try to alleviate this problem, but the chip I used wasn’t actually properly suited to this use-case and interfered with video output, so I had to carefully rework the board to bypass the chip. I’ll have to fix it in a later revision.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/dock-rework.jpg\" alt=\"Bypassing the HDMI buffer chip\" width=\"1440\" height=\"1359\"><figcaption><p>Bypassing the HDMI buffer chip</p></figcaption></figure><p>After the rework, HDMI output worked! The rest of the features are still a work in progress.</p><figure><img loading=\"lazy\" src=\"https://eli.lipsitz.net/posts/introducing-gamebub/media/bare-gamebub-in-dock.jpg\" alt=\"Game Bub PCB on the dock, connected to an external monitor\" width=\"1440\" height=\"2116\"><figcaption><p>Game Bub PCB on the dock, connected to an external monitor</p></figcaption></figure><p>Congratulations on reading this far! This writeup ended up being incredibly long, even with a lot of details left out.</p><p>I’m proud of what I accomplished over the last year and a half: I met all of my goals to produce a polished handheld FPGA retrogaming device. I pushed my electrical engineering and product design skills to the limit, and learned a lot in the process. Professional product and hardware designers deserve  respect.</p><p>I deliberately designed this project with lots of possible extension opportunities to keep me occupied for a long time. I worked hard to get to the point where I’m comfortable sharing Game Bub with the world, but I still have a long list of TODOs for the future.</p><p>In the near term, I’m going to work on finishing the dock, implementing wireless controller support (and maybe wired). I plan to use the <a href=\"https://github.com/ricardoquesada/bluepad32\">Bluepad32</a> library to do so.</p><p>I also want to improve the accuracy of my Game Boy Advance emulator: my goal here is to someday pass the entire <a href=\"https://github.com/mgba-emu/suite\">mGBA test suite</a>. I hope that I can contribute back to the wonderful  community with my emulator, and I plan to write-up some of my research around the GBA cartridge interface and link port.</p><p>I have a long list of mostly minor changes to make to the MCU firmware: improving UI render performance, bits of polish like low battery notifications, eliminating display glitching when reloading the FPGA, and that sort of thing. I also plan to add more utilities, like a cartridge dumper and save backup/restore feature.</p><p>Some day, I want to emulate the <a href=\"https://en.wikipedia.org/wiki/Game_Boy_Advance_Wireless_Adapter\">Game Boy Advance Wireless Adapter</a> over Wi-Fi, e.g. with <a href=\"https://docs.espressif.com/projects/esp-idf/en/stable/esp32s3/api-reference/network/esp_now.html\">ESP-NOW</a>. This won’t be compatible with the original wireless adapter, unfortunately, since that uses raw 2.4 GHz modulation rather than Wi-Fi.</p><p>I designed Game Bub with extremely low production volumes in mind, using off-the-shelf commodity parts to keep the overall cost down. However, there are a few things I would have liked to be able to do, but are only possible with much higher volumes:</p><ul><li>A better LCD module (likely custom): native landscape mode to avoid the need for triple-buffering. Ideally a 720x480 resolution display, to allow for 3x GBA scaling and filter effects.</li><li>High-quality injection molded case and buttons: 3D printing is great for low volume production, but an injection molded case would be great. It would be more precise (allowing for tighter tolerances), stronger, and allow for significantly more color options.</li><li>Custom battery pack: or at least customizing the length of the connector wire. The current solution is hacky and doesn’t make the best use of internal space, due to limited off-the-shelf battery options.</li><li>Smaller BGA parts for SRAM and SDRAM to free up board space (and move internal signals to 1.8 volts): this is actually something that would be possible in smaller volumes too, if I were willing to send parts from Mouser or DigiKey to JLCPCB for assembly.</li></ul>","contentLength":69379,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43027335"},{"title":"Spanish 'running of the bulls' festival reveals crowd movements can be predicted","url":"https://phys.org/news/2025-02-spanish-bulls-festival-reveals-crowd.html","date":1739372332,"author":"gmays","guid":670,"unread":true,"content":"\n<p>Article URL: <a href=\"https://phys.org/news/2025-02-spanish-bulls-festival-reveals-crowd.html\">https://phys.org/news/2025-02-spanish-bulls-festival-reveals-crowd.html</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43026001\">https://news.ycombinator.com/item?id=43026001</a></p>\n<p>Points: 110</p>\n<p># Comments: 45</p>\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Writing a Gimp 3.0 Plugin","url":"https://schoenitzer.de/blog/2025/Gimp%203.0%20Plugin%20Ressources.html","date":1739366772,"author":"nudin","guid":607,"unread":true,"content":"\n<p>Article URL: <a href=\"https://schoenitzer.de/blog/2025/Gimp%203.0%20Plugin%20Ressources.html\">https://schoenitzer.de/blog/2025/Gimp%203.0%20Plugin%20Ressources.html</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43025176\">https://news.ycombinator.com/item?id=43025176</a></p>\n<p>Points: 152</p>\n<p># Comments: 144</p>\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: Letting LLMs Run a Debugger","url":"https://github.com/mohsen1/llm-debugger-vscode-extension","date":1739354054,"author":"mohsen1","guid":443,"unread":true,"content":"<p>I just built an experimental VSCode extension called LLM Debugger. It’s a proof-of-concept that lets a large language model take charge of debugging. Instead of only looking at the static code, the LLM also gets to see the live runtime state—actual variable values, function calls, branch decisions, and more. The idea is to give it enough context to help diagnose issues faster and even generate synthetic data from running programs.</p><p>* Active Debugging: It integrates with Node.js debug sessions to gather runtime info (like variable states and stack traces).</p><p>* Automated Breakpoints: It automatically sets and manages breakpoints based on both code analysis and LLM suggestions.</p><p>* LLM Guidance: With live debugging context, the LLM can suggest actions like stepping through code or adjusting breakpoints in real time.</p><p>I built this out of curiosity to see if combining static code with runtime data could help LLMs solve bugs more effectively. It’s rough around the edges and definitely not production-ready</p><p>I’m not planning on maintaining it further. But I thought it was a fun experiment and wanted to share it with you all.</p><p>Check out the attached video demo to see it in action. Would love to hear your thoughts and any feedback you might have!</p>","contentLength":1250,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43023698"},{"title":"TL;DW: Too Long; Didn't Watch Distill YouTube Videos to the Relevant Information","url":"https://tldw.tube/","date":1739326517,"author":"pkaeding","guid":454,"unread":true,"content":"\n<p>Article URL: <a href=\"https://tldw.tube/\">https://tldw.tube/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=43021044\">https://news.ycombinator.com/item?id=43021044</a></p>\n<p>Points: 235</p>\n<p># Comments: 161</p>\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: Mapping the Unix Magic Poster – An Interactive Annotation Project","url":"https://drio.github.io/unixmagic/","date":1739312557,"author":"drio","guid":442,"unread":true,"content":"<p>I built this as a static site that lets us annotate the Unix Magic poster by placing markers on references and adding descriptions to explain them. I've added a few so far, but there's much more to document.</p><p>What I love about this approach is that contributions happen not just on the site itself but also through PRs, where we can discuss and refine the details of each reference. Feel free to send a PR!</p><p>Would love feedback, suggestions, and PRs from the community!</p>","contentLength":465,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43019136"},{"title":"Show HN: I made a tiny book using a pen-plotter and AI","url":"https://muffinman.io/blog/the-tiny-book-of-great-joys/","date":1739209951,"author":"stankot","guid":441,"unread":true,"content":"<p>If you are interested in how I over-engineered the process of making a tiny book for my wife, using AI, a pen plotter, a 3D printer, and a lot of time, you are in the right place. The book is titled  , and here is how it turned out:</p><p>My wife is delighted with it, so it was worth all the effort.</p><p>This post will take you through the process. It will be a long one, but please stick around - I promise there will be a lot of pretty pictures.</p><p>Here is the outline of the post:</p><p>I had this idea for a while after seeing something similar somewhere on the internet.. Since then, I always wanted to make one for my wife - a physically small book with a bunch of small drawings of our memories together, inside jokes, and little things she likes.</p><p>I wanted the illustrations to be hand-drawn, and I had a plan to ask my friend to do them. But I knew he would refuse any kind of payment, so I felt bad adding more work to his plate. So I shelved the idea, but every now and then, it would pop up in my head.</p><p>Fast forward a few years - we got a kid, and our routine completely changed. We are enjoying it a lot, but it can be very exhausting, and every day seems identical to the last. That's why I decided I needed to do something for her to break the routine. The book idea seemed perfect - personal and handcrafted - so I gave it a try.</p><p>To be able to do everything myself, I went to create digital drawings and then draw them on paper using my trusty pen plotter.</p><p>With the idea in place, I moved on to creating the drawings - which turned out to be a challenge of its own.</p><p>For pen plotting, one needs vector files, so I started drawing in Figma. Unfortunately, I quickly realized that my drawing skills would not get me the result I had envisioned. Determined to do it this time, I decided to try using AI to generate images.</p><p>I got myself a Midjourney subscription and started playing with it. It took a lot of failed attempts to figure out how to get drawings that were simple and had a strong hand-drawn feel to them. Even then, I ended up editing every one of them, but more on that later.</p><p>One of the first images I was satisfied with (it didn't end up in the book, though):</p><p>It took a lot of time, but it was fun. Failed attempts were often quirky and funny, and I was learning how to use the tool. And it made me feel like a secret agent, doing it next to my wife, who had no idea what I was up to.</p><p>I may be wrong, but I think Midjourney wasn't built for the kind of illustrations I had in mind. I was after simple, hand-drawn illustrations that felt personal. Luckily, I found a style reference () that worked well for my case. I used it to generate almost all of the drawings that ended up in the book. For those who haven't used Midjourney - you can use images as style references to influence the style of images you want to generate.</p><p>Most of my images were generated using that  code and a  between 150 and 400 (it can go from 0 to 1000).</p><p>As for the prompts, these are the key terms I combined with the description and the style reference:</p><ul><li>isolated on white background</li></ul><p>It took me a lot of tries - between 10 and 30 attempts for each image you see in the book.</p><p>Once I solved the image generation part, I had to figure out how to turn them into vector files for plotting. The first thing I tried was something similar to halftone. As you can see below, in this process, the images completely lost the hand-drawn feel.</p><p>Then I remembered <a href=\"https://www.instagram.com/p/CNJ_ZBOHZKj/\">this plot</a> of Marble Machine X I did a while ago, for which I used AutoTrace to convert the original image to a vector file. The great thing about AutoTrace is that it supports \"centerline tracing\". And this time, I learned that Inkscape has a great AutoTrace plugin, which made it even easier to convert.</p><h3>What makes centerline tracing different</h3><p>Most of the tools that convert raster to vector images do it by outlining shapes. This is not suitable for plotting, as each line in the original image becomes a sausage-like shape. Centerline tracing, on the other hand, tries to draw a single line following the middle path through shapes. Don't worry if it sounds confusing; the example below should make things clearer.</p><p>Here is the image of Link from  generated by Midjourney:</p><p>After applying a common vectorization technique, we get this. As you can see, each line in the original drawing is now outlined, creating this messy-looking image.</p><p>But if we use centerline tracing, it suddenly looks a lot more like a drawing. It is not perfect, but don't worry - we are going to clean it up in the next step.</p><p>In the points where lines touch or cross, AutoTrace is not sure which line to follow and creates these funky-looking joints. Here is an exaggerated example to show you what I'm talking about. Input is the raster image at the top and the vectorized result is at the bottom:</p><p>But I found out that if I roughly separate these lines, I get a much better result.</p><p>Let's now apply this technique to the image of Link we've seen above. After separating lines (and some cleaning up) this is the image I ended up with. It is rough, but it is only used as an input for the tracing process, so it doesn't really matter. This was manual and somewhat tedious process, but I enjoyed it overall. It was a sort of meditation for me.</p><p>And finally, when we trace this image, we get a really nice and clean vector file perfect for plotting. <img alt=\"Very clean vectorized image of Link\" src=\"https://muffinman.io/img/tiny-book/link-05-after.png\"></p><p>Here is another example. We start with the image I generated using Midjourney:</p><p>After editing, removing details and separating lines, we get this one:</p><p>And the traced vector result:</p><p>You'll notice that in both examples I did  . I did that for pretty much all of the images, to fix things I wasn't able to polish using prompts. I also removed a lot of details to make sure images are crisp and readable at the small size.</p><p>All of this took a lot of experimentation, but it gave me a pretty solid workflow which I used to generate all of the images. The complete flow looks like this:</p><ul><li>Generate images using Midjourney.</li><li>Upscale them two times, because upscaled images were easier to edit and tracing was more precise.</li><li>Clean up, redraw and separate lines by hand using Gimp.</li><li>Use Inkscape plugin to run AutoTrace centerline tracing.</li></ul><p>It took me a while to generate all the images, and the fact that I was trying to keep it a secret from my wife didn't help. I think I did it over the span of two weeks, mostly in the evening after she would go to bed.</p><h3> never stood a chance!</h3><p>Before we continue I just want to show you two funky images of Link that really made me laugh:</p><p>With the drawings ready, I turned to the next crucial part - the text. I first wanted to write everything by hand, photograph it and then vectorize it in the same way I did with the images. But it was a hassle - I had to do a lot of editing for text to look as my handwriting.</p><p>Evil Mad Scientist, the maker of my pen plotter, has a fantastic tool called <a href=\"https://wiki.evilmadscientist.com/Hershey_Text\">Hershey Text</a>. It contains a bunch of single-line fonts ideal for plotting. I chose the EMS Elfin font as it looked playful and hand-drawn. I used it to write all of the text in the book and I think it turned out great.</p><p>The tricky part with bookbinding is that pages are not printed in order, but in a way that when you fold the sheets in half, you get the right order. I used Figma to design the layout, with a great care to make sure pages are in order after double-sided plotting.</p><p>Here is the layout laid out on A4 sized paper. Sorry for blurring the text, but a lot of it is very personal and I want to keep it for our eyes only.</p><p>Plotting is the part that went the smoothest, but not without hiccups. I usually use Pigma Micron blackliner markers. They use archival quality ink and they are literally indestructible. But this time, even the thinnest one I had was too thick for the book this small.</p><p>Here you can see the first  using markers of 0.2mm and 0.1mm thickness respectively. Lines got a bit smudged and looked much thicker than I expected. This was also the moment I realized I need to remove  from the images to make them readable at this size.</p><p>I needed to find a thinner pen.</p><h3>Technical pen to the rescue</h3><p>Blackliner markers were made as a more practical replacement for technical pens. But from what I've read, an old-school technical pen was the only thing capable of achieving super-fine lines I wanted. I went online and ordered Rotring Isograph 0.2mm. As soon as it arrived I sneaked out to my study and did another test plot using it. Oh boy, was I happy when I saw the result:</p><p>Lines were thin and crisp and at this point I was convinced the project will be a success!</p><p>All of the first plots were done on 120gsm printer paper. It is somewhat thick paper and drawings looked fantastic. Unfortunately, when I bound the pages together, the drawings and letters would get transferred on the opposite pages. I could probably get away with it, considering the whole hand made feel of the book. But I wanted it to be perfect.</p><p>A friend advised me to leave ink to dry for a few hours. I left each side to dry for 24 hours, but it smudged again. Next time I tried putting the plot (before cutting the pages) between two sheets of papers and pressing it with heavy books. I did that for more than 24 hours, but still after cutting and bounding the pages, they got smudged again. At this point I was becoming somewhat desperate. As the last resort I ordered different, 100gsm paper and to my relief it worked! Crisis averted!</p><p>In the final version you can still see tiny traces on a few pages, but these are barely visible and don't really bother me.</p><p>After plotting and cutting I was left with a stack of somewhat delicate pages. Now, it was finally time to turn them into a book.</p><p>As you can imagine, I had zero bookbinding experience. There are a lot of resources online, but two of them were crucial for my project as they were on how to bind tiny books:</p><p>After reading and watching these and a few generic articles on bookbinding, I gathered enough info to try doing it myself. I thought I was super clever because I 3D printed sides and spine of the book. I designed sewing holes in the spine so I can connect the pages directly to it without using glue. It was a decent idea, but it left a gap between two  . Still, I went with it for the first try.</p><p>I laid everything down on the canvas that the book would be wrapped in and started assembling it. But I made a crucial mistake - I used super glue. It dries quickly, it is stiff, and doesn't glue 3D printed plastic well and it dissolved the paper I used. Long story short, I made a mess. But I didn't stress too much, I just proclaimed that version is a prototype and used it as a learning experience.</p><p>I ordered proper bookbinding glue (PVA). While I was waiting for it, I focused on properly sewing the pages together.</p><p>The first time I sewed the pages together, I poked the holes by hand and they were somewhat uneven. Again, it was nothing major, but I didn't like it. So I designed and 3D printed a simple tool to help me drill the holes evenly.</p><p>The tool has two parts, and the pages fit snugly between them. Both top and bottom parts have holes, so I was able to put the needle through and poke perfectly even holes in the pages. I'm very proud of this silly contraption.</p><p>Here you can see all of the eight sheets with sewing holes.</p><p>Fun fact, I designed all 3D parts using JavaScript and <a href=\"https://replicad.xyz/\">Replicad</a> library. Here is <a href=\"https://studio.replicad.xyz/workbench?from-url=https://muffinman.io/img/tiny-book/model.js\">a link</a> if you want to play with the model in your browser.</p><p>But I ditched the 3D printed spine and used the technique called , which works great when you have only two signatures. It made signatures way more tight than when I connected them separately to the 3D printed spine.</p><p>When the glue arrived, I plotted everything again and took it from the top. I swapped 3D printed sides for cardboard. Using proper glue was a game changer. I had enough time to apply it before it hardened, and when it dried it stayed flexible. And when it got onto my fingers, it was easy to remove. Everything was much cleaner, and I finally managed to put it all together.</p><p>Unfortunately, I was rushing to finish the book, so I didn't take any photos of the process. But here are a few I do have:</p><p>If you are an experienced bookbinder and reading this, I'm sorry for the bookbinding crimes I probably committed. I promise I won't use super glue again.</p><p>It looked great! It was not perfect (more on that below), but I was super happy with how it turned out. It had a distinct handcrafted feel to it, the images turned out fantastic, and I think I really managed to bring out a personal touch with it.</p><p>On the day I finished the book and gave it to my wife, we were both exhausted (our kid was teething, and we had a very rough night), so I thought she would appreciate a little pick-me-up.</p><p>When I gave it to her, the first thing she asked was, \"Will I cry?\". She was brave, but it definitely got her all mushy and made her day. After reading, she carefully put it on the shelf, out of the reach of the little one.</p><p>Then I asked her if she ever suspected I was preparing a surprise for her, and she said that she had no idea. But she also said that she thought it was weird that I would often plot something and not brag about it to her afterwards. It was true, I love showing her my work, but luckily she didn't give it too much thought, and I was able to finish my secret project.</p><h3>One thing I would like to fix</h3><p>Like I mentioned, the book isn't perfect. The sides are a bit too large, so the pages seem too deep inside when the book is closed. For the same reason, the end pages turned out to be a bit short, which gives it a weird, uneven look. It is purely aesthetic, but I think it is the only thing keeping it from being perfect.</p><p>Lesson learned if I ever end up doing something similar.</p><p>It took way longer than it should have—it took me a month and a half to finish it. It took so long because I did it in secrecy, which meant working late in the evenings when my wife and kid were asleep. A bunch of little failures... ehm, I mean  also prolonged the project. And finally, I had to order multiple things, so I was blocked a few times while I was waiting for four different deliveries.</p><p>But the final assembly took me around two and a half hours from start to finish - plotting, cutting, sewing, and bookbinding. Mostly because I had already practiced all of them and defined the exact process.</p><p>It was so much fun. I love projects that span across multiple disciplines. This one touched AI, drawing, plotting, modeling, 3D printing, sewing, and bookbinding. I encountered a lot of little hiccups, but I also learned about all of them. Some of the errors I made could have been avoided if I had been more patient. But I hope you'll cut me some slack - I was super excited and eager to see how it would turn out, and I had limited time windows when I could do it in secrecy. Still, I need to take it as a lesson - being patient will help me save time when doing projects like this one.</p><p>The highlight for me was that I could do it without an illustrator. Love it or hate it, AI ended up being a fantastic tool that filled the gap in my skill set, which was crucial for making the book.</p><p>I hope you enjoyed this write-up as much as I enjoyed making the book and writing the post. And I do hope I inspired you to try making something of your own. If I did, please reach out on GitHub, I would love to see it.</p>","contentLength":15245,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43003052"},{"title":"Show HN: Global 3D topography explorer","url":"https://topography.jessekv.com/","date":1739202885,"author":"jessekv","guid":440,"unread":true,"content":"<div>\n                Click catchements or regions on the map to render them in 3D.\n                <a href=\"https://jessekv.com/post/watersheds/\" target=\"_blank\">Learn more</a></div>","contentLength":105,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43001688"},{"title":"Show HN: A unique generated maze to share with your valentine","url":"https://love.berk.es/","date":1739198155,"author":"berkes","guid":439,"unread":true,"content":"<dd><p> is an art project. It is so called <a href=\"https://en.wikipedia.org/wiki/Generative_art\">generative art</a>: I write the software, and the software creates art autonomously. \n            A nice introduction into generative art is <a href=\"https://www.youtube.com/watch?v=4Se0_w0ISYk\">this talk by Tim Holman</a>.\n          </p></dd><dd><p>\n          In a gallery in London, I came across gorgeaus screenprints by <a href=\"https://rbyrneart.com/\">Ricky Byrne</a>. I loved their use of color and hand-produced feel. Attention for color, layout, tension.\n          So I started experimenting with maze generation algorithms in Rust, with Nannou.<p>\n          In the process, I decided to make it a web app, for valentine, so everyone can create their own maze. And ported the Rust code to TypeScript in a tiny web app. </p><a href=\"https://www.youtube.com/watch?v=HyK_Q5rrcr4\">The Coding Train has a great tutorial set on maze generation</a>. I used the same common recursive backtracking algorithm, because the aesthetics are what I was looking for. </p></dd><dd><p>\n          The names you provide are used to generate <a href=\"https://en.wikipedia.org/wiki/Random_seed \">unique randomnes</a>. \n          This is used in a <a href=\"https://en.wikipedia.org/wiki/Maze_generation_algorithm\">maze generation algorithm</a> to create a maze. \n          I deliberately chose to animate the maze generation, to show the process. It is a slow process, but I think it is interesting to watch it carve out your maze. </p></dd><dd><p>\n          Saving, copying and sharing the maze is disabled until the maze is generated. Once the maze is generated, you can save, copy and share the maze. \n          Sharing, copying won't work on all browsers and is affected by some browser plugins or settings. The best result is on Chrome on Android. \n          </p></dd><dd><p>, the only parameter you can provide is the names. The maze is generated based on these names, and the algorithm is fixed. This is by design. Only the two names determine the artwork. \n            However, you can change the source code, see below.\n          </p></dd><dd><p>\n            The code is available on <a href=\"https://github.com/berkes/art/tree/main/lost-in-love\">GitHub</a>. Feel free to fork, change and improve it, or just have fun with it. </p></dd><dd><ul><li><a href=\"https://nannou.cc/\">Nannou</a> for the original maze generation</li><li><a href=\"https://vitejs.dev/\">Vite</a> for the build and web stuff</li></ul></dd>","contentLength":1890,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43000764"},{"title":"Show HN: HTML visualization of a PDF file's internal structure","url":"https://github.com/desgeeko/pdfsyntax/blob/main/docs/browse.md","date":1739195573,"author":"desgeeko","guid":438,"unread":true,"content":"<p>Hi,\nI've just finished a rebuild of this function and added a lot of new features: info, page index, minimap, inverted index,... \nI think it may be useful for inspection, debugging or just as a learning resource showcasing the PDF file format.\nThis is a pet project and I would be happy to receive some feedback!\nRegards</p>","contentLength":320,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43000303"}],"tags":["hn"]}