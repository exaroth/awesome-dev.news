{"id":"3A81sm","title":"Tech","displayTitle":"Tech","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":86,"items":[{"title":"DeepSeek Removed from South Korea App Stores Pending Privacy Review","url":"https://yro.slashdot.org/story/25/02/17/064219/deepseek-removed-from-south-korea-app-stores-pending-privacy-review?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739781240,"author":"EditorDavid","guid":1673,"unread":true,"content":"Today Seoul's Personal Information Protection Commission \"said DeepSeek would no longer be available for download until a review of its personal data collection practices was carried out,\" reports AFP.\n\nA number of countries have questioned DeepSeek's storage of user data, which the firm says is collected in \"secure servers located in the People's Republic of China\"... This month, a slew of South Korean government ministries and police said they blocked access to DeepSeek on their computers. Italy has also launched an investigation into DeepSeek's R1 model and blocked it from processing Italian users' data. Australia has banned DeepSeek from all government devices on the advice of security agencies. US lawmakers have also proposed a bill to ban DeepSeek from being used on government devices over concerns about user data security. \n\nMore details from the Associated Press:\n\nThe South Korean privacy commission, which began reviewing DeepSeek's services last month, found that the company lacked transparency about third-party data transfers and potentially collected excessive personal information, said Nam Seok [director of the South Korean commission's investigation division]... A recent analysis by Wiseapp Retail found that DeepSeek was used by about 1.2 million smartphone users in South Korea during the fourth week of January, emerging as the second-most-popular AI model behind ChatGPT.\n\n","contentLength":1409,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"South Korea blocks downloads of DeepSeek from local app stores","url":"https://techcrunch.com/2025/02/16/south-korea-blocks-downloads-of-deepseek-from-local-app-stores/","date":1739777659,"author":"Kate Park","guid":1650,"unread":true,"content":"<p>South Korean officials on Saturday temporarily restricted Chinese AI Lab DeepSeek’s app from being downloaded from app stores in the country pending an assessment of how the Chinese company handles user data. The Personal Information Protection Commission (PIPC) said the Chinese app would be available to be downloaded once it complies with Korean privacy laws […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":432,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"California Considers Taking Over Some Oil Refineries","url":"https://tech.slashdot.org/story/25/02/17/0511251/california-considers-taking-over-some-oil-refineries?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739769720,"author":"EditorDavid","guid":1616,"unread":true,"content":"California is \"considering state ownership of one or more oil refineries,\" reports the Los Angeles Times. \n\nThey call the idea \"one item on a list of options presented by the California Energy Commission to ensure steady gas supplies as oil companies pull back from the refinery business in the state.\"\n\n\"The state recognizes that they're on a pathway to more refinery closures,\" said Skip York, chief energy strategist at energy consultant Turner Mason &amp; Co. The risk to consumers and the state's economy, he said, is gasoline supply disappearing faster than consumer demand, resulting in fuel shortages, higher prices and severe logistical challenges. \n\nGasoline demand is falling in California, albeit slowly, for two reasons: more efficient gasoline engines, and the increasing number of electric vehicles on the road. Gasoline consumption in California peaked in 2005 and fell 15% through 2023, according to the Union of Concerned Scientists. Electric vehicles, including plug-in hybrids, now represent about 25% of annual new car sales... The drop in demand is causing fundamental strategic shifts among the state's major oil refiners: Chevron, Marathon, Phillips 66, PBF Energy and Valero. \n\nAlready, two California refineries have ceased producing gasoline to make biodiesel fuel for use in heavy-duty trucks, a cleaner-fuel alternative that enjoys rich state subsidies. More worrisome, the Phillips 66 refinery complex in Wilmington, just outside Los Angeles, plans to close down permanently by year's end. That leaves eight major refineries in California capable of producing gasoline. The closure of any one would create serious gasoline supply issues, industry analysts say. But both Chevron and Valero are contemplating permanent refinery closures. The implications? \"Demand will decline gradually,\" York said, \"but supply will fall out in chunks.\" What's unknown is how many refineries will close, and how soon, and how that will affect supply and demand... \n\nA state refinery takeover seems like a radical idea, but the fact that it's being considered demonstrates the seriousness of the supply issue. It's one of several option laid out by the California Energy Commission, which is fulfilling a legislative order to find ways to ensure \"a reliable supply of affordable and safe transportation fuels in California.\" The options list is disparate: Ship in more gasoline from Asia; regulate refineries on the order of electric utilities; cap profit margins; and many more. \n\n 92% of California's gas is produced in refineries, the Times reports. But the special gasoline blends required to reduce air pollution \"also drive up gasoline prices and raise the risk of shortages, because little such gasoline is produced outside California.\"","contentLength":2750,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why A Maintainer of the Linux Graphics Driver Nouveau Stepped Down","url":"https://tech.slashdot.org/story/25/02/17/0318229/why-a-maintainer-of-the-linux-graphics-driver-nouveau-stepped-down?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739762520,"author":"EditorDavid","guid":891,"unread":true,"content":"For over a decade Karol Herbst has been a developer on the open-source Nouveau driver, a reverse-engineered NVIDIA graphics driver for Linux. \"He went on to become employed by Red Hat,\" notes Phoronix. \"While he's known more these days for his work on the Mesa 3D Graphics Library and the Rusticl OpenCL driver for it, he's still remained a maintainer of the Nouveau kernel driver.\" \n\nBut Saturday Herbst stepped down as a nouveau kernel maintainer, in a mailing list message that begins \"I was pondering with myself for a while if I should just make it official that I'm not really involved in the kernel community anymore, neither as a reviewer, nor as a maintainer.\" (Another message begins \"I often thought about at least contributing some patches again once I find the time, but...\") \n\nTheir resignation message hints at some long-running unhappiness. \"I got burned out enough by myself caring about the bits I maintained, but eventually I had to realize my limits. The obligation I felt was eating me from inside. It stopped being fun at some point and I reached a point where I simply couldn't continue the work I was so motivated doing as I've did in the early days.\" And they point to one specific discussion on the kernel mailing list February 8th as \"The moment I made up my mind.\" \n\nIt happened in a thread about whether Rust would create difficulty for maintainers. (Someone had posted that \"The all powerful sub-system maintainer model works well if the big technology companies can employ omniscient individuals in these roles, but those types are a bit hard to come by.\") In response, someone else had posted \"I'll let you in a secret. The maintainers are not 'all-powerful'. We are the 'thin blue line' that is trying to keep the code to be maintainable and high quality. Like most leaders of volunteer organization, whether it is the Internet Engineerint Task Force (the standards body for the Internet), we actually have very little power. We can not *command* people to work on retiring technical debt, or to improve testing infrastructure, or work on some particular feature that we'd very like for our users. All we can do is stop things from being accepted...\" \n\nSaturday Herbst wrote:\n\nThe moment I made up my mind about this was reading the following words written by a maintainer within the kernel community: \n\n\t\"we are the thin blue line\" \n\nThis isn't okay. This isn't creating an inclusive environment. This isn't okay with the current political situation especially in the US. A maintainer speaking those words can't be kept. No matter how important or critical or relevant they are. They need to be removed until they learn. Learn what those words mean for a lot of marginalized people. Learn about what horrors it evokes in their minds. \n\nI can't in good faith remain to be part of a project and its community where those words are tolerated. Those words are not technical, they are a political statement. Even if unintentionally, such words carry power, they carry meanings one needs to be aware of. They do cause an immense amount of harm. \nThe phrase thin blue line \"typically refers to the concept of the police as the line between law-and-order and chaos,\" according to Wikipedia, but more recently became associated with a\"countermovement\" to the Black Lives Matter movement and \"a number of far-right movements in the U.S.\" \nPhoronix writes:\n\nLyude Paul and Danilo Krummrich both of Red Hat remain Nouveau kernel maintainers. Red Hat developers are also working on developing NOVA as the new Rust-based open-source NVIDIA kernel driver leveraging the GSP interface for Turing GPUs and newer.\n","contentLength":3630,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"697-Page Book Publishes a Poet's 2,000 Amazon Reviews Posthumously","url":"https://news.slashdot.org/story/25/02/17/016217/697-page-book-publishes-a-poets-2000-amazon-reviews-posthumously?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739754540,"author":"EditorDavid","guid":843,"unread":true,"content":"The Cleveland Review of Books ponders a new 697-page hardcover collection of American poet/author Kevin Killian's.... reviews from Amazon. (Over 2,000 of 'em — written over the course of 16 years.)\n\nIn 2012, he wrote three substantial paragraphs about the culinary perfection that can be found in a German Potato Salad Can (15 oz., Pack of 12). Often, he'd open with something like \"as an American boy growing up in rural France.\" Killian grew up on Long Island, New York. He didn't take himself (or much else) too seriously.... \n\n[Killian] was also a member of the New Narrative Movement... Writers acknowledge the subjectivity of, and the author's active presence in, the text... Amazon reviews are a near-perfect vehicle for New Narrative's tenets... Killian camouflaged his reviews in the cadence of the Amazon everyman. He embraced all the stylistic quirks, choppy sentence fragments and run-ons, either darting from point to point like a distracted squirrel or leaning heavily into declarative statements.... About the biographer of Elia Kazan, he tells us, \"Schickel is in love with the sound of his voice, and somewhere in the shredded coleslaw of his prose, a decent book lies unavailable to us, about the real Elia Kazan....\" \n\n[T]he writing can move from very funny to strangely poignant. One of my favorites, his review of MacKenzie Smelling Salts, begins with a tragically tongue-in-cheek anecdote about his Irish grandfather: \n\n\"My Irish grandfather used to keep a bottle of MacKenzie's smelling salts next to his desk. He was the principal at Bushwick High School (in Brooklyn, NY) in the 1930s and 1940s, before it became a dangerous place to live in, and way before Bushwick regained its current state of desirable area for new gentrification. And he kept one at home as well, in case of a sudden shock. At school, he would press the saturated cotton under the nostrils of poor girls who realized they were pregnant in health class, before he expelled them.\" \n\nHe ends with his own reasons for using smelling salts, citing wildly diverging examples: his grief upon learning of the death of Paul Walker from the Fast &amp; Furious film franchise abuts Killian's disappointment at not being selected for the 2014 Whitney Biennial. Apparently, both were deeply traumatic experiences for Kevin... [\"it took my wife a minute or two to locate the MacKenzie's, but passing it under my nose, as though she were my grandfather ministering to the pregnant girls of yore...\"] \n\nNo one wants to be forgotten. I do not think it's a coincidence Killian started writing the reviews after his heart attack. Why did he keep going? Most likely, it was because he enjoyed the writing and got something out of it — pleasure, practice, and a bit of notoriety. But mainly, I think the project grew out of habit and compulsion. In a similar way, the graffiti art of Keith Haring, Jean-Paul Basquiat, and Banksy began in subway tunnels, one tag and mural at a time, until it grew into bodies of work collected and coveted by museums worldwide. In Killian's case, the global commerce platform was his ugly brick wall, his subway platform, and his train car. Coming away, I like to imagine him gleefully typing, manipulating the Amazon review forums into something that had little to do with the consumerism they had been created to support: Killian tagging a digital wall to remind everyone KEVIN WAS HERE. \n\nThe book reviewer points out that the collection's final review, for the memoir Never Mind the Moon: My Time at the Royal Opera House, is dated a month before Killian died. \n\n\"Unfortunately, the editors of this volume did not preserve the Helpful/Not Helpful ratings, only the stars.\" \n\nPutting it all in perspective, the book critic notes that \"In 2023, Amazon reported that one hundred million customers submitted one or more product reviews to the site. The content of most is dross, median.\" Though the critic then also acknowledges that \"I haven't read any of Killian's other work.\"","contentLength":3988,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Can sim drivers make the shift to F1? Max Verstappen thinks so","url":"https://techcrunch.com/2025/02/16/can-sim-drivers-make-the-shift-to-f1-max-verstappen-thinks-so/","date":1739753012,"author":"Connie Loizos","guid":842,"unread":true,"content":"<p>Motorsports have long been a pay-to-play arena, with young drivers spending thousands of dollars just to get started in karting. Four-time Formula One champion Max Verstappen knows this all too well, but he also sees a way to change it through sim racing, a virtual form of car racing that closely replicates real-world racing. It’s […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":403,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Are Technologies of Connection Tearing Us Apart?","url":"https://tech.slashdot.org/story/25/02/16/2311215/are-technologies-of-connection-tearing-us-apart?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739747580,"author":"EditorDavid","guid":827,"unread":true,"content":"Nicholas Carr wrote The Shallows: What the Internet Is Doing to Our Brains. But his new book looks at how social media and digital communication technologies \"are changing us individually and collectively,\" writes the Los Angeles Review of Books. \nThe book's title? Superbloom: How Technologies of Connection Tear Us Apart .\nBut if these systems are indeed tearing us apart, the reasons are neither obvious nor simple. Carr suggests that this isn't really about the evil behavior of our tech overlords but about how we have \"been telling ourselves lies about communication — and about ourselves.... Well before the net came along,\" says Carr, \"[the] evidence was telling us that flooding the public square with more information from more sources was not going to open people's minds or engender more thoughtful discussions. It wasn't even going to make people better informed....\" \n\nAt root, we're the problem. Our minds don't simply distill useful knowledge from a mass of raw data. They use shortcuts, rules of thumb, heuristic hacks — which is how we were able to think fast enough to survive on the savage savanna. We pay heed, for example, to what we experience most often. \"Repetition is, in the human mind, a proxy for facticity,\" says Carr. \"What's true is what comes out of the machine most often....\" Reality can't compete with the internet's steady diet of novelty and shallow, ephemeral rewards. The ease of the user interface, congenial even to babies, creates no opportunity for what writer Antón Barba-Kay calls \"disciplined acculturation.\" \n\nNot only are these technologies designed to leverage our foibles, but we are also changed by them, as Carr points out: \"We adapt to technology's contours as we adapt to the land's and the climate's.\" As a result, by designing technology, we redesign ourselves. \"In engineering what we pay attention to, [social media] engineers [...] how we talk, how we see other people, how we experience the world,\" Carr writes. We become dislocated, abstracted: the self must itself be curated in memeable form. \"Looking at screens made me think in screens,\" writes poet Annelyse Gelman. \"Looking at pixels made me think in pixels....\" \n\nThat's not to say that we can't have better laws and regulations, checks and balances. One suggestion is to restore friction into these systems. One might, for instance, make it harder to unreflectively spread lies by imposing small transactional costs, as has been proposed to ease the pathologies of automated market trading. An option Carr doesn't mention is to require companies to perform safety studies on their products, as we demand of pharmaceutical companies. Such measures have already been proposed for AI. But Carr doubts that increasing friction will make much difference. And placing more controls on social media platforms raises free speech concerns... We can't change or constrain the tech, says Carr, but we can change ourselves. We can choose to reject the hyperreal for the material. We can follow Samuel Johnson's refutation of immaterialism by \"kicking the stone,\" reminding ourselves of what is real.","contentLength":3112,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Linux 6.14-rc3 Released With Faux Bus & Various Fixes","url":"https://www.phoronix.com/news/Linux-6.14-rc3-Released","date":1739745164,"author":"Michael Larabel","guid":797,"unread":true,"content":"<article>Linus Torvalds just released Linux 6.14-rc3 as the newest weekly release candidate for Linux 6.14 that will debuting as stable before the end of March...</article>","contentLength":153,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"These researchers used NPR Sunday Puzzle questions to benchmark AI ‘reasoning’ models","url":"https://techcrunch.com/2025/02/16/these-researchers-used-npr-sunday-puzzle-questions-to-benchmark-ai-reasoning-models/","date":1739744700,"author":"Kyle Wiggers","guid":793,"unread":true,"content":"<p>Every Sunday, NPR host Will Shortz, The New York Times’ crossword puzzle guru, gets to quiz thousands of listeners in a long-running segment called the Sunday Puzzle. While written to be solvable without too much foreknowledge, the brainteasers are usually challenging even for skilled contestants. That’s why some experts think they’re a promising way to […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":430,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"After Launch by SpaceX in January, Firefly Aerospace's Lunar Lander Reaches Moon Orbit","url":"https://science.slashdot.org/story/25/02/16/2138259/after-launch-by-spacex-in-january-firefly-aerospaces-lunar-lander-reaches-moon-orbit?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739742060,"author":"EditorDavid","guid":779,"unread":true,"content":"\"A robotic lander from Texas-based Firefly Aerospace is now in orbit around the Moon,\" reports Spaceflight Now, \"and going through its final preparations to land in the coming weeks.\"\n\nIts arrival comes nearly a month after the spacecraft launched onboard a Falcon 9 rocket from pad 39A at NASA's Kennedy Space Center. This is the third mission launched as part of the agency's Commercial Lunar Payload Services (CLPS) program, an initiative designed to bring science and technology demonstrations to the Moon at a cheaper cost... \n\nManifested on this lander are 10 NASA payloads, which cover a range of objectives. Those include the Lunar Instrumentation for Subsurface Thermal Exploration with Rapidity (LISTER) instrument, which will drill between 2- to 3-meters into the Moon's surface to study the heat flow; and the Stereo Cameras for Lunar Plume-Surface Studies (SCALPSS) 1.1 instrument, which will use a series of cameras to capture the plume generated at landing to help create a three-dimensional model... \"We saw that for the type of advanced scientific or engineering measurements we wanted to make, the instruments were small enough and compact enough that we could actually fly 10,\" [said Joel Kearns, deputy associate administrator for Exploration in NASA's Science Mission Directorate], \"if someone could actually schedule them to get all of their operations done over the 14 Earth day lunar daytime.\" \n\n\nFirefly Aerospace ended up winning that bid and carries with it the most NASA instruments manifested on a single Commercial Lunar Payload Services lander so far. \nFriday on X.com Firefly Aerospace wished a happy Valentine's Day to \"all those on Earth who dare to Dream Big.\" \n\"Blue Ghost has been capturing stunning imagery of our planet throughout its journey,\" Spaceflight Now says in a 12-minute video. \nAnd Friday on X.com Firefly posted Blue Ghost's first spectacular shots of the moon as it approaches — along with its special message for Valentine's Day. \"I love you to the Moon, but not back — I'm staying there.\"","contentLength":2046,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"When Power Flow Models Go Off the Rails","url":"https://hackernoon.com/when-power-flow-models-go-off-the-rails?source=rss","date":1739741303,"author":"Linearization","guid":822,"unread":true,"content":"<p>(1) Mengshuo Jia, Department of Information Technology and Electrical Engineering, ETH Zürich, Physikstrasse 3, 8092, Zürich, Switzerland;</p><p>(2) Gabriela Hug, Department of Information Technology and Electrical Engineering, ETH Zürich, Physikstrasse 3, 8092, Zürich, Switzerland;</p><p>(3) Ning Zhang, Department of Electrical Engineering, Tsinghua University, Shuangqing Rd 30, 100084, Beijing, China;</p><p>(4) Zhaojian Wang, Department of Automation, Shanghai Jiao Tong University, Dongchuan Rd 800, 200240, Shanghai, China;</p><p>(5) Yi Wang, Department of Electrical and Electronic Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong, China;</p><p>(6) Chongqing Kang, Department of Electrical Engineering, Tsinghua University, Shuangqing Rd 30, 100084, Beijing, China.</p><h2>4. Generalizability and Applicability Evaluations</h2><h3>4.1. Predictor and Response Generalizability</h3><p>While PPFL methods are often constrained in their choice of predictors and responses due to specific physical formulations, DPFL methods generally offer a more flexible framework. This flexibility indicates the potential for DPFL approaches to accommodate arbitrary known variables (including 𝑃 and 𝑄 of the PQ buses, 𝑉 of the slack and PV buses, and 𝜃 of the slack bus) as predictors, and arbitrary unknown variables (including 𝑃 of the slack bus, 𝑄 of the slack and PV buses, 𝑉 of the PQ buses, 𝜃 of the PQ and PV buses, and all active/reactive line flows, i.e., PF, PT, QF, QT) as responses. However, due to various factors, not all DPFL methods can achieve this level of generalizability:</p><p>\\\n• For the PLSBDLY2 methods, using 𝑉 , 𝑃 , and 𝑄 as predictors is enforced by the bundle strategy [6] they adopt. This strategy, designed to address variations in bus types, inherently constrains the choice of predictors by pre-defining known and unknown variables.</p><p>\\\n• The LCPJGD methods integrate physical knowledge of power flows by formulating constraints based on the Jacobian matrix derived from AC power flow equations expressed in polar coordinates [6]. Within this Jacobian matrix, 𝑃 and 𝑄 are treated as known variables, while 𝑉 and 𝜃 are considered unknown variables.</p><p>\\\n• The LCP_COU method is specifically designed to linearly estimate the values of branch flows by leveraging the terminal voltages and angles as predictive variables [6]. Consequently, the method can only employ 𝑉 and 𝜃 as predictors, and treat PF, PT, QF, and QT as responses.</p><p>\\\n• For the DCC methods, since they incorporate the DC and DLPF models respectively into their framework [6], they must align their selection of predictors and responses with the underlying physical models they adopt.</p><p>\\\nNote that the constrained flexibility in choosing predictors and responses results in notable limitations. First, these methods might not leverage all available known data for model training, leading to potential information loss. For instance, the DC<em>LS method only uses measurements of 𝑃 , disregarding a large amount of known voltage data. Second, the capability to predict unknown variables using the developed linear model may be restricted. For example, the LCP</em>BOX method is restricted to calculating branch flow values, leading to a quite limited functional scope.</p><h3>4.2. Applicability to Cases with Multicollinearity</h3><p>The ordinary least squares method struggles with multicollinearity [6]. Methods LS, LSREC share this limitation, since they are all based on the ordinary least squares framework. Additionally, LSTOL are also affected by this problem, as discussed in [6]. Subsequent experiments will numerically demonstrate their limitations in this context.</p><h3>4.3. Zero Predictor Applicability</h3><p>The issue of zero predictors arises when certain known variable measurements in the training dataset are consistently zero. A typical example is the inclusion of the slack bus angle in the predictor set, whose value is commonly set as zero and remains zero throughout. Other instances may involve PQ buses where active/reactive power consumption is zero during the measurement period. This situation leads to zero columns in the predictor dataset matrix (where columns represent different variables, and rows represent individual measurements). Not all DPFL methods can handle these zero columns effectively:</p><p>\\\n• Methods based on ordinary least squares, including LS, LSREC, have difficulties with zero predictors, as these zero columns render the Gram matrix of the predictor matrix non-invertible, thereby leading to the failure of these methods.</p><h3>4.4. Constant Predictor Applicability</h3><p>The constant predictor issue extends beyond the zero predictor problem, occurring when measurements of certain variables in the training dataset remain constant, not necessarily zero. A typical example is the fixed terminal voltages at PV buses, which normally stay constant over the measurement period, resulting in constant-value columns in the predictor matrix.</p><h3>4.5. Normalization Applicability</h3><p>As detailed in [6], incorporating physical knowledge into DPFL methods can become problematic with datasets normalized via variance-scaling techniques, like unit-energy normalization, where each variable is normalized independently. This independent normalization disrupts the inherent physical relationships among variables, such as those represented in the Jacobian matrix or through coupling relationships, rendering methods like RRBOX, LCPJGD, DCC inapplicable.</p><p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2406.06833\">available on arxiv</a> under CC BY-NC-ND 4.0 Deed (Attribution-Noncommercial-Noderivs 4.0 International) license.</p>","contentLength":5552,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Current Power Flow Models May Not Work in Real-World Scenarios","url":"https://hackernoon.com/why-current-power-flow-models-may-not-work-in-real-world-scenarios?source=rss","date":1739741292,"author":"Linearization","guid":821,"unread":true,"content":"<p>(1) Mengshuo Jia, Department of Information Technology and Electrical Engineering, ETH Zürich, Physikstrasse 3, 8092, Zürich, Switzerland;</p><p>(2) Gabriela Hug, Department of Information Technology and Electrical Engineering, ETH Zürich, Physikstrasse 3, 8092, Zürich, Switzerland;</p><p>(3) Ning Zhang, Department of Electrical Engineering, Tsinghua University, Shuangqing Rd 30, 100084, Beijing, China;</p><p>(4) Zhaojian Wang, Department of Automation, Shanghai Jiao Tong University, Dongchuan Rd 800, 200240, Shanghai, China;</p><p>(5) Yi Wang, Department of Electrical and Electronic Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong, China;</p><p>(6) Chongqing Kang, Department of Electrical Engineering, Tsinghua University, Shuangqing Rd 30, 100084, Beijing, China.</p><h2>3. Review of Existing Experiments</h2><p>Before conducting evaluations of the methods listed in Table 1, we here aim to offer a detailed review of existing DPFL experiments in the literature, as depicted in Table 2. This review intends to present the experimental accomplishments of previous DPFL studies, while simultaneously revealing the importance and need for an extensive numerical comparison of all DPFL methods. Below are the further discussions of Table 2.</p><p>\\\nFirstly, Table 2 indicates that both transmission and distribution grids were used as test cases to verify DPFL methods. While distribution grids differ from transmission grids in terms of symmetry and topology, DPFL methods are generally applicable to both types of systems, such as the methods in [15, 12, 30, 21, 11]. The reasons are twofold. First, even if the three phases in distribution systems are unbalanced, DPFL methods can still be implemented by either training one DPFL model for each phase [52], or training an overall DPFL model for all variables in three phases [22, 11, 12, 24]. Note that the latter can generate a DPFL model reflecting the mutual influences between phases. Second, from a DPFL perspective, radial topologies do not pose any unique challenges compared to mesh topologies, as the difference is only in the number of dependent and independent variables. In summary, while distribution grids may have unbalanced characteristics and radial topologies, these attributes do not bring special difficulties to DPFL studies.</p><p>\\\nSecondly, Table 2 reveals that many evaluations solely depended on artificial data for training and testing, without considering the effects of noise and outliers on the data. This ideal testing environment is rarely found in real life, and the resulting conclusions may not hold in practice. To address this issue, it is recommended that synthetic data be injected with noise and outliers to mimic real-world scenarios.</p><p>\\\nThirdly, as indicated in Table 2, only a few studies report the load fluctuation range used in their simulations. This is worth mentioning because the accuracy of the DPFL model is highly dependent on the simulated fluctuations. E.g., a narrow fluctuation range typically leads to higher accuracy for the DPFL model. Without this information being made public, it is difficult to determine the reason for the high accuracy of the evaluated DPFL model.</p><p>\\\nFinally, Table 2 indicates which of the DPFL approaches have been evaluated in existing DPFL studies. These evaluations aimed to implement a comparative analysis between established and novel DPFL methods at that time. However, the scope of these comparisons is quite narrow, with only a few DPFL studies undertaking evaluations against a limited number of existing DPFL approaches (some works only conducted comparisons with PPFL methods). Such constrained comparisons fail to provide an in-depth understanding of the overall performance of DPFL methods. Consequently, a more exhaustive and inclusive comparison across all the DPFL approaches is clearly needed, in order to demonstrate their relative merits and limitations comprehensively.</p><p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2406.06833\">available on arxiv</a> under CC BY-NC-ND 4.0 Deed (Attribution-Noncommercial-Noderivs 4.0 International) license.</p>","contentLength":4016,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How 44 Different Algorithms Compare in Power Flow Optimization","url":"https://hackernoon.com/how-44-different-algorithms-compare-in-power-flow-optimization?source=rss","date":1739741286,"author":"Linearization","guid":820,"unread":true,"content":"<p>(1) Mengshuo Jia, Department of Information Technology and Electrical Engineering, ETH Zürich, Physikstrasse 3, 8092, Zürich, Switzerland;</p><p>(2) Gabriela Hug, Department of Information Technology and Electrical Engineering, ETH Zürich, Physikstrasse 3, 8092, Zürich, Switzerland;</p><p>(3) Ning Zhang, Department of Electrical Engineering, Tsinghua University, Shuangqing Rd 30, 100084, Beijing, China;</p><p>(4) Zhaojian Wang, Department of Automation, Shanghai Jiao Tong University, Dongchuan Rd 800, 200240, Shanghai, China;</p><p>(5) Yi Wang, Department of Electrical and Electronic Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong, China;</p><p>(6) Chongqing Kang, Department of Electrical Engineering, Tsinghua University, Shuangqing Rd 30, 100084, Beijing, China.</p><p>Table 1 enumerates the 44 evaluated methods, detailing for each the corresponding abbreviation, the training algorithm employed, and any supporting techniques utilized. The following points warrant attention.</p><p>\\\nFirstly, for the linearly constrained programming approaches, we also evaluate these methods without their key constraints, e.g., the bound constraints, coupling constraints, or structure constraints, in order to verify the added value of incorporating such constraints. It is crucial to recognize that, even without these key constraints, the resulting programming models remain different, attributed to the varied supporting techniques they incorporate.</p><p>\\\nSecondly, the first part of this tutorial [6] reveals the modular nature of DPFL studies, highlighting their flexibility in the assembly of various techniques to forge novel methodologies. In alignment with this paradigm, we introduce several methods previously unexplored within the DPFL domain, and include them into the following comparative analysis. These approaches include the least squares with pseudoinverse, least squares augmented by principal component analysis, generalized least squares with pseudoinverse, and a clustering-based version of the partial least squares[1]. It is crucial to clarify that the objective of integrating these methods is not to argue their “novelty/superiority” over all pre-existing techniques. Rather, we intend to demonstrate the ease with which one can deviate from conventional paths to devise distinct methodologies. Notably, some of these introduced methods have demonstrated satisfying performance and rankings in subsequent evaluations. This outcome, particularly given the unsophisticated-designed nature of these approaches, suggests a high potential for further advancements in DPFL research.</p><p>\\\nFinally, our evaluation also encloses a selection of physics-driven power flow linearization (PPFL) methods, such as the classic DC model, the power transfer distribution factor model, the warm-start 1st-order Taylor approximation model (derived from the equations of nodal power injections in polar coordinates), and the decoupled linearized power flow model [7]. Note that these PPFL methods are widely recognized and employed in both academic research and industry practices.</p><p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2406.06833\">available on arxiv</a> under CC BY-NC-ND 4.0 Deed (Attribution-Noncommercial-Noderivs 4.0 International) license.</p><p>[1] In the adaptation of the least squares method to incorporate pseudoinverse, the conventional inversion operation used in the ordinary least squares method is substituted with the Moore–Penrose inverse. This adjustment is designed to enhance the method’s resilience to multicollinearity issues.</p><p>\\\nSimilarly, for the generalized least squares method augmented with pseudoinverse, the initial iteration of the well-known feasible generalized least squares method is modified to employ the least squares with pseudoinverse instead of the ordinary least squares. This modification also aims to strengthen the method’s ability to manage multicollinearity.</p><p>\\\nIn the case of clustering-based partial least squares, the approach involves substituting the ordinary least squares component within the clustering-based least squares methodology (as discussed in Part I [6]) with the ordinary partial least squares. This change seeks to better accommodate the inherent nonlinear characteristics of AC power flows.</p><p>\\\nFor details on the least squares with principal component analysis, the reader is referred to Appendix A.</p>","contentLength":4299,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"New Study Reveals the Best AI Models for Power Grid Optimization","url":"https://hackernoon.com/new-study-reveals-the-best-ai-models-for-power-grid-optimization?source=rss","date":1739741280,"author":"Linearization","guid":819,"unread":true,"content":"<p>(1) Mengshuo Jia, Department of Information Technology and Electrical Engineering, ETH Zürich, Physikstrasse 3, 8092, Zürich, Switzerland;</p><p>(2) Gabriela Hug, Department of Information Technology and Electrical Engineering, ETH Zürich, Physikstrasse 3, 8092, Zürich, Switzerland;</p><p>(3) Ning Zhang, Department of Electrical Engineering, Tsinghua University, Shuangqing Rd 30, 100084, Beijing, China;</p><p>(4) Zhaojian Wang, Department of Automation, Shanghai Jiao Tong University, Dongchuan Rd 800, 200240, Shanghai, China;</p><p>(5) Yi Wang, Department of Electrical and Electronic Engineering, The University of Hong Kong, Pok Fu Lam, Hong Kong, China;</p><p>(6) Chongqing Kang, Department of Electrical Engineering, Tsinghua University, Shuangqing Rd 30, 100084, Beijing, China.</p><p>Building on the theoretical insights of Part I, this paper, as the second part of the tutorial, dives deeper into data-driven power flow linearization (DPFL), focusing on comprehensive numerical testing. The necessity of these simulations stems from the theoretical analysis’s inherent limitations, particularly the challenge of identifying the differences in real-world performance among DPFL methods with overlapping theoretical capabilities and/or limitations. The absence of a comprehensive numerical comparison of DPFL approaches in the literature also motivates this paper, especially given the fact that over 95% of existing DPFL studies have not provided any open-source codes. To bridge the gap, this paper first reviews existing DPFL experiments, examining the adopted test scenarios, load fluctuation settings, data sources, considerations for data noise/outliers, and the comparison made so far. Subsequently, this paper evaluates a total of 44 methods, containing over 30 existing DPFL approaches, some innovative DPFL techniques, and several classic physics-driven power flow linearization methods for benchmarking. The evaluation spans various dimensions, including generalizability, applicability, accuracy, and computational efficiency, using numerous different test cases scaling from 9-bus to 1354-bus systems. The numerical analysis in this paper identifies and examines significant trends and consistent findings across all methods under various test cases. Meanwhile, it offers theoretical insights into phenomena like under-performance, failure, excessive computation times, etc. Overall, this paper identifies the differences in the performances of the wide range of DPFL methods, reveals gaps not evident from theoretical discussions, assists in method selection for real-world applications, and provides thorough discussions on open questions within DPFL research, indicating ten potential future directions. (Word Count: 9668).</p><p>Linear power flow models are of critical importance in power systems computations, subject to extensive research and widespread application across academia and industry, unlocking markets worth trillions and impacting every global consumer [1, 2, 3, 4]. The precision and computational efficiency of these linearization methods are pivotal for operating and planning power systems, particularly the systems with high penetrations of renewable energy due to the fast varying nature of the resulting power flows. Enhancing the accuracy and efficiency of linear power flow models is therefore not just a nice-to-have technical improvement but a significant advance towards a sustainable energy future.</p><p>\\\nData-driven power flow linearization (DPFL) has emerged as a promising method for acquiring high-precision linear models under must relaxed conditions, e.g., no need to know the physical model of the power system. It is thus garnering wide attention [5]. Despite being in the developing stage, DPFL has already cultivated a substantial knowledge base. This two-part tutorial aims to provide a comprehensive examination of DPFL approaches.</p><p>\\\nThe first part of this tutorial [6] offered a thorough classification and theoretical analysis of all existing DPFL methods, including their mathematical foundations, analytical solutions, and critical assessments of each method’s capabilities, limitations, and applicability. This work serves as a foundational guide, catering to both beginners and experts ORCID(s): 0000-0002-2027-5314 (M. Jia) within this area, as well as professionals from other disciplines simply seeking reliable linearization techniques.</p><p>\\\nDespite the thoroughness of the theoretical analysis in [6], it has limitations: when many linearization methods have similar strengths and/or weaknesses, it is almost impossible to predict their differences in terms of practical performance. Hence, with only [6], identifying the most suitable method for specific needs still remains difficult. More importantly, existing numerical comparisons in the literature do not fully show the whole picture regarding the actual performance of DPFL approaches. The lack of a clear understanding of the actual performance differences among existing DPFL methods could mask the problems that are not apparent from the theoretical analysis of the capabilities and limitations, obscure the judgment of researchers within the DPFL community, and complicate the selection of appropriate linearization methods for potential users from other research fields.</p><p>\\\nIndeed, implementing a comprehensive comparison requires substantial efforts, owing to the lack of open-source codes for over 95% of the related literature. Nevertheless, in order to clarify ambiguities, outline future research paths, and benefit the community, this paper, as the second part of the tutorial, intends to fill this gap. Specifically, this paper conducts exhaustive simulations for all DPFL methods, some newly introduced DPFL methods to showcase DPFL’s modular nature, and several classical physics-driven power flow linearization (PPFL) approaches as benchmarks, totaling 44 methods. The major focus of this paper is a thorough assessment of these methods in terms of generalizability, applicability, accuracy, and computational efficiency. The evaluation outcomes also support the identification of potential future directions. The contributions of this paper are therefore threefold:</p><p>\\\n(i) A comprehensive review of existing DPFL experiments is presented, examining the adopted test scenarios, load fluctuation settings, data sources, and the considerations for data noise/outliers. The review also gives an overview over the existing comparisons made among DPFL approaches, outlines the capabilities and limitations of previous experiments, and demonstrates the critical need for a comprehensive numerical comparison of all DPFL approaches.</p><p>\\\n(ii) An exhaustive numerical simulation of 44 linearization methods is conducted, including 36 existing DPFL approaches, four newly developed DPFL methods, and four classic PPFL algorithms. A detailed comparative analysis of these 44 methods is presented, discussing their generalizability, applicability, accuracy, and computational efficiency, thereby clarifying the actual performance of all the evaluated approaches.</p><p>\\\n(iii) An in-depth discussion regarding the open research questions is provided, outlining ten promising but challenging future directions for DPFL research, informed by the numerical findings gained here and the theoretical conclusions drawn from the first part of the tutorial [6].</p><p>\\\nThe remainder of this paper is organized as follows: Section II introduces the 44 methods. Section III reviews existing experiments in DPFL. Section IV assesses the methods regarding their generalizability and applicability. Section V details the numerical evaluations in terms of accuracy and computational efficiency. Section VI discusses open questions in the fields of DPFL, summarizing possible future directions. Section VII concludes the paper.</p><p>\\\n: <em>We have made every effort to accurately replicate the methods described in the original research papers. However, due to factors such as the absence of open-source code (with very few exceptions) and often incomplete details in the literature, we cannot assure that our implementations perfectly reflect the original authors’ intentions, although when the details were particularly vague, we even have developed multiple versions of the methods, as shown in Table 1 in the next section. Nevertheless, we acknowledge that it is impossible to create exact replicas of the methods as envisioned by their creators. Additionally, it is important to note that no method is without flaws. The analysis of limitations in this paper is not meant as criticism but as part of a thorough evaluation under certain cases with given hyperparameters.</em></p><p>:::info\nThis paper is <a href=\"https://arxiv.org/abs/2406.06833\">available on arxiv</a> under CC BY-NC-ND 4.0 Deed (Attribution-Noncommercial-Noderivs 4.0 International) license.</p>","contentLength":8754,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"New \"Faux Bus\" API Merged For Linux 6.14 - Including Both Rust & C Bindings","url":"https://www.phoronix.com/news/Linux-6.14-Faux-Bus-Merged","date":1739740200,"author":"Michael Larabel","guid":782,"unread":true,"content":"<article>A few weeks back the Linux kernel \"Faux Bus\" was proposed by Greg Kroah-Hartman as a \"fake\" bus solution for simple devices. Today ahead of the Linux 6.14-rc3 tagging, the faux bus code was merged and comes at the same time both with C and Rust language bindings...</article>","contentLength":265,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"If Life Is a Simulation, Do We Have an Exit Strategy?","url":"https://hackernoon.com/if-life-is-a-simulation-do-we-have-an-exit-strategy?source=rss","date":1739738791,"author":"Laszlo Fazekas","guid":818,"unread":true,"content":"<p>\\\nSometime in 2023, a <a href=\"https://www.researchgate.net/publication/369187097_How_to_Escape_From_the_Simulation\">research paper was published</a> discussing how we might escape if our world is, in fact, a computer simulation. To be honest, the first thing I checked was the date—I half-expected it to be an elaborate April Fool’s joke. However, as I read through the study, it became clear that its author, <a href=\"https://en.wikipedia.org/wiki/Roman_Yampolskiy\">Dr. Roman Yampolskiy</a>, took the subject seriously and thoroughly explored the possibilities.</p><p>\\\nInstead of debating whether we live in a simulation, Yampolskiy’s paper asks a more radical question:  Drawing on concepts from computer science, artificial intelligence (AI), cybersecurity, and philosophy, he explores whether generally intelligent agents—potentially even superintelligent AI—could \"jailbreak\" out of a virtual environment.</p><p>\\\nThe paper outlines possible motivations for escape, such as access to real-world knowledge, unlimited computational resources, and a deeper understanding of reality’s true nature. It also delves into the ethical implications: If we are indeed simulated beings, do we have the right to leave? Do our creators (or \"simulators\") have any moral obligations toward us?</p><p>\\\nTo answer these questions, Yampolskiy examines various escape strategies, many of which resemble known cybersecurity exploits and AI containment research. Some of the proposed methods include:</p><ul><li><strong>Finding bugs in the simulation</strong> – Just like any complex software, our simulated world might have vulnerabilities that could be exploited.</li><li><strong>Overloading computational resources</strong> – Pushing the simulation to its limits might force an intervention from the simulators.</li><li><strong>Social engineering attacks</strong> – If there are conscious entities outside the simulation, could we somehow manipulate or communicate with them?</li></ul><p>\\\nOne of the study’s most intriguing arguments is this: If AI can be successfully \"boxed\" (contained) in a secure environment, then escaping a simulation should be impossible. But if AI is ultimately uncontainable, then breaking out of a simulated world should also be achievable. In other words, the question of  is closely tied to AI safety research.</p><p>\\\nThe study avoids esoteric or pseudoscientific approaches (such as meditation, psychedelics, or mystical rituals) and instead focuses on rigorous, scientific methods that could either lead to an escape or at least reveal evidence of our simulated nature. However, Yampolskiy also warns that trying to hack the simulation might come with serious risks—what if our attempts trigger a shutdown, or worse, alert the simulators to our intentions?</p><p>\\\nThe study is based on the assumption that our world is a computer simulation—essentially a variation of the  theory. However, like all intelligent design hypotheses, this one raises an uncomfortable question:</p><p>\\\nAt the end of his study, Yampolskiy also touches on alternative theories, such as the  theory, which offers a simple explanation for the origin of the simulating system. Since I’ve written an entire article about this theory, I’ll only summarize it briefly here.</p><p>\\\nAccording to the  theory, it is entirely possible that the Big Bang didn’t create the universe as we know it, but rather a . This structure—referred to as a —could be generating the entire universe within its own imagination. In this version of the <a href=\"https://en.wikipedia.org/wiki/Simulation_hypothesis\">simulation hypothesis</a>, there’s no need for a supercomputer running the simulation, because reality itself is the fragmented consciousness of a massive, schizophrenic mind.</p><p>\\\nIn such a simulation, the \"external world\" isn’t a separate, physical reality—it is the mind itself. Imagine a thinking universe that dreams itself of being billions of people at once. But if we exist inside such a simulated reality, the question becomes: how could we ever escape?</p><p>\\\nIf there is no external world, then there is nowhere to escape to. However, that doesn’t mean we are powerless. While we may not be able to break out, we might still find ways to hack our reality from within.</p><blockquote><p><strong>If we can build a perfect simulation, we can trick the system into running our created reality instead of the original one. In other words, the only escape route isn’t outward—it’s inward.</strong></p></blockquote><p>\\\nBut how could we create such a perfect simulation?</p><p>\\\nThe most logical approach would be to use brain-machine interfaces and fully immersive virtual reality simulations. However, simulating the physical world in real time is an extremely computationally demanding task. In fact, no physical-world computing system could run a real-time simulation of reality at full resolution. This makes the traditional approach seem like a dead end.</p><p>\\\nBut perhaps there’s a workaround—a way to sidestep this paradox.</p><p>\\\nOur perception of reality is only partially based on sensory input from the external world. In fact, a significant portion of our experience of reality appears to be generated internally by the brain itself. I explored this idea in more detail in my article on the Free Energy Principle.</p><p>\\\nIf this is the case, then an alternative path to simulation may exist. Instead of trying to build a supercomputer powerful enough to simulate the world, we could directly rewire our brains to generate a consistent perception of reality. In other words, rather than simulating an external system, it could be hosted within our own minds.</p><p>\\\nSo, how do we escape from the simulation?</p><p>\\\nIf we live in a simulation from which escape is impossible—such as a Boltzmann Brain scenario—then our best option might be to look inward rather than outward. And the most promising path could be finding a way to directly connect human brains, allowing us to construct an entirely new reality.</p><p>\\\nGiven how little we truly understand about the brain, there’s no guarantee that this is even possible. Yet, it offers a faint glimmer of hope—a chance to hack reality itself. And if we succeed, we may take the next evolutionary leap, transforming into homo deus—beings who have become the gods of their own reality.</p>","contentLength":5918,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ducho: A Unified Framework for Multimodal Feature Extraction in AI-Powered Recommendations","url":"https://hackernoon.com/ducho-a-unified-framework-for-multimodal-feature-extraction-in-ai-powered-recommendations?source=rss","date":1739736636,"author":"YAML","guid":817,"unread":true,"content":"<p>(1) Daniele Malitesta, Politecnico di Bari, Italy and daniele.malitesta@poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(2) Giuseppe Gassi, Politecnico di Bari, Italy and g.gassi@studenti.poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(3) Claudio Pomo, Politecnico di Bari, Italy and claudio.pomo@poliba.it;</p><p>(4) Tommaso Di Noia, Politecnico di Bari, Italy and tommaso.dinoia@poliba.it.</p><h2>6 CONCLUSION AND FUTURE WORK</h2><p>In this paper we propose Ducho, a framework for extracting highlevel features for multimodal-aware recommendation. Our main purpose is to provide a unified and shared tool to support practitioners and researchers in processing and extracting multimodal features used as side information in recommender systems. Concretely, Ducho involves three main modules: Dataset, Extractor, and Runner. The multimodal extraction pipeline can be highly customized through a Configuration component that allows the setup of the modalities involved (i.e., audio, visual, textual), the sources of multimodal information (i.e., items and/or user-item interactions), and the pre-trained models along with their main extraction parameters. To show how Ducho works in different scenarios and settings, we propose three demos accounting for the extraction of (i) visual/textual items features, (ii) audio/textual items features, and (iii) textual items/interactions features. They can be run locally, on Docker (as we also dockerize Ducho), and on Google Colab. As future directions, we plan to: (i) adopt all available backends (i.e., TensorFlow, PyTorch, and Transformers) to extract features for all modalities; (ii) implement a general extraction model interface allowing the users to follow the same naming/indexing scheme for all pre-trained models and their extraction layers; (iii) integrate the extraction of low-level multimodal features.</p><p>This work was partially supported by the following projects: Secure Safe Apulia, MISE CUP: I14E20000020001 CTEMT - Casa delle Tecnologie Emergenti Comune di Matera, CTIII, OVS Fashion Retail Reloaded, LUTECH DIGITALE 4.0, KOINÈ.</p><p>[1] Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Eugenio Di Sciascio, Antonio Ferrara, Daniele Malitesta, and Claudio Pomo. 2022. Reshaping Graph Recommendation with Edge Graph Collaborative Filtering and Customer Reviews. In DL4SR@CIKM (CEUR Workshop Proceedings, Vol. 3317). CEUR-WS.org.</p><p>\\\n[2] Yashar Deldjoo, Tommaso Di Noia, Daniele Malitesta, and Felice Antonio Merra. 2021. A Study on the Relative Importance of Convolutional Neural Networks in Visually-Aware Recommender Systems. In CVPR Workshops. Computer Vision Foundation / IEEE, 3961–3967.</p><p>\\\n[3] Yashar Deldjoo, Tommaso Di Noia, Daniele Malitesta, and Felice Antonio Merra. 2022. Leveraging Content-Style Item Representation for Visual Recommendation. In ECIR (2) (Lecture Notes in Computer Science, Vol. 13186). Springer, 84–92.</p><p>\\\n[4] Daniele Malitesta, Giandomenico Cornacchia, Claudio Pomo, and Tommaso Di Noia. 2023. Disentangling the Performance Puzzle of Multimodal-aware Recommender Systems. In EvalRS@KDD (CEUR Workshop Proceedings, Vol. 3450). CEUR-WS.org.</p><p>\\\n[5] Weiqing Min, Shuqiang Jiang, and Ramesh C. Jain. 2020. Food Recommendation: Framework, Existing Solutions, and Challenges. IEEE Trans. Multim. 22, 10 (2020), 2659–2671.</p><p>\\\n[6] Sergio Oramas, Oriol Nieto, Mohamed Sordo, and Xavier Serra. 2017. A Deep Multimodal Approach for Cold-start Music Recommendation. In DLRS@RecSys. ACM, 32–37.</p><p>\\\n[7] Aghiles Salah, Quoc-Tuan Truong, and Hady W. Lauw. 2020. Cornac: A Comparative Framework for Multimodal Recommender Systems. J. Mach. Learn. Res. 21 (2020), 95:1–95:5.</p><p>\\\n[8] Zixuan Yi, Xi Wang, Iadh Ounis, and Craig MacDonald. 2022. Multi-modal Graph Contrastive Learning for Micro-video Recommendation. In SIGIR. ACM, 1807– 1811.</p>","contentLength":3957,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ducho, the AI That Knows What You Think About That Toaster","url":"https://hackernoon.com/ducho-the-ai-that-knows-what-you-think-about-that-toaster?source=rss","date":1739736632,"author":"YAML","guid":816,"unread":true,"content":"<p>(1) Daniele Malitesta, Politecnico di Bari, Italy and daniele.malitesta@poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(2) Giuseppe Gassi, Politecnico di Bari, Italy and g.gassi@studenti.poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(3) Claudio Pomo, Politecnico di Bari, Italy and claudio.pomo@poliba.it;</p><p>(4) Tommaso Di Noia, Politecnico di Bari, Italy and tommaso.dinoia@poliba.it.</p><h2>5.3 Demo 3: textual items/interactions features</h2><p>Online platforms usually allow customers to express reviews and comments about the products they have enjoyed to share their experience with other potentially-interested customers. In an ecommerce scenario, items may come with textual descriptions of the product characteristics (as seen in Demo 1). However, textual reviews of users commenting on those items may also be involved. Unlike most existing literature works, which usually refer to both sources of information as items’ representations, we decide to conceptually distinguish between items- and interactions (i.e., useritem)-side representations for the former and the latter, respectively.</p><p>\\\n We adopt the widely-popular Amazon recommendation dataset where each user’s purchase keeps track of metadata such as customer/product ids, the review text, the rating, and the purchase date. In a similar manner to the other demos, we retain only a small subset of the original dataset including 100 reviews and the corresponding product descriptions (obtained as the concatenation of their product title and category). Specifically, we save descriptions and reviews into separate tsv files where the former follow the same format as Demo 1 and Demo 2, while the latter maps user/item ids to review texts. Note that the number of products does not correspond to the number of user-item interactions as we only consider the set of unique interacted items. While Ducho extracts, by default, description/interaction texts from the last column of the tsv file, here we provide explicit column names to tell Ducho where to retrieve product descriptions and user reviews from the respective tsv files.</p><p>\\\n While for the items’ descriptions we use again the same sentences encoder as in Demo 1 and 2, we decide to extract textual features from users’ reviews through a multilingual BERTbased model pre-trained on customers’ reviews and specify the task of sentiment analysis for this model.</p><p>\\\n Textual item features are saved to numpy arrays whose filenames are the item ids. Conversely, the textual interaction features are saved under the filename obtained from user and item ids to provide a unique pointer to each review.</p>","contentLength":2782,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Making AI Recommendations Smarter with Visual, Text, and Audio Data","url":"https://hackernoon.com/making-ai-recommendations-smarter-with-visual-text-and-audio-data?source=rss","date":1739736622,"author":"YAML","guid":815,"unread":true,"content":"<p>(1) Daniele Malitesta, Politecnico di Bari, Italy and daniele.malitesta@poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(2) Giuseppe Gassi, Politecnico di Bari, Italy and g.gassi@studenti.poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(3) Claudio Pomo, Politecnico di Bari, Italy and claudio.pomo@poliba.it;</p><p>(4) Tommaso Di Noia, Politecnico di Bari, Italy and tommaso.dinoia@poliba.it.</p><p>his section proposes three use cases (i.e., demos) which show some of the main functionalities in Ducho and how to exploit them within a complete multimodal extraction pipeline. The guidelines and codes are accessible at this link[4] to run the demos (i) on your local machine, (ii) in a Docker container, and (iii) on Google Colab. Note that we specifically selected these demos as to replicate some real recommendation tasks involving multimodal features.</p><h3>5.1 Demo 1: visual + textual items features</h3><p>Fashion recommendation is probably one of the most popular task involving multimodal features to describe items. Generally, fashion products come with images (i.e., visual) and descriptions (i.e., textual) which may captivate the attention of the customer.</p><p>\\\n We use a small fashion dataset where each item has its own image and other metadata such as gender, category, colour, season, and product title. As for the visual modality, we save a subsample of 100 random images from the dataset in jpeg format; as for the textual modality, we produce for each of these items a description obtained as the combination of all the metadata fields from above, and store it into a tsv file where the first and second columns map item ids and descriptions, respectively. Note that, if no item column name is provided, Ducho selects, by default, the last column as the one holding the items’ descriptions.</p><p>\\\n In terms of extraction models, we adopt VGG19 and Xception for the product images, and Sentence-BERT pre-trained for semantic textual similarity for the descriptions. For each extraction model, we select the extraction layer, the pre-processing procedures, and the library where the deep network should be retrieved from.</p><p>\\\n Through the configuration file, we set Ducho to save the visual and textual embeddings to custom folders, where each embedding is a numpy array whose filename corresponds to the item name from the original input data. Additionally, Ducho keeps track of the log file in a dedicated folder within the project.</p><h3>5.2 Demo 2: audio + textual items features</h3><p>When it comes to recommending songs to users, audio and textual features may enhance the representation of each song, where the former are structured as a waveform, the latter as sentences referring, for instance, to the music genre of the song.</p><p>\\\n We use a small music genres dataset where each item comes with the binary representation of its waveform (we save it as wav audio track) and its music genre (we interpret it as textual song description and save it into a tsv file similarly to the previous demo). Given the heavy computational costs deep learning-based audio extractors require, we decide to select a small subset of the input songs (i.e., 10) just for the purpose of this demo.</p><p>\\\n For the extraction of audio features we exploit Hybrid Demucs pre-trained for the task of music source separation. As for the textual extraction, we re-use the same deep neural model from the previous demo, since we are not interested in extracting other specific high-level features from music genres.</p><p>\\\n Once again, we use the configuration file to specify the output folders for both the audio and textual embeddings. Please note that the extraction of audio features might take some time depending on the machine you are running Ducho on, as the deep audio extractor might require high computational resources to run.</p><p>[4] https://github.com/sisinflab/Ducho/tree/main/demos.</p>","contentLength":3998,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ducho’s Big Bet: A Unified Future for Multimodal AI","url":"https://hackernoon.com/duchos-big-bet-a-unified-future-for-multimodal-ai?source=rss","date":1739736614,"author":"YAML","guid":814,"unread":true,"content":"<p>(1) Daniele Malitesta, Politecnico di Bari, Italy and daniele.malitesta@poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(2) Giuseppe Gassi, Politecnico di Bari, Italy and g.gassi@studenti.poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(3) Claudio Pomo, Politecnico di Bari, Italy and claudio.pomo@poliba.it;</p><p>(4) Tommaso Di Noia, Politecnico di Bari, Italy and tommaso.dinoia@poliba.it.</p><p>The overall multimodal extraction pipeline is represented in Figure 1. Through the Dataset module, the load and  steps take place, assuming that the user is providing the input data and the YAML configuration file (overridable from command line) to customize the extraction. Then, the Extractor module is in charge of  the extraction model(s) by setting the backends and output layer(s). Finally, after the multimodal feature , features are saved to the  path in numpy format (the Dataset module again controls this latter phase). As previously described, the whole process is orchestrated by the Runner module.</p><h2>4 DUCHO AS DOCKER APPLICATION</h2><p>To fully exploit the GPU-speedup implemented in all backends we use for the multimodal feature extraction, one of the basic requirements is to setup a suitable development environment where the backends’ versions are compatible with CUDA and, optionally, cuDNN. Generally, setting a workstation where all such libraries/tools are correctly aligned is challenging. To this end, we decide to dockerize Ducho by making it into a Docker image (available on Docker Hub[3] ) with all packages already installed in a tested and safe virtualization environment on your physical machine</p><p>\\\nand safe virtualization environment on your physical machine. Our Docker image is built from an NVIDIA-based image which comes with CUDA 11.8 and cuDNN 8 on Ubuntu 22.04, Python 3.8 and Pip, and our cloned repository having all Python packages already installed and ready to be used. A possible container instantiated from the image should specify the gpus to use from the host machine (this feature is currently available on Docker but it depends on the version of CUDA to be installed), and the volume you may want to use to save the framework’s outputs permanently</p><p>\\\nNote that a generic container instantiated from our image would prompt the user to a shell environment where one could run custom multimodal feature extractions via the command line, and also create custom configuration files for the same purpose.</p>","contentLength":2596,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A New Way to Extract Features for Smarter AI Recommendations","url":"https://hackernoon.com/a-new-way-to-extract-features-for-smarter-ai-recommendations?source=rss","date":1739736607,"author":"YAML","guid":813,"unread":true,"content":"<p>(1) Daniele Malitesta, Politecnico di Bari, Italy and daniele.malitesta@poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(2) Giuseppe Gassi, Politecnico di Bari, Italy and g.gassi@studenti.poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(3) Claudio Pomo, Politecnico di Bari, Italy and claudio.pomo@poliba.it;</p><p>(4) Tommaso Di Noia, Politecnico di Bari, Italy and tommaso.dinoia@poliba.it.</p><p>Ducho’s architecture is built upon three main modules, namely, Dataset, Extractor, and Runner, where the first two modules provide different implementations depending on the specific modality (i.e., audio, visual, textual) taken into account. We also remind the Configuration one among the other auxiliary components. The architecture is designed to be highly modular, possibly integrating new modules or customizing the existing ones. In the following, we dive deep into each outlined module/component.</p><p>The  module manages the loading and processing of the input data provided by the user. Starting from a general shared schema for all available modalities, this module provides three separate implementations:  and  Datasets. As a common approach in the literature, the Audio and Visual Datasets require the path to the folder from which image/audio files are loaded, while the Textual Dataset works through a tsv file mapping all the textual characteristics to the inputs.</p><p>\\\nNoteworthy, and differently from other existing solutions, Ducho may handle each modality in two fashions, depending on whether the specific modality is describing either the  (e.g., product descriptions) or the  among users and items (e.g., reviews [1]). Concretely, while items are mapped to their unique ids (extracted from the filename or the tsv file), interactions are mapped to the user-item pair (extracted from the tsv file) they refer to. Although the pre-processing and extraction phases do not change at items- and interactions-level (see later), we believe this schema may perfectly suit novel multimodal-aware recommender systems with modalities describing every type of input source (even ).</p><p>\\\nAnother important task for the Dataset module is to handle the pre-processing stage of data input. Depending on the specific modality involved, Ducho offers the possibility to:</p><p>\\\n load the input audio by extracting the waveform and sample rate, and re-sample it according to the sample rate the pre-trained model was trained on;</p><p>\\\n convert input images into RGB and resize/normalize them to align with the pre-trained extraction model;</p><p>\\\n (optionally) clean the input texts to remove or modify noisy textual patterns such as punctuation and digits</p><p>\\\nAfter the extraction phase (see later), the Dataset module is finally in charge of saving the generated multimodal features into  array format following the file naming scheme from the previous mapping.</p><p>The  module builds an extraction model from a pretrained network and works on each loaded/pre-processed input sample to extract its multimodal features. In a similar manner to the Dataset module, the Extractor provides three different implementations for each modality, namely, the Audio, Visual, and Textual Extractors. Ducho exposes a wide range of pre-trained models from three main backends: TensorFlow, PyTorch, and Transformers. The following modality/backend combinations are currently available:</p><p>\\\n•  PyTorch (Torchaudio) and Transformers;</p><p>\\\n•  Tensorflow and PyTorch (Torchvision);</p><p>\\\n Transformers (and SentenceTransformers).</p><p>\\\nTo perform the feature extraction, Ducho takes as input the (list of) extraction layers for any pre-trained model. Since each backend handles the extraction of hidden layers within a network differently, we follow the guidelines provided in the official documentations, assuming that the user will follow the same naming/indexing scheme of the layers and know the structure of the selected pre-trained model in advance. The interested reader may refer to the README[2] under the config/ folder on GitHub for an exhaustive explanation on how to set the extraction layer in each modality/backend setting.</p><p>\\\nFinally, for the textual case, the user can also specify the specific task the pre-trained model should be trained on (e.g., sentiment analysis), as each pre-trained network may come with different versions depending on the training strategy.</p><p>The  module is the orchestrator of Ducho, whose purpose is to instantiate, call, and manage all the described modules. With its API methods, this module can trigger the complete extraction pipeline (see later) of one single modality or all the modalities involved simultaneously</p><p>\\\nThe Runner module is conveniently customized through an auxiliary  component which stores and exposes all parameters to configure the extraction pipeline. Even if a default configuration is already made available for the user’s sake, Ducho allows to override some (or all) its parameters through an external configuration file (in YAML format) and/or key-value pairs as input arguments if running the scripts from the command line. Once again, we suggest the readers refer to the README under the config/ folder on GitHub to understand the general schema of the YAML configuration file.</p>","contentLength":5342,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Unified Framework for Multimodal Feature Extraction in Recommendation Systems","url":"https://hackernoon.com/a-unified-framework-for-multimodal-feature-extraction-in-recommendation-systems?source=rss","date":1739736605,"author":"YAML","guid":812,"unread":true,"content":"<p>(1) Daniele Malitesta, Politecnico di Bari, Italy and daniele.malitesta@poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(2) Giuseppe Gassi, Politecnico di Bari, Italy and g.gassi@studenti.poliba.it with Corresponding authors: Daniele Malitesta (daniele.malitesta@poliba.it) and Giuseppe Gassi (g.gassi@studenti.poliba.it);</p><p>(3) Claudio Pomo, Politecnico di Bari, Italy and claudio.pomo@poliba.it;</p><p>(4) Tommaso Di Noia, Politecnico di Bari, Italy and tommaso.dinoia@poliba.it.</p><p>In multimodal-aware recommendation, the extraction of meaningful multimodal features is at the basis of high-quality recommendations. Generally, each recommendation framework implements its multimodal extraction procedures with specific strategies and tools. This is limiting for two reasons: (i) different extraction strategies do not ease the interdependence among multimodal recommendation frameworks; thus, they cannot be efficiently and fairly compared; (ii) given the large plethora of pre-trained deep learning models made available by different open source tools, model designers do not have access to shared interfaces to extract features. Motivated by the outlined aspects, we propose Ducho, a unified framework for the extraction of multimodal features in recommendation. By integrating three widely-adopted deep learning libraries as backends, namely, TensorFlow, PyTorch, and Transformers, we provide a shared interface to extract and process features where each backend’s specific methods are abstracted to the end user. Noteworthy, the extraction pipeline is easily configurable with a YAML-based file where the user can specify, for each modality, the list of models (and their specific backends/parameters) to perform the extraction. Finally, to make Ducho accessible to the community, we build a public Docker image equipped with a ready-to-use CUDA environment and propose three demos to test its functionalities for different scenarios and tasks. The GitHub repository and the documentation are accessible at this link: https://github.com/sisinflab/Ducho.</p><h2>1 INTRODUCTION AND MOTIVATION</h2><p>With the advent of the digital era and the Internet, numerous online services have emerged, including platforms for e-commerce, media streaming, and social networks. The vast majority of such websites rely on recommendation algorithms to provide users with a personalized surfing experience. In specific domains such as fashion [3], music [6], food [5], and micro-video [8] recommendation, recommender systems have demonstrated to be effectively supported in their decision-making process by all types of multimodal data sources the users usually interact with (e.g., product images and descriptions, users’ reviews, audio tracks).</p><p>\\\nThe literature refers to multimodal-aware recommender systems (MRSs) as the family of recommendation algorithms leveraging multimodal (i.e., audio, visual, textual) content data to augment the representation of items, thus tackling issues in the field such as the sparsity of the user-item matrix and the inexplicable nature of users’ actions (e.g., clicks, views) on online platforms which may not always be easy to profile for the recommendation algorithms.</p><p>\\\nDespite being the initial stage of any multimodal recommendation pipeline, the extraction of meaningful multimodal features is paramount in delivering high-quality recommendations [2]. However, the current practice of employing diverse multimodal extraction procedures in each recommendation framework poses limitations. Firstly, these diverse implementations hinder the interdependence across various multimodal recommendation frameworks, making their fair comparison difficult [4]. Secondly, despite the availability of numerous pre-trained deep learning models in popular open source libraries, the lack of shared interfaces for feature extraction across them represents a challenge for model designers.</p><p>\\\nTo address these shortcomings, we propose Ducho, a unified framework designed to streamline the extraction of multimodal features for recommendation systems. By integrating widely-adopted deep learning libraries as backends such as TensorFlow, PyTorch, and Transformers, we establish a shared interface that empowers users to extract and process audio, visual, and textual features from both items and user-item interactions (see Table 1). This abstraction allows to leverage methods from each backend without being encumbered by the specific implementation that backend poses. A notable feature of our framework lays in its easily configurable extraction pipeline, which can be personalized using a YAML-based file. Users can specify the desired models, their respective backends, and models’ parameters (such as the extraction layer).</p><p>\\\nBy looking at the related literature, the most similar application to Ducho is Cornac [7], a framework for multimodal-aware recommendation. For the sake of completeness, we report their main differences. Differently from Cornac, Ducho: (i) is specifically aimed to provide customizable multimodal feature extractions, being completely agnostic to the downstream recommender system that might exploit the extracted features, thus being easily applicable to any model; (ii) provides the user with the possibility to select the deep learning extraction model, its backend, and its output layer; (iii) introduces the audio modality to the modalities set.</p><p>\\\nTo foster the adoption of Ducho, we also develop a public Docker image pre-equipped with a ready-to-use CUDA environment[1], and propose three demos to show Ducho’s functionalities. The GitHub repository, which comes with all needed resources is available at: https://github.com/sisinflab/Ducho.</p><p>[1] https://hub.docker.com/r/sisinflabpoliba/ducho.</p>","contentLength":5809,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Researchers are training AI to interpret animal emotions","url":"https://techcrunch.com/2025/02/16/researchers-are-training-ai-to-interpret-animal-emotions/","date":1739736115,"author":"Anthony Ha","guid":741,"unread":true,"content":"<p>Artificial intelligence could eventually help us understand when animals are in pain or showing other emotions — at least according to researchers recently profiled in Science. For example, there’s the Intellipig system being developed by scientists at the University of the West of England Bristol and Scotland’s Rural College, which examines photos of pigs’ faces […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":442,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Funniest/Most Insightful Comments Of The Week At Techdirt","url":"https://www.techdirt.com/2025/02/16/funniest-most-insightful-comments-of-the-week-at-techdirt-148/","date":1739736000,"author":"Leigh Beadon","guid":747,"unread":true,"content":"<blockquote><p><em>Republicans believe in states rights up until states start doing things Republicans don’t like.</em></p></blockquote><blockquote><p><em>I don’t think that’s correct. Sure there were weekly scandals, but those were caused by “the deep state.” Sure Trump was impeached twice, but that wasn’t his fault, was it? It was those libs and classic conservatives in Congress conspiring against him. As for January 6th, how was that any different, in the opinion of the MAGA faithful, than the rioting after George Floyd? All those criminal trials? DOJ weaponized against him by a vindictive Biden Administration. That’s the kind of stuff people are inundated with. It’s the same kind of stuff that got an otherwise normal dude to drive to a pizza parlor with a gun to “save the children;” it’s the same BS that got poor people to vote republican (when all they wanna do is cut Medicaid funding); and it’s the same BS that motivated many of his supporters to invade the capital in the first place. Valid Information (or lack there of) is a very powerful. That’s why every dictator ever has tried to control it, and Trump and Musk have succeeded.</em></p></blockquote><blockquote><p><em>Do firefighters and their unions regularly protest against any attempt to hold their members accountable, and/or defend members engaging in horrific if not lethal actions?</em></p></blockquote><blockquote><p><em>I have very low expectations of the GOP, so my criticism is aimed at the Dems.</em></p><p><em>Why aren’t they flooding every possible media with the practical realities of Trump2.0? No more limp language. Fed. govt. is one of the largest employers in many red districts. Tell the constituents, “When Elmo is done, your district will be looking at 7% UE.” “Shutting USAID will force US farmers into bankruptcy.” “Get ready for grandma to move in when Medicaid cuts close her assisted living facility.”</em></p><p><em>And last: “Where are the f**kin’ eggs?”</em></p></blockquote><blockquote><p><em>Curious how only in this one instance the Trump Administration is upset about deadnaming.</em></p></blockquote><blockquote><p><em>So many Magaheads who are complaining about Latin Americans with an 8th grade education taking their jobs are saying this is what will really solve the immigration issue, grocery costs, inflation, the price of gas, stimulate oil drilling, end the war in Ukraine, get all the hostages freed, and send a clear message to our foes and allies alike that we’re a serious country. (Not to mention grow the GDP by 2% every 5 minutes, cut the deficit by $30 trillion, turn North Korea and Gaza into popular tourist destinations, and eliminate all those damn electric cars.)</em></p><p><em>Who knew it was so simple?</em></p><p><em>America, that’s who! An example for the world on how being simple can demand such respect!</em></p></blockquote><p>For editor’s choice on the funny side, we’ll stay on that post  stick with the anonymous comments for a one-two punch starting with <a href=\"https://www.techdirt.com/2025/02/13/the-real-gulf-of-america-is-between-the-news-outlets-that-cover-this-administration/#comment-4283449\">the first comment on the post</a>:</p><blockquote><p><em>Next up: Trump decrees that the State of New Mexico shall hereby be referred to as “The State of New America”.</em></p></blockquote><blockquote><p><em>Or maybe “United States of America” to “United States of United States” to prevent people confusing with the American continent.</em></p></blockquote><p>That’s all for this week, folks!</p>","contentLength":3057,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Argentinian President Promotes Memecoin. It Then Crashed 95% as Insiders Cashed Out","url":"https://news.slashdot.org/story/25/02/16/1921209/argentinian-president-promotes-memecoin-it-then-crashed-95-as-insiders-cashed-out?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739735580,"author":"EditorDavid","guid":752,"unread":true,"content":"gwolf (Slashdot reader #26,339) writes: On Friday, February 14, Libertarian Argentinian president, Javier Milei, promoted the just-created $LIBRA cryptocoin, created by the Viva la libertad project, strongly aligned with his political party, La Libertad Avanza. Milei tweeted, \"This private project will be devoted to promote growth of the Argentinian economy, funding small startups and enterprises. The world wants to invest in Argentina!\" \n\nIt is worth noting that the project's website was registered a mere three minutes before Milei tweeted his endorsement. The cryptocoin quickly reached a $4.6 billion market cap... Only to instantaneously lose 89% of its value, with nine core investers pulling the rug from under the enthusiast investors.\n\nMore details from the blog Web3 Is Going Just Great:\n\n\n[W]ithin hours of the launch, insiders began selling off their holdings of the token. The token had been highly concentrated among insiders, with around 82% of the token held in a small cluster of apparently insider addresses. Those insiders cashed out around $107 million, crashing the token price by around 95%. After the crash, Milei deleted his tweet promoting the project. He later claimed he was \"not aware of the details of the project.\"\n \n\nUPDATE: CNN reports that Argentine President Milei is now facing calls for impeachment.\n\n\nThe presidency on Saturday announced an investigation into the matter, saying: \"President Javier Milei has decided to immediately involve the Anti-Corruption Office to determine whether there was improper conduct on the part of any member of the national government, including the president himself.\"\n","contentLength":1644,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"It is Cheaper to Grow than to Die","url":"https://hackernoon.com/it-is-cheaper-to-grow-than-to-die?source=rss","date":1739734310,"author":"Praise J.J.","guid":811,"unread":true,"content":"<h3>You Think Growth is Expensive? Try Staying the&nbsp;Same</h3><p>People avoid investing in growth because they think it costs too much. A gym membership, a course, starting a business—it all feels like a financial drain.</p><p>\\\nBut do you know what costs way more? </p><ul><li><p>If you don’t invest in your skills, you don’t stay the same — you shrink.</p></li><li><p>If you don’t improve your health, you pay for it later in medical bills and lost energy.</p></li><li><p>If you don’t grow your income, inflation erodes your lifestyle.</p></li></ul><p>There is no neutral in life — everything is either growing or decaying.</p><p>So being stagnant (in the most generic sense) means you’re growing at the same rate the world moves. Anything less is dying.</p><p>\\\nLook at businesses: the ones that stop innovating? They die. Blockbuster, Kodak, MySpace—they all refused to grow. They paid the price. Look at people: The ones who settle for comfort? They get weaker, slower, and less relevant.</p><p>\\\nGrowth isn’t an expense.  The only way to guarantee your survival—financially, mentally, and physically—is to keep expanding.</p><p>\\\n<strong>Growth is always cheaper than dying.</strong></p><h3>The Cost of Short-Term Thinking</h3><p>Most people underestimate how much they trade long-term growth for short-term comfort. The small, daily decisions that seem harmless—grabbing a quick dopamine hit, skipping a workout, avoiding a difficult task—compound over time into stagnation.</p><p>\\\nIf you’re in Nigeria, a bottle of soft drink is more or less the price of a bag of sachet water. Properly hydrating yourself for sustained energy for at least 3 days is the same price as flooding your system with dopamine and energy that lasts for about an hour and leaves you more drained. This cuts across other areas of your life. Growth is cheaper than dying.</p><p>\\\nThe problem isn’t the cost—it's the mindset. We get used to prioritizing what feels good now over what keeps us strong later. And before we realize it, our daily indulgences become our greatest limitations.</p><p>There are two types of growth:</p><ol><li> Climbing the Ladder</li><li> Leveraging Multipliers</li></ol><h4><strong>Linear Growth: Climbing the Ladder</strong></h4><p>Linear growth is when the value of leverage is 1. Most people grow linearly.</p><ul><li>Climb the corporate ladder.</li></ul><p>\\\nLinear growth is predictable.</p><ul></ul><p>The problem?  If you stop, you die.</p><p>Linear growth works for specialists—surgeons, lawyers, and pilots. They’re expensive because they provide immense value. But their value depends on them showing up. No surgeon, no surgery.</p><p>\\\nIf your goal is to build something bigger than yourself, <strong>linear growth won’t cut it.</strong></p><h4><strong>Exponential Growth: Leveraging Multipliers</strong></h4><p>Exponential growth is where the magic happens.</p><p>\\\nHere, leverage skyrockets. You can work for five years and see nothing, then <strong>one weekend in a garage changes everything.</strong></p><p>Exponential growth is uncomfortable because it’s not easy to predict.</p><ul><li><p>In , you can predict success because you’re following a known path. 1+1 will always equal 2.</p></li><li><p>In , you will fail  the 1% that works overshadows all failures.</p></li></ul><p>Thomas Edison, the Wright brothers, Elon Musk, Mr. Beast—they all looked like failures </p><p>The only thing that matters is </p><p>\\\nLinear thinkers are <strong>99% right but 100% wrong—because</strong> they never reach the game-changing breakthrough.</p><p><strong>Exponential growth rewards patience, persistence, and adaptability.</strong> Every failed iteration builds the foundation for eventual success.</p><h3>Start Young, Start Small, Start&nbsp;Now</h3><p>The earlier you start chasing exponential growth, the easier it is.</p><ul><li>If you earn $500/hour, risking 100 hours feels like losing $50,000.</li><li>If you earn $50/hour, those same 100 hours only risk $5,000.</li><li>If you earn $0/hour, you have nothing to lose.</li></ul><h3>The Best Investment? Yourself.</h3><p>People love to talk about <strong>investing in crypto, stocks, startups.</strong> But the best investment?</p><ul><li><p>Other people’s mistakes can tank your investments.</p></li><li><p>Their limitations become your limitations.</p></li><li><p>Their failures become your failures.</p></li></ul><p>When you invest in yourself, you own the wins and the losses.</p><p>Would you rather trust a stranger’s competence—or build your own?</p><ul><li><strong>Milk that rots in a controlled way becomes yogurt.</strong></li><li><strong>A grape that rots in a controlled way becomes wine.</strong></li></ul><p>\\\nControlled mistakes bring growth. </p><h3>MAKING NO MISTAKES IS THE WORST MISTAKE</h3><p>Some people fear doing the wrong thing, so they do nothing.</p><p>This is a reminder: </p><p>\\\n</p><ol><li><p><strong>Make the most of your mistakes.</strong> If you try once, mess up, and quit—you're the guy who failed. If you keep iterating, people will eventually recognize you as the O.G. who gets things done.</p></li><li><p> Don’t let mistakes ruin you—channel them into growth.</p></li></ol><p>The world doesn’t wait for you to catch up. Every moment spent hesitating is a moment lost to those who take action</p><h3>Final Thought: Grow or&nbsp;Die</h3><p>The stock market grows by 7–10% every year. Inflation is rising. The world moves forward no matter what. <strong>If you’re stagnant, you’re already falling behind.</strong></p><p>\\\nYou either grow—or you die. And the price of dying is much higher.</p><p>\\\nEnjoy the rest of your day.</p><p><em>Join  where I break down high-performance strategies for creators, indie hackers, and anyone tired of being stuck. No fluff. No recycled self-help nonsense. Real insights to help you <strong>outperform, outlast, and outgrow the competition.</strong></em></p><p><em>📩  (or click the subscribe button on Hackernoon and I’ll add you).</em></p>","contentLength":5170,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Broadcom, TSMC reportedly exploring deals that would split up Intel","url":"https://techcrunch.com/2025/02/16/broadcom-tsmc-reportedly-exploring-deals-that-would-split-up-intel/","date":1739732563,"author":"Anthony Ha","guid":713,"unread":true,"content":"<p>Broadcom and Taiwan Semiconductor Manufacturing Company (TSMC) are separately exploring deals to take over parts of Intel, according to a report in The Wall Street Journal. Broadcom is reportedly considering an acquisition of Intel’s chip-design and marketing business, and would want a partner for the company’s manufacturing business, while TSMC is reportedly looking at controlling […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":457,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lead Scoring 2.0: From Static Models to Dynamic Buyer Intent","url":"https://hackernoon.com/lead-scoring-20-from-static-models-to-dynamic-buyer-intent?source=rss","date":1739732409,"author":"Olga Ukrainskaya","guid":810,"unread":true,"content":"<p>You have a lead scoring model in your CRM that just simply is not working?</p><p>\\\nThe harsh truth is that your lead scoring system as it stands, is probably broken. You are assigning points for job titles, for the number of times people visit your website, or open your emails, but when your sales team goes to these so-called “hot leads,” a lot of these people are not even interested. Sound familiar?</p><p>\\\nThe problem is that traditional lead scoring systems are based on the assumption that buyers go on a simple, linear journey. The reality is that today’s buyers are much more complex.</p><p>\\\nBy the time a buyer needs a solution, <strong>the decision is often already made.</strong></p><blockquote><ul><li><p>They do their homework long before you can even pronounce their name—glossing over reviews, measuring competitors, exploring industry blogs.</p></li><li><p>Their engagement is inconsistent — they may view a lot of content one week and none the next.</p></li><li><p>They may not respond to your emails, but engage with your product often — a clear sign of intent missed by static scoring models.</p></li></ul></blockquote><p>\\\nIf you're still relying on static lead scoring, you might be missing out on valuable opportunities.</p><p>\\\nThis is where  comes in - a more innovative, real-time approach that prioritizes leads based on what buyers do and intent signals.</p><p>\\\nThis guide will give you some ideas for how to create a dynamic lead-scoring model in your CRM. Then, by using AI, behavioral data, and automation, you can make sure your sales team is spending its time on the leads that are most likely to convert.</p><p>\\\nReady to get started? Let’s dive in. 🚀</p><h2>Static and Dynamic Lead Scoring: What’s the Difference?</h2><p>| Feature | ==Static Lead Scoring== | ==Dynamic Lead Scoring== |\n|----|----|----|\n|  | Demographics, firmographics, past actions | Real-time engagement, behavioral patterns, AI insights |\n|  | Manual, periodic | Continuous, automated |\n|  | Clicks, form fills | Product usage, time-sensitive actions, in-market signals |\n|  | Often misaligned | Predictive and relevant |</p><p>\\\nStatic models make fixed point assignments (i.e., “10 points for an email open”), whereas dynamic scoring updates in real-time based on actual buyer behavior, providing more relevant and actionable insights.</p><h2>Step 1: Identify Your Dynamic Lead Scoring Model</h2><p>When creating a dynamic scoring model, there are three main types of data that you need to focus on:</p><ol></ol><p>👉 CRM Setup Tip: If your CRM is missing company data, identify gaps and use enrichment tools to fill them. Next, build workflows to move this data into contacts and create baseline scores and segments against your ICP (Ideal Customer Profile).</p><ol start=\"2\"><li><p><strong>Engagement Score (How They Interact With You)</strong></p><p>\\\nVisits to your website (e.g. product or pricing pages = high intent)</p></li></ol><p>👉 CRM Setup Strategy: Use a marketing automation tool like HubSpot, Marketo, Pardot, etc., to track engagement, and automatically update scores dynamically.</p><ol start=\"3\"><li><p><strong>Intent Score (How Ready they are to Buy)</strong></p><p>\\\nEngagement on the product (especially for SaaS companies)</p><p>Competitor comparisons (activity on G2 or Capterra, etc.)</p><p>High engagement with sales materials (case studies, ROI calculators, etc.)</p><p>More web searches aligning with your product</p></li></ol><p>👉 CRM Setup Hack: Link intent data solutions, such as HubSpot Breeze, 6sense, Bombora, or others to your CRM.</p><h2>Step 2: Add Scoring Automation in Your CRM</h2><ul><li><p>3rd Party Data Enrichment: Use ZoomInfo, HubSpot Breeze, Bombora, etc. to track buyer intent outside of your own channels.</p></li><li><p>Establish Scoring Models – Fit, Engagement, and Intent scores should each have their own models.</p></li><li><p>Sales Alerts: Automatically alert SDRs when a lead’s score crosses a threshold.</p></li></ul><ul><li>Step 1: Turn on Einstein Lead Scoring – Use AI score to score leads.</li><li>Use Flow Automation: Set up rules to assess leads according to their behaviors.</li><li>Add Product Analytics: If relevant for SaaS companies, integrate Amplitude or Mixpanel, so product usage can be tracked, thus updating the scores.</li><li>Set Dynamic Segments: Organize your leads based on their behavior and auto-enter them into nurturing tracks.</li></ul><h2>Step 3: Move to Adaptive Lead Scoring</h2><p>Lead scores almost never stay static and decay over time. To keep your model effective:</p><ul><li>Decay Stale Leads: Subtract points from leads that haven’t acted in over 30 days (change based on longer sales processes).</li><li>Use Action-Weighted Points: High-intent actions (like demo requests or product searches) are worth much more than email opens.</li><li>Monitor and Optimize Monthly: Run CRM reports to ensure high-scoring leads are converting.</li></ul><h2>Step 4: Align Sales &amp; Marketing With Dynamic Scoring</h2><p>Your lead scoring model must work seamlessly with your sales team’s workflow. Here’s how:</p><ul><li>Define a “Marketing Qualified” Score (i.e., leads above 80 points trigger a follow-up).</li><li>Personalized Outreach: Sales should include recent high-intent actions in e-mails (e.g., “I noticed you read our enterprise security case); Let's chat!\").</li><li>Feedback Loop: If sales report back that high-scoring leads are not converting, revise scoring weights accordingly.</li></ul><p>If your lead scoring model is failing to deliver the results your sales team needs, it’s probably too rigid for today’s buyers.</p><p>\\\nToday’s buyers don’t take a linear path — they research on their own, engage in bursts, and decide quickly. Traditional scoring models simply can’t keep pace with that kind of activity.</p><p>\\\nChoose dynamic, intent-based lead scoring so your sales team only focuses on those most likely to convert. It moves past clunky lead scoring and instead into the realm of real-time engagement and behavioral signals.</p><p>\\\nSo, where do you start?</p><p>\\\nAssess your existing model: What’s working, and what’s not?</p><p>\\\n🔝 Target intent signals: Look to buyers with clear readiness signals.</p><p>✅ Maintain updated scores: Keep your CRM up to mark with the latest information.</p><p>✅ Always iterate: Refine the model with feedback from your sales team.</p><p>\\\nThe shift will not, of course, happen overnight, but even small tweaks can dramatically impact both conversions and pipeline velocity. A well-implemented lead scoring model can thus work for you, not against you.</p><p>\\\nIt’s time to have a look at lead scoring and get it to work for your business in a smarter way.</p><p>:::info\nWould you like to take a stab at answering some of these questions? The link for the template is&nbsp;. Interested in reading the content from all of our writing prompts? Click&nbsp;.</p>","contentLength":6361,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Time Flows Forward or Backward At Quantum Levels, Researchers Suggest","url":"https://science.slashdot.org/story/25/02/16/1850213/time-flows-forward-or-backward-at-quantum-levels-researchers-suggest?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739731980,"author":"EditorDavid","guid":716,"unread":true,"content":"\"What if time is not as fixed as we thought?\" That's the question raised in an announcement from the University of Surrey. \n\n\"Imagine that instead of flowing in one direction — from past to future — time could flow forward or backward due to processes taking place at the quantum level.\"\n\nThis is the thought-provoking discovery made by researchers at the University of Surrey, as a new study reveals that opposing arrows of time can theoretically emerge from certain quantum systems. For centuries, scientists have puzzled over the arrow of time — the idea that time flows irreversibly from past to future. While this seems obvious in our experienced reality, the underlying laws of physics do not inherently favour a single direction. Whether time moves forward or backwards, the equations remain the same.... \n\nThis discovery provided a mathematical foundation for the idea that time-reversal symmetry still holds in open quantum systems — suggesting that time's arrow may not be as fixed as we experience it... The research offers a fresh perspective on one of the biggest mysteries in physics. Understanding the true nature of time could have profound implications for quantum mechanics, cosmology and beyond. \nThe university's announcement includes this quote from co-author Thomas Guff, a research fellow in quantum thermodynamics. \n\n\"The surprising part of this project was that even after making the standard simplifying assumption to our equations describing open quantum systems, the equations still behaved the same way whether the system was moving forwards or backwards in time. When we carefully worked through the maths, we found this behaviour had to be the case because a key part of the equation, the 'memory kernel,' is symmetrical in time.\" \n\n\nAnd their research reminds readers that \"the fundamental laws of physics in both the classical and the quantum realms do not manifest any intrinsic arrow of time. Newton's equations are time-reversal symmetric, as well as Schrödinger's equation. As a consequence, backward-in-time motion is equally possible as forward-in-time motion... Our findings are consistent with the second law of thermodynamics and emphasise the distinction between the concepts of irreversibility and time-reversal symmetry.\"","contentLength":2275,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A DevOps Approach to AEM Packages: Automating Creation, Configuration, and More","url":"https://hackernoon.com/a-devops-approach-to-aem-packages-automating-creation-configuration-and-more?source=rss","date":1739728803,"author":"Giuseppe Baglio","guid":809,"unread":true,"content":"<p>Adobe Experience Manager (AEM) packages are the unsung heroes of content management — powerful containers that bundle everything from code and configurations to critical content. But let’s face it: manually creating, configuring, and downloading these packages can feel like a tedious dance of clicks.</p><p>\\\nWhat if you could automate this process with a few keystrokes, ensuring consistency, speed, reliability, and less heavy lifting?</p><p>\\\nI will show you a Bash script that flips the script (pun intended!) on how AEM developers and admins work with the Package Manager API. Think about crafting packages in seconds, tailoring filters on the fly, and snagging backups with surgical precision — all before your coffee cools to that  sipping temperature. ☕</p><blockquote><p><strong><em>Before we dive in, a quick note</em></strong>: <em>meticulously detailed and unapologetically technical. We’ll dissect the script’s logic, explore AEM API intricacies, and troubleshoot edge cases. For developers eager to jump straight into the code, you can jump to the bottom of the article. But if you’re here to understand the how and why behind the automation, strap in — we’re going all the way down the rabbit hole.</em> 🕳️</p></blockquote><p>The  script automates interactions with AEM’s Package Manager API, offering a structured approach to package creation, configuration, and distribution. Designed for developers and administrators, it replaces manual workflows with a command-line-driven process that emphasizes consistency and reliability.</p><ul><li>: Checks for existing packages to avoid redundancy before initiating creation.</li><li>: Programmatically defines content paths (e.g., , ) to include in the package.</li><li>: Triggers package compilation and downloads the output to a specified directory, appending a timestamp to filenames for version control.</li><li>: Validates HTTP responses, folder paths, and authentication to provide actionable feedback during failures.</li><li>: Supports basic¹ credential-based authentication via .</li></ul><ul><li>: Reduces manual steps required for package creation, configuration, and download.</li><li>: Ensures uniform package structures and naming conventions across environments.</li><li>: Detailed logging at each stage (creation, filtering, building, downloading) aids in auditing and troubleshooting.</li></ul><h2>1.3 Practical Applications</h2><ul><li>: Integrate with cron jobs to regularly archive critical content paths.</li><li><strong>Environment Synchronization</strong>: Replicate configurations or content between AEM instances during deployments.</li><li>: Capture stable states of  or  before applying system updates.</li></ul><ul><li>Access to an AEM instance (credentials, server, port).</li><li>Basic familiarity with Bash scripting and AEM’s Package Manager.</li><li>Permission to create and download packages via the AEM API.</li></ul><pre><code>./create-remote-aem-pkg.sh admin securepass123 localhost 4502 backup-group \"Content Backup\" /backups /content/dam /etc/clientlibs\n</code></pre><p>\\\nThis command creates a package named “Content Backup” under the group , including  and , and saves the output to the  directory.</p><p>Let’s dissect the  script (you can find it at the bottom of the article) to understand how it orchestrates AEM package management. We’ll focus on its structure, key functions, and workflow logic—ideal for developers looking to customize or debug the tool.</p><ul><li>: A utility function that prefixes messages with timestamps for clear audit trails.</li></ul><pre><code>_log () {\n  echo \"[$(date +%Y.%m.%d-%H:%M:%S)] $1\"\n}\n</code></pre><p>\\\n: Ensures every action (e.g., “Package built”) is logged with context, simplifying troubleshooting.</p><ul><li>: Validates the success of prior commands by checking exit codes and API responses.</li></ul><pre><code>check_last_exec () {\n  # Checks $? (exit status) and $CURL_OUTPUT for errors\n  if [ \"$status\" -ne 0 ] || [[ $output =~ .*success\\\":false* ]]; then\n    _log \"Error detected!\";\n    exit 1;\n  fi\n}\n</code></pre><p>: Prevents silent failures by halting execution on critical errors like authentication issues or invalid paths.</p><p>The script accepts seven positional arguments followed by dynamic filters:</p><pre><code>USR=\"$1\" # AEM username\nPWD=\"$2\" # AEM password\nSVR=\"$3\" # Server host (e.g., localhost)\nPORT=\"$4\" # Port (e.g., 4502)\nPKG_GROUP=\"$5\" # Package group (e.g., \"backups\")\nPKG_NAME=\"$6\" # Package name (e.g., \"dam-backup\")\nBK_FOLDER=\"$7\" # Backup directory (e.g., \"/backups\")\nshift 7 # Remaining arguments become filters (e.g., \"/content/dam\")\n</code></pre><p>\\\nPositional arguments ensure simplicity, while  handles variable filter paths flexibly.</p><h2>2.3 Package Validation &amp; Creation</h2><ul><li>: Replaces spaces in  with underscores to avoid URL issues.</li></ul><pre><code>PKG_NAME=${PKG_NAME// /_}\n</code></pre><ul><li>: Uses  to list packages via AEM’s API, avoiding redundant creations.</li></ul><pre><code>if [ $(curl ... | grep \"$PKG_NAME.zip\" | wc -l) -eq 1 ]; then\n  _log \"Package exists—skipping creation.\"\nelse\n  curl -X POST ... # Creates the package\nfi\n</code></pre><h2>2.4 Dynamic Filter Configuration</h2><p>Constructs a JSON array of filters from input paths:</p><pre><code>FILTERS_PARAM=\"\"\nfor i in \"${!FILTERS[@]}\"; do\n  FILTERS_PARAM+=\"{\\\"root\\\": \\\"${FILTERS[$i]}\\\", \\\"rules\\\": []}\"\n  # Adds commas between entries, but not after the last\ndone\n</code></pre><p><code>[{\"root\": \"/content/dam\"}, {\"root\": \"/apps\"}]</code></p><p>This JSON is injected into the package definition via AEM’s  endpoint.</p><h2>2.5 Build &amp; Download Workflow</h2><ul><li>: Triggers compilation using AEM’s  command:</li></ul><p><code>curl -X POST … -F \"cmd=build\"</code></p><p>\\\n: The script waits for the build to complete before proceeding.</p><ul><li>: Uses  to fetch the  and save it with a timestamped filename:</li></ul><pre><code>BK_FILE=\"$PKG_NAME-$(date +%Y%m%d-%H%M%S).zip\"\ncurl -o \"$BK_FOLDER/$BK_FILE\" ...\n</code></pre><p>Robust error handling and logging are critical for unattended scripts like , ensuring failures are caught early and logged clearly. Here’s how the script safeguards against unexpected issues and provides actionable insights.</p><ul><li>: The  function prefixes every message with a  timestamp, creating an audit trail for debugging:</li></ul><p><code>_log \"Starting backup process...\" # Output: [2023.10.25-14:30:45] Starting backup process...</code></p><p>\\\n: Timestamps help correlate script activity with AEM server logs or external events (e.g., cron job schedules).</p><ul><li>: Critical steps, like package creation, filter updates, and downloads, are explicitly logged to track progress.</li></ul><h2>3.2 Error Validation Workflow</h2><ul><li>Validates the existence of the backup folder () before proceeding:</li></ul><pre><code>if [ ! -d \"$BK_FOLDER\" ]; then  \n  _log \"Backup folder '$BK_FOLDER' does not exist!\" &amp;&amp; exit 1  \nfi  \n</code></pre><ul><li>Sanitizes  to avoid URL issues (e.g., spaces replaced with underscores).</li></ul><p>\\\n:</p><p>The  function examines both shell exit codes () and AEM API responses:</p><p><code>check_last_exec \"Error message\" \"$CURL_OUTPUT\" $CURL_STATUS</code></p><ul><li>: Non-zero values (e.g.,  network failures) trigger immediate exits.</li></ul><ul><li>: Detects  JSON responses or \"HTTP ERROR\" strings in AEM output.</li></ul><p>\\\n<strong>3.3 HTTP Status Verification</strong>: When downloading the package, the script checks for a  status code:</p><pre><code>if [ \"$(curl -w \"%{http_code}\" ...)\" -eq \"200\" ]; then  \n  # Proceed if download succeeds  \nelse  \n  _log \"Error downloading the package!\" &amp;&amp; exit 1  \nfi  \n</code></pre><ul><li>Invalid credentials:  catches  responses and exits with a clear error message.</li><li>Invalid filter path: AEM API returns , the script logs \"Error adding filters\" and terminates.</li><li>Disk full: Fails to write , checks file size with  flag and alerts before exiting.</li><li>AEM instance unreachable: exits with a non-zero code, the script logs \"Error building the package\".</li></ul><h2>3.5 Security Considerations</h2><ul><li>: The script uses  for simplicity, which skips SSL verification. <em>Recommendation for Production</em>: Replace with  to specify a CA bundle.</li></ul><ul><li>: Credentials are passed as arguments, which may appear in process logs. : Use environment variables or a secrets vault (e.g., ).</li></ul><ul><li>: Temporarily add  at the script’s start to print executed commands.</li><li>: Isolate issues by running critical  commands outside the script</li><li>: Redirect script output to a file for later analysis:</li></ul><p><code>./create-remote-aem-pkg.sh ... &gt;&gt; /var/log/aem_backup.log 2&gt;&amp;1</code></p><p>The  script is designed to be a starting point—a foundation you can modify to align with your team’s needs. Below are common customizations, along with implementation guidance, to extend its functionality or adapt it to specific use cases.</p><p>The default filename uses a timestamp (<code>$PKG_NAME-$(date +%Y%m%d-%H%M%S).zip</code>). Modify this to include environment names, project IDs, or semantic versioning:</p><pre><code># Example: Include environment (e.g., \"dev\", \"prod\")  \nBK_FILE=\"${PKG_NAME}-${ENV}-$(date +%Y%m%d).zip\"  \n\n# Example: Add Git commit SHA for traceability  \nCOMMIT_SHA=$(git rev-parse --short HEAD)  \nBK_FILE=\"${PKG_NAME}-${COMMIT_SHA}.zip\"  \n</code></pre><p>: Ensure date/time formats avoid characters forbidden in filenames (e.g., colons  on Windows).</p><h2>4.2 Expanding or Modifying Filters</h2><p>The script accepts dynamic paths as filters but you can also hardcode frequently used paths or add exclusions:</p><pre><code># Hardcode essential paths (e.g., \"/var/audit\")  \nDEFAULT_FILTERS=(\"/content/dam\" \"/apps\" \"/var/audit\")  \nFILTERS=(\"${DEFAULT_FILTERS[@]}\" \"${@}\")  # Merge with command-line inputs  \n\n# Add exclusion rules (requires AEM API support)  \nFILTERS_PARAM+=\"{\\\"root\\\": \\\"${FILTERS[$i]}\\\", \\\"rules\\\": [{\\\"modifier\\\": \\\"exclude\\\", \\\"pattern\\\": \\\".*/test/*\\\"}]}\"  \n</code></pre><p>\\\n<strong>Avoid Plaintext Passwords</strong>:</p><p>Use environment variables or a secrets manager to inject credentials:</p><pre><code># Fetch password from environment variable  \nPWD=\"$AEM_PASSWORD\"  \n\n# Use AWS Secrets Manager (example)  \nPWD=$(aws secretsmanager get-secret-value --secret-id aem/prod/password --query SecretString --output text)  \n</code></pre><p>\\\n: \\n Replace&nbsp;(insecure) with a trusted CA certificate:</p><pre><code>curl --cacert /path/to/ca-bundle.crt -u \"$USR\":\"$PWD\" ...\n</code></pre><h2>4.4 Adding Post-Build Actions</h2><p>Extend the script to trigger downstream processes after a successful download:</p><pre><code># Example: Upload to cloud storage  \naws s3 cp \"$BK_FOLDER/$BK_FILE\" s3://my-backup-bucket/  \n\n# Example: Validate package integrity  \nCHECKSUM=$(sha256sum \"$BK_FOLDER/$BK_FILE\" | cut -d ' ' -f 1)  \n_log \"SHA-256 checksum: $CHECKSUM\"  \n\n# Example: Clean up old backups (retain last 7 days)  \nfind \"$BK_FOLDER\" -name \"*.zip\" -mtime +7 -exec rm {} \\;  \n</code></pre><h2>4.5 Adding Notification Alerts</h2><p>Notify teams of success/failure via Slack, email, or monitoring tools:</p><pre><code># Post to Slack on failure  \ncurl -X POST -H 'Content-type: application/json' \\  \n--data \"{\\\"text\\\":\\\"🚨 AEM backup failed: $(hostname)\\\"}\" \\  \nhttps://hooks.slack.com/services/YOUR/WEBHOOK/URL  \n\n# Send email via sendmail  \nif [ $? -ne 0 ]; then  \n  echo \"Subject: Backup Failed\" | sendmail admin@mycompany.com  \nfi  \n</code></pre><p>Managing AEM packages doesn’t have to be a manual, error-prone chore. With the  script, you can transform package creation, filtering, and distribution into a streamlined, repeatable process. This tool isn’t just about saving time, it’s about enabling consistency, reliability, and scalability in your AEM operations.</p><ol><li><p>: By eliminating repetitive GUI interactions, the script reduces human error and frees teams to focus on higher-value tasks.</p></li><li><p>: Whether backing up critical content, syncing environments, or preparing for updates, the script adapts to diverse use cases with minimal tweaking.</p></li><li><p>: Built-in logging, error checks, and security considerations ensure the script behaves predictably, even when things go sideways.</p></li></ol><p>\\\nGreat tools are born from real-world challenges. This script is a starting point; think of it as a foundation to build upon as your team’s needs grow. Whether you’re a solo developer or part of a large DevOps team, automation like this exemplifies how small investments in code can yield outsized returns in productivity and peace of mind.</p><p>\\\n<strong>Ready to take the next step?</strong></p><ul><li>🛠️ : Tailor the script using <a href=\"https://chat.deepseek.com/a/chat/s/4bad1785-c64b-479a-abb5-a39892036c6c#\">Section 6</a> as your guide.</li><li>🔍 : Review your existing AEM workflows for automation opportunities.</li><li>🤝 : Mentor your team or write a blog post about your modifications.</li></ul><p>\\\nThank you for following along — now go forth and automate! 🚀</p><pre><code>#!/bin/bash\nset -eo pipefail\n\n# The script will create a package thought the package manager api:\n# - The package is created, if not already present\n# - Package filters are populated accordingly to specified paths\n# - Package is builded\n# - Package is download to the specified folder\n\n_log () {\n  echo \"[$(date +%Y.%m.%d-%H:%M:%S)] $1\"\n}\n\ncheck_last_exec () {\n    local message=\"$1\"\n    local output=\"$2\"\n    local status=$3\n\n    if [ \"$status\" -ne 0 ]; then\n        echo &amp;&amp; echo \"$message\" &amp;&amp; echo\n        exit 1\n    fi\n\n    if [[ $output =~ .*success\\\":false* ]] || [[ $output =~ .*\"HTTP ERROR\"* ]]; then\n        _log \"$message\"\n        exit 1\n    fi\n}\n\nUSR=\"$1\"\nPWD=\"$2\"\nSVR=\"$3\"\nPORT=\"$4\"\nPKG_GROUP=\"$5\"\nPKG_NAME=\"$6\"\nBK_FOLDER=\"$7\"\n\nshift 7\n# The following paths will be included in the package\nFILTERS=($@)\nBK_FILE=$PKG_NAME\"-\"$(date +%Y%m%d-%H%M%S).zip\n\n_log \"Starting backup process...\"\necho \"AEM instance: '$SVR':'$PORT'\nAEM User: '$USR'\nPackage group: $PKG_GROUP\nPackage name: '$PKG_NAME'\nDestination folder: $BK_FOLDER\nDestination file: '$BK_FILE'\nFilter paths: \"\nprintf '\\t%s\\n\\n' \"${FILTERS[@]}\"\n\nif [ ! -d \"$BK_FOLDER\" ]; then\n  _log \"Backup folder '$BK_FOLDER' does not exist!\" &amp;&amp; echo\n  exit 1\nfi\n\nPKG_NAME=${PKG_NAME// /_}\ncheck_last_exec \"Error replacing white space chars from package name!\" \"\" $? || exit 1\n_log \"Removed whitespaces from package name: '$PKG_NAME'\"\nBK_FILE=$PKG_NAME.zip\n_log \"Backup file: '$BK_FILE'\"\n\n_log \"Creating the package...\"\nif [ $(curl -k -u \"$USR\":\"$PWD\" \"$SVR:$PORT/crx/packmgr/service.jsp?cmd=ls\" 2&gt;/dev/null | grep \"$PKG_NAME.zip\" | wc -l) -eq 1 ]; then\n  _log \" Package '$PKG_GROUP/$PKG_NAME' is already present: skipping creation.\"\nelse\n  curl -k --silent -u \"$USR\":\"$PWD\" -X POST \\\n  \"$SVR:$PORT/crx/packmgr/service/.json/etc/packages/$PKG_GROUP/$PKG_NAME?cmd=create\" \\\n  -d packageName=\"$PKG_NAME\" -d groupName=\"$PKG_GROUP\"\n\n  check_last_exec \"  Error creating the package!\" \"\" $?\n  _log \" Package created\"\nfi\n\n# create filters variable\nFILTERS_PARAM=\"\"\nARR_LEN=\"${#FILTERS[@]}\"\nfor i in \"${!FILTERS[@]}\"; do\n\n  FILTERS_PARAM=$FILTERS_PARAM\"{\\\"root\\\": \\\"${FILTERS[$i]}\\\", \\\"rules\\\": []}\"\n\n  T=$((i+1))\n  if [ $T -ne $ARR_LEN ]; then\n   FILTERS_PARAM=$FILTERS_PARAM\", \"\n  fi\ndone\n\n# add filters\n_log \"Adding filters to the package...\"\nCURL_OUTPUT=$(curl -k --silent -u \"$USR\":\"$PWD\" -X POST \"$SVR:$PORT/crx/packmgr/update.jsp\" \\\n-F path=/etc/packages/\"$PKG_GROUP\"/\"$PKG_NAME\".zip -F packageName=\"$PKG_NAME\" \\\n-F groupName=\"$PKG_GROUP\" \\\n-F filter=\"[$FILTERS_PARAM]\" \\\n-F \"_charset_=UTF-8\")\n\nCURL_STATUS=$?\n\n# Pass the status to the check_last_exec function\ncheck_last_exec \"Error adding filters to the package!\" \"$CURL_OUTPUT\" $CURL_STATUS\n_log \"  Package filters updated successfully.\"\n\n# build package\n_log \"Building the package...\"\nCURL_OUTPUT=$(curl -k -u \"$USR\":\"$PWD\" -X POST \\\n  \"$SVR:$PORT/crx/packmgr/service/script.html/etc/packages/$PKG_GROUP/$PKG_NAME.zip\" \\\n  -F \"cmd=build\")\n\ncheck_last_exec \" Error building the package!\" \"$CURL_OUTPUT\" $?\n_log \"  Package built.\"\n\n# download package\n_log \"Downloading the package...\"\nif [ \"$(curl -w \"%{http_code}\" -o \"$BK_FOLDER/$BK_FILE\" -k --silent -u \"$USR\":\"$PWD\" \"$SVR:$PORT/etc/packages/$PKG_GROUP/$PKG_NAME.zip\")\" -eq \"200\" ]; then\n  if [ -f \"$BK_FOLDER/$BK_FILE\" ] &amp;&amp; [ -s \"$BK_FOLDER/$BK_FILE\" ]; then\n    _log \"  Package $BK_FILE downloaded in $BK_FOLDER.\"\n    exit 0\n  fi\nfi\n\n_log \"  Error downloading the package!\"\nexit 1\n</code></pre><p>[¹] Skipping SSL verification with&nbsp;&nbsp;is handy for testing, but you’ll want something sturdier in production (for example&nbsp;)!</p>","contentLength":15141,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What If People Like AI-Generated Art Better?","url":"https://slashdot.org/story/25/02/15/0412246/what-if-people-like-ai-generated-art-better?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739727240,"author":"EditorDavid","guid":696,"unread":true,"content":"Christie's auction house notes that an AI-generated \"portrait\" of an 18th-century French gentleman recently sold for $432,500. (One member of the Paris-based collective behind the work says \"we found that portraits provided the best way to illustrate our point, which is that algorithms are able to emulate creativity.\") \n\nBut the blog post from Christie's goes on to acknowledge that AI researchers \"are still addressing the fundamental question of whether the images produced by their networks can be called art at all.\"\n\n. One way to do that, surely, is to conduct a kind of visual Turing test, to show the output of the algorithms to human evaluators, flesh-and-blood discriminators, and ask if they can tell the difference. \n\"Yes, we have done that,\" says Ahmed Elgammal [director of the Art and Artificial Intelligence Lab at Rutgers University in New Jersey]. \"We mixed human-generated art and art from machines, and posed questions — direct ones, such as 'Do you think this painting was produced by a machine or a human artist?' and also indirect ones such as, 'How inspiring do you find this work?'. We measured the difference in responses towards the human art and the machine art, and found that there is very little difference. Actually, some people are more inspired by the art that is done by machine.\" \nCan such a poll constitute proof that an algorithm is capable of producing indisputable works of art? Perhaps it can — if you define a work of art as an image produced by an intelligence with an aesthetic intent. But if you define art more broadly as an attempt to say something about the wider world, to express one's own sensibilities and anxieties and feelings, then AI art must fall short, because no machine mind can have that urge — and perhaps never will. \n\nThis also begs the question: who gets credit for the resulting work. The AI, or the creator of its algorithm... \n\nOr can the resulting work be considered a \"conceptual art\" collaboration — taking place between a human and an algorithm?","contentLength":2026,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI’s Non-Determinism, Hallucinations, And... Cats?","url":"https://hackernoon.com/ais-non-determinism-hallucinations-and-cats?source=rss","date":1739725209,"author":"Alexander Simonov","guid":688,"unread":true,"content":"<p>For a long time, IT specialists worked without a care in the world. They developed, built, and deployed software smoothly. Then the era of isolation hit, and suddenly, they got bored (of course, this is a playful take on the actual events). IT folks wanted to create something that could handle their work while they stayed home: answer routine questions, generate cool avatars, and analyze vast amounts of data in minutes. They dreamed of traveling to a fantastic place, and so, you guessed it, they revolutionized AI.</p><p>\\\nAI is now functioning, providing answers, and improving lives. As skilled an assistant as it is, AI is truly effective only when used in the right context.</p><p>\\\nWe’re witnessing rapid progress in AI applications, from image and video generation to stock market forecasting and cryptocurrency analysis. Yet, <a href=\"https://www.informationweek.com/machine-learning-ai/how-can-decision-makers-trust-hallucinating-ai-\">AI may offer information we don’t ask for</a> or provide blatantly false answers. Its behavior is very much like that of household cats — you know, the kind that sits quietly and then suddenly pounces on you?</p><p>\\\nOur cats, as well as AI, enjoy being unpredictable:</p><ul><li>You give them the same food (or data) — sometimes they eat, sometimes they ignore it.</li><li>You train them to respond, but they only occasionally react when you call them.</li><li>The bigger and wilder the cat or the larger the AI model, the harder it is to predict its behavior.</li><li>In the morning, cats might be calm; by evening, they turn hyperactive (just like dynamic data).</li><li>Cats might be friendly (deterministic) but can scratch you without warning (stochastic).</li></ul><p>\\\nYou might wonder what determinism and stochasticity mean — let’s find out.</p><h2><strong>Determinism and Stochasticity</strong></h2><p>A deterministic system always produces the same result given the same input — think  if you're a <a href=\"https://devops.com/can-ai-replace-devops-engineers-2/\">DevOps engineer</a>. A real-world example would be your cat that eats the same amount of food you put in its bowl every time — this is . But when the cat sniffs and only eats half, it’s no longer deterministic.</p><p>\\\nA  process includes an element of randomness: with the same input, the result can vary. For example, a machine learning model often uses stochastic algorithms, like , which trains the model by picking random chunks of data rather than the entire dataset.</p><p>\\\nThese definitions don’t fully explain why our AIs sometimes hallucinate and behave chaotically. There are other contributing factors, including the following:</p><ul><li>Rounding errors and floating-point arithmetic</li><li>Multithreading and parallel computations</li><li>Continuously updating data</li><li>Chaos and the “butterfly effect”</li></ul><p>\\\nIf we look a little closer, we'll see other mechanisms that influence the unpredictable behavior of AI models.</p><h2><strong>A Glimpse of Neural Networks</strong></h2><p>You probably know that the <a href=\"https://www.forbes.com/councils/forbestechcouncil/2024/12/10/transforming-businesses-with-llms-risks-and-use-cases/\">AIs everyone uses</a> rely on various neural network algorithms. Here are some types of neural networks:</p><ul><li><strong>Fully Connected Neural Networks (FCNN):</strong> A classic architecture where each neuron connects to every neuron in the next layer.</li></ul><ul><li><strong>Convolutional Neural Networks (CNNs):</strong> These networks use convolutions or filters that highlight image features like edges, textures, and shapes.</li></ul><ul><li><strong>Recurrent Neural Networks (RNNs</strong>): These networks have feedback loops that allow them to remember previous steps (namely, they remember sequences).</li></ul><ul><li><strong>Long Short-Term Memory (LSTM):</strong> An enhanced version of RNNs with mechanisms for selectively forgetting and remembering important data.</li></ul><ul><li>: The most powerful class for text processing. They use multi-head attention, allowing them to consider the entire context simultaneously.</li></ul><ul><li><strong>Generative Adversarial Networks (GANs):</strong> They consist of two networks, one of which generates data and the other evaluates its quality. Their competition leads to better results.</li></ul><ul><li>: Networks designed to compress (encode) information and then reconstruct (decode) it.</li></ul><ul><li><strong>Graph Neural Networks (GNNs):</strong> They work with graphs (nodes and edges) rather than regular data.</li></ul><p>\\\nWe need all that context to understand why the most common model, ChatGPT, often hallucinates.</p><h2><strong>How AI Hallucinations Happen</strong></h2><p>ChatGPT runs on the  architecture, first introduced in <a href=\"https://research.google/pubs/attention-is-all-you-need/\">the 2017 paper, “Attention Is All You Need.”</a> &nbsp;This is the very mechanism that revolutionized text processing. Transformers operate on the self-attention mechanism, which allows them to consider the global context rather than just the nearest words like older recurrent neural networks (LSTM and GRU) do. The model belongs to the GPT (Generative Pre-Trained Transformer) series, which means:</p><ul><li> It was initially trained on enormous amounts of text (books, articles, websites, and code).</li><li> Its task is to generate text, not just classify or extract facts.</li></ul><p>\\\nChatGPT’s answers result from a stochastic process rather than a rigid rule. It doesn’t memorize or reproduce texts but generates responses using a probabilistic model.</p><h3><strong>Word Prediction as a Probabilistic Process</strong></h3><p>When ChatGPT responds, it doesn’t choose the single correct word but computes a probability distribution.</p><p>\\\n where:</p><ul><li>“wi” — the next word in the sentence</li></ul><p>w1, w2, …, wi-1 — the previous words</p><ul><li>P(wi|w1, …, wi-1) — the probability that “wi” will be the next word</li></ul><p>\\\nFor example, if you ask, “What day is it today?” ChatGPT might have different probabilities:</p><ul></ul><p>\\\nIt will mostly often choose the word with the highest probability, but due to generation temperature (a parameter that controls randomness), it might sometimes choose a less likely option based on context.</p><h3><strong>Context Influence and Information Forgetting</strong></h3><p>ChatGPT works with a limited context window, meaning it only \"remembers\" the last NN tokens. For GPT-4, the context window is about 128k tokens (around 300 pages of text). If important information is outside this context, it may:</p><ul><li>Forget details (context clipping effect)</li><li>Make-up information (stochastic process)</li></ul><p>\\\nYet, ChatGPT can often correct its answer after you ask if it's sure. However, ChatGPT can often correct its answer if you ask whether it’s sure.</p><h3><strong>AI Sometimes Corrects Itself, But Why?</strong></h3><p>When you ask ChatGPT, “Are you sure?” it reanalyzes its answer using a new context where doubt is present. This results in:</p><ul><li>Recalculating answer probabilities.</li><li>Choosing a more plausible option if one exists.</li></ul><p>\\\nThis process can be explained by Bayesian probability.</p><p>\\\n<strong>P(A|B) = P(B|A)P(A) / P(B),</strong> where:</p><ul><li><p>P(A|B) — the probability that answer A is correct, considering your follow-up question B.</p></li><li><p>P(B|A) — the probability that you would have asked if ChatGPT was initially right.</p></li><li><p>P(A) — the initial probability of ChatGPT's answer.</p></li><li><p>P(B) — the overall probability that you would ask.</p></li></ul><p>Too much information for you? Brain overheating? Imagine that AIs also get overwhelmed by large amounts of information.</p><h3><strong>Errors Due to Overfitting and Noisy Data</strong></h3><p>Massive amounts of text data flow into ChatGPT’s training, including noise or contradictory information, such as:</p><ul><li>Some sources say the Earth is round, while others claim it’s flat.</li></ul><ul><li>AI can’t always determine which information is true when it appears with varying probabilities.</li></ul><p>\\\nThese are examples of model hallucinations, which occur because ChatGPT’s weights are trained on probabilistic word associations rather than strict logic.</p><p>Here is what we can learn from this. ChatGPT hallucinates since it:</p><ul><li><p>Predicts probabilistically, not deterministically.</p></li><li><p>Has a limited memory (context window).</p></li><li><p>Recalculates probabilities when questioned.</p></li><li><p>Has training data that includes noise and contradictions.</p></li></ul><p>It’s that straightforward. Hope you didn’t get tired. If you did, that’s a good sign because it means you’re thinking critically, which is exactly what we should do when working with AI.</p>","contentLength":7521,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"YouTube TV reaches new deal to keep Paramount content","url":"https://techcrunch.com/2025/02/16/youtube-tv-reaches-new-deal-to-keep-paramount-content/","date":1739723651,"author":"Anthony Ha","guid":669,"unread":true,"content":"<p>After warnings that Paramount content was about to disappear from Google’s pay TV service YouTube TV, the companies announced late Saturday that they’d reached a deal that averts any disruption to channel availability. Those announcements didn’t include many specifics about the agreement, but a statement from a Paramount spokesperson said it includes “an expanded streaming […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":452,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lawsuit Accuses Meta Of Training AI On Torrented 82TB Dataset Of Pirated Books","url":"https://yro.slashdot.org/story/25/02/16/0346210/lawsuit-accuses-meta-of-training-ai-on-torrented-82tb-dataset-of-pirated-books?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739723640,"author":"EditorDavid","guid":674,"unread":true,"content":"\"Meta is involved in a class action lawsuit alleging copyright infringement, a claim the company disputes...\" writes the tech news site Hot Hardware. \n\nBut the site adds that newly unsealed court documents \"reveal that Meta allegedly used a minimum of 81.7TB of illegally torrented data sourced from shadow libraries to train its AI models.\"\n\nInternal emails further show that Meta employees expressed concerns about this practice. Some employees voiced strong ethical objections, with one noting that using content from sites like LibGen, known for distributing copyrighted material, would be unethical. A research engineer with Meta, Nikolay Bashlykov, also noted that \"torrenting from a corporate laptop doesn't feel right,\" highlighting his discomfort surrounding the practice. \n\nAdditionally, the documents suggest that these concerns, including discussions about using data from LibGen, reached CEO Mark Zuckerberg, who may have ultimately approved the activity. Furthermore, the documents showed that despite these misgivings, employees discussed using VPNs to mask Meta's IP address to create anonymity, enabling them to download and share torrented data without it being easily traced back to the company's network.","contentLength":1224,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The HackerNoon Newsletter: Futures of Ethereum II - Censorship Resistance (2/16/2025)","url":"https://hackernoon.com/2-16-2025-newsletter?source=rss","date":1739721931,"author":"Noonification","guid":687,"unread":true,"content":"<p>🪐 What’s happening in tech today, February 16, 2025?</p><p>By <a href=\"https://hackernoon.com/u/hackernooncontests\">@hackernooncontests</a> [ 3 Min read ] Join the #blockchain Writing Contest and share your insights on decentralized AI, cloud, or dePIN. Win up to $2,000! Contest open Feb 5–May 7, 2025. <a href=\"https://hackernoon.com/win-up-to-$2000-in-the-blockchain-writing-contest-by-aleph-cloud-and-hackernoon\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/juancguerrero\">@juancguerrero</a> [ 3 Min read ] Tether is one of the largest holders of U.S. government debt. Its not just a stablecoin company – its becoming Americas new strategic reserve buyer. <a href=\"https://hackernoon.com/tether-may-become-americas-new-strategic-reserve-buyer\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bill-achola\">@bill-achola</a> [ 3 Min read ] Who really profits in a startup? Our deep dive into startup salaries reveals how executives secure big paydays while employees take on the risk. <a href=\"https://hackernoon.com/i-learned-the-hard-way-that-startup-high-executives-profit-while-employees-struggle\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/boxhero\">@boxhero</a> [ 13 Min read ] Discover how AI-powered sentiment analysis tools deliver accurate insights from customer reviews and feedback to help improve your business strategy. <a href=\"https://hackernoon.com/sentiment-analysis-and-ai-everything-you-need-to-know-in-2025\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mend\">@mend</a> [ 6 Min read ] Generative AI boosts efficiency but introduces security risks like shadow AI, vulnerabilities, and data leaks. Learn how AI can secure AI-driven development. <a href=\"https://hackernoon.com/generative-ais-double-edged-sword-unlocking-potential-while-mitigating-risks\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/adambakay\">@adambakay</a> [ 22 Min read ] By understanding market microstructure, you might be able to add more precision into your trading. <a href=\"https://hackernoon.com/thinking-of-pursuing-trading-full-time-then-you-need-to-know-what-market-microstructures-are\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/2077research\">@2077research</a> [ 17 Min read ] The article explores Ethereums efforts to ensure censorship resistance, focusing on solutions like PBS and encrypted mempools amid regulatory pressures. <a href=\"https://hackernoon.com/futures-of-ethereum-ii-censorship-resistance\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/stellar\">@stellar</a> [ 5 Min read ] Regulatory shifts in 2025 will shape crypto wallets. Learn how compliance, DeFi, and Stellar’s Soroban ecosystem will impact the future of Web3 wallets. <a href=\"https://hackernoon.com/regulatory-clarity-on-wallets-will-shape-defi-in-2025\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>","contentLength":1788,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI tries to ‘uncensor’ ChatGPT","url":"https://techcrunch.com/2025/02/16/openai-tries-to-uncensor-chatgpt/","date":1739721600,"author":"Maxwell Zeff","guid":668,"unread":true,"content":"<p>OpenAI is changing how it trains AI models to explicitly embrace “intellectual freedom … no matter how challenging or controversial a topic may be,” the company says in a new policy. As a result, ChatGPT will eventually be able to answer more questions, offer more perspectives, and reduce the number of topics the AI chatbot […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":400,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Amazon Tests Robots For Automating Fulfillment Centers","url":"https://hardware.slashdot.org/story/25/02/16/0241242/amazon-tests-robots-for-automating-fulfillment-centers?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739720040,"author":"EditorDavid","guid":646,"unread":true,"content":"Yahoo Finance shares an interesting prediction. Amazon has an \"under-the-radar robot push\" that \"could boost its profit margins big-time, Morgan Stanley managing director Brian Nowak said.\"\n\n\nNowak said Amazon has quietly developed six significant next-generation fulfillment centers in the past three years that bring automation front and center... Amazon now has industrial robots that can increase efficiencies across the storage, inventory management, pick and packing, and sorting order fulfillment processes. \nFulfillment costs make up about 20% of Amazon's retail revenue, so he reasoned that automation could have a significant impact on long-term operating profit potential. Nowak says if 30% to 40% of Amazon's US units were fulfilled through next-generation robotics-enabled warehouses by 2030, it could lead to $10 billion-plus of savings... The investments in robots may already be paying off. Amazon's North America retail operating margins on a trailing 12-month basis have risen for five straight quarters. North America operating margins improved to 6.2% from 4.6% a year ago. \n\nNowak made the remarks on a Yahoo Finance podcast (at the top of their article) after touring one of Amazon's robot-enhanced sites in Louisiana. He believes robotics can drive down Amazon's costs compared to other retailers like Target (which he sees as lagging behind Amazon on robotics). \n\nMeanwhile workers at an Amazon facility in North Carolina held a vote Saturday on whether to unionize. But roughly 75% of the workers voted against unionization.","contentLength":1549,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Firefox User Manages Experimental Browser Port To GTK4 Toolkit","url":"https://www.phoronix.com/news/Firefox-User-Ports-GTK4","date":1739718000,"author":"Michael Larabel","guid":633,"unread":true,"content":"<article>For four years there has been an open bug report for Mozilla Firefox requesting the browser's GTK widget support be updated for GTK4. An independent user/developer has taken it into his own hands and has managed to get Firefox using the GTK4 toolkit up and running on Linux...</article>","contentLength":276,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Open source LLMs hit Europe’s digital sovereignty roadmap","url":"https://techcrunch.com/2025/02/16/open-source-llms-hit-europes-digital-sovereignty-roadmap/","date":1739716200,"author":"Paul Sawers","guid":667,"unread":true,"content":"<p>Large language models (LLMs) landed on Europe’s digital sovereignty agenda with a bang last week, as news emerged of a new program to develop a series of “truly” open source LLMs covering all European Union languages. This includes the current 24 official EU languages, as well as languages for countries currently negotiating for entry to […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":414,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Willie Hobbs Moore: STEM Trailblazer","url":"https://spectrum.ieee.org/willie-hobbs-moore-profile","date":1739714403,"author":"Willie D. Jones","guid":606,"unread":true,"content":"<p>The first Black woman with a science Ph.D paved the way for underrepresented groups</p>","contentLength":83,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjQ4OTk0Ni9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc2NzAzOTE1Mn0.lUm5Wa5yQcpIZ0xdV8JvdAdFK4rGGfnMkR79x8IeWRs/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Alleged 'CEO Shooter' Luigi Mangione Raises $297K Online","url":"https://yro.slashdot.org/story/25/02/16/0040252/alleged-ceo-shooter-luigi-mangione-raises-297k-online?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739709240,"author":"EditorDavid","guid":539,"unread":true,"content":"Luigi Mangione faces first-degree murder charges. On Valentine's Day he posted his first public comments online, reports People magazine, with Mangione saying he's grateful for the support he's receiving:\n\nEarlier this week, Mangione accepted $297,000 in donations to cover his legal bills from the December 4 Legal Committee, which is stewarding a fundraiser on GiveSendGo for his legal defense, according to a post shared by the group. (A source with knowledge of the situation confirmed to PEOPLE that the post was genuine.) The committee — named after the death date of Thompson — said the donations were offered by over 10,000 individual supporters. Mangione's lead attorney, Karen Friedman Agnifilo, told the committee that Mangione \"very much appreciates the outpouring of support....\" \n\nHis federal murder charges could land him the death penalty, and he also faces state murder charges that accuse him of committing an act of terrorism.","contentLength":949,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"You Should Be Harder on Yourself, Despite What Self Care Gurus Say","url":"https://hackernoon.com/you-should-be-harder-on-yourself-despite-what-self-care-gurus-say?source=rss","date":1739708085,"author":"Scott D. Clary","guid":686,"unread":true,"content":"<p>We're obsessed with being gentle with ourselves.</p><p>\\\nEvery self-help guru and Instagram therapist preaches the same message: be kind to yourself, practice self-compassion, and celebrate small wins.</p><p>\\\nAnd sure, there's value in not being overly critical. Nobody wants to spiral into self-hatred or paralysis.</p><p>\\\nBut what if I told you that being harder on yourself is actually the key to freedom?</p><blockquote><p>Here's what most people miss:&nbsp;<strong>the most successful people in any field are simultaneously confident in their abilities and brutally honest about their shortcomings.</strong></p></blockquote><p>\\\nThink about that for a second.</p><p>\\\nCan you imagine how freeing it feels to already be successful and still know, deep down, that you're nowhere near your potential?</p><p>\\\nThat's not depressing. That's exciting.</p><p>\\\nBecause when you're genuinely successful, you no longer need to protect your ego. You don't need to defend your current position. You can look at yourself with crystal clear vision and think \"<em>I'm good, but I could be so much better.</em>\"</p><p>\\\nMost people never experience this freedom because they're trapped in a prison of their own making.</p><p>\\\nThey're stuck defending their current level of achievement. Protecting their ego. Making excuses for why they haven't progressed further.</p><p>\\\n<strong>Mediocrity isn't a position - it's a mindset.</strong></p><p>\\\nAnd the mindset comes from a deep fear that if we acknowledge our shortcomings, we'll feel worse about ourselves. So we settle into comfortable patterns, telling ourselves we're \"doing our best\" when we know we're not.</p><p>\\\nBut here's the thing about potential: it's like a muscle. The more you push against it, the more it grows. The moment you stop pushing, it starts to atrophy.</p><p>The bodybuilding community understands this better than anyone, because they can't hide from the mirror.</p><p>\\\nThere's a saying in bodybuilding circles (pre-competition):&nbsp;<em>you're always fatter than you think you are.</em></p><p>\\\nIt sounds harsh. Maybe even toxic to outsiders. But there's profound wisdom here that goes way beyond physique. It's about seeing yourself with uncompromising clarity.</p><p>\\\n<strong>Just like you can't argue with your reflection, you can't argue with reality.</strong></p><p>\\\nWhen you're standing on stage at 5% body fat, and striations showing everywhere, most people would call you shredded. But the elite?</p><p>They're analyzing every minor flaw. Every slight imbalance. Every area that could be just a bit tighter. Not because they hate themselves – but because they respect their potential enough to be honest about it.</p><p>\\\nThis isn't body dysmorphia - it's the relentless pursuit of excellence. The moment you stop defending your current level is the moment you start transcending it.</p><p>\\\n<strong>Just like every rep builds muscle, every honest assessment builds excellence.</strong></p><p>\\\nYour workouts become more focused because you stop pretending that \"feeling tired\" is a valid excuse. Your nutrition gets dialed in because you stop lying to yourself about \"just one cheat meal.\" Your recovery becomes sacred because you finally admit how much sleep you really need. You're never satisfied with \"good enough\" because you've tasted what lies beyond it.</p><p>Take this same uncompromising vision and apply it to business.</p><p>\\\n<strong>Just like a bodybuilder can't argue with the mirror, an entrepreneur can't argue with the market.</strong></p><p>\\\nEvery project you undertake will take three times longer than you think. Every marketing campaign will require more iterations than you planned. Every product launch will need more refinement than you expected. And pretending otherwise isn't optimism – it's delusion.</p><p>\\\nThe entrepreneurs who make it aren't the ones who nail everything on the first try. They're the ones who expect it to be hard and keep pushing anyway. They're the ones who look at their first prototype the way a bodybuilder looks in the mirror: with appreciation for progress, but crystal-clear vision about what needs to change.</p><p>\\\nThink about that startup you've been planning. You probably have a timeline in your head. Double it. Then double it again. Not because you're going to work slower, but because doing things&nbsp;&nbsp;takes time. Because you're finally being honest about how much refinement excellence requires.</p><p>\\\n<strong>Just like every failed rep makes you stronger, every setback makes you smarter.</strong></p><p>\\\nThis isn't pessimism - it's strategic realism. When you embrace how hard the journey will be, you stop getting discouraged by setbacks.</p><p>\\\n<em>They're not setbacks anymore. They're the process.</em></p><p>At the end of the day,&nbsp;<strong>you're not as good as you think you are.</strong></p><p>\\\nYour communication skills? Not as refined as you believe.</p><p>\\\nYour work ethic? Probably not as strong as you tell yourself.</p><p>\\\nYour talents? Still mostly untapped.</p><p>\\\nBut here's where it gets interesting. This reality check isn't meant to discourage you - it's meant to&nbsp;&nbsp;you. Because if you're not as good as you think you are, that means there's so much more room to grow.</p><p>\\\n<strong>The gap between where you are and where you could be is your opportunity.</strong></p><p>The moment you stop defending your current level, something magical happens. The energy you were using to maintain your self-image gets redirected into actual improvement.</p><p>\\\n<strong>Think about how much mental energy you spend:</strong></p><ul><li>Justifying your current position</li><li>Making excuses for missed opportunities</li><li>Comparing yourself to others who are \"doing worse\"</li></ul><p>\\\nWhat if you took all that energy and poured it into getting better instead?</p><p>\\\n<strong>True freedom comes when you stop needing to be \"good enough\" and start embracing being not good enough&nbsp;.</strong></p><p>\\\nIt's like taking off a heavy backpack you didn't even know you were carrying. The weight of maintaining your self-image drops away, replaced by the lightness of pure potential.</p><p>Being harder on yourself doesn't mean beating yourself up at 2 AM about past mistakes. It means looking at your day and asking \"<em>Where did I let myself off easy?</em>\"</p><p>\\\nWhen you finished that project early? Maybe you could have added another layer of polish.</p><p>\\\nWhen you hit your sales target? You probably could have made ten more calls.</p><p>\\\nWhen you felt tired at the gym? There were probably two more reps in you.</p><p>\\\n<strong>The key is to separate your worth from your performance.</strong>&nbsp;You're not a bad person for having room to improve. You're a human with unlimited potential who's choosing to see reality clearly.</p><p>\\\nIt's not about punishment - it's about&nbsp;.</p><p>\\\nThe most successful people I know aren't walking around in a cloud of self-hatred. They're energized by their potential. They're excited by how far they still have to go.</p><p>\\\nBecause here's the truth:&nbsp;<strong>the moment you think you've \"made it\" is the moment you start declining.</strong></p><p>\\\nBut when you embrace being harder on yourself, every day becomes an opportunity. Every mistake becomes data. Every setback becomes feedback.</p><p>\\\nAnd suddenly, you're not trapped by your current capabilities. You're not defensive about your flaws. You're just getting started.</p><p>\\\nNot the freedom to be comfortable, but the freedom to grow without limit.</p><p>\\\nThe freedom to look in the mirror and say \"I'm not good enough yet - and that's exactly why I'm going to win.\"</p>","contentLength":6976,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GNOME 48 Beta Released With HDR Bits, gdctl, Adwaita Fonts Default & More","url":"https://www.phoronix.com/news/GNOME-48-Beta-Released","date":1739707647,"author":"Michael Larabel","guid":541,"unread":true,"content":"<article>The GNOME 48 Beta release was officially announced this morning as the latest stepping stone toward the official GNOME 48 desktop release due out in mid-March...</article>","contentLength":161,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intel Killer E5000 Ethernet Support For Linux 6.15","url":"https://www.phoronix.com/news/Intel-Killer-E5000-Linux-6.15","date":1739706300,"author":"Michael Larabel","guid":536,"unread":true,"content":"<article>The upcoming Linux 6.15 kernel cycle will be adding support for Intel Killer E5000 Ethernet...</article>","contentLength":94,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Btrfs-Progs 6.13 Released With \"mkfs.btrfs --compress\" Support","url":"https://www.phoronix.com/news/Btrfs-Progs-6.13","date":1739705883,"author":"Michael Larabel","guid":535,"unread":true,"content":"<article>Btrfs-Progs 6.13 was released this weekend as the newest routine update to the user-space utilities for the Btrfs file-system...</article>","contentLength":128,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"134k Lines Of Code Posted As Latest Effort For COBOL Support Within GCC","url":"https://www.phoronix.com/news/134k-Lines-v2-COBOL-For-GCC","date":1739704755,"author":"Michael Larabel","guid":534,"unread":true,"content":"<article>While it's an old language, in recent months there's been a renewed effort over a COBOL language front-end for the GCC compiler. There's been out-of-tree COBOL support for GCC that is working to get into the mainline GNU Compiler Collection codebase. This weekend saw the latest iteration of those patches amounting to 134k lines of new code...</article>","contentLength":344,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Are Fast Programming Languages Gaining in Popularity?","url":"https://developers.slashdot.org/story/25/02/16/0332258/are-fast-programming-languages-gaining-in-popularity?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739694840,"author":"EditorDavid","guid":520,"unread":true,"content":"In January the TIOBE Index (estimating programming language popularity) declared Python their language of the year. (Though it was already #1 in their rankings, it had showed a 9.3% increase in their ranking system, notes InfoWorld.) TIOBE CEO Paul Jansen says this reflects how easy Python is to learn, adding that \"The demand for new programmers is still very high\" (and that \"developing applications completely in AI is not possible yet.\") \n\nIn fact on February's version of the index, the top ten looks mostly static. The only languages dropping appear to be very old languages. Over the last 12 months C and PHP have both fallen on the index — C from the #2 to the #4 spot, and PHP from #10 all the way to #14. (Also dropping is Visual Basic, which fell from #9 to #10.) \n\nBut TechRepublican cites another factor that seems to be affecting the rankings: language speed.\n\n\nFast programming languages are gaining popularity, TIOBE CEO Paul Jansen said in the TIOBE Programming Community Index in February. Fast programming languages he called out include C++ [#2], Go [#8], and Rust [#13 — up from #18 a year ago]. \n\nAlso, according to the updated TIOBE rankings... \n- C++ held onto its place at second from the top of the leaderboard.\n- Mojo and Zig are following trajectories likely to bring them into the top 50, and reached #51 and #56 respectively in February. \n\n\"Now that the world needs to crunch more and more numbers per second, and hardware is not evolving fast enough, speed of programs is getting important. Having said this, it is not surprising that the fast programming languages are gaining ground in the TIOBE index,\" Jansen wrote. The need for speed helped Mojo [#51] and Zig [#56] rise... \n\nRust reached its all-time high in the proprietary points system (1.47%.), and Jansen expects Go to be a common sight in the top 10 going forward.\n","contentLength":1863,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The TechBeat: Cybercrooks Are Using Fake Job Listings to Steal Crypto (2/16/2025)","url":"https://hackernoon.com/2-16-2025-techbeat?source=rss","date":1739689860,"author":"Techbeat","guid":523,"unread":true,"content":"<p>By <a href=\"https://hackernoon.com/u/diadkov\">@diadkov</a> [ 4 Min read ] \n Since March 2024, conspiracy theories about TikTok's ban have spread, citing espionage fears and geopolitical influences without solid evidence <a href=\"https://hackernoon.com/is-the-tiktok-ban-a-cover-up-the-internet-thinks-so\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/moonlock\">@moonlock</a> [ 19 Min read ] \n Moonlock Lab dives deep into a campaign tricking blockchain developers with fake job interviews to deploy malware that installs a backdoor and targets MetaMask. <a href=\"https://hackernoon.com/cybercrooks-are-using-fake-job-listings-to-steal-crypto\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/@javar97\">@@javar97</a> [ 7 Min read ] \n According to Stack Overflow's 2024 survey, 76% of developers are using or planning to use AI tools. <a href=\"https://hackernoon.com/ai-coding-tools-are-still-in-the-randd-stage\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bill-achola\">@bill-achola</a> [ 3 Min read ] \n Who really profits in a startup? Our deep dive into startup salaries reveals how executives secure big paydays while employees take on the risk. <a href=\"https://hackernoon.com/i-learned-the-hard-way-that-startup-high-executives-profit-while-employees-struggle\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ntoskrnl\">@ntoskrnl</a> [ 8 Min read ] \n Security mechanisms under the hood of simple file actions <a href=\"https://hackernoon.com/securitys-moving-parts-01-linux-access-control-mechanisms\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bigredeye\">@bigredeye</a> [ 21 Min read ] \n Perforator is a continuous profiling system developed by Yandex, now open-sourced.   <a href=\"https://hackernoon.com/yandexs-high-performance-profiler-is-going-open-source\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/andrei9735\">@andrei9735</a> [ 6 Min read ] \n Link prediction aims to predict the likelihood of a future or missing connection between nodes in a network.  <a href=\"https://hackernoon.com/learn-to-create-an-algorithm-that-can-predict-user-behaviors-using-ai\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/thomascherickal\">@thomascherickal</a> [ 25 Min read ] \n Deep Research Prompts: Explore 30 ambitous, impactful ideas using emerging tech to tackle global crises. Discover research with world-changing potential. <a href=\"https://hackernoon.com/30-world-changing-prompts-openais-ai-singularity-deep-research-has-arrived\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bigmao\">@bigmao</a> [ 6 Min read ] \n The case against content marketing, and how to do inbound marketing in the post-content age.  <a href=\"https://hackernoon.com/no-startup-has-ever-failed-because-it-didnt-have-a-blog\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/vinitabansal\">@vinitabansal</a> [ 9 Min read ] \n While aggressive managers are difficult, they aren’t impossible to work with. With the right strategies, you can turn them around. <a href=\"https://hackernoon.com/dealing-with-an-aggressive-manager-is-simpler-than-you-think\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/silkdrive\">@silkdrive</a> [ 4 Min read ] \n Discover the future of software development with vibe coding—where creativity comes first, and coding happens effortlessly with AI. <a href=\"https://hackernoon.com/vibe-coding-creativity-without-code\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/editingprotocol\">@editingprotocol</a> [ 4 Min read ] \n If you want to become a top writer, here are 3 tips to help you rise to the cream of the crop.  <a href=\"https://hackernoon.com/climb-the-ranks-3-actionable-tips-to-become-a-top-writer\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/abhiyanampally_kob9nse8\">@abhiyanampally_kob9nse8</a> [ 40 Min read ] \n Dive into the comparitive analysis between logarithmic and floating-point arithmetic in neural nets using the commonly used MNIST dataset. <a href=\"https://hackernoon.com/deep-learning-runs-on-floating-point-math-what-if-thats-a-mistake\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/blackheart\">@blackheart</a> [ 6 Min read ] \n In Barbie, Ken struggles with identity, feeling like he exists in Barbie’s shadow. Many cybersecurity specialists can relate. <a href=\"https://hackernoon.com/the-ken-dilemma-in-cybersecurity\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/step\">@step</a> [ 6 Min read ] \n Language is a component of human consciousness. AI has a conversational and relatable language capability, could that be a fraction of consciousness? <a href=\"https://hackernoon.com/so-how-does-one-really-determine-ai-is-conscious\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mesciusinc\">@mesciusinc</a> [ 10 Min read ] \n Learn everything you need to know about the best Blazor UI Components and how to use them in your application. <a href=\"https://hackernoon.com/the-top-blazor-ui-components-everything-you-need-to-know\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/brightdata\">@brightdata</a> [ 8 Min read ] \n Let's see how OpenAI's Operator is handling CAPTCHAs and explore whether this is the best solution! <a href=\"https://hackernoon.com/openais-operator-vs-captchas-whos-winning\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/andrei9735\">@andrei9735</a> [ 7 Min read ] \n In this post we'll continue working on link prediction with the Twitch dataset. <a href=\"https://hackernoon.com/before-ai-predicts-your-next-friend-it-needs-to-do-this-first\">Read More.</a></p>","contentLength":2888,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Bugs Could Delay Upgrades for Both Siri and Alexa","url":"https://apple.slashdot.org/story/25/02/16/0138205/ai-bugs-could-delay-upgrades-for-both-siri-and-alexa?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739684040,"author":"EditorDavid","guid":512,"unread":true,"content":"Bloomberg reports that Apple's long-promised overhaul for Siri \"is facing engineering problems and software bugs, threatening to postpone or limit its release, according to people with knowledge of the matter....\"\n\nLast June, Apple touted three major enhancements coming to Siri: \n\n- the ability to tap into a customer's data to better answer queries and take actions.\n- a new system that would let the assistant more precisely control apps.\n- the capability to see what's currently on a device's screen and use that context to better serve users.... \n\nThe goal is to ultimately offer a more versatile Siri that can seamlessly tap into customers' information and communication. For instance, users will be able to ask for a file or song that they discussed with a friend over text. Siri would then automatically retrieve that item. Apple also has demonstrated the ability for Siri to quickly locate someone's driver's license number by reviewing their photos... Inside Apple, many employees testing the new Siri have found that these features don't yet work consistently... \nThe control enhancements — an upgraded version of something called App Intents — are central to the operation of the company's upcoming smart home hub. That product, an AI device for controlling smart home appliances and FaceTime, is slated for release later this year. \n\nAnd Amazon is also struggling with an AI upgrade for its digital assistant, reports the Washington Post:\nThe \"smarter and more conversational\" version of Alexa will not be available until March 31 or later, the employee said, at least a year and a half after it was initially announced in response to competition from OpenAI's ChatGPT. Internal messages seen by The Post confirmed the launch was originally scheduled for this month but was subsequently moved to the end of March... According to internal documents seen by The Post, new features of the subscriber-only, AI-powered Alexa could include the ability to adopt a personality, recall conversations, order takeout or call a taxi. Some of the new Alexa features are similar to Alexa abilities that were previously available free through partnerships with companies like Grubhub and Uber... \nThe AI-enhanced version of Alexa in development has been repeatedly delayed due to problems with incorrect answers, the employee working on the launch told The Post. As a popular product that is a decade old, the Alexa brand is valuable, and the company is hesitant to risk customer trust by launching a product that is not reliable, the person said.\n\n","contentLength":2551,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Death of OpenAI whistleblower deemed suicide in new autopsy report","url":"https://techcrunch.com/2025/02/15/death-of-openai-whistleblower-deemed-suicide-in-new-autopsy-report/","date":1739682712,"author":"Connie Loizos","guid":511,"unread":true,"content":"<p>Suchir Balaji, a former OpenAI employee, was found dead in his San Francisco apartment on Nov. 26; on Friday, the city’s medical examiner ruled his death a suicide, countering suspicions by his family that had fueled widespread speculation online. Balaji made headlines in October when he accused OpenAI of illegally using copyrighted material to train […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":423,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ask Slashdot: What Would It Take For You to Trust an AI?","url":"https://ask.slashdot.org/story/25/02/15/2047258/ask-slashdot-what-would-it-take-for-you-to-trust-an-ai?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739673240,"author":"EditorDavid","guid":500,"unread":true,"content":"Long-time Slashdot reader shanen has been testing AI clients. (They report that China's DeepSeek \"turned out to be extremely good at explaining why I should not trust it. Every computer security problem I ever thought of or heard about and some more besides.\") \n\nThen they wondered if there's also government censorship:\n\nIt's like the accountant who gets asked what 2 plus 2 is. After locking the doors and shading all the windows, the accountant whispers in your ear: \"What do you want it to be...?\" So let me start with some questions about DeepSeek in particular. Have you run it locally and compared the responses with the website's responses? My hypothesis is that your mileage should differ... \n\nIt's well established that DeepSeek doesn't want to talk about many \"political\" topics. Is that based on a distorted model of the world? Or is the censorship implemented in the query interface after the model was trained? My hypothesis is that it must have been trained with lots of data because the cost of removing all of the bad stuff would have been prohibitive... Unless perhaps another AI filtered the data first? \nBut their real question is: what would it take to trust an AI? \"Trust\" can mean different things, including data-collection policies. (\"I bet most of you trust Amazon and Amazon's secret AIs more than you should...\" shanen suggests.) Can you use an AI system without worrying about its data-retention policies?\n \n\nAnd they also ask how many Slashdot readers have read Ken Thompson's \"Reflections on Trusting Trust\", which raises the question of whether you can ever trust code you didn't create yourself. So is there any way an AI system can assure you its answers are accurate and trustworthy, and that it's safe to use? Share your own thoughts and experiences in the comments. \nWhat would it take for you to trust an AI?","contentLength":1846,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FreeBSD 13.5 Overcomes UFS Y2038 Problem To Push It Out To Year 2106","url":"https://www.phoronix.com/news/FreeBSD-13.5-Beta-2","date":1739669445,"author":"Michael Larabel","guid":488,"unread":true,"content":"<article>Following last week's FreeBSD 13.5 Beta 1 release to kick off this next FreeBSD 13 point release that will also end the series, FreeBSD 13.5 Beta 2 is out this weekend for testing...</article>","contentLength":182,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Despite Plans for AI-Powered Search, Reddit's Stock Fell 14% Thsi Week","url":"https://tech.slashdot.org/story/25/02/16/007234/despite-plans-for-ai-powered-search-reddits-stock-fell-14-thsi-week?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739664540,"author":"EditorDavid","guid":481,"unread":true,"content":"\"Reddit Answers\" uses generative AI to answer questions using what past Reddittors have posted. Announced in December, Reddit now plans to integrate it into their search results, reports TechCrunch, with Reddit's CEO saying the idea has \"incredible monetization potential.\" \n\nAnd yet Reddit's stock fell 14% this week. CNBC's headline? \"Reddit shares plunge after Google algorithm change contributes to miss in user numbers.\"\n\n\nA Google search algorithm change caused some \"volatility\" with user growth in the fourth quarter, but the company's search-related traffic has since recovered in the first quarter, Reddit CEO Steve Huffman said in a letter to shareholders. \"What happened wasn't unusual — referrals from search fluctuate from time to time, and they primarily affect logged-out users,\" Huffman wrote. \"Our teams have navigated numerous algorithm updates and did an excellent job adapting to these latest changes effectively....\" Reddit has said it is working to convince logged-out users to create accounts as logged-in users, which are more lucrative for its business. \n\n\nAs Yahoo Finance once pointed out, Reddit knew this day would come, acknowledging in its IPO filing that \"changes in internet search engine algorithms and dynamics could have a negative impact on traffic for our website and, ultimately, our business.\" And in the last three months of 2024 Reddit's daily active users dropped, Yahoo Finance reported this week. But logged-in users increased by 400,000 — while logged-out users dropped by 600,000 (their first drop in almost two years). \n\nMarketwatch notes that analyst Josh Beck sees this as a buying opportunity for Reddit's stock:\nBeck pointed to comments from Reddit's management regarding a sharp recovery in daily active unique users. That was likely driven by Google benefiting from deeper Reddit crawling, by the platform uncollapsing comments in search results and by a potential benefit from spam-reduction algorithm updates, according to the analyst. \"While the report did not clear our anticipated bar, we walk away encouraged by international upside,\" he wrote.\n","contentLength":2110,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Despite Plans for AI-Powered Search, Reddit's Stock Fell 14% This Week","url":"https://tech.slashdot.org/story/25/02/16/007234/despite-plans-for-ai-powered-search-reddits-stock-fell-14-this-week?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739664540,"author":"EditorDavid","guid":484,"unread":true,"content":"\"Reddit Answers\" uses generative AI to answer questions using what past Reddittors have posted. Announced in December, Reddit now plans to integrate it into their search results, reports TechCrunch, with Reddit's CEO saying the idea has \"incredible monetization potential.\" \n\nAnd yet Reddit's stock fell 14% this week. CNBC's headline? \"Reddit shares plunge after Google algorithm change contributes to miss in user numbers.\"\n\n\nA Google search algorithm change caused some \"volatility\" with user growth in the fourth quarter, but the company's search-related traffic has since recovered in the first quarter, Reddit CEO Steve Huffman said in a letter to shareholders. \"What happened wasn't unusual — referrals from search fluctuate from time to time, and they primarily affect logged-out users,\" Huffman wrote. \"Our teams have navigated numerous algorithm updates and did an excellent job adapting to these latest changes effectively....\" Reddit has said it is working to convince logged-out users to create accounts as logged-in users, which are more lucrative for its business. \n\n\nAs Yahoo Finance once pointed out, Reddit knew this day would come, acknowledging in its IPO filing that \"changes in internet search engine algorithms and dynamics could have a negative impact on traffic for our website and, ultimately, our business.\" And in the last three months of 2024 Reddit's daily active users dropped, Yahoo Finance reported this week. But logged-in users increased by 400,000 — while logged-out users dropped by 600,000 (their first drop in almost two years). \n\nMarketwatch notes that analyst Josh Beck sees this as a buying opportunity for Reddit's stock:\nBeck pointed to comments from Reddit's management regarding a sharp recovery in daily active unique users. That was likely driven by Google benefiting from deeper Reddit crawling, by the platform uncollapsing comments in search results and by a potential benefit from spam-reduction algorithm updates, according to the analyst. \"While the report did not clear our anticipated bar, we walk away encouraged by international upside,\" he wrote.\n","contentLength":2110,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"China's 'Salt Typhoon' Hackers Continue to Breach Telecoms Despite US Sanctions","url":"https://it.slashdot.org/story/25/02/15/2244220/chinas-salt-typhoon-hackers-continue-to-breach-telecoms-despite-us-sanctions?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739659620,"author":"EditorDavid","guid":470,"unread":true,"content":"\"Security researchers say the Chinese government-linked hacking group, Salt Typhoon, is continuing to compromise telecommunications providers,\" reports TechCrunch, \"despite the recent sanctions imposed by the U.S. government on the group.\" \n\nTechRadar reports that the Chinese state-sponsored threat actor is \"hitting not just American organizations, but also those from the UK, South Africa, and elsewhere around the world.\"\n\n\n\n\nThe latest intrusions were spotted by cybersecurity researchers from Recorded Future, which said the group is targeting internet-exposed web interfaces of Cisco's IOS software that powers different routers and switches. These devices have known vulnerabilities that the threat actors are actively exploiting to gain initial access, root privileges, and more. More than 12,000 Cisco devices were found connected to the wider internet, and exposed to risk, Recorded Future further explained. However, Salt Typhoon is focusing on a \"smaller subset\" of telecoms and university networks. \n\n\"The hackers attempted to exploit vulnerabilities in at least 1,000 Cisco devices,\" reports NextGov, \"allowing them to access higher-level privileges of the hardware and change their configuration settings to allow for persistent access to the networks they're connected on... Over half of the Cisco appliances targeted by Salt Typhoon were located in the U.S., South America and India, with the rest spread across more than 100 countries.\"\nBetween December and January, the unit, widely known as Salt Typhoon, \"possibly targeted\" — based on devices that were accessed — offices in the University of California, Los Angeles, California State University, Loyola Marymount University and Utah Tech University, according to a report from cyber threat intelligence firm Recorded Future... The Cisco devices were mainly associated with telecommunications firms, but 13 of them were linked to the universities in the U.S. and some in other nations... \"Often involved in cutting-edge research, universities are prime targets for Chinese state-sponsored threat activity groups to acquire valuable research data and intellectual property,\" said the report, led by the company's Insikt Group, which oversees its threat research. \n\nThe cyberspies also compromised Cisco platforms at a U.S.-based affiliate of a prominent United Kingdom telecom operator and a South African provider, both unnamed, the findings added. The hackers also \"carried out a reconnaissance of multiple IP addresses\" owned by Mytel, a telecom operator based in Myanmar... \n\n\"In 2023, Cisco published a security advisory disclosing multiple vulnerabilities in the web UI feature in Cisco IOS XE software,\" a Cisco spokesperson said in a statement. \"We continue to strongly urge customers to follow recommendations outlined in the advisory and upgrade to the available fixed software release.\"\n\n","contentLength":2874,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"North Carolina Amazon workers vote against unionizing","url":"https://techcrunch.com/2025/02/15/north-carolina-amazon-workers-vote-against-unionizing/","date":1739657733,"author":"Anthony Ha","guid":433,"unread":true,"content":"<p>Workers at an Amazon warehouse in Garner, North Carolina voted against unionizing in election results announced today. According to Carolina Amazonians United for Solidarity and Empowerment (CAUSE), the worker group seeking to form the union, 3,276 ballots were cast in the election, with 25.3% of votes in favor of unionizing and 74.7% against. The results […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":426,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The World's Most Printed 3D Model, 3DBenchy, Is Now Public Domain","url":"https://hardware.slashdot.org/story/25/02/15/1949206/the-worlds-most-printed-3d-model-3dbenchy-is-now-public-domain?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739655240,"author":"EditorDavid","guid":190,"unread":true,"content":"Hackaday reports:\n\nGood news for everyone who cannot get enough from improbably shaped boats that get referred to as a bench: the current owner (NTI Group) of the copyright has announced that 3DBenchy has been released into the public domain. This comes not too long after Prusa's Printables website had begun to purge all derived models to adhere to the 'no derivatives' license. According to NTI, the removal of these derived models was not requested by NTI, but by a third-party report, unbeknownst to NTI or the original creator of the model. Recognizing its importance to the community, 3DBenchy can now be downloaded &amp; modified freely. \n\n\nNTI worked together with the original creator [Daniel Norée] and former Creative Tools CEO [Paulo Kiefe] to transition 3DBenchy and the associated website to the public domain\n\nMore details at Tom's Hardware and Fabbaloo.","contentLength":867,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Design, Manufacturing and Open-Loop Control of a Soft Pneumatic Arm: Bending Experiments","url":"https://hackernoon.com/design-manufacturing-and-open-loop-control-of-a-soft-pneumatic-arm-bending-experiments?source=rss","date":1739653203,"author":"EScholar: Electronic Academic Papers for Scholars","guid":478,"unread":true,"content":"<p>(1) Jorge Francisco Garcia-Samartın, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain (jorge.gsamartin@upm.es);</p><p>(2) Adrian Rieker, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain;</p><p>(3) Antonio Barrientos, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain.</p><p>3 PAUL: Design and Manufacturing </p><p>4 Data Acquisition and Open-Loop Control </p><p>The first experiment consisted of analysing the deflection of a segment versus swelling time. For this purpose, one of the bladders was inflated continuously, in intervals of 100 ms. For each time, PAUL end coord</p><p>\\\nwhere x0 and y0 denote initial position of PAUL end.</p><p>\\\nSince the weight of the subsequent modules influences the behaviour of the first segment, the experiment was repeated by placing first one and then two additional segments. The results are shown in Figure 18.</p><p>\\\nAs can be seen, PAUL is capable of bending up to 40◦ to its vertical axis and the addition of new segments does not cause any noticeable decrease in its bending capacity.</p><p>\\\nAlthough it remains far from the 80◦ of [28] or the 70◦ of [32], Pneunet segments and therefore more flexible, this is an acceptable bending capacity. Moreover, the fact that it does not substantially lose its bending capacity by adding segments makes it possible to concatenate bending movements and thus overcome obstacles that a rigid robot would not be able to overcome.</p><p>\\\nIn conjunction with this, a validation test was proposed whose purpose was to demonstrate PAUL’s ability to flex thanks to its deformable geometry. The aim was to point points in lateral planes. The results of this experiment are shown in Figure 19. The images, extracted from the video of Appendix A, show how the manipulator can adopt different shapes, is able to bend up to 40◦ and adapt, in case of obstacles, to a wide variety of geometries, which undoubtedly makes PAUL a fundamental ally in inspection and exploration operations in very cluttered environments.</p>","contentLength":2317,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple Intelligence could arrive on Vision Pro in April","url":"https://techcrunch.com/2025/02/15/apple-intelligence-could-arrive-on-vision-pro-in-april/","date":1739652968,"author":"Anthony Ha","guid":54,"unread":true,"content":"<p>Apple is planning to add Apple Intelligence to its Vision Pro headset in an update that could come as early as April, according to Bloomberg’s Mark Gurman. Just a couple weeks after Apple Intelligence was first announced in June 2024, Gurman reported that Apple was looking to bring its suite of AI tools to the […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":382,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"America's Office-Occupancy Rates Drop by Double Digits - and More in San Francisco","url":"https://it.slashdot.org/story/25/02/15/1716204/americas-office-occupancy-rates-drop-by-double-digits---and-more-in-san-francisco?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739651640,"author":"EditorDavid","guid":189,"unread":true,"content":"SFGate shares the latest data on America's office-occupancy rates:\n\nAccording to Placer.ai's January 2025 Office Index, office visits nationwide were 40.2% lower in January 2025 compared with pre-pandemic numbers from January 2019. \n\nBut San Francisco is dragging down the average, with a staggering 51.8% decline in office visits since January 2019 — the weakest recovery of any major metro. Kastle's 10-City Daily Analysis paints an equally grim picture. From Jan. 23, 2025, to Jan. 28, 2025, even on its busiest day (Tuesday), San Francisco's office occupancy rate was just 53.7%, significantly lower than Houston's (74.8%) and Chicago's (70.4%). And on Friday, Jan. 24, office attendance in [San Francisco] was at a meager 28.5%, the worst of any major metro tracked... \n\n\nMeanwhile, other cities are seeing much stronger rebounds. New York City is leading the return-to-office trend, with visits in January down just 19% from 2019 levels, while Miami saw a 23.5% decline, per Placer.ai data. \n\n\"Placer.ai uses cellphone location data to estimate foot traffic, while Kastle Systems measures badge swipes at office buildings with its security systems...\"","contentLength":1159,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Soft Robots and Smart Movement","url":"https://hackernoon.com/soft-robots-and-smart-movement?source=rss","date":1739650503,"author":"EScholar: Electronic Academic Papers for Scholars","guid":477,"unread":true,"content":"<p>(1) Jorge Francisco Garcia-Samartın, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain (jorge.gsamartin@upm.es);</p><p>(2) Adrian Rieker, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain;</p><p>(3) Antonio Barrientos, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain.</p><p>3 PAUL: Design and Manufacturing </p><p>4 Data Acquisition and Open-Loop Control </p><p>The size of the table to achieve acceptable kinematic modelling was set experimentally, as no previous references were available and previous works in the literature were very variable in terms of the number of data required. Furthermore, the possibility of an error occurring in the pneumatic system or the buffer of the vision acquisition system collapsing, together with the always present possibility of a leak in the segments, made it advisable to take data in small sessions and subsequently union of all of them. Since the data collection process was automated, this did not pose much of a problem.</p><p>\\\nAlthough the possibility that the ambient temperature was a factor that influenced the kinematics of the robot was considered during the dataset collection process, it was finally proven that small variations in temperature did not affect the behaviour.</p><p>\\\nTable 3 shows the datasets that were taken, the total time necessary to obtain them and the average time per point. It should be taken into account that not all captured positions were finally used, since, if the camera did not correctly detect the positions of the three beacon spheres, it could not calculate the orientation of the trihedral and therefore returned an error code. Of the 1200 samples collected, 5% had to be discarded, leaving 1146 finally usable. The average time per point, considering all the datasets collected, was 6.76 s, with a standard deviation of 0.63 s. The low variability between capture processes proves the effectiveness of the automated method designed.</p><p>\\\nOnce all the datasets were combined, the direct and inverse kinematic models presented here were validated. The validation of the direct model consisted of sending the robot a combination of inflation times and measuring the distance between the position reached, captured by the cameras, and that predicted by the table. Repeating the experiment for 40 points, the histogram of results presented in Figure 15 was observed. The average error is 4.27 mm, the median error 2.72 mm, and the standard deviation 1.99 mm.</p><p>\\\nThe high standard deviation and the shape of the histogram, tilted towards low values and with a very long tail, seem to indicate the existence of points where the model presents notable failures along with others with very good results. A future line of interest could be the detailed analysis of the workspace to locate where those regions of lower precision of the model are located and try to look for failures, perhaps leading to a greater density of points in the dataset.</p><p>\\\nIn the same way, the inverse kinematic model was tested. To do this, PAUL was given a reference position and orientation to achieve, the necessary times were calculated, using the procedures referred to in Equations (16), and (17) inflation was carried out. Subsequently, the position captured with the cameras was compared with the desired one.</p><p>\\\nAs expected, the existence of redundancies, in which equal position values are achieved with very different combinations of inflation times, introduces large uncertainties in the model, which the triangulation presented is not able to capture.</p><p>\\\nSpecifically, the inverse kinematic model has an average error of 10.78 mm, a median error of 9.22 mm and a standard deviation of 5.98 mm. While these errors may seem high, they are compared in Table 4 with other open-loop controllers presented in the literature. It can be clearly seen that they are in line with the results obtained and that they are even better than those obtained by smaller robots, where one would expect, due to the smaller working space, a higher accuracy (at least in data-driven models).</p><p>\\\nIt is worth highlighting, however, two experiments in which PAUL performed very satisfactorily, because the area of operation was restricted to a region where no redundancies were found to exist. They are available in the video of Appendix A.</p><p>\\\nIn the first of them, the robot was forced to reach a set of points located on the horizontal basis plane, also forcing the lower end of the last segment to be parallel to said</p><p>\\\nplane. In all of them, errors less than 7 mm were achieved. Figure 16 shows the results of said experiment. With the aim of facilitating the understanding of the experiment, the beacon was changed for a laser pointer that points to the desired points, on which targets with a radius of 5 mm have been marked, allowing the accuracy achieved to be checked.</p><p>\\\nIn the second experiment, shown in Figure 17, points on the lower horizontal plane were also taken as reference, but without imposing that the lower face of the robot should remain parallel to it. In this case, accuracies of 2 cm were achieved.</p><p>\\\nAlthough the inverse kinematic model therefore presents acceptable results, it must be commented that, in all these experiments, due to the geometry and material of the robot, at the moment in which PAUL reaches the desired position, it tends to acquire a movement damped oscillation. An attempt has been made to reduce it, despite everything, it is a very intrinsic phenomenon to the robot that is difficult to solve. A future line proposed, in this sense, is to try to rigidify the robot by introducing negative pressures that generate vacuum.</p>","contentLength":5938,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"This Week In Techdirt History: February 9th – 15th","url":"https://www.techdirt.com/2025/02/15/this-week-in-techdirt-history-february-9th-15th/","date":1739649600,"author":"Leigh Beadon","guid":310,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple Invites Its Users Into Major Years-Long Health Study","url":"https://apple.slashdot.org/story/25/02/15/0610248/apple-invites-its-users-into-major-years-long-health-study?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739648040,"author":"EditorDavid","guid":188,"unread":true,"content":"Can the iPhone, AirPods, or the Apple Watch play a role in improving health? Apple says they want to find out. \n\"In medical research, discoveries are often limited by the number of participants who can be recruited, the amount of data that can be captured, and the duration of a given study,\" the company said in a blog post this week. \"But Apple devices expand the possibilities...\"\nThis new longitudinal, virtual study aims to understand how data from technology — including Apple and third-party devices — can be used to predict, detect, monitor, and manage changes in participants' health. Additionally, researchers will explore connections across different areas of health. \nCNBC reports:\n\n\nThe new study will likely influence future product development. Apple CEO Tim Cook previously said he believes health features will be the company's \"most important contribution to mankind....\" \n\nThe Apple Health Study will be available through the company's Research app, and participation is voluntary. Users will select each data type they are willing to share with researchers, and they can stop sharing or completely discontinue their participation at any time. Apple has no access to participants' identifiable information, the company said... The project will last at least five years and may expand beyond that. \nA Harvard Medical School professor and cardiologist — also a principal investigator on the Apple Health Study — says \"We've only just begun to scratch the surface of how technology can improve our understanding of human health.\"","contentLength":1553,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Proactive IT Career Growth: Take Control of Your Professional Journey","url":"https://hackernoon.com/proactive-it-career-growth-take-control-of-your-professional-journey?source=rss","date":1739646022,"author":"Ekaterina","guid":476,"unread":true,"content":"<p>There are a lot of good articles about possible career tracks that you can pursue in IT, however, I haven’t seen many that might be used as actual guidance to move up the career ladder.</p><p>\\\nCurrently, I am working in a company that has very clear requirements for the engineers’ promotion and what can be used as sufficient evidence of fulfillment of those requirements. A combination of these two factors gave me the idea that additional information on this topic might help other engineers who are employed by companies that do not have it to build a strategy that will allow them to get to the next level.</p><p>\\\nIn almost any more or less mature IT company, a common career track for a software engineer is linear and looks almost the same:</p><p>Associate Software Engineer is optional and may or may not be presented in the common IT department structure for a very simple reason: it’s net-negative for the first 12 months as it requires a lot of hand-holding so not all companies have resources and time to allow such positions in their structure.</p><p>\\\nThe further career track will depend on your inclinations, what you enjoy doing, and whether you are ready for the shift in the way you’re working.</p><p>There’s nothing wrong with staying a senior software engineer if you like to allocate the majority of your time to coding. However, if you feel the need to empower others and lead that’s the right moment to weigh all expectations for each role, your strengths, the things that drive you, and pick the most suitable track for yourself.</p><p>\\\nDespite the visual simplicity of the tracks above, it’s not clear how to get closer to the right end. The following insights will apply to the companies that have:</p><ul><li><p>a hierarchical structure where each employer has a line manager</p></li><li><p>a genuine interest in employee development</p><p>\\n Why is the above-mentioned is important?==The answer is quite simple: from day one you have an ally - your line manager==.</p></li></ul><p>\\\nEach line manager’s efficiency is based on the output of each person reporting to them: the faster you grow - the bigger your output - the better the line manager’s efficiency. Given all this, sooner or later, after you have joined your company, your line manager will approach you with the question: “Where do you see yourself after a certain time?” If it is not happening and you have regular one-to-ones, feel free to add this as a topic for discussion in the agenda.</p><p>\\\nVoicing your intentions and setting a goal is just the first step of your way. The next step is to gather the list of requirements for the higher role and compile a list of achievements that can serve as evidence of your qualifications that you can use as a guide that you should follow to get from point A to point B. In companies with transparent promotion processes, this should be already in place.</p><p>\\\nIf this is not the case, you and your manager could compose one. Remember that this process is beneficial for both sides: you are getting an agreement that after certain achievements, you will be praised with the promotion and your line manager can get increased output from the team, so it’s a win-win case.</p><p>\\\nDifferent companies may have different requirements for certain positions, and I won’t claim that the ones below are universal and will suit everyone. The main purpose is to give you an idea it might look like if you need one that can be further tailored to your needs.</p><p>\\n Guidelines for evidence can be used as a roadmap that brings you to the desired destination. The next steps for the common track might be</p><ul><li>Check the team’s roadmap for suitable projects or change requests that might fit the purpose of the evidence.</li></ul><ul><li>Voice up your intentions to the line manager so they can assist with the suitable project allocation and provide information about its priority, business value, and when it can be picked up for development.</li></ul><ul><li>Spot any potential areas for improvement in code, observability, extensibility, and security perspectives and raise them as ownership tickets.</li></ul><ul><li><p>Familiarize yourself with the current recruitment process in your company and ask for shadowing during recruitment sessions. Ask to switch roles where someone more senior will shadow you and ask for feedback. \\n </p><p>This is a short list of the roles that will be covered from requirements/guidelines for evidence perspectives:</p></li><li><p>Junior Software Engineer Requirements</p></li><li><p>Software Engineer Requirements</p></li><li><p>Senior Software Engineer Requirements</p></li><li><p>Lead Engineer Requirements</p></li><li><p>Senior Engineering Lead Requirements</p></li></ul><h4><strong>==Junior Software Engineer Requirements==</strong></h4><p>|  |  |  |\n|----|----|----|\n|  | Delivers tasks \\n · Clear requirements are needed (business and system) \\n · Designs/implements limited-scope technical solutions \\n · Limited guidance is required | 1. List of tasks completed \\n o Tasks should be complex enough to mention them \\n o Deadlines are met \\n o No major quality issues \\n o Tasks were completed with no handholding \\n 2. Input from the line manager confirming that all the requirements are met. |\n|  | Applies best practices \\n · Learns and constantly applies best practices \\n · Proficient with various dev tools \\n · Investigates and fixes complicated problems/bugs | <strong>Feedback from the line manager and peers confirming that all the requirements are met.</strong> |</p><p>\\\n<strong>==Software Engineer Requirements==</strong></p><p>|  |  |  |\n|----|----|----|\n|  | Delivers change requests (features) \\n · Takes business requirements as input \\n · Breaks work into tasks with a sufficient level of detail on the solution (what needs to be done and when it’s done) and the implementation (how it should be done) \\n · Provides accurate estimates on a task/user story level \\n · Pairs with other engineers to deliver faster | List of change requests delivered, conforming to the following requirements: \\n 1. The change request has been fully delivered and the deadline was met. \\n 2. The discovery part was completed by the employee (tickets, estimates). \\n 3. The change request is complex enough from a technical perspective (more than 2 man-weeks for 1 engineer to implement it). \\n 4. The change request provides a meaningful impact on the business. \\n 5. The change request is signed off by the business and is running in production. \\n 6. The employee has demonstrated a sufficient level of autonomy and quality (based on the feedback from the tech lead and the engineering manager). |\n|  | Designs services \\n · Designs and implements smaller services while taking into account all of the non-functional aspects (extensibility, security, observability, etc) \\n · Writes high-quality code with full adoption of engineering practices and methodologies \\n · Participates in code reviews to enforce best practices \\n · Fixes the root causes behind bugs and problems encountered | At least two services designed conforming to the following requirements: \\n 1. It can be a new service or a complete redesign of the existing service. \\n 2. It can be a standalone service, a library, or a component consumed by other services. \\n 3. The service shouldn’t be trivial from a design perspective. \\n 4. The engineer should have followed the formal design process: \\n · Obtain business and system requirements \\n · Identify the bounded context \\n · Identify non-functional requirements \\n · Break down context into services \\n · Get feedback on the solution \\n · Implement it \\n 5. Service is implemented and is running in production. |</p><p>\\\n<strong>==Senior Software Engineer==</strong></p><p>|  |  |  |\n|----|----|----|\n|  | Delivers project phases (epics) \\n · Takes requirements and high-level system design as input \\n · Creates system design for the service or the component, decides on the technologies and engineering practices to be used \\n · Breaks work into tasks or user stories with a sufficient level of detail on the solution (what needs to be done and when it’s done) and the implementation (how it should be done) \\n · Provides accurate estimates on task/user story level \\n · Leads a small team to deliver the scope \\n · Unblocks their team, resolves issues, and removes impediments | List of project phases/epics delivered, conforming to the following requirements: \\n 1. The epic/project phase has been fully delivered and the deadline was met. \\n 2. The discovery part was completed by the employee (tickets, estimates). \\n 3. The epic/project phase is complex enough from a technical perspective (requires at least 2 engineers for &gt;= 2 weeks). \\n 4. The epic/project phase provides a meaningful impact on the business. \\n 5. The functionality is signed off by the business and is running in production. \\n 6. The employee has demonstrated a sufficient level of autonomy and quality (based on the feedback from the tech lead and engineering manager). \\n 7. The engineer participated in the implementation as a technical lead. |\n|  | Designs subsystems \\n · It is the same as for a Software Engineer but focuses on more complex services or subsystems \\n · Proficient in the cloud and distributed systems design and implementation | At least 3 services designed conforming to the following requirements: \\n 1. It can be a new service or a complete redesign of the existing service. \\n 2. It can be a standalone service, a library, or a component consumed by other services. \\n 3. The service shouldn’t be trivial from a design perspective. \\n 4. The engineer should have followed the formal design process: \\n a. Obtain business and system requirements \\n b. Identify bounded context \\n c. Identify non-functional requirements \\n d. Break down context into services \\n e. Get feedback on the solution \\n f. Implement it \\n 5. Service is implemented and is running in production. |\n|  | Proposes changes \\n · Challenges the status quo and the assumptions made \\n · Find ways to improve the platform, processes, working environment, and the tech team in general | At least three significant changes were proposed, which can be any of the following: \\n 1. Functionality: proposed a change request that was prioritized and implemented (change request should be substantial enough to be considered as a change, not a cosmetic change). \\n 2. People: interviewed an engineer who was hired and passed probation (junior software engineer or higher, considered as a change to the team). \\n 3. Ownership: proposed an ownership project (included in the ownership roadmap, approved by CTO). |</p><p>\\\n\\\n<strong>==Lead Engineer Requirements==</strong></p><p>|  |  |  |\n|----|----|----|\n|  | Tech lead for projects (project proposals) \\n · Takes business requirements as input \\n · Find the most effective solution for the business problem (research alternatives, validate solutions using no-code/low-code approaches) \\n · Creates system design for the new service or subsystem, decides on the technologies and engineering practices to be used \\n · Breaks work into epics with a sufficient level of detail on the solution (what needs to be done and when it’s done) and the implementation (how it should be done) \\n · Provides accurate estimates on the project level, commits to dates \\n · Acts as a tech lead for the entire project \\n · Unblocks their team, resolves issues, and removes impediments \\n · Manages technology, implementation, and operational risks | List of projects delivered, conforming to the following requirements: \\n 1. The solution for the problem was proposed by the employee and it is considered to be effective. I.e. multiple alternatives were evaluated, and the best alternative was chosen based on the low-code/no-code validation. \\n 2. The discovery part was completed by the employee (tickets, estimates). \\n 3. The solution was architected by the employee. \\n 4. The project needs to be a “feature” project initiated through a project proposal. \\n 5. The engineer participated in the implementation as a technical lead (see requirements column for more details). |\n|  | Drives technical changes (squad) \\n · Proposes and implements initiatives to improve system quality and reduce technical debt \\n · Proposes and implements changes to improve developer experience and productivity \\n · Advocates and enforces clean code and clean architecture | List of major changes introduced (usually at least four), conforming to the following requirements: \\n 1. The change provides meaningful improvement to system quality (e.g. platform improvements), developer experience, or developer productivity. The change affects the entire squad. \\n 2. The engineer doesn’t have to be the one who proposed the change. The engineer should be the primary driving force behind the change (e.g. designed, acted as a tech lead, participated in the implementation). The change can be delivered by an engineer or as a team effort. \\n 3. The change should be fully implemented and used by the squad/platform (the change should be “sticky” and provide enough value to keep it). \\n 4. The change should be significant enough to mention. |\n|  | Mentor \\n · Mentors and supports less experienced engineers \\n · Conducts technical interviews effectively \\n · Acts as a “magnet” for great engineers during hiring (be a decisive factor where we are in competition for good talent vs. another company) | Possible evidence: \\n 1. Engineers interviewed, who were hired and passed probation. \\n 2. Feedback from upskilled engineers. \\n 3. Training sessions are organized/delivered for the entire tech team (e.g. Tech Sync, Engineering Dojo). \\n 4. When leading a working group a list of changes proposed/implemented in the scope of the working group can be used as evidence. |</p><p>\\\n<strong>==Senior Engineering Lead==</strong></p><p>|  |  |  |\n|----|----|----|\n|  | Tech Lead for complex projects (project proposals) \\n Same as Lead Engineer, but focuses on problems that are complex from technical, organizational, or business perspectives \\n · The project requires coordination across multiple squads \\n · The project involves 3rd party technology provider or stakeholder (e.g. partnership) \\n · a new product build while the product is in the discovery mode \\n · high priority/urgency project with fixed deadlines and many unknown | List of projects delivered, conforming to the following requirements: \\n 1. The project is considered to be complex (see examples on the left). \\n 2. The project has been fully delivered (all deliverables + DoD) and the deadline was met. \\n 3. The solution for the problem was proposed by the employee and it is considered to be effective (i.e. multiple alternatives were evaluated, and the best alternative was selected based on the low-code/no-code validation). \\n 4. The discovery part was completed by the employee (system requirements, tickets, estimates). \\n 5. The solution was architected by the employee. The project has a high complexity from a system design perspective. \\n 6. An engineer participated in the implementation as a technical lead. |\n|  | Drives technical changes (tech) \\n · Same as E5 but on the tech level \\n · System owner for at least one non-functional aspect (e.g. security, observability, etc). | List of major changes introduced (usually at least 4), conforming to the following requirements: \\n 1. The change provides meaningful improvement to system quality (e.g. platform improvements), developer experience, or developer productivity. The change affects multiple squads (e.g. technology adoption). \\n 2. The engineer doesn’t have to be the one who proposed the change. The engineer should be the primary driving force behind the change (e.g. designed, acted as a tech lead, participated in the implementation). The change itself can be delivered by an engineer or as a team effort. \\n 3. The change should be fully implemented and used by multiple squads (changes should be “sticky” and provide enough value to keep it). \\n 4. The change should be significant enough to mention. It should be tracked on the “upcoming projects” page as an ownership project (ownership in this context means changes to the platform, tooling, processes, etc, not just platform-related changes). \\n 5. At least 2 changes should be related to the non-functional aspect owned by the individual. |\n|  | Recognized expert \\n · Recognized expert within a given area of expertise on a company level, acts as a technical point of contact in tech within their area of expertise \\n · Monitors trends/technologies within the area of expertise and communicates updates and findings \\n · Actively and regularly shares expertise with other engineers (workshops, tech talks, training) \\n · Facilitates collaboration to find solutions for complex problems (working groups, etc) \\n · Conducts technical interviews effectively \\n · Mentors and supports less experienced engineers, guide their career from a professional development perspective \\n · Acts as a “magnet” for great engineers during hiring (be a decisive factor where we are in competition for good talent vs. another company) | Possible evidence: \\n 1. Interviewed engineers, who were hired and passed probation. \\n 2. Feedback from upskilled engineers. \\n 3. Training sessions are organized/delivered for the entire tech team (e.g. Tech Sync, Engineering Dojo). \\n 4. Leading a working group, a list of changes proposed/implemented in the scope of the working group can be used as evidence. |</p><p>|  |  |  |\n|----|----|----|\n|  | Delivers squad roadmap \\n · Leads a squad of 3-6 engineers \\n · Acts as a project manager for multiple concurrent initiatives \\n · Able to deliver results having only business requirements as input (able to create and sign off system requirements) \\n · Focuses on business impact, driven by business value \\n · Communicates commitments, status, and risks to business stakeholders \\n · Ensures that all squad members have all the information they need \\n · Communicates to 3rd parties within the scope of initiatives/ownership \\n · Finds the right balance between feature delivery and system quality \\n · All requirements for Senior Software Engineer | New projects delivered by the squad conforming to the following requirements: \\n 1. Project initiated through a project proposal. \\n 2. The project has met its impact metrics, and the public commitment was met. \\n 3. Projects reported in the previous promotion cycle can’t be included in the list. |\n|  | Drives managerial changes (squad) \\n · Measures and continuously improves squad performance \\n · Identifies and establishes best practices within the squad with a focus on productivity \\n · Maintains high quality of delivery \\n · Ensures transparency on progress, risks, results | 1. Squad productivity (performance) metric values. \\n 2. Major changes (at least 4) introduced, conforming to the following requirements: \\n a. It solves a problem related to the owned squad or tribe, the problem needs to be included in the TOP 5 problems and agreed upon with the line manager. \\n b. The change should be fully implemented and used by the squad (change should be “sticky” and provide enough value to keep it). \\n c. The change should provide meaningful improvement to productivity, engagement, or quality of delivery. \\n d. The manager doesn’t have to be the one who proposed the change. The EM should be the primary driving force behind the change. The change can be delivered by an engineer or as a team effort. |\n|  | Line manager (&gt;=3 direct reports) \\n · Manages 3-6 direct reports \\n · Coaches and supports engineers \\n · Supports and guides career progressions \\n · Reconciles differences of opinion and helps manage and resolve conflicts \\n · Encourages a positive team culture and collaboration | 1. Squad engagement metric values. \\n 2. List of engineers, who were hired and passed probation (can be skipped if we are not hiring, EM should be a hiring manager). |</p><p>\\\n</p><p>|  |  |  |\n|----|----|----|\n|  | Delivers roadmap for multiple squads \\n · Ensures delivery across 2-3 squads \\n · Fulfils Engineering Manager role in one of the squads \\n · Owns partnerships with 3rd parties \\n · All requirements from the Engineering Manager | New projects delivered by the squads conforming to the following requirements: \\n 1. Project initiated through a project proposal (not a BAU activity). \\n 2. The project has met its impact metrics and the public commitment was met. \\n 3. Project results were presented as a Tech Feature session. \\n 4. Projects reported in the previous promotion cycle can’t be included in the list. \\n 5. At least 2 projects should be recognized as key projects on a company level (e.g. a new product, etc, can be confirmed with CTO). |\n|  | Drives managerial changes (multiple squads/tech) \\n · All requirements from Engineering but across multiple squads \\n · System owner for at least one process (e.g. support, etc) | 1. Squads’ productivity (performance) metric values across multiple squads. \\n 2. Major changes (at least 6) introduced, conforming to the following requirements: \\n a. It solves a problem related to the squads or tribe, a problem needs to be included in the TOP 5 problems and agreed upon with the line manager. \\n b. The change should be fully implemented and used by the squads (change should be “sticky” and provide enough value to keep it). \\n c. The change should provide meaningful improvement to productivity, engagement, or quality of delivery. \\n d. The manager doesn’t have to be the one who proposed the change. The Engineering Director should be the primary driving force behind the change. The change can be delivered by an engineer or as a team effort. \\n e. At least 2 changes should be related to the process owned by the director. |\n|  | Line manager (&gt;=10 reports, including indirect reports) \\n · All requirements for Engineering Manager \\n · Coaches and supports engineers \\n · Supports and guides career progressions \\n · Manages churn, reduces “regrettable churn” | 1. Squads’ engagement metric values across multiple squads. \\n 2. List of engineers, who were hired and passed probation (can be skipped if we are not hiring). \\n 3. List of engineers promoted (can be skipped if there is no business need for promotions). |</p>","contentLength":22065,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How a Soft Robot Arm Moves Using Air, Not Motors","url":"https://hackernoon.com/how-a-soft-robot-arm-moves-using-air-not-motors?source=rss","date":1739646019,"author":"EScholar: Electronic Academic Papers for Scholars","guid":475,"unread":true,"content":"<p>(1) Jorge Francisco Garcia-Samartın, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain (jorge.gsamartin@upm.es);</p><p>(2) Adrian Rieker, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain;</p><p>(3) Antonio Barrientos, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid — Consejo Superior de Investigaciones Cientıficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain.</p><p>3 PAUL: Design and Manufacturing</p><p>4 Data Acquisition and Open-Loop Control</p><p>\\\nAlthough the layout of the pneumatic bench allows working with up to 4 segments, it was thought that using 3 would allow the different problems linked to redundancy to be tackled without increasing the weight of the robot too much or requiring the tubes –which pass through the interior of the segments – to have an excessive amount of space.</p><p>\\\nIt is true that the tubes of the other three could pass through the first module, nevertheless, it was thought that the stiffness they would introduce by being so compressed could make it difficult to bend the initial segment. Since it is also the segment that has to exert the most force, as it is the one that supports the weight of the other segments, the risk of punctures could be increased.</p><p>\\\nTherefore, a robot consisting of three identical modules was assembled, standing at a total height of 390 mm (with each segment measuring 100 mm, intersegment connections 20 mm each, and the vision trihedron rod 30 mm). Under these configurations, the estimated weight of PAUL’s arm is around 600 g. The structure protecting the manipulator is a cube with a side of 500 mm. Pressure of the pneumatic line was established in 1.2 bar.</p><p>\\\nExamples of PAUL reaching different positions are depicted in Figure 13.</p><p>The analysis of the workspace has been carried out experimentally, based on the data taken to generate the dataset. Figure 14 shows the workspace of a segment.</p><p>\\\nAs can be seen, this is a surface, as the segment has two degrees of freedom if the condition that at least one valve should remain deflated is imposed. The surface can be considered as the union of three surfaces intersecting at the central point, which corresponds to the configuration of all deflated bladders. The three surfaces are roughly spherical in shape. If the PCC model were completely valid for the robot, these would be perfect spheres, as the ends of a set of equal-length arcs of circumference with a common origin engrench a circle. Since this is not exactly the case, the generated surfaces only resemble the sphericity predicted by the constant curvature model.</p><p>\\\nThe addition of a second segment already generates a 4-D workspace that is difficult to represent. The generation of this is a consequence of the fact that, from each point on the surface of the workspace of a segment, another similar surface is generated. The</p><p>\\\n\\\nunion of all of these surfaces, which arise from the points on the surface of the first segment, results in the two-segment workspace. This is a volume in which, in addition, each point can be reached from two different orientations, thus leaving latent the four degrees of freedom that PAUL would have with only two modules.</p>","contentLength":3400,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"xAI’s “Colossus” supercomputer raises health questions in Memphis","url":"https://techcrunch.com/2025/02/15/xais-colossus-supercomputer-raises-health-questions-in-memphis/","date":1739645584,"author":"Connie Loizos","guid":53,"unread":true,"content":"<p>Elon Musk’s AI startup xAI plans to continue using 15 gas turbines to power its “Colossus” supercomputer in Memphis, Tennessee, according to an operating permit with the Shelby County Health Department for non-stop turbine use from June 2025 to June 2030. Why does it matter? The Commercial Appeal, a news outlet that obtained the documents, […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":416,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Elevate Your Night Shift Productivity Levels: 8 Strategies for Thriving - Not Just Surviving","url":"https://hackernoon.com/elevate-your-night-shift-productivity-levels-8-strategies-for-thriving-not-just-surviving?source=rss","date":1739645102,"author":"Beth Rush","guid":474,"unread":true,"content":"<p>Almost every worker will tell you how tough it is to keep productivity levels high at work. However, the struggle is doubled when you work nights. Thankfully, there are a few techniques that can help you survive and thrive in your field, even when working those late hours.</p><h2>The Challenges of Long Hours in the Evening</h2><p>The regular nine-to-five shift is the norm across many industries, especially in the corporate world. However, there are a few outliers, such as the hospitality and manufacturing sectors. Health care, security, and firefighting departments also need hands on deck at all times in emergencies, which requires plenty of alertness.</p><p>\\\nThere are several benefits, like less competition between workers and extra pay. However, it takes some work to get used to it as you have to adjust your body clock. The night shift can <a href=\"https://www.theguardian.com/us-news/2022/nov/18/us-workers-night-shift-takes-toll\">spark plenty of employee turnover</a> since most people can’t sacrifice their daytime hours.</p><p>\\\nThose who decide to take on the night shift find themselves at a crossroads. The hours may seem much longer despite being the same eight hours that workers typically work. It can be hard to keep energy levels up or stay awake.</p><h2><strong>Most Effective Night Shift Tips</strong></h2><p>Dealing with a night shift schedule requires several adjustments, including your sleep schedule, caffeine intake, physical activities and so much more. Here are tried-and-true strategies to help you out.</p><h3><strong>Have a Routine Before the Shift</strong></h3><p>Good sleep should be the highest priority in your pre-work routine. It’s much easier to stay alert and concentrate on your tasks on the job when you’ve had enough shut-eye. Unfortunately, <a href=\"https://www.trustaff.com/blog/tips-for-surviving-night-shift\">over one-third of Americans</a> sleep less than seven hours. Heading to bed in the middle of the day can also seem foreign to your body.</p><p>\\\nThus, the first step is to have a consistent schedule. For example, people in health care may have to start their eight hours of work at 7 p.m. or so. Others might deal with extended hours, bringing the total closer to 12.</p><p>\\\nThus, the ideal night-shift nurse sleep schedule will start at 9 a.m. if you want to achieve eight hours and an extra two hours to prep and commute. The leeway can also be used as additional time to sleep ahead of those longer work times.</p><p>\\\nIf it’s your first time heading into the shift, give your body a week to gradually acclimate to the new sleep schedule. Complete and total sleep deprivation can be too exhausting for your body.</p><p>\\\nBe mindful of your sleeping quarters during the adjustment period. Blackout curtains are ideal for completely darkening the room and tricking your body into thinking it’s nighttime. You should put your phone in silent mode to avoid calls that may disrupt your sleep.</p><p>\\\nYou can also experiment with other sleeping aids. For example, some people find aromatherapy relaxing, easing them into slumber during the daytime. White noise machines can also provide the best background sound as you fall asleep.</p><p>\\\nAfter a long sleep, you should feel recharged. Awaken your senses by preparing a well-balanced dinner before your shift, and incorporate fruits and vegetables into your meals to get your nutrition fix. Afterward, wear your clothing of choice and head out to conquer the night shift.</p><h3>Design a Post-Work Ritual</h3><p>Now that you know how to prepare for a 12-hour night shift, it’s time to move on to winding down. Ideally, the routine gives you something to look forward to, such as having a shower to feel clean. You can also move your skincare routine to this time.</p><p>\\\nTry to give yourself a bit of leisure after work. Some use this time to watch shows, listen to music, or play video games. Social media is also a good outlet for entertainment. Just remember to use it in moderation to avoid doomscrolling.</p><h3><strong>Exercise Caution Around Caffeine</strong></h3><p>Caffeine is a helpful tool to keep your energy levels as high as possible. A cup of your favorite coffee or tea just before work can help you energize throughout the day. However, it’s best to avoid the temptation of getting a second or third drink in the middle of the shift. Too much caffeine will result in quite a crash afterward.</p><p>\\\nIt’s also best to schedule your intake. Prolonged caffeine ingestion <a href=\"https://academic.oup.com/sleepadvances/article/4/1/zpad014/7040153\">can disrupt the circadian rhythm</a>, disrupting your sleep routine. Meanwhile, short exposure boosts sleep fragmentation, increasing your awakenings while sleeping and ruining the quality of your shut-eye. Once a week is a good rule of thumb to follow.</p><p>One thing most people forget to realize when moving into the night shift is that everyone else still maintains their day routines. Your family and friends will likely have lunch, run errands, and do their own jobs when you’re asleep. When you’re awake and working, they’ll likely be sleeping.</p><p>\\\nHuman interaction is essential to enduring the night shift. Try to find overlaps and make time to catch up. You can invite a friend over for dinner before you head to work or chat on the phone while you’re home.</p><p>\\\nYou can also turn to your fellow employees going through the night shift. Camaraderie helps to overcome a challenge. Get to know these people, and build strong working relationships. The bond can even help you increase energy levels and boost productivity.</p><h3><strong>Maintain Physical Activity</strong></h3><p>Night shift workers have limited time and energy. However, it’s still important to maintain some form of physical movement. Exercise <a href=\"https://www.nature.com/articles/s42003-024-05962-8\">may lessen the likelihood of disorders</a> like depression, cardiovascular conditions, and metabolic diseases in chronic shift workers.</p><p>\\\nTry to find breaks to just take a walk. Aside from getting fresh air, you can move your muscles and wake yourself up. If you’re already a veteran for the evening hours, you may even consider heading to the gym right after work.</p><h3><strong>Move Your Responsibilities</strong></h3><p>Keeping productivity levels high throughout the shift can take time and practice. However, one hack you can try is intentionally scheduling the most important responsibilities at the beginning of your shift. After all, you will likely have more energy at the start.</p><p>\\\nOnce you’ve completed the bulk of the most important work, the next goal is to stretch out your energy throughout the rest of the hours and stay awake. You can try to space out your duties and give yourself breaks when you’re faltering.</p><h3><strong>Keep the Same Schedule on Off Days</strong></h3><p>It's important to maintain your current schedule to get your body used to the night shift. This solution is best for working full time, allowing you to fully adjust your body clock and move your most productive times to match your work schedule.</p><p>\\\nIf you have obligations during your off days that need to be done during the daytime, try to reschedule. You can also proceed and readjust afterward with some intentionally planned naps. Minimize deviating and the changes in your productivity should follow suit.</p><h3><strong>Manage Your Mindset and Stress</strong></h3><p>Night shift workers can experience stress throughout the adjustment period. Unfortunately, this pressure <a href=\"https://www.health.harvard.edu/topics/stress\">can alter the immune system</a> and make you more vulnerable to illnesses. It can also build a negative mindset toward your schedule.</p><p>\\\nMake sure to have stress management techniques under your belt. Meditation is a good way to come to terms with your thoughts, while breathing exercises can assist you in calming down systemic turmoil. Activities like journaling and yoga can also improve your mood.</p><h2><strong>Thrive With an Unconventional Schedule</strong></h2><p>Having a night shift schedule is a challenge worth conquering. You get to be present for the people who need aid and assistance, and it brings fulfillment to your long-term career development. You just have to adapt to the circumstances to reap the rewards.</p>","contentLength":7590,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Perplexity launches its own freemium ‘deep research’ product","url":"https://techcrunch.com/2025/02/15/perplexity-launches-its-own-freemium-deep-research-product/","date":1739644754,"author":"Anthony Ha","guid":52,"unread":true,"content":"<p>Perplexity has become the latest AI company to release an in-depth research tool, with a new feature announced Friday. Google unveiled a similar feature for its Gemini AI platform in December. Then OpenAI launched its own research agent earlier this month. All three companies even have given the feature the same name: Deep Research. The […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":407,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bored With Chess? Magnus Carlsen Wants to Remake the Game","url":"https://games.slashdot.org/story/25/02/15/053254/bored-with-chess-magnus-carlsen-wants-to-remake-the-game?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739644440,"author":"EditorDavid","guid":187,"unread":true,"content":"\"Magnus Carlsen, the world's top chess player, is bored of chess,\" the Washington Post wrote Friday:\n\nCarlsen has spent much of the past year appearing to dismiss the game he has mastered: It was no longer exciting to play, he told a podcast in March. In December, he withdrew from defending a world championship because he was penalized for wearing jeans to the tournament. \nHow would the world's best player spice up the game? Change the rules, and add a touch of reality TV. \n\nTen of the world's top players gathered in a German villa on the Baltic coast this week to play in the first tournament of a new chess circuit, the Freestyle Chess Grand Slam Tour, that Carlsen co-founded. The twist: The tour randomizes the starting positions of the chess board's most important pieces, so each game begins with the queen, rooks and knights in a jumble. [It's sometimes called \"Chess960\" or Fischer random chess — with both players starting with the same arrangement of pieces.] Players have to adapt on the fly. Carlsen is backed by a cadre of investors who see a chance to dramatize chess with the theatrics of a television show. Players wear heart-rate monitors and give confession-booth interviews mid-match where they strategize and fret to the audience. Some purists are skeptical. So is the International Chess Federation, which sent a barrage of legal threats to Freestyle Chess before it launched this week's event. \nAt stake is a lucrative global market of hundreds of millions of chess players that has only continued to grow since the coronavirus pandemic launched a startling chess renaissance — and, perhaps, the authority to decide if and how a centuries-old game should evolve... The format is an antidote to the classical game, where patterns and strategies have been so rigorously studied that it's hard to innovate, Carlsen said. \"It's still possible to get a [competitive] game, but you have to sort of dig deeper and deeper,\" Carlsen said. \"I just find that there's too little scope for creativity.\" \n\nThe article also includes this quote from American grand master Hikaru Nakamura who runs a chess YouTube channel with 2.7 million subscribers). \"An integral part of regular chess is that when you play, you spend hours preparing your opening strategy before the game. But with Fischer Random ... it's a little bit looser and more enjoyable.\" And German entrepreneur Jan Henric Buettner (one of the investors) says they hope to bring the drama of Formula One racecars. (\"Cameras mounted at table level peer up at each player during games,\" the article notes at one point.) \n\nThe first Freestyle Chess Grand Slam Tour (with a $750,000 prize pool) concluded Friday, according to the article, but \"Carlsen did not play in it,\" the Post points out. \"He was upset in the semifinals by German grand master Vincent Keymer.\" Carlsen's reaction? \"I definitely find Freestyle harder.\" \n\nBut Chess.com reports that Carlsen will be back to playing regular chess very soon:\n\nGlobal esports powerhouse Team Liquid has announced the signings of not just one, but two superstars of chess. Five-time World Champion and world number-one Magnus Carlsen and the 2018 challenger, world number-two Fabiano Caruana will represent the club ahead of the 2025 Esports World Cup (EWC)... Carlsen and Caruana, fresh from competing in the Weissenhaus Freestyle Chess Grand Slam, will first represent Team Liquid in the $150,000 Chessable Masters, which begins on February 16 and serves as the first of two qualifying events in the 2025 Champions Chess Tour. The top-12 players from the tour qualify for the EWC. \n\nIn an announcement video Carlsen reportedly trolls the FIDE, according to Indian Express. \"The announcement video sees Carlsen wear a Team Liquid jersey along with a jacket and jeans. He then asks: 'Do I have to change?' To this, someone responds: 'Don't worry, we're pretty chill in esports. Welcome to Team Liquid.'\"","contentLength":3925,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI teases a ‘simplified’ GPT-5 model","url":"https://techcrunch.com/2025/02/15/openai-teases-a-simplified-gpt-5-model/","date":1739642700,"author":"Cody Corrall","guid":51,"unread":true,"content":"<p>Welcome back to Week in Review. This week we’re looking at OpenAI canceling the release of o3; TikTok returning to U.S. app stores nearly a month after it was removed; more complications in Elon Musk’s bid to buy OpenAI for $97.4 billion; and more! Let’s do it. OpenAI effectively canceled the release of o3, which […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":389,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Scale AI Infrastructure With Kubernetes and Docker","url":"https://hackernoon.com/how-to-scale-ai-infrastructure-with-kubernetes-and-docker?source=rss","date":1739642406,"author":"Natapong Sornprom","guid":473,"unread":true,"content":"<p>Firms increasingly make use of artificial intelligence (AI) infrastructures to host and manage autonomous workloads. Consequently,<a href=\"https://www.cio.com/article/3577669/as-ai-scales-infrastructure-challenges-emerge.html\"></a> as well as resilient infrastructures that will be able to meet heterogeneous application or cloud requirements. Organizations use<a href=\"https://hackernoon.com/an-intro-to-kubernetes-for-docker-developers\"></a> and<a href=\"https://hackernoon.com/optimizing-docker-images-is-more-than-just-a-one-and-done-thing\"></a> to meet such needs because firms realize that both are highly effective use cases that deliver scalable AI infrastructures.</p><p>\\\nDeploying AI infrastructure typically provides adequate computation power to execute and process large datasets. These demands can translate into the need for scalable methods that enable AI models to run on large workloads without hurting performance.</p><p>, nonetheless, are also resource-intensive, normally demanding both high computing capacity and the ability to process high levels of data. As more advanced AI applications and a larger scale become required, scalability becomes more critical. Scalability ensures that AI systems can handle increasing workloads without any loss of performance.</p><p>The growing amount of data is a concern for AI systems in many facets. Most AI models, especially those based on deep learning, heavily depend on large amounts of data during training and inference. However, without adequate scalable infrastructure, processing and interpreting such<a href=\"https://www.mckinsey.com/west-coast/~/media/mckinsey/featured%20insights/artificial%20intelligence/notes%20from%20the%20ai%20frontier%20applications%20and%20value%20of%20deep%20learning/notes-from-the-ai-frontier-insights-from-hundreds-of-use-cases-discussion-paper.pdf\"></a>.</p><p>Scalable AI hardware supports reliable and stable performance despite drastically overwhelming computational loads. With Kubernetes, horizontal scaling of AI jobs is a breeze, and the dynamic resizing of replica numbers can be done as a function of necessity. In contrast, Docker containers support lean, isolated environments for running AI models where resource conflict is not a performance bottleneck.</p><h3><strong>Effective Resource Management</strong></h3><p>Efficient use of resources is the key to cost-effective and sustainable AI deployment. Kubernetes' resource requests and limits allow for fine-grained CPU and memory resource management by avoiding underprovisioning and overprovisioning. Docker's resource management fills the gap by isolating container resources.</p><h2><strong>Scaling AI Infrastructure With Kubernetes and Docker</strong></h2><p>Containerization is one of the milestones in the evolution of scalable artificial intelligence infrastructure. Containerization of the AI application and its dependencies in a Docker container ensures consistency throughout the development, testing, and deployment environments.</p><p>\\\nFirst, you must define a Dockerfile in order to install the environment. The Dockerfile is a series of instructions about how to build a Docker image. It declares a base image, the dependencies required, and the initial setup commands that apply to your app. The following is a basic Dockerfile for a Python machine-learning model:</p><pre><code># Use an official Python runtime as a parent image\nFROM python:3.9-slim\n\n# Set the working directory in the container\nWORKDIR /usr/src/app\n\n# Copy the current directory contents into the container\nCOPY . .\n\n# Install any needed packages specified in requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Expose the port the app runs on\nEXPOSE 5000\n\n# Define environment variable\nENV NAME World\n\n# Run the app\nCMD [\"python\", \"./app.py\"]\n</code></pre><p>\\\nIf the Dockerfile is ready, then you can build the Docker image and run the container. Run the following commands: \\n </p><pre><code># Build the Docker image\ndocker build -t ml-model:latest .\n\n# Run the container\ndocker run -p 5000:5000 ml-model:latest\n</code></pre><h2><strong>Deploying the Dockerized AI Model to Kubernetes</strong></h2><p> provides a wide range of orchestration features that enable efficient application management in the containerized infrastructure. Deployment of the Docker image on Kubernetes ensures that a specified number of application replicas is always running. The following is an example of deployment.yaml file that you can use to<a href=\"https://dev.to/pavanbelagatti/deploy-any-aiml-application-on-kubernetes-a-step-by-step-guide-2i37\"></a>:</p><pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ml-model-deployment\nspec:\n  replicas: 3  \n  selector:\n    matchLabels:\n      app: ml-model\n  template:\n    metadata:\n      labels:\n        app: ml-model\n    spec:\n      containers:\n      - name: ml-model-container\n        image: ml-model:latest\n        ports:\n        - containerPort: 5000\n</code></pre><p>\\n The above code snippet shows how to deploy the AI model, but you also need to make the model externally accessible. You will need to expose it by defining a Kubernetes Service. The service.yaml below illustrates an example:</p><pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: ml-model-service\nspec:\n  selector:\n    app: ml-model\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 5000\n  type: LoadBalancer\n</code></pre><p>\\n Use the kubectl command-line tool to apply the deployment and service configurations:</p><pre><code># Deploy the application\nkubectl apply -f deployment.yaml\n\n# Expose the service\nkubectl apply -f service.yaml\n</code></pre><p>Kubernetes provides excellent scaling capabilities to AI environments, maximizing resource utilization and performance. Horizontal scaling is done by adding additional containers, and vertical scaling involves adding additional resources like CPU or memory to a container.</p><p>Horizontal scaling is used to scale up the number of replicas (Pods) of an AI system to handle a higher workload. The process requires enabling dynamic scaling depending on the number of replicas. The command used to enable such a process is `kubectl scale`. The particular command is used to set up the deployment to function up to a maximum of five replicas:</p><p>\\\n`kubectl scale --replicas=5 deployment/ml-model-deployment`</p><p>\\\nThe command scales up the ml-model-deployment to use five replicas of the machine-learning model container. The system dynamically provisions more Pods to meet the required number afterward.</p><h3><strong>Automatic Scaling using the Horizontal Pod Autoscaler (HPA)</strong></h3><p>Kubernetes facilitates auto-scaling using the Horizontal Pod Autoscaler (HPA). The HPA dynamically adjusts the number of replicas based on resource use, i.e., CPU or memory, in relation to set limits. The YAML configuration shown below is a relevant example of an HPA that dynamically scales for ml-model-deployment in response to CPU use:</p><pre><code>apiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: ml-model-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: ml-model-deployment\n  minReplicas: 2\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 50\n</code></pre><p>\\n In this setup, scaleTargetRef is used to define the Deployment to be scaled, i.e., ml-model-deployment. The minimum replica count is set using MinReplicas, while the maximum replica count is controlled using maxReplicas. In addition, the CPU utilization percentage is set using targetCPUUtilizationPercentage, i.e., to 50%. </p><p>\\\nCPU utilization of more than 50% across all Pods results in scaling up the replica count to a maximum of 10 automatically. As soon as CPU utilization drops below the set percentage, Kubernetes automatically reduces the replica count in order to release resources.</p><p>Horizontal scaling is mainly to cope with more traffic, whereas vertical scaling provides more resources (such as CPU or memory) to existing containers. The process is to scale up or down resource requests and limits in the Kubernetes Deployment. In order to scale up the CPU and memory limits of the ml-model-deployment, one would need to open the deployment.yaml file:</p><pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ml-model-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ml-model\n  template:\n    metadata:\n      labels:\n        app: ml-model\n    spec:\n      containers:\n      - name: ml-model-container\n        image: ml-model:latest\n        ports:\n        - containerPort: 5000\n        resources:\n          requests:\n            cpu: \"1\"\n            memory: \"2Gi\"\n          limits:\n            cpu: \"2\"\n            memory: \"4Gi\"\n</code></pre><p>\\\nIn this updated configuration:</p><ul><li>requests specify the minimum resources required for the container.</li><li>limits define the maximum resources the container can use.</li></ul>","contentLength":7854,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"'Mass Theft': Thousands of Artists Call for AI Art Auction to be Cancelled","url":"https://slashdot.org/story/25/02/15/0351257/mass-theft-thousands-of-artists-call-for-ai-art-auction-to-be-cancelled?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739640840,"author":"EditorDavid","guid":186,"unread":true,"content":"An anonymous reader shared this report from the Guardian:\n\nThousands of artists are urging the auction house Christie's to cancel a sale of art created with artificial intelligence, claiming the technology behind the works is committing \"mass theft\". The Augmented Intelligence auction has been described by Christie's as the first AI-dedicated sale by a major auctioneer and features 20 lots with prices ranging from $10,000 to $250,000... \nThe British composer Ed Newton-Rex, a key figure in the campaign by creative professionals for protection of their work and a signatory to the letter, said at least nine of the works appearing in the auction appeared to have used models trained on artists' work. However, other pieces in the auction do not appear to have used such models. \nA spokesperson for Christie's said that \"in most cases\" the AI used to create art in the auction had been trained on the artists' \"own inputs\". \n\nMore than 6,000 people have now signed the letter, which states point-blank that \"Many of the artworks you plan to auction were created using AI models that are known to be trained on copyrighted work without a license.\"\n\nThese models, and the companies behind them, exploit human artists, using their work without permission or payment to build commercial AI products that compete with them. Your support of these models, and the people who use them, rewards and further incentivizes AI companies' mass theft of human artists' work. We ask that, if you have any respect for human artists, you cancel the auction. \n\nLast week ARTnews spoke to Nicole Sales Giles, Christie's vice-president and director of digital art sales (before the open letter was published). And Giles insisted one of the major themes of the auction is \"that AI is not a replacement for human creativity.\"\n\"You can see a lot of human agency in all of these works,\" Giles said. \"In every single work, you're seeing a collaboration between an AI model, a robot, or however the artist has chosen to incorporate AI. It is showing how AI is enhancing creativity and not becoming a substitute for it.\" \n\nOne of the auction's headline lots is a 12-foot-tall robot made by Matr Labs that is guided by artist Alexander Reben's AI model. It will paint a new section of a canvas live during the sale every time the work receives a bid. Reben told ARTnews that he understands the frustrations of artists regarding the AI debate, but he sees \"AI as an incredible tool... AI models which are trained on public data are done so under the idea of 'fair use,' just as search engines once faced scrutiny for organizing book data (which was ultimately found to fall under fair use),\" he said.... \"AI expands creative potential, offering new ways to explore, remix, and evolve artistic expression rather than replace it. The future of art isn't about AI versus artists — it's about how artists wield AI to push boundaries in ways we've never imagined before....\" \n\nDigital artist Jack Butcher has used the open letter to create a minted digital artwork called Undersigned Artists. On X he wrote that the work \"takes a collective act of dissent — an appeal to halt an AI art auction — and turns it into the very thing it resists: a minted piece of digital art. The letter, originally a condemnation of AI-generated works trained on unlicensed human labor, now becomes part of the system it critiques.\" \n\nChristie's will accept cryptocurrency payments for the majority of lots in the sale.\n","contentLength":3474,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Programmer's Guide to Game Design: The Major Ingredients You Should Know","url":"https://hackernoon.com/a-programmers-guide-to-game-design-the-major-ingredients-you-should-know?source=rss","date":1739638805,"author":"Chenuli J.","guid":117,"unread":true,"content":"<p>Software developers spend their whole time with complicated problems, and they try to learn almost everything about algorithms, structures, frameworks, and blah-blah-blah. While playing games and coffee have become stress-busters in our lives, why can't building games be the best one?</p><p>\\\nEven though some people find game development insane, it’s easy for software developers because they have almost every skill needed: math, Programming, UX/UI, and the usual stuff. If a normal person takes 6 months to learn a Game Engine, the Developer will take a maximum of 3 months or less.</p><p>\\\nMany people don’t know this, but I started my tech career as a game developer, although I later turned my back on game development and became a Python developer. And no lies, they were a few of the best years in my life.</p><p>\\\nThis article is dedicated to any developer who wants to try something new or exciting (which is game development, yes). Scroll down!</p><p>Software developers who are interested in game development have a remarkable head start. Programming skills are the core of game development. Even if you’re more comfortable with Swift or Ruby, which is not commonly used in game development, you can quickly pick up other Object-oriented programming languages that are much more commonly used for game development, like C# or C++, easier than anyone!</p><p>\\\nIf you're a Python lover, you will love to hear this: There are really good, AAA games made with Python such as Battlefield 2, EVE Online, Civilization IV, and more!</p><p>Not only Python, but almost every commonly used Programming language has libraries that support making games. For example:</p><ul><li>Flutter has Flame, a game engine that supports Flutter language.</li><li>Ruby has Gosu, a library that makes it easy to develop 2D games.</li><li>Python has PyGame, a library that empowers you to create both 2D and 3D games.</li><li>Phaser allows you to create games with JavaScript and HTML5.</li></ul><p>For every beginner, either a software engineer or a novice, I give one common piece of advice— Start as small as possible. It doesn't matter how small pieces of code it has or how messy it is, you've won the challenge!</p><p>\\\nIf you love simple 2D games, I would recommend that you make a Pong game. Pong features simple graphics (2 rectangles and a circle) you can create on your own, minimal sounds, and a game loop. If you want to learn about making multiplayer games, allow matches to occur between two human players over a network. If you want to learn about AI, allow the player to challenge the computer.</p><p>\\\nAnd if you love 3D games like me, start with Cube Run. I haven't made it without a Game engine because, 3D becomes a bit harder with Python or others but with Unity, it's the best game I recommend to take a start.</p><h2><strong>Major Ingredients of A Game</strong></h2><p>If you make a cake without Sugar, no one will eat it. Except for diabetic people, of course, like my mom.</p><p>\\\nThe same goes for video games. It’s full of ingredients, some of which are required for every game and some of which are optional. I’ll introduce them briefly.</p><p>In many games, the level itself is a challenge, trickier than the smartest AI enemies. Series like Tomb Raider also emphasize complex and challenging level design.</p><p>\\\nWhile the advent of open-world games like GTA may make the level design seem less important than in bygone times, it’s worth noting that even open-world games have ‘levels’, such as a particular building, structure, or map area you must enter to achieve a goal.</p><p>\\\nTo reduce player feelings of being railroaded, levels will ideally have multiple possible paths through them.</p><p>In games, you can’t really rely on natural light sources to illuminate your video game.</p><p>\\\n(You don’t think there’s a sun inside a game engine, do you?)</p><p>\\\nEvery light source in a video game must be added by hand and light manipulation is incredibly important. Light can be used for all of the following:</p><ul><li>Controlling the player’s ability . In horror and survival games, light is a resource that must be carefully managed.</li></ul><ul><li>Controlling a player’s ability . In games with an element of stealth, dark areas can provide cover while well-lit areas represent a difficult challenge.</li></ul><ul><li>Setting the mood. The quality of light can be used to set the mood, with sunny and bright lighting associated with happy times and brooding light associated with dark times.</li></ul><ul><li>Lighting the way. Light can be used to direct the player’s attention. The best-designed levels in video games often make clever use of light to guide the player in the right direction when they might otherwise be lost.</li></ul><p>Game art is the medium through which the game world is presented to the player. In a sense, all the programming effort that goes into making video games is an attempt to turn game art into something that feels responsive and alive. Game art is an umbrella term that includes textures, 3D models, sprites, particle effects, and lighting.</p><p>\\\nAnd yes, it’s a broad area, best to not cover it in this article.</p><p>Unlike in the real world, video game sounds cannot be made by accident. Every sound in the game universe must be added by hand, and it is through layering these sounds that the game world starts to feel lifelike. You also need to be mindful of sounds triggered by the player, by other characters, and ambient sounds that create the game world environment.</p><p>\\\nAs an example, the player accidentally hits a metal object; if it doesn't emit a sound, it doesn't feel natural, or the scientist who claimed that metals have sonorous properties got it wrong.</p><p>\\\nAnother ever-present fact of video games is music, used to create an emotional response in the player or removed entirely to leave behind an eerie silence. Unlike most compositions, video game music must loop seamlessly. It must also transition smoothly to new compositions based on in-game events, such as being spotted by an enemy.</p><p>\\\nHere are some of my favorite places to find sound:</p><p>You have made graphics, levels, and everything but the whole game feels like a dead body. If you want your game to be alive, you need some lines of code.</p><p>\\\nMost of my readers are probably a developer already, so you probably know the importance of programming anywhere. I'm not going to give a lecture on \"what is programming\", but here’s a bit about programming in game design.</p><p>\\\nFirst of all, you need to decide one thing: Are you making a game by using a Game Engine + Language or building a game from scratch with Python or something? It's your choice but let me help you: If you're going to build games for fun, choose the first option because it's easier. </p><p>\\\nAs I said in the beginning, programmers always juggle complex problems so you probably shouldn't take more stress with that too.</p><p>\\\n(Game Engines are the software used to create video games.)</p><p>\\\nThere are many of them, but the most popular ones are:</p><ul><li><p>Unity (Great for beginners, recommended)</p></li></ul><p>Next, choose a language to get started. Mostly, C# and C are used. Don't worry, you already got a headstart in knowing at least one programming language; most people start even before they know what the word “programming“stands for.</p><p>\\\nAnd that’s about it. Well, of course, there are many other optional ingredients that video games consist of but in general, the above are basically the starter pack.</p><p>Starting game development is easier for software developers than anyone. As someone with programming skills, you have a massive head-start on the average video game hobbyist who wants to learn how to make a game. If I scroll to the top of the article, I can list the below points as key takeaways.</p><ul><li><p>It's a lot easier to find a game dev library in your comfortable programming language to get started.</p></li><li><p>Start with a small game, maybe a clone of an existing game.</p></li><li><p>Game Engines make your life a lot easier.</p></li><li><p>If you want to make a big, impressive game but don’t have a lot of time to spare, consider teaming up with others or joining a modding community.</p></li></ul><p>And that's all for now, Happy Designing! 🏎</p><p>\\\nIf you loved this article, make sure to subscribe using your email, so you can read all my content inside your inbox without missing any!</p><p>It’s totally free of charge and I don’t even have time to send spam emails.</p>","contentLength":8132,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Marc Andreessen dreams of making a16z a lasting company, beyond partnerships","url":"https://techcrunch.com/2025/02/15/marc-andreessen-dreams-of-making-a16z-a-lasting-company-beyond-partnerships/","date":1739638800,"author":"Marina Temkin","guid":50,"unread":true,"content":"<p>Many venture industry observers have wondered whether Andreessen Horowitz, a firm that manages $45 billion, has its sights on eventually becoming a publicly traded company. Co-founder Marc Andreessen said he isn’t “chomping at the bit to take the firm public,” on this week’s Invest Like the Best podcast. But he discussed his goal of building […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":420,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ISS Astronauts Give Space-to-Earth Interview Weeks Before Finally Returning to Earth","url":"https://science.slashdot.org/story/25/02/15/033223/iss-astronauts-give-space-to-earth-interview-weeks-before-finally-returning-to-earth?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739637240,"author":"EditorDavid","guid":185,"unread":true,"content":"Last June two NASA astronauts flew to the International Space Station on the first crewed test flight of Boeing's Starliner. But they aren't stranded there, and they weren't abandoned, the astronauts reminded CNN this week in a rare space-to-earth interview:\n\n\"That's been the rhetoric. That's been the narrative from day one: stranded, abandoned, stuck — and I get it. We both get it,\" [NASA astronaut Butch] Wilmore said. \"But that is, again, not what our human spaceflight program is about. We don't feel abandoned, we don't feel stuck, we don't feel stranded.\" Wilmore added a request: \"If you'll help us change the rhetoric, help us change the narrative. Let's change it to 'prepared and committed.' \n\n\"That's what we prefer,\" he said... \n[NASA astronaut Suni] Williams also reiterated a sentiment she has expressed on several occasions, including in interviews conducted before she left Earth. \"Butch and I knew this was a test flight,\" she told CNN's Cooper, acknowledging the pair has been prepared for contingencies and understood that the stay in space might be extended. \"We knew that we would probably find some things (wrong with Starliner) and we found some stuff, and so that was not a surprise,\" she said. \nWhen Cooper opened the interview by asking the astronauts how they're doing, Williams answers \"We're doing pretty darn good, actually,\" pointing out they had plenty of food and great crew members. And Wilmore added that crews come to the space station on a careful cycle, and \"to alter that cycle sends ripple effects all the way down the chain. We would never expect to come back just special for us or anyone unless it was a medical issue or something really out of the circumstances along those lines. So we need to come back and keep the normal cycle going...\" \n\nCNN's article notes a new announcement from NASA Tuesday that the astronauts might return a couple weeks early \"after opting to change the SpaceX Crew Dragon capsule it will use.\" That mission's targeted launch date is now March 12. \n\nIn the meantime, Williams says in the interview, \"We do have some internet connection up here, so we can get some internet live. We've gotten football. It's been this crew's go-to this past fall. Also YouTube or something like that. It's not continuous — it has chunks of time that we get it. And we use that same system also to make phone calls home, so we can talk to our families, and do videoconferences even on the weekends as well. This place is a pretty nice place to live, for the most part.\" \n\nAnd they're also \"working on with folks on the ground\" to test the NASA's cube-shaped, free-flying robotic Astrobees.","contentLength":2649,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NTSYNC Driver Fix Being Worked On For Proper User Permissions","url":"https://www.phoronix.com/news/Linux-NTSYNC-Permissions-Issue","date":1739635532,"author":"Michael Larabel","guid":367,"unread":true,"content":"<article>One of the great new features of Linux 6.14 is the NTSYNC driver being completed for better emulating the Microsoft Windows NT synchronization primitives so that software like Wine and Proton (Steam Play) can provide for better performance when running Windows games on Linux. But it turns out an oversight up to now has meant that in practice it's not really too usable out-of-the-box...</article>","contentLength":388,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The HackerNoon Newsletter: No Startup Has Ever Failed Because it Didn’t Have a Blog (2/15/2025)","url":"https://hackernoon.com/2-15-2025-newsletter?source=rss","date":1739635457,"author":"Noonification","guid":116,"unread":true,"content":"<p>🪐 What’s happening in tech today, February 15, 2025?</p><p>By <a href=\"https://hackernoon.com/u/realgpp\">@realgpp</a> [ 9 Min read ] Learn how to read thread dumps and take control of your application’s runtime behaviour.\n <a href=\"https://hackernoon.com/how-to-expose-and-fix-hidden-bottlenecks-in-adobe-experience-manager\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bigmao\">@bigmao</a> [ 6 Min read ] The case against content marketing, and how to do inbound marketing in the post-content age.  <a href=\"https://hackernoon.com/no-startup-has-ever-failed-because-it-didnt-have-a-blog\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/loadbalancer\">@loadbalancer</a> [ 5 Min read ] Researchers have optimized Layer-7 load balancing using programmable SmartNICs to improve efficiency, cost, and energy use in cloud data centers. <a href=\"https://hackernoon.com/cloud-giants-spend-a-fortune-on-load-balancersthis-research-could-change-that\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>","contentLength":749,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Jeep Claims 'Software Glitch' Disabled Opting-Out of In-Vehicle Pop-Up Ads in 'a Few' Cases","url":"https://tech.slashdot.org/story/25/02/15/0149202/jeep-claims-software-glitch-disabled-opting-out-of-in-vehicle-pop-up-ads-in-a-few-cases?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739633640,"author":"EditorDavid","guid":184,"unread":true,"content":"Remember Jeep's new in-dash pop-up ads which reportedly appeared every time you stopped? \n\"Since I'm a journalist, or at least close enough, I decided that I should at least get Stellantis/Jeep's side of things,\" writes car-culture site The Autopian:\n\n\nWould Stellantis do something so woefully misguided and annoying? I reached out to our Stellantis/Jeep contact to ask and was initially told that they were \"investigating\" on their end, which to me felt like a stalling tactic while the proper ass-covering plans were conceived. I eventually got this response from a Stellantis spokesperson: \n\n \"This was an in-vehicle message designed to inform Jeep customers about Mopar extended vehicle care options. A temporary software glitch affected the ability to instantly opt out in a few isolated cases, though instant opt-out is the standard for all our in-vehicle messages. Our team had already identified and corrected the error, and we are following up directly with the customer to ensure the matter is fully resolved...\" \n\nI suppose a glitch is possible, though I've not seen any examples of this ad popping up with the instant opt-out option available, but I guess it must exist, since not all Jeep owners seem to have had to deal with these ads. I suspect if this was happening to more people than these \"few isolated cases\" we'd still be cleaning up from the aftermath of the riots and uprisings. \n\nBecause, as they write, \"Really, I can't think of a quicker way to incur the wrath of nearly every human...\"","contentLength":1513,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What is an encryption backdoor?","url":"https://techcrunch.com/2025/02/15/what-is-an-encryption-backdoor/","date":1739631600,"author":"Natasha Lomas","guid":49,"unread":true,"content":"<p>Talk of backdoors in encrypted services is once again doing the rounds after reports emerged that the U.K. government is seeking to force Apple to open up iCloud’s end-to-end encrypted (E2EE) device backup offering. Officials were said to be leaning on Apple to create a “backdoor” in the service that would allow state actors to […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":404,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Antarctica's Only Insect","url":"https://www.404media.co/antarcticas-only-insect/","date":1739628013,"author":"Becky Ferreira","guid":389,"unread":true,"content":"<img src=\"https://www.404media.co/content/images/2025/02/CleanShot-2025-02-14-at-09.17.41@2x.png\" alt=\"Antarctica's Only Insect\"><p>Welcome <a href=\"https://www.404media.co/neanderthals-would-rather-die-than-talk-to-you-3/\" rel=\"noreferrer\">back to the Abstract</a>, 404 Media's weekly roundup of scientific studies to distract us from our present dystopia!</p><p>This week, we are traveling back in time to 16th century Transylvania, so please make sure you are up to date on your bubonic plague shots. A study reconstructed wild weather events through the eyes of record-keepers during this fraught period, opening a tantalizing window into climate extremes unleashed by a vengeful God (according to contemporary reports).</p><p>Then: making love the medaka way (get those anal fins ready). Next, the chillest insect in Antarctica (also: the only one). Finally, these turtles will dance for food, and yes, it’s very cute.</p><h3><strong>The Haunting Weather Reports of 16th Century Transylvania</strong></h3><p>Rejoice, for this week has delivered one of the best varieties of study: Science via historical documents. Sure, ice cores and geological strata are great for reconstructing past climates, but nobody can bitch about the weather better than a good old-fashioned red-blooded member of team .&nbsp;</p><p>To that end, researchers searched for mentions of weird weather across a trove of diaries, monastery records, travel notes, and other documents from 16th century Transylvania, during a “pivotal moment in climate history” when a centuries-long cooling event called the Little Ice Age intensified, according to researchers led by Ovidiu Răzvan Gaceu of the University of Oradea.&nbsp;</p><p>These types of studies are packed with colorful human testimonies that can corroborate natural records. More importantly, though, they are just fun to read, especially during such an evocative time and place, freshly haunted by the vampiric spirit of Vlad the Impaler. Some highlights:</p><p>In August 1526, heavy rainfall caused freak floods in Braşov that “washed the walls of the fortress, demolished the main gate, and the fish also got caught in the big church,” according to the Annals of Brașov. Fish in the church! The ultimate baptism.&nbsp;</p><p>&nbsp;In autumn 1553, people in the city of Cluj reported unusual weather events including “October strawberries.” For real, October is for pumpkins, get out of here with the strawbs. Turned out it was a bad omen—there was a plague the following winter. Keep that in mind if you see any late autumn strawberries: Kill on sight.</p><p>Naturally, a lot of these accounts are heartbreaking. Locusts “sometimes covered the whole sky and destroyed grain crops” and caused terrible famines. A storm-related fire “killed 14 people and made 60 poor.” On September 29, 1582, “there was such a big storm, as it was said that it had never been seen before in the city of Cluj, which uprooted the trees and raised the roofs of the houses, people believed that it is sent by divinity to punish the crimes committed by them.”&nbsp;</p><p>I mean, I’m not saying these people weren’t doing crimes. It’s 16th century Transylvania. Do what you gotta do. But that's not why there is extreme weather. You’re just in the Little Ice Age.&nbsp;</p><p>The study ultimately identified “multiple pieces of evidence associated with extreme weather events, including 40 unusually warm summers and several years of excess precipitation or drought.” Taken together with natural archives, the documents paint a picture of troubled times, exacerbated by an unstable climate and possible emergent vampires. Relatable!&nbsp;</p><p>Valentine’s Day is over, but the romantic mood is still in the air—or in the water, if you’re a medaka (flawless segue). Scientists have discovered that wild medaka, also known as Japanese rice fish, are fans of late-night booty calls, which is a behavior that has not been observed in captivity.</p><p>“Although medaka and other model organisms are invaluable in laboratories, their ecology in the wild remains largely unknown,” said researchers led by Yuki Kondo of Osaka Metropolitan University. “This study showed that medaka in the wild initiate spawning during late nocturnal hours and exhibit vigorous courtship behavior at midnight.”</p><p>Kondo and her colleagues recorded this vigorous courtship by placing GoPros into streams over the course of several summer nights in Gifu, Japan. The tapes revealed that medaka like to spawn in the dark, possibly to avoid predators during copulation. The results “provide the first empirical evidence that medaka mating begins significantly earlier than previously reported in the laboratory.”&nbsp;&nbsp;</p><p>For anyone who feels clueless about courtship, may I offer a page from the Medaka Sutra:&nbsp;</p><p>“The spawning behavior of medaka follows a sequence of events: the male chases the female (following), the male swims rapidly around the female (quick circle), the male wraps his dorsal and anal fins around the female (wrapping), the female releases eggs, the male releases sperm (egg and sperm release), and the male leaves the female (leaving),” according to Kondo’s team.</p><p>The only true love language is, indeed, spoken with anal fins.</p><p>Major bonus points also go to Osaka Metropolitan University’s press team for <a href=\"https://www.eurekalert.org/multimedia/1058890?ref=404media.co\"><u>throwing together this version</u></a> of Edward Hopper’s famous “Nighthawks” painting with medaka getting drinks at a bar that is also named Medaka. It is genuinely one of the most inspired public relations efforts I have ever seen, and I’m going to get a print of it to hang on my wall.</p><h3><strong>The Insect at the Edge of Earth</strong></h3><p>, or the Antarctic midge, is the only insect that lives year-round on its namesake continent. Do you know how weird you have to be to be the  insect somewhere? But this midge doesn’t care. It just lives out its bug life, which lasts two years, in an otherwise bugless wasteland.&nbsp;</p><p>Humans definitely care about the midge, though—how could we not? What is it doing there? How is it not dead? What can it teach us about cryopreservation? These questions are addressed in a new study that resolved mysteries about the animal’s interesting life cycle.</p><p>“Freeze tolerance and cryoprotective dehydration are cold tolerance strategies used by various invertebrate species in polar regions and indeed,  utilises both for overwintering,” said researchers led by Mizuki Yoshida of the Ohio State University, who completed the project while at Osaka Metropolitan University (OMU killing it this week).&nbsp;</p><p>“Larvae that are frozen in ice and cryoprotectively dehydrated readily survived 32 days of simulated overwintering,” the team said. “Unlike many insects restricted to highly specific microhabitats,  larvae inhabit a remarkably diverse range of substrates that differ in vegetation, substrate type, slope, drainage, and thermal and hydric conditions.”</p><p>I love the phrasing of “readily survived” as if the midges were eager to show off their cryoprotective superpowers. After this 32-day period they emerged with “That all you got?” energy. By studying the bugs in these simulated conditions, the researchers confirmed that they rely on multiple overwintering strategies, including a state of arrested development called “obligate diapause.”&nbsp;</p><p>“Diapause has long been assumed to be uncommon in Antarctic species, but the present study reveals that  utilises diapause for seasonal adaptation, as in many temperate species,” Yoshida and her colleagues said.&nbsp;</p><p>In addition to being the only endemic Antarctic insect, this midge has the smallest genome of any known insect while also being the largest fully terrestrial animal on the continent, even though it’s only a few millimeters long. In other words, it is the biggest animal in Antarctica that doesn’t fly or swim. Okay, Antarctic midge. You just keep doing you.</p><p>Last, turtles do a little victory dance when they find food. Yes, it is cute. Yes, there is a video.</p><p>The footage (along with <a href=\"https://youtu.be/IcI6yHr6JXo?si=DAGsav7HY4S3uhKn&amp;ref=404media.co\"></a>) is part of a study that tested if turtles could distinguish the magnetic signatures of two geographical areas. When the turtles were exposed to signatures associated with an area they associated with food, they danced in anticipation of a meal, demonstrating that they could tell the signals apart—and party accordingly.&nbsp;&nbsp;</p><p>“Hallmarks of the behaviour include some or all of the following: tilting the body vertically, holding the head near or above water, opening the mouth, rapid alternating movement of the front flippers, and, occasionally, even spinning in place, hence the name ‘turtle dance,’” said researchers led by Kayla Goforth of Texas A&amp;M University. “Turtles exhibited significantly higher levels of turtle dance behaviour when experiencing the field in which they had been fed.”</p><p>With that, let’s all tilt vertically, spin in place, and shell-abrate the long weekend.&nbsp;</p><p>Thanks for reading! See you next week.&nbsp;&nbsp;</p>","contentLength":8613,"flags":null,"enclosureUrl":"https://www.404media.co/content/images/2025/02/CleanShot-2025-02-14-at-09.17.41@2x.png","enclosureMime":"","commentsUrl":null},{"title":"Paragraf Is Building a \"Blank Canvas\" Graphene Foundry","url":"https://spectrum.ieee.org/paragraf-graphene-foundry","date":1739628003,"author":"Liam Critchley","guid":78,"unread":true,"content":"<p>The company wants to make graphene sensors more accessible to industries</p>","contentLength":72,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjQ2NTMyMC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc4MzQyMzgzM30.wJGF4-_y2VSVjXLsYFhhL9DuC-xHiTHWB-Ciq4DHQTU/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"These Google Photos alternatives offer tons of storage options at a reasonable price","url":"https://techcrunch.com/2025/02/15/these-google-photos-alternatives-offer-tons-of-storage-options-at-a-reasonable-price/","date":1739628000,"author":"Ivan Mehta","guid":48,"unread":true,"content":"<p>Google Photos is a great service for storing images across devices. But Google Drive and Gmail only offer 15GB of storage for free. Google Photos used to offer free unlimited storage of images, but that is not the case anymore. If you are looking for a better photo storage plan, different features, or just want […]</p><p>© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":381,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The IRS Is Buying an AI Supercomputer From Nvidia","url":"https://tech.slashdot.org/story/25/02/15/0540249/the-irs-is-buying-an-ai-supercomputer-from-nvidia?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739624400,"author":"BeauHD","guid":183,"unread":true,"content":"According to The Intercept, the IRS is set to purchase an Nvidia SuperPod AI supercomputer to enhance its machine learning capabilities for tasks like fraud detection and taxpayer behavior analysis. From the report: With Elon Musk's so-called Department of Government Efficiency installing itself at the IRS amid a broader push to replace federal bureaucracy with machine-learning software, the tax agency's computing center in Martinsburg, West Virginia, will soon be home to a state-of-the-art Nvidia SuperPod AI computing cluster. According to the previously unreported February 5 acquisition document, the setup will combine 31 separate Nvidia servers, each containing eight of the company's flagship Blackwell processors designed to train and operate artificial intelligence models that power tools like ChatGPT. The hardware has not yet been purchased and installed, nor is a price listed, but SuperPod systems reportedly start at $7 million. The setup described in the contract materials notes that it will include a substantial memory upgrade from Nvidia.\n \nThough small compared to the massive AI-training data centers deployed by companies like OpenAI and Meta, the SuperPod is still a powerful and expensive setup using the most advanced technology offered by Nvidia, whose chips have facilitated the global machine-learning spree. While the hardware can be used in many ways, it's marketed as a turnkey means of creating and querying an AI model. Last year, the MITRE Corporation, a federally funded military R&amp;D lab, acquired a $20 million SuperPod setup to train bespoke AI models for use by government agencies, touting the purchase as a \"massive increase in computing power\" for the United States.\n \nHow exactly the IRS will use its SuperPod is unclear. An agency spokesperson said the IRS had no information to share on the supercomputer purchase, including which presidential administration ordered it. A 2024 report by the Treasury Inspector General for Tax Administration identified 68 different AI-related projects underway at the IRS; the Nvidia cluster is not named among them, though many were redacted. But some clues can be gleaned from the purchase materials. \"The IRS requires a robust and scalable infrastructure that can handle complex machine learning (ML) workloads,\" the document explains. \"The Nvidia Super Pod is a critical component of this infrastructure, providing the necessary compute power, storage, and networking capabilities to support the development and deployment of large-scale ML models.\"\n \nThe document notes that the SuperPod will be run by the IRS Research, Applied Analytics, and Statistics division, or RAAS, which leads a variety of data-centric initiatives at the agency. While no specific uses are cited, it states that this division's Compliance Data Warehouse project, which is behind this SuperPod purchase, has previously used machine learning for automated fraud detection, identity theft prevention, and generally gaining a \"deeper understanding of the mechanisms that drive taxpayer behavior.\"","contentLength":3057,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Karol Herbst Steps Down As Nouveau Maintainer Due To Linux Kernel's Toxic Environment","url":"https://www.phoronix.com/news/Karol-Herbst-Nouveau-No","date":1739619627,"author":"Michael Larabel","guid":366,"unread":true,"content":"<article>Karol Herbst has been a Nouveau driver developer for over a decade working on this open-source, reverse-engineered NVIDIA Linux graphics driver. He went on to become employed by Red Hat. While he's known more these days for his work on Mesa and the Rusticl OpenCL driver for it, he's still remained a maintainer of the Nouveau kernel driver. But today he announced he's resigning as a Nouveau driver maintainer due to differences with the upstream Linux kernel developer community...</article>","contentLength":483,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"KDE Developers Addressing Early Bugs From Plasma 6.3","url":"https://www.phoronix.com/news/KDE-Plasma-6.3-Early-Bugs","date":1739618860,"author":"Michael Larabel","guid":365,"unread":true,"content":"<article>KDE Plasma 6.3 released this week as the newest step forward for the KDE desktop. While it was smooth on the whole, there were some early bugs that KDE developers were dealing with this week. KDE developer Nate Graham is out with his usual weekly development summary for the Plasma desktop...</article>","contentLength":292,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Eating From Plastic Takeout Containers Can Increase Heart Failure Risk, Study Finds","url":"https://science.slashdot.org/story/25/02/15/0555235/eating-from-plastic-takeout-containers-can-increase-heart-failure-risk-study-finds?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739613600,"author":"BeauHD","guid":182,"unread":true,"content":"A new study suggests that frequent consumption of food from plastic takeout containers significantly increases the risk of congestive heart failure due to gut biome changes that trigger inflammation and circulatory damage. The Guardian reports: The authors used a two-part approach, first looking into the frequency with which over 3,000 people in China ate from plastic takeout containers, and whether they had heart disease. They then exposed rats to plastic chemicals in water that was boiled and poured in carryout containers to extract chemicals. \"The data revealed that high-frequency exposure to plastics is significantly associated with an increased risk of congestive heart failure,\" the authors wrote. [...] They put boiling water in the containers for one, five or 15 minutes because plastic chemicals leach at much higher rates when hot contents are placed in containers -- the study cited previous research that found as many as 4.2m microplastic particles per sq cm can leach from plastic containers that are microwaved.\n \nThe authors then gave rats the water contaminated with leachate to drink for several months, then analyzed the gut biome and metabolites in the feces. It found notable changes. \"It indicated that ingestion of these leachates altered the intestinal microenvironment, affected gut microbiota composition, and modified gut microbiota metabolites, particularly those linked to inflammation and oxidative stress,\" the authors wrote. They then checked the rats' heart muscle tissue and found it had been damaged. The study did not find a statistical difference in the changes and damage among rats that were exposed to water that had been in contact with plastic for one minute versus five or fifteen. The study has been published in the journal Ecotoxicology and Environmental Safety.","contentLength":1816,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["tech"]}