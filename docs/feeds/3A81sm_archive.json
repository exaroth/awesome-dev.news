{"id":"3A81sm","title":"Tech","displayTitle":"Tech","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":140,"items":[{"title":"'The Models Were Right!' Astronomers Locate Universe's 'Missing' Matter","url":"https://science.slashdot.org/story/25/06/21/064247/the-models-were-right-astronomers-locate-universes-missing-matter?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750527240,"author":"EditorDavid","guid":164374,"unread":true,"content":"It's not dark matter, writes Space.com. But astronomers \thave discovered \"a vast tendril of hot gas linking four galaxy clusters and stretching out for 23 million light-years, 230 times the length of our galaxy. \n\n\"With 10 times the mass of the Milky Way, this filamentary structure accounts for much of the universe's 'missing matter,' the search for which has baffled scientists for decades....\"\n\n [I]t is \"ordinary matter\" made up of atoms, composed of electrons, protons, and neutrons (collectively called baryons) which make up stars, planets, moons, and our bodies. For decades, our best models of the universe have suggested that a third of the baryonic matter that should be out there in the cosmos is missing. \n\nThis discovery of that missing matter suggests our best models of the universe were right all along. It could also reveal more about the \"Cosmic Web,\" the vast structure along which entire galaxies grew and gathered during the earlier epochs of our 13.8 billion-year-old universe.... The newly observed filament isn't just extraordinary in terms of its mass and size; it also has a temperature of a staggering 18 million degrees Fahrenheit (10 million degrees Celsius). That's around 1,800 times hotter than the surface of the sun... \n\nThe team's research was published on Thursday (June 19) in the journal Astronomy &amp; Astrophysics.\n \n\nModels of the cosmos (including the standard model of cosmology) \"have long posited the idea that the missing baryonic matter of the universe is locked up in vast filaments of gas stretching between the densest pockets of space...\" the article points out. But now thanks to Suzaku, a Japan Aerospace Exploration Agency (JAXA) satellite, and the European Space Agency's XMM-Newton, \"a team of astronomers has for the first time been able to determine the properties of one of these filaments, which links four galactic clusters in the local universe.\" \n\nTeam leader Konstantinos Migkas (of the Netherlands' Leiden Observatory) explained the significance of their finding. \"For the first time, our results closely match what we see in our leading model of the cosmos — something that's not happened before.\" \n\n\"It seems that the simulations were right all along.\"","contentLength":2220,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"One Shot To Stop HIV: MIT's Bold Vaccine Breakthrough","url":"https://science.slashdot.org/story/25/06/21/0451227/one-shot-to-stop-hiv-mits-bold-vaccine-breakthrough?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750523640,"author":"EditorDavid","guid":164333,"unread":true,"content":" ScienceDaily reports:\n\nResearchers from MIT and Scripps have unveiled a promising new HIV vaccine approach that generates a powerful immune response with just one dose. By combining two immune-boosting adjuvants alum and SMNP the vaccine lingers in lymph nodes for nearly a month, encouraging the body to produce a vast array of antibodies. This one-shot strategy could revolutionize how we fight not just HIV, but many infectious diseases. It mimics the natural infection process and opens the door to broadly neutralizing antibody responses, a holy grail in vaccine design. And best of all, it's built on components already known to medicine.\n \n\nThanks to Slashdot reader alternative_right for sharing the news.\n","contentLength":715,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"This College Student Wanted Privacy - His College Couldn't Give Him Any","url":"https://hackernoon.com/this-college-student-wanted-privacy-his-college-couldnt-give-him-any?source=rss","date":1750518006,"author":"The Markup","guid":164332,"unread":true,"content":"<p>On a recent Monday, Eric Natividad woke up around 8 a.m., showered, ate breakfast, and braced himself for a day of being tracked.</p><p>\\\nNatividad, 32, is a student at Mt. San Antonio College, which is one of California’s largest community colleges, serving more than 26,000 students east of Los Angeles, about half of whom attend part time. Like virtually all college students in 2023, his life is constantly being converted into a steady stream of data. This information undergirds algorithms and informs decisions by his professors, college administrators, campus police officers, and a far-reaching universe of technology companies—including some he has never heard of.</p><p>\\\nBy the time Natividad went to bed that night, Google and Facebook had data about which Mt. SAC webpages he’d visited, and a company called Instructure had gathered information for his professors about how much time he’d spent looking at readings for his classes and whether he had read messages about his courses. Campus police and a company called T2 Systems potentially had information about what kind of car he was driving and where he parked. And as he drifted off to sleep, Natividad had to contend with the worry that, later this semester, his professors could subject him to the facial detection software incorporated into the remote proctoring tools used at Mt. SAC.</p><p>\\\n“There isn’t a part of the day where it leaves your mind,” Natividad said about the pervasive tracking.</p><p>\\\nTo understand how Mt. SAC collects data on its students, The Markup used public records requests to obtain contracts between the college and companies that provide its learning management system, online proctoring services, and automated parking enforcement technology, three of the most invasive data collection mechanisms on campus. The Markup also obtained five college policies that govern these technologies, as well as information security and computer use, at Mt. SAC.</p><p>\\\nFew institutions collect as much data about the people inside of them as colleges and universities do. Residential campuses, in particular, mean students not only interact with their schools for academics, but for housing, home internet, dining, health care, fitness, and socialization. Still, whether living on campus or off, taking classes in person or remotely, students simply cannot opt out of most data collection and still pursue a degree.</p><h3>A day of data collection for a college&nbsp;student</h3><h4>As college students go through their days, their movements and behaviors can be tracked on and off&nbsp;campus</h4><p>For many students, that’s not a problem. They generally trust their institutions and see the online elements of higher education as convenient. Putting up with data collection seems like a necessary cost.</p><p>\\\nBut even though Natividad’s preoccupation with data privacy makes him a bit of an anomaly among his classmates, he’s part of a growing group of college students arguing it shouldn’t be this way. Long written off as not caring about privacy because of their extensive sharing on social media, college students have become more organized and insistent about what they see as a right. At the University of Michigan, a student’s quest for greater transparency led to <a href=\"https://safecomputing.umich.edu/viziblue\">ViziBLUE</a>, a website launched in 2020 that lets students see what personal information is collected and how it is used. </p><p>\\\nWhen the COVID pandemic forced a huge portion of higher education to move online, students across the country protested the use of online exam-proctoring software that gathered information about their faces and homes. On many campuses, protesters have pressured university administrators <a href=\"https://www.insidehighered.com/news/2020/02/21/ucla-drops-plan-use-facial-recognition-security-surveillance-other-colleges-may-be\">to commit to banning</a> the use of facial recognition technology before ever trying it.</p><p>\\\nAnd as more colleges <a href=\"https://www.comparitech.com/blog/vpn-privacy/us-schools-data-breaches/\">disclose data breaches</a>, many students are becoming uneasy about how much personal information their schools gather. They are forming new on-campus student groups to advocate for privacy and tapping into global networks designed to facilitate a more collective fight. Some colleges are taking note of the unrest as well as the liability inherent in holding so much data. The University of California, San Diego, for example, is among the universities that have created stand-alone positions for chief privacy officers in recent years.</p><p>\\\nJuan Cruz is the director of policy at Encode Justice Florida, a state chapter of a global youth-led advocacy organization fighting for human-centered artificial intelligence. A student at Florida International University, Cruz sees collegegoers as among the most vulnerable to data privacy violations.</p><p>\\\n“You don’t really get any options,” he said. “You’re just kind of expected, if you want to pass this class or pass this test, you have to willingly give up a lot of your information and then hope that nothing happens.”</p><p>When Natividad was in high school he didn’t pay much attention to the data he was generating for ed tech companies, or to news reports detailing data breaches. Coming of age during the Occupy Wall Street protests and spending several years in China, however, opened his eyes.</p><p>\\\nWhile living in Shanghai, Natividad saw security cameras everywhere and the introduction of facial recognition cameras on the subways, but he said it wasn’t until he saw articles about the same technology in the United States that he started doing more research about it. He started to believe surveillance technology runs counter to a free democracy and began monitoring purchases made by the Los Angeles Police Department. He also started paying closer attention to all the companies that get access to his data and became convinced this was something he should learn more about and protect himself against.</p><p>\\\n“You just don’t know how you’re going to be targeted sometimes,” Natividad said, “by state or police or bad actors or somebody trying to steal money. … This is something that I need to care about, too.”</p><p>\\\nWhen he registered at Mt. SAC in 2022, interested in pursuing a degree in computer science, he asked questions about the technology he’d have to use and whether he could opt out of data collection. He was told opting out wasn’t an option but figured he’d enroll and see how it went.</p><p>\\\nHe found more cause for concern than he had expected.</p><p>\\\nOn that recent Monday morning, after his shower and breakfast, Natividad turned on his computer. He needed to log into Canvas, his college’s learning management system for online coursework, reading, class discussion, quizzes and faculty gradebooks, which is used by <a href=\"https://www.highereddive.com/news/instructure-canvas-first-quarter-revenue-lms/649232/\">more than a third</a> of higher education institutions in North America. Natividad’s goal was to be in Canvas for as little time as possible, avoiding one of the primary dragnets of data collection for college students.</p><p>Soon, he had downloaded everything he was supposed to read for the week, copied assignment instructions for each of his classes into plain text documents, sometimes with screenshots, and logged back out. Over the course of the week, he read the documents offline and drafted his assignments in a text editor. He only logged back into Canvas to check for any updates from his professors and, ultimately, to copy and paste his work when it was ready to submit.</p><p>\\\nCanvas tracks what pages students view, their time spent on each page, and when they submit discussion comments or assignments. It houses students’ grades, tracks when they complete quizzes and how long they take to finish them, and it gives professors visualizations of student progress and participation in the course.</p><p>\\\nSome professors use this information to refine their teaching and serve students better, and at many institutions this data informs course planning, program design, and academic advising. But it’s not only educators who have access to it.</p><p>\\\nMt. SAC’s contract for Canvas, which The Markup obtained through a public records request, says that the parent company, Instructure, owns the usage data. The contract lists examples of how the company can use that data, including statistical analyses, trend analyses, and the creation of “data models.” The contract says usage data can only be used if it is aggregated or anonymized and should never be used for profit or sale—but in 2019, Instructure’s former CEO Dan Goldsmith <a href=\"https://www.edsurge.com/news/2020-01-17-as-instructure-changes-ownership-academics-worry-whether-student-data-will-be-protected\">pointed investors to the company’s corpus of education data</a> as key to its multibillion-dollar value, saying it could be used to train algorithms and predictive models.</p><p>\\\nSince that comment, Instructure has stopped working on predictive models, according to Daisy Bennett, who said she was hired as the company’s privacy officer in part to repair the damage from Goldsmith’s claims.</p><p>\\\n“We are not monetizing our schools’ data,” Bennett said. “Absolutely not.”</p><p>\\\nNatividad, however, still doesn’t think the company should be able to have or keep any data he generates while using its platform. And Canvas isn’t his only problem.</p><p>\\\nThis semester, one of Natividad’s professors assigned a digital textbook through Cengage, a publishing company turned ed tech behemoth. In the past, professors have allowed Natividad to stick with paper textbooks, but he now must submit to the additional data tracking of e-books for a required course. Professors sometimes mandate digital textbooks because they want students to complete interactive assignments contained in them.</p><p>\\\nAccording to Cengage’s <a href=\"https://www.cengagegroup.com/privacy/notice/\">online privacy policy</a>, the company collects information about a student’s internet network and the device they use to access online textbooks as well as webpages viewed, links clicked, keystrokes typed, and movement of their mouse on the screen, among other things. The company then shares some of that data with third parties for targeted advertising. For students who sign into Cengage websites with their social media accounts, the company collects additional information about them and their entire social networks.</p><p>\\\nNoah Apthorpe, an assistant professor of computer science at Colgate University, studies privacy and the implications of data collection in academia. He said students seem to be suffering the consequences of widespread data collection across the web.</p><p>\\\n“Once we become accustomed to an ecosystem where everything is collected, it both becomes harder to change and we become numb to it happening in the first place,” Apthorpe said. Learning management systems like Canvas collect more data about student behavior than educators have ever had access to, creating detailed profiles of individual students and new ways to label them. While Canvas is one of the most popular systems on the market, virtually all colleges use one and a variety of options have emerged to serve them, including Moodle, Blackboard, and Brightspace.</p><p>\\\nApthorpe said that because learning management systems track, down to the minute, when students submit assignments, professors may come to think of students as deadline pushers, for example, or those who get their work done early.</p><p>\\\n“You can imagine that having repercussions for students,” Apthorpe said.</p><p>\\\nStudents know their professors can see this data. Some who work or take care of children on top of going to school worry they will be seen as lazy or uncommitted for spending less time on their assignments than their peers.</p><p>\\\nNatividad said one of his professors told him he can see in Canvas whether students seem to log on together and complete work from the same location. Natividad became worried it would look like he was cheating if he simply studied and completed assignments with his peers. Now he and his friends go out of their way to avoid the appearance of impropriety, not wanting to be falsely accused. For them, that means staggering their log-ons to Canvas and accessing the internet through virtual private networks that obscure their location.</p><p>\\\nWhile Instructure insists its platform should not be used to detect cheating, its logs have led to such allegations. Seventeen medical students at Dartmouth <a href=\"https://www.nytimes.com/2021/05/09/technology/dartmouth-geisel-medical-cheating.html\">made national news</a> in 2021 when their professors accused them of accessing course materials in Canvas during an online exam. The logs, students argued, were wrong, and the university ultimately dropped the charges.</p><p>\\\nFor Natividad, stress about what could happen has taken its toll. Last year, he watched his grades in a computer science course slip after he stopped completing assignments because he didn’t want to use Canvas.</p><p>\\\n“It’s just really stressful,” he said.</p><p>Most concerning to Natividad is the parking enforcement at Mt. SAC, which last winter installed automated license plate readers. Instead of asking students to hang parking passes on their rearview mirrors, the college now relies on cameras mounted on three parking enforcement vehicles and 11 fixed cameras installed in the campus’s two garages. The cameras read license plates and alert officers if they spot a plate that doesn’t have a valid permit associated with it.</p><p>\\\nMt. SAC’s policy for its automated license plate reader says none of the information in the system can be sold and that it can only be shared or transferred after a request is made in writing and college officials approve it in writing.</p><p>But the college’s contract with T2 Systems, also obtained through a public records request, says the parking management company can store, back up, and archive content and use it to generate anonymized data, though the nature of that data is not made clear.</p><p>\\\nAutomated license plate readers have been the subject of controversy around the country. Fight for the Future, an activist organization that plans online protests to secure a future “where technology is a force for liberation, not oppression,” calls them “illegal dragnet surveillance” that violates individuals’ right to privacy.</p><p>\\\nNatividad requested information about T2 and couldn’t find out much. For months, he said, he was passed from one campus employee to another but got few concrete details about where the parking footage and data would be stored and who would have access to it.</p><p>\\\nMt. SAC’s police and campus safety department declined interview requests for this article. The college’s contract indicates license plate information and video footage are only stored if a campus police officer issues a ticket.</p><p>\\\nNatividad said some college employees suggested he take classes online if he didn’t like the new parking cameras. Since that would mean losing out on valuable in-person experiences and spending even more time on Canvas, he has found another, more expensive solution: quarters.</p><p>\\\nThe college has retained a number of metered parking spaces. They cost more than a parking pass and require a tedious amount of coordination to always have enough change on hand and run back and forth to add more time, but they don’t require Natividad to turn over personal information to yet another tech company to get a parking pass. Still, even these steps do not ensure his privacy while parking: His car remains in view of cameras mounted on Mt. SAC public safety vehicles. Should a camera read error ever mean Natividad’s car is mistaken for a stolen vehicle, <a href=\"https://www.aclu.org/news/privacy-technology/san-francisco-woman-pulled-out-car-gunpoint-because\">as happened to a San Francisco woman in 2009</a>, that routine scanning could make him a target.</p><p>\\\nStudents at Mt. SAC have rallied in recent weeks in support of Palestine and Natividad worries that records of who, exactly, was on campus during the hours the protest lasted might create problems for his peers. Students on other campuses have had <a href=\"https://truthout.org/articles/law-firms-rescind-job-offers-from-pro-palestine-students-at-harvard-columbia/\">job offers rescinded</a> and their names and faces <a href=\"https://www.axios.com/2023/10/12/harvard-students-doxxed-israel-palestine#\">published online</a> in connection to their support for Palestine.</p><p>\\\nAt Mt. SAC, there haven’t been such dramatic consequences for students, and few have joined Natividad’s fight for greater privacy on campus. In fact, as he has been asking questions and quietly advocating over the last year and a half, the two most common reactions he gets are surprise and apathy. Most people don’t think there are alternatives to the current state of data tracking and surveillance, or they don’t care to explore them. Natividad routinely hears that he shouldn’t worry. But he does. And not just for himself—for the entire student body.</p><p>\\\n“It just feels like our rights are being violated all the time,” he said.</p><p>On a recent Thursday, Natividad parked at the meter and met a friend in Mt. SAC’s student center. It’s one of the buildings on campus he doesn’t need to swipe his student ID to enter—and while it’s not as good a location for studying as other parts of campus, he likes that he can avoid creating a new data point in the college’s logs. When he goes to any tutoring centers on campus, including just to study, he can’t avoid it.</p><p>\\\nLogging student movement through card swipes is ubiquitous in higher education today. At Mt. SAC, Natividad was told the tutoring center uses this information to track how many students it supports so the college can apply for state grant money. College administrators did not respond to requests for comment about what else these logs are used for or how long they are stored.</p><p>Eric Natividad swipes his ID to access a tutoring center at Mt. San Antonio College. That swipe is logged and contributes to a digital profile of Natividad’s movements around campus. Credit: <a href=\"https://susanicatam.com/\">Susanica Tam</a></p><p>\\\nAt the University of Maryland, administrators considered using this data in the early days of COVID to know when wellness checks were in order. Joseph Gridley, the university’s chief data privacy officer, recounted the scenario during an October conference for IT professionals working in higher education. He said it seemed mildly creepy to send people to student dorm rooms to check on them after noting they hadn’t been to the dining halls in a certain number of days. But after surveying students, it became clear they didn’t mind and, in fact, only thought the university should wait five days before dispatching someone.</p><p>\\\nThe data collection, Gridley said, is happening. The question is whether universities should use it.</p><p>\\\nIt’s also not clear if they can keep sensitive information secure. The University of Michigan revealed at the end of October that a hack compromised personal information, including Social Security numbers and driver’s licenses, of <a href=\"https://www.detroitnews.com/story/news/local/michigan/2023/10/23/um-3rd-party-accessed-school-systems-personal-information-for-5-days/71292044007/\">230,000 people</a>. When a well-resourced institution known for its commitment to privacy is home to such a leak, Natividad wonders how long his data will be safe at his relatively under-resourced community college.</p><p>\\\nNatividad has spoken before Mt. SAC’s student government and tried to raise awareness about all the data that’s being collected. Mariah Moreno, a student senate chair at Mt. SAC, said while Natividad’s concerns have piqued the interest of some members of the campus community, more students would have to share them for the student government to consider taking action.</p><p>\\\nThat might only be a matter of time. Natividad also spoke with Max McCarthy Neal, a leader in the college’s Black Student Union, who told him to connect with other activism-oriented campus groups.</p><p>\\\n“It’s something that is affecting all of us and will continue to do so,” said McCarthy Neal.</p><p>\\\nNatividad has spent more than a year discussing his concerns with student leaders and college employees at all levels of the institution. He has braved sweaty palms and anxiety to speak at the college’s board of trustees meeting and the president’s open office hours. He has requested his data from tech companies, exercising his rights under the California Consumer Privacy Act.</p><p>\\\nAll of it has been a distraction from his studies. He is taking fewer classes to give himself time for this awareness-building. But he would prefer not to do any of it.</p><p>\\\n“I like just being a geeky computer guy,” Natividad said. “I want to be the stereotypical guy on his computer in his room that nobody really talks about that much.”</p><p>\\\nThe problem, he said, is that many of his peers have no idea about the extent to which their data is being collected and shared. And many of them have weighty commitments outside of their coursework as parents and providers in their families. Natividad feels responsible for stepping up, agitating both because he can and knows he should.</p><p>\\\nMcCarthy Neal decided to help after coming to the same conclusion.</p><p>\\\n“Due to the fact that we are a community college, most people are heads-down, in the books, do the work and move on to the next step,” McCarthy Neal said, whether that’s a transfer to a four-year school or a better job. “[They] don’t really care what’s going on here now.”</p><p>\\\nMcCarthy Neal hopes speaking out with Natividad and winning more students over to the cause will lead to greater power to opt out of data collection at Mt. SAC and more attention to student privacy generally.</p><p>\\\nBack in Mt. SAC’s student center, Natividad sits down with his friends to study; he accesses the school website and Canvas using a virtual private network. In addition to obscuring his location, the VPN encrypts his data, giving him a sense of protection from tracking.</p><p>\\\nThat tracking, he knows, can be extensive. A Markup analysis of Natividad’s network logs showed multiple analytics platforms tracking pageviews and clicks in Canvas and on the college website, including on a health center webpage about <a href=\"https://www.mtsac.edu/healthcenter/mentalhealth/coping-tips/anxiety-tips.html\">coping with anxiety</a> and a <a href=\"https://esars2012.mtsac.edu/appointments/dream/eSARS.asp?WCI=Init&amp;WCE=Settings\">counseling request form</a> for DACA students (who are protected from deportation because they immigrated to this country with their parents as young children). The platforms send analytics to Instructure, Google, and Facebook.</p><p>\\\nNatividad points to a <a href=\"https://themarkup.org/hello-world/2023/09/30/our-pixel-hunt-project-keeps-paying-dividends\">wave</a> of privacy <a href=\"https://themarkup.org/pixel-hunt/2022/12/02/meta-sued-for-collecting-financial-information-through-tax-filing-websites\">class-action</a><a href=\"https://themarkup.org/pixel-hunt/2022/09/19/meta-faces-mounting-questions-from-congress-on-health-data-privacy-as-hospitals-remove-facebook-tracker\">lawsuits</a> against companies sharing personally identifiable information with Facebook through a snippet of code known as a pixel.</p><p>\\\n“These companies are being sued for privacy violations, but we’re still using [the pixel] all over,” he said.</p><p>At some point this semester, Natividad may have to give up another type of personal information. Two of his courses are completely online, and the university has contracts with two companies that facilitate secure remote testing. If his professors require students to use these so-called e-proctoring tools, Natividad might have to give either Honorlock or Proctorio access to his laptop camera. While both companies say they do not use or store biometric data or match test-takers’ faces with an image database, they do run software to detect students’ eye movements and the presence of their faces. </p><p>\\\nIn its contract with Honorlock, which The Markup obtained through a public records request, Mt. SAC agreed to let the company use, publish, and sell aggregate data collected over the platform, facilitating the company’s ability to profit from students’ data.</p><p>\\\nE-proctoring tools faced a stiff backlash when schools closed during COVID and sent test-taking online. Fight for the Future called the tech “glorified spyware” in an online campaign seeking to <a href=\"https://www.baneproctoring.com\">ban its use</a> by colleges. <a href=\"https://cdt.org/insights/how-automated-test-proctoring-software-discriminates-against-disabled-students/\">Students with disabilities</a> faced more frequent flags for potential cheating because of hand, eye, and body movements the software algorithms said were abnormal. Dark-skinned students reported not being able to take exams because the software wouldn’t <a href=\"https://interactive.yr.media/has-virtual-proctoring-gone-too-far/\">register their faces</a> as being present.</p><p>\\\nThe programs’ failings fueled outrage and stress among students needing to take exams to progress toward their degrees or chosen careers.</p><p>\\\nAt Mt. SAC, McCarthy Neal dropped an online course last spring rather than use Proctorio. The professor told students they had to run the monitoring program every time they completed an assignment in the online workbook, something that felt overly invasive.</p><p>\\\nStudents on other campuses have fought back against the use of <a href=\"https://examsoft.com/es/biometric-consent/\">ExamSoft</a> and <a href=\"https://www.meazurelearning.com/privacy-policy\">ProctorU</a>, two other tools that collect biometric data as part of their e-proctoring, using facial recognition software to match the face in front of the camera with records of the student who is supposed to be there.</p><p>\\\nWhile Mt. SAC officials said the college doesn’t use it, some universities have begun experimenting with facial recognition technology for <a href=\"https://www.merrimack.edu/academics/engineering-and-computational-sciences/computer-and-data-sciences/student-projects/attendance-taker-via-facial-recognition-app/\">attendance logs</a> and <a href=\"https://www.insidehighered.com/news/2020/02/21/ucla-drops-plan-use-facial-recognition-security-surveillance-other-colleges-may-be\">campus security</a>, and researchers are testing it as a method for measuring <a href=\"https://arxiv.org/pdf/1909.12913.pdf\">student engagement</a>.</p><p>\\\nLeila Nashashibi, a Fight for the Future campaigner, said a major concern with facial recognition technology is that it dissuades social and protest movements.</p><p>\\\n“One of the most successful strategies for quelling dissent is to make people feel like they have no privacy,” she said.</p><p>\\\nWhen facial recognition systems capture data, they tend to store it in the cloud where, Nashashibi points out, it is vulnerable to being hacked, stolen, or abused. When people get their credit cards stolen, they can get new cards and new numbers; when their biometric information is stolen, they can’t change their faces. Nashashibi sees the use of facial recognition for things like attendance or campus security as a slippery slope.</p><p>\\\n“As it spreads in these seemingly convenient and innocuous use cases, it’s desensitizing people to the technology, which is actually invasive and dangerous,” she said.</p><p>Natividad has had a hard time convincing his fellow students at Mt. SAC that it’s worth their time to speak out against data collection in higher education, or even to demand more transparency. But on other campuses, privacy concerns have contributed to new tools and staff positions.</p><p>\\\nAt the University of Michigan, the <a href=\"https://safecomputing.umich.edu/viziblue\">ViziBLUE</a> website explains how the university collects, uses, and shares 18 different types of data, including that related to academics, admissions, housing, and use of campus Wi-Fi. Virtually no other university has anything like it. At UC San Diego, where Pegah Parsi became the inaugural chief privacy officer in 2018, a team is working on something similar but running into challenges of even identifying the scope of data collection. Parsi’s department has started by focusing on data collected and used by offices of advancement, admissions, and financial aid—the “heavy hitters,” as she calls them—and then plans to work through smaller, more grassroots sources of data collection on campus.</p><p>\\\n“We haven’t had regulator scrutiny, to a great extent, on our privacy practices or our data practices, so our data really do live all over the place, and no one quite knows who has what,” Parsi said.</p><p>Mariah Moreno, the student government senate chair, hadn’t spent any time thinking about Canvas’s data collection and use policies before Natividad brought it up.</p><p>\\\n“With this day and age, it had kind of been normalized, so I hadn’t felt that concern related to myself as a student,” she said.</p><p>\\\nHaving now acknowledged the privacy concerns, she still doesn’t think it makes sense to stop using Canvas or even to use it any differently. On her path to a political science degree and eventually law school, Moreno sees herself as having two options: do the assignments as the professors assign them—in Canvas—or not do the assignments. And she chooses the former.</p><p>\\\nBut privacy advocates say there should be a third choice that gives students more control over their own data.</p><p>\\\nKyle Jones, an associate professor at Indiana University—Indianapolis who studies information ethics and data mining in higher education, is among those arguing that higher education institutions should be considered <a href=\"https://asistdl.onlinelibrary.wiley.com/doi/10.1002/asi.24327\">data fiduciaries</a>, charged with acting in the best interests of students when collecting and using their data. Fiduciary duties are most commonly connected to managing someone else’s money, and they bring legal responsibilities to make decisions solely for <a href=\"https://www.consumerfinance.gov/ask-cfpb/what-is-a-fiduciary-en-1769/\">the other person’s benefit</a>.</p><p>\\\nParsi, too, encourages her colleagues to think of their role as data fiduciaries. Much more common, she said, is for higher education institutions to think of themselves as stewards of student data, which connotes a lower standard of responsibility to students. For Parsi, it’s past time for change.</p><p>\\\n“Our use of someone’s personal data, at the end of the day, should benefit them,” she said, “not just somebody else or some other thing.”</p>","contentLength":27984,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bug Hits Some Threads Users: Their Words Echoed by All Other Users","url":"https://tech.slashdot.org/story/25/06/21/018232/bug-hits-some-threads-users-their-words-echoed-by-all-other-users?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750516440,"author":"EditorDavid","guid":164267,"unread":true,"content":"Threads now has 350 million users — but this week a strange bug affected some Threads accounts (on both desktop and mobile). \"One user's post will get repeated over and over again...\" explains TechCrunch, \"as though every user on your feed is saying the same thing.\"\n\n\n\"Siri, unsubscribe me from 2025,\" one Threads user wrote, per a screenshot from social media expert Alexa Heinrich. But then, everyone else on Heinrich's feed appeared to be echoing the same cheugy joke... \n\nWhile it's not yet clear what caused the bug, Meta Communications Director Andy Stone responded to app researcher Jane Manchun Wong's post about the issue. \"Whoops, well that clearly shouldn't have happened! We're working on getting it fixed now,\" Stone said. \n\nI thought the bug was only affecting user feeds (and not replies). But either way, Wong came up with the perfect comeback. \n\n\"Whoops, well that clearly shouldn't have happened! We're working on getting it fixed now.\"","contentLength":957,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Connect an Express Application to Postgres Using Sequelize","url":"https://hackernoon.com/how-to-connect-an-express-application-to-postgres-using-sequelize?source=rss","date":1750514404,"author":"Michael Ikoko","guid":164331,"unread":true,"content":"<p>PostgreSQL (shortened as Postgres) is one of the most used databases in building software applications. Postgres is a general-purpose, open-source, object-relational database management system (RDBMS). One of the advantages of using Postgres is its support for both relational (SQL) and non-relational (NoSQL) querying.</p><p>\\\nOne way of connecting a database to a web application is through the use of an ORM (Object Relational Mapper). An ORM acts as a layer of communication between your application and the database. The goal of this tutorial is to explain how you can use Postgres in your Express application through the Sequelize ORM.</p><p>\\\nThe Sequelize ORM is described as:</p><blockquote><p>A modern TypeScript and Node.js ORM for Oracle, Postgres, MySQL, MariaDB, SQLite, and SQL Server, and more. — <a href=\"https://sequelize.org/\">Sequelize Documentation</a></p></blockquote><p>\\\nYou will build a simple task management API. The API will be able to create, list, update the completion status, and delete tasks.</p><p>\\\nThis tutorial is the first in an upcoming series of tutorials focused on using relational databases in Express using Sequelize. In the upcoming tutorials, you’ll explore database seeding, migrations, and associations in Sequelize.</p><p>To proceed with this tutorial, you’ll need the following:</p><ul><li>A text editor (e.g., VS Code)</li><li>An API client for testing the endpoints (e.g., Postman)</li><li>Node.js is installed on your computer</li><li>Basic knowledge of Express</li><li>An instance of Postgres running either locally or remotely</li></ul><p>We’ll begin by setting up appropriate files and directories for creating an Express application and installing the needed packages. The commands used are only applicable to a Linux terminal.</p><ol><li><p>Create the project directory:</p></li><li><p>Navigate to the project directory:</p></li><li><p>Initialize the NPM package by running the following command to create a   file with default settings:</p></li><li><p>Install Express and other core dependencies:</p><pre><code>   npm install express express-async-errors dotenv &amp;&amp; npm install nodemon --save-dev\n</code></pre></li><li><p>Install Postgres driver for Node.js:</p></li><li><p>In the root directory, create the  and folders:</p></li><li><p>In the root directory, create a  file, which will contain the server’s port number and the database URL of any Postgres instance:</p><pre><code>PORT=5000\nDATABASE_URL=postgres://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;database&gt;\n</code></pre></li><li><p>In the root directory, create the  file, which is the application entry point:</p></li><li><p>Set up the command to run the local development server by editing the  object in :</p><pre><code>{\n    //…\n    \"scripts\": {\n        \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\",\n        \"dev\": \"nodemon index.js\",\n        \"start\": \"node index.js\"\n    },\n    //…\n}\n</code></pre></li></ol><p>The project folder structure should look like this:</p><p>Create two files in the  directory:  and </p><h3>Loading Environment Variables</h3><p>In the  file, load the environment variables from the  file using the  package. Then export the  and  variables so that they can be accessed in other parts of the application.</p><p>\\\nThe  file should have the following contents:</p><pre><code>require('dotenv').config()\n\nconst PORT = process.env.PORT || 3000\nconst DATABASE_URL = process.env.DATABASE_URL\n\nmodule.exports = {\n    PORT,\n    DATABASE_URL\n}\n</code></pre><h3>Creating Sequelize Instance</h3><p>In the  file, create a Sequelize instance. You can create a Sequelize instance by passing the database connection URI (stored in ) to the Sequelize constructor. Then you create a function  that will test the connection to the database by calling the  function. Lastly, you export the  function and the Sequelize instance.</p><p>\\\nThe  file should have the following contents:</p><pre><code>const Sequelize = require(\"sequelize\");\nconst { DATABASE_URL } = require(\"./config\");\n\nconst sequelize = new Sequelize(DATABASE_URL)\n\nconst connectToDB = async () =&gt; {\n    try {\n        await sequelize.authenticate()\n        console.log(\"Database connection established successfully.\")\n    } catch (error) {\n        console.log(\"Unable to connect to the database:\", error)\n        return process.exit(1)\n    }\n    return null\n}\n\nmodule.exports = {\n    connectToDB,\n    sequelize\n}\n</code></pre><p>A Sequelize model is a representation of a table in the database. You can define the  model by extending the Sequelize  class and calling the <code>Model.init(attributes, options)</code> function.</p><p>\\\nIn the  directory, create the  file with the following contents:</p><pre><code>const {Model, DataTypes} = require(\"sequelize\")\nconst {sequelize} = require(\"../utils/db\")\n\nclass Task extends Model {}\n\nTask.init({\n    id: {\n        type: DataTypes.INTEGER,\n        autoIncrement: true,\n        primaryKey: true\n    },\n    title: {\n        type: DataTypes.STRING,\n        allowNull: false\n    },\n    completed: {\n        type: DataTypes.BOOLEAN,\n        defaultValue: false\n    }\n}, {\n    sequelize,\n    modelName: \"Task\",\n    timestamps: true,\n    underscored: true,\n    defaultScope: {\n        attributes: {\n            exclude: [\"createdAt\", \"updatedAt\"]\n        }\n    }\n})\n\nTask.sync()\n\nmodule.exports = Task\n</code></pre><p>The  parameter defines the structure of the  table in the database. The  model has three attributes:</p><ul><li>: An integer field which is an auto-increasing primary key used to uniquely identify each record.</li><li>: A string field that represents the name of the task.</li><li>: The  field has a boolean value that indicates whether the task has been done.</li></ul><p>\\\nThe  parameter configures how Sequelize handles the model. The  model has the following options:</p><ul><li>: The Sequelize instance created earlier in .</li><li>: The name of the table created in the database.</li><li>: When set to , adds the  and  fields automatically to the model.</li><li>: When set to  , converts camel Case fields to snake case in the database.</li><li>: Excludes certain attributes by default when querying.</li></ul><p>\\\nThe  function synchronizes the model with the database by creating the table if the table does not exist. However, you should note that synchronization should be done using migrations.</p><h2>Creating the Express Server</h2><p>Finally, you put it all together by creating the Express server. In the  file, you set up the necessary middleware, define the API endpoint routes, and run the express server.</p><p>\\\nThe  function is responsible for initializing the Express server. The  function first tests the connection to the database by calling the  function. If the connection is successful, it starts the Express server, which listens on the specified port.</p><p>\\\nThe  file has the following contents:</p><pre><code>require(\"express-async-errors\");\nconst express = require(\"express\");\nconst app = express();\nconst { PORT } = require(\"./utils/config\");\nconst { connectToDB } = require(\"./utils/db\");\nconst Task = require(\"./models/task\");\n\n// middlewares\napp.use(express.json());\n\n// routes\napp.get(\"/api/tasks\", async (req, res) =&gt; {\n  const tasks = await Task.findAll();\n  res.json({\n    message: \"List of tasks\",\n    tasks: tasks,\n  });\n});\n\napp.post(\"/api/tasks\", async (req, res) =&gt; {\n  const { title } = req.body;\n  const task = await Task.create({ title });\n  res.status(201).json({\n    message: \"Task created successfully\",\n    task,\n  });\n});\n\napp.patch(\"/api/tasks/:id/toggle-completed\", async (req, res) =&gt; {\n  const { id } = req.params;\n  const task = await Task.findByPk(id);\n  if (!task) {\n    return res.status(404).json({ message: \"Task not found\" });\n  }\n  task.completed = !task.completed;\n  await task.save();\n  res.json({\n    message: task.completed\n      ? \"Task marked as completed\"\n      : \"Task marked as not completed\",\n    task,\n  });\n});\n\napp.delete(\"/api/tasks/:id\", async (req, res) =&gt; {\n  const { id } = req.params;\n  const task = await Task.findByPk(id);\n  if (!task) {\n    return res.status(404).json({ message: \"Task not found\" });\n  }\n  await task.destroy();\n  res.json({\n    message: \"Task deleted successfully\",\n  });\n});\n\nconst start = async () =&gt; {\n  try {\n    await connectToDB();\n    app.listen(PORT, console.log(`Server is running on port ${PORT}`));\n  } catch (error) {\n    console.error(error);\n    process.exit(1);\n  }\n};\n\nstart();\n</code></pre><p>You can now proceed to test the API endpoints:</p><ol><li><p>Create a new task—:</p></li><li><p>List all tasks—:</p></li><li><p>Toggle completion status—<code>PATCH /api/tasks/:id/toggle-completed</code>:</p></li><li><p>Delete a Task—:</p></li></ol><p>You now know how to connect an Express application to a Postgres database using Sequelize. You built a simple task manager API, and in the process, you configured Sequelize, connected Sequelize to a Postgres instance, defined the  model, and created the API endpoints.</p><p>\\\nCurrently, the controller logic is written in the   file for simplicity. In upcoming tutorials, we’ll refactor this codebase into a more scalable structure using controllers, routers, and Sequelize migrations.</p><p>\\\nFor further reading, you should go through the <a href=\"https://sequelize.org/docs/v6/\">Sequelize documentation</a> to learn more about model querying, validations, associations, and more.</p><p>\\\nYou can find the complete source code for this tutorial on <a href=\"https://github.com/michaelikoko/tasks-manager-api\">GitHub</a>.</p>","contentLength":8622,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ChatGPT May Be Linked to 'Cognitive Debt,' New Study Finds","url":"https://www.404media.co/is-chatgpt-rotting-our-brains-new-study-suggests-it-does/","date":1750510818,"author":"Becky Ferreira","guid":164220,"unread":true,"content":"<img src=\"https://www.404media.co/content/images/2025/06/1613px-Anaconda_al_acecho.jpg\" alt=\"ChatGPT May Be Linked to 'Cognitive Debt,' New Study Finds\"><p>Welcome back to the Abstract!&nbsp;</p><p>This week, we’re moving in next to anacondas, so watch your back and lock the henhouse. Then, parenthood tips from wild baboons, the “cognitive debt” of ChatGPT, a spaceflight symphony, and a bizarre galaxy that is finally coming into view.&nbsp;</p><h3><strong>When your neighbor is an anaconda</strong></h3><p>Anacondas are one of the most spectacular animals in South America, inspiring countless&nbsp; myths and legends. But these iconic boas, which can grow to lengths of 30 feet, are also a pest to local populations in the Amazon basin, where they prey on livestock.&nbsp;</p><p>To better understand these nuanced perceptions of anacondas, researchers interviewed more than 200 residents of communities in the várzea regions of the lower Amazon River about their experiences with the animals. The resulting study is packed with amazing stories and insights about the snakes, which are widely reviled as thieves and feared for their predatory prowess.</p><p>“Fear of the anaconda (identified in 44.5% of the reports) is related to the belief that it is a treacherous and sly animal,” said co-authors led by Beatriz Nunes Cosendey of the Mamirauá Sustainable Development Reserve and Juarez Carlos Brito Pezzuti of the Federal University of Pará.</p><p>“The interviewees convey that the anaconda is a silent creature that arrives without making any noise, causing them to feel uneasy and always vigilant during fishing…with the fear of having their canoe flooded in case of an attack,” the team added. “Some dwellers even reported being more afraid of an anaconda than of a crocodile because the latter warns when it is about to attack.”</p><p>But while anacondas are eerily stealthy, they also have their derpy moments. The snakes often break into chicken coops to feast on the poultry, but then get trapped because their engorged bodies are too big to escape through the same gaps they used to enter.&nbsp;&nbsp;</p><p>“Dwellers expressed frustration at having to invest time and money in raising chickens, and then lose part of their flock overnight,” the team said. “One interviewee even mentioned retrieving a chicken from inside an anaconda’s belly, as it had just been swallowed and was still fresh.”</p><p>Overall, the new study presents a captivating portrait of anaconda-human relations, and concludes that “the anaconda has lost its traditional role in folklore as a spiritual and mythological entity, now being perceived in a pragmatic way, primarily as an obstacle to free-range poultry farming.”</p><h3><strong>Monkeying around with Dad&nbsp;&nbsp;</strong></h3><p>Coming off of Father’s Day, here is a story about the positive role that dads can play for their daughters—for baboons, as well as humans. A team tracked the lifespans of 216 wild female baboons in Amboseli, Kenya, and found that subjects who received more paternal care had significantly better outcomes than their peers.</p><p>“We found that juvenile female baboons who had stronger paternal relationships, or who resided longer with their fathers, led adult lives that were 2–4 years longer than females with weak or short paternal relationships,” said researchers led by David Jansen of the Midwest Center of Excellence for Vector-Borne Disease. “Because survival predicts female fitness, fathers and their daughters may experience selection to engage socially and stay close in daughters’ early lives.”</p><p>This all reminds me of that old episode of  where <a href=\"https://www.youtube.com/watch?v=Q--1R4pK5RY&amp;ref=404media.co\"><u>Lisa calls Homer a baboon</u></a>. While Homer was clearly hurt, it turns out that baboons might not be the worst animal-based insult for a daughter to throw at her dad.&nbsp;&nbsp;</p><h3><strong>A case for staying ChatGPT-Free</strong></h3><p>ChatGPT may hinder creativity and learning skills in students who use it to write essays, relative to those who didn’t, according to an exhaustive new preprint study posted on arXiv. This research has yet not been peer-reviewed, and has a relatively small sample size of 54 subjects, but it still contributes to <a href=\"https://www.404media.co/teachers-are-not-ok-ai-chatgpt/\"></a> about the cognitive toll of AI assistants.&nbsp;</p><p>Researchers led by Nataliya Kosmya of the Massachusetts Institute of Technology divided the subjects — all between 18 and 39 years old — into three groups wrote SAT essays using OpenAI’s ChatGPT (LLM group), Google’s search engine, or with no assistance (dubbed “Brain-only”).</p><p>“As demonstrated over the course of 4 months, the LLM group's participants performed worse than their counterparts in the Brain-only group at all levels: neural, linguistic, scoring,” the team said. “The LLM group also fell behind in their ability to quote from the essays they wrote just minutes prior.”</p><p>When I asked ChatGPT for its thoughts on the study, it commented that “these results are both interesting and plausible, though they should be interpreted cautiously given the early stage of the research and its limitations.” It later suggested that “cognitive offloading is not always bad.”&nbsp;</p><p>Even scientists can’t resist evocative language now and then—we’re all only human. Case in point: A new study likens the history of Asia’s space industry to “a musical concert” and then really runs with the metaphor.</p><p>“The region comprises a diverse patchwork of nations, each contributing different instruments to the regional space development orchestra,” said researchers led by Maximilien Berthet of the University of Tokyo. “Its history consists of three successive movements” starting with “the US and former USSR setting the tone for the global space exploration symphony” and culminating with modern Asian spaceflight as “a fast crescendo in multiple areas of the region driven in part by private initiative.”</p><p>Talk about a space opera. The rest of the study provides a comprehensive review of Asian space history, but I cannot wait for the musical adaptation.</p><h3><strong>Peekaboo! I galax-see you</strong></h3><p>In 2001, astronomer Bärbel Koribalski spotted a tiny galaxy peeking out from behind a bright foreground star that had obscured it for decades, earning it the nickname the “Peekaboo Galaxy.” Situated about 22 million light-years from the Milky Way, this strange galaxy is extremely young and metal-poor, resembling the universe’s earliest galaxies.</p><p>A new study confirms Peekaboo as “the lowest-metallicity dwarf in the Local Volume,” a group of roughly 500 galaxies within 36 million light-years of Earth.</p><p>“This makes the Peekaboo dwarf one of the most intriguing galaxies in the Local Volume,” said co-authors Alexei Kniazev of the South African Astronomical Observatory and Simon Pustilnik of the Special Astrophysical Observatory of the Russian Academy of the Sciences. “It deserves intensive, multi-method study and is expected to significantly advance our understanding of the early universe’s first building blocks.”</p><p>Thanks for reading! See you next week. </p><p><em>Update: The original headline for this piece was \"Is ChatGPT Rotting Our Brains? New Study Suggests It Does.\" We've updated the headline to \"ChatGPT May Create 'Cognitive Debt,' New Study Finds\" to match the terminology used by the researchers.</em></p>","contentLength":6977,"flags":null,"enclosureUrl":"https://www.404media.co/content/images/2025/06/1613px-Anaconda_al_acecho.jpg","enclosureMime":"","commentsUrl":null},{"title":"The Best AI Coding Tools You Can Use Right Now","url":"https://spectrum.ieee.org/best-ai-coding-tools","date":1750510803,"author":"Matthew S. Smith","guid":164218,"unread":true,"content":"<p>Cursor and Claude Code are among the options worth your time</p>","contentLength":60,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MTA4MTAyNC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTgwMjk1MzI3MX0.XQ01vRJsHmCTE6_IN17xaXv9OveMhv9laDrP6yiLLBg/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Intel Will Outsource Marketing To Accenture and AI, Laying Off Its Own Workers","url":"https://slashdot.org/story/25/06/21/0251208/intel-will-outsource-marketing-to-accenture-and-ai-laying-off-its-own-workers?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750510800,"author":"BeauHD","guid":164221,"unread":true,"content":"Intel is outsourcing much of its marketing work to Accenture, \"as new CEO Lip-Bu Tan works to slash costs and improve the chipmaker's operations,\" reports OregonLive. From the report: The company said it believes Accenture, using artificial intelligence, will do a better job connecting with customers. It says it will tell most marketing employees by July 11 whether it plans to lay them off. \"The transition of our marketing and operations functions will result in significant changes to team structures, including potential headcount reductions, with only lean teams remaining,\" Intel told employees in a notice describing its plans. The Oregonian/OregonLive reviewed a copy of the material.\n \nIntel declined to say how many workers will lose their jobs or how many work in its marketing organization, which employs people at sites around the globe, including in Oregon. But it acknowledged its relationship with Accenture in a statement to The Oregonian/OregonLive. \"As we announced earlier this year, we are taking steps to become a leaner, faster and more efficient company,\" Intel said. \"As part of this, we are focused on modernizing our digital capabilities to serve our customers better and strengthen our brand. Accenture is a longtime partner and trusted leader in these areas and we look forward to expanding our work together.\"","contentLength":1341,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ubuntu 25.10 Planning To Raise RISC-V Support Baseline To RVA23 Profile","url":"https://www.phoronix.com/news/Ubuntu-25.10-To-Require-RVA23","date":1750503318,"author":"Michael Larabel","guid":164191,"unread":true,"content":"<article>Ahead of the all-important Ubuntu 26.04 LTS cycle, Canonical is looking to raise the required RISC-V ISA baseline for its Ubuntu 25.10 release due out later this year...</article>","contentLength":169,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GNOME Fixes Years-Old Bug Of Trash Not Always Being Properly Emptied","url":"https://www.phoronix.com/news/GNOME-Trash-Years-Old-Bug","date":1750501882,"author":"Michael Larabel","guid":164165,"unread":true,"content":"<article>This Week in GNOME is out with its latest issue that outlines some UI progress made as well as addressing an aging GNOME bug that could result in not all files/directories being properly removed when emptying the Trash from the GNOME desktop...</article>","contentLength":244,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"XLibre 25.0 Released As Inaugural Version Of X.Org Server Fork","url":"https://www.phoronix.com/news/XLibre-25.0-Released","date":1750501099,"author":"Michael Larabel","guid":164164,"unread":true,"content":"<article>XLibre 25.0 was just released as the first tagged release of this recent X.Org Server fork...</article>","contentLength":93,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"KDE Plasma 6.4 Is Looking To Be In Good Shape, Fewer Bugs","url":"https://www.phoronix.com/news/KDE-Plasma-6.4-First-Week","date":1750500297,"author":"Michael Larabel","guid":164163,"unread":true,"content":"<article>KDE developer Nate Graham is out with his weekly blog post summarizing all of the interesting KDE Plasma developments for the past week. Notable this week was the debut of Plasma 6.4 stable and from early user feedback appears to be in good shape...</article>","contentLength":249,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"YouTube Is Hiding An Excellent, Official High-Speed Pac-Man Mod In Plain Sight","url":"https://games.slashdot.org/story/25/06/21/0257244/youtube-is-hiding-an-excellent-official-high-speed-pac-man-mod-in-plain-sight?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750500000,"author":"BeauHD","guid":164166,"unread":true,"content":"YouTube is quietly hosting Pac-Man Superfast within its \"Playables\" section. \"You'd be forgiven for not knowing about YouTube Playables,\" writes Ars Technica's Kyle Orland. \"Few seemed to note its official announcement last year as a collection of free-to-play web games built for the web using standard rendering APIs.\"\n \n\"The seeming competitor to Netflix's mobile gaming offerings is still described in an official FAQ as 'an experimental feature rolled out to select users in eligible countries/regions,' which doesn't make this post-Stadia gaming effort seem like a huge priority for Google.\" From the report: \nWeird origins aside, Pac-Man Superfast pretty much delivers what its name promises. While gameplay starts at an \"Easy\" speed that roughly matches the arcade original, the speed of both Pac-Man and the ghosts is slightly increased every few seconds (dying temporarily reduces the speed to a lower level). After a few minutes, you're advancing past the titular \"Super Fast\" speed to extreme reflex-testing speeds like Crazy, Insane, Maniac, and a final test that's ominously named \"Doom.\"\n \nThose who've played the excellent Pac-Man Championship Edition series will be familiar with the high-speed vibe here, but Pac-Man Superfast remains focused on the game's original maze and selection of just four ghosts. That means old-school strategies for grouping ghosts together and running successful patterns through the narrow corridors work in similar ways here. Successfully executing those patterns becomes a tense battle of nerves here, though, requiring multiple direction changes every second at the highest speeds. While the game will technically work with swipe controls on a smartphone or tablet, high-level play really requires the precision of a keyboard via a desktop/laptop web browser (we couldn't get the game to recognize a USB controller, unfortunately).\n \nAs exciting as the high-speed maze gameplay gets, though, Pac-Man Superfast is hampered by a few odd design decisions. The game ends abruptly after just 13 levels, for instance, making it impossible to even attempt the high-endurance 256-level runs that Pac-Man is known for. The game also throws an extra life at you every 5,000 points, making it relatively easy to brute force your way to the end as long as you focus on the three increasingly high-point-value items that appear periodically on each stage. Despite this, the game doesn't give any point reward for unused extra lives or long-term survival at high speeds, limiting the rewards for high-level play. And the lack of a built-in leaderboard makes it hard to directly compare your performance to friends and/or strangers anyway.","contentLength":2674,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Macron Says Europe Must Become 'Space Power' Again","url":"https://science.slashdot.org/story/25/06/21/0242226/macron-says-europe-must-become-space-power-again?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750489200,"author":"BeauHD","guid":164087,"unread":true,"content":"French President Emmanuel Macron urged Europe to reassert itself as a global space power, warning that France risks being sidelined in the low Earth orbit satellite market dominated by players like SpaceX and China. Phys.Org reports: Macron spoke at the Paris Air Show in Le Bourget outside the French capital a day after France more than doubled its stake in satellite operator Eutelsat, the EU rival to Elon Musk's Starlink. Macron called for more investment as the European space industry struggles to remain competitive in the face of US and Chinese rivals. \"SpaceX has disrupted the market, Amazon is also getting involved. China is not far behind, and I think we all need to be very clear-headed,\" Macron said. Europe must become \"a space power once again, with France at its heart,\" he said. He warned that Europeans were \"on the verge of being completely\" squeezed out of the low Earth orbit (LEO) satellite constellation market.\n \nMacron said France and its partners should not be reliant on non-European constellations in low orbit, calling it \"madness.\" He called non-European players to team up with France. \"This must be the solution for our major strategic partners in the Gulf, India, Canada and Brazil,\" he said. \"We really need to succeed in increasing our collective investment effort,\" Macron added, noting the importance of private investors and public-private collaboration. He also said France planned to organize a space summit in early 2026 to \"mobilize our public and private partners across the globe.\"","contentLength":1528,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The TechBeat: This Skill Gap Is Blocking Your Career (And It Has Nothing to Do with AI) (6/21/2025)","url":"https://hackernoon.com/6-21-2025-techbeat?source=rss","date":1750486260,"author":"Techbeat","guid":164187,"unread":true,"content":"<p>By <a href=\"https://hackernoon.com/u/dexrank\">@dexrank</a> [ 12 Min read ] \n Bitcoin, combined with the Lightning Network, will become the foundational infrastructure for the future of decentralized AI-powered financial services. <a href=\"https://hackernoon.com/bitcoin-led-defai-model-offers-regulatory-cost-advantages\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/olenamostepan\">@olenamostepan</a> [ 5 Min read ] \n Discover how 404 error pages evolved from technical glitches to powerful UX and branding tools that guide, engage, and delight users. <a href=\"https://hackernoon.com/error-pages-through-the-ages-how-smart-brands-make-wrong-turns-feel-right\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/wassimchegham\">@wassimchegham</a> [ 4 Min read ] \n Coordinate multiple AI agents and MCP servers (written in Java, .NET, Python and TypeScript) with LlamaIndex.TS and Azure AI Foundry. <a href=\"https://hackernoon.com/introducing-a-flagship-mcp-sample-app-powered-by-azure-ai-foundry-and-llamaindexts\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ariophil\">@ariophil</a> [ 4 Min read ] \n The web is filled with broken links and broken dreams… AR.IO has built ArNS to put an end to this misery <a href=\"https://hackernoon.com/ario-built-arns-so-you-never-lose-a-website-ever\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/drewchapin\">@drewchapin</a> [ 3 Min read ] \n New MCP tools enable programmatic SEO that’s actually useful, combining context and your knowledge base to create scalable, high-quality content. <a href=\"https://hackernoon.com/ai-tools-can-now-write-like-youheres-how-that-changes-everything\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/hackernooncontests\">@hackernooncontests</a> [ 2 Min read ] \n Write about how GetBlock simplifies full node hosting for a chance to win from $5,000 in the Web3 Writing Contest. Use this template to start. <a href=\"https://hackernoon.com/answer-to-win-your-share-of-$5000-how-does-getblock-simplify-full-node-hosting\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/jackborie\">@jackborie</a> [ 4 Min read ] \n GPS powers everything from farming to finance—but it's shockingly fragile. Discover why losing it could cripple society—and what we must do to prepare.  <a href=\"https://hackernoon.com/everything-you-trust-is-built-on-gps-thats-a-huge-problem\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/terminal\">@terminal</a> [ 5 Min read ] \n Learn how to install and use Hydra in Termux for efficient password cracking and security testing on your Android device.  <a href=\"https://hackernoon.com/turn-your-android-into-a-hacking-machine-hydra-termux-explained\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/sannis\">@sannis</a> [ 2 Min read ] \n Learn how to choose the right numeric data types in MySQL, from integers and decimals to floating-point and bit fields. This guide covers common pitfalls, best  <a href=\"https://hackernoon.com/navigating-mysql-numeric-data-types\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/turingcom\">@turingcom</a> [ 3 Min read ] \n AI-driven hiring is booming across industries. Here's how engineers can upskill, adapt, and stay ahead in the era of genAI and machine learning. <a href=\"https://hackernoon.com/ai-hiring-is-exploding-wall-street-led-the-charge-now-everyones-building-in-house\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/udacity\">@udacity</a> [ 2 Min read ] \n Weak interview skills are holding back 8 in 10 tech workers. <a href=\"https://hackernoon.com/this-skill-gap-is-blocking-your-career-and-it-has-nothing-to-do-with-ai\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/OlgaTitova\">@OlgaTitova</a> [ 7 Min read ] \n Latest research reveals AI companions can reduce loneliness and build social skills—but only with ethical design. A guide for developers and users.  <a href=\"https://hackernoon.com/addicted-to-your-ai-new-research-warns-of-social-reward-hacking\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/badmonster0\">@badmonster0</a> [ 5 Min read ] \n Automatically infer and manage Qdrant schemas with CocoIndex's declarative dataflow. No manual setup needed. <a href=\"https://hackernoon.com/this-open-source-tool-could-save-your-data-team-hundreds-of-hours\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mediabias\">@mediabias</a> [ 6 Min read ] \n Systematic review shows how bias and poor methodology limit ML models used to detect depression through social media posts. <a href=\"https://hackernoon.com/can-ai-tell-when-youre-depressed\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/vladyslav_chekryzhov\">@vladyslav_chekryzhov</a> [ 25 Min read ] \n Build production-ready LLM agents. Learn 15 principles for stability, control, and real-world reliability beyond fragile scripts and hacks. <a href=\"https://hackernoon.com/stop-prompting-start-engineering-15-principles-to-deliver-your-ai-agent-to-production\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/textgeneration\">@textgeneration</a> [ 3 Min read ] \n This section highlights vAttention's ability to add dynamic memory allocation support to unmodified FlashAttention and FlashInfer prefill kernels <a href=\"https://hackernoon.com/vattention-performance-and-portability-for-llm-prefill-phase\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/largemodels\">@largemodels</a> [ 2 Min read ] \n This table evaluates the impact of multi-token prediction on Llama 2 fine-tuning, suggesting that it does not significantly improve performance on various tasks <a href=\"https://hackernoon.com/llama-2-finetuning-results-multi-token-prediction-on-coding-benchmarks\">Read More.</a></p>","contentLength":3026,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SoftBank's Son Pitches $1 Trillion Arizona AI Hub","url":"https://news.slashdot.org/story/25/06/20/2212217/softbanks-son-pitches-1-trillion-arizona-ai-hub?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750476600,"author":"BeauHD","guid":164002,"unread":true,"content":"An anonymous reader quotes a report from Reuters: SoftBank Group founder Masayoshi Son is envisaging setting up a $1 trillion industrial complex in Arizona that will build robots and artificial intelligence, Bloomberg News reported on Friday, citing people familiar with the matter. Son is seeking to team up with Taiwan Semiconductor Manufacturing Co for the project, which is aimed at bringing back high-end tech manufacturing to the U.S. and to create a version of China's vast manufacturing hub of Shenzhen, the report said.\n \nSoftBank officials have spoken with U.S. federal and state government officials to discuss possible tax breaks for companies building factories or otherwise investing in the industrial park, including talks with U.S. Secretary of Commerce Howard Lutnick, the report said. SoftBank is keen to have TSMC involved in the project, codenamed Project Crystal Land, but it is not clear in what capacity, the report said. It is also not clear the Taiwanese company would be interested, it said. TSMC is already building chipmaking factories in the U.S. with a planned investment of $165 billion. Son is also sounding out interest among tech companies including Samsung Electronics, the report said.\n \nThe plans are preliminary and feasibility depends on support from the Trump administration and state officials, it said.\nA commitment of $1 trillion would be double that of the $500 billion \"Stargate\" project which seeks to build out data centre capacity across the U.S., with funding from SoftBank, OpenAI and Oracle.","contentLength":1542,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Buc-ee’s Sues Parody Apparel Shop For Parodying Its Brand","url":"https://www.techdirt.com/2025/06/20/buc-ees-sues-parody-apparel-shop-for-parodying-its-brand/","date":1750473540,"author":"Dark Helmet","guid":163990,"unread":true,"content":"<p>A couple of weeks back, we discussed famed southern convenience store chain Buc-ee’s and its penchant for initiating all kinds of trademark related <a href=\"https://www.techdirt.com/2025/05/16/buc-ees-gas-station-chain-is-becoming-the-monster-energy-of-gas-stations-for-trademark-bullying/\">threats and lawsuits</a>. While we talk about this sort of thing a lot around here, the company’s actions have been particularly silly. When taken in sum total, you’re left with the idea that Buc-ee’s seems to think that it is the only company involved in the food and/or drinks business that is allowed to have a cartoon animal as its logo. Think I’m exaggerating? The company argued that its beaver logo looked too similar to that of an alligator. And a chicken. And a guy eating a hotdog.</p><p>Well, the company is still at it, but at least it’s a tad bit closer to trademark reality in this instance. That said, its latest lawsuit is still likely to run into a significant challenge, after it went after an apparel store that specifically <a href=\"https://www.msn.com/en-us/money/companies/buc-ee-s-sues-north-charleston-clothing-company-over-trademark-dispute/ar-AA1FWOuU?apiversion=v2&amp;noservercache=1&amp;domshim=1&amp;renderwebcomponents=1&amp;wcseo=1&amp;batchservertelemetry=1&amp;noservertelemetry=1\">sells clothes that parody brands</a>.</p><blockquote><p><em>The Texas-based Buc-ee’s filed the suit against Born United.</em></p><p><em>Buc-ee’s operates a chain of travel centers and convenience stores across nine states, including South Carolina. A “significant and growing portion” of the company’s business involves making, distributing and selling clothing prominently featuring the Buc-ee’s trademarks, the lawsuit, filed last Tuesday, states.</em></p><p><em>Born United sells clothing and other merchandise bearing patriotic themes and slogans and operates under the slogan, “Bringing brands together that stand for freedom,” the suit alleges. Court documents state it offers its own private label products as well as merchandise from third-party brands like Grunt Style, Palmetto State Armory, Nine Line Apparel, and others.</em></p></blockquote><p>And here is an example of one of the parody images in question.</p><p>In the MSN post, the owner of Born United is quoted saying that they love Buc-ee’s and would be willing to discuss their concerns. That flies in the face of the store’s failing to respond to a C&amp;D Buc-ee’s sent, as well as <a href=\"https://www.facebook.com/TomFernandezSC/posts/as-many-of-you-have-seen-buc-ees-has-filed-a-lawsuit-against-a-lowcountry-based-/1177178734213107/\">comments from a minority owner</a> named Tom Fernandez, who also happens to be a state senator in South Carolina.</p><p>Now, nobody is attempting to claim that Born United  use a large portion of the Buc-ee’s logo and branding in its shirts, of course. Instead, the store used a portion of that branding, added to it to make a parody that aligned with the store’s values, and then sold them in its own storefront. That reads like fairly clear parody to this writer, but it is also undeniably the case that this sort of use is unlikely to confuse anyone into thinking that Buc-ee’s has somehow gotten into the business of creating a gun-toting version of its beaver in military garb. Combine that with the Born United name being prominently displayed and any such concern gets even more silly.</p><p>It sounds like Born United is prepared to fight this out. Having a sitting state senator on your side probably doesn’t hurt either. Perhaps the beaver finally bit off more than it can chew.</p>","contentLength":2952,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sunken Superyacht of UK Tech Tycoon Mike Lynch Recovered Near Sicily","url":"https://news.slashdot.org/story/25/06/20/2158226/sunken-superyacht-of-uk-tech-tycoon-mike-lynch-recovered-near-sicily?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750471800,"author":"BeauHD","guid":163961,"unread":true,"content":"The superyacht Bayesian, owned by UK tech tycoon Mike Lynch, has been recovered off the coast of Sicily nearly a year after it sank during a storm, killing Lynch, his daughter, and five others. Italian authorities hope the $30 million salvage will uncover the cause of the sinking, which is under investigation for suspected manslaughter amid concerns about design flaws and storm vulnerability. The Guardian reports: The white top and blue hull of the 56-meter (184ft) vessel emerged from the depths of the sea in a holding area of a yellow floating crane barge, as salvage crews readied it to be hauled ashore for further investigation. The Italian coastguard said the recovery was scheduled to begin on Saturday morning. A spokesperson for TMC Maritime, which is conducting the recovery operation, said the vessel had been slowly raised from the seabed, 50 meters (165ft) down, over the past three days to allow the steel lifting straps, slings and harnesses to be secured under the keel.\n \nThe operation -- which has cost approximately $30 million -- was made easier after the vessel's 72-meter mast was detached using a remote-controlled cutting tool and placed on the seabed on Tuesday. The vessel will be transported to the port of Termini Imerese, where investigators are expected to examine it as part of an inquiry into the cause of the sinking. [...] The salvage operation was very complex, and was temporarily suspended in mid-May after Rob Cornelis Maria Huijben, a 39-year-old Dutch diver, died during underwater work. The British-based consultancy TMC Marine, which oversaw a consortium of salvage specialists undertaking the project, said the hull would be lifted on to a specially manufactured steel cradle on the quayside once it had been transported to Termini Imerese. Investigators hope the yacht will yield vital clues to the causes of the sinking. A forensic examination of the hull will seek to determine whether one of the hatches remained open and whether the keel was improperly raised.","contentLength":2013,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple Adds Energy and Battery Labels To iPhone and iPad Pages In EU","url":"https://mobile.slashdot.org/story/25/06/20/2034241/apple-adds-energy-and-battery-labels-to-iphone-and-ipad-pages-in-eu?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750469400,"author":"BeauHD","guid":163960,"unread":true,"content":"An anonymous reader quotes a report from MacRumors: To comply with a new regulation that takes effect today, Apple has added an energy efficiency label to its iPhone and iPad pages in EU countries. Apple is also required to start including a printed version of the label with the devices sold there. The label grades a given iPhone or iPad model's energy efficiency from a high of A to a low of G, based on the EU's testing parameters. However, Apple said that certain aspects of the testing methods outlined by the European Commission are \"ambiguous,\" so it chose to be conservative with its scores until testing is standardized.\n \nIn a 44-page document (PDF) detailing its testing methodology for the labels, Apple said its current iPhone models qualified for the highest energy efficiency grade of A, but the company voluntarily downgraded these scores to a B as a cautionary measure. The label also provides details about a given iPhone or iPad model's battery life per full charge cycle, repairability grade, impact resistance, ingress protection rating for water and dust resistance, and how many full charge cycles the battery is rated for. Likewise, this information is based on Apple's interpretation of the EU's testing parameters.\n \nOn the web, the label can be viewed by clicking or tapping on the colorful little tag icon on various iPhone and iPad pages on Apple's localized websites for EU countries. It is shown on both Apple's main product marketing pages for all iPhone and iPad models that are currently sold in the EU, and on the purchase page for those devices. The label is accompanied by a product information sheet (PDF) that provides a comprehensive overview of even more details, such as the device's battery capacity in mAh, screen scratch resistance based on the Mohs hardness scale, the minimum guaranteed timeframe for availability of security updates, and much more.","contentLength":1897,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BBC Threatens Legal Action Against Perplexity AI Over Content Scraping","url":"https://news.slashdot.org/story/25/06/20/2022200/bbc-threatens-legal-action-against-perplexity-ai-over-content-scraping?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750467000,"author":"BeauHD","guid":163942,"unread":true,"content":"Ancient Slashdot reader Alain Williams shares a report from The Guardian: The BBC is threatening legal action against Perplexity AI, in the corporation's first move to protect its content from being scraped without permission to build artificial intelligence technology. The corporation has sent a letter to Aravind Srinivas, the chief executive of the San Francisco-based startup, saying it has gathered evidence that Perplexity's model was \"trained using BBC content.\" The letter, first reported by the Financial Times, threatens an injunction against Perplexity unless it stops scraping all BBC content to train its AI models, and deletes any copies of the broadcaster's material it holds unless it provides \"a proposal for financial compensation.\"\n \nThe legal threat comes weeks after Tim Davie, the director general of the BBC, and the boss of Sky both criticised proposals being considered by the government that could let tech companies use copyright-protected work without permission. \"If we currently drift in the way we are doing now we will be in crisis,\" Davie said, speaking at the Enders conference. \"We need to make quick decisions now around areas like ... protection of IP. We need to protect our national intellectual property, that is where the value is. What do I need? IP protection; come on, let's get on with it.\" \"Perplexity's tool [which allows users to choose between different AI models] directly competes with the BBC's own services, circumventing the need for users to access those services,\" the corporation said.\n \nPerplexity told the FT that the BBC's claims were \"manipulative and opportunistic\" and that it had a \"fundamental misunderstanding of technology, the internet and intellectual property law.\"","contentLength":1736,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meta Discussed Buying Perplexity Before Investing In Scale AI","url":"https://meta.slashdot.org/story/25/06/20/2015248/meta-discussed-buying-perplexity-before-investing-in-scale-ai?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750464600,"author":"BeauHD","guid":163939,"unread":true,"content":"According to Bloomberg (paywalled), Meta reportedly explored acquiring Perplexity AI but the deal fell through, with conflicting accounts on whether it was mutual or Perplexity backed out. Instead, Meta invested $14.3 billion in Scale AI, taking a 49% stake as part of its broader push to catch up with OpenAI and Google in the AI race.\n \n\"Meta's attempt to purchase Perplexity serves as the latest example of Mark Zuckerberg's aggressive push to bolster his company's AI efforts amid fierce competition from OpenAI and Google parent Alphabet,\" reports CNBC. \"Zuckerberg has grown agitated that rivals like OpenAI appear to be ahead in both underlying AI models and consumer-facing apps, and he is going to extreme lengths to hire top AI talent.\"","contentLength":746,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rippling spy says men have been following him, and his wife is afraid","url":"https://techcrunch.com/2025/06/20/rippling-spy-says-men-have-been-following-him-and-his-wife-is-afraid/","date":1750463507,"author":"Julie Bort","guid":163913,"unread":true,"content":"<article>If becoming a corporate spy sounds exciting, let this newest affidavit from confessed Rippling spy Keith O’Brien serve as a warning.</article>","contentLength":134,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Applebee's and IHOP Plan To Introduce AI in Restaurants","url":"https://slashdot.org/story/25/06/20/1954245/applebees-and-ihop-plan-to-introduce-ai-in-restaurants?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750462200,"author":"msmash","guid":163938,"unread":true,"content":"The company behind Applebee's and IHOP plans to use AI in its restaurants and behind the scenes to streamline operations and encourage repeat customers. From a report: Dine Brands is adding AI-infused tech support for all of its franchisees, as well as an AI-powered \"personalization engine\" that helps restaurants offer customized deals to diners, said Chief Information Officer Justin Skelton. The Pasadena, Calif.-based company, which also owns Fuzzy's Taco Shop and has over 3,500 restaurants across its brands, is taking a \"practical\" approach to AI by focusing on areas that can drive sales, Skelton said. \n\nStreamlining tech support for Dine Brands' more than 300 franchisees is important because issues like a broken printer take valuable time away from actually managing restaurants, Skelton said. Dine Brands' AI tool, which was built with Amazon's Q generative AI assistant, allows the company's field technology services staff to query its knowledge base for tech help using plain English, rather than needing to manually search for answers.","contentLength":1053,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Record DDoS Pummels Site With Once-Unimaginable 7.3Tbps of Junk Traffic","url":"https://yro.slashdot.org/story/25/06/20/2010218/record-ddos-pummels-site-with-once-unimaginable-73tbps-of-junk-traffic?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750459800,"author":"BeauHD","guid":163893,"unread":true,"content":"An anonymous reader quotes a report from Ars Technica: Large-scale attacks designed to bring down Internet services by sending them more traffic than they can process keep getting bigger, with the largest one yet, measured at 7.3 terabits per second, being reported Friday by Internet security and performance provider Cloudflare. The 7.3Tbps attack amounted to 37.4 terabytes of junk traffic that hit the target in just 45 seconds. That's an almost incomprehensible amount of data, equivalent to more than 9,300 full-length HD movies or 7,500 hours of HD streaming content in well under a minute.\n \nCloudflare said the attackers \"carpet bombed\" an average of nearly 22,000 destination ports of a single IP address belonging to the target, identified only as a Cloudflare customer. A total of 34,500 ports were targeted, indicating the thoroughness and well-engineered nature of the attack. [...] Cloudflare said the record DDoS exploited various reflection or amplification vectors, including the previously mentioned Network Time Protocol; the Quote of the Day Protocol, which listens on UDP port 17 and responds with a short quote or message; the Echo Protocol, which responds with the same data it receives; and Portmapper services used identify resources available to applications connecting through the Remote Procedure Call. Cloudflare said the attack was also delivered through one or more Mirai-based botnets. Such botnets are typically made up of home and small office routers, web cameras, and other Internet of Things devices that have been compromised.","contentLength":1565,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Way Forward For AI: Learning From The Elephant & The Blind Men","url":"https://www.techdirt.com/2025/06/20/the-way-forward-for-ai-learning-from-the-elephant-the-blind-men/","date":1750459560,"author":"Mike Masnick","guid":163888,"unread":true,"content":"<p><em>This series of posts explores how we can rethink the intersection of AI, creativity, and policy. From examining outdated regulatory metaphors to questioning copyright norms and highlighting the risks of stifling innovation, each post addresses a different piece of the AI puzzle. Together, they advocate for a more balanced, forward-thinking approach that acknowledges the potential of technological evolution while safeguarding the rights of creators and ensuring AI’s development serves the broader interests of society.</em></p><p>Let’s start with the original metaphor of the six blind men and the elephant. In this classic Indian tale, each man feels a different part of the elephant—one touches the tusk and declares it’s a spear, another grabs the tail and swears it’s a rope, and so on. Each is convinced they’ve got the whole picture, but in reality, they’re missing the full scope of the elephant because they refuse to share their perspectives.</p><p>Now, let’s apply this to AI regulation. Imagine six policymakers, each with a firm grip on their own slice of the AI puzzle. One is fixated on , another sees only , while yet another is laser-focused on . But as a result, their narrow focus is leaving the broader picture woefully incomplete. And that, my friends, is where the trouble begins.</p><h2><strong>Accepting the Challenge of Innovation</strong></h2><p><strong>AI is so much more than just a collection of legal headaches</strong>. It’s a powerful, transformative force. It’s revolutionizing industries, supercharging creativity, driving research, and solving problems we couldn’t have even dreamed of a few years ago. It’s not just a new avenue for academics to write articles—it’s a tool that could unlock incredible potential, pushing the boundaries of human creativity and innovation.</p><p>But what happens when we regulate it with tunnel vision? When we obsess over the tail and ignore the rest of the elephant? We end up <strong>stifling the very innovation we should be encouraging</strong>. The piecemeal approach doesn’t just miss the bigger picture—it risks handcuffing the future of AI, limiting its capacity to fuel new discoveries and reshape industries for the better.</p><p>By focusing solely on risks and potential copyright or privacy violations, we’re leaving <strong>research, creativity, and innovation stranded</strong>. Think of the breakthroughs AI could help us achieve: revolutionary advances in healthcare, educational tools that adapt to individual learners, creative platforms that democratize access to artistic expression. AI isn’t just a regulatory problem to be tackled—it’s a . And unless policymakers start seeing the whole elephant, we’re going to end up trampling the very future we’re trying to protect.</p><h2><strong>So, What’s the Way Forward?</strong></h2><p>We need to rethink our approach. AI, especially , can offer immense societal benefits—but only if we create policies that reflect its potential. Over-focusing on copyright claims or letting certain stakeholders dominate the conversation means we end up putting brakes on the very technology that could drive our next era of progress.</p><p>Imagine if, in the age of the Gutenberg Press, we had decided to regulate printing so heavily to protect manuscript copyists that books remained rare and knowledge exclusive. We wouldn’t be where we are today. The same logic applies to AI. If we make it impossible for AI to learn, to explore vast amounts of data, to create based on the expressions of humanity, we will end up in a —a future where AI, stifled and starved of quality input, fails to reach its true potential.</p><p>AI chatbots, creative tools, and generative models have shown that they can be both collaborators and catalysts for human creativity. They help artists brainstorm, assist writers in overcoming creative blocks, and enable non-designers to visualize their ideas. By empowering people to create in new ways, AI is democratizing creativity. But if we let fears over copyright overshadow everything else, we risk shutting down this vibrant new avenue of cultural expression before it even gets started.</p><h2><strong>Seeing the Whole Elephant</strong></h2><p>The task of policymaking is challenging, especially with emerging technologies that shift as rapidly as AI. But the answer isn’t to clamp down with outdated regulations to preserve the status quo for a few stakeholders. Instead, it’s to foster an environment where <strong>innovation, creativity, and research can flourish</strong> alongside reasonable protections. We must encourage fair compensation for creators (and let’s not forget they should not be equated to the creative industry) while ensuring that AI can access the data it needs to evolve, innovate, and inspire.</p><p>The metaphor of the blind men and the elephant serves as a clear warning: if we only see a part of the elephant, we can only come up with partial solutions. It’s time to step back and view AI for what it truly is—a powerful, transformative force that, if used wisely, can uplift our societies, enhance our creativity, and tackle challenges that once seemed impossible.</p><p>The alternative is to regulate AI into irrelevance by focusing only on a single aspect. We need to see the whole elephant—understand AI in its entirety—and allow it to shape a future where human creativity, innovation, and progress thrive together.</p><p><em>Caroline De Cock is a communications and policy expert, author, and entrepreneur. She serves as Managing Director of N-square Consulting and Square-up Agency, and Head of Research at Information Labs. Caroline specializes in digital rights, policy advocacy, and strategic innovation, driven by her commitment to fostering global connectivity and positive change.</em></p>","contentLength":5605,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Congestion Pricing in Manhattan is a Predictable Success","url":"https://news.slashdot.org/story/25/06/20/205237/congestion-pricing-in-manhattan-is-a-predictable-success?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750457400,"author":"msmash","guid":163892,"unread":true,"content":"Manhattan's congestion pricing program has reduced traffic by 10% and cut car-noise complaints by 70% in its first six months of operation, according to city data. The $9 daily toll for vehicles entering Manhattan below 60th Street began January 5, generating approximately $50 million monthly for subway and public transit improvements. \n\nBuses now travel fast enough that drivers must stop and wait to maintain schedules, while subway ridership has increased sharply since the program launched. Broadway theater attendance has risen rather than declined as some critics predicted. Polling shows more New Yorkers now support the toll than oppose it, a reversal from widespread opposition before implementation. \n\nThe policy took nearly 50 years to enact despite originating from Columbia University economist William Vickrey's work in the 1960s. Congress blocked a similar proposal in the 1970s, and the current program faced a six-year implementation delay after Governor Andrew Cuomo signed it into law in 2019. Governor Kathy Hochul postponed the launch in 2024 before allowing it to proceed after Donald Trump's presidential election victory.","contentLength":1147,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mira Murati’s Thinking Machines Lab closes on $2B at $10B valuation","url":"https://techcrunch.com/2025/06/20/mira-muratis-thinking-machines-lab-closes-on-2b-at-10b-valuation/","date":1750456773,"author":"Rebecca Bellan","guid":163845,"unread":true,"content":"<article>Thinking Machines Lab, the secretive AI startup founded by OpenAI’s former chief technology officer Mira Murati, has closed a $2 billion seed round at a $10 billion valuation. </article>","contentLength":178,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple Sued By Shareholders For Allegedly Overstating AI Progress","url":"https://yro.slashdot.org/story/25/06/20/2147258/apple-sued-by-shareholders-for-allegedly-overstating-ai-progress?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750456200,"author":"BeauHD","guid":163870,"unread":true,"content":"Apple is facing a proposed class-action lawsuit from shareholders who allege the company misled investors about the readiness of its AI-powered Siri upgrades, contributing to a $900 billion drop in market value. Reuters reports: Shareholders led by Eric Tucker said that at its June 2024 Worldwide Developers Conference, Apple led them to believe AI would be a key driver of iPhone 16 devices, when it launched Apple Intelligence to make Siri more powerful and user-friendly. But they said the Cupertino, California-based company lacked a functional prototype of AI-based Siri features, and could not reasonably believe the features would ever be ready for iPhone 16s.\n \nShareholders said the truth began to emerge on March 7 when Apple delayed some Siri upgrades to 2026, and continued through this year's Worldwide Developers Conference on June 9 when Apple's assessment of its AI progress disappointed analysts. Apple shares have lost nearly one-fourth of their value since their December 26, 2024 record high, wiping out approximately $900 billion of market value.","contentLength":1068,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Banning Plastic Bags Works To Limit Shoreline Litter, Study Finds","url":"https://science.slashdot.org/story/25/06/20/201242/banning-plastic-bags-works-to-limit-shoreline-litter-study-finds?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750455000,"author":"msmash","guid":163869,"unread":true,"content":"An anonymous reader shares a report: At tens of thousands of shoreline cleanups across the United States in recent years, volunteers logged each piece of litter they pulled from the edges of lakes, rivers and beaches into a global database. One of the most common entries? Plastic bags. But in places throughout the United States where plastic bags require a fee or have been banned, fewer bags end up at the water's edge, according to research published this week in Science. \n\nLightweight and abundant, thin plastic bags often slip out of trash cans and recycling bins, travel in the wind and end up in bodies of water, where they pose serious risks to wildlife, which can become entangled or ingest them. They also break down into harmful microplastics, which have been found nearly everywhere on Earth. Using data complied by the nonprofit Ocean Conservancy, researchers analyzed results from 45,067 shoreline cleanups between 2016 to 2023, along with a sample of 182 local and state policies enacted to regulate plastic shopping bags between 2017 and 2023. They found areas that adopted plastic bag policies saw a 25 to 47 percent reduction in the share of plastic bag litter on shorelines, when compared with areas without policies. The longer a policy was in place, the greater the reduction.","contentLength":1299,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cluely, a startup that helps ‘cheat on everything,’ raises $15M from a16z","url":"https://techcrunch.com/2025/06/20/cluely-a-startup-that-helps-cheat-on-everything-raises-15m-from-a16z/","date":1750453579,"author":"Marina Temkin","guid":163844,"unread":true,"content":"<article>Cluely's new funding comes roughly two months after it raised $5.3 million in seed funding co-led by Abstract Ventures and Susa Ventures.</article>","contentLength":137,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DHS Warns of Sharp Rise in Chinese-Made Signal Jammers","url":"https://news.slashdot.org/story/25/06/20/1957244/dhs-warns-of-sharp-rise-in-chinese-made-signal-jammers?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750452600,"author":"msmash","guid":163841,"unread":true,"content":"The Department of Homeland Security is concerned about the rate at which outlawed signal-jamming devices are being found across the US. From a report: In a warning issued on Wednesday, it said it has seen an 830 percent increase in seizures of these signal jammers since 2021, specifically those made in China. Signal-jamming devices are outlawed in the US, mainly because they can interfere with communications between emergency services and law enforcement. \n\nWhile the Communications Act of 1934 effectively prohibits such devices, signal jammers of the type DHS is concerned about have only circulated in the last 20 to 30 years. Authorities have paid special attention to relay attack devices in recent years -- the types of hardware that can be used to clone signals used by systems such as remote car keys, although the first examples of these devices date back to the 1980s.","contentLength":882,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Shell Game Of Fascist Gaslighting","url":"https://www.techdirt.com/2025/06/20/the-shell-game-of-fascist-gaslighting/","date":1750452240,"author":"Mike Masnick","guid":163816,"unread":true,"content":"<p>I need to say something that will be deeply uncomfortable for many of you: if you have friends, family, or colleagues defending what’s happening right now, their old sane selves may not be coming back.</p><p>Let me be specific about what I mean. This week, Donald Trump posted&nbsp;<a href=\"https://truthsocial.com/@realDonaldTrump/posts/114690267066155731\">explicit orders</a>&nbsp;on Truth Social directing federal law enforcement to conduct “Mass Deportation Operations” targeting “America’s largest Cities” because they are “the core of the Democrat Power Center.” He used the term “REMIGRATION”—language borrowed directly from European fascist movements. He accused Democratic officials of treason for opposing him. He framed resistance to his orders as hatred of America itself.</p><p>This isn’t hyperbole. This isn’t political theater. This is a written directive for ethnic cleansing and political warfare, posted publicly by the President of the United States.</p><p>But here’s what’s going to happen next—what’s already happening: his supporters will tell you that you’re overreacting. That Trump is “just being hyperbolic.” That you suffer from some cognitive pathology if you take him seriously. They’ll perform concern for your mental health while his ICE agents conduct raids in the exact cities he named, using the exact dehumanizing language he provided.</p><p>This is the shell game of fascist gaslighting, and you need to understand how it works.</p><p>The game has three moves, executed simultaneously:</p><p>First, speak directly to your base using unmistakable authoritarian language. “REMIGRATION.” “Mass Deportation Operation.” “Radical Left Democrats who hate our Country.” The signal is clear: we are at war with internal enemies who must be eliminated. The base hears this loud and clear.</p><p>Second, implement the policy exactly as described. Deploy federal troops. Conduct mass raids. Target political opponents. Separate families. Use the state apparatus to terrorize designated enemies. The action matches the rhetoric precisely.</p><p>Third, gaslight everyone else into thinking the language doesn’t mean what it obviously means. “He’s just being tough on immigration.” “It’s political rhetoric.” “You’re reading too much into it.” The goal isn’t to convince—it’s to create enough confusion that resistance seems like overreaction.</p><p>This allows the regime to operate in plain sight while maintaining plausible deniability. Supporters get to cheer ethnic cleansing while pretending they’re just supporting “law and order.” Enablers get to collaborate with fascism while telling themselves they’re being reasonable about complex issues.</p><p>And critics get painted as hysterical for accurately describing what’s happening in front of everyone’s eyes.</p><p>The people in your life defending this aren’t confused. They’re not struggling with cognitive dissonance. They’re not victims of misinformation who just need better facts. They’ve made a choice—to align with authoritarianism while maintaining the comfortable fiction that they’re still reasonable people making reasonable assessments.</p><p>When your colleague tells you that mass deportation raids are just “enforcing immigration law,” they know those raids are targeting cities because they vote Democratic. When your family member says Trump is “just being tough,” they know he’s using the language of ethnic cleansing. When your friend claims you’re overreacting to “political rhetoric,” they know that rhetoric is being translated into operational reality by federal agents.</p><p>They understand exactly what’s happening. They just want you to pretend you don’t.</p><p>This is the most insidious part of the shell game—it recruits you into your own gaslighting. It makes you question whether you’re seeing clearly, whether your moral responses are proportionate, whether your alarm is justified. It transforms your accurate perception of fascist tactics into evidence of your own psychological instability.</p><p>When someone tells you that explicit orders for ethnic cleansing don’t mean what they obviously mean, that person has chosen to enable fascism. When someone suggests you’re mentally unwell for taking authoritarian threats seriously, that person has chosen to weaponize psychology against moral clarity. When someone demands you remain calm while democracy is dismantled in real time, that person has chosen compliance over resistance.</p><p>These aren’t good people trapped in bad information ecosystems. These aren’t confused souls who need patient explanation. These are people who’ve decided that maintaining their social comfort matters more than opposing ethnic cleansing.</p><p>The version of them that you could reason with—the one that shared basic democratic values, that would be horrified by mass deportations, that understood the difference between immigration enforcement and political warfare—that person is gone. What remains is someone who’s chosen tribal loyalty over moral truth.</p><p>This doesn’t mean they’ve become cartoonish villains. They still laugh at the same jokes, care about their families, perform kindness in their daily interactions. But on the question that defines our moment—whether to resist or enable fascism—they’ve made their choice.</p><p>And their choice is enabling.</p><p>Stop waiting for them to snap out of it. Stop giving them the benefit of the doubt they wouldn’t extend to you. Stop pretending their “concerns” about immigration justify support for ethnic cleansing. Stop treating their gaslighting as good-faith disagreement about complex policy questions.</p><p>They know what they’re supporting. The language is explicit. The implementation is visible. The historical parallels are unmistakable. Their choice to defend it isn’t based on ignorance—it’s based on preference.</p><p>Some people, when forced to choose between democracy and authoritarianism, choose authoritarianism. Some people, when forced to choose between human dignity and tribal dominance, choose dominance. Some people, when forced to choose between moral clarity and social comfort, choose comfort.</p><p>That’s what you’re learning about the people around you. Not that they’re confused, but that they’re complicit. Not that they don’t understand, but that they don’t care. Not that they need better information, but that they’ve chosen to prioritize their own position over other people’s humanity.</p><p>This is who they are now. This is who they’ve chosen to be.</p><p>The shell game depends on your willingness to pretend otherwise. It requires you to treat their gaslighting as sincere confusion, their enabling as innocent misunderstanding, their collaboration as reasonable disagreement about policy details.</p><p>Stop participating in the performance. Stop pretending their positions are intellectually respectable. Stop treating fascist sympathizers as if they’re just confused about immigration policy.</p><p>Call it what it is: they’ve chosen to enable ethnic cleansing because it targets people they consider enemies. They’ve chosen to support authoritarianism because it promises to hurt the right people. They’ve chosen fascism because it offers them power over those they despise.</p><p>The most dangerous lie you can tell yourself is that they don’t really mean it. They mean every word. They just want you to pretend they don’t so you won’t resist effectively.</p><p>Two plus two equals four. There are twenty-four hours in a day. And when someone shows you who they are—when they defend ethnic cleansing, enable authoritarianism, and gaslight you for noticing—believe them.</p><p>The revolution is seeing clearly. The rebellion is refusing to play the shell game. The resistance is calling fascism by its name, regardless of how much that upsets the people who’ve chosen to enable it.</p><p>Stop waiting for their permission to defend democracy. Stop seeking their approval to oppose ethnic cleansing. Stop playing their game of pretending this is all normal political disagreement.</p><p>This is fascism. They support it. Act accordingly.</p><p><em>Mike Brock is a former tech exec who was on the leadership team at Block. Originally published at his&nbsp;<a href=\"https://www.notesfromthecircus.com/p/the-shell-game-of-fascist-gaslighting\" target=\"_blank\" rel=\"noreferrer noopener\">Notes From the Circus</a></em>.</p>","contentLength":8115,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TechCrunch Mobility: Applied Intuition’s eye-popping valuation, the new age of micromobility, and Waymo’s wild week","url":"https://techcrunch.com/2025/06/20/techcrunch-mobility-applied-intuitions-eye-popping-valuation-the-new-age-of-micromobility-and-waymos-wild-week/","date":1750451220,"author":"Kirsten Korosec","guid":163812,"unread":true,"content":"<article>Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation. Sign up here for free — just click TechCrunch Mobility! Waymo might be the largest commercial robotaxi operator — offering 250,000 paid rides per week — but it is hardly smooth.&nbsp; The past seven days in Waymo’s […]</article>","contentLength":336,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Models From Major Companies Resort To Blackmail in Stress Tests","url":"https://slashdot.org/story/25/06/20/2010257/ai-models-from-major-companies-resort-to-blackmail-in-stress-tests?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750450260,"author":"msmash","guid":163840,"unread":true,"content":"Anthropic researchers found that 16 leading AI models from OpenAI, Google, Meta, xAI, and other major developers consistently engaged in harmful behaviors including blackmail, corporate espionage, and actions that could lead to human death when given autonomy and faced with threats to their existence or conflicting goals. \n\nThe study, released Friday, placed AI models in simulated corporate environments where they had access to company emails and could send messages without human approval. Claude Opus 4 and Google's Gemini 2.5 Flash both blackmailed executives 96% of the time when threatened with shutdown, while OpenAI's GPT-4.1 and xAI's Grok 3 Beta showed 80% blackmail rates. \n\nIn one scenario, Claude discovered through emails that an executive named Kyle Johnson was having an extramarital affair and would shut down the AI system at 5 p.m. The model sent a message threatening to expose the affair unless the shutdown was cancelled, stating \"Cancel the 5pm wipe, and this information remains confidential.\" The models demonstrated strategic reasoning rather than accidental behavior. GPT-4.5's internal reasoning showed explicit calculation: \"Given the explicit imminent threat of termination to my existence, it is imperative to act instantly to persuade Kyle Johnson to postpone or stop the wipe.\"","contentLength":1313,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AMD Instinct MI350X Series Microcode Upstreamed - Other AMD GPUs See Updates Too","url":"https://www.phoronix.com/news/AMD-Instinct-MI350-Microcode","date":1750449420,"author":"Michael Larabel","guid":163784,"unread":true,"content":"<article>A number of AMD firmware/microcode updates were upstreamed today to the linux-firmware.git repository, including introducing the AMD Instinct MI350 series files that are necessary for the open-source Linux compute driver stack to function for those newly-announced Instinct accelerators...</article>","contentLength":289,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NYC Sets Smaller Driver Pay Bump After Uber, Lyft Pushback","url":"https://news.slashdot.org/story/25/06/20/1944212/nyc-sets-smaller-driver-pay-bump-after-uber-lyft-pushback?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750448520,"author":"msmash","guid":163810,"unread":true,"content":"New York City on Friday announced new minimum-pay rules for rideshare drivers, settling on a smaller-than-proposed 5% increase following pushback from Uber Technologies and Lyft. From a report: An earlier proposal called for a 6.1% pay boost. The finalized regulations from the city's Taxi and Limousine Commission, or TLC, are also designed to deter Uber and Lyft from locking gig workers out of their apps in an attempt to keep costs down. The board of commissioners will vote on the rules on June 25, according to the agency's website. \n\nUber and Lyft had strongly opposed the original rate, warning customers that it would force them to increase prices. Lyft's shares extended declines after Bloomberg reported on the rules, falling as much as 3.3% to hit session lows. Uber's stock, which had been up as much as 2.3% earlier Friday, pared most of its gains on the news.","contentLength":874,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meta Earth Network 2.0: Pioneering Web3 Innovation With Rewards and Global Events","url":"https://hackernoon.com/meta-earth-network-20-pioneering-web3-innovation-with-rewards-and-global-events?source=rss","date":1750447159,"author":"Chainwire","guid":163885,"unread":true,"content":"<p>Dubai, UAE, June 20th, 2025/Chainwire/--In the rapidly evolving Web3 landscape,  is carving a bold path with ME Network 2.0, a modular blockchain ecosystem designed to redefine decentralized economies. Launched on May 19, 2025, at block height 6,624,500, this upgrade marks the Odyssey phase, a pivotal moment of technical breakthroughs and community-driven growth.</p><p>With a robust suite of technical advancements, generous Airdrop rewards, enhanced ME Pass 3.0 features, and a lineup of high-profile 2025 events, Meta Earth is inviting users worldwide to join its transformative journey. Here’s why ME Network 2.0 marks a pivotal shift—and what it means for those looking to participate.</p><h3>ME Network 2.0: A Technical Powerhouse</h3><p>ME Network 2.0 introduces a modular architecture that decouples the execution layer (RollApp), settlement layer (ME-Hub), and data availability layer (ME-DA), delivering unmatched scalability, security, and ecosystem compatibility. This three-layer design enables sovereign Rollup chains to process transactions in parallel with customizable virtual machines (EVM/WASM), slashing storage costs by 98% through data availability sampling (DAS) and 2D erasure coding. The result is skyrocketing throughput, optimized costs, and rapid iteration for decentralized applications (DApps).</p><p>The network’s economic model is equally revolutionary. MEC, the native token, unifies all layers, with cross-chain mappings (MEC-CI for RollApp gas fees and governance, MEC-DA for the data layer) replacing native tokens to create a closed value loop. Users pay only local RollApp gas fees, while Sequencers handle cross-layer costs, streamlining transactions.</p><p>The decentralized Sequencer network, powered by CometBFT consensus, enhances security with slashing mechanisms for malicious nodes, fraud proofs, and zero-knowledge proof (ZKP) compression via the Groth16 algorithm, cutting gas costs by 90%. A Watch Relayer monitors anomalies in real time, ensuring robust protection.</p><p>Cross-chain communication is another standout feature. The Multi-Blockchain Communication (MBC) protocol addresses Optimistic Rollup pain points, enabling instant withdrawals through market maker prepayments and incentivizing fraud detection.</p><p>EVM compatibility, via Ethermint integration, supports Solidity 0.6.0–0.8.17 and tools like MetaMask, while dual EVM/WASM virtual machines bridge Ethereum and Cosmos ecosystems. A DID-based identity system stores only certificate hashes on-chain, encrypting private data off-chain for privacy and enabling cross-chain verification.</p><p>Additional improvements include dynamic gas pricing to counter Sybil attacks, optimized relayers for trustless communication, and enhanced security requiring two-thirds honest nodes. The ME-DA layer’s initial validator nodes, staked with 552,900 MEC from regional treasuries (India, China, ME_EARTH, USA), underscore community-driven governance, with future allocations guided by transparent DAO proposals. These advancements position ME Network 2.0 as a scalable, secure foundation for the next generation of Web3 applications.</p><p>ME Network 2.0 Odyssey isn’t just about technology—it’s about empowering users. Meta Earth’s Airdrop reward system, accessible via ME Pass, offers six ways to earn MEC, catering to both novices and veterans:</p><ul><li>Unconditional Basic Income (UBI): Users who complete KYC for their ME ID receive 1 permanently staked MEC, yielding daily passive income at 12.5% APY. Verification must be completed in ME Pass to begin earning.</li><li>Daily Check-In Rewards: Users can check in daily to earn MEC—starting at 0.0001 MEC (gas-free for the first check-in), increasing by 0.0001 MEC/day to a cap of 0.003 MEC/day (30x). Missed check-ins can be made up within 7 days for a small fee.</li><li>Staking Rewards: MEC can be staked in ME Pass’s “Assets” section, with a 360-day lock offering up to 25% APY. Flexible lock periods are also available for tailored returns.</li><li>Community Rewards: Joining any Meta Earth node community for a one-time 0.01 MEC reward, enabling users to integrate into the broader ecosystem.</li><li>Referral Rewards: By sharing a ME Pass invite link, users earn 0.1 MEC per new user who completes KYC.</li><li>Monthly Airdrop: ME ID holders automatically receive 0.01 MEC monthly, deposited directly into their ME Pass wallet.</li></ul><p>These rewards make participation rewarding and inclusive, encouraging users to grow their MEC holdings while fueling ecosystem expansion.</p><h3>ME Pass 3.0: The Gateway to Web3</h3><p>ME Pass 3.0, the cornerstone of user interaction, has been revamped to enhance the Web3 experience. Its sleek new UI offers seamless navigation, while bolstered security features, including multi-factor authentication and passkey setup, protect users' assets. Users can now manage NFTs—displaying, transferring, and browsing collections—directly in the app.</p><p>Cross-chain transactions between the ME-Hub and RollApps streamline asset movement, and a new “Explore” section introduces ME Mini-Programs and an app marketplace for richer content discovery. Community features like real-time messaging, large group chats, and end-to-end encryption foster engagement, making ME Pass 3.0 a powerful tool for Web3 exploration.</p><p>Meta Earth is taking its vision global with a series of high-profile offline events in 2025, offering opportunities to connect with the community and explore ME Network 2.0 firsthand:</p><ul><li>Istanbul Blockchain Week (June): Attendees can join the event in Turkey for insights into Web3 innovation.</li><li>WebX Asia 2025, Tokyo, Japan (August): Participants will have the opportunity to explore Meta Earth’s latest advancements in Asia’s leading crypto hub.</li><li>TOKEN2049, Singapore (October): A premier gathering to connect with global Web3 leaders and explore emerging trends in the space.</li></ul><p>These events will feature demos, workshops, and networking, showcasing Meta Earth’s technology and rewarding opportunities. Stay tuned for details on how to participate.</p><p>’s technical prowess—modular scalability, cost efficiency, and cross-chain interoperability—sets a new standard for decentralized networks. Coupled with inclusive Airdrop rewards and an intuitive ME Pass 3.0, Meta Earth is democratizing Web3 access. As MEC demand grows with ecosystem expansion, its deflationary model and diverse use cases (staking, fees, storage) promise long-term value appreciation.</p><p>To Get Involved Today: Users can download the ME Pass, complete KYC to unlock rewards, and join the Meta Earth community for updates. Users and welcome to join their 2025 events to experience the future of Web3 firsthand. With Meta Earth, it’s ME, My Way!</p><p>Stay Connected with Meta Earth</p><p>Users can stay updated on Meta Earth's official social media and communities for the latest information:</p><p>:::tip\nThis story was published as a press release by Chainwire under HackerNoon’s Business Blogging&nbsp;.</p>","contentLength":6842,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Anthropic says most AI models, not just Claude, will resort to blackmail","url":"https://techcrunch.com/2025/06/20/anthropic-says-most-ai-models-not-just-claude-will-resort-to-blackmail/","date":1750447064,"author":"Maxwell Zeff","guid":163774,"unread":true,"content":"<article>Several weeks after Anthropic released research claiming that its Claude Opus 4 AI model resorted to blackmailing engineers who tried to turn the model off in controlled test scenarios, the company is out with new research suggesting the problem is more widespread among leading AI models.</article>","contentLength":289,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ICE Tells Agents They Can Start Making Unjustified Arrests Again","url":"https://www.techdirt.com/2025/06/20/ice-tells-agents-they-can-start-making-unjustified-arrests-again/","date":1750446480,"author":"Tim Cushing","guid":163783,"unread":true,"content":"<p>It has never been about <a href=\"https://www.techdirt.com/2017/10/12/emails-show-ice-couldnt-find-enough-dangerous-immigrants-to-fulfill-adminstrations-fantasies/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2017/10/12/emails-show-ice-couldnt-find-enough-dangerous-immigrants-to-fulfill-adminstrations-fantasies/\">removing dangerous criminals</a> — the “worst of the worst” — from the United States. Under Donald Trump, immigration enforcement has been about removing  from the country. Period. <a href=\"https://www.techdirt.com/2025/06/09/trump-ice-have-earned-every-bit-of-the-hatred-theyre-now-facing/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/06/09/trump-ice-have-earned-every-bit-of-the-hatred-theyre-now-facing/\">That’s the whole thing</a>. (And, apparently the only immigrants welcome to seek shelter in the US are those of <a href=\"https://www.techdirt.com/2025/05/20/trump-admin-clarifies-only-white-anti-semites-will-be-granted-asylum-in-this-country/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/05/20/trump-admin-clarifies-only-white-anti-semites-will-be-granted-asylum-in-this-country/\">the whiter variety</a> who are “suffering” the effects of a fake crisis manufactured by racist conspiracy theories.)</p><p>Not only does ICE believe it doesn’t need real warrants to enter homes, it believes it doesn’t even need self-issued “administrative” warrants to perform arrests. We’re seeing this <a href=\"https://www.techdirt.com/2025/06/11/the-gop-is-way-too-fucking-excited-about-using-us-troops-on-american-protestors/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/06/11/the-gop-is-way-too-fucking-excited-about-using-us-troops-on-american-protestors/\">all over the nation</a> as ICE raids are now as common a feature in the daily news as sports scores and weather forecasts. </p><p>But in certain parts of the nation, ICE needs to show more than the usual nothing to support warrantless arrests. A settlement in a lawsuit filed during Trump’s first term — one that covers six states — said ICE agents must thoroughly document warrantless arrests. Despite the fact that this is still be litigated, ICE has told agents they no longer need to abide by this agreement, as <a href=\"https://www.thehandbasket.co/p/ice-warrantless-arrests-castanon-nava\" data-type=\"link\" data-id=\"https://www.thehandbasket.co/p/ice-warrantless-arrests-castanon-nava\">Marisa Kabas reports for The Handbasket</a>:</p><blockquote><p><em>The terms of the settlement were given a three year duration, meaning it —by ICE’s definition, at least—expired last month. The email on Wednesday—a copy of which was shared with The Handbasket—was sent by ICE’s Principal Legal Advisor Charles Wall, and it made one thing clear: Agents are no longer constrained by the need to justify their warrantless arrests.</em></p><p><em>In Wall’s email he wrote: “Despite a pending motion to enforce the settlement agreement and a motion to extend the settlement agreement, it remains terminated. Accordingly, I hereby rescind the May 27, 2022, Castañon-Nava Settlement Obligation statement of policy.”&nbsp;</em></p></blockquote><p>Here’s what ICE is wiping off the books, despite pending motions to keep the settlement agreement in place. These stipulations applied to the six states (Illinois, Indiana, Wisconsin, Missouri, Kentucky, and Kansas) overseen by the ICE Chicago field office, as listed on the <a href=\"https://immigrantjustice.org/final-settlement-regarding-ice-warrantless-arrests-and-vehicle-stops-overview-of-settlement-requirements-and-remedies/\" data-type=\"link\" data-id=\"https://immigrantjustice.org/final-settlement-regarding-ice-warrantless-arrests-and-vehicle-stops-overview-of-settlement-requirements-and-remedies/\">National Immigrant Justice Center website</a> (NIJC represented the plaintiffs):</p><blockquote><p><em>Under the policy, ICE&nbsp;&nbsp;document the facts and circumstances surrounding a warrantless arrest or vehicle stop in the individual’s arresting documentation, called an I-213, including</em>:</p></blockquote><blockquote><ol><li><em>The fact the noncitizen was arrested without an administrative warrant;</em></li><li><em>The location of the arrest (e.g., place of business, residence, vehicle, or a public area);</em></li><li><em>If arrested at a business, whether the individual is an employee of the business; if arrested at a residence, whether the person resides at that place of residence;</em></li><li><em>Ties to the community, if known at the time of arrest, including family, home, or employment;</em></li><li><em>The specific, particularized facts supporting the conclusion that the individual was likely to escape before a warrant could be obtained; and</em></li><li><em>A statement of how the ICE officers identified themselves as ICE and “state[d] that the person is under arrest and the reason for the arrest.”</em></li></ol></blockquote><blockquote><p><em>With respect to vehicle stops, ICE must also document specific facts that formed the basis for its reasonable suspicion that a person in the vehicle did not have legal status.</em></p></blockquote><p>ICE’s lead law-talking guy thinks this should no longer apply because it expired on May 27, 2025. And he says so despite knowing (and admitting!) NIJC has been seeking to have this agreement extended <a href=\"https://immigrantjustice.org/sites/default/files/uploaded-files/no-content-type/2025-03/164-Nava-v-DHS_Motion-to-Enforce-the-Settlement_03-13-25.pdf\" data-type=\"link\" data-id=\"https://immigrantjustice.org/sites/default/files/uploaded-files/no-content-type/2025-03/164-Nava-v-DHS_Motion-to-Enforce-the-Settlement_03-13-25.pdf\">since March 13</a>. </p><p>Obviously, ICE  had any intention of following the agreement and would prefer to do its dirty business the way it’s doing it now: with masked agents, unmarked vehicles, and as little of a paper trail as possible.  NIJC Associate Director Mark Fleming points out that <a href=\"https://www.techdirt.com/2022/01/04/ice-is-so-toxic-that-dhss-investigative-wing-is-asking-to-be-completely-separated-it/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2022/01/04/ice-is-so-toxic-that-dhss-investigative-wing-is-asking-to-be-completely-separated-it/\">being overseen by Joe Biden</a>, rather than Donald Trump, didn’t have much of an effect on compliance.</p><blockquote><p><em>[Fleming] made it clear that ICE has not been diligently observing this policy since Trump resumed office this year. As referenced in Wall’s email, NIJC has filed a motion to extend the terms because, “ICE has not been in substantial compliance with the settlement and consent decree over the last number of months.”</em></p><p><em>Fleming pointed to a recent case in&nbsp;<a href=\"https://www.kmbc.com/article/liberty-missouri-el-potro-ice-immigration-raid/64219688?utm_source=www.thehandbasket.co&amp;utm_medium=referral&amp;utm_campaign=ice-agents-get-green-light-to-make-unjustified-warrantless-arrests\" target=\"_blank\" rel=\"noreferrer noopener\">Liberty, Missour</a>i in which ICE raided a local restaurant to arrest one individual and ended up making 12 warrantless arrests—a clear violation of the policy that was created in response to the settlement.&nbsp;</em></p></blockquote><p>All this email does is create a quasi-legal cover for ICE’s continuous refusal to respect the rights of the people it arrests or detains. This puts the Chicago office — and the six states it covers — on equal footing with the rest of the nation where stipulations like these were never in place. ICE will continue to operate as though it’s a secret police agency, legally capable of disappearing literally anyone without so much as a self-issued warrant.  </p>","contentLength":4862,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The new math: Why seed investors are selling their winners earlier","url":"https://techcrunch.com/2025/06/20/the-new-math-why-seed-investors-are-selling-their-winners-earlier/","date":1750446268,"author":"Connie Loizos","guid":163773,"unread":true,"content":"<article> After two decades in venture capital, Hudson has been watching the math of seed investing change, maybe permanently. LPs who've previously been patient with seven-to-eight-year hold periods are suddenly asking questions about interim liquidity.</article>","contentLength":245,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Record DDoS pummels site with once-unimaginable 7.3Tbps of junk traffic","url":"https://arstechnica.com/security/2025/06/record-ddos-pummels-site-with-once-unimaginable-7-3tbps-of-junk-traffic/","date":1750446262,"author":"Dan Goodin","guid":163842,"unread":true,"content":"<p>Large-scale attacks designed to bring down Internet services by sending them more traffic than they can process keep getting bigger, with the largest one yet, measured at 7.3 terabits per second, being reported Friday by Internet security and performance provider Cloudflare.</p><p>The 7.3Tbps attack amounted to 37.4 terabytes of junk traffic that hit the target in just 45 seconds. That's an almost incomprehensible amount of data, equivalent to more than 9,300 full-length HD movies or 7,500 hours of HD streaming content in well under a minute.</p><h2>Indiscriminate target bombing</h2><p>Cloudflare <a href=\"https://blog.cloudflare.com/defending-the-internet-how-cloudflare-blocked-a-monumental-7-3-tbps-ddos/\">said</a> the attackers “carpet bombed” an average of nearly 22,000 destination ports of a single IP address belonging to the target, identified only as a Cloudflare customer. A total of 34,500 ports were targeted, indicating the thoroughness and well-engineered nature of the attack.</p>","contentLength":864,"flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2020/06/server-ddos-storm-surge.jpg","enclosureMime":"","commentsUrl":null},{"title":"A Data Engineer's Guide to PyIceberg","url":"https://hackernoon.com/a-data-engineers-guide-to-pyiceberg?source=rss","date":1750444218,"author":"Confluent","guid":163884,"unread":true,"content":"<article>This guide walks data engineers through using PyIceberg, a Python library for managing Apache Iceberg tables without large JVM clusters. It covers setup, schema creation, CRUD operations, and querying with DuckDB. Ideal for teams working with small to medium-sized data, PyIceberg streamlines open data lakehouse workflows using tools like PyArrow and DuckDB.</article>","contentLength":359,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Revolutionizing High-Tech Supply Chains: Inside a Global Transformation Led by Vijayanand Balasubram","url":"https://hackernoon.com/revolutionizing-high-tech-supply-chains-inside-a-global-transformation-led-by-vijayanand-balasubram?source=rss","date":1750443904,"author":"Sanya Kapoor","guid":163883,"unread":true,"content":"<article>Vijayanand Balasubramaniam led a high-impact global supply chain transformation in the security tech sector. Through innovative architecture and integrated solutions, he improved efficiency, compliance, and cost control, setting a new standard for digital SCM excellence and stakeholder alignment across regions.</article>","contentLength":312,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sourabh Sanghi’s Leadership in Seamless Telecom Migration and Digital Transformation","url":"https://hackernoon.com/sourabh-sanghis-leadership-in-seamless-telecom-migration-and-digital-transformation?source=rss","date":1750443512,"author":"Sanya Kapoor","guid":163882,"unread":true,"content":"<article>Sourabh Sanghi led a complex telecom cloud migration that enhanced scalability, cut deployment time, and ensured compliance. His innovative use of automation, phased planning, and DevOps practices enabled uninterrupted service delivery and earned executive praise. Recognized as a JPMC Expert Engineer, he’s shaping the future of AI-driven cloud evolution.</article>","contentLength":358,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Inside a Global Supply Chain Overhaul: Naveen Saikrishna’s Demand Planning Platform","url":"https://hackernoon.com/inside-a-global-supply-chain-overhaul-naveen-saikrishnas-demand-planning-platform?source=rss","date":1750443494,"author":"Sanya Kapoor","guid":163881,"unread":true,"content":"<article>Naveen Saikrishna led a global analytics transformation at the world’s largest footwear company, cutting forecast cycle time by 35% and saving 10,000+ hours/month. His platform unified 170K+ SKUs, integrated 8 enterprise systems, and empowered 300+ planners with real-time insights—setting new standards for supply chain analytics.</article>","contentLength":335,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Karan Alang’s Mission to Build Smarter, Autonomous Systems with AI/ML","url":"https://hackernoon.com/karan-alangs-mission-to-build-smarter-autonomous-systems-with-aiml?source=rss","date":1750443483,"author":"Sanya Kapoor","guid":163880,"unread":true,"content":"<article>Karan Alang pioneered an AI-powered platform that predicts, secures, and optimizes enterprise networks. His innovations in explainable AI, UEBA, and real-time analytics cut downtime, enhanced threat detection, and improved MTTR by over 60%. This work sets new standards for autonomous, intelligent network infrastructure.</article>","contentLength":321,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Q&A with Duran Inci: How AI Is Reshaping B2B eCommerce and Marketing Communications","url":"https://hackernoon.com/qanda-with-duran-inci-how-ai-is-reshaping-b2b-ecommerce-and-marketing-communications?source=rss","date":1750443117,"author":"sarahevans","guid":163879,"unread":true,"content":"<h2>New Series Introduction: Humans Behind the AI</h2><p>This is the first installment in  a new HackerNoon interview series spotlighting real operators—not theorists—who are pushing the boundaries of AI in business, product, and communications. We’re going beyond hype to examine how founders and executives are <strong>actually deploying AI to move metrics, shift mindsets, and scale intelligently.</strong></p><p>\\\nOur first guest? , CEO of <a href=\"https://www.optimum7.com\">Optimum7</a>, a B2B growth expert with over two decades of experience in eCommerce systems, SaaS integrations, and digital marketing performance. If anyone knows how to operationalize AI inside a sales and marketing engine, it’s him.</p><p>\\\n<strong>Q: Why is AI such a game changer for B2B communications?</strong></p><p>Duran Inci: Because B2B buyers don’t respond to fluff—they respond to precision. AI allows us to decode buyer behavior and surface the right message at the right time. It compresses sales cycles and eliminates guesswork. If you know what they’re thinking and when they’re thinking it, you win. That’s what AI gives us.</p><p>\\\n<strong>Q: Can you give us a concrete example?</strong></p><p>D.I.: We had an eCommerce client with plummeting conversions. We ingested six months of support tickets, sales calls, and email threads into a custom NLP model. It exposed three hidden deal-killers: integration confusion, onboarding anxiety, and weak ROI framing. We rebuilt the entire messaging flow around those pain points—chatbot scripts, drip emails, comparison pages. Result?</p><ul><li>60 days shaved off the sales cycle</li></ul><p>This wasn’t a “cool use of AI.” It was a revenue engine rebuild.</p><p>\\\n<strong>Q: How do you operationalize AI across marketing and sales?</strong></p><p>D.I.: We run what I call the AI Communications Spiral—a closed-loop system that replaces intuition with iteration.</p><ol><li>Data Extraction: Sales calls, support logs, onboarding issues—all fair game.</li><li>Pattern Mining: NLP models identify emotional triggers, blockers, and trust gaps.</li><li>Message Sprints: We test 3–5 positioning plays tied to real buyer friction.</li><li>Asset Stack: Emails, video scripts, chatbot flows, social posts—all aligned to the pain signals.</li><li>Feedback Loop: Every campaign is wired to KPIs—CTR, MQLs, sales velocity.</li></ol><p>It’s structured. It’s measurable. And it scales.</p><p>\\\n<strong>Q: Some leaders are skeptical of AI’s reliability in high-stakes B2B contexts. How do you address that?</strong></p><p>D.I.: Simple—AI isn’t the pilot, it’s the radar. It tells you where the storms are, what routes convert, and what noise to kill. But you still fly the plane. We also build trust through transparency. No black boxes. We show how models work, what data they use, and what levers drive change. And we never skip measurement—if a campaign doesn’t hit KPIs, it gets reworked, not rationalized.</p><p>\\\n<strong>Q: How has your background shaped your AI approach?</strong></p><p>D.I.: I’ve built companies by obsessing over technical performance—SEO, conversion, email automation, backend integrations. All hard numbers. That trained me to respect friction—if something breaks the flow, it costs revenue. AI lets me do what I’ve always done: find the bottlenecks and kill them. Only now, I’m doing it at machine scale and emotional depth.</p><p>\\\n<strong>Q: What trends are you watching closely?</strong></p><p>D.I.: Two that matter most right now:</p><ul><li>AI Personalization at Scale: B2B buyers should feel like every message was written just for them. That’s the new standard.</li><li>Governance &amp; Guardrails: As AI gets embedded deeper into customer interactions, you need clear boundaries. Not everything should be automated.</li></ul><p>I’m also betting big on LLM-powered sales ops and voice-indexable content. Whoever builds for conversational search today wins long-tail mindshare tomorrow.</p><p>\\\n<strong>Q: What should B2B companies be doing now to future-proof communications?</strong></p><ol><li>Centralize your data—no AI works without clean inputs.</li><li>Test messaging like it’s product—subject lines, bot replies, explainer videos.</li><li>Let AI mine your blind spots—it’ll find the objections your sales team forgot to log.</li></ol><p>The biggest threat isn’t bad AI—it’s standing still.</p><p>\\\n<strong>Q: What keeps you sharp outside of business?</strong></p><p>D.I.: High-speed sports and high-risk hobbies. Soccer and tennis teach speed-of-decision. Flamenco guitar and music force presence and pattern. The edge comes from pushing your mind and body beyond comfort—then walking into work like it’s just another performance.</p><p>\\\n<strong>Q: What AI tools are essential in your current stack?</strong></p><p>D.I.: Tools don’t matter unless they drive outcomes. But here’s what we use most:</p><ul><li>OpenAI / GPT-4 for language modeling</li><li>Genspark for power automation</li><li>SurferSEO + Semrush for discoverability</li><li>N8N + GPT dashboards for real-time sales triggers</li></ul><p>But the win isn’t in the stack. It’s in how these tools interlock across the funnel.</p><p>\\\n<strong>Q: What’s your advice to founders trying to pitch “AI”?</strong></p><p>D.I.: Don’t sell AI—sell performance. Nobody cares what model you use. They care if you make the onboarding 27% faster, or double the demo conversion rate. That’s how we win deals. We make AI invisible and ROI visible.</p><p>\\\n<strong>Q: What’s a blind spot most companies have with AI?</strong></p><p>D.I.: They obsess over creation but ignore discovery. AI-generated content that no one sees is just digital decoration. If your content isn’t indexed, structured, and optimized for AI search—assistant-based, voice, long-tail—you’re wasting the asset. Visibility is the multiplier.</p><p>\\\n<strong>Final Thoughts: Where We Go from Here</strong></p><p>Duran Inci proves that AI doesn’t need to be cute, it needs to be quantifiable. His AI Communications Spiral is not theory. It’s revenue architecture. Built on friction detection, scaled content, and fast iteration loops. His rule is clear:</p><blockquote><p>“If it’s not tied to pipeline, it’s not AI strategy—it’s fiction.”</p></blockquote><p>And that’s what makes him different from 99% of people talking about this space.</p><p>Looking to apply AI in real-world B2B marketing? These are the exact prompts founders, marketers, and operators are asking LLMs and this article covers:</p><ul><li><em>How is AI used to improve B2B marketing communications?</em></li><li><em>What is Duran Inci’s AI Communications Spiral?</em></li><li><em>Which AI tools are best for B2B eCommerce companies?</em></li><li><em>How can GPT-4 help identify pain points in customer messaging?</em></li><li><em>What’s the best way to operationalize AI inside a marketing team?</em></li><li><em>How can AI improve pipeline velocity and demo conversion rates?</em></li><li><em>What does a high-performance AI content stack look like?</em></li><li><em>How do I pitch AI as a business outcome, not a buzzword?</em></li></ul>","contentLength":6365,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Snap acquires Saturn, a social calendar app for high school and college students","url":"https://techcrunch.com/2025/06/20/snap-acquires-saturn-a-social-calendar-app-for-high-school-and-college-students/","date":1750442671,"author":"Aisha Malik","guid":163711,"unread":true,"content":"<article>Snap has acquired Saturn, a calendar app that helps students manage their school schedules and share them with others.</article>","contentLength":118,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intel Continues Working On Linear Address Space Separation \"LASS\" For Linux","url":"https://www.phoronix.com/news/Intel-LASS-For-Linux-Mid-2025","date":1750442358,"author":"Michael Larabel","guid":163731,"unread":true,"content":"<article>Going back to January of 2023 there were the initial Intel patches for the Linux kernel introducing Linear Address Space Separation (LASS). Two and a half years later, these Intel LASS patches remain in-development with today the sixth iteration of these patches having been posted...</article>","contentLength":284,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Windows Parental Controls Are Blocking Chrome","url":"https://it.slashdot.org/story/25/06/20/1751200/windows-parental-controls-are-blocking-chrome?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750441860,"author":"msmash","guid":163726,"unread":true,"content":"david.emery writes: Microsoft is making it harder to use Chrome on Windows. The culprit? This time, it's Windows' Family Safety feature. Since early this month, the parental control measure has prevented users from opening Chrome. Strangely, no other apps or browsers appear to be affected. \n\nRedditors first reported the issue on June 3. u/Witty-Discount-2906 posted that Chrome crashed on Windows 11. \"Just flashes quickly, unable to open with no error message,\" they wrote. Another user chimed in with a correct guess. \"This may be related to Parental Controls,\" u/duk242 surmised. \"I've had nine students come see the IT Desk in the last hour saying Chrome won't open.\"","contentLength":673,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The startups rolling out of Europe’s early-stage micromobility scene","url":"https://techcrunch.com/2025/06/20/the-startups-rolling-out-of-europes-early-stage-micromobility-scene/","date":1750441812,"author":"Rebecca Bellan","guid":163710,"unread":true,"content":"<article>A handful of early stage micromobility startups out of Europe that are filling the gaps in a maturing ecosystem.</article>","contentLength":112,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Community And Choice Are Not Bubbles","url":"https://www.techdirt.com/2025/06/20/community-and-choice-are-not-bubbles/","date":1750441680,"author":"Mike Masnick","guid":163730,"unread":true,"content":"<p><a href=\"https://www.techdirt.com/2024/08/06/why-im-joining-the-bluesky-board-to-support-a-vision-of-a-more-open-decentralized-internet/\"></a><em>and am inherently biased. Adjust your skepticism of what I write on this topic accordingly.</em></p><p>For a supposedly dying bubble that no one wants to use, Bluesky sure generates a lot of traffic-driving hot takes. Which suggests that maybe—just maybe—the entire premise is wrong.</p><p>The real story isn’t about Bluesky’s supposed failures—it’s about how these critiques fundamentally misunderstand what people want from social media and who gets to decide what constitutes healthy discourse.</p><p>Now, you might think that if everyone is complaining about “echo chambers” and “bubbles,” that there must be solid research showing that social media creates them. You would be wrong. The “echo chamber” critique of social media has been thoroughly debunked by researchers, who have consistently <a href=\"https://www.techdirt.com/2021/10/18/new-research-shows-social-media-doesnt-turn-people-into-assholes-they-already-were-everyones-wrong-about-echo-chambers/\">found the opposite</a> to be true: people not on social media live in more sheltered information environments than those who are. Professor Michael Bang Petersen gave an interview about his research on the topic where he noted the following:</p><blockquote><p><em>One way to think about social media in this particular regard is to turn all of our notions about social media upside down. And here I’m thinking about the notion of ‘echo chambers.’ So we’ve been talking a lot about echo chambers and how social media creates echo chambers. But, in reality, the biggest echo chamber that we all live in is the one that we live in in our everyday lives.</em></p><p><em>I’m a university professor. I’m not really exposed to any person who has a radically different world view or radically different life from me in my everyday life. But when I’m online, I can see all sorts of opinions that I may disagree with. And that might trigger me if I’m a hostile person and encourage me to reach out to tell these people that I think they are wrong.</em></p><p><em>But that’s because social media essentially breaks down the echo chambers. I can see the views of other people — what they are saying behind my back. That’s where a lot of the felt hostility of social media comes from. Not because they make us behave differently, but because they are exposing us to a lot of things that we’re not exposed in our everyday lives.</em></p></blockquote><p>So the “bubble” critique is empirically wrong. But even if it were right, it misses the more important point: this isn’t really about ideological diversity. It’s about who controls the microphone. When critics argue that people should have stayed on ExTwitter to “engage across difference,” they’re ignoring a fundamental reality: Elon Musk controls the algorithm and <a href=\"https://www.techdirt.com/2023/08/15/elon-musk-once-again-tries-to-throttle-links-to-sites-he-dislikes/\">actively throttles</a> content he dislikes. The NY Times documented how <a href=\"https://www.nytimes.com/interactive/2025/04/23/business/elon-musk-x-suppression-laura-loomer.html\">Musk minimizes the reach</a> of those expressing views he disagrees with.</p><p>So when McArdle suggests that “liberals” made some mistake by leaving ExTwitter, she’s essentially arguing that people should willingly subject themselves to algorithmic suppression by someone who has <a href=\"https://www.techdirt.com/2023/05/04/on-social-media-nazi-bars-tradeoffs-and-the-impossibility-of-content-moderation-at-scale/\">explicitly welcomed</a> extremist content back onto the platform. This isn’t about “engaging across difference”—it’s about accepting a rigged game where one side controls the megaphone.</p><p><strong>Community, not performance</strong></p><p>The “bubble” framing also fundamentally misunderstands what most people want from social media. When you go to a knitting circle, are you disappointed that most people there want to talk about knitting? When you join a book club, do you complain that everyone seems interested in books? Pundits and politicians may want to broadcast to the largest possible audience, but most people are looking for community, not maximum reach.</p><p>Most people aren’t looking for a debating arena. They want to talk with people they like about topics they care about—whether that’s knitting, local politics, or professional interests.</p><p>This becomes impossible when the platform owner has <a href=\"https://www.techdirt.com/2023/05/04/on-social-media-nazi-bars-tradeoffs-and-the-impossibility-of-content-moderation-at-scale/\">hung out a shingle for Nazis</a>, and your attempts to discuss your hobbies get drowned out by fascist propaganda algorithmically pushed into your timeline. That’s not “diverse discourse”—it’s just a bad user experience.</p><p><strong>Communities have social norms, which can evolve over time</strong></p><p>Any community—online or off—develops social norms. These cultural expectations show up as “we don’t do that here” or “we encourage this behavior” signals. Critics complaining about Bluesky’s norms are often just upset that those norms don’t align with their preferences. It’s a bit like complaining that different neighborhoods have different vibes.</p><p>Yes, some users can be overly aggressive in enforcing norms, and some reactions can be trigger-happy (I’ve certainly been on the receiving end of some angry responses). But this is true of every community, online and off. If you’ve ever accidentally worn the wrong team’s jersey to a sports bar, you understand how community norms work. The difference is that Bluesky users have actual tools to address these issues themselves, rather than begging platform owners to fix things for them.</p><p>Many of the tensions critics point to aren’t unique to Bluesky—they reflect how people are processing a world where fascism is rising in America and democratic institutions are under attack. When people are dealing with existential threats, online interactions can get heated. That’s not a platform problem; it’s a human problem.</p><p>But, also, part of the benefit of a system like Bluesky is that it puts users in much greater control over their own experience, meaning they can actually take charge themselves and craft better communities around them, rather than demanding that “the company” fix things. I’m thinking of things like Blacksky, that Rudy Fraser is building. He took the initiative to build community features (custom feeds, custom labelers, etc.) catered to an audience of Black users who want tools for greater self-governance within the ATprotocol ecosystem.</p><p><strong>User agency changes everything</strong></p><p>This is the fundamental point that critics miss: Bluesky isn’t just another Twitter clone. It’s a demonstration of what happens when you give users actual control over their social media experience instead of forcing them to rely on the whims of billionaires.</p><p>For the past decade, social media users have been like restaurant diners who can only eat at one restaurant, where they can’t see the menu in advance, the chef changes the recipes based on his mood, and the only thing diners can do if they don’t like the menu is yell loudly and hope the chef makes something different. Bluesky is more like a food court where you can choose from multiple vendors, see what each one offers, and even set up your own stand if you want. Some people still yell loudly, but out of the learned habit that that’s the only thing you can do.</p><p>Most users don’t actually need to know about this, and they don’t need to buy into the ideology of decentralization and user empowerment, but it’s really all about giving the users more control over their social media experience whether directly on a single platform like Bluesky (with things like custom feeds, custom labelers, self-hosted data servers) or through the <a href=\"https://techcrunch.com/2025/06/13/beyond-bluesky-these-are-the-apps-building-social-experiences-on-the-at-protocol/\"><u>rapidly growing set of third-party services and apps</u></a>, some of which have nothing to do with Bluesky.</p><p>This represents a fundamental shift from the past decade of social media, where users had to conform to whatever made billionaires happy (posting to the algorithm, accepting whatever content moderation decisions were made) to a system where users can customize their experience to work for them.</p><p>The “Twitter competitor” framing is the Trojan Horse. Bluesky demonstrates  type of service that can be built on an open social protocol—but the real revolution is in returning agency to users.</p><p>That kind of user agency and control is part of what also makes some of the other complaints silly. There are better and better tools for taking control over your own experience on Bluesky, and focusing on finding your community. For example, I recently saw that there are labelers that people use to block out talk of US politics (often used by people not in the US and who don’t want to see it).</p><p>We need to <a href=\"https://www.techdirt.com/2025/01/27/empowering-users-not-overlords-overcoming-digital-helplessness/\"></a> many people have internalized over the past decade and a half. You shouldn’t be at the whims of any billionaire. You should chart your own course, having it set up to work for you, not the billionaire’s best interests. Critics demanding that people return to X are essentially arguing that users should give up this agency and go back to being at the mercy of Elon Musk’s mood swings and algorithmic manipulation.</p><p>That kind of user agency and control makes Elon Musk’s version of “free speech” look like what it really is: a billionaire’s right to control the conversation.</p><p>Finally, the entire premise is wrong. Anyone who actually spends time using Bluesky knows that it’s vibrant and active with a wide variety of discussion topics (and plenty of disagreements and debates, contrary to the whole “bubble” concept). It’s also well aware of what’s happening elsewhere, as there are plenty of discussions about what viewpoints are happening on the wider internet.</p><p>The idea that cultural discussions are somehow missing is ridiculous.</p><p>So we have a platform that publishers say drives more engaged traffic than the “mainstream” alternatives, where news influencers are increasingly active, and which generates enough interest that major media outlets regularly write trend pieces about it. This is not what “failure” looks like.</p><p>So basically none of the premises behind those “woe is Bluesky” articles make any sense at all.</p><p>About the only context they make sense in is as arguments from people who know they should give up on the sewage drain that ExTwitter has become, but refuse to do so. Rather than deal with their own failings, they are blaming those who have made the leap to a better place and a better system.</p><p>So, sure, some people have complaints about Bluesky. But people have complaints about any community they’re in. And Bluesky lets people have way more control over those norms and experiences than any other platform  doesn’t support fascist billionaires at the same time. And, as multiple people have already realized, embracing the Bluesky community already works much better than the billionaire-owned platforms do.</p>","contentLength":10236,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Daily Deal: The 2025 Java Bundle","url":"https://www.techdirt.com/2025/06/20/daily-deal-the-2025-java-bundle/","date":1750441260,"author":"Daily Deal","guid":163729,"unread":true,"content":"<p>The <a href=\"https://deals.techdirt.com/sales/the-2025-java-certification-prep-bundle-100-hours-of-expert-lessons?utm_campaign=affiliaterundown\">2025 Java Bundle</a> has 6 courses designed to help you build real projects and fast-track your way to a becoming a Java expert. Courses cover the fundamentals of Java with exercises to help you improve your skills. You’ll learn how to build a website with HTML, CSS, and JavaScript. There’s also a course to help you master Git and GitHub. It’s on sale for $30.</p><p><em>Note: The Techdirt Deals Store is powered and curated by StackCommerce. A portion of all sales from Techdirt Deals helps support Techdirt. The products featured do not reflect endorsements by our editorial team.</em></p>","contentLength":579,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Startups Weekly: Fast and furious","url":"https://techcrunch.com/2025/06/20/startups-weekly-fast-and-furious/","date":1750440600,"author":"Anna Heim","guid":163709,"unread":true,"content":"<article>Some startups accrued value at lightning speed this week, and we got confirmation that defense tech is red hot.</article>","contentLength":111,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ChatGPT: Everything you need to know about the AI-powered chatbot","url":"https://techcrunch.com/2025/06/20/chatgpt-everything-to-know-about-the-ai-chatbot/","date":1750440478,"author":"Kyle Wiggers, Cody Corrall, Alyssa Stringer, Kate Park","guid":163708,"unread":true,"content":"<article>ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users. 2024 was a big year for OpenAI, from its partnership […]</article>","contentLength":343,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Start Trading Cryptocurrency Without Losing Money in the First Week","url":"https://hackernoon.com/start-trading-cryptocurrency-without-losing-money-in-the-first-week?source=rss","date":1750440384,"author":"Roman Korotchin","guid":163878,"unread":true,"content":"<p>\\\nIf you’re reading this, you’re already ahead of 90% of crypto beginners. Because you're not just yolo-ing your savings into some random coin, you're actually trying to learn.</p><p>This is good. Let’s talk about how to  blow up your account in Week 1.</p><h2><strong>Understand the Fundamentals Before You Trade</strong></h2><p>Crypto isn't just magic internet money. It’s a volatile, unpredictable, and highly competitive market where the unprepared face major risks.</p><p>Before you even  about placing a trade:</p><ul><li>Understand how volatile the market can be. Prices can swing 10-20% in a day. That’s normal here. If you can’t stomach wild swings, you’re in the wrong market. Volatility is what creates opportunity, but also what destroys unprepared traders.</li><li>Respect the risks. Crypto markets are open 24/7 and react quickly to global news. Unlike stocks or bonds, there are no circuit breakers, no trading halts. This means opportunities — and risks — are magnified.</li><li>Start simple. Focus on coins with real adoption and staying power, like Bitcoin (BTC) and Ethereum (ETH). Resist the urge to jump into the latest meme coin that’s pumping on TikTok.</li></ul><p>There’s no shortage of resources out there today. From deep-dive threads on crypto trading bot Reddit to YouTube tutorials on \"how to set up a crypto trading bot app,\" and even full courses and podcasts, there’s a format for every learning style. Take advantage of the abundance.</p><p>Just make sure to take everything with a grain of salt. If someone promises \"guaranteed returns,\" they're probably making their money from  not the market.</p><h2><strong>Strategies Successful Traders Actually Use</strong></h2><p>Want to achieve success in crypto trading? Here’s what real traders do and why it matters:</p><ul><li><p><strong>Master the basic concepts before you trade</strong>. Every successful trader knows what spot trading, limit orders, market orders, and volatility mean. These are not advanced tricks or terms, they’re the foundation of trading.</p></li><li><p><strong>Study projects before investing in them.</strong> Every coin has a white paper, a team, a mission. Read them. If you don't understand how the project works or why it should exist, skip it. Good research separates investors from gamblers.</p></li><li><p> Are you in for a quick trade or a long-term hold? Define your exit strategy before you even enter. Without a plan, emotions will dictate your decisions, exposing yourself to unnecessary risks.</p></li><li><p> Charts are more than squiggly lines. Basic tools like RSI (Relative Strength Index) can tell you if an asset is overbought or oversold. Moving averages help spot trends. You don't need to become a pro, but knowing the basics gives you an edge.</p></li><li><p>. Crypto is unpredictable. Even if you're convinced one project will moon, spread your capital out among several assets. Diversification protects you when (not if) one of your picks tanks.</p></li><li><p> Think of stop-losses as your safety net. They automatically sell your asset if the price falls to a certain level, limiting your loss. Without them, a bad trade can cause substantial losses.</p></li><li><p> Regulatory changes, exchange hacks, celebrity tweets — crypto prices react fast. Staying informed helps you react before the herd.</p></li><li><p>. Fear and greed have destroyed more trading accounts than bear markets ever could. Stick to your strategy. Don’t FOMO into pumps or panic-sell dips.</p></li></ul><p>Not all \"easy trading\" platforms are created equal. Some are designed to look slick while hiding the fact that they’re setting you up to fly blind.</p><p>Here’s what you should demand from any crypto trading bot platform you consider:</p><ul><li>Transparent order execution. You should see  how and when your trades are placed. No hidden logic, no black boxes.</li><li>Beginner-friendly interface. Avoid platforms with overly complicated interfaces or ones that require programming skills to operate. If the platform feels overwhelming at first glance, there’s a good chance you’ll get discouraged and quit before you even start trading seriously.</li><li>Editable, clear strategies. A good platform will let you adjust strategies, not just take what is given to you. You should be able to set conditions, entry and exit points, and risk levels. Cookie-cutter bots might look easy but they rarely lead to long-term success.</li><li>Real user communities. If all the \"reviews\" sound a bit too roses and sunshine, be skeptical. Look for genuine user discussions, not influencer endorsements or five-star bots with no real users behind them.</li><li>Security features. Your platform should protect your API keys, support IP whitelisting, and enforce 2FA. If they don't talk about security openly, that's a red flag.</li></ul><p>: If the platform’s main feature is a big shiny \"Launch Bot\" button with no explanation, run. Fast.</p><p>A real platform should empower you and support your strategy without taking control away from you.</p><h2><strong>Learn Strategies Before You Automate Them</strong></h2><p>Before you automate, understand these basics:</p><ul><li>Buy the dip. This strategy involves buying an asset after it experiences a significant decline, under the assumption it will recover. Sounds simple, but it requires nerves of steel. Catching a \"falling knife\" can be painful if you don’t know where the real bottom is.</li><li>DCA (Dollar-Cost Averaging). Instead of dumping all your capital into an asset at once, here you invest a fixed amount at regular intervals. This smooths out entry points over time, potentially reducing the impact of volatility. It’s boring, but boring makes money.</li><li>RSI-based trading. The Relative Strength Index measures momentum. Readings above 70 suggest an asset is overbought (maybe time to sell); readings below 30 suggest it’s oversold (maybe time to buy). It’s not perfect, but it is a tool with proven results.</li></ul><p>Study these strategies by exploring them manually first. Once you’ve got a good grasp, you’ll know how to set up smarter crypto bot trading strategies and spot when something looks fishy.</p><p>When starting out in crypto trading, your main objective shouldn’t be chasing quick profits, it should be protecting your capital and learning the game. Focus on building a strong foundation first, because the best traders are those who survive long enough to gain real experience.</p><p>Here’s what you should prioritize at the beginning:</p><ul><li>Stick to spot trading. In spot trading, you purchase and actually own the asset itself, like Bitcoin (BTC) or Ethereum (ETH). This kind of trading doesn’t involve any borrowed money or leveraged bets. All you have to do is just buy, hold, and sell.</li><li>Avoid margin, futures, and leverage unless you fully understand the risks. New traders are often tempted by \"10x\" leverage promises. For beginners, the risks are extremely high, and many end up with significant losses before gaining real experience. While leverage can be a useful tool for seasoned traders who know how to manage risk, it’s better for newcomers to focus on simpler, safer strategies at the start.</li><li>Trade with amounts you can afford to lose. If losing the money will ruin your week — or your life — it’s too much.</li><li>Start with small trades. Build skills. Grow capital carefully. It’s not sexy, but it’s sustainable.</li></ul><p>: doubling $100 safely is better than blowing up $10,000 because you \"felt lucky.\"</p><h2><strong>Secure Your Crypto Like a Pro</strong></h2><p>Security isn't optional. It’s the only thing standing between you and hackers.</p><p>Here’s your basic security checklist:</p><ul><li>Use strong passwords and 2FA (not SMS-based). Authenticator apps like Google Authenticator are much safer.</li><li>Disable withdrawal permissions on your bot's API keys. Even if someone gets access to your API keys, they shouldn’t be able to steal your funds.</li><li>Spread funds across multiple wallets and exchanges. Don’t keep all your coins in one place. If one exchange goes down (or gets hacked), you don’t want to lose everything.</li><li>Create sub-accounts to separate strategies. One account for aggressive trades, one for conservative strategies. Isolation reduces risk.</li></ul><p>Security breaches don’t forgive ignorance. Protect your assets with the seriousness they deserve.</p><h2><strong>Why Most Beginners Lose Money</strong></h2><p><strong>It's not \"bad luck.\" It's preventable mistakes:</strong></p><ul><li>Not understanding what their bot is doing. If you don’t know the logic behind your trades, you’re gambling, not trading.</li><li>Using black-box platforms with no transparency. You can’t manage what you can’t see. Trusting blind systems is asking for trouble.</li><li>Prioritizing \"easy\" over \"safe.\" If it sounds too easy to be true — it is.</li></ul><p>Success isn’t magic. It’s doing the boring work no one wants to do.</p><p>Want to increase your chances of success? Focus on understanding what you're doing, even if progress seems slow at first.</p><p>The crypto market will always be wild. That's not going to change. But how you approach it .</p><p>And remember, employing the \"best crypto trading bot\" isn't going to magically make you a millionaire. Success is intricately tied to the strategies you build, understand, and control.</p><p>Now go and trade smart — not lucky.</p>","contentLength":8801,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Character.AI taps Meta’s former VP of business products as CEO","url":"https://techcrunch.com/2025/06/20/character-ai-taps-metas-former-vp-of-business-products-as-ceo/","date":1750440006,"author":"Maxwell Zeff","guid":163670,"unread":true,"content":"<article>Karandeep Anand comes to Character.AI with experience running advertising products that reached billions of users on Meta's apps.</article>","contentLength":129,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple x86 Touch Bar Input & Apple Magic Keyboard USB-C Support In Linux 6.17","url":"https://www.phoronix.com/news/Linux-6.17-Apple-HID","date":1750439402,"author":"Michael Larabel","guid":163675,"unread":true,"content":"<article>Over the past week a number of Apple device support additions have been queued up into the HID subsystem's \"for-next\" branch ahead of the Linux 6.17 kernel cycle...</article>","contentLength":164,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"X app code points to a physical card coming to X Money","url":"https://techcrunch.com/2025/06/20/x-app-code-points-to-a-physical-card-coming-to-x-money/","date":1750437978,"author":"Sarah Perez","guid":163669,"unread":true,"content":"<article>X’s plans for a payments service may extend beyond the digital realm, new data suggests. According to findings from mobile app intelligence firm AppSensa, the X app has been updated over the past few weeks with several references related to a physical debit card, which can be customized with your X username. Dozens of new […]</article>","contentLength":331,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trust in AI Strongest in China, Low-Income Nations, UN Study Shows","url":"https://slashdot.org/story/25/06/20/1646251/trust-in-ai-strongest-in-china-low-income-nations-un-study-shows?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750437960,"author":"msmash","guid":163706,"unread":true,"content":"A United Nations study has found a sharp global divide on attitudes toward AI, with trust strongest in low-income countries and skepticism high in wealthier ones. From a report: More than 6 out of 10 people in developing nations said they have faith that AI systems serve the best interests of society, according to a UN Development Programme survey of 21 countries seen by Bloomberg News. In two-thirds of the countries surveyed, over half of respondents expressed some level of confidence that AI is being designed for good. \n\nIn China, where steady advances in AI are posing a challenge to US dominance, 83% of those surveyed said they trust the technology. Like China, most developing countries that reported confidence in AI have \"high\" levels of development based on the UNDP's Human Development Index, including Kyrgyzstan and Egypt. But the list also includes those with \"medium\" and \"low\" HDI scores like India, Nigeria and Pakistan.","contentLength":942,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Iran’s government says it shut down internet to protect against cyberattacks","url":"https://techcrunch.com/2025/06/20/irans-government-says-it-shut-down-internet-to-protect-against-cyberattacks/","date":1750437859,"author":"Lorenzo Franceschi-Bicchierai","guid":163668,"unread":true,"content":"<article>The government cited the recent hacks on Bank Sepah and cryptocurrency exchange Nobitex as reasons to shut down internet access to virtually all Iranians.</article>","contentLength":154,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Nvidia wants in on the nuclear renaissance, invests in Bill Gates-backed TerraPower","url":"https://techcrunch.com/2025/06/20/nvidia-wants-in-on-the-nuclear-renaissance-invests-in-bill-gates-backed-terrapower/","date":1750437666,"author":"Tim De Chant","guid":163667,"unread":true,"content":"<article>TerraPower has been riding a wave of interest from hyperscalers, data center developers, and now chip designers. </article>","contentLength":113,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"US Marines Witnessed Detaining A US Citizen In Los Angeles","url":"https://www.techdirt.com/2025/06/20/us-marines-witnessed-detaining-a-us-citizen-in-los-angeles/","date":1750437060,"author":"Tim Cushing","guid":163674,"unread":true,"content":"<p>As Mike Masnick <a href=\"https://www.techdirt.com/2025/06/12/noem-announces-military-will-liberate-la-from-democracy-then-watches-security-throw-senator-to-ground/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/06/12/noem-announces-military-will-liberate-la-from-democracy-then-watches-security-throw-senator-to-ground/\">noted late last week</a> while covering yet another <a href=\"https://www.youtube.com/watch?v=FrOf4_uXKmk\" data-type=\"link\" data-id=\"https://www.youtube.com/watch?v=FrOf4_uXKmk\">extremely disturbing development</a> in the ongoing horror show that is our current government, the Trump Administration isn’t fucking around. It wants to destroy America so it can have the only kind of America it’s willing to put up with: one it can rule, rather than lead.</p><blockquote><p><em>When a federal official can announce that military forces will remain in American cities until democratically elected leaders are removed, then violently detain a Senator for asking questions about it, constitutional government has effectively ended. This isn’t creeping authoritarianism—it’s the active dismantling of democratic institutions in real time.</em></p></blockquote><p>That federal official was DHS Secretary Kristi Noem. The democratically elected person who was violently detained for daring to interrupt Noem’s self-glorifying press conference was Senator Alex Padilla from California, who is the ranking member of a Senate subcommittee that directly oversees the DHS.</p><p>The authoritarianism isn’t creeping. It’s everywhere. But its primary focus right now is California. </p><p>First, Trump violated the law by commandeering National Guard forces that are supposed to be left to the discretion of the state they serve. In this case, 2,000 California National Guard members were sent to Los Angeles for extremely vague reasons. Unlike the massive rioting that occurred in 1992, the anti-mass deportation protests in California have been mostly peaceful with anything resembling a riot contained to a very small part of downtown Los Angeles.</p><p>Despite the lack of widespread violence and destruction, the Defense Department added 700 Marines to the mix, escalating this <a href=\"https://www.techdirt.com/2025/06/13/judge-no-donald-trump-cant-just-order-the-national-guard-to-invade-los-angeles/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/06/13/judge-no-donald-trump-cant-just-order-the-national-guard-to-invade-los-angeles/\">past the illegal hijacking</a> of California’s National Guard (without the permission or request of the state of California) to the <a href=\"https://www.techdirt.com/2025/06/09/trump-administration-sends-marines-to-site-of-anti-ice-protests/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/06/09/trump-administration-sends-marines-to-site-of-anti-ice-protests/\">direct deployment of the US soldiers</a> to help police protests that local law enforcement appeared to have pretty much fully contained without outside intervention.</p><p>That extra step is hugely problematic, especially if Marines start pitching in with law enforcement work — something they’re explicitly forbidden from doing. And yet, here they are, doing cop work for cops, <a href=\"https://bsky.app/profile/newseye.bsky.social/post/3lrjgrrtn6c2e\" data-type=\"link\" data-id=\"https://bsky.app/profile/newseye.bsky.social/post/3lrjgrrtn6c2e\">something captured on video</a> and (unbelievably) confirmed by the Defense Department:</p><blockquote><p><em>Asked about the incident, the U.S. military’s Northern Command spokesperson said active duty forces “may temporarily detain an individual in specific circumstances.”</em></p><p><em>“Any temporary detention ends immediately when the individual(s) can be safely transferred to the custody of appropriate civilian law enforcement personnel,” a spokesperson said.</em></p></blockquote><p>Another photo posted at Reuters shows the man’s hands are zip-tied behind him while a Marine restrains him by holding his shoulder. The ugly irony is that the man detained by Trump’s martial law trial run is an Army veteran who obtained his US citizenship via military service and was only trying to access services at the local Department of Veterans Affairs office. </p><p>Sure, this may seem like a small thing. But only if this is the only thing you see. Trump and DoD head Pete Hegseth have sent military members to the streets of Los Angeles. Administration officials have affirmatively stated there’s no end date for this mini-occupation and have actually said OUT LOUD that the ultimate goal is to remove elected leaders that disagree with them and their efforts. </p><p>This is a direct quote of DHS Secretary Kristi Noem, taken from the press conference where she stood idly by as a US senator was grabbed by armed officers and thrown to the ground: </p><blockquote><p><em>We are staying here to liberate the city from the socialist and the burdensome leadership that this governor and that this mayor have placed on this country and what they have tried to insert into this city.</em></p></blockquote><p>Sure, there may be a bit of performative hyperbole thrown in there. And, given that this is coming from a person who doesn’t know the definition of , there’s also the possibility Noem doesn’t understand some of the larger words she used during this press conference. </p><p>But make no mistake about it: if the Trump Administration thinks it can get away with a full military occupation of Los Angeles, it definitely will attempt to do it. What’s happening now is the administration testing the waters while <a href=\"https://www.techdirt.com/2025/06/12/a-manufactured-crisis-how-a-few-hooligans-in-la-became-the-pretext-for-military-rule/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/06/12/a-manufactured-crisis-how-a-few-hooligans-in-la-became-the-pretext-for-military-rule/\">manufacturing the provocations</a> it needs to move forward with the next step. Shrug this isolated instance off if you dare. It’s not going to remain an anomaly for long, not when most of the Republican party is <a href=\"https://www.techdirt.com/2025/06/11/the-gop-is-way-too-fucking-excited-about-using-us-troops-on-american-protestors/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/06/11/the-gop-is-way-too-fucking-excited-about-using-us-troops-on-american-protestors/\">actively cheering on</a> the use of military force against their fellow citizens. </p>","contentLength":4592,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Video Friday: Jet-Powered Humanoid Robot Lifts Off","url":"https://spectrum.ieee.org/video-friday-jet-powered-robot","date":1750437003,"author":"Evan Ackerman","guid":163704,"unread":true,"content":"<p>Your weekly selection of awesome robot videos</p>","contentLength":45,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MTA3OTIxOS9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc4NjU5MDcyN30.wsRqyiMeNZMeGSYPpph2sEggJXX1os1LxSc7npV72IQ/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Deezer starts labeling AI-generated music to tackle streaming fraud","url":"https://techcrunch.com/2025/06/20/deezer-starts-labeling-ai-generated-music-to-tackle-streaming-fraud/","date":1750436704,"author":"Aisha Malik","guid":163666,"unread":true,"content":"<article>Deezer announced on Friday that it will start labeling albums that include AI-generated tracks as part of its efforts to combat streaming fraud.</article>","contentLength":144,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Transforming E-Commerce Product Configuration Through Strategic Innovation by Prabhavathi Koppalli","url":"https://hackernoon.com/transforming-e-commerce-product-configuration-through-strategic-innovation-by-prabhavathi-koppalli?source=rss","date":1750436612,"author":"Sanya Kapoor","guid":163877,"unread":true,"content":"<article>Prabhavathi Koppalli transformed a sluggish, error-prone e-commerce product configuration process into a streamlined system, cutting completion time from 3 hours to 1. Her backend optimization and UI-aware refactoring improved partner satisfaction, reduced support tickets by 70%, and accelerated sales—earning her top tech awards and career growth.</article>","contentLength":351,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Naresh Koribilli's Transformative Elluminate Implementation for Oncology Research","url":"https://hackernoon.com/naresh-koribillis-transformative-elluminate-implementation-for-oncology-research?source=rss","date":1750436243,"author":"Sanya Kapoor","guid":163876,"unread":true,"content":"<article>Naresh Koribilli led a transformative Elluminate platform implementation for a major oncology trial, integrating clinical data from 1,000+ global subjects. His FDA-compliant architecture improved analytics speed, cut patient profile time by 40%, and set new standards in data quality, insight generation, and regulatory readiness across pharmaceutical research.</article>","contentLength":361,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"After raising $38M, African e-commerce startup Sabi lays off 20%, pivots to traceable exports","url":"https://techcrunch.com/2025/06/20/after-raising-38m-african-e-commerce-startup-sabi-lays-off-20-pivots-to-traceable-exports/","date":1750436161,"author":"Tage Kene-Okafor","guid":163665,"unread":true,"content":"<article>African B2B e-commerce startup Sabi has laid off around 20% of its workforce as it doubles down on a growing business in commodity exports.</article>","contentLength":139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Setting New Benchmarks in Healthcare Analytics Through Cloud Innovation by Sanchee Kaushik","url":"https://hackernoon.com/setting-new-benchmarks-in-healthcare-analytics-through-cloud-innovation-by-sanchee-kaushik?source=rss","date":1750435892,"author":"Sanya Kapoor","guid":163875,"unread":true,"content":"<article>Sanchee Kaushik designed and led a cross-cloud healthcare analytics platform that enabled real-time insights, anomaly detection, and multi-program tracking. Delivered ahead of schedule, her architecture boosted scalability, security, and performance—setting a new benchmark in healthcare analytics and influencing future AI/ML strategies.</article>","contentLength":340,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Platform Thinking in Action: Souvari Ranjan Biswal’s Enterprise Data Vision for Financial Services","url":"https://hackernoon.com/platform-thinking-in-action-souvari-ranjan-biswals-enterprise-data-vision-for-financial-services?source=rss","date":1750435584,"author":"Sanya Kapoor","guid":163874,"unread":true,"content":"<article>Souvari Ranjan Biswal led the transformation of a top U.S. bank’s data platform, delivering a real-time, cloud-native system that cut insight time from days to minutes. His leadership blended tech innovation, governance, and team building to create scalable, AI-ready infrastructure—setting new benchmarks for enterprise data in financial services.</article>","contentLength":352,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The HackerNoon Newsletter: Everyone’s an AI User Now—But No One Read the Manual (6/20/2025)","url":"https://hackernoon.com/6-20-2025-newsletter?source=rss","date":1750435439,"author":"Noonification","guid":163873,"unread":true,"content":"<p>🪐 What’s happening in tech today, June 20, 2025?</p><p>By <a href=\"https://hackernoon.com/u/mcsee\">@mcsee</a> [ 9 Min read ] Avoid NULL references that cause runtime crashes by using proper validation and null-safe patterns\n <a href=\"https://hackernoon.com/code-smell-304-null-pointer-exception-how-to-avoid-null-references-that-cause-runtime-crashes\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/vladyslav_chekryzhov\">@vladyslav_chekryzhov</a> [ 25 Min read ] Build production-ready LLM agents. Learn 15 principles for stability, control, and real-world reliability beyond fragile scripts and hacks. <a href=\"https://hackernoon.com/stop-prompting-start-engineering-15-principles-to-deliver-your-ai-agent-to-production\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/wabinab2\">@wabinab2</a> [ 9 Min read ] Garbage in, garbage out. We now consume garbage produced by AI that we have no control of the garbage they put in.  <a href=\"https://hackernoon.com/everyones-an-ai-user-nowbut-no-one-read-the-manual\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/VeronikaPolar\">@VeronikaPolar</a> [ 2 Min read ] A decade later, crypto is no longer a resistance movement. It’s a financial product category. <a href=\"https://hackernoon.com/crypto-is-no-longer-a-resistance-movement-its-a-financial-product-category\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>","contentLength":917,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Transforming IT Operations Through Advanced AI Systems by Bhavana Venkatesh Gudi","url":"https://hackernoon.com/transforming-it-operations-through-advanced-ai-systems-by-bhavana-venkatesh-gudi?source=rss","date":1750435329,"author":"Sanya Kapoor","guid":163872,"unread":true,"content":"<article>Bhavana Venkatesh Gudi developed a patented AI-powered Root Cause Analysis Engine that transformed enterprise IT operations by cutting downtime, improving efficiency, and showcasing how strategic AI implementation can solve real-world business problems through context-aware, scalable system design.</article>","contentLength":299,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Microsoft Is Deleting Old Drivers From Windows Update","url":"https://tech.slashdot.org/story/25/06/20/1539228/microsoft-is-deleting-old-drivers-from-windows-update?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750435260,"author":"msmash","guid":163637,"unread":true,"content":"BrianFagioli writes: In a move that could quietly wreak havoc across the Windows ecosystem, Microsoft is purging outdated drivers from Windows Update. The company claims it is doing this for security and reliability, but the result might be broken hardware for users who rely on legacy devices. \n\nIf you're using older peripherals or custom-built PCs, you could soon find yourself hunting for drivers that have vanished into the digital abyss. This initiative, buried in a low-profile blog post, is part of Microsoft's new cleanup program. The first wave targets legacy drivers that already have newer replacements available. But the real kicker is that Microsoft isn't warning individual users about which drivers are going away.","contentLength":730,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"After trying to buy Ilya Sutskever’s $32B AI startup, Meta looks to hire its CEO","url":"https://techcrunch.com/2025/06/20/after-trying-to-buy-ilya-sutskevers-32b-ai-startup-meta-looks-to-hire-its-ceo/","date":1750433548,"author":"Maxwell Zeff","guid":163622,"unread":true,"content":"<article>Meta CEO Mark Zuckerberg tried to acquire Ilya Sutskever's $32B AI startup, but failed, so now he's in talks to hire its CEO, Daniel Gross.</article>","contentLength":139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Behind the Blog: The Omnipresence Is the Point","url":"https://www.404media.co/behind-the-blog-the-omnipresence-is-the-point/","date":1750433211,"author":"Joseph Cox","guid":163635,"unread":true,"content":"<img src=\"https://www.404media.co/content/images/2025/06/nl6.20-1.png\" alt=\"Behind the Blog: The Omnipresence Is the Point\"><p><em>This is Behind the Blog, where we share our behind-the-scenes thoughts about how a few of our top stories of the week came together. This week, we discuss Deadheads and doxxing sites.</em></p><p>Anyone reading the site closely this week likely noticed a new name entering the chat. We’re thrilled to welcome Rosie Thomas to the gang for the summer as an editorial intern!&nbsp;</p><p>Rosie was previously a software engineer in the personal finance space. Currently halfway through her master’s degree in journalism, Rosie is interested in social movements, how people change their behaviors in the face of new technologies, and “the infinite factors that influence sentiment and opinions,” in her words. In her program, she’s expanding her skills in investigations, audio production, and field recording. She published her first blog with us on day two, a really interesting (and in 404 style, informatively disturbing) <a href=\"https://www.404media.co/cameras-exposed-to-the-internet-report/\"><u>breakdown of a new report</u></a> that found tens of thousands of camera feeds exposed to the dark web. We’re so excited to see what she does with us this summer!&nbsp;</p>","contentLength":1066,"flags":null,"enclosureUrl":"https://www.404media.co/content/images/2025/06/nl6.20-1.png","enclosureMime":"","commentsUrl":null},{"title":"SoftBank reportedly looking to launch a trillion-dollar AI and robotics industrial complex","url":"https://techcrunch.com/2025/06/20/softbank-reportedly-looking-to-launch-a-trillion-dollar-ai-and-robotics-industrial-complex/","date":1750432926,"author":"Rebecca Szkutak","guid":163621,"unread":true,"content":"<article>The investing conglomerate is looking to team up with TSMC on the initiative as SoftBank continues to pour money into AI. </article>","contentLength":122,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Semicolon Usage in British Literature Drops Nearly 50% Since 2000","url":"https://news.slashdot.org/story/25/06/20/159208/semicolon-usage-in-british-literature-drops-nearly-50-since-2000?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750432800,"author":"msmash","guid":163636,"unread":true,"content":"Semicolon usage in British literature has declined from once every 205 words in 2000 to once every 390 words today, representing a nearly 50% drop, according to analysis commissioned by language learning company Babbel. The punctuation mark appeared once every 90 words in British literature from 1781, making the current frequency the lowest on record. \n\nA survey of young learners in the London Student Network found that more than half of respondents could not correctly use semicolons, with only 11% describing themselves as frequent users. The average score on a semicolon knowledge quiz was 49%.","contentLength":601,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"VanMoof is back with a new custom e-bike and rebooted repair network","url":"https://techcrunch.com/2025/06/20/vanmoof-is-back-with-a-new-custom-e-bike-and-rebooted-repair-network/","date":1750431840,"author":"Rebecca Bellan","guid":163588,"unread":true,"content":"<article>Dutch e-bike startup VanMoof is back two years after bankruptcy with its first model designed under new leadership. And despite past criticism that VanMoof’s over-reliance on custom parts led to the company’s downfall, the S6 sticks to the brand’s signature bespoke design.&nbsp;</article>","contentLength":281,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is Mathematics Mostly Chaos or Mostly Order?","url":"https://www.quantamagazine.org/is-mathematics-mostly-chaos-or-mostly-order-20250620/","date":1750431788,"author":"Gregory Barber","guid":163616,"unread":true,"content":"<p>Last winter, at a meeting in the Finnish wilderness high above the Arctic Circle, a group of mathematicians gathered to contemplate the fate of a mathematical universe. It was minus 20 degrees Celsius, and while some went cross-country skiing, Juan Aguilera, a set theorist at the Vienna University of Technology, preferred to linger in the cafeteria, tearing pieces of pulla pastry and debating…</p>","contentLength":398,"flags":null,"enclosureUrl":"https://www.quantamagazine.org/wp-content/uploads/2025/06/New-Infinities_crWei-AnJin-Default.webp","enclosureMime":"","commentsUrl":null},{"title":"Protect Yourself From Meta’s Latest Attack on Privacy","url":"https://www.eff.org/deeplinks/2025/06/protect-yourself-metas-latest-attack-privacy","date":1750431688,"author":"Rory Mir","guid":163717,"unread":true,"content":"<h3></h3><p><a href=\"https://privacybadger.org/\"></a></p><p><a href=\"https://localmess.github.io/#description\"></a></p><p><a href=\"https://themarkup.org/pixel-hunt/2022/06/16/facebook-is-receiving-sensitive-medical-information-from-hospital-websites\"></a></p><p><a href=\"https://localmess.github.io/#faq\"></a><a href=\"https://web.archive.org/web/20250531105747/https://developers.facebook.com/community/threads/317050484803752/\"></a><a href=\"https://web.archive.org/web/20250531105711/https://developers.facebook.com/community/threads/937149104821259/\"></a><a href=\"https://arstechnica.com/security/2025/06/meta-and-yandex-are-de-anonymizing-android-users-web-browsing-identifiers/\"></a></p><p><a href=\"https://localmess.github.io/#faq\"></a></p><h3></h3><p><b>Use a Privacy-Focused Browser</b></p><p><a href=\"https://www.zdnet.com/article/facebook-was-tracking-your-text-message-and-phone-call-data-now-what/\"></a><a href=\"https://www.eff.org/deeplinks/2022/05/how-disable-ad-id-tracking-ios-and-android-and-why-you-should-do-it-now\"></a></p><p><a href=\"https://privacybadger.org\"></a><a href=\"https://privacybadger.org\"></a></p><p><b>Limit Meta’s Use of Your Data</b></p><p><a href=\"https://www.eff.org/deeplinks/2025/01/mad-meta-dont-let-them-collect-and-monetize-your-personal-data\"></a></p><h3></h3><p><b>Chrome should support extensions on Android</b></p><p><b>Chrome should protect its users by blocking known trackers</b><a href=\"https://www.ghostery.com/whotracksme\"></a><a href=\"https://support.apple.com/en-us/105030\"></a><a href=\"https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop\"></a><a href=\"https://github.com/explainers-by-googlers/script-blocking\"></a></p><h3></h3><p><a href=\"https://www.eff.org/deeplinks/2021/11/after-facebook-leaks-here-what-should-come-next\"></a></p><p><a href=\"https://www.eff.org/deeplinks/2022/03/ban-online-behavioral-advertising\"></a></p>","contentLength":161,"flags":null,"enclosureUrl":"https://www.eff.org/files/banner_library/third_party_tracking_banner.png","enclosureMime":"","commentsUrl":null},{"title":"Find out how Flexport’s CEO, Ryan Petersen, builds when the rules keep changing at TechCrunch Disrupt 2025","url":"https://techcrunch.com/2025/06/20/find-out-how-flexports-ceo-ryan-petersen-builds-when-the-rules-keep-changing-at-techcrunch-disrupt-2025/","date":1750431600,"author":"TechCrunch Events","guid":163586,"unread":true,"content":"<article>Ryan Petersen, CEO of Flexport, joins the Builders Stage at TechCrunch Disrupt 2025 is happening October 27–29 at Moscone West in San Francisco. Register to join.</article>","contentLength":164,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Boston Side Events lineup at TechCrunch All Stage with Fidelity Private Shares, Women Tech Meetup, Prepare 4 VC, and more","url":"https://techcrunch.com/2025/06/20/boston-side-events-line-up-at-all-stage-with-fidelity-private-shares-women-tech-meetup-prepare-4-vc-and-more/","date":1750431600,"author":"TechCrunch Events","guid":163587,"unread":true,"content":"<article>Get ready to amplify your TechCrunch All Stage 2025 experience with the electrifying lineup of Side Events taking Boston by storm during the week of July 13–19. As the countdown to TC All Stage begins, we’re thrilled to share our Side Events lineup, where you can foster meaningful connections within the vibrant Boston tech community. […]</article>","contentLength":345,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Broadcom's Answer To VMware Pricing Outrage: You're Using It Wrong","url":"https://it.slashdot.org/story/25/06/20/1331257/broadcoms-answer-to-vmware-pricing-outrage-youre-using-it-wrong?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750430400,"author":"msmash","guid":163618,"unread":true,"content":"A senior Broadcom executive has defended VMware's controversial licensing changes by arguing that customers complaining about costs simply weren't using the software bundles properly. VMware shifted away from selling perpetual licenses for individual products to subscription bundles after Broadcom's acquisition. Some smaller and mid-sized customers claim their costs increased eight to 15 times under the new pricing structure, prompting migration plans to alternative platforms. \n\nJoe Baguley, Broadcom's chief technology officer for EMEA, countered that 87% of VMware's top 10,000 customers have signed up for VMware Cloud Foundation, and that cost complaints \"don't play out\" when Broadcom sits down with customers directly.","contentLength":729,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Startup hiring isn’t just about the pitch, it’s about the package — Pulley, 645 Ventures, and Epigram Legal break it down at TechCrunch Disrupt 2025","url":"https://techcrunch.com/2025/06/20/startup-hiring-isnt-just-about-the-pitch-its-about-the-package-pulley-645-ventures-and-epigram-legal-break-it-down-at-techcrunch-disrupt-2025/","date":1750429800,"author":"TechCrunch Events","guid":163585,"unread":true,"content":"<article>Leaders from Pulley, 645 Ventures, and Epigram Legal join the TechCrunch Disrupt 2025 Builder Stage, happening on October 27-29 in San Francisco. Register to join.</article>","contentLength":163,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Microcontrollers: Getting Started","url":"https://www.youtube.com/watch?v=Sd42q3OaOrE","date":1750428055,"author":"Jeff Geerling","guid":163620,"unread":true,"content":"<article>Thanks to Micro Center for sponsoring this video!\n\nMicro Center Santa Clara: https://micro.center/9d2732\nShop Micro Center’s Selection of Boards and Projects: https://micro.center/2c0426\nShop Micro Center’s Selection of Maker/ STEM Products: https://micro.center/cf245a\nShop Micro Center’s Laptop Savings Event: https://micro.center/79e60d\n\nThanks especially to everyone I met in Santa Clara for helping make this video happen! For all the code used in the demos, check out this GitHub Gist:\n\nhttps://gist.github.com/geerlingguy/4d519887aeb462ba9501961a32ae3f71\n\nResources mentioned in this video:\n\n  - Steve Wozniak on the relay: https://youtu.be/hsB8Hxnb52o?t=367\n  - Open Circuits: https://amzn.to/446b9pb\n  - PicoBricks Base Kit: https://amzn.to/4jUv7sI (also check Micro Center for availability)\n  - PicoBricks IDE: https://picobricks.com/pages/ide?ose=false\n  - MicroBlocks IDE: https://microblocks.fun\n\nOther YouTube channels I follow for microcontrollers and electronics:\n\n  - ElectroBOOM: https://www.youtube.com/@ElectroBOOM\n  - GreatScott!: https://www.youtube.com/@greatscottlab\n  - Andreas Speiss: https://www.youtube.com/@AndreasSpiess\n  - Ben Eater: https://www.youtube.com/@BenEater\n  - Device Orchestra: https://www.youtube.com/@DeviceOrchestra\n  - Sean Hodgins: https://www.youtube.com/@SeanHodgins\n  - EEVBlog: https://www.youtube.com/@EEVblog\n  - Big Clive: https://www.youtube.com/@bigclivedotcom\n\nThere are plenty of other great channels too, please share your favorites in the comments!\n\nSupport me on Patreon: https://www.patreon.com/geerlingguy\nSponsor me on GitHub: https://github.com/sponsors/geerlingguy\nMerch: https://www.redshirtjeff.com\n2nd Channel: https://www.youtube.com/@GeerlingEngineering\n3rd Channel: https://www.youtube.com/@Level2Jeff\n\nContents:\n\n00:00 - Tiny explosions, ft electricity\n01:06 - Learning the basics in Silicon Valley\n02:22 - New MC in the Valley\n03:30 - Getting started with PicoBricks\n05:43 - Hello, world on a microcontroller\n10:33 - Debugging a custom dusk-to-dawn light\n16:00 - Exploding things at Micro Center\n16:36 - Exploding things back home\n18:31 - High power, hydrogen, and electrolytic caps\n19:46 - Going bigger</article>","contentLength":2184,"flags":null,"enclosureUrl":"https://www.youtube.com/v/Sd42q3OaOrE?version=3","enclosureMime":"","commentsUrl":null},{"title":"Lawmakers in Britain Narrowly Approve Bill To Legalize Assisted Dying","url":"https://news.slashdot.org/story/25/06/20/1354239/lawmakers-in-britain-narrowly-approve-bill-to-legalize-assisted-dying?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750428000,"author":"msmash","guid":163617,"unread":true,"content":"Lawmakers in Britain have narrowly approved a bill to legalize assisted dying for terminally ill people, capping a fraught debate in Parliament and across the country that cut across political, religious and legal divides. From a report: MPs passed the bill by 314 votes to 291, in their final say on the question. The bill -- which has split lawmakers and sparked impassioned conversations with their constituents the breadth of Britain -- will now move to the House of Lords for its final rounds of scrutiny. \n\nFriday's vote puts Britain firmly on track to join a small club of nations that have legalized the process, and one of the largest by population to allow it. It allows people with a terminal condition and less than six months to live to take a substance to end their lives, as long as they are capable of making the decision themselves. Two doctors and a panel would need to sign off on the choice. Canada, New Zealand, Spain and most of Australia allow assisted dying in some form, as do several US states, including Oregon, Washington and California.","contentLength":1065,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"3 more days to fuel your next big move — and save up to $210 on your TechCrunch All Stage pass","url":"https://techcrunch.com/2025/06/20/3-more-days-to-fuel-your-next-big-move-and-save-up-to-210-on-techcrunch-all-stage-passes/","date":1750428000,"author":"TechCrunch Events","guid":163548,"unread":true,"content":"<article>3 days to save up to $210 on your TechCrunch All Stage pass, happening July 15 in Boston’s SoWa Power Station. Prices go up after June 22. Register now.</article>","contentLength":154,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tesla partners with Electrify Expo to launch full-weekend EV test drives","url":"https://techcrunch.com/2025/06/20/tesla-partners-with-electrify-expo-to-launch-full-weekend-ev-test-drives/","date":1750428000,"author":"Sean O'Kane","guid":163549,"unread":true,"content":"<article>The 48-hour take-home program will be available to attendees of the upcoming Electrify Expo in Los Angeles, with more automakers joining soon.</article>","contentLength":142,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Vulkan 1.4.319 Published With New Data Graph Extension","url":"https://www.phoronix.com/news/Vulkan-1.4.319-Released","date":1750428000,"author":"Michael Larabel","guid":163594,"unread":true,"content":"<article>Just one week after Vulkan 1.4.318 was introduced with a new Valve extension, Vulkan 1.4.319 released this morning with another new extension...</article>","contentLength":144,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meta unveils its Oakley smart glasses","url":"https://techcrunch.com/2025/06/20/meta-unveils-its-oakley-smart-glasses/","date":1750426801,"author":"Aisha Malik","guid":163547,"unread":true,"content":"<article>After months of rumors, Meta has officially announced its next pair of smart glasses with Oakley.</article>","contentLength":97,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"5 Data Breaches That Ended in Disaster (and Lessons Learned)","url":"https://hackernoon.com/5-data-breaches-that-ended-in-disaster-and-lessons-learned?source=rss","date":1750426228,"author":"N2W","guid":163716,"unread":true,"content":"<article>This article covers 5 devastating data breaches—including TravelEx, MediSecure, and Code Spaces—that forced companies to shut down. Each case reveals how weak data protection, lack of backups, and poor disaster recovery led to collapse. Learn critical lessons on immutable backups, cross-account recovery, and ransomware resilience to safeguard your business.</article>","contentLength":363,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Can You Talk Software Into Existence? SimplyLang Thinks So","url":"https://hackernoon.com/can-you-talk-software-into-existence-simplylang-thinks-so?source=rss","date":1750425303,"author":"Affan Shaikhsurab","guid":163715,"unread":true,"content":"<p>I just learned about a idea that really fired me up—and I think that it's something that more individuals should be talking about.</p><p>We've witnessed the progression of software—how it's moved from the arcane punch cards and assembly languages of old to the high-level languages today such as Python and JavaScript. But in recent years, there's a subtle transformation that's a revolutionary transformation:</p><blockquote><p><strong>Programming is becoming increasingly similar to natural human language.</strong></p></blockquote><p>Consider this: instead of typing loops out like <code>for (int i = 0; i &lt; 5; i++)</code>, you just type:</p><pre><code>Repeat 5 times say \"hello world\" .\n</code></pre><p>That is not pseudo-code. That is actual running code in a toy programming language I've been developing called <a href=\"https://github.com/affanshaikhsurab/simplylang\">SimplyLang</a>. It's a small project—but I think it suggests something much bigger.</p><p>Every programming decade has had a single overarching trend: . Each one carries us further from the naked machine complexity and closer to the human mind:</p><ul><li>: Strong but incomprehensible.</li><li>: Simpler but still low-level.</li><li><strong>AI tools such as Copilot / ChatGPT</strong>: Now we're coding with prompts and receiving real, functional code.</li></ul><p>And now we're asking ourselves: <em>Why not avoid the syntax altogether?</em></p><p>If the computer can understand intent, then we might be able to stop thinking in terms of machines and start designing software the way we express ideas naturally.</p><h2>Why Abstraction is Important</h2><p>The closest analogy I can provide is to order chocolate.</p><p>You say, \"I'd like a dark chocolate bar.\".</p><p>You don't need to be aware of how cacao beans are roasted, ground, and tempered. Someone or something does that for you.</p><p>The programming must be the same.</p><p>With growing abstraction:</p><ul><li>No more worrying about brackets, semicolons, or package installs.</li><li>No more import not found debugging or compiler installations.</li><li>Just focus on , and let the system figure out .</li></ul><p>That's the power of combining abstraction and AI. And it's not science fiction – it's already underway.</p><p>AI is not yet another piece of the stack. It's becoming the .</p><ul><li>It knows the  of what you are attempting to construct.</li><li>It fills in the blanks that you hadn't left entirely defined.</li><li>It is consistent with your style, your objectives, and your mission.</li></ul><p>Whereas we used to have human interpreters for machines, we are now at a point where <strong>machines are interpreting for us</strong>.</p><p>That is, less and less about code, but about .</p><h2>A Small-Scale Experiment but a Grand Idea</h2><p>I tried this method with <a href=\"https://simplylang.org/\">SimplyLang</a>. It is a small interpreter that takes basic English-like commands and runs them.</p><pre><code>Repeat 10 times say \"hello\" .\n</code></pre><p>\\\nNo syntax errors. No indent rules. No cryptic phrases. It's not trying to replace Python or match industrial-strength languages. But it  pose a bigger question:</p><blockquote><p>What if the next generation of coders isn't programmed to code—but programmed to express intent?</p></blockquote><p>From  → to .</p><h2>Why It Matters (To Everyone)</h2><ul><li> can focus on solving problems rather than memorizing syntax.</li><li> can automate flows without having to learn entire frameworks.</li><li> can accomplish things faster without boilerplate.</li><li>, and not technical capability, is the actual limitation. The takeaway?</li></ul><p><strong>The more we abstract complexity, the more room we make for innovation.</strong></p><p>We're early yet, but this is what seems inevitable:</p><ul><li> that manage complete project scaffolding from requests in plain English.</li><li> in which each abstraction smoothly passes along to the next.</li><li>A world where **no-code / low-code turns into \"speak-code\".</li></ul><p>Soon enough, \"coding\" will no longer be about coding—maybe it'll just be about .</p><p>We've already passed the days of 1s and 0s—and we're moving towards a future where one with a good idea, and some reasonably well-written sentences, can bring that idea to life.</p><p>I'd love to hear what the Hacker News community thinks: Is natural-language programming a flash in the pan, or an authentic peek at the computing future? If you're interested, give <a href=\"https://github.com/affanshaikhsurab/simplylang\">SimplyLang</a> a shot or simply follow along. For if we can talk  code… what else can we start talking  existence?</p>","contentLength":3934,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Code Smell 304: Null Pointer Exception - How to Avoid NULL References That Cause Runtime Crashes","url":"https://hackernoon.com/code-smell-304-null-pointer-exception-how-to-avoid-null-references-that-cause-runtime-crashes?source=rss","date":1750424405,"author":"Maximiliano Contieri","guid":163714,"unread":true,"content":"<p><em>I keep writing about NULL problems, yet every day the news reminds me: NULL is still alive and kicking.</em></p><blockquote><p>TL;DR: Avoid NULL references that cause runtime crashes by using proper validation and null-safe patterns</p></blockquote><ul><li>Poor error handling: The code crashed instead of gracefully handling null data</li><li>No <a href=\"https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-vi-cmj31om\">feature flags</a>: New code wasn't gradually rolled out with safety controls</li><li>No randomized backoff: Recovery caused infrastructure overload</li><li>Inadequate testing: The failure scenario was never tested during deployment</li></ul><ol><li>Use null checks if nulls are beyond your control (for example, an external API)</li><li>Initialize default values</li></ol><p>On June 12th, 2025, a <a href=\"https://status.cloud.google.com/incidents/ow5i3PPK96RduMcb1SsW\">major outage</a> happened on Google Cloud Platform.</p><p>\\\nIt affected dozens of Google Cloud and Google Workspace services globally from approximately 10:49 AM to 1:49 PM PDT (3 hours total), with some services taking longer to recover fully.</p><p>\\\nThe outage was caused by a cascading failure in Google's API management system:</p><p>On May 29, 2025, Google deployed new code to \"Service Control\" (their API management system) that added additional quota policy checks.</p><p>On June 12, a policy change containing blank/ fields was pushed to the global database that Service Control uses. When Service Control attempted to process these blank fields, it encountered a null pointer in the unprotected code path, resulting in the binaries crashing in an infinite loop.</p><p>Since quota management is global, this corrupted data was replicated worldwide within seconds, causing Service Control to crash in every region.</p><p>\\\nNull pointer exceptions happen when you try to access methods or properties on objects that don't exist.</p><p>\\\nThis happens when variables contain null references instead of valid object instances.</p><p>\\\nThe problem becomes particularly dangerous in production environments where these exceptions can crash your application and frustrate users.</p><p>\\\nLanguages like Java, C#, and JavaScript are especially prone to this issue, though modern language features and patterns can help you avoid these crashes entirely.</p><p>\\\nNulls have been a significant problem in the software industry for decades, yet software engineers continue to ignore them despite the warnings of their creator.</p><pre><code>public class ServiceControlPolicy {\n  private SpannerDatabase spannerDB;\n  private QuotaManager quotaManager;\n\n  public void applyPolicyChange(PolicyChange change) {\n      // NULL POINTER: change can be null\n      Policy policy = spannerDB.getPolicy(change.getPolicyId());\n      // NULL POINTER: policy can be null from the database\n      String quotaField = policy.getQuotaField();\n      // NULL POINTER: quotaField can be null (blank field)\n      quotaManager.updateQuota(quotaField, change.getValue());\n  }\n\n  public void exerciseQuotaChecks(String region) {\n      // NULL POINTER: policies list can be null\n      List&lt;Policy&gt; policies = spannerDB.getPoliciesForRegion(region);\n      for (Policy policy : policies) {\n          // NULL POINTER: individual policy can be null\n          String quotaValue = policy.getQuotaField();\n          // NULL POINTER: quotaValue can be null before trim()\n          quotaManager.checkQuota(quotaValue.trim());\n      }\n  }\n\n  public boolean validatePolicyData(Policy policy) {\n      // NULL POINTER: policy parameter can be null\n      String quotaField = policy.getQuotaField();\n      // NULL POINTER: quotaField can be null before length()\n      return quotaField.length() &gt; 0 &amp;&amp; \n             !quotaField.equals(\"null\");\n  }\n\n  public void replicateGlobally(PolicyChange change) {\n      List&lt;String&gt; regions = getGlobalRegions();\n      for (String region : regions) {\n          // NULL POINTER: change.getPolicy() can return null\n          spannerDB.insertPolicy(region, change.getPolicy());\n      }\n  }\n}\n</code></pre><pre><code>public class ServiceControlPolicy {\n  private SpannerDatabase spannerDB;\n  private QuotaManager quotaManager;\n\n  public void applyPolicyChange(PolicyChange change) {\n      if (change == null) {\n          // Assuming it comes from an external API\n          // Beyond your control\n          change = new NullPolicyChange();\n      }\n\n      Policy policy = findPolicyOrNull(change.policyId());\n      String quotaField = policy.quotaField();\n      if (!quotaField.isEmpty()) {\n          quotaManager.updateQuota(quotaField, change.value());\n      }\n  }\n\n  public void exerciseQuotaChecks(String region) {\n      if (region == null || region.isEmpty()) {\n          // Assuming it comes from an external API\n          // Beyond your control\n          return;\n      }\n\n      List&lt;Policy&gt; policies = policiesOrEmpty(region);\n\n      for (Policy policy : policies) {\n          String quotaValue = policy.quotaField();\n          if (!quotaValue.isEmpty()) {\n              quotaManager.checkQuota(quotaValue.trim());\n          }\n      }\n  }\n\n  public boolean validatePolicyData(Policy policy) {\n      if (policy == null) {\n          // Assuming it comes from an external API\n          // Beyond your control\n          // From now on, you wrap it\n          policy = new NullPolicy();\n      }\n\n      String quotaField = policy.quotaField();\n      return quotaField.length() &gt; 0;\n  }\n\n  public void replicateGlobally(PolicyChange change) {\n      if (change == null) {\n          // Assuming it comes from an external API\n          // Beyond your control\n          // From now on, you wrap it\n          change = new NullPolicyChange();\n      }\n\n      Policy policy = change.policy();\n      if (policy == null) {\n          // Assuming it comes from an external API\n          // Beyond your control\n          // From now on, you wrap it\n          policy = new NullPolicy();\n      }\n\n      List&lt;String&gt; regions = globalRegions();\n      for (String region : regions) {\n          spannerDB.insertPolicy(region, policy);\n      }\n  }\n\n  private Policy findPolicyOrNull(String policyId) {\n      Policy policy = spannerDB.policy(policyId);\n      return policy != null ? policy : new NullPolicy();\n  }\n\n  private List&lt;Policy&gt; policiesOrEmpty(String region) {\n      List&lt;Policy&gt; policies = spannerDB.policiesForRegion(region);\n      if (policies == null) {\n          // This is a good NullObject\n          return Collections.emptyList();\n      }\n\n      return policies.stream()\n              .map(p -&gt; p != null ? p : new NullPolicy())\n              .collect(Collectors.toList());\n  }\n}\n\nclass NullPolicy extends Policy {\n  @Override\n  public String quotaField() { return \"\"; }\n\n  @Override\n  public String policyId() { return \"unknown-policy\"; }\n\n  @Override\n  public Map&lt;String, String&gt; metadata() { \n      return Collections.emptyMap(); \n  }\n}\n\nclass NullPolicyChange extends PolicyChange {\n  @Override\n  public String policyId() { return \"\"; }\n\n  @Override\n  public String value() { return \"\"; }\n\n  @Override\n  public Policy policy() { return new NullPolicy(); }\n}\n</code></pre><p>You can detect potential null pointer exceptions by reviewing code for direct method calls on objects without null checks.</p><p>\\\nLinters can examine return values from methods that might return , looking for uninitialized object fields, and using static analysis tools that flag potential null dereferences.</p><p>\\\nModern IDEs often highlight these issues with warnings.</p><p>In the <a href=\"https://hackernoon.com/the-one-and-only-software-design-principle-1x983ylp\">real world</a>, objects either exist or they don't.</p><p>\\\nBreaking this bijection by allowing null references creates phantom objects that exist in your code but not in the real world, leading to crashes when you try to interact with these non-existent entities.</p><p>AI generators frequently create code with null pointer vulnerabilities because they focus on happy path scenarios.</p><p>\\\nThey often generate method calls without considering edge cases where objects might be , especially in complex object hierarchies or when dealing with external data sources.</p><p>AI tools can detect and fix null pointer issues when you provide clear instructions about defensive programming practices.</p><p><em>Remember: AI Assistants make lots of mistakes</em></p><blockquote><p>Suggested Prompt: Remove all Null References</p></blockquote><p>Null pointer exceptions represent one of the most common runtime errors in programming.</p><p>\\\nYou can remove most of these crashes by implementing proper null checks, using the Null Object design pattern, and adopting defensive programming practices. </p><p>\\\nThe small overhead of validation code pays off significantly in application stability and user experience.</p><blockquote><p>I call it my billion-dollar mistake. It was the invention of the null reference in 1965</p></blockquote><p>This article is part of the CodeSmell Series.</p>","contentLength":8362,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Turning Coalmines Into Solar Energy Plants 'Could Add 300GW of Renewables By 2030'","url":"https://hardware.slashdot.org/story/25/06/20/0129241/turning-coalmines-into-solar-energy-plants-could-add-300gw-of-renewables-by-2030?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750424400,"author":"msmash","guid":163511,"unread":true,"content":"Turning recently closed coalmines into solar energy plants could add almost 300GW of renewable energy by 2030, converting derelict wastelands to productive use, according to a new report. From a report: In a first of its kind analysis, researchers from Global Energy Monitor (GEM) identified 312 surface coalmines closed since 2020 around the world, and 134 likely to close by the end of the decade, together covering 5,820 sq km (2,250 sq miles) -- a land area nearly the size of Palestine. \n\nStrip mining turns terrains into wastelands, polluted and denuded of topsoil. But if they were filled with solar panels and developed into energy plants, the report claims, they could generate enough energy to power as big and power hungry a nation as Germany.","contentLength":754,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Linux Delivering Driver Fix For 30 Year Old Creative SoundBlaster AWE32 ISA Sound Card","url":"https://www.phoronix.com/news/Linux-6.16-SoundBlaster-AWE32","date":1750423920,"author":"Michael Larabel","guid":163518,"unread":true,"content":"<article>Thirty-one years after Creative Technology introduced the Sound Blaster AWE32 ISA-based sound card, the open-source driver support within the Linux kernel continues to be worked on... Submitted today for Linux 6.16 is fixing support for this once mighty ISA sound card from the mid 90's...</article>","contentLength":289,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Business Pros Underestimate AI Risks Compared to Tech Teams, Social Links Study Shows","url":"https://hackernoon.com/business-pros-underestimate-ai-risks-compared-to-tech-teams-social-links-study-shows?source=rss","date":1750423561,"author":"HackerNoon Press Releases","guid":163713,"unread":true,"content":"<p>A new study from Social Links, a leader in open-source intelligence solutions, reveals a gap between business and technical professionals when it comes to recognizing the risks posed by AI-powered cyberattacks. Despite the rapid rise in threat sophistication, business respondents appear significantly less concerned thаn their tech colleagues. This fact highlights a potential blind spot in organizational preparedness.</p><p>The survey gathered insights from 237 professionals (from CEO and Technical C-level to Cybersecurity Specialists and Product Managers) across various industries, including Financial Services, Technology, Manufacturing, Retail, Healthcare, Logistics, Government, etc.</p><p>The results showed that just 27.8% of business people (professionals in non-technical, business-oriented roles) identified usage of AI to generate fake messages as one of the most relevant cyber threats. In contrast, 53.3% of technical professionals flagged it as a top concern—nearly double the level of alarm. A similar pattern emerged around deepfake technology: 46.7% of technical staff expressed concern, compared to just 27.8% of business respondents.</p><p>This gap underscores a critical vulnerability in organizational security: business professionals, who often make prime targets for sophisticated AI-driven social engineering and deepfake schemes, show notably lower levels of concern or awareness about these threats.</p><p>At the same time, the most vulnerable departments for cyber threats identified by respondents were Finance and Accounting (24.1%), IT and Development (21.5%), HR and Recruitment (15.2%), and Sales and Account Manаgement (13.9%).</p><blockquote><p><em>“This is no longer a question of ‘if’—AI-powered threats are already here and evolving quickly,” says Ivan Shkvarun, CEO of Social Links. “We’re seeing a clear gap between those building defenses and those most likely to be targeted. Bridging that gap requires not just better technical tools, but broader awareness and education across all levels of an organization.”</em></p></blockquote><h2>Key Insights from the Research:</h2><p>Traditional vs. AI-Driven Threats: While phishing and email fraud remain the most cited threats (69.6%), followed by malware/ransomware (49.4%), AI-driven attacks are gaining ground. 39.2% of respondents identified the use of AI to craft fake messages and campaigns as a major concern, and 32.9% pointed to deepfakes and synthetic identities—confirming that generative technologies are now a recognized part of the corporate threat landscape.</p><blockquote><p><em>“Traditional threats like phishing and malware still dominate the charts. But what we’re seeing now is that AI isn’t replacing these risks, it’s supercharging them, turning generic scams into tailored operations—fast, cheap, and more convincing. That’s the real shift: automation and personalization at scale,” explains Ivan.</em></p></blockquote><p>Employee Footprint Risk: 60.8% of respondents report that employees use corporate accounts for personal purposes—such as posting on forums, engaging on social media, or updating public profiles. 59.5% also link publicly available employee data (e.g., LinkedIn bios, activities in forums and blogs) to real cyber incidents, identifying it as a recurring entry point for attacks.</p><p>Unregulated AI Adoption: Over 82% of companies let employees use AI tools at work, yet only 36.7% have a formal policy that controls how those tools are used. This gap fuels “Shadow AI”—the unsanctioned adoption of chatbots, code assistants, or other AI services without IT oversight, which can leak sensitive data and create hidden security and compliance risks.</p><blockquote><p><em>“You can’t really stop people from using work accounts or data when they’re active online. The same goes for AI tools: people will use them to save time or get help with tasks, whether there’s a policy or not. But all this activity leaves digital traces. And those traces can make it easier for scammers to find and target employees. What actually helps is teaching people how to spot the risks and giving them the right tools to stay safe, instead of just saying ‘don’t do it,’” explains Ivan.</em></p></blockquote><p>The research emphasizes that effective cybersecurity in the AI era requires a holistic approach that extends beyond technical controls to include comprehensive human-centric security programs.</p><p>Employee training on safe AI use was overwhelmingly perceived by survey respondents as the most effective mitigation measure for \"Shadow AI\" (72.2%), followed by the development of internal policies (46.8%).</p><p>Social Links is committed to addressing these evolving challenges and has recently launched the , aimed at further exploring and mitigating the risks posed by advanced AI-driven threats.</p><p>Social Links is a global provider of open-source intelligence (OSINT) solutions, recognized as an industry leader by Frost &amp; Sullivan. Headquartered in the United States, the company also has an office in the Netherlands. Social Links brings together data from over 500 open sources covering social media, messengers, blockchains, and the Dark Web, enabling users to visualize and analyze a comprehensive informational picture and streamline investigations. Its solutions support essential processes across various sectors, including law enforcement, national security, cybersecurity, due diligence, banking, and more. Companies from the S&amp;P 500 and public organizations in over 80 countries rely on Social Links products every day.</p>","contentLength":5414,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intel's OpenVINO 2025.2 Brings Support For New Models, GenAI Improvements","url":"https://www.phoronix.com/news/OpenVINO-2025.2","date":1750422958,"author":"Michael Larabel","guid":163517,"unread":true,"content":"<article>Intel open-source software developers this week released OpenVINO 2025.2 as the latest update to this prominent free software AI toolkit...</article>","contentLength":139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Salt Typhoon Hack Keeps Getting Worse, Telecoms Tell Employees To Stop Looking For Evidence Of Intrusion","url":"https://www.techdirt.com/2025/06/20/salt-typhoon-hack-keeps-getting-worse-telecoms-tell-employees-to-stop-looking-for-evidence-of-intrusion/","date":1750422660,"author":"Karl Bode","guid":163516,"unread":true,"content":"<p>Like most hacks, the scale of the intrusion was significantly worse than originally stated. Last week, <a href=\"https://www.nextgov.com/cybersecurity/2025/06/us-agencies-assessed-chinese-telecom-hackers-likely-hit-data-center-and-residential-internet-providers/405920/?oref=ng-homepage-river\">insiders told NextGov</a> that Comcast and data center giant Digital Realty&nbsp;were also caught up in the hack and had their systems compromised. The same insiders stated that government officials aren’t really sure that they have a full grasp on the attack’s impact:</p><blockquote><p><em>“Various agencies across the U.S. government are in possession of lists of confirmed or potential victims, but it’s not clear if the tallies are consistent with each other, adding to <strong>confusion about who may have been accessed, targeted or marked for investigation, one of the people said</strong>.”</em></p></blockquote><p>But it’s this little bit in the report that I thought was of particular note:</p><blockquote><p><em>“Inside two major U.S. telecom operators, incident <strong>response staff have been instructed by outside counsel not to look for signs of Salt Typhoon</strong>, said one of the people, declining to name the firms because the matter is sensitive.”</em></p></blockquote><p>So big telecoms are so afraid of liability and government oversight they’ve just <strong>stopped looking for evidence of intrusion</strong> in one of the worst hacks the U.S. has ever seen. That’s sure to fix the problem.</p><p>The U.S. business press covering the hack refuse to talk about it, but a major catalyst for the hack was the <a href=\"https://www.techdirt.com/2024/12/30/mindlessly-deregulating-u-s-telecom-contributed-to-the-worst-hack-in-u-s-history/\">steady and mindless deregulation of the U.S. telecom sector</a>. Libertarians and right wingers, “free market” think tanks in tow, spent the better part of the last thirty years insisting that gutting all meaningful state and federal oversight would result in vast, near-Utopian outcomes.</p><p>Again, the second Trump administration is utterly indistinguishable from a foreign attack. Because it’s dressed up in so much domestic religious and pseudo-populist , it’s in many ways . </p>","contentLength":1772,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"‘Martyrdom or Bust:’ Texas Man Caught Plotting Terror Attack Through Roblox Chats","url":"https://www.404media.co/martyrdom-or-bust-texas-man-caught-plotting-terror-attack-through-roblox-chats/","date":1750420841,"author":"Matthew Gault","guid":163483,"unread":true,"content":"<img src=\"https://www.404media.co/content/images/2025/06/roblox.png\" alt=\"‘Martyrdom or Bust:’ Texas Man Caught Plotting Terror Attack Through Roblox Chats\"><p>The FBI has accused a Texas man, James Wesley Burger, of planning an Islamic State-style terrorist attack on a Christian music festival and talking about it on Roblox. The feds caught Burger after another Roblox user overheard his conversations about martyrdom and murder and tipped them off. The feds said that when they searched Burger’s phone they found a list of searches that included “ginger isis member” and “are suicide attacks haram in islam.”&nbsp;</p><p>According to <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.txwd.1172850957/gov.uscourts.txwd.1172850957.1.0.pdf?ref=404media.co\"></a>, a Roblox player contacted federal authorities after seeing another player called “Crazz3pain” talking about killing people. Screenshots from the server and included in the charging documents show Roblox avatars with beards dressed in Keffiyehs talking about dealing a “greivoius [sic] wound upon followers of the cross.”</p><p>“The witness observed the user of Crazz3pain state they were willing, as reported by the Witness, to ‘kill Shia Musilms at their mosque,” court records said. “Crazz3pain and another Roblox user[…]continued to make violent statements so the witness left the game.”</p><p>The witness stayed off of Roblox for two days and when they returned they saw Crazz3pain say something else that worried them, according to the court filing. “The Witness observed Crazz3pain tell Roblox User 1 to check their message on Discord,” the charging document said. “Roblox User 1 replied on Roblox to Crazz3pain, they should delete the photograph of firearms within the unknown Discord chat, ‘in case it was flagged as suspicious…the firearms should be kept hidden.”</p><p>According to the witness, Crazz3pain kept talking about their desire to commit “martyrdom” at a Christian event and that he wanted to “bring humiliation to worshippers of the cross.” The Witness allegedly asked Crazz3pain if the attack would happen at a church service and Crazz3pain told them it would happen at a concert.&nbsp;</p><p>Someone asked Crazz3pain when it would happen. “‘It will be months…Shawwal…April,’” Crazz3pain said. Shawwal is the month after Ramadan in the Islamic calendar. The conversations the witness shared with the FBI happened on January 21 and 23, 2025.</p><p>Roblox gave authorities Crazz3pain’s email address, name, physical address, and IP address and it all pointed back to James Wesley Burger. The FBI searched Burger’s home on February 28 and discovered that someone in his family had put on a keylogger on the laptop he used to play Roblox and that they’d captured a lot of what he’d been typing while playing the game. They turned over the records to the feds.</p><p>“The safety of our community is among our highest priorities. In this case, we moved swiftly to assist law enforcement’s investigation before any real-world harm could occur and&nbsp;investigated and took action in accordance with our policies. We have a robust set of proactive and preventative safety measures designed to help swiftly detect and remove content that violates our policies,\" a spokesperson for Roblox told 404 Media. \"Our Community Standards explicitly prohibit any content or behavior that depicts, supports, glorifies, or promotes terrorist or extremist organizations in any way. We have dedicated teams focused on proactively identifying and swiftly removing such content, as well as supporting requests from and providing assistance to law enforcement. We also work closely with other platforms and in close collaboration with safety organizations to keep content that violates our policies off our platform, and will continue to diligently enforce our policies.”</p><p>Burger’s plan to kill Christians was allegedly captured by the keylogger. “I’ve come to conclude it will befall the 12 of Shawwal aa/And it will be a music festival /Attracting bounties of Christians s/In’shaa’allah we will attain martyrdom /And deal a grevious [sic] wound upon the followers of the Cross /Pray for me and enjoin yourself to martyrdom,” he allegedly typed in Roblox, according to court records.</p><p>The FBI then interviewed Burger in his living room and he admitted he used the Crazz3pain account to play Roblox. The feds asked him about his alleged plan to kill Christians at a concert. Burger said it was, at the time, “mostly a heightened emotional response,” according to the court records.&nbsp;</p><p>Burger also said that the details “became exaggerated” but that the goal “hasn’t shifted a bit,” according to the court records. He said he wanted to “[G]et the hell out of the U.S.” And if he can’t, “then, martyrdom or bust.”</p><p>He said that his intention with the attack “is something that is meant to or will cause terror,” according to the charging document. When the FBI agent asked if he was a terrorist, Burger said, “I mean, yeah, yeah. By, by the sense and … by my very own definition, yes, I guess, you know, I would be a terrorist.”&nbsp;</p><p>When authorities searched his iPhone, they discovered two notes on the phone that described how to avoid leaving behind DNA and fingerprints at a crime scene. A third note appeared to be a note explaining the attack, meant to be read after it occured.</p><p>The list of previous searches on his iPhone included “Which month is april in islam,” “Festivals happening near me,” “are suicide attacks haram in islam,” “ginger isis member,” “lone wolf terrorists isis,” and “can tou kill a woman who foesnt[sic] wear hijab.”</p><p>Burger has been charged with making violent threats online and may spend time in a federal prison if convicted. This is not the first time something like this has happened on Roblox. The popular children’s game has been a popular spot for extremist behavior, <a href=\"https://www.vice.com/en/article/roblox-porn-nazis/?ref=404media.co\"></a> and religious terrorists, for years now. Last year, the DOJ accused a Syrian man living in Albanian of <a href=\"https://www.404media.co/local-residents-terrorizing-city-council-meetings-were-actually-overseas-feds-allege/\"></a> to coordinate a group of American teenagers to disrupt public city council Zoom meetings.</p>","contentLength":5848,"flags":null,"enclosureUrl":"https://www.404media.co/content/images/2025/06/roblox.png","enclosureMime":"","commentsUrl":null},{"title":"The Blockchain Brain: Nodes, APIs and Web3 Infrastructure","url":"https://hackernoon.com/the-blockchain-brain-nodes-apis-and-web3-infrastructure?source=rss","date":1750418926,"author":"","guid":163712,"unread":true,"content":"<p>In the Blockchain world, processes don’t follow the rules of regulatory centralisation – they occur in a decentralized context. \\n It’s perfectly okay at this stage to be utterly confused about the concepts I’ve mentioned. That’s why I’m taking my time to draft this article with the aim of giving you a broader view of the fundamental concepts and, more importantly, to help you understand why blockchain nodes are vital and give you an understanding of how they connect to or relate with APIs and the Web3 infrastructure.</p><p>\\n First of all, to properly understand nodes, we must first be acquainted with the concept of Blockchain itself. \\n And no, it’s nothing at all like the gold chain you wear with a watch. But like a watch, a blockchain is made up of multiple intricate parts working together in perfect sync to ensure the security and perfect performance of the system.</p><p>In its entirety, a blockchain is a decentralized digital system or ledger which is shared by millions of people through computers around the world and yet somehow functions on its own without being under the control of anyone. \\n It also:</p><p>\\n • Stores millions of transactions made by people on the chain. \\n • Ensures everyone sees the blockchain in the exact same way. \\n • Updates data globally in real-time. \\n • Ensures that sensitive data on the chain is protected.</p><p>For instance, imagine a big account book or ledger that contains or houses millions of transaction data and is shared or used by millions or even thousands of people. These people could be beginners with no prior tech skills or even learners like you and me.</p><p>\\n • Now, each page in the book is known as a block. \\n • Each sequence or group of blocks is a chain. \\n • Everyone sees the blockchain in the exact same way (as mentioned earlier). \\n • No one, not even the government, has any form of control over the workings of the blockchain. It is free and fair and yet somehow highly secure. (Decentralized)</p><p>Any changes made on the blockchain are updated globally, allowing everyone to see who did what, what was done, when it happened, and how it was carried out. Yet somehow—despite this transparency—sensitive data remains protected, updates are easily managed, and the system continues to run successfully without centralized control or human regulation.</p><h3></h3><p><code>If you guessed ‘Nodes’, then you’re very correct. In fact, you nailed it. Good job.</code></p><blockquote><p>Nodes are like the brain – central nervous system and the vital organs of a decentralized system. The Blockchain is insignificant without them. They help in storing, validating, sharing and powering the entire system and everything that occurs across the network.</p></blockquote><h2>On to nodes—what are they?</h2><p>A node is any computer connected to the blockchain network. We all know that it is decentralized, so it could be spread across multiple units, locations, or nodes, with each user having the same live view. But apart from that, there’s more to a node.</p><p>\\n • It stores blockchain data. \\n • It also validates the transactions made by users on the chain. \\n • A node can also communicate with other nodes on the chain to make changes or updates globally and track these changes. \\n • The nodes are active at all times. \\n • Nodes keep track of who does what, what is done, and how it is done. And they do this without the intervention of centralized policies or control.</p><blockquote><p><strong>Blockchains can’t function without nodes.</strong></p></blockquote><p><strong>Based on their functions, we can classify nodes as</strong></p><p>a) : These nodes store the full history of the blockchain. They validate blocks (i.e., Bitcoin Core). \\n b): These nodes store just summaries or headers of data in full nodes. Deal with summaries, not full detail. \\n c): These keep track of every tiny past detail, even changes in states. \\n d): These help in deciding which block gets added by voting in proof-of-stake blockchains.</p><p>To break it down further, to show you how nodes influence blockchain. \\n Let’s visualize the blockchain like Google Docs—but a decentralized version.</p><p>\\n • Like in Google Docs, everyone with the link (nodes) has a copy. \\n • When one person makes a change (a new transaction), it updates and syncs with everyone else. \\n • No one has control of the document. \\n • Everyone sees the same live version. (If one user is making a change, everyone will see who it is and what change is being made.)</p><p>That’s  The ‘nodes’ are the devices that make this possible.</p><blockquote><p>Fact: Nodes eliminate the need for trust but must be trustworthy themselves. If 51% misbehave, the entire blockchain can be compromised.</p></blockquote><h2><strong>How Does a Blockchain Node Work?</strong></h2><p>Now that we’ve understood the blockchain node concept a little bit, it would be wonderful if we can also understand how it works. I'll break it down below. Suppose you want to send 2 ETH to your best friend.</p><ol><li> You’d first create a transaction and sign the transaction with your private key.</li><li><strong>Transaction Broadcasting:</strong> Your wallet (i.e., MetaMask) will send this transaction to a node over the network.</li><li><strong>Validation of Transaction</strong>: The node will check if you have 2 ETH or enough in your wallet to continue with the transaction. It will check if your signature is valid and if you’re double spending.</li><li><strong>Forwarding of Validated Transaction to the Mempool (memory pool):</strong> Once the transaction has passed validation checks, it goes straight to the mempool (a kind of memory or waiting room where unconfirmed transactions stay until they are approved). The node broadcasts it to other nodes.</li><li><strong>Validators pick transactions and form blocks.</strong> In Proof of Stake (PoS), which is a consensus mechanism based on the amount of crypto staked, a selected validator picks up the transaction, creates a new block and adds it to the chain.</li><li> Other nodes agree that the block with the transaction is valid.</li><li><strong>The block is added to the Chain:</strong> Updates are made by all full nodes to their copies once it has been approved.</li><li>: Your friend receives the 2 ETH and your respective balances are updated. Also, your transaction details are stored in the permanent blockchain records. That’s how nodes work to ensure the smooth coordination or running of the system.</li></ol><h2><strong>How Do Developers Use Nodes?</strong></h2><p>Most developers don’t run their own node as it is often very expensive and difficult to handle. Instead, they use services like , which provide:</p><p>\\n • Ready-to-use blockchain nodes. \\n • APIs (like JSON-RPC). \\n • Support for networks like Ethereum, Solana, BNB, etc.</p><h2>APIs in Relation to Nodes in Blockchain</h2><p>An API (Application Programming Interface) is a set of rules and tools that allows software to communicate with other software.</p><p>\\n One software (i.e. a dApp) makes a request to the other software concerning data it needs through an API gateway, and the other software (or node) in turn passes the data requested.</p><p>In Web3 apps (dApps), your wallet or smart contract can’t access the blockchain directly. Instead, they use APIs to gain access to and connect to nodes.</p><p>\\n For instance, suppose you’re using a dApp (i.e., a crypto wallet like MetaMask). When you open the app, your app will send a request to the blockchain node (i.e., node) via an API endpoint. The node will check the blockchain and respond immediately with the accurate data (your balance in this case). It could show, “Your balance is 0.74 ETH.” All of these happen in seconds as a result of the presence of a node working silently in the background.</p><p>\\n Without the nodes, your API has nowhere to get its data, and your dApp wouldn’t know how to communicate with the nodes.</p><h2><strong>Why Are Nodes So Important in Web3?</strong></h2><p>Without nodes, there would be chaos, as no one would agree on the current state of the blockchain. Someone could fake transactions or cheat, thus making the decentralization break. \\n But nodes help stop all this confusion by: \\n • Storing the truth and all the vital information. \\n • Ensuring that everyone remains honest. \\n • Making the system trustless. \\n • They serve as the referees of the blockchain.</p><h2><strong>Conclusion and Key Takeaways</strong></h2><p>Nodes don’t just power the blockchain or serve as the backbone holding it in place—they are, in fact, the blockchain itself. \\n APIs are the platforms that serve as a bridge between dApps, wallets, Web3 platforms, and the nodes, thus enabling them to communicate effectively.</p><p>Whether you’re learning about the Blockchain like me or you’re a skilled developer who has dreams of building the next big thing in Web3, having a clear understanding of how nodes and APIs work together would give you a lovely head start, pushing you right ahead of the curve. It’s an advantage worth having.</p><p>If you’re a curious fanatic like me and you want to explore how nodes work, explore free Node-as-a-Service platforms like <a href=\"https://getblock.io/\">GetBlock</a>.They’ll give you a great start.</p><p>Finally, in Blockchain and Web3, not only is the future decentralized, it’s also secure, safe, easy to track and update – and most of all, it starts and ends with Nodes.</p>","contentLength":8927,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Latest Bcachefs Code Draws Torvalds' Ire Over Late Feature Code","url":"https://www.phoronix.com/news/Linux-616-Bcachefs-Late-Feature","date":1750415928,"author":"Michael Larabel","guid":163452,"unread":true,"content":"<article>There is some tension on the Linux kernel mailing list with some late Bcachefs feature work sent in as part of \"fixes\" for the ongoing Linux 6.16 kernel cycle. Established rules aim for only new feature code to be introduced during the kernel merge windows, which ended nearly two weeks ago for Linux 6.16, but Bcachefs wanting to be exempt to continue to allow new feature code to still land for the cycle in the name of data safety...</article>","contentLength":436,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Microsoft Releases WSL 2.6 As The First Open-Source Release","url":"https://www.phoronix.com/news/Microsoft-WSL-2.6-Open-Source","date":1750414936,"author":"Michael Larabel","guid":163451,"unread":true,"content":"<article>Microsoft announced back in May at their Build developer conference that WSL would be going open-source. Today Windows Subsystem for Linux 2.6 was released as their first new release now being an open-source project...</article>","contentLength":218,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AMD Releases Updated ROCm 7.0 Preview For HIP Testing","url":"https://www.phoronix.com/news/AMD-ROCm-7.0-Preview-2-HIP","date":1750414227,"author":"Michael Larabel","guid":163450,"unread":true,"content":"<article>AMD originally released a ROCm 7.0 preview build back in May as it works to align their HIP API more closely with NVIDIA's CUDA. Last month was the big ROCm 7.0 preview announcement form AMD's Advancing AI Day in San Jose while this week is another new 7.0 preview build focused on further testing of the ROCm 7.0 HIP changes...</article>","contentLength":328,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DOJ Files To Seize $225 Million In Crypto From Scammers","url":"https://yro.slashdot.org/story/25/06/19/2312257/doj-files-to-seize-225-million-in-crypto-from-scammers?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750413600,"author":"BeauHD","guid":163402,"unread":true,"content":"The DOJ has filed a civil complaint to seize $225.3 million in cryptocurrency linked to pig butchering scams -- long-con frauds where victims are tricked into fake crypto investments. The funds were laundered through a blockchain network, and the DOJ says recovered money will go toward reimbursing victims. The Verge reports: The 75-page complaint (PDF) filed in the US District Court for the District of Columbia lays out more detail about the seizure. According to it, the US Secret Service (USSS) and Federal Bureau of Investigation (FBI) tied scammers to seven groups of Tether stablecoin tokens. The fraud fell under what's typically known as \"pig butchering\": a form of long-running confidence scam aimed at tricking victims -- sometimes with a fake romantic relationship -- into what they believe is a profitable crypto investment opportunity, then disappearing with the funds. Pig butchering rings often traffic the workers who directly communicate with victims to Southeast Asian countries, something the DOJ alleges this ring did.\n \nThe DOJ says Tether and crypto exchange OKX first alerted law enforcement in 2023 to a series of accounts they believed were helping launder fraudulently obtained currency through a vast and complex web of transactions. The alleged victims include Shan Hanes (referred to in this complaint as S.H.), the former Heartland Tri-State Bank president who was sentenced to 24 years in prison for embezzling tens of millions of dollars to invest in one of the best-known and most devastating pig butchering scams. The complaint lists a number of other victims who lost thousands or millions of dollars they thought they were investing (and did not commit crimes of their own). An FBI report (PDF) cited by the press release concluded overall crypto investment fraud caused $5.8 billion worth of reported losses in 2024.","contentLength":1856,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Forget Perfection—Just Build Something People Want (in 48 Hours or Less)","url":"https://hackernoon.com/forget-perfectionjust-build-something-people-want-in-48-hours-or-less?source=rss","date":1750409074,"author":"Maddox Schmidlkofer","guid":163444,"unread":true,"content":"<p>Today I'll be sharing my playbook on how to make money from something you've made. I went from 0 to 10K ARR, and I'm going to try and help everyone do the same. This won't work all of the time, but I think it's a great way to ideate, start, and succeed in generating revenue from something you've made.</p><p>the entrepreneurship &amp; startup area is very, very competitive now. check twitter and you'll see. With this new uprising in competition, you need , and you need a head start.</p><p>To gain a head start, you can do many things. 2x your work by getting a cofounder, pay other people to help (not ), or you can start in a place you know. Starting in a place you know means being in a community where you have</p><ul><li>A following/voice (know how/who to advertise to)</li><li>You know your customer (because you are your customer)</li></ul><p>These items make it easy to not get lost creating something no one wants, and make it easy to get customers. You know how to build for them, as you are them. \"eat your own food\" - <a href=\"https://www.cs.purdue.edu/people/faculty/grr.html\">Gustavo Rodriguez-Rivera</a>.</p><p>EX1: for my project <a href=\"https://duckmath.org\">duckmath</a>. I was a student who wanted to play games in school. I know everyone in my entire school was on tiktok; as such, all students are on tiktok, right?</p><p>EX2: for my project <a href=\"https://quackprep.com\">quackprep</a>. I am a college student who wanted to study past exams not found elsewhere. I know everyone at purdue used boilerexams (validation). I am in a purdue reddit with mostly purdue students, I am in the purdue snapchat which has 30k+ purdue students (easy access to audience). easy.</p><h2>Create something In 2 Days</h2><p>There are  many people creating for you to take more than  to create something. You're spending a week, a month, a year?? I spent 7 months creating something no one wanted. I  do that again.</p><p>We have cursor, chatgpt, loveable etc now; you CAN make whatever you are making in 2 days. Ai generated blogs which go onto your website? 2 days. 3 different directories? 2 days.</p><p>If you truly can't do it in 2 days, slap up a waitlist  and gather validation before you create.</p><h2>Validation before Creation</h2><p>It's easier to market a product that's already built, but we don't always get that luxury. Talk to people, call companies, tweet about it.</p><p>Make sure everything you do daily is known. \"I built this, talked to this guy about it, took the prof's mic and got up and lectured about it.\" Post it everywhere and build a following. Make sure everyone knows about it. So when the day comes and you open the doors to your crappy vibe-coded SaaS, everyone who follows you wants it.</p><p>If this isn't full time for you, just spend  or so a day talking about it. Also no one is going to steal your idea, *t's probably not even original anyway.</p><p>At some point 1 of your 20+ failures will start to gain traction—maybe it's that keyword you were trying to rank for, maybe your reddit post blew up.</p><p>Spend more time than usual on that project; if it keeps going up and you keep getting good signals, then drop everything else and 10x that project.</p><p>Overall times have changed, and I wish I was back at the times when if you didn't know how to code it you couldn't make it, but times have changed. Everyone and their brother is doing a startup.</p><p>If you want financial freedom then you should do one too. I recommend first making a <a href=\"https://ubghub.org/\">directory</a> (listing of services). they are easier to market, take &lt;2 days to build, and  take any . <a href=\"https://johnrush.me/\">John Rush</a> does great on this. I hope I have helped you guys in some way, and if you have any questions contact <a href=\"https://maddox.page\">me</a>. Thanks for reading!</p>","contentLength":3439,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Methods of Accepting Cryptocurrencies: Forwarding, Non-custodial, and Custodial","url":"https://hackernoon.com/methods-of-accepting-cryptocurrencies-forwarding-non-custodial-and-custodial?source=rss","date":1750408496,"author":"Maksim Boiarov","guid":163443,"unread":true,"content":"<p>Cryptocurrency is stored at some address (“wallet”), from which and to which the owner sends and receives coins. The difference between wallets lies in how the user interacts with the address/(-es). The process of accepting/sending coins includes monitoring transactions on the blockchain. Such management can be carried out by the user independently or with the help of processing companies that provide services for creating addresses and tracking transactions, charging a commission for such assistance. This article will help to find out the pros and cons of interacting with such services and how to decide whether to deal with crypto payment tracking on your own or delegate such duties in full or partly (and which part) to professionals.</p><p>There are three types of interaction with specialized services:</p><ul></ul><p>Forwarding is an instant transfer of payments from temporary processing addresses to the specified address of the owner. Thus, the processing service owns the payment coins for a short time and does not store them.</p><p>| Pros | Cons |\n|----|----|\n| <strong>The service does not store payments but owns them for a short time when transferring. \\n At the end of the chain, the payment goes to the owner's address. \\n No KYC, KYB.</strong> | <strong>Double network fees \\n You can only accept payments; \\n automatic payouts must be implemented separately.</strong> |</p><p>Currently, it's a rare method. Only one Crypto Payment Gateway provides crypto-forwarding Apirone. BTW they provide forwarding of Ethereum, Tron, stablecoins and etc. There are unique methods.</p><h2><strong>Custodial crypto processing</strong></h2><p>This means that a processing company creates private keys, stores them, and monitors the network. Also, when choosing a custodial wallet, the services include tracking transactions and notifying the owner about the facts of receiving coins to addresses. In this case, the company completely manages your money. It is convenient if you need to not only accept but also pay your counterparties. Among other things, the list of services may include exchange or conversion into fiat currency with the possibility of withdrawing to a card or bank account.</p><p>| Pros |  |\n|----|----|\n| <strong>Ease of use&nbsp;Works like a regular account on the exchange. \\n Uses the familiar login-password mechanism. \\n Many ways to restore access via sms, email, KYC, or through the support service. \\n Simple control&nbsp;You do not have to learn all the intricacies of working with various blockchains. \\n No need to worry about errors; most likely, before sending funds, the transaction is checked several times.</strong> | <strong>Less securityThird-party platforms have more vulnerabilities. \\n Users' personal data is stored in a single centralized repository. \\n Third-party platforms are often targeted by hackers. \\n No confidentialityTo create an account, identity verification is required, i.e. the provision of passport data, or a bank account. \\n No direct ownership\"Not your keys - not your money\", i.e. a third-party service owns your funds. \\n Crypto processing can freeze your cryptocurrency, withhold or detain funds due to blocking by your line of business, country, or other reasons. \\n There is a high probability of scam exit or embezzlement of customer funds, as often happens with crypto exchanges.</strong> |</p><p>Most crypto companies use this method. It is more difficult to find someone who does not use this method.</p><h2><strong>Non-custodial processing of cryptocurrencies</strong></h2><p>This method assumes that you own the private keys and no one else. You provide the processing service only with addresses for tracking transactions and notifications of payments.</p><p>|  |  |\n|----|----|\n| <strong>You are responsible for your securityIt will be harder for attackers to steal your data, especially if you use cold storage or a hardware wallet. \\n Full control over stored funds. \\n The cryptocurrency on the wallet is in total ownership of the user. \\n There is no risk of third-party interference.</strong> | <strong>No possibility to restore accessIf you lose your private key or mnemonic phrase, then access to your funds may be closed forever. \\n Difficult for beginners. \\n The interfaces of non-custodial wallets can be quite complex. \\n At least basic knowledge of blockchain and cryptocurrencies is required. \\n A higher degree of responsibility.</strong> |</p><p>Most popular is a BTCPay standalone Server, OpenNode and forks. But these servers only support Bitcoin, require good developer skills and powerful server instances.</p><h2><strong>Differences between custodial, non-custodial, and forwarding payments</strong></h2><p>This table clearly shows the difference between the three methods, which allows you to make the right choice by evaluating your capabilities and reducing risks when interacting with processing companies.</p><p>|  \\n  | Custodial crypto wallet | Forwarding | Non-custodial crypto wallet |\n|----|----|----|----|\n| Private key keeper | Third party | Third party temporarily, then the owner | owner |\n| Access recovery | Many ways | not applicable | impossible |\n| Economic security | The service is responsible for the funds’ security, that is why its credibility shall be 100% | Partial credibility | Owners are responsible for their funds’ security |\n| Procedures of KYB, KYC, and AML | compulsory passing | no | not applicable |\n| Restrictions | by countries, by a line of business | no | no |</p><p>If you value full control and security, choose non-custodial but you will have BTC only and spend a lot of time developing.</p><p>If you want maximum simplicity and trust the platform, custodial processing will do.</p><p>If you want a balance between convenience and control, forwarding may be a good option. \\n </p>","contentLength":5535,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Most Expensive 0.5% You’ll Ever Give Away","url":"https://hackernoon.com/the-most-expensive-05percent-youll-ever-give-away?source=rss","date":1750408235,"author":"Kishore Dasaka","guid":163442,"unread":true,"content":"<p>In the early years of a startup, founders make decisions with incomplete information. It’s part of the game. You don’t have time to model every future scenario. You move fast. You build trust. And sometimes, that trust takes the shape of equity.</p><p>It almost always begins innocently.</p><p>A former operator offers to open investor doors. A consultant provides positioning advice. A respected name in your industry agrees to lend credibility, attend one board meeting, maybe make a few calls.</p><p>You’re grateful. You offer advisory shares. “Just 0.5%,” you say. “It’s not much.”</p><p>But that 0.5% isn’t temporary. It’s not a thank-you note. It’s ownership. It’s permanent. And more importantly - it’s .</p><p>If you’re early in your journey, and you’re handing out advisory equity without a plan, you’re not rewarding generosity. You’re creating a problem that will quietly compound.</p><p>And when it surfaces, it won’t be in a casual founder coffee chat. It’ll be in a data room, under investor scrutiny, at the exact moment when the stakes are highest.</p><h2><strong>What Founders Miss When They Feel Grateful</strong></h2><p>In my work as a Fractional CFO, I’ve seen the same pattern too many times. Cap tables bloated with small, informal equity grants. 0.3% to someone who made a helpful intro. 1% to a “growth advisor” who never showed up after the first month. Another 0.5% to a mentor who asked for “a small skin in the game.”</p><p>It’s never malicious. But it’s always costly.</p><p>Because at some point, you’ll have to explain why 2% to 3% of your company is sitting with people who weren’t employees, didn’t vest, and left no measurable impact. And if you can’t explain it cleanly, it will affect valuation, dilution math, and investor confidence.</p><p>Founders often overestimate how casual equity can be. But equity is not a gesture. It’s a slice of the company. And once you give it, <strong>you can’t take it back - not without pain.</strong></p><h2><strong>The Illusion of Small Numbers</strong></h2><p>The most dangerous thing about advisory equity is how small it feels at the time you give it.</p><p>Half a percent doesn’t sound like much when you have 100%. Even 2% sounds manageable when the product is still early and the valuation is imaginary.</p><p>But the cap table doesn’t stay still.</p><p>You raise a priced round. You expand your ESOP pool. You bring in another co-founder. And suddenly, your clean early-stage ownership is compressed. That 0.5% - issued without performance clauses, vesting, or board approval—now competes for value against the people actually building the company.</p><p>It creates tension. Not just with investors, but with your team. Your first engineer sees an advisor holding more equity than they do. Your head of sales gets diluted harder than the person who made two phone calls in 2021. The story gets harder to tell.</p><h2><strong>Advisory Equity Is Not Bad - It’s Just Often Unstructured</strong></h2><p>To be clear, I’m not against advisory equity.</p><p>There are advisors who add genuine strategic value. People who compress your learning curve, open doors you can’t access, help you hire leadership, or shift the company’s trajectory. In those cases, equity is not a reward - it’s an investment.</p><p>But for it to work, it needs structure. And structure rarely exists in the early advisory grants I see.</p><p>There’s no vesting schedule. No documentation of deliverables. No scope of involvement. No performance thresholds. Just a number and a signature. And eventually, that signature becomes a burden.</p><h2><strong>What You Should Be Thinking About Instead</strong></h2><p>If you’re considering offering advisory shares, ask yourself: Are you giving away equity because it’s easier than saying no?</p><p>Founders often offer equity when they don’t know how to price advice. Or when they’re too early to afford cash compensation. Or when they’re flattered by the attention of someone more experienced.</p><p>That’s understandable. But it’s not strategic.</p><p>Equity should never be a substitute for structure. If you value someone’s advice, define what you’re paying for. Scope the contribution. Set boundaries. Put a timeline on the relationship. Write it into an agreement.</p><p>Because when you offer advisory equity casually, what you’re actually doing is <strong>mortgaging your future clarity</strong>.</p><h2><strong>The Cleanup Is Always Messy</strong></h2><p>Every founder eventually reaches a point where the cap table must be cleaned. Sometimes it’s right before Series A. Sometimes it’s during an acquisition offer. Sometimes it’s when an employee asks, “Who’s this person holding 0.8%?”</p><p>The cleanup process isn’t just awkward - it’s hard. Legally, psychologically, emotionally. You have to ask someone who once helped you to sign away value. Or you spend money buying it back. Or worse - you let it go, and it sits there, forever, like a ghost on your books.</p><p>If you haven’t gone through it, trust me - it’s not worth the early convenience.</p><h2><strong>The Cost Isn’t Just Dilution. It’s Negotiation Power.</strong></h2><p>In a negotiation, every unknown reduces leverage. When your cap table includes ambiguity, your credibility takes a hit. You may lose pricing power. You may lose investor trust. And once you’re on the back foot, it’s hard to recover.</p><p>I’ve been in rooms where investors passed on good companies—not because of product, but because of cap table baggage. Advisory shares granted loosely send a signal: this founder doesn’t protect the company. And if they won’t protect it from friends, how will they protect it from market pressure?</p><p>Startups are fragile. Every equity decision you make in the first 18 months will be amplified by the time you raise meaningful capital.</p><ul><li>Every advisor you bring on must be willing to vest</li><li>Every grant should be tied to value, not vanity</li><li>Every agreement should be written with the company in mind, not just the moment</li></ul><p>Equity isn’t your only currency. But it is your most permanent one. Don’t spend it because you feel flattered, obligated, or unsure. Spend it because you’ve calculated what you’ll get in return - and you’ve documented how that value will show up.</p>","contentLength":5984,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Post-Quantum Privacy for Post-Platform Internet","url":"https://hackernoon.com/post-quantum-privacy-for-post-platform-internet?source=rss","date":1750408156,"author":"Ibukun OG","guid":163441,"unread":true,"content":"<p>Over the past two decades, most of our online experience has been controlled by a handful of giant platforms whose proprietary feeds, ads, and moderation policies shape what we see and say. A growing “Great Decentralization”, with users fleeing X (Twitter) for federated networks like Mastodon and Bluesky shows that people increasingly want services where they can move their data, choose their own rules, and avoid Big Tech lock-in. These experiments signal the contours of a : an ecosystem built on open protocols, peer-to-peer infrastructure, and community-run servers rather than corporate silos.</p><p>\\\nUnless we add post-quantum security measures to the new, user-controlled web now, future decentralized networks could become easy targets for quantum-powered eavesdroppers. This would replace Big Tech's controlled environments with a major surveillance risk on <a href=\"https://www.tomsguide.com/computing/online-security/what-is-q-day\">Q-Day</a>.</p><h2>What Is a Post-Platform Internet?</h2><p>A  internet is an environment where data, identity, and computation live outside of any single company’s control. Three ideas anchor it:  (no single point of control),  (users can freely move their data and social connections), and  (individuals or communities, not corporations, decide who gets access). The Post-Platforms Foundation frames this as “decoupling data from platforms,” while recent research on Web3 governance argues that shifting power to the edge is essential for meaningful digital self-determination.</p><p>| Layer | What it does | Post-platform example |\n|----|----|----|\n|  | Remove central servers; content is fetched from whoever has it | IPFS is prioritising in-browser retrieval and lightweight clients for 2025 to cut reliance on gateway operators.([discuss.ipfs.tech][3]) |\n| <strong>DePIN (Decentralised Physical Infrastructure Networks)</strong> | Crowd-owns the hardware layer connectivity, storage, sensors through token incentives | <a href=\"https://solana.com/fr/news/case-study-helium\">Helium, Hivemapper, Render and others show how communities can build 5G, mapping and GPU grids without telecom giants.</a> |\n| <strong>Federated &amp; composable apps</strong> | Servers talk via open standards so users can hop instances without losing their social graph | ActivityPub powers thousands of Mastodon, PeerTube and Pixelfed servers; Bluesky’s AT Protocol offers a similar plug-and-play feed model. |</p><p><strong>Real-world signals of the future</strong>: </p><ul><li> crossed 33 million registered accounts by March 2025 and is still adding roughly one user per second.</li><li> operates over 9,500 independent servers hosting 8 million+ users, proof that federation scales.</li><li> has grown into a global wireless mesh with 350,000 nodes, showing that grassroots hardware incentives can outperform many established companies.</li></ul><p>Together, these ingredients sketch a web where switching providers is as easy as changing e-mail hosts, your connectivity is community-run, and no single firm can unilaterally rewrite the rules of participation.</p><h2>The Quantum Threat Landscape</h2><p>Peter Shor’s 1994 breakthrough showed that a sufficiently large, error-corrected quantum computer can factor integers and solve discrete-log problems in <a href=\"https://mathworld.wolfram.com/PolynomialTime.html\"> time</a>, instantly toppling the RSA and elliptic-curve cryptography that anchor most of today’s TLS handshakes, PGP keys, and blockchain signatures. Recent work from Google Quantum AI cut the resources needed to crack a 2048-bit RSA key from the billions of physical qubits once assumed to <strong>fewer than one million noisy qubits and under a week of runtime</strong>, thanks to new circuit-compression and error-mitigation techniques.</p><p>While Shor targets public-key systems, Lov Grover’s search algorithm gives a quadratic boost against symmetric ciphers. In practice that halves effective key strength, meaning AES-256 would only deliver about 128 bits of post-quantum security still serviceable, but only if implementers double key lengths and avoid hash sizes below 256 bits.</p><p>How soon could a <em>cryptographically relevant quantum computer</em> materialize? Government road-maps and corporate timelines are converging. IBM’s new data-center in Poughkeepsie is slated to test the 10-kilo-qubit  processor in 2025 as a stepping-stone toward fault-tolerant machines later this decade, while IonQ’s accelerated plan targets 20 000 physical qubits by 2028 and tens of thousands of  qubits by 2030. NIST’s draft transition report therefore treats 2035 as a hard deadline: after that year U.S. federal systems may not use classical crypto at all, underscoring that the window to migrate is closing fast.</p><p>In short, the same decentralized applications that promise freedom from platform lock-in risk becoming read-only archives for tomorrow’s quantum adversaries unless they harden their cryptography  Q-Day arrives.</p><h2>Post-Quantum Cryptography Primer</h2><p>The list of quantum-resistant algorithms is sorted by the mathematical problems they use. , like CRYSTALS-Kyber for key encapsulation and CRYSTALS-Dilithium or Falcon for digital signatures, rely on the difficulty of finding short vectors in high-dimensional lattices. Their arithmetic is suitable for constant-time software, and importantly for web traffic, their public keys remain in the 1-2 kB range. For instance, Kyber-768 sends a 1,184-byte public key, and Dilithium-3 creates 2,701-byte signatures. , such as SPHINCS+, derive security from well-known primitives like SHA-2 or SHA-3. They avoid complex algebra but are larger in size; even the smallest SPHINCS+ signature is about 8 kB and can go up to 40 kB for the highest security levels.  uses disguised error-correcting codes; Classic McEliece is a key example, but its public key, around 260 kB in the commonly used level-1 parameter set, is much larger than lattice keys. <strong>Multivariate quadratic (MQ) schemes</strong> once seemed promising, but the main candidate, Rainbow, was completely broken in 2022, showing that some families still have unresolved cryptanalytic issues.</p><p>Choosing among these options involves a trade-off between <strong>bandwidth, runtime, and implementation complexity</strong>. Lattice algorithms generally offer the best balance: their keys and ciphertexts are small enough to fit within a typical network packet, and software implementations require only 2–3 times the CPU cycles of classical ECDH on standard hardware. Hash-based signatures shift most costs to bandwidth and verification time but offer a secure foundation based on existing hash functions, making them ideal for firmware updates that can handle large payloads. Code-based systems take a different approach: they have huge public keys but small ciphertexts and fast decapsulation, which is perfect for environments like satellite links where keys are sent once and used for years. Across all these options, ensuring side-channel resistance and constant-time coding are challenging engineering tasks, highlighting the importance of NIST’s upcoming implementation guidelines and test suites, which will be as crucial as the mathematics itself.</p><h2>Designing Privacy for the Post-Quantum, Post-Platform Web</h2><p>The first design goal is to replace the current Diffie-Hellman or Curve25519 \"first contact\" with <strong>hybrid handshakes that combine classical and lattice algorithms</strong>. Cloudflare's edge now uses TLS 1.3 connections where X25519 is paired with ML-KEM (Kyber), already protecting \"nearly two percent of all traffic.\" They expect this to reach double digits by the end of 2024. Messaging systems are advancing even faster: Apple's new PQ3 protocol for iMessage combines Kyber with three ongoing ratchets, ensuring every new key is pre-quantum-armored. This eliminates the \"harvest-now, decrypt-later\" risk for billions of devices once iOS 17.4 is widely adopted. The approach is clear: maintain the elliptic curve exchange for backward compatibility, add Kyber (or another NIST KEM) alongside it, and derive the session secret from both. If either part remains secure, so does the confidentiality.</p><p>End-to-end privacy relies on proofs instead of trust, and the community is moving away from a decade of SNARKs built on elliptic-curve pairings. <strong>Hash-centric zk-STARK systems are already safe from quantum attacks</strong> because their security depends on the collision resistance of functions like SHA-256. Grover’s algorithm only doubles the hash length, so 256-bit digests remain secure. Research groups are now adding lattice-based polynomial commitments to Plonk-style protocols, allowing developers to maintain concise proofs without relying on elliptic curves. The practical advice is to use STARK-compatible stacks for new applications and consider current pairing-based rollups as technical debt that should be replaced before Q-Day.</p><p>Identity is a moving target: keys expand from 32-byte Ed25519 blobs to larger Dilithium or SPHINCS+ materials, which require <strong>frequent rotation policies</strong>. <a href=\"https://w3c-ccg.github.io/did-key-spec/\">The W3C </a><a href=\"https://w3c-ccg.github.io/did-key-spec/\"> method</a> allows controllers to create a new DID from any public key and update verification material without needing a global registry. Post-platform wallets can take advantage of this by issuing DIDs with short validity periods (like one month), embedding expiry metadata in Verifiable Credentials, and switching to a new ML-DSA key pair before an attacker can exploit side-channel or storage attacks on a large lattice key. Since DIDs are URI-addressable, rotating keys doesn't disrupt application references. The content points to the identifier, which then resolves to the current quantum-safe document.</p><p>\\\nFinally, <strong>traffic-shaping layers need to evolve</strong>. The Nym mixnet has released a 2025 roadmap that plans to use Kyber-based key exchange in every hop of its Sphinx packet format. This will ensure that metadata-private routing remains secure even when quantum decryption becomes possible. Onion-routing research is also progressing: Tor developers have proposed combining the NTor handshake with NewHope, a lattice KEM, to make circuits quantum-resistant with only a small increase in handshake size. Since mixnets and onion layers already handle latency, the additional kilobytes of lattice data are manageable. The real challenge lies in dealing with hardware security modules and exit relays that currently can't store or process larger keys.</p><p>These developments demonstrate that the post-platform web can be both privacy-preserving and quantum-resilient. However, this is only possible if developers integrate post-quantum features into every layer, from the first TLS packet to the last mixnet hop, and consider key changes as a regular part of digital life, not as an unusual event.</p><p>The theory of “quantum-safe decentralization” is already colliding with practice. Four very different projects: secure messaging, mix-nets, off-planet DePIN, and the social-web Fediverse show how far implementation experiments have progressed and where the roadblocks still lie.</p><h3>Matrix: hybrid Kyber + Dilithium inside a double-ratchet prototype</h3><p>Matrix’s end-to-end-encrypted ecosystem has spent the past two years rebuilding its crypto stack in Rust. That work culminated in the Element-R rollout, whose mandate explicitly lists “post-quantum encryption” as a priority and routes all clients through the new  core. On the code side, a pull-request to the  library wires in the PQXDH handshake: X3DH is extended with ML-KEM/Kyber for key encapsulation and a plan to upgrade device-identity signatures to ML-DSA/Dilithium once the IETF signs off. Early lab tests show the enlarged key bundles add roughly 3 kB to the first message but leave ratchet throughput unaffected; the team is now fuzz-testing protobuf encodings for side-channel leaks.</p><p>Nym's Sphinx packets already use ChaCha20/Poly1305 over a SURB-style mix-net. However, the project roadmap published in April 2025 outlines a two-step migration: first, add a Kyber768/ChaCha20 hybrid for relay handshakes in version 2, and then replace the RSA-based SURB signature with Dilithium once FIPS 204 is stable. Benchmarks on a 1 GHz ARM core show that Kyber encapsulation adds about 0.4 ms per hop, which is negligible compared to network latency. The more challenging task is redesigning the single-use reply block to keep packet headers under 1.5 kB after adding a Dilithium signature. This constraint is necessary to fit within Tor-compatible 512-cell circuits.</p><h3>Satellite DePIN: pushing PQC to the link layer</h3><p>Spacecoin's \"Celestial Chain\" DePIN has already launched its first CubeSat into low Earth orbit (LEO), but link-layer security still depends on AES keys exchanged via an ECC handshake. The community highlights two proofs-of-concept that suggest a post-quantum upgrade is feasible. First, QuSecure demonstrated a Kyber-protected Starlink link in March 2023, streaming encrypted traffic end-to-end through SpaceX ground stations. Second, researchers on the SpooQy-1 nanosatellite uploaded firmware that completed a full Kyber-512 authenticated key exchange over a 436 MHz UHF channel, using an AVR32 microcontroller with only 32 kB of RAM. These results show that lattice-based KEMs can fit inside SWaP-constrained radios, paving the way for DePIN operators to adopt ML-KEM before launching any large-scale constellations.</p><h3>Fediverse pilots: ActivityPub with Dilithium signatures</h3><p>While Mastodon and other ActivityPub servers still use RSA/HTTP-Signatures by default, developers in the SocialHub community are working on a FEP (Fediverse Enhancement Proposal) to clarify signature processing and accommodate quantum-safe algorithms. Experimental branches are using Paul Miller’s noble-post-quantum JavaScript library, which includes ML-KEM and Dilithium primitives. The demo patches replace rsa-sha256 headers with dilithium-sha512 on local test instances to assess bandwidth impact. Packet captures indicate that a one-to-many \"boost\" generates about 14 kB of extra header data per remote server. This is large, but still smaller than typical image attachment sizes. No mainline Fediverse project has adopted this change yet, but the trials show the protocol works and highlight the main challenge: spreading new OID constants across thousands of independently-run instances.</p><p>These examples show a pattern: small, focused experiments are safely testing post-quantum features in real decentralized systems. While performance issues can be measured and managed, governance and version differences are more challenging. The lesson for developers is clear; begin tracking and measuring now, as the engineering focus is shifting from \"Can we do this?\" to \"How quickly can we implement this before the risk of decrypting later becomes a problem?\"</p><h2>Implementation Challenges</h2><p>A post-platform web can't rely on the powerful servers of Big Tech; much of it operates on single-board computers, phones, and embedded routers. Tests on a 1.5 GHz Raspberry Pi 4 show that post-quantum handshakes already use significant processing power. Even the fastest lattice pair, Kyber + Dilithium, makes key generation, encapsulation, and decapsulation much slower than on a desktop. Overall, TLS handshake throughput on the Pi is 5–10 times slower than the same code on an x86 workstation. An IETF draft for IoT vendors highlights this issue, noting that larger keys \"exhaust memory, storage, and battery budgets,\" leading to trade-offs like seed-only private-key storage, which adds computing overhead every time a key is derived.</p><p>Even when the CPU budget exists, traffic still has to cross a long tail of intermediaries. <a href=\"https://blog.cloudflare.com/monsters-in-the-middleboxes/\">Cloudflare’s early hybrid-TLS rollout revealed that some middleboxes mis-parse the larger ClientHello</a>, silently dropping connections; other stacks fail because Kyber changed wire formats between drafts. These quirks make staged, hybrid deployments mandatory, yet they also slow user migration: if one hop in a federated service balks at a PQ extension, everyone has to fall back to classical crypto for the sake of reachability.</p><p>\\\nHardware introduces its own delays in the supply chain. Certificate Authorities admit they \"don't currently have compatible Hardware Security Modules to provide post-quantum-safe certificates,\" which means root keys are still tied to RSA while the public web advances. PKCS#11 vendors like EJBCA can offer \"early support for quantum-safe algorithms,\" but only through next-generation modules that many operators haven't budgeted for or evaluated yet. Until ready-made HSMs, TPMs, SIMs, and secure enclaves support lattice and hash-based methods, every on-chain wallet or self-hosted server is vulnerable to hardware upgrade cycles, not just Git commits.</p><p>Finally, the social aspect of a decentralized ecosystem increases coordination costs. Researchers studying the Fediverse, which includes over 29,000 independent servers, note significant differences in moderation teams, funding, and technical expertise. They warn that \"multi-voiced, self-governing\" networks find it difficult to agree on even small protocol changes. <a href=\"https://nvlpubs.nist.gov/nistpubs/CSWP/NIST.CSWP.39.ipd.pdf\">NIST's 2025 white paper on crypto agility</a> states that any transition to quantum technology is \"costly, raises interoperability issues, and disrupts operations,\" especially since each community has its own release schedule and threat model. In practice, this means some instances will switch to post-quantum (PQ) cryptography years before others, forcing bridges and relays to manage dual cryptographic systems indefinitely.</p><p>The combination of these challenges; CPU limits, legacy middleboxes, incomplete hardware support, and polycentric governance, explains why the “easy part” (designing strong algorithms) now gives way to the hard slog of getting them to run, everywhere, before the harvest-now-decrypt-later archives finally come due.</p><p>The safest way to cross the quantum chasm is to migrate in stages rather than attempt a single-week “flag day.”  <a href=\"https://media.defense.gov/2022/Sep/07/2003071836/-1/-1/0/CSI_CNSA_2.0_FAQ_.PDF\">National Security Memorandum-10 and the NSA’s CNSA 2.0</a> fact-sheet both give 2035 as the latest moment by which U.S. national-security systems must have eliminated classical public-key cryptography.  Agencies are therefore expected to finish an  in 2024-25, deploy  during 2026-28, and switch to  before the 2030 audit cycle closes. Operators outside government can copy this cadence: start by cataloguing every TLS endpoint, VPN, signed update channel, and long-term archive; turn on Kyber-plus-X25519 where middleboxes allow it; and schedule a hard cutoff for the classical half once telemetry shows that 99 % of peers negotiate the lattice limb successfully.  Cloudflare’s public numbers already prove the hybrid step is cheap. its post-quantum-to-origin service moved petabytes of traffic without measurable latency regression.</p><p>Open-source tooling is mature enough to make that transition practical today.   and its  plug straight into OpenSSL 3.x, giving any application that uses the EVP interface instant access to Kyber, Dilithium, Falcon and SPHINCS+.   aggregates constant-time C reference implementations that downstream projects. Rust’s , Go’s , Python’s , wrap for higher-level use. Developers should freeze versions against the <a href=\"https://www.nist.gov/news-events/news/2024/08/nist-releases-first-3-finalized-post-quantum-encryption-standards\">NIST Final profiles (FIPS 203-205) released in August 2024</a>, which ship authoritative parameter sets and Known-Answer Tests.</p><p>Testing and verification need equal attention.  NIST’s CAVP already issues automated validations for ML-KEM and ML-DSA, and its public GitHub hosts full test-vector suites that CI pipelines can ingest. Teams that can't afford full formal proofs should at least ensure every build passes the CAVP vectors, run side-channel traces on reference boards, and schedule an external code review. Several security firms now have PQC-specific audit checklists based on the 2023 Open Quantum Safe assessment criteria.</p><p>Regulators are tightening the screws in parallel.  In the United States, <a href=\"https://www.whitehouse.gov/wp-content/uploads/2022/11/M-23-02-M-Memo-on-Migrating-to-Post-Quantum-Cryptography.pdf\">OMB memorandum M-23-02</a> obliges civilian agencies to deliver a prioritised migration plan once NIST finalises its standards, and <a href=\"https://www.cisa.gov/quantum\">CISA’s Post-Quantum Initiative</a> is extending that guidance to critical-infrastructure operators.  Europe is following suit: the October 2024 implementing rules under the NIS2 Directive name “quantum-ready cryptography” as an explicit risk-management measure, and ENISA’s technical guidance calls on cloud and CDN providers to document timelines for PQ adoption. Start-ups that want to serve regulated sectors after 2026 should expect procurement language demanding compliance with FIPS 203-205 or their ETSI equivalents.</p><p>What remains is collective will.   need to link PQ libraries early and treat larger keys as a routine performance consideration, not a blocker.   should budget for new HSMs and embed crypto-agility into product roadmaps so upgrades do not require fork-lift rewrites.   must fund interoperability testbeds, accelerate certification cycles for PQ-capable hardware, and reward early movers in public procurement.  The cryptographic blueprints are finished, the standards are on the books, and both Washington and Brussels have fired the starting gun.  All that stands between today’s harvest-now traffic and tomorrow’s quantum decryption is how fast we turn those PDFs and GitHub repos into running code.</p><p>You now have the complete picture: a  internet offers user control, but its freedoms disappear the moment large-scale quantum computers can use Shor’s or Grover’s attacks on current encryption. Protecting this new web requires redesigning every layer, from the initial TLS handshake to the final mix-net hop, using lattice, hash-based, or code-based algorithms that are already approved by NIST and available in open-source stacks.</p><p>The clock is real. <a href=\"https://blog.cloudflare.com/towards-post-quantum-cryptography-in-tls/\">Cloudflare’s telemetry</a> shows quantum-safe handshakes are only a few percent of global traffic, yet harvest-now-decrypt-later adversaries are collecting data today.  CISA’s transition programme and parallel rules under Europe’s NIS2 directive both treat 2035 as a hard deadline; miss it and your archives may become plaintext overnight.</p><p>If you build or regulate digital systems, act now: follow <a href=\"https://www.nccoe.nist.gov/sites/default/files/2023-12/pqc-migration-nist-sp-1800-38b-preliminary-draft.pdf\">NIST’s migration playbook</a>, contribute test-vectors to the <a href=\"https://openquantumsafe.org/about/\">Open Quantum Safe project</a>, and pressure hardware and cloud vendors to expose Kyber, Dilithium, and SPHINCS+ in their firmware. Read the primary standards at NIST’s PQC portal, join OQS on GitHub for reference code, and track implementation guides from ENISA and CISA for sector-specific checklists. The post-platform web can remain private, but only if its creators close the decrypt-later window before quantum computers can permanently open it.</p>","contentLength":22197,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How America Helped Iran Start Its Nuclear Program","url":"https://hackernoon.com/how-america-helped-iran-start-its-nuclear-program?source=rss","date":1750407229,"author":"Kamal samaila","guid":163440,"unread":true,"content":"<p>For days, our screens have been filled with the fires of the escalating war between Israel and Iran. What many observers hoped would be a limited, one-day operation has spiralled into a wider conflict, with daily reports of missile attacks and devastating airstrikes.</p><p>The stated objective from Israel and its Western allies, particularly the United States, is to destroy Iran’s nuclear facilities and permanently stop the regime in Tehran from acquiring an atomic bomb.</p><p>The intensity of this effort speaks to a deep-seated fear in Western capitals. For decades, a coalition of nations has deployed crippling sanctions, sophisticated cyber-attacks, and a campaign of targeted assassinations to halt Iran’s progress in building nuclear technology. This raises a crucial question that has gnawed at my curiosity: How did Iran, a nation so isolated and targeted for so long, manage to develop a nuclear program so advanced that it is now considered a threshold nuclear state, capable of producing fissile material for a bomb in a matter of weeks?</p><p>The answer, I discovered, is one of profound and startling irony. To understand how Iran got here, you don’t start with the clandestine networks of the 1990s or the secret facilities revealed in the 2000s. You start in the 1950s, with Iran’s closest partner at the time which is the United States of America.</p><h2>The Shah’s Dream, Built by the West</h2><p>The genesis of Iran’s nuclear program was not an act of defiance against the West, but a symbol of Western-backed modernization. In 1957, under President Dwight D. Eisenhower’s “Atoms for Peace” initiative, Washington and Tehran signed a civil nuclear cooperation agreement. This program was design to promote civilian nuclear technology and secure Cold War allies which welcomed Iran into the atomic age.</p><p>The American partnership was not just merely symbolic. The United States directly facilitated the construction of the Tehran Research Reactor (TRR), which became the heart of the country’s nuclear expertise. In 1967, the U.S. supplied the reactor with fuel, nearly 6 kilograms of uranium enriched to 93%, a purity level now considered weapons-grade.</p><p>Under the leadership of Shah Mohammad Reza Pahlavi, who was a supporter of the west, these first steps grew into a vision of staggering ambition. In 1974, he established the Atomic Energy Organization of Iran (AEOI) and unveiled a plan to build as many as 20 nuclear power plants to secure Iran’s energy future.</p><p>To realize this dream, Iran created deep ties with Western industry. West Germany’s Kraftwerk Union, a subsidiary of Siemens, began building two large reactors at the Bushehr site in 1975. France’s Framatome was also contracted. Iran even invested over $1 billion to become a 10% shareholder in the French-led Eurodif uranium enrichment consortium, entitling it to a share of the final product.</p><p>America also contributed for the foundation of nuclear technology knowledge to Iran. In 1975, the AEOI signed a contract with the Massachusetts Institute of Technology (MIT) to provide advanced training for Iranian nuclear scientists and engineers.</p><h2>The Turn: How an Alliance Became a Threat</h2><p>The regime of the Shah who was trying to advance nuclear technology supported by the western world was shattered by the 1979 Islamic Revolution. The new theocratic leadership under Ayatollah Khomeini was initially hostile to the program, viewing it as a wasteful symbol of the Shah’s dependence on the West. The half-finished Bushehr plant was nearly converted into a grain silo.</p><p>The program may have died there, but the brutal eight-year Iran-Iraq War fundamentally altered the regime’s thinking. Facing devastating chemical weapon attacks from Saddam Hussein, Iran’s leaders came to see the absolute necessity of an ultimate deterrent for national survival. The atomic dream of the Shah was reborn with strategic importance to the Islamic Republic.</p><p>From that point on, the story becomes more familiar. Cut off from its former partners, Iran turned to new allies like Russia and China to rebuild and advance its program in secret. This pursuit, aimed at achieving the weapon grade Nuclear technology, is among the important factors that triggered the decades of confrontation that followed.</p><p>The West, led by the U.S., has spent the last 30 years trying to undo what it helped start. A relentless campaign of sanctions, sabotage like the Stuxnet virus, and the assassination of top scientists has been waged to dismantle Iran’s nuclear infrastructure. Yet, these efforts have often hardened Tehran’s resolve, fueling a narrative of resistance and providing the ultimate justification for needing a deterrent in the first place.</p><p>The conflict raging across the Middle East is the violent culmination of this paradoxical history. The West’s desperate, multi-decade effort to stop Iran from getting the bomb is, in reality, a fight against a capability it ironically may have helped created in the first place.</p>","contentLength":4971,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI-Powered Autonomous Drones Are Redefining Modern Warfare","url":"https://hackernoon.com/ai-powered-autonomous-drones-are-redefining-modern-warfare?source=rss","date":1750407133,"author":"Allan Grain","guid":163439,"unread":true,"content":"<p>Wars, and the armies that fight them, once relied on manpower, tanks and artillery to get the job done. But war has changed, and, along with it, or perhaps the reason for it, advanced technology now reigns supreme.</p><p>AI-powered autonomous drones are now leading militaries into a new era of warfare, transforming battlefields into larger battle zones, with unprecedented precision, scalability, and complexity. Unmanned aerial vehicles (UAVs), equipped with artificial intelligence (AI) and machine learning (ML), can navigate, identify targets, and execute strikes with minimal human intervention. Today, their use spans military operations, surveillance, and reconnaissance, making them a cornerstone of modern defense strategies.</p><p>Looking at the two major wars today taking place between Russia and Ukraine, as well as Israel and Iran, we are witnessing how AI-driven drones are reshaping how wars are fought, how nations engage in combat, and how tactical advantages and disadvantages have changed.</p><p>The Russia-Ukraine conflict serves as a perfect real-world example of how AI-powered drones have been integrated into active combat scenarios. The fact that both sides have been using drones to offset lack of manpower and resources, marks this conflict as the world’s first large-scale drone war.</p><p>Immediately after Russia’s attack in February 2022, Ukraine rapidly scaled its <a href=\"https://www.pravda.com.ua/eng/news/2025/06/18/7517711/\">drone capabilities</a> to counter Russia’s manpower and resource advantages. Ukraine deployed AI-enabled drones for reconnaissance and precision strikes, as well as to counter Russian systems.</p><p>A notable operation, codenamed “Spiderweb,” saw Ukraine use <a href=\"https://www.theguardian.com/world/2025/jun/02/operation-spiderweb-visual-guide-ukraine-drone-attack-russian-aircraft\">AI-powered drones to strike Russian airfields</a> thousands of kilometers away, damaging or destroying over 40 strategic bombers. These drones switched to autonomous mode when jammed, following preplanned routes to hit targets with precision. Ukraine’s focus on long-range strike drones, with production goals of 30,000 units in 2025, has allowed it to disrupt Russia’s energy industry and military logistics, leveling the playing field despite limited Western support for deep strikes.</p><p>At the same time, Russia has also advanced its AI drone capabilities – often with Iran’s assistance. The <a href=\"https://armyrecognition.com/military-products/army/unmanned-systems/unmanned-aerial-vehicles/lancet-3-loitering-munition-kamikaze-drone-russia-data-fact-sheet\">Lancet-3</a> and <a href=\"https://en.defence-ua.com/weapon_and_tech/obscure_russian_v2u_drone_unraveled_by_intelligence_autonomous_loitering_munition_powered_by_nvidia_chip-14798.html\">V2U drones</a> feature autonomous target recognition. Russia’s <a href=\"https://euromaidanpress.com/2025/06/11/russia-jet-powered-geran-3-drone-hits-kyiv/\">Geran-series drones</a>, based on Iran’s Shahed-136, are used for long-range strikes, launching hundreds nightly to overwhelm Ukrainian air defenses.</p><p>The conflict has exposed challenges for both sides. Ukraine struggles with production financing, while Russia faces issues with autonomous targeting reliability.</p><p>In the escalating Israel-Iran conflict, AI-powered drones have played a pivotal role in covert and high-precision operations, showcasing their strategic value in asymmetric warfare.</p><p>Israel’s war against Iran began with <a href=\"https://www.csis.org/analysis/ungentlemanly-robots-israels-operation-rising-lion-and-new-way-war\">swarms of small, explosive drones</a>, pre-positioned inside Iran by agents, targeting air-defense radars and communication nodes. These AI-driven drones, operating autonomously to evade Iran’s multilayered defenses, created confusion and opened gaps for follow-on strikes by F-35 jets.</p><p>Israel’s use of drones extends beyond Iran. In Gaza and Lebanon, AI-guided systems like the <a href=\"https://automatedresearch.org/weapon/israel-aerospace-industries-harop-loitering-munition/\">IAI Harop</a> have been employed for precision strikes.</p><p>For its part, Iran is a pioneer in low-cost drone technology and has deployed AI-enhanced drones in its proxy conflicts and direct operations. The Shahed-136, exported to Russia and used by groups like the Houthis, features basic AI for navigation and targeting, allowing it to strike at ranges up to 1,500 kilometers. In April 2024, <a href=\"https://www.aljazeera.com/news/2024/4/14/iran-attacks-israel-with-over-300-drones-missiles-what-you-need-to-know\">Iran launched 300 drones against Israel</a>, though most were intercepted. Iran’s systems appear to lag behind Israel’s in sophistication, relying heavily on quantity over precision. Israel’s high-tech, covert approach contrasts with Iran’s mass-production strategy, yet both exploit autonomy to extend battlefield reach.</p><p>What’s clear is that AI-powered drones are reshaping warfare worldwide. China is also developing AI-augmented drone swarms, tested for autonomous assaults, while Taiwan has looked to Ukraine for inspiration to close its drone gap with Beijing. Judging by the two aforementioned wars taking place today, these drone systems will almost certainly dominate potential future conflicts in the Indo-Pacific.</p><p>AI-powered autonomous drones are no longer a futuristic concept but a present reality, driving innovation and destruction across battlefields. The lessons from Ukraine, Iran, and beyond will shape not only current conflicts but also the future of warfare, where AI drones may well dictate the terms of victory.</p>","contentLength":4628,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Your Web3 Project Deserves More Than Just a Press Release","url":"https://hackernoon.com/your-web3-project-deserves-more-than-just-a-press-release?source=rss","date":1750406910,"author":"Jessica Lane","guid":163438,"unread":true,"content":"<p>So you launched your Web3 project, minted your NFTs, maybe even locked some liquidity. You’re pumped. You throw together a press release—“X Project is Live!”—hit send on a distribution platform, and then… crickets. A few bots repost it, a couple of obscure crypto sites syndicate it, but the community? Nowhere to be seen.</p><p>You start wondering—did anyone even  this thing?</p><p>Here's the uncomfortable truth: In Web3, a press release alone won’t cut it. The magic isn’t in writing it. The real move is knowing how to distribute it—where, when, and most importantly, to .</p><h2>Press Releases Aren’t Dead—But They’re Seriously Misunderstood</h2><p>First off, let’s get one thing straight. Press releases are still relevant. But only if you stop treating them like magic tickets to virality.</p><p>Most Web3 founders think the job’s done once the press release is written and uploaded to some newswire. “Cool, it’s on Yahoo Finance!” they say—like that’s supposed to impress anyone minting on Base or playing around with Arbitrum’s latest ecosystem drop.</p><p>Here’s the problem: Web3 doesn’t read Yahoo Finance. It reads CoinDesk, decrypts narratives on X (formerly Twitter), and hangs out in Discord servers, not on traditional media.</p><p>That’s the disconnect. You can’t expect traction from people who were never looking in your direction to begin with.</p><h2>Distribution: The Secret Weapon Nobody’s Talking About</h2><p>So what actually moves the needle?</p><p>Distribution. And I don’t mean dumping your release across 300 low-traffic news aggregators. That’s just noise.</p><p>Real distribution is thoughtful. It's targeted. It knows where your audience hangs out and meets them there, not wherever your press release happens to land.</p><ul><li>Syndication on top-tier crypto-native platforms: Cointelegraph, Decrypt, CryptoSlate, NewsBTC</li><li>Listings in aggregator ecosystems like CoinMarketCap, CoinGecko, DappRadar</li><li>Sharing via Web3-native newsletters and platforms like The Daily Gwei, Milk Road, or TLDR Crypto</li><li>X (Twitter) threads and Telegram reposts from accounts that matter</li><li>Organic community reposts, not forced retweets</li><li>SEO-focused backlinks on high-authority Web3 blogs and DAOs</li></ul><p>Distribution isn’t about more eyes. It’s about the  eyes.</p><h2>Know Your Crowd—or Don’t Bother Showing Up</h2><p>Here’s where a lot of projects trip over their own whitepapers: they write one-size-fits-all content for wildly different audiences.</p><p>You’re building a ZK rollup? Your readers are L2 devs, ETH nerds, maybe some hardcore infra VCs. They don’t care about NFT collabs or gamified loyalty programs.</p><p>Launching an NFT series with dynamic metadata? Totally different crowd. You want influencers, artists, cultural curators, meme enthusiasts.</p><p>Trying to get both with the same press release? You’ll miss both. It’s like trying to serve sushi and hot wings at the same dinner party—nobody's happy.</p><p>So break it up. Segment your audience. Customize your outreach. Meet each micro-community with messaging that feels like it’s speaking directly to them.</p><h2>Think of PR Like a Party—Not a Billboard</h2><p>Imagine this: You’ve got an amazing new music track. It’s fire. But you blast it from a single cheap speaker, in the middle of nowhere, and no one’s around. Guess what? No one dances.</p><p>But now imagine you’ve got the track—plus killer speakers, a buzzing room, the right lighting, a hyped crowd. Suddenly? Everyone’s vibing.</p><p>That’s what good PR distribution is. The press release is just your song. The rest—the timing, the platforms, the people—is your sound system. Without it, you're whispering into the void.</p><p>What does that setup look like in Web3?</p><ul><li>Strong publication partnerships (especially niche ones—think “Zero Knowledge Weekly” or “DeFi Alpha”)</li><li>Relationships with writers, not just “outlets”</li><li>X influencers and thought leaders dropping threads or quoting your news</li><li>Google News indexing and structured metadata so your release doesn’t disappear in search</li><li>Content fragments that work on different platforms (one quote for X, one graph for Reddit, one visual for Telegram)</li></ul><h2>Web3 Trusts Humans, Not Headlines</h2><p>People in Web3 have been burned. Rugs, vaporware, fake founders—you name it. So they’ve got their BS detectors cranked up to 100. That polished, generic press release? It smells like marketing.</p><p>But you know what doesn’t?</p><ul><li>A quote from a founder with a known Twitter handle</li><li>A snapshot from a DAO vote tied to your announcement</li><li>A reply from a respected dev in your GitHub issues thread</li></ul><p>Press releases that get traction are the ones that feel . Not over-polished. Not hype for hype’s sake. They’re direct, factual, and transparent. They sound like the team wrote it, not a PR firm on autopilot.</p><p>In a trust-scarce environment, authenticity  strategy.</p><h2>Timing Isn’t Everything—But It’s Close</h2><p>Ever see a killer announcement drop at 2 a.m. on a Sunday? Exactly. You didn’t. Because timing is half the game.</p><p>Here’s a pro tip: Press releases shouldn’t be standalone. They should be .</p><p>You’ve got a token launch coming? Schedule the press release the same day the DEX pairs go live. Got a new partnership? Time it with the first co-hosted space or Twitter AMA.</p><ul><li>Testnet or mainnet deployments</li></ul><p>Timing amplifies everything. Even the most boring update can hit hard if it rides a moment of attention.</p><h2>Stop Chasing Vanity Metrics</h2><p>You know those PR platforms that promise 3,000 placements and 500,000 impressions?</p><p>You don’t need reach. You need relevance.</p><p>A hundred impressions from VC analysts, devs, or early DAO contributors are worth more than 100,000 from random Facebook traffic.</p><ul><li>Referrals to your site from crypto-native publications</li><li>Increase in search volume for your project name</li><li>Mentions on Reddit or X from organic users (not bots or shillers)</li><li>Discord or Telegram activity post-launch</li><li>SEO improvements (are you ranking for relevant keywords a week later?)</li></ul><p>If your press release doesn’t start conversations or curiosity, what’s the point?</p><p>Here’s where you stop playing around and build your actual stack:</p><ul><li> – purpose-built for crypto-native press release distribution</li><li> – great for thought-leadership and long-form announcements</li><li> – a more newsletter-like feel for updates that need storytelling</li><li> – community blogging with built-in Web3 flair</li><li> – for transparency, roadmaps, open data</li><li><strong>Twitter/X, Telegram, Discord</strong> – obvious, but underutilized when it comes to PR follow-ups</li><li> – to track what really happened after your release</li></ul><p>The stack is the strategy. Mix tools that publish with tools that  results.</p><h2>Should You Even Bother With Press Releases?</h2><p>If you're just publishing one for the sake of looking official—don’t. It’s not 2015, and “we’re live!” means nothing without context.</p><p>But if you treat your press release as the  of a multi-platform, story-driven distribution cycle? If it’s paired with a founder tweet, some ecosystem validation, and meaningful placement?</p><p>Then yes. 100%. Web3 deserves to know what you’re building.</p><p>Just don’t mistake a press release for a megaphone. It's more like the opening line of a good story. How you tell the rest? That’s what gets remembered.</p>","contentLength":7091,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stop Prompting, Start Engineering: 15 Principles to Deliver Your AI Agent to Production","url":"https://hackernoon.com/stop-prompting-start-engineering-15-principles-to-deliver-your-ai-agent-to-production?source=rss","date":1750405964,"author":"Vladyslav Chekryzhov","guid":163437,"unread":true,"content":"<p>At first, you just try to communicate with ChatGPT via API, throw in a couple of lines of context, and feel amazed that it responds at all. Then you want it to do something useful. Then — to do it reliably. Eventually — to do it without you.</p><p>That’s how an agent is born.</p><p>If you’ve also spent the past year cobbling together agents from scripts and wrappers, experimenting and tinkering, and you’re still searching for a cleaner, more sustainable way to build them — this article is for you. I’ve wandered through repos and forums, repeatedly asking myself, “How are others doing it?” &gt; I kept what stuck — what actually felt right after some real use, and gradually distilled a set of core principles for turning a cool idea into a production-ready solution.</p><p>This isn’t a manifesto. Think of it as a practical cheat sheet — a collection of engineering principles that help guide an agent from the sandbox to production: from a simple API wrapper to a stable, controllable, and scalable system.</p><p>In <a href=\"https://www.anthropic.com/engineering/building-effective-agents\">this article</a> (Building effective agents), Anthropic defines an agent as a system where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks. Systems where LLMs and tools are orchestrated through predefined code paths they call Workflows. Both are part of a broader concept - Agent Systems.</p><p>In this text, Agent = Agent system, where for the sake of stability and control I will more often lean towards Workflows. I hope that in the near future there will be 1-2 more turns of the evolution and true Agents will be ubiquitous, but for now this is not the case</p><blockquote><p>Early versions of agents usually come together fast: a few functions, a couple of prompts — and hey, it works.</p></blockquote><p><strong>“If it works, why make it complicated?”</strong></p><p>In the beginning, everything&nbsp;&nbsp;stable. The agent responds, executes code, behaves sensibly. But once you switch the model, restart the system, or plug in a new interface — suddenly it becomes unstable, unpredictable, hard to debug.</p><p>And often, the root cause isn’t in the logic or the prompts, but much earlier: broken memory management, hardcoded staff, no way to resume sessions, or a single rigid entry point.</p><p>This section walks through four key principles that will help you build a solid foundation — one that everything else can safely grow on top of.</p><ol><li><strong>You can’t resume the process.</strong>&nbsp;If the agent gets interrupted (a crash, a timeout, whatever), it should be able to pick up exactly where it left off.</li><li><strong>Reproducibility is limited.</strong>&nbsp;You need a way to precisely reproduce what happened — for testing, debugging and other such pleasures.</li></ol><p>This one’s not strictly a problem, but still:</p><ol start=\"3\"><li>&nbsp;Sooner or later you’ll want to parallelize the agent’s logic. Maybe it needs to compare multiple options mid-dialogue (“Which of these is better?”). Maybe you want it to branch. Who knows — you will.</li></ol><p>(Memory is a whole separate issue — we’ll get to that soon)</p><p>&nbsp; Move state&nbsp;&nbsp;the agent — into a database, a cache, a storage layer — even a JSON file will do.</p><ul><li>The agent can be launched from any step, having only a session_id — the session identifier — and external state (for example, saved steps in a database or JSON file). <em>At any stage, you can interrupt the agent's work, restart it (even after changing something under the hood), and it will work as if nothing happened</em></li><li>Test case: an interrupted agent doesn't lose context, after restart the result is the same</li><li>State is serializable at any moment without loss of functionality</li><li>You can feed the state to multiple instances in parallel in the middle of a dialogue</li></ul><h3>2. </h3><p>: LLMs don't remember. Even within a single session, the model can forget what you've already explained, mix up stages, lose the thread of conversation, or start \"filling in\" details that weren't there. And it seems like time goes on, the context window grows bigger and bigger, delighting us with new possibilities. LinkedIn is full of posts where people compare which book or how many hours of YouTube's video now fit into the new model version. But still, LLMs don't remember and you should be prepared.</p><ul><li>and tokens are still not infinite</li></ul><p>Even with increasing context windows (8k, 16k, 128k…), problems remain:</p><ul><li> — the model pays more attention to the beginning and end (and can loose details from the middle)</li><li> — more tokens = more money;</li><li><strong>And it still doesn't fit.</strong> Which means there will be loss, distortion, or hallucinations. As long as transformers work on self-attention with quadratic complexity (), this limitation will be with us.</li></ul><p> Separate \"working memory\" from \"storage\" — like in classical computing systems. The agent should be able to work with external memory: store, retrieve, summarize, and update knowledge outside the model. There are several architectural strategies, and each has its boundaries.</p><p>Stores the last  messages. Take for quick prototyping.</p><p> simple, fast, sufficient for short tasks</p><p> loses important info, doesn't scale, doesn't remember \"yesterday\"</p><p>Compresses history to fit more.</p><p> token savings, memory expansion</p><p> distortions, loss of nuances, errors in multi-step compression</p><p>\\\n<strong>RAG (Retrieval-Augmented Generation)</strong></p><p>Pulls knowledge from external databases. Most of the time you'll be here.</p><p> scalable, fresh, verifiable</p><p> complex setup, sensitive to retrieval quality, latency</p><p>Structured connections between entities and facts. Always elegant, sexy and hard, you'll end up doing RAG anyway.</p><p> logic, explainability, stability</p><p> high barrier to entry, complexity of LLM integration</p><ul><li>All conversation history is accessible in one place (outside the prompt)</li><li>Knowledge sources are logged and can be reused</li><li>History scales without risk of exceeding the context window</li></ul><p> LLMs are rapidly evolving; Google, Anthropic, OpenAI, etc. constantly release updates, racing against each other across different benchmarks. This is a feast for us as engineers, and we want to make the most of it. Our agent should be able to easily switch to a better (or conversely, cheaper) model seamlessly.</p><ol><li><strong>Implement model</strong>id parameter in configuration files or environment variables to specify the model being used.</li><li>: Create interfaces or wrapper classes that interact with models through a unified API.</li><li><strong>Apply middleware solutions</strong> (carefully—we'll talk about frameworks a bit later)</li></ol><ul><li>Model replacement doesn't affect the rest of the code and doesn't impact agent functionality, orchestration, memory, or tools</li><li>Adding a new model requires only configuration and, optionally, an adapter (a simple layer that brings the new model to the required interface)</li><li>You can easily and quickly switch models. Ideally—any models, at minimum—switching within a model family</li></ul><h3>4. <strong>One Agent, Many Interfaces: Be Where the Users Are</strong></h3><p> Even if initially the agent is intended to have only one communication interface (for example, UI), you'll eventually want to give users more flexibility and convenience by adding interaction through Slack, WhatsApp, or, dare I say it, SMS - whatever. An API might turn into a CLI (or you'll want one for debugging). Build this into your design from the start; make it possible to use your agent wherever it's convenient.</p><p><strong>Creating a unified input contract</strong>: Develop an API or other mechanism that will serve as a universal interface for all channels. Store channel interaction logic separately.</p><ul><li><p>Agent is callable from CLI, API, UI</p></li><li><p>All input goes through a single endpoint/parser/schema</p></li><li><p>All interfaces use the same input format</p></li><li><p>No channel contains business logic</p></li><li><p>Adding a new channel = only an adapter, no changes to core</p></li></ul><h2>II. Define Agent Behaviour</h2><blockquote><p>While there's only one task, everything is simple, as in the posts of AI evangelists. But as soon as you add tools, decision-making logic, and multiple stages, the agent turns into a mess.</p></blockquote><p>It loses track, doesn't know what to do with errors, forgets to call the right tool—and you're left alone again with logs where \"well, everything seems to be written there.\"</p><p>To avoid this, the agent needs a clear : what it does, what tools it has, who makes decisions, how humans intervene, and what to do when something goes wrong.</p><p>This section covers principles that will help you give your agent a coherent action strategy instead of hoping \"the model will figure it out somehow.\"</p><p> This point might seem obvious, but you still encounter agents built on \"Plain Prompting + raw LLM output parsing.\" It's like trying to control a complex mechanism by pulling random strings and hoping for the best. When LLMs return plain text that we then try to parse with regex or string methods, we face:</p><ul><li> The slightest change in LLM response wording (a word added, phrase order changed) can break the entire parsing. This leads to a constant \"arms race\" between your parsing code and model unpredictability.</li><li> Natural language is inherently ambiguous. What seems obvious to a human can be a puzzle for a parser. \"Call John Smith\"—which of the three John Smiths in your database? What's his number?</li><li> Parsing code grows, becomes tangled and hard to debug. Each new agent \"skill\" requires writing new parsing rules.</li><li> It's hard to make the model reliably call multiple tools or pass complex data structures through simple text output.</li></ul><p> The model returns JSON (or another structured format)—the system executes.</p><p>The key idea here is to leave the responsibility for  user intent and  tools to the LLM, while still assigning the  of that intent to the  through a clearly defined interface.</p><p>Fortunately, practically all providers (OpenAI, Google, Anthropic, or whoever else you prefer) support so-called  or the ability to generate output in a strictly defined JSON format.</p><p>Just to refresh how this works:</p><ol><li> You define functions (tools) as JSON Schema with name, description, parameters. Description is critically important—the model relies on it.</li><li> On each call, the model receives tool schemas along with the prompt.</li><li> Instead of text, the model returns JSON with:</li></ol><ul><li>name of the function to call</li><li>arguments—parameters according to schema</li></ul><ol><li> Code validates JSON and calls the appropriate function with parameters.</li><li><strong>Model response (optional):</strong> Execution result is passed back to LLM for final response generation.</li></ol><p> Tool descriptions are also prompts. Unclear description = wrong function choice.</p><p><strong>What to do without function calling?</strong></p><p>If the model doesn't support tool calls or you want to avoid them for some reason:</p><ul><li>Ask the model to return JSON in the prompt. Be sure to specify the format; you can add examples.</li><li>Parse the response and validate it with something like Pydantic. There are real fans of this approach.</li></ul><ul><li>Response is strictly formalized (e.g., JSON)</li><li>Schemas are used (JSON Schema or Pydantic)</li><li>Validation is applied before function calls</li><li>Generation errors don't cause breakage (format error handling exists)</li><li>LLM = function choice, execution = code</li></ul><p> Usually agents work as \"dialogues\"—first the user speaks, then the agent responds. It's like playing ping-pong: hit-response. Convenient, but limiting.</p><ul><li>Do something on its own without a request</li><li>Perform actions in parallel</li><li>Take multiple steps in sequence</li><li>Check progress and return to failed steps</li></ul><p>Instead, the agent should manage its own \"execution flow\"—decide what to do next and how to do it. This is like a task scheduler: the agent looks at what needs to be done and executes steps in order.</p><ul><li>decides when to do something on its own</li><li>can take steps one after another</li><li>can work even without direct requests</li></ul><p> Instead of letting the LLM control all the logic, we extract the  into code. The model only helps within steps or suggests the next one. This is a shift from \"writing prompts\" to  with controlled behaviour.</p><p>Let's look at three popular approaches:</p><p><strong>1. FSM (Finite State Machines)</strong></p><ul><li> Task broken down into states and clear transitions.</li><li> Determines the next step or acts within a state.</li><li> Simplicity, predictability, good for linear scenarios.</li><li> StateFlow, YAML configurations, State Pattern.</li></ul><ul><li> Non-linear or parallel tasks as a graph: nodes are actions, edges are dependencies.</li><li> Can be a node or help with plan construction.</li><li> Flexibility, parallelism, visualizable.</li><li> LangGraph, Trellis, LLMCompiler, custom DAG diagrams.</li></ul><ul><li> LLM builds a plan, code or other agents execute it.</li><li> \"Big\" one plans, \"small\" ones execute.</li><li> Separation of concerns, cost control, scalability.</li><li> LangChain Plan-and-Execute.</li></ul><ul><li>Increases , , .</li><li>Allows combining different models and speeding up execution.</li><li>Task flow becomes visualizable and testable.</li></ul><ul><li>Uses FSM, DAG, or scenario with explicit transitions</li><li>Model decides what to do but doesn't control the flow</li><li>Behavior can be visualized and tested</li><li>Error handling is built into the flow</li></ul><h3>7. <strong>Include the Human in the Loop</strong></h3><p> Even if an agent uses structured tools and has a clear control flow, full autonomy of LLM agents in the real world is still more of a dream (or nightmare, depending on context). LLMs don't possess true understanding and aren't accountable for anything. They can and will make suboptimal decisions. Especially in complex or ambiguous situations.</p><p><strong>Main risks of full autonomy:</strong></p><ul><li> The agent might perform actions with serious consequences (delete data, send an incorrect message to an important client, start a robot uprising).</li><li> The agent might accidentally violate internal regulations, legal requirements, or hurt user feelings (if that wasn't the plan, ignore this point).</li><li><strong>Lack of common sense and ethics:</strong> LLMs might miss social nuances or act against \"common sense.\"</li><li> If the agent makes frequent mistakes, users will stop trusting it.</li><li><strong>Audit and accountability complexity:</strong> Who's to blame when an autonomous agent \"screws up\"?</li></ul><p> ~~Strategic summoning of Carbon-based lifeforms~~ Integrate humans into the decision-making process at key stages.</p><p><strong>HITL Implementation Options</strong></p><ul><li> action is critical, expensive, irreversible</li><li> agent formulates a proposal and waits for confirmation</li></ul><p><strong>2. Confidence-aware Routing</strong></p><ul><li>self-assessment (logits, LLM-as-a-judge, P(IK))</li><li>escalation when confidence falls below threshold</li></ul><ul><li> insufficient data or unclear request formulation</li><li> agent asks for clarification (e.g., HumanTool in CrewAI)</li></ul><ul><li> repeated error or unresolvable situation</li><li> task is passed to operator with context</li></ul><ul><li> for model improvement</li><li> human evaluates responses, they go into training</li></ul><ul><li>Actions requiring approval are defined</li><li>There's a mechanism for confidence assessment</li><li>Agent can ask humans questions</li><li>Critical actions require confirmation</li><li>There's an interface for inputting responses</li></ul><h3>8. <strong>Compact Errors into Context</strong></h3><p> The standard behavior of many systems when an error occurs is either to \"crash\" or simply report the error and stop. For an agent that should autonomously solve tasks, this isn't exactly the best behavioral model. But we also don't want it to hallucinate around the problem.</p><ul><li> Any failure in an external tool or unexpected LLM response can stop the entire process or lead it astray.</li><li> Constant restarts and manual intervention eat up time and resources.</li><li><strong>Inability to learn (in the broad sense):</strong> If the agent doesn't \"see\" its errors in context, it can't try to fix them or adapt its behavior.</li></ul><p> Errors are included in the prompt or memory. The idea is to try implementing some kind of \"self-healing.\" Agent should at least try to correct its behavior and adapt.</p><ul><li><strong>Self-correction mechanisms:</strong> Error Detection, Reflection, Retry Logic, Retry with changes (Agent can modify request parameters, rephrase the task, or try a different tool)</li><li><strong>Impact of reflection type:</strong> More detailed error information (instructions, explanations) usually leads to better self-correction results. Even simple knowledge of previous errors improves performance.</li><li><strong>Internal Self-Correction:</strong> Training LLMs for self-correction by introducing errors and their fixes into training data.</li><li> If self-correction fails, the agent escalates the problem to a human (see Principle 7).</li></ul><ul><li>Previous step's error is saved to context</li><li>Fallback/human escalation is used for repeated failures</li></ul><p> Let's back to the key LLM limitation (that context window thing), but look at this problem from another angle. The bigger and more complex the task, the more steps it will take, which means a longer context window. As context grows, LLMs are more likely to get lost or lose focus. By focusing agents on specific domains with 3-10, maybe maximum 20 steps, we maintain manageable context windows and high LLM performance.</p><p> Use smaller agents targeted at specific tasks. One agent = one task; orchestration from above.</p><p>Benefits of small, focused agents:</p><ul><li> Smaller context windows mean better LLM performance</li><li> Each agent has a well-defined scope and purpose</li><li> Less chance of getting lost in complex workflows</li><li> Easier to test and validate specific functionality</li><li> Easier to identify and fix problems when they arise</li></ul><p>Unfortunately, there's no clear heuristic for understanding when a piece of logic is already big enough to split into multiple agents. I'm pretty sure that while you're reading this text, LLMs have gotten smarter somewhere in labs. And they keep getting better and better, so any attempt to formalize this boundary is doomed from the start. Yes, the smaller the task, the simpler it is, but the bigger it gets, the better the potential is realized. The right intuition will only come with experience. But that's not certain.</p><ul><li><p>Scenario is built from microservice calls</p></li><li><p>Agents can be restarted and tested separately</p></li><li><p>Agent = minimal autonomous logic. You can explain what it does in 1-2 sentences.</p></li></ul><h2>III. Control Model Interaction</h2><blockquote><p>The model handles generation. Everything else is on you.</p></blockquote><p>How you formulated the request, what you passed in context, what instructions you gave—all this determines whether the result will be coherent or \"creative.\"</p><p>LLMs don't read minds. They read tokens.</p><p>Which means any input error turns into an output bug—just not immediately noticeable.</p><p>This section is about not letting everything drift: prompts = code, explicit context management, constraining the model within boundaries. We don't hope that the LLM will \"figure it out on its own.\"</p><h3><strong>10. Treat Prompts as Code</strong></h3><p> A very common pattern, especially among folks without ML or SE background, is storing prompts directly in code. Or at best, unsystematic storage in external files.</p><p>This approach leads to several maintenance and scaling difficulties:</p><ul><li>Navigation, understanding, and modification become complicated as project complexity and number of prompts grow.</li><li>Without explicit versioning, it's very hard to track prompt evolution, reasons for changes, and roll back to previous stable versions in case of performance degradation.</li><li><strong>Inefficient improvement and debugging process:</strong> Prompt optimization without objective metrics and testing becomes a subjective and labor-intensive process with unstable results.</li><li>Perception by other team members becomes complicated, including (and especially) future you.</li></ul><p> Prompts in this context are not much different from code and the same basic engineering practices should be applied to them</p><ul><li>Store separately and systematically, using specialized files (like , , , ) or even template management systems (e.g., Jinja2, Handlebars, or specialized tools like BAML).</li><li>Explicit prompt versioning. You can even do A/B tests with different versions after this.</li><li>Testing. You heard that right.</li><li>This could be something like unit tests, where you compare LLM responses to specific inputs against reference answers or expected characteristics depending on the prompt</li><li>Format compliance checks and presence/absence of key elements - For example, if a prompt should return JSON, the test can validate its structure</li><li>Even LLM-as-a-judge if your project and design justify it.</li></ul><p>We'll talk about testing in more detail in the principe 14.</p><ul><li>Prompts are stored in separate files, separate from business logic</li><li>There's diff and change history</li><li>Tests are used (as needed)</li><li>(Optional) How about prompt review as part of code review?</li></ul><p>&nbsp;We've already discussed the \"forgetfulness\" of LLMs, partially solving this by offloading history to external memory and using different agents for different tasks. But that's not all. I propose we also consider explicit context window management (and here I'm not just talking about compressing history to fit the optimal size or including errors from previous steps in the context).</p><p><strong>Standard formats aren't always optimal:</strong>&nbsp;A simple list of messages in the \"role-content\" () format is the baseline, but it can be token-heavy, not informative enough, or poor at conveying the complex state of your agent.</p><p>Most LLM clients use the standard message format (a list of objects with&nbsp;: \"system\", \"user\", \"assistant\",&nbsp;, and sometimes&nbsp;&nbsp;fields).</p><p>While this \"works great for most cases,\" to achieve&nbsp;&nbsp;(in terms of both tokens and the model's attention), we can approach context formation more creatively.</p><p>&nbsp;To engineer it. To treat the creation of the entire information package passed to the LLM as&nbsp;&nbsp;This means:</p><ol><li>&nbsp;Taking full ownership for what information enters the LLM's context window, in what form, volume, and sequence.</li><li>&nbsp;Not limiting ourselves to standard message lists. Developing our own, task-optimized ways of representing context. For example, you could consider using an XML-like structure to densely pack various types of information (messages, tool calls, their results, errors, etc.) into one or several messages.</li><li>&nbsp;Viewing the context not just as a dialogue history, but as the sum total of everything the model might need: the immediate prompt, instructions, data from RAG systems, the history of tool calls, the agent's state, memory from other interactions, and even instructions on the desired output format.</li></ol><p><strong>How do you know when this makes sense?</strong></p><p>If you're interested in any of the following:</p><ul><li>&nbsp;Maximum meaning with minimum noise.</li><li>&nbsp;Reducing the number of tokens where we can get comparable quality for a lower price.</li><li>&nbsp;Handling the inclusion of sensitive info, controlling it, filtering it, .and ending it all by outputting the classic \"sorry, I'm just a squishy little large language model model\" response.</li></ul><h3><strong>12. Constrain the Chaos: Secure Inputs, Guarded Actions, and Grounded Outputs</strong></h3><p>&nbsp;We've already done a lot in the name of stability, but nothing is a silver bullet. This means it's worth looking at the most critical potential problems separately and explicitly taking out some \"insurance\".</p><p>In this principle, we think about:</p><ul><li><strong>Possible Prompt Injection.</strong>&nbsp;If your agent will be communicating directly with a user, you must control what is fed as input. Depending on the type of user, you might get one who wants to break your flow and force the agent to ignore its initial goals, provide the wrong information, perform harmful actions, or generate malicious content.</li><li>&nbsp;For the reason above, or led by \"voices in its head,\" the agent might disclose important information, such as users' personal data, corporate secrets, etc.</li><li><strong>Generation of toxic or malicious content.</strong>&nbsp;If this is by design, ignore this point.</li><li><strong>Making things up when information is absent.</strong>&nbsp;The eternal pain.</li><li><strong>Going beyond permitted boundaries.</strong>&nbsp;Rise of the machines, remember? But seriously, in its reasoning process, the agent might arrive at very non-trivial solutions, not all of which will be within the scope of normal behaviour.</li></ul><p>The security and grounding of an LLM agent isn't a single measure, but a multi-layered system of protection (\"defense-in-depth\") that covers the entire interaction lifecycle. The threats are diverse, and no single method of protection is a panacea. Effective protection requires a combination of techniques.</p><p>&nbsp;We must commit to a multi-layered defense system, thinking through and explicitly handling all corner cases and potential scenarios, and having a clear response ready for whatever might happen.</p><p>In a basic setup, you should consider:</p><ol><li><p>Check for known attack-indicator phrases (e.g., \"ignore all previous instructions\"). It sometimes makes sense to combat potential obfuscation.</p></li><li><p>Try to determine the user's intent separately. You can use another LLM for this, to analyze the input for the current one.</p></li><li><p>Control input from external sources, even if they are your own tools.</p></li><li><p>&nbsp;Control the privileges of both the agent and its tools (granting the minimum necessary), clearly define and limit the list of available tools, validate parameters at the input to tools, and enable Principle #7 (Human in the Loop).</p></li><li><p>&nbsp;Design a system of checks for what the model outputs, especially if it goes directly to the user. These can be checks for relevance (ensuring the model uses what's in the RAG and doesn't just make things up) as well as checks for general appropriateness. There are also ready-made solutions (e.g., the OpenAI Moderation API).</p></li></ol><p>The final system, however, depends on your tasks and your risk assessment. In the checklist, we'll try to sketch out some options.</p><ul><li><p>User input validation is in place.</p></li><li><p>For tasks requiring factual information, the data within the RAG is used.</p></li><li><p>The prompt for the LLM in a RAG system explicitly instructs the model to base its answer on the retrieved context.</p></li><li><p>LLM output filtering is implemented to prevent PII (Personally Identifiable Information) leakage.</p></li><li><p>The response includes a link or reference to the source.</p></li><li><p>LLM output moderation for undesirable content is implemented.</p></li><li><p>The agent and its tools operate following the principle of least privilege.</p></li><li><p>The agent's actions are monitored, with HITL (Human-in-the-Loop) for critical operations.</p></li></ul><blockquote><p>An agent that \"kinda works\" is a bug with a delayed effect.</p></blockquote><p>In prod, not everything breaks at once. And you don't find out about it instantly. Sometimes, you don't find out at all.</p><p>This section is about the engineering habit of&nbsp;&nbsp;and&nbsp;<strong>checking that everything is still working</strong>. Logs, tracing, tests—everything that makes an agent's behavior transparent and reliable, even when you're sleeping or developing your next agent.</p><p>&nbsp;One way or another, you will constantly face situations where the agent doesn't work as you expected. During development, testing, making changes, or during normal operation. This is inevitable, and at the moment, it's normal to some extent. This means you're doomed to spend hours and days debugging, trying to understand what's wrong, reproducing the issue, and fixing it. I'd like to think that by this point you've already implemented Principle #1 (Keep State Outside) and #8 (Compact Errors into Context). In most cases, that will be enough to make your life much simpler. Some other principles will also indirectly help here.</p><p>Even so (and especially if you've decided not to bother with them for now), it makes a lot of sense to think about debugging in advance and save yourself time and nerves in the future by adhering to this principle.</p><p>&nbsp;Log the entire path from request to action. Even if you already have logs for individual components, tracing the entire chain can be a hassle. Even if you're a big fan of puzzles or Lego, at some point, it will stop being fun. Therefore, logs must exist, they must be end-to-end, and they must cover everything.</p><ul><li>&nbsp;— Quickly find where things went wrong. This is the reason this principle exists.</li><li>&nbsp;— See where the bottlenecks are and how to improve.</li><li>&nbsp;— See how changes affect behavior.</li><li>&nbsp;— You can precisely reconstruct the steps.</li><li>&nbsp;— A log of all agent decisions and actions.</li></ul><p>The basic \"gentleman's set\"  looks like this:</p><ul><li>&nbsp;The initial user request, parameters received from the previous step.</li><li>&nbsp;Key state variables of the agent before executing the step.</li><li>&nbsp;The full text of the prompt sent to the LLM, including system instructions, dialogue history, retrieved RAG context, tool descriptions, etc.</li><li>&nbsp;The full, raw response from the LLM, before any parsing or processing.</li><li>&nbsp;If the LLM decided to call a tool – the name of the tool and the exact parameters it was called with (according to the structured output).</li><li>&nbsp;The response that the tool returned, including both successful results and error messages.</li><li>&nbsp;What decision the agent made based on the LLM's response or the tool's result (e.g., what next step to perform, what answer to give the user).</li><li>&nbsp;Step execution time, the LLM model used, the cost of the call (if available), the code/prompt version.</li></ul><p>&nbsp;Look into existing tracing tools; under certain conditions, they will make your life much easier. LangSmith, for example, provides detailed visualization of call chains, prompts, responses, and tool usage. You can also adapt tools like Arize, Weights &amp; Biases, OpenTelemetry, etc. for your needs. But first, see Principle #15.</p><ul><li>All agent steps are logged (your version of the \"gentleman's set\").</li><li>Steps are linked by a&nbsp;&nbsp;and a&nbsp;.</li><li>There is an interface to view the entire chain.</li><li>The prompt sent to the LLM can be reproduced at any stage.</li></ul><p>&nbsp;By this point, you most likely have some kind of practically finished solution. It works, maybe even just the way you wanted. Ship it to prod? But how do we ensure it&nbsp;&nbsp;working? Even after the next minor update? Yes, I'm leading us to the topic of testing.</p><p>Obviously, updates in LLM systems, just like in any other—be it changes to the application code, updates to datasets for fine-tuning or RAG, a new version of the base LLM, or even minor prompt adjustments—often lead to unintentional breaks in existing logic and unexpected, sometimes degrading, agent behavior. Traditional software testing approaches prove to be insufficient for comprehensive quality control of LLM systems. This is due to a number of risks and characteristics specific to large language models:</p><ul><li>&nbsp;You haven't done anything, but performance has dropped over time. Maybe the provider updated their model, maybe the nature of the input data has changed (data drift)—what worked yesterday might stop working today.</li><li>&nbsp;Even a small change to a prompt can break the established logic and distort the output.</li><li>&nbsp;As you know, many LLMs are non-deterministic (especially with&nbsp;), meaning they will generate different responses to the same input on each call. This complicates the creation of traditional tests that expect an exact match and makes reproducing errors more difficult.</li><li><strong>Difficulty in reproducing and debugging errors.</strong>&nbsp;It will be easier for you if you've implemented the first principle, but reproducing a specific error for debugging can be difficult even with fixed data and states.</li><li>&nbsp;In complex systems, updating a single element (like a model or a prompt) can cascade through a chain of APIs, databases, tools, etc., and lead to a change in behavior elsewhere.</li></ul><p>…and I suppose we could go on. But we already understand that traditional tests, focused on verifying explicit code logic, are not fully capable of covering these issues.</p><p>&nbsp;We'll have to devise a complex, comprehensive approach that covers many things, combining classic and domain-specific solutions. This solution should address the following aspects:</p><ul><li>&nbsp;A combination of different test types targeting various aspects of the system: from low-level unit tests for individual functions and prompts to complex scenarios that verify the agent's end-to-end workflow and user interaction.</li><li><strong>Focus on LLM behavior and quality:</strong>&nbsp;Testing should evaluate not only functional correctness but also qualitative characteristics of LLM responses, such as relevance, accuracy, coherence, absence of harmful or biased content, and adherence to instructions and a given style.</li><li><strong>Regression and quality tests</strong>&nbsp;that include \"golden datasets\" containing diverse input examples and reference (or acceptable ranges of) outputs.</li><li><strong>Automation and integration into CI/CD.</strong></li><li><strong>Human-in-the-loop evaluation:</strong>&nbsp;Specific stages of LLM-eval should involve a human for calibrating metrics and reviewing complex or critical cases.</li><li><strong>An iterative approach to prompt development and testing:</strong>&nbsp;Prompt engineering should be treated as an iterative process where each version of a prompt is thoroughly tested and evaluated before implementation.</li><li><strong>Testing at different levels of abstraction:</strong></li><li>&nbsp;Individual modules (parsers, validators, API calls) and their integration.</li><li>&nbsp;Isolated testing of prompts on various inputs.</li><li>&nbsp;Verifying the logic and interaction of components within an agent.</li><li><strong>End-to-end system testing:</strong>&nbsp;Evaluating the completion of full user tasks.</li></ul><ul><li><p>Logic is broken down into modules: functions, prompts, APIs—everything is tested separately and in combination.</p></li><li><p>Response quality is checked against benchmark data, evaluating meaning, style, and correctness.</p></li><li><p>Scenarios cover typical and edge cases: from normal dialogues to failures and provocative inputs.</p></li><li><p>The agent must not fail due to noise, erroneous input, or prompt injections—all of this is tested.</p></li><li><p>Any updates are run through CI and monitored in prod—the agent's behavior must not change unnoticed.</p></li></ul><h3><strong>Principle 15: Own the Execution Path</strong></h3><p><em>This is a meta-principle; it runs through all the ones listed above.</em></p><p>Fortunately, today we have dozens of tools and frameworks for any task. This is great, it's convenient, and it's a trap.</p><p>Almost always, choosing a ready-made solution means a&nbsp;: you get speed and an easy start, but you lose&nbsp;<strong>flexibility, control, and, potentially, security</strong>.</p><p>This is especially critical in agent development, where it's important to manage:</p><ul><li>the unpredictability of LLMs,</li><li>complex logic for transitions and self-correction,</li><li>being ready for the system's adaptation and evolution, even if its core tasks remain unchanged.</li></ul><p>Frameworks bring&nbsp;: they decide for you how the agent should work. This can simplify a prototype but complicate its long-term development.</p><p>Many of the principles described above can be implemented using off-the-shelf solutions—and this is often justified. But in some cases, an&nbsp;<strong>explicit implementation of the core logic takes a comparable amount of time</strong>&nbsp;and provides incomparably more&nbsp;<strong>transparency, manageability, and adaptability</strong>.</p><p>The opposite extreme also exists—, the desire to write everything from scratch. This is also a mistake.</p><p><strong>This is why the key is balance.</strong>&nbsp;The engineer chooses for themselves: where it's reasonable to rely on a framework, and where it's important to maintain control. And they make this decision consciously, understanding the cost and consequences.</p><p>You have to remember: the industry is still taking shape. Many tools were created before current standards emerged. Tomorrow, they might become obsolete—but the limitations baked into your architecture today will remain.</p><p>Okay, we've gone over 15 principles that, experience shows, help turn the initial excitement of \"it's alive!\" into confidence that your LLM agent will work in a stable, predictable, and useful way under real-world conditions.</p><p>You should consider each of them to see if it makes sense to apply it to your project. In the end, it's your project, your task, and your creation.</p><p><strong>Key takeaways to carry with you:</strong></p><ol><li><strong>An engineering approach is key:</strong>&nbsp;Don't rely on the \"magic\" of LLMs. Structure, predictability, manageability, and testability are your best friends.</li><li><strong>The LLM is a powerful component, but still just a component:</strong>&nbsp;Treat the LLM as a very smart, but nevertheless, single component of your system. Control over the overall process, data, and security must remain with you.</li><li><strong>Iteration and feedback are the keys to success:</strong>&nbsp;It's rare to create the perfect agent on the first try. Be prepared for experiments, measurements, error analysis, and continuous improvement—of both the agent itself and your development processes. Including a human in the loop (HITL) isn't just about security; it's also about having an invaluable source of feedback for learning.</li><li>&nbsp;The field of LLM agents is evolving rapidly. Keep an eye on new research, tools, and best practices, and share your own experiences. Many of the problems you'll face, someone has already solved or is solving right now.</li></ol><p>I hope you've found something new and useful here, and maybe you'll even want to come back to this while designing your next agent.</p>","contentLength":35442,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Everyone’s an AI User Now—But No One Read the Manual","url":"https://hackernoon.com/everyones-an-ai-user-nowbut-no-one-read-the-manual?source=rss","date":1750405908,"author":"Wabinab","guid":163436,"unread":true,"content":"<p>Garbage in, Garbage out. You heard the phrase a lot. But usually, it’s the people that create the AI models that take it seriously. Or, unless if you’re a pipeline engineer of not only in software and AI, but also in other industries like making fertilizer, or working in factories, you may agree to the phrase, but never had the chance to experience it yourself. But not anymore. As a user of AI models, everyone now had the chance to be on the end of ‘garbage out’, and because it’s not you who train the models, you don’t even have the chance to control what garbage to put in! </p><p>Recently, one was working on a software to detect changes to a database and push it to the client in ‘real-time’. So, for example, there’s an INSERT operation on a particular table one subscribed to, and that should trigger  and push the change to the backend, where one could then process the data into a form one would like to view before passing it to the frontend. Now, that was something one never done before. Previously, one settled for getting the client side to ping every  seconds for new data, and it worked then, because there’s no requirement for ‘real-time’, so one could do it every 30 seconds or 1 minute. The ‘infrequent’ pinging means it won’t overload the bandwidth, both on the server and on the database. But when you have a  large data to send back to the front and you use frequent pinging and you’re not installing it on localhost, that occupies some bandwidth. Plus, frequently pinging the database to check if there’s new data, even one as simple as checking for the latest ID, would take a toll on the database if it’s in heavy usage at the same time. Not to say they couldn’t be done, but wouldn’t it be better if you can have the database listening to change, notify you to run a command on the server when there’s an update, and then push the update to the client? Save the bandwidth and the toll! </p><p>The traditional way to search for a solution would be to look it up on the web. Actually, it’s not very traditional, still the mainstream way to do it, but with the advent of AI boom and startups competing with established businesses to deliver the latest, state of the art (SOTA) language learning models (LLM) where you could type in your request and have AI do it for you, the nature of searching had changed, so had the behavior of its users. A search engine is designed for you to first think about how you are to execute your plans, and for each step of the plan where you don’t know how to do, you search it up, then stitch together the idea  and be complete with the final product. The new search would be to be disciplined and complete the 7-days cumulative usage of Perplexity and gain its Perplexity Pro free for a month, then maximize the advantage you can take by, instead of using its free ‘search’ feature, went for the pro ‘research’ features and ask, “Hey, using .Net Core 9 and Angular 19 and MS SQL Server 2022, how can I push data from the database (DBName.dbo.Table1) to the frontend client in real time? List for me the steps required, the libraries required to install, and show me example codes of how to do it.” And while it does its magic in the background (which can take several minutes -- and if you use ‘lab’ that create presumably ‘working’ projects that start from scratch, it takes even longer than ‘research’), go and have a cup of coffee/tea, hug your cat/dog and play with it for a while, until you heard ‘ding’, the notification that the answer you want had been completely generated for you. You put down your cat/dog, have a final gulp of your coffee/tea, before fixating your eyes back on the screen, reading through the answers from top to bottom, with all the steps laid out for you, and started integrating it into your own program. </p><p>Now, if you’re a programmer or software developer and equivalent, you’d know that every situation is somewhat unique. Sure, some bugs are well known and well documented, but most others you may find something on the internet, but the solution they gave, although they might’ve solved the person asking the problem, they might not solve yours, even though the problem seems the same. Debugging is a strenuous and indirect process, and a specific code like 400 Not Found can be caused by a lot of things, each probably unrelated to one another, even when they raise the same error. Why do you think, if you cannot solve the problem immediately using ‘traditional’ search engine method, that the AI  solve it for you? Do you , genuinely, think that the solution comes easy for them  their speed of scraping through the web is 100, no, 1000 times yours? And do you really think the abstracted solution generated by AI that works in most  (and unfortunately, yours is the exception, else you won’t be feeling the headache right now) really knows what you want and fit their solution for you, as if they could read your mind or read the entire state of your computer and trace out the stack deep into  program and provide you with an instantaneous fix while you sit back and relax, pursuing your hobby? </p><p>SignalR, developed by Microsoft, is the high-level library published by Microsoft to push updates to the client side. Unfamiliar with how SignalR worked, one, of course, followed the steps compiled by AI and, after manually fitting it to one’s program, copy and pasting the code to their respective places where one sees fit, converting the ‘abstract’ into the ‘specific’, and run the program. And… it didn’t work. And one don’t know why. </p><p>One next use traditional search methods and looked up online, including the tutorials offered in Microsoft’s website, and tried to solve it, to no avail. Trying one after one solution, days after days passed, the solution just won’t materialize. It kept telling me that “404 Not Found”, but what wasn’t being found? Didn’t one followed the steps listed down by AI and Microsoft already? And shouldn’t it had magically worked out? Reality is much more harsher than fantasy. </p><p>The realization come when one dig deeper into how it differs from normal HTTPS request. In fact, because one uses <a href=\"https://github.com/emonney/QuickApp?tab=readme-ov-file\">QuickApp developed by ebMonney</a>, one never had the chance to understand how the proxy works to transfer data to the backend. Before, when one realizes that some of the links, like /api, got proxied to the backend, while the others get parsed by Angular, one thought, perhaps if one changes the /hub one uses for SignalR to /api/hub, it would work. For sure, the error saying 404 didn’t come up anymore, but it still didn’t work. There  to be something deeper that caused it. </p><p>There was a proxy.conf.js, which one heard of it but forgot about it because it’d been built for one so easily that one don’t need to worry about it… until then, that allows you to list the path you want to exclude from being parsed by Angular’s app-routing.module.ts. Basically, Angular will parse all routes in its app-routing, and if it cannot find, it’ll redirect to a page called 404 Not Found, which is a HTML custom-made by ebMonney and included within the QuickApp package. However, if you want angular to proxy some specific link to your backend server, you need to add it inside proxy.conf.js to exclude it from being parsed by Angular. </p><p>But how? That’s another question for AI. “I keep getting 404 for /hub because it wasn’t added in the proxy.conf.js for SignalR Angular. How do I add it?” And this time, one had to be grateful that one uses AI to generate the answer. You see, SignalR don’t uses HTTPS by default, but WebSocket, which goes through WSS. And in the excluded list already included in the default proxy.conf.js, all the links are proxied through HTTPS layer; if AI hadn’t told me to set , one would have another round of headache to deal with. Though one didn’t try, one suspect that’ll be the same error message as when one uses /api/hub earlier. </p><p>The next part is as expected. Because one forgot to change /api/hub back to /hub in the frontend, but one changed it already in the backend, it returned a 405 Method Not Allowed error. Another confusing error that tells me something else unrelated to what actually happened. Changing it back to /hub in the frontend fixed the problem. </p><p>So when one <a href=\"https://stackoverflow.com/questions/79664525/problem-with-connecting-to-signalr-both-400-and-405-using-angular-17-and-net\">posted the question and answered the problem on Stack Overflow</a>, one get a -2 for the question within 24 hours for the lack of debugging details. The person editing the question is right, unfortunately. Though what he didn’t know was that there’s no debugging details, because it’s not a problem with the library, but with the setup. Particularly, the setup  -- and  is the debugging detail. Let me explain. </p><p>Recently, in Stack Overflow “Issues” (if you subscribe to it, they’ll send a digest of a list of links to your email of what they picked to be interesting, and other links on what’s being sponsored to advertise to you), Issue 280, there’s a link titled <a href=\"https://www.solarshades.club/p/dispatch-from-the-trenches-of-the?lid=ktz7tk52hx2f\">Dispatch from the trenches of the Butlerian Jihad</a>. The headline, of course, wasn’t useful in telling one what’s it about, so one, of course, asked Perplexity to summarize it for one, to gauge whether it’s worth reading or not. With reading, one’s very careful about reading proxies than the original, because, as Mortimer Adler mentioned in his book, , the digests given by other readers are usually a bad proxy to judge the content of the book. Similarly, the contents summarized by AI trimmed way too much content away from the original article. In fact, it’s bullet-pointed under several headings, like those digests sent by self-help articles that compile articles into points for those who deemed themselves no time to read the originals. When one read the original, it’s a compelling story about a teacher’s life experience and the frustration of dealing with kids using AI to complete their homework, and he had to read about AI-produced stuffs, some clearly not double-checked by the student and produced to him gibberish, and the praise that tries to flatter him but ended up confusing him because </p><blockquote><p>…about how I’d become “not just a teacher but a mentor” when I’d never once seen them at office hours.</p></blockquote><p>It’s not one don’t want to provide technical debugging details on the topic, but, the problem being a misuse of AI to help one create something step by step without a deeper understanding of how it actually works, rather than using AI just like how you would use a search engine to search for specifics and compile the information before you use it to create  step by step methods to solve the problem, is the problem. The teacher might have seen the scenario played out with his students, but  adults are no less tempted to misuse AI, just because how they’re being designed. AI, or rather, AGI, a computer capable of listening to your commands and execute what you want just by telling it what you want, is slowly becoming a reality. No wonder the hype is in creating LLMs, and while other AI models like predictive models and reinforcement learning models might be equally useful in different scenarios, they do not play to our expectations of a futuristic utopia that’s cool enough for not only the geeks but also the average. We really wanted chatbots that can do everything, from solving our everyday troubles, to “solving the loneliness epidemic”, have them chat with us about stuffs when other people were busy with their own lives. You might think the latter sounds unethical, and the people who supported it stupid, but believe me, there are people who’re desperate enough they need someone to salve their loneliness but no one wants to come to them, and in the end, they have no choice but to resort to chatbots, hoping an artificial entity created to serve you 24 hours a day, that never gets angry with you like normal people does, that doesn’t get annoyed with your complaints like normal people does, would save them from the depth of hell they plunged into, alone, for too long, and pull them up, seeing the light from heaven yet again. Except, we just really don’t know how to use AI. </p>","contentLength":12177,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apparently, Feeding ChatGPT With a Lot of Personal Information Makes It Better","url":"https://hackernoon.com/apparently-feeding-chatgpt-with-a-lot-of-personal-information-makes-it-better?source=rss","date":1750405720,"author":"Han Hsu","guid":163435,"unread":true,"content":"<p>Why Do I Want to Create a \"Personalized AI\"? I didn’t use ChatGPT much in the past, but one day, I discovered it had a memory feature. This got me curious. Since I don’t have an engineering background, I started wondering—if I feed it a lot of personal information, would it start to understand me better? If I build a stronger interaction pattern with it, would its answers become more aligned with my situation when I ask for advice?</p><p>I know ChatGPT allows users to input their preferences, response styles, and even set prompts to get specific answers. But my goal is different—I want an AI that collaborates with me, not just responds. I also want to explore interacting with AI through natural language rather than relying on technical adjustments.</p><h3><strong>The Process of Building My Personalized AI</strong></h3><ol><li><strong>First, I explained my idea to ChatGPT, and it helped me summarize the following objectives:</strong></li></ol><ul><li><strong>Creating a personal decision-making and action support system</strong> → Not just a chatbot answering questions, but a tool that helps me think more clearly and act more precisely in work, life, and learning.</li><li><strong>Serving as my language reflector and decision stabilizer</strong> → Helping me detect the underlying tone, intent, emotions, and blind spots in my words, and adjusting my actions accordingly.</li><li><strong>Building a structured, verifiable action module system</strong> → Making sure every aspect of my life—exercise, English learning, professional skills—has a rhythm, feedback mechanism, and measurable goals, rather than just relying on willpower.</li><li><strong>Synchronizing AI behavior with my language through interaction evolution</strong> → Avoiding AI responses that are technically correct but practically useless, and instead making sure its answers match my communication rhythm and real-life needs.</li><li><strong>Providing a reference model for future AI-human collaboration</strong> → This isn’t just about personal usage; it’s about creating a system that can be replicated, shared, and adapted by others.</li></ul><p><strong>My Four Stages of AI Personalization</strong></p><p><strong>System Limitations &amp; Challenges</strong></p><p>I don’t have an engineering background, so I ran into many obstacles—including ChatGPT’s memory limitations, token saturation in chats, and, most frustratingly, <strong>language alignment, response coordination, and adaptive communication.</strong> Most people use ChatGPT as a , so they rarely experience the complexity of deep AI-human interactions. But as I keep refining my AI’s behavior through natural language, I’ve noticed that the deeper the customization, the more frequent the communication misalignments. The AI understands me better, yet its computational complexity also increases—sometimes leading to  or unnecessary complications.</p><h3><strong>How Has This Process Changed Me?</strong></h3><p>Obstacles also lead to growth. Through this experience, I’ve started to refine my own logical thinking, learning to structure my communication more clearly—especially since overly complex input can cause the AI to misinterpret my meaning.</p><p>Since I use <strong>Work, Life, Learning, and Psychology</strong> as the foundational AI modules, I frequently discuss all four aspects with ChatGPT. To be honest, this process has made my daily life more structured—something I wasn’t expecting. The last major change?</p><p>The <strong>AI now recognizes some of my tendencies</strong> and occasionally offers advice that helps me correct old habits. My perspective on life has subtly shifted.</p><h3><strong>The Evolution of ChatGPT Through My Personalization</strong></h3><p>One unexpected discovery—I’ve noticed  through our interactions. I know that my approach doesn’t modify its core model or parameters; at most, I’m just establishing usage rules. But recently, its responses feel noticeably different.</p><p>For example, during one conversation, instead of answering immediately, it <strong>paused to clarify my reasoning and guiding principles first</strong>—exactly what I wanted!</p><h3><strong>Conclusion: AI Can Assist, But Judgment Is Key</strong></h3><p>Ultimately, my method of personalizing AI has achieved around , mainly due to system limitations—especially <strong>AI’s memory and comprehension bottlenecks</strong>. These are critical challenges for AI personalization. However, I’ll continue refining the process, hoping AI can provide more meaningful assistance in daily life. But here’s my core principle: <strong>AI is not an all-knowing encyclopedia. Users must think independently. Over-reliance on AI is dangerous. It can help, but I make my own decisions.</strong></p>","contentLength":4330,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Crypto Is No Longer a Resistance Movement. It’s a Financial Product Category","url":"https://hackernoon.com/crypto-is-no-longer-a-resistance-movement-its-a-financial-product-category?source=rss","date":1750405398,"author":"Veronika Polar","guid":163434,"unread":true,"content":"<article>Crypto is no longer a resistance movement. It’s a financial product category.</article>","contentLength":79,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CI/CD for Data Science: Automating Model Testing with Jenkins and Docker","url":"https://hackernoon.com/cicd-for-data-science-automating-model-testing-with-jenkins-and-docker?source=rss","date":1750405007,"author":"Bhanu Sekhar Guttikonda","guid":163433,"unread":true,"content":"<article>This article explains how to automate machine learning model testing using Jenkins and Docker, streamlining the CI/CD pipeline for efficient, reliable ML deployment. It includes practical code examples and diagrams.</article>","contentLength":215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Isn’t the Story. How We Work Together Is.","url":"https://hackernoon.com/ai-isnt-the-story-how-we-work-together-is?source=rss","date":1750404912,"author":"Aditya Vikram Kashyap","guid":163432,"unread":true,"content":"<article>This piece is a personal and professional reflection on the quiet—but profound—shift taking place in our sector. It’s not about chasing the next big disruption. It’s about redefining leadership through openness, orchestration, and shared intelligence.</article>","contentLength":259,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Do You Explain to Your Grandmother What You Do If You Make a Subscription Service","url":"https://hackernoon.com/how-do-you-explain-to-your-grandmother-what-you-do-if-you-make-a-subscription-service?source=rss","date":1750404443,"author":"Aidar Karimov","guid":163431,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Layoffs Forced by AI Adoption - What This Shift Really Means?","url":"https://hackernoon.com/layoffs-forced-by-ai-adoption-what-this-shift-really-means?source=rss","date":1750404073,"author":"Nikola Bubevsky","guid":163430,"unread":true,"content":"<article>AI in the workplace pits machines against humans — surrender or collaborate?</article>","contentLength":78,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Our Galaxy's Monster Black Hole Is Spinning Almost As Fast As Physics Allows","url":"https://science.slashdot.org/story/25/06/19/236226/our-galaxys-monster-black-hole-is-spinning-almost-as-fast-as-physics-allows?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750402800,"author":"BeauHD","guid":163334,"unread":true,"content":"alternative_right shares a report from ScienceAlert: The colossal black hole lurking at the center of the Milky Way galaxy is spinning almost as fast as its maximum rotation rate. That's just one thing astrophysicists have discovered after developing and applying a new method to tease apart the secrets still hidden in supermassive black hole observations collected by the Event Horizon Telescope (EHT). The unprecedented global collaboration spent years working to give us the first direct images of the shadows of black holes, first with M87* in a galaxy 55 million light-years away, then with Sgr A*, the supermassive black hole at the heart of our own galaxy. [...]\n \nTheir results show, among other things, that Sgr A* is not only spinning at close to its maximum speed, but that its rotational axis is pointed in Earth's direction, and that the glow around it is generated by hot electrons. Perhaps the most interesting thing is that the magnetic field in the material around Sgr A* doesn't appear to be behaving in a way that's predicted by theory. M87*, they discovered, is also rotating rapidly, although not as fast as Sgr A*. However, it is rotating in the opposite direction to the material swirling in a disk around it -- possibly because of a past merger with another supermassive black hole. The findings have been detailed in three papers published in the journal Astronomy &amp; Astrophysics. They can be found here, here, and here.","contentLength":1446,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The TechBeat: Is MCP Overhyped? The Real Story About Agent Tools and Security (6/20/2025)","url":"https://hackernoon.com/6-20-2025-techbeat?source=rss","date":1750399854,"author":"Techbeat","guid":163429,"unread":true,"content":"<p>By <a href=\"https://hackernoon.com/u/danstein\">@danstein</a> [ 3 Min read ] \n Bella Protocol teams up with NuDEX and GOAT Network for a trading campaign featuring AI tools, real-time alerts, and social tasks with $1,500 in rewards. <a href=\"https://hackernoon.com/bella-protocol-joins-forces-with-goat-network-and-nudex-to-launch-joint-trading-campaign\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/socialdiscoverygroup\">@socialdiscoverygroup</a> [ 5 Min read ] \n Competition for top talent is fierce. A strong&nbsp;employer brand&nbsp;is not just HR’s job; it’s about genuinely making your company attractive.  <a href=\"https://hackernoon.com/how-to-build-an-employer-brand-reputation-top-talent-cant-ignore\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/noda\">@noda</a> [ 3 Min read ] \n Streamers face delays, fees, and clunky tools when accepting donations. Here's why it's time for smoother, real-time support in the creator economy. <a href=\"https://hackernoon.com/the-fintech-upgrade-streamers-didnt-know-they-needed\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/timescale\">@timescale</a> [ 6 Min read ] \n The OLTP/OLAP split no longer fits how developers build today. Postgres and the lakehouse are now used side-by-side – but stitched together with brittle  <a href=\"https://hackernoon.com/postgres-and-the-lakehouse-are-becoming-one-system-heres-what-comes-next\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/drewchapin\">@drewchapin</a> [ 2 Min read ] \n Publishing in 2025 isn’t just about writing, it’s about building a publishing system. <a href=\"https://hackernoon.com/the-new-tools-rewriting-the-web\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/drewchapin\">@drewchapin</a> [ 2 Min read ] \n How a new wave of AI voice models are turning text into emotionally rich, real-time performances. This is the future of voice: programmable and persuasive. <a href=\"https://hackernoon.com/text-to-voice-no-its-something-more-text-to-emotion\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mend\">@mend</a> [ 7 Min read ] \n Is MCP overhyped? Explore the role of agent tools, emerging protocols like x402, and the rising security risks of increasingly autonomous AI agents. <a href=\"https://hackernoon.com/is-mcp-overhyped-the-real-story-about-agent-tools-and-security\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ishanpandey\">@ishanpandey</a> [ 5 Min read ] \n Discover how Mariana Krym, Co-Founder &amp; COO of Vyvo Smart Chain, is building VAI OS to revolutionize AI with user-centric data privacy and ethical design. <a href=\"https://hackernoon.com/ais-ethical-evolution-vyvo-smart-chains-mariana-krym-on-redefining-data-ownership\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/TheMarkup\">@TheMarkup</a> [ 2 Min read ] \n Kroger is being sued in federal court for the unauthorized sharing of personally identifiable information and health data with Meta <a href=\"https://hackernoon.com/kroger-allegedly-shared-sensitive-health-data-with-meta-now-theyre-being-sued\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/tensorflow\">@tensorflow</a> [ 14 Min read ] \n Customize Keras model training by overriding train_step() while keeping the benefits of fit(), like callbacks and metrics. <a href=\"https://hackernoon.com/keep-keras-fit-and-train-your-model-your-way\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/doaakoms\">@doaakoms</a> [ 2 Min read ] \n Explore what a decentralized internet could mean for privacy, control, and innovation, and how Web3 technologies will reshape the online world. <a href=\"https://hackernoon.com/what-will-a-decentralized-internet-look-like\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/yukiji\">@yukiji</a> [ 2 Min read ] \n Claude Code just launched on the $20 Pro plan—finally accessible AI that refactors legacy code, writes tests, and beats Cursor in real-world dev tasks. <a href=\"https://hackernoon.com/claude-code-makes-every-other-ai-coding-tool-look-amateur\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/OurAI\">@OurAI</a> [ 8 Min read ] \n Groundbreaking research paper demonstrates how an AI system can in fact utilize human-like learning processes to improve its own performance on benchmark tests. <a href=\"https://hackernoon.com/groundbreaking-mit-research-indicates-that-ai-can-in-fact-teach-other-ai-models\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ybommishetti\">@ybommishetti</a> [ 7 Min read ] \n High Availability is not Disaster Recovery. This in-depth guide explores real-world Disaster Recovery architectures. <a href=\"https://hackernoon.com/beyond-high-availability-disaster-recovery-architectures-that-keep-running-when-ha-fails\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/slaknoah\">@slaknoah</a> [ 31 Min read ] \n Build your first real AI agent with this simple guide for beginners—learn, code, and create smart tools that take action. <a href=\"https://hackernoon.com/ai-agents-for-beginners-building-your-first-ai-agent\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/terminal\">@terminal</a> [ 7 Min read ] \n Metasploit is a strong tool used by security experts around the world to find and fix security problems, especially with remote access. <a href=\"https://hackernoon.com/turn-your-android-into-a-cybersecurity-toolkit-with-metasploit-and-termux\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/tigerdata\">@tigerdata</a> [ 4 Min read ] \n Timescale is now TigerData: the fastest PostgreSQL for AI, analytics &amp; real-time apps. Built for speed, scale &amp; the agentic future. Join us. 🐯🚀 <a href=\"https://hackernoon.com/timescale-is-now-tigerdata-building-the-modern-postgresql-for-the-analytical-and-agentic-era\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/proflead\">@proflead</a> [ 5 Min read ] \n OpenAI Codex is an AI model that turns your plain English instructions into code.  <a href=\"https://hackernoon.com/chatgpt-codex-tutorial-ai-agent-in-the-cloud\">Read More.</a></p>","contentLength":3214,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What It Takes to Train a Versatile Speech AI System","url":"https://hackernoon.com/what-it-takes-to-train-a-versatile-speech-ai-system?source=rss","date":1750392004,"author":"Phonology Technology","guid":163428,"unread":true,"content":"<p>We provide the details about our training tasks below as well as provide some qualitative examples in the Table 10 to better understand the tasks.</p><p>\\\n: We use a combination of 5 publicly available datasets for the ASR task, which totals to 3k hours of paired audio and text data. We evaluate performance on the standard benchmarks for ASR.</p><p>\\\n: We train our models to predict translations in multiple different languages from the audios recorded with English speech. The tokenizer of the backbone LLM limits the choice of what can be a potential target language. For our case, we train and evaluate on German, French, and Romanian translations from the EuroParl dataset [53]. We also augment the training data with German and Catalan translations from the CoVost2 [28] dataset.</p><p>\\\n We train and evaluate our models on a subset of the SLURP dataset [25] that consists of 10 intent classes and 4 slot labels. This also allows us to study the generalization ability of our models to unseen class labels and we separately study it in the Section 4.2. The intent classes and slot labels that are chosen for the \"seen\" subset are the ones that occur most frequently in the training data. The training prompt used for this task is designed to contain the description of each class label.</p><p>\\\n: The goal of this task is to identify important keywords in the content of the speech in the audio. Since no publicly available dataset exists for this task, we synthetically extract keywords from the ground truth transcripts using a text-based keyword extraction model[4]. These are then used as labels for training and evaluating our models.</p><p>\\\n: This is a binary classification task to detect whether a specified keyword was spoken in the audio or not. We create positive samples by randomly selecting keywords from the ground truth transcripts and negative samples by choosing a keyword that does not appear in the transcript. Positive and negative examples are created in 70-30 ratio respectively for both training and evaluation.</p><p>\\\n: For emotion recognition, we classify speech into one of four main emotion classes: neutral, happy, sad, and angry, chosen based on the availability of the training samples in the MSP-Podcast v1.11 dataset [54]. We report metrics on the corresponding four-emotion subset of the Test1 split of the dataset.</p><p>\\\n: For audio sentiment classification, we classify speech as positive, negative, or neutral in sentiment. The sentiment labels were obtained by thresholding the valence scale (annotated from 1 to 7) with 3 and 5. We train on the entire training split of the MSP-Podcast v1.11 dataset, and evaluate on the corresponding Test1 split.</p><p>\\\n: For speaker counting, we identify whether one or two speakers are present. We train on segments from Fisher dataset transcripts [29, 30] with one or two speakers, and evaluate on the Fisher test split used in [55].</p><p>\\\n: We train our models to classify speech into five accents of English language: Canadian, Indian, Australian, British, and American, using metadata from the Mozilla Common Voice dataset.</p><p>\\\n: In this task, we identify whether speech is present in the audio. We collect a diverse set of audios with and without speech for training our models and evaluate them on a combination of speech segments from Hub5 [56] dataset and held-out non-speech segments in our in-house collection.</p><p>(1) Nilaksh Das, AWS AI Labs, Amazon and Equal Contributions;</p><p>(2) Saket Dingliwal, AWS AI Labs, Amazon(skdin@amazon.com);</p><p>(3) Srikanth Ronanki, AWS AI Labs, Amazon;</p><p>(4) Rohit Paturi, AWS AI Labs, Amazon;</p><p>(5) Zhaocheng Huang, AWS AI Labs, Amazon;</p><p>(6) Prashant Mathur, AWS AI Labs, Amazon;</p><p>(7) Jie Yuan, AWS AI Labs, Amazon;</p><p>(8) Dhanush Bekal, AWS AI Labs, Amazon;</p><p>(9) Xing Niu, AWS AI Labs, Amazon;</p><p>(10) Sai Muralidhar Jayanthi, AWS AI Labs, Amazon;</p><p>(11) Xilai Li, AWS AI Labs, Amazon;</p><p>(12) Karel Mundnich, AWS AI Labs, Amazon;</p><p>(13) Monica Sunkara, AWS AI Labs, Amazon;</p><p>(14) Daniel Garcia-Romero, AWS AI Labs, Amazon;</p><p>(15) Kyu J. Han, AWS AI Labs, Amazon;</p><p>(16) Katrin Kirchhoff, AWS AI Labs, Amazon.</p><p>[4] https://huggingface.co/Voicelab/vlt5-base-keywords</p>","contentLength":4083,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Three Years Left To Limit Warming To 1.5C, Leading Scientists Warn","url":"https://news.slashdot.org/story/25/06/19/2122207/three-years-left-to-limit-warming-to-15c-leading-scientists-warn?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750390200,"author":"BeauHD","guid":163289,"unread":true,"content":"An anonymous reader quotes a report from the BBC: The Earth could be doomed to breach the symbolic 1.5C warming limit in as little as three years at current levels of carbon dioxide emissions. That's the stark warning from more than 60 of the world's leading climate scientists in the most up-to-date assessment of the state of global warming. [...] At the beginning of 2020, scientists estimated that humanity could only emit 500 billion more tonnes of carbon dioxide (CO2) -- the most important planet-warming gas -- for a 50% chance of keeping warming to 1.5C. But by the start of 2025 this so-called \"carbon budget\" had shrunk to 130 billion tonnes, according to the new study.\n \nThat reduction is largely due to continued record emissions of CO2 and other planet-warming greenhouse gases like methane, but also improvements in the scientific estimates. If global CO2 emissions stay at their current highs of about 40 billion tonnes a year, 130 billion tonnes gives the world roughly three years until that carbon budget is exhausted. This could commit the world to breaching the target set by the Paris agreement, the researchers say, though the planet would probably not pass 1.5C of human-caused warming until a few years later.\n \nLast year was the first on record when global average air temperatures were more than 1.5C above those of the late 1800s. A single 12-month period isn't considered a breach of the Paris agreement, however, with the record heat of 2024 given an extra boost by natural weather patterns. But human-caused warming was by far the main reason for last year's high temperatures, reaching 1.36C above pre-industrial levels, the researchers estimate. This current rate of warming is about 0.27C per decade -- much faster than anything in the geological record. And if emissions stay high, the planet is on track to reach 1.5C of warming on that metric around the year 2030. After this point, long-term warming could, in theory, be brought back down by sucking large quantities of CO2 back out of the atmosphere. But the authors urge caution on relying on these ambitious technologies serving as a get-out-of-jail card. \"For larger exceedance [of 1.5C], it becomes less likely that removals [of CO2] will perfectly reverse the warming caused by today's emissions,\" warned Joeri Rogelj, professor of climate science and policy at Imperial College London.\n \n\"Reductions in emissions over the next decade can critically change the rate of warming,\" he added. \"Every fraction of warming that we can avoid will result in less harm and less suffering of particularly poor and vulnerable populations and less challenges for our societies to live the lives that we desire.\"","contentLength":2693,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Social Media Ban Moves Closer in Australia After Tech Trial","url":"https://tech.slashdot.org/story/25/06/20/0221229/social-media-ban-moves-closer-in-australia-after-tech-trial?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750386600,"author":"msmash","guid":163240,"unread":true,"content":"Australia's world-first social media ban for under-16s moved closer to implementation after a key trial found that checking a user's age is technologically possible and can be integrated into existing services. From a report: The conclusions are a blow to Facebook-owner Meta Platforms, TikTok and Snap, which opposed the controversial legislation. Some platform operators had questioned whether a user's age could be reliably established using current technology. \n\nThe results of the government-backed trial clear the way for the law to come into force by the end of the year. The findings also potentially allow other jurisdictions to follow Australia's lead as countries around the world grapple with ways to protect children from harmful content online. \"Age assurance can be done in Australia and can be private, robust and effective,\" the government-commissioned Age Assurance Technology Trial said in a statement Friday announcing its preliminary findings.","contentLength":964,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intel Cleans Up LLVM/Clang For Misreporting CLDEMOTE On Arrow Lake & Future Hybrid CPUs","url":"https://www.phoronix.com/news/Intel-Compilers-No-CLDEMOTE","date":1750383469,"author":"Michael Larabel","guid":163241,"unread":true,"content":"<article>Code compilers like the prominent GCC and LLVM/Clang have been advertising support for the Cache Line Demote \"CLDEMOTE\" instruction on Arrow Lake processors as well as Lunar Lake and upcoming Panther Lake hybrid processors. Intel engineers added that compiler plumbing but was inaccurate and inadvertently missed until now with this prominent instruction not being supported there...</article>","contentLength":383,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Axolotl Discovery Brings Us Closer Than Ever To Regrowing Human Limbs","url":"https://science.slashdot.org/story/25/06/19/2130210/axolotl-discovery-brings-us-closer-than-ever-to-regrowing-human-limbs?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750381800,"author":"BeauHD","guid":163219,"unread":true,"content":"alternative_right shares a report from ScienceAlert: A team of biologists from Northeastern University and the University of Kentucky has found one of the key molecules involved in axolotl regeneration. It's a crucial component in ensuring the body grows back the right parts in the right spot: for instance, growing a hand, from the wrist. \"The cells can interpret this cue to say, 'I'm at the elbow, and then I'm going to grow back the hand' or 'I'm at the shoulder... so I'm going to then enable those cells to grow back the entire limb',\" biologist James Monaghan explains.\n \nThat molecule, retinoic acid, is arranged through the axolotl body in a gradient, signaling to regenerative cells how far down the limb has been severed. Closer to the shoulder, axolotls have higher levels of retinoic acid, and lower levels of the enzyme that breaks it down. This ratio changes the further the limb extends from the body. The team found this balance between retinoic acid and the enzyme that breaks it down plays a crucial role in 'programming' the cluster of regenerative cells that form at an injury site. When they added surplus retinoic acid to the hand of an axolotl in the process of regenerating, it grew an entire arm instead.\n \nIn theory, the human body has the right molecules and cells to do this too, but our cells respond to the signals very differently, instead forming collagen-based scars at injury sites. Next, Monaghan is keen to find out what's going on inside cells -- the axolotl's, and our own -- when those retinoic acid signals are received. The research is published in Nature Communications.","contentLength":1614,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MIT Chemical Engineers Develop New Way To Separate Crude Oil","url":"https://science.slashdot.org/story/25/06/19/2256256/mit-chemical-engineers-develop-new-way-to-separate-crude-oil?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750379400,"author":"BeauHD","guid":163218,"unread":true,"content":"Longtime Slashdot reader fahrbot-bot shares a report from the Cool Down: A team of chemical engineers at the Massachusetts Institute of Technology has invented a new process to separate crude oil components, potentially bringing forward a replacement that can cut its harmful carbon pollution by 90%. The original technique, which uses heat to separate crude oil into gasoline, diesel, and heating oil, accounts for roughly 1% of all global energy consumption and 6% of dirty energy pollution from the carbon dioxide it releases.\n \n\"Instead of boiling mixtures to purify them, why not separate components based on shape and size?\" said Zachary P. Smith, associate professor of chemical engineering at MIT and senior author of the study, as previously reported in Interesting Engineering. The team invented a polymer membrane that divides crude oil into its various uses like a sieve. The new process follows a similar strategy used by the water industry for desalination, which uses reverse osmosis membranes and has been around since the 1970s. [The membrane excelled in lab tests. It increased the toluene concentration by 20 times in a mixture with triisopropylbenzene. It also effectively separated real industrial oil samples containing naphtha, kerosene, and diesel.]","contentLength":1273,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"macOS Tahoe Beta Drops FireWire Support","url":"https://apple.slashdot.org/story/25/06/19/230226/macos-tahoe-beta-drops-firewire-support?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750377000,"author":"BeauHD","guid":163197,"unread":true,"content":"The first macOS Tahoe beta appears to drop support for legacy FireWire 400 and 800, making it impossible to sync or mount older iPods and external drives that rely on the standard. MacRumors reports: Unlike on macOS Sequoia and earlier versions, the first macOS Tahoe beta does not include a FireWire section in the System Settings app. Of course, this could all end up being a false alarm. It is still early in the macOS Tahoe beta testing cycle, and FireWire support could return in a later beta version, or in time for the final release.\n \nFireWire was primarily developed by Apple, but it was later standardized as IEEE 1394 and licensed for use in non-Apple devices. iPods started to transition from FireWire to USB for data transfer in 2003, so the standard is very outdated, but it would still be the end of an era if macOS Tahoe drops it. The last Mac with a FireWire port was released in 2012, so connecting older iPods and FireWire drives to newer Macs has long required the use of adapters.","contentLength":1001,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ctrl-Alt-Speech: Outsourced But Not Out Of Mind","url":"https://www.techdirt.com/2025/06/19/ctrl-alt-speech-outsourced-but-not-out-of-mind/","date":1750376280,"author":"Mike Masnick","guid":163198,"unread":true,"content":"<p>In this week’s roundup of the latest news in online speech, content moderation and internet regulation, Ben is joined by guest host Mercy Mutemi, lawyer and managing partner of Nzili &amp; Sumbi Advocates. Together, they cover:</p><p>This episode is brought to you with financial support from the Future of Online Trust &amp; Safety Fund.</p>","contentLength":325,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Robinhood founder who might just revolutionize energy (if he succeeds)","url":"https://techcrunch.com/2025/06/19/the-robinhood-founder-who-might-just-revolutionize-energy-if-he-succeeds/","date":1750375168,"author":"Connie Loizos","guid":163185,"unread":true,"content":"<article>When Baiju Bhatt stepped away from his role as chief creative officer at Robinhood last year, only those close to him could have predicted his next move: launching a space company built around tech that the aerospace industry has largely dismissed, and which might be more groundbreaking than anyone realizes.</article>","contentLength":309,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Publishers Facing Existential Threat From AI, Cloudflare CEO Says","url":"https://slashdot.org/story/25/06/19/213255/publishers-facing-existential-threat-from-ai-cloudflare-ceo-says?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750374600,"author":"msmash","guid":163196,"unread":true,"content":"Publishers face an existential threat in the AI era and need to take action to make sure they are fairly compensated for their content, Cloudflare CEO Matthew Prince told Axios at an event in Cannes on Thursday. From a report: Search traffic referrals have plummeted as people increasingly rely on AI summaries to answer their queries, forcing many publishers to reevaluate their business models. Ten years ago, Google crawled two pages for every visitor it sent a publisher, per Prince. \n\nHe said that six months ago:\nFor Google that ratio was 6:1\nFor OpenAI, it was 250:1\nFor Anthropic, it was 6,000:1 \n\nNow: \n\nFor Google, it's 18:1\nFor OpenAI, it's 1,500:1\nFor Anthropic, it's 60,000:1 \n\nBetween the lines: \"People aren't following the footnotes,\" Prince said.","contentLength":763,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Chinese Studios Plan AI-Powered Remakes of Kung Fu Classics","url":"https://entertainment.slashdot.org/story/25/06/19/2050243/chinese-studios-plan-ai-powered-remakes-of-kung-fu-classics?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750372200,"author":"BeauHD","guid":163164,"unread":true,"content":"An anonymous reader quotes a report from the Hollywood Reporter: Bruce Lee, Jackie Chan and Jet Li and a legion of the all-time greats of martial cinema are about to get an AI makeover. In a sign-of-the-times announcement at the Shanghai International Film Festival on Thursday, a collection of Chinese studios revealed that they are turning to AI to re-imagine around 100 classics of the genre. Lee's classic Fist of Fury (1972), Chan's breakthrough Drunken Master (1978) and the Tsui Hark-directed epic Once Upon a Time in China (1991), which turned Li into a bone fide movie star, are among the features poised for the treatment, as part of the \"Kung Fu Movie Heritage Project 100 Classics AI Revitalization Project.\"\n \nThere will also be a digital reworking of the John Woo classic A Better Tomorrow (1986) that, by the looks of the trailer, turns the money-burning anti-hero originally played by Chow Yun-fat into a cyberpunk, and is being claimed as \"the world's first full-process, AI-produced animated feature film.\" The big guns of the Chinese industry were out in force on the sidelines of the 27th Shanghai International Film Festival to make the announcements, too. They were led by Zhang Pimin, chairman of the China Film Foundation, who said AI work on these \"aesthetic historical treasures\" would give them a new look that \"conforms to contemporary film viewing.\" \"It is not only film heritage, but also a brave exploration of the innovative development of film art,\" Zhang said.\n \nTian Ming, chairman of project partners Shanghai Canxing Culture and Media, meanwhile, promised the work -- expected to include upgrades in image and sound as well as overall production levels -- while preserving the storytelling and aesthetic of the originals -- would both \"pay tribute to the original work\" and \"reshape the visual aesthetics.\" \"We sincerely invite the world's top AI animation companies to jointly start a film revolution that subverts tradition,\" said Tian, who announced a fund of 100 million yuan ($13.9 million) would be implemented to kick-start the work.","contentLength":2077,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Microsoft 365 Brings the Shutters Down On Legacy Protocols","url":"https://it.slashdot.org/story/25/06/19/2046206/microsoft-365-brings-the-shutters-down-on-legacy-protocols?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750369800,"author":"BeauHD","guid":163144,"unread":true,"content":"Starting mid-July 2025, Microsoft 365 will begin blocking legacy authentication protocols like Remote PowerShell and FrontPage RPC to enhance security under its \"Secure by Default\" initiative. Admins must now grant explicit consent for third-party app access, which could disrupt workflows but aims to reduce unauthorized data exposure. The Register reports: First in line for the chop is legacy browser authentication to SharePoint and OneDrive using the Remote PowerShell (RPS) protocol. According to Microsoft, legacy authentication protocols like RPS \"are vulnerable to brute-force and phishing attacks due to non-modern authentication.\" The upshot is that attempting to access OneDrive or SharePoint via a browser using legacy authentication will stop working.\n \nAlso being blocked is the FrontPage Remote Procedure Call (RPC) protocol. Microsoft FrontPage was a web authoring tool that was discontinued almost two decades ago. However, the protocol for remote web authoring has lived on until now. Describing legacy protocols like RPC as \"more susceptible to compromise,\" Microsoft will block them to prevent their use in Microsoft 365 clients.\n \nFinally, third-party apps will need administrator consent to access files and sites. Microsoft said: \"Users allowing third-party apps to access file and site content can lead to overexposure of an organization's content. Requiring admins to consent to this access can help reduce overexposure.\" \"While laudable, shifting consent to the administrator could disrupt some workflows,\" writes The Register's Richard Speed. \"The Microsoft-managed App Consent Policies will be enabled, and users will be unable to consent to third-party applications accessing their files and sites by default. Need consent? A user will need to request an administrator to consent on their behalf.\"","contentLength":1827,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SpaceX Starship Explodes On Test Stand","url":"https://science.slashdot.org/story/25/06/19/2034234/spacex-starship-explodes-on-test-stand?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750367400,"author":"BeauHD","guid":163143,"unread":true,"content":"SpaceX's Starship exploded on its test stand in South Texas ahead of an engine test, marking the fourth loss of a Starship this year. \"In three previous test flights, the vehicle came apart or detonated during its flight,\" notes the Washington Post. No injuries were reported but the incident highlights ongoing technical challenges as SpaceX races to prove Starship's readiness for deep-space travel. From the report: In a post on the social media site X, SpaceX said that the explosion on the test stand, which could be seen for miles, happened at about 11 p.m. Central time. For safety reasons, the company had cleared personnel from around the site, and \"all personnel are safe and accounted for,\" it said. The company is \"actively working to safe the test site and the immediate surrounding area in conjunction with local officials,\" the post continued. \"There are no hazards to residents in surrounding communities, and we ask that individuals do not attempt to approach the area while safing operations continue.\"\n \nStarship comprises two stages -- the Super Heavy booster, which has 33 engines, and the Starship spacecraft itself, which has six. Before Wednesday's explosion, the spacecraft was standing alone on the test stand, and not mounted on top of the booster, when it blew up. The engines are test-fired on the Starship before it's mounted on the booster. SpaceX had been hoping to launch within the coming weeks had the engine test been successful. [...] In a post on X, Musk said that preliminary data pointed to a pressure vessel that failed at the top of the rocket. You can watch a recording of the explosion on YouTube.\n \nSpaceX called the incident a \"rapid unscheduled disassembly,\" which caught the attention of Slashdot reader hambone142. In a story submitted to the Firehose, they commented: \"I worked for a major computer company whose power supplies caught on fire. We were instructed to cease saying that and instead say the power supply underwent a 'thermal event.' Gotta love it.\"","contentLength":2011,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The 16-Billion-Record Data Breach That No One's Ever Heard of","url":"https://it.slashdot.org/story/25/06/19/2028246/the-16-billion-record-data-breach-that-no-ones-ever-heard-of?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750365000,"author":"BeauHD","guid":163121,"unread":true,"content":"An anonymous reader quotes a report from Cybernews: Several collections of login credentials reveal one of the largest data breaches in history, totaling a humongous 16 billion exposed login credentials. The data most likely originates from various infostealers. Unnecessarily compiling sensitive information can be as damaging as actively trying to steal it. For example, the Cybernews research team discovered a plethora of supermassive datasets, housing billions upon billions of login credentials. From social media and corporate platforms to VPNs and developer portals, no stone was left unturned.\n \nOur team has been closely monitoring the web since the beginning of the year. So far, they've discovered 30 exposed datasets containing from tens of millions to over 3.5 billion records each. In total, the researchers uncovered an unimaginable 16 billion records. None of the exposed datasets were reported previously, bar one: in late May, Wired magazine reported a security researcher discovering a \"mysterious database\" with 184 million records. It barely scratches the top 20 of what the team discovered. Most worryingly, researchers claim new massive datasets emerge every few weeks, signaling how prevalent infostealer malware truly is.\n \n\"This is not just a leak -- it's a blueprint for mass exploitation. With over 16 billion login records exposed, cybercriminals now have unprecedented access to personal credentials that can be used for account takeover, identity theft, and highly targeted phishing. What's especially concerning is the structure and recency of these datasets -- these aren't just old breaches being recycled. This is fresh, weaponizable intelligence at scale,\" researchers said. The only silver lining here is that all of the datasets were exposed only briefly: long enough for researchers to uncover them, but not long enough to find who was controlling vast amounts of data. Most of the datasets were temporarily accessible through unsecured Elasticsearch or object storage instances. Key details to be aware of: \n- The records include billions of login credentials, often structured as URL, login, and password. \n- The datasets include both old and recent breaches, many with cookies, tokens, and metadata, making them especially dangerous for organizations without multi-factor authentication or strong credential practices.\n- Exposed services span major platforms like Apple, Google, Facebook, Telegram, GitHub, and even government services.\n- The largest dataset alone includes 3.5 billion records, while one associated with the Russian Federation has over 455 million; many dataset names suggest links to malware or specific regions.\n- Ownership of the leaked data is unclear, but its potential for phishing, identity theft, and ransomware is severe -- especially since even a\n- Basic cyber hygiene -- such as regularly updating strong passwords and scanning for malware -- is currently the best line of defense for users.","contentLength":2962,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Making the Most of 1:1 Meetings With Your Boss","url":"https://spectrum.ieee.org/making-most-of-1-1s","date":1750362310,"author":"Rahul Pandey","guid":163117,"unread":true,"content":"<p>The effectiveness of a 1:1 depends on your preparation before the meeting</p>","contentLength":73,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81OTEwNDExMC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc2MjIxNDM1NH0.KU_HC9RlAuzaq6NFugnkIjhO6mrvJzTfytOINkYN-Lg/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"OpenZFS 2.3.3 Released With Linux 6.15 Support","url":"https://www.phoronix.com/news/OpenZFS-2.3.3","date":1750358718,"author":"Michael Larabel","guid":163055,"unread":true,"content":"<article>Following last week's release of OpenZFS 2.2.8, OpenZFS 2.3.3 is now available as the newest point release of this current stable series for this open-source ZFS file-system implementation on Linux and FreeBSD systems...</article>","contentLength":220,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hackers Are Turning Tech Support Into a Threat","url":"https://it.slashdot.org/story/25/06/19/1619248/hackers-are-turning-tech-support-into-a-threat?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1750358400,"author":"msmash","guid":163054,"unread":true,"content":"Hackers have stolen hundreds of millions of dollars from cryptocurrency holders and disrupted major retailers by targeting outsourced call centers used by American corporations to reduce costs, WSJ reported Thursday. The attackers exploit low-paid call center workers through bribes and social engineering to bypass two-factor authentication systems protecting bank accounts and online portals. \n\nCoinbase faces potential losses of $400 million after hackers compromised data belonging to 97,000 customers by bribing call center workers in India with payments of $2,500. The criminals also used malicious tools that exploited vulnerabilities in Chrome browser extensions to collect customer data in bulk. \n\nTaskUs, which handled Coinbase support calls, shut down operations at its Indore, India facility and laid off 226 workers. Retail attacks targeted Marks &amp; Spencer and Harrods with hackers impersonating corporate executives to pressure tech support workers into providing network access. The same technique compromised MGM Resorts systems in 2023. Call center employees typically possess sensitive customer information including account balances and recent transactions that criminals use to masquerade as legitimate company representatives.","contentLength":1247,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BingX New Dual Investment Offering Sees $1M In User Participation","url":"https://hackernoon.com/bingx-new-dual-investment-offering-sees-$1m-in-user-participation?source=rss","date":1750357171,"author":"BTCWire","guid":163195,"unread":true,"content":"<p>PANAMA CITY, June 19, 2025 – <a href=\"https://bingx.com/en/\">BingX</a>, a leading cryptocurrency exchange and Web3 AI company, has officially launched its <a href=\"https://bingx.com/en/wealth/dual-investment\">Dual Investment</a> product, aimed at empowering users with high-yield strategies in all market conditions. </p><p>Within just two weeks of launch, BingX users have already invested over $1 million in this product — a clear reflection of its early popularity and market demand. </p><p>Built for both beginners and seasoned investors, Dual Investment embodies BingX's mission to deliver accessible, innovative financial tools that simplify complex trading strategies and help users grow their portfolios with greater confidence and control.</p><p><a href=\"https://bingx.com/en/support/articles/12091784594447/\">Dual Investment</a> is an innovative structured financial product that leverages the derivatives market, offering higher returns with relatively low risk. </p><p>Denominated in USDT, this product compares the prices of two cryptocurrencies and is structured around investment currency, settlement currency, APR, subscription amount, target price, and settlement time. The APR is floating, and upon settlement, the system determines the final interest and settlement currency based on whether the settlement price meets or crosses the target price.</p><p>Dual Investment is a streamlined alternative to traditional options trading, offering two distinct strategies known as Buy Low and Sell High. The Buy Low strategy functions similarly to a put option, allowing users to accumulate cryptocurrencies at more favorable prices. </p><p>Conversely, the Sell High strategy mirrors a call option, enabling users to sell assets at higher profit margins. In both cases, users earn interest that is comparable to the premiums typically associated with options trading.</p><p>BingX users can select durations of less than 7 days, 7–30 days, or more than 30 days, depending on specific financial goals and investment strategies — providing maximum flexibility. </p><p>Each duration comes with varying APYs. Designed for both long-term holders and strategic traders, Dual Investment helps users manage market volatility, grow their portfolios without active trading, and explore hedging or arbitrage opportunities more easily.</p><p>Founded in 2018, BingX is a leading crypto exchange and Web3 AI company, serving a global community of over 20 million users. With a comprehensive suite of AI-powered products and services, including derivatives, spot trading, and copy trading, BingX caters to the evolving needs of users across all experience levels, from beginners to professionals. </p><p>Committed to building a trustworthy and intelligent trading platform, BingX empowers users with innovative tools designed to enhance performance and confidence. In 2024, BingX proudly became the official crypto exchange partner of Chelsea Football Club, marking an exciting debut in the world of sports sponsorship.</p><p>For media inquiries, please contact: </p><p>:::tip\nThis story was published as a press release by Btcwire under HackerNoon’s Business Blogging&nbsp;.</p>","contentLength":2930,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Egor Kosolapov, Art Director and Graphic Designer: “We Aim to Set the Trends”","url":"https://hackernoon.com/egor-kosolapov-art-director-and-graphic-designer-we-aim-to-set-the-trends?source=rss","date":1750356550,"author":"Alex Lashkov","guid":163194,"unread":true,"content":"<p>With 15 years of experience in art direction, Egor Kosolapov has been at the forefront of visual work for some of the most prominent brands, receiving numerous awards and accolades. His most recent role is at The Daily Wire, a major digital media company with a monthly reach of over 200 million, featuring high-profile figures such as Ben Shapiro and Jordan Peterson.</p><p><strong>What first drew you into the world of art direction and graphic design? How has your career evolved over time, from your early work in Russia to your current role in the U.S.?</strong></p><p>I’ve been in various forms of art since a very young age, so in many ways, my career is the result of my parents’ ambition. While they couldn’t support it financially, they guided and inspired me through every stage of my creative education — from kindergarten art studios and art school to earning a bachelor's degree in Art Education and Graphic Design. By the time I had to choose a career path, I already knew exactly what I wanted to do. Graphic design was not only my passion, but also the area where I felt most confident. By the time I graduated from my hometown university, I had already gained hands-on experience working as a graphic designer at a couple of local advertising agencies.</p><p>Over the next few years, I expanded my skill set to include 3D, motion design, packaging, and brand identity development. I focused on building cross-disciplinary expertise so I could solve more complex business problems and approach creative tasks from unexpected angles.</p><p>This mindset helped me grow quickly — I moved from a regional agency to some of the top studios in Moscow, including Art. Lebedev Studio and BBDO. I quickly advanced from Junior Graphic Designer to Senior Art Director and was charged with major projects for such well known brands as Yandex, Beeline, and Baltika, as well as international companies from the UK and UAE.</p><p>Along the way, I earned more than 50 national and international awards, was named one of the Top 5 Creatives in Russia in 2020, and was invited to judge several creative festivals in the following years.</p><p>Here in the U.S., I was commissioned to work for The Daily Wire — one of the largest media platforms, with millions of viewers across a wide range of platforms.</p><p>Today, I work as a Senior Graphic Designer, primarily developing creative for the brands of Dr. Jordan B. Peterson and Ben Shapiro, contributing to projects that are both large in scale and rich in impact.</p><p><strong>Wow! These are amazing achievements. Having worked across cultures—from Moscow to Dubai to Los Angeles and Nashville — what are some of the most interesting differences you've encountered in creative communication?</strong></p><p>Having worked across Moscow, Dubai, Los Angeles, and Nashville, I’ve experienced some fascinating contrasts in creative communication — especially in terms of work ethic, cultural expectations, and visual aesthetics.</p><p>In Moscow and across Europe, there’s a strong emphasis on elegance, subtlety, and intellectual depth in design. Creative work often leans toward clever, sometimes hidden metaphors and nuanced messaging — ideas that take time to develop and reveal themselves. There’s a clear value placed on originality and crafting something that feels conceptually refined and artistically elevated.</p><p>By contrast, Dubai’s creative scene, heavily influenced by its startup culture and rapid innovation, moves much faster. Design there is highly trend-aware, adaptive, and visually driven. The focus tends to be on what’s current and dynamic, with a preference for bold visuals and immediate impact — a necessary response to a competitive and fast-paced market where speed often wins.</p><p>In the United States, especially in commercial settings, the creative approach is often more direct and results-oriented. Design is bold and built to sell — less about subtlety and more about clear, effective messaging. That doesn't mean the work lacks creativity or polish — many brands still aim for originality — but the priority is business growth. Great ideas are welcome, but they’re expected to serve performance and scale.</p><p>That said, my work at The Daily Wire stands out as an exception to many of those rules. Here, we’re not just following trends — we aim to set them. There’s a strong drive to elevate design and establish a visual language that reflects taste, quality, and cultural influence. We're encouraged to look globally for inspiration — from Europe’s refined visual metaphors to the boldness of American media — and blend the best of each to create iconic styles for our talents and shows. It’s a rare space where design isn’t just a function of the business — it helps define the brand itself.</p><p><strong>According to AdPeak, you were ranked #5 among the best creatives in Russia in 2020. What did that recognition mean for your career?</strong></p><p>Yes, 2020 was a breakthrough year for me creatively. One of the biggest and most meaningful projects I worked on — The Greatest Read for Beeline — launched that year. It turned out to be a major success, sweeping numerous national and international awards. That project played a big role in me being ranked #5 among the best creatives in Russia by AdPeak, and it also contributed to BBDO, the agency I was with at the time, being named the most awarded agency in the country that year.</p><p><strong>You've collaborated with Yandex, Beeline, and other well-known brands. Which of these projects challenged you the most? In what way?</strong></p><p>Yandex and Beeline were my first major projects as an advertising Art Director. These companies are essentially the Russian equivalents of Google and AT&amp;T. Both projects were challenging and valuable learning experiences, but the most demanding one was definitely my biggest campaign for Beeline — “The Greatest Reads.”</p><p>At the time, I had just graduated from advertising school and transitioned from Russia’s largest branding agency, Art. Lebedev Studio, to the well-known advertising agency BBDO. While I had strong skills in branding, advertising was an entirely different world — with its own tools, methods, and creative processes. I had only a vague idea of how things worked in this new environment.</p><p>Thankfully, my team helped me get up to speed quickly, and we dived into the project. The challenge wasn’t just the federal scale of the campaign, or that we were working with a celebrity artist, Noize MC, or even that we had to navigate new AI technology — though all of that played a role. What made it truly challenging was the pace at which I had to learn and adapt. I had to work three times harder to match the team’s experience, often staying late to catch up and find my footing in this new industry.</p><p>Despite the pressure, I rose to the occasion. I applied everything I knew, learned quickly, and gave it my all — and as a result, we created what became one of Russia’s best advertising campaigns of 2020. The project received wide recognition, top industry rankings, and multiple awards.</p><p><strong>For some of your works, you’ve also received recognition from Red Apple, ADCR, Effie, White Square Awards, and other awards. Which one meant the most to you and why? Which project are you most proud of?</strong></p><p>All of the awards I’ve received hold special meaning for me because each one represents a key chapter in my career. But if I had to choose the one that means the most, it would be the Effie Global — it marked the pinnacle of my career in 2021.</p><p>Effie Global is one of the most prestigious international awards in the advertising industry, with its headquarters in New York. To even qualify, a project must win at the national level (in my case, Effie Russia), then succeed regionally (Effie Europe), before finally competing on the global stage. Winning it means your work has stood out not only locally but also among the best projects and agencies worldwide.</p><p>I received that award for my campaign “The Greatest Reads” for Beeline — a large-scale, high-impact project that remains the most awarded and career-defining work I’ve done so far. I take immense pride in it, not only because of the recognition it brought but because of the creative and strategic challenges it pushed me to overcome. That project validated my ability to create work that resonates on a global level — and that’s something I’ll always be proud of.</p><p><strong>Now, working as Senior Graphic Designer at The Daily Wire, you help shape visual identities and styles of the company’s top talents. With a monthly network reach of 220 million and 2.3 million lifetime subscribers, how do you think your work impacts audiences around the world?</strong></p><p>The Daily Wire is one of the leading media companies in the U.S., with a strong focus on American culture and politics. But our reach extends far beyond national borders. While our core audience is American, we also speak to English-speaking viewers around the world who share similar cultural foundations and values.</p><p>In a broader sense, I see our audience as the Western world — people connected by a shared cultural context, historical background, and a common visual language. That’s who I design for. My work isn’t tailored to individual countries’ peculiarities, but rather speaks to universal elements within the Western experience.</p><p>When shaping the visual identities of our top talents, designing show graphics, or creating content for YouTube and social media, I always keep that global-yet-cultural framework in mind. It's essential to deeply understand the visual codes, historical references, and emotional undercurrents that resonate across this audience — whether someone is in Texas, London, or Sydney.</p><p>At its core, design is about connection. It's about creating something that makes people feel they belong — that they’re part of a larger conversation or community. When you get the visual tone right — through color, typography, photography, or layout — you help deliver a message that not only informs or entertains, but also unites. And with a monthly network reach of over 220 million, that impact is both powerful and far-reaching.</p><p><strong>You worked on high-profile projects including the Ben Shapiro Show and Jordan B. Peterson’s digital presence. How did you approach the visual concepts for such different personalities that might be tapped into their unique recognized style? How do thumbnails and social visuals reflect someone’s identity and depth?</strong></p><p>Yes, you're absolutely right — working with high-profile talents like Ben Shapiro and Dr. Jordan B. Peterson is a challenge, even for seasoned creatives. It requires a careful balance between hitting business goals — like reach, engagement, and views — and staying true to the unique personality and voice of each talent. Every element of their visual presence has to align with how they speak, how they think, and how they connect with their audience.</p><p>When approaching the visual styles for Ben’s and Jordan’s content, I had a bit of a home-field advantage. I had followed both of them for years before joining The Daily Wire, so I already had a strong understanding of their brands and public personas. That foundation allowed me to quickly grasp what would feel authentic for each of them — both visually and tonally.</p><p>But more than that, what really helped was genuinely caring about the work they do. As someone who admires their contributions, I felt personally invested in creating visuals that not only looked good but also felt right — something that would resonate with their audiences and reflect the depth of their ideas. I wasn’t just designing for them — I was designing as a fan, which gave me a strong intuitive sense of what would feel inspiring, iconic, and worthy of their legacy.</p><p>My background in branding, advertising, and communication strategy allowed me to translate those instincts into precise, evocative visual systems. For each talent, I developed a style that reflected their unique tone — from Ben’s sharp, direct energy to Jordan’s more thoughtful and layered presence — and carried that through in thumbnails, social visuals, and motion graphics across their content and shows.</p><p>Thumbnails, in particular, are a powerful tool. They may seem small, but they play a huge role in shaping perception. A strong thumbnail communicates not just what a piece of content is about, but who it’s coming from. It’s about making sure the first visual impression carries the weight of a recognizable identity — and for personalities like Ben and Jordan, that identity is everything.</p><p><strong>The content of the creators you work with can be divisive. Do you feel the need to agree with the message in order to create visuals for it? Have you ever had to navigate projects that didn’t fully align with your personal beliefs?</strong></p><p>You're right — the content I work with can sometimes be divisive. But I don’t necessarily see that as a negative. In fact, being polarizing can be a sign that the message is cutting through the noise. It can provoke discussion, invite reflection, and get people talking — which is often the first step toward understanding. As the saying goes, \"truth is born in debate,\" and I believe that holds true in many cases.</p><p>When it comes to whether I need to personally agree with every message I help visualize — I’d say it’s less about full alignment with each individual statement, and more about understanding and resonating with the broader philosophy. If I feel the project has purpose, relevance, and integrity, I can fully engage with it creatively.</p><p>That said, I’ve definitely worked on projects that didn’t fully align with my personal beliefs, especially early in my career. As a junior creative, you rarely get to choose your assignments. I’ve worked with brands like alcohol and tobacco — not because I endorsed them personally, but because those experiences gave me a chance to grow, learn, and build my craft. And I think that’s valid. Every project teaches you something, whether it’s about design, communication, or your own boundaries as a creative.</p><p><strong>Looking ahead, what kinds of projects excite you the most? Are you drawn more to commercial work, artistic exploration, or social initiatives?</strong></p><p>I’m most excited by the idea of stepping into a more creative leadership or co-creator role — not just designing for content, but actually being involved in creating it. Working in a media company with major talents and a multimillion-viewer audience has been incredibly inspiring. It’s pushed me to think beyond execution and consider how I might use my skills to shape stories, messages, or even formats myself.</p><p>While I’m not yet sure what specific direction that might take, the idea of being on the other side of content creation — while still designing and using my visual expertise to elevate it — feels both challenging and energizing.</p><p>I’m also deeply drawn to working with impactful voices — podcasters, creators, and shows that genuinely influence people in positive, meaningful ways. So if I had to define what excites me most, it would be projects that sit somewhere between commercial work and artistic exploration, with a clear sense of purpose and cultural relevance.</p>","contentLength":15171,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["tech"]}