{"id":"5EtLJWwbEiHVuC","title":"Kubernetes","displayTitle":"Kubernetes","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":18,"items":[{"title":"Navigating Failures in Pods With Devices","url":"https://kubernetes.io/blog/2025/07/03/navigating-failures-in-pods-with-devices/","date":1751500800,"author":"","guid":181564,"unread":true,"content":"<p>Kubernetes is the de facto standard for container orchestration, but when it\ncomes to handling specialized hardware like GPUs and other accelerators, things\nget a bit complicated. This blog post dives into the challenges of managing\nfailure modes when operating pods with devices in Kubernetes, based on insights\nfrom <a href=\"https://sched.co/1i7pT\">Sergey Kanzhelev and Mrunal Patel's talk at KubeCon NA\n2024</a>. You can follow the links to\n<a href=\"https://static.sched.com/hosted_files/kccncna2024/b9/KubeCon%20NA%202024_%20Navigating%20Failures%20in%20Pods%20With%20Devices_%20Challenges%20and%20Solutions.pptx.pdf?_gl=1*191m4j5*_gcl_au*MTU1MDM0MTM1My4xNzMwOTE4ODY5LjIxNDI4Nzk1NDIuMTczMTY0ODgyMC4xNzMxNjQ4ODIy*FPAU*MTU1MDM0MTM1My4xNzMwOTE4ODY5\">slides</a>\nand\n<a href=\"https://www.youtube.com/watch?v=-YCnOYTtVO8&amp;list=PLj6h78yzYM2Pw4mRw4S-1p_xLARMqPkA7&amp;index=150\">recording</a>.</p><h2>The AI/ML boom and its impact on Kubernetes</h2><p>The rise of AI/ML workloads has brought new challenges to Kubernetes. These\nworkloads often rely heavily on specialized hardware, and any device failure can\nsignificantly impact performance and lead to frustrating interruptions. As\nhighlighted in the 2024 <a href=\"https://ai.meta.com/research/publications/the-llama-3-herd-of-models/\">Llama\npaper</a>,\nhardware issues, particularly GPU failures, are a major cause of disruption in\nAI/ML training. You can also learn how much effort NVIDIA spends on handling\ndevices failures and maintenance in the KubeCon talk by <a href=\"https://kccncna2024.sched.com/event/1i7kJ/all-your-gpus-are-belong-to-us-an-inside-look-at-nvidias-self-healing-geforce-now-infrastructure-ryan-hallisey-piotr-prokop-pl-nvidia\">Ryan Hallisey and Piotr\nProkop All-Your-GPUs-Are-Belong-to-Us: An Inside Look at NVIDIA's Self-Healing\nGeForce NOW\nInfrastructure</a>\n(<a href=\"https://www.youtube.com/watch?v=iLnHtKwmu2I\">recording</a>) as they see 19\nremediation requests per 1000 nodes a day!\nWe also see data centers offering spot consumption models and overcommit on\npower, making device failures commonplace and a part of the business model.</p><p>However, Kubernetes’s view on resources is still very static. The resource is\neither there or not. And if it is there, the assumption is that it will stay\nthere fully functional - Kubernetes lacks good support for handling full or partial\nhardware failures. These long-existing assumptions combined with the overall complexity of a setup lead\nto a variety of failure modes, which we discuss here.</p><h3>Understanding AI/ML workloads</h3><p>Generally, all AI/ML workloads require specialized hardware, have challenging\nscheduling requirements, and are expensive when idle. AI/ML workloads typically\nfall into two categories - training and inference. Here is an oversimplified\nview of those categories’ characteristics, which are different from traditional workloads\nlike web services:</p><dl><dd>These workloads are resource-intensive, often consuming entire\nmachines and running as gangs of pods. Training jobs are usually \"run to\ncompletion\" - but that could be days, weeks or even months. Any failure in a\nsingle pod can necessitate restarting the entire step across all the pods.</dd><dd>These workloads are usually long-running or run indefinitely,\nand can be small enough to consume a subset of a Node’s devices or large enough to span\nmultiple nodes. They often require downloading huge files with the model\nweights.</dd></dl><p>These workload types specifically break many past assumptions:</p><table><caption>Workload assumptions before and now</caption><tbody><tr><td>Can get a better CPU and the app will work faster.</td><td>Require a  device (or ) to run.</td></tr><tr><td>When something doesn’t work, just recreate it.</td><td>Allocation or reallocation is expensive.</td></tr><tr><td>Any node will work. No need to coordinate between Pods.</td><td>Scheduled in a special way - devices often connected in a cross-node topology.</td></tr><tr><td>Each Pod can be plug-and-play replaced if failed.</td><td>Pods are a part of a larger task. Lifecycle of an entire task depends on each Pod.</td></tr><tr><td>Container images are slim and easily available.</td><td>Container images may be so big that they require special handling.</td></tr><tr><td>Long initialization can be offset by slow rollout.</td><td>Initialization may be long and should be optimized, sometimes across many Pods together.</td></tr><tr><td>Compute nodes are commoditized and relatively inexpensive, so some idle time is acceptable.</td><td>Nodes with specialized hardware can be an order of magnitude more expensive than those without, so idle time is very wasteful.</td></tr></tbody></table><p>The existing failure model was relying on old assumptions. It may still work for\nthe new workload types, but it has limited knowledge about devices and is very\nexpensive for them. In some cases, even prohibitively expensive. You will see\nmore examples later in this article.</p><h3>Why Kubernetes still reigns supreme</h3><p>This article is not going deeper into the question: why not start fresh for\nAI/ML workloads since they are so different from the traditional Kubernetes\nworkloads. Despite many challenges, Kubernetes remains the platform of choice\nfor AI/ML workloads. Its maturity, security, and rich ecosystem of tools make it\na compelling option. While alternatives exist, they often lack the years of\ndevelopment and refinement that Kubernetes offers. And the Kubernetes developers\nare actively addressing the gaps identified in this article and beyond.</p><h2>The current state of device failure handling</h2><p>This section outlines different failure modes and the best practices and DIY\n(Do-It-Yourself) solutions used today. The next session will describe a roadmap\nof improving things for those failure modes.</p><h3>Failure modes: K8s infrastructure</h3><p>In order to understand the failures related to the Kubernetes infrastructure,\nyou need to understand how many moving parts are involved in scheduling a Pod on\nthe node. The sequence of events when the Pod is scheduled in the Node is as\nfollows:</p><ol><li> is scheduled on the Node</li><li> is registered with the  via local gRPC</li><li> uses  to watch for devices and updates capacity of\nthe node</li><li> places a  on a Node based on the updated capacity</li><li> asks  to  devices for a </li><li> creates a  with the allocated devices attached to it</li></ol><p>This diagram shows some of those actors involved:</p><p>As there are so many actors interconnected, every one of them and every\nconnection may experience interruptions. This leads to many exceptional\nsituations that are often considered failures, and may cause serious workload\ninterruptions:</p><ul><li>Pods failing admission at various stages of its lifecycle</li><li>Pods unable to run on perfectly fine hardware</li><li>Scheduling taking unexpectedly long time</li></ul><p>The goal for Kubernetes is to make the interruption between these components as\nreliable as possible. Kubelet already implements retries, grace periods, and\nother techniques to improve it. The roadmap section goes into details on other\nedge cases that the Kubernetes project tracks. However, all these improvements\nonly work when these best practices are followed:</p><ul><li>Configure and restart kubelet and the container runtime (such as containerd or CRI-O)\nas early as possible to not interrupt the workload.</li><li>Monitor device plugin health and carefully plan for upgrades.</li><li>Do not overload the node with less-important workloads to prevent interruption\nof device plugin and other components.</li><li>Configure user pods tolerations to handle node readiness flakes.</li><li>Configure and code graceful termination logic carefully to not block devices\nfor too long.</li></ul><p>Another class of Kubernetes infra-related issues is driver-related. With\ntraditional resources like CPU and memory, no compatibility checks between the\napplication and hardware were needed. With special devices like hardware\naccelerators, there are new failure modes. Device drivers installed on the node:</p><ul><li>Be compatible with an app</li><li>Must work with other drivers (like <a href=\"https://developer.nvidia.com/nccl\">nccl</a>,\netc.)</li></ul><p>Best practices for handling driver versions:</p><ul><li>Monitor driver installer health</li><li>Plan upgrades of infrastructure and Pods to match the version</li><li>Have canary deployments whenever possible</li></ul><p>Following the best practices in this section and using device plugins and device\ndriver installers from trusted and reliable sources generally eliminate this\nclass of failures. Kubernetes is tracking work to make this space even better.</p><h3>Failure modes: device failed</h3><p>There is very little handling of device failure in Kubernetes today. Device\nplugins report the device failure only by changing the count of allocatable\ndevices. And Kubernetes relies on standard mechanisms like liveness probes or\ncontainer failures to allow Pods to communicate the failure condition to the\nkubelet. However, Kubernetes does not correlate device failures with container\ncrashes and does not offer any mitigation beyond restarting the container while\nbeing attached to the same device.</p><p>This is why many plugins and DIY solutions exist to handle device failures based\non various signals.</p><p>In many cases a failed device will result in unrecoverable and very expensive\nnodes doing nothing. A simple DIY solution is a . The\ncontroller could compare the device allocatable count with the capacity and if\nthe capacity is greater, it starts a timer. Once the timer reaches a threshold,\nthe health controller kills and recreates a node.</p><p>There are problems with the  approach:</p><ul><li>Root cause of the device failure is typically not known</li><li>The controller is not workload aware</li><li>Failed device might not be in use and you want to keep other devices running</li><li>The detection may be too slow as it is very generic</li><li>The node may be part of a bigger set of nodes and simply cannot be deleted in\nisolation without other nodes</li></ul><p>There are variations of the health controller solving some of the problems\nabove. The overall theme here though is that to best handle failed devices, you\nneed customized handling for the specific workload. Kubernetes doesn’t yet offer\nenough abstraction to express how critical the device is for a node, for the\ncluster, and for the Pod it is assigned to.</p><p>Another DIY approach for device failure handling is a per-pod reaction on a\nfailed device. This approach is applicable for  workloads that are\nimplemented as Jobs.</p><p>There are some problems with the  approach for Jobs:</p><ul><li>There is no well-known  condition, so this approach does not work for the\ngeneric Pod case</li><li>Error codes must be coded carefully and in some cases are hard to guarantee.</li><li>Only works with Jobs with , due to the limitation of a pod\nfailure policy feature.</li></ul><p>So, this solution has limited applicability.</p><p>A little more generic approach is to implement the Pod watcher as a DIY solution\nor use some third party tools offering this functionality. The pod watcher is\nmost often used to handle device failures for inference workloads.</p><p>Since Kubernetes just keeps a pod assigned to a device, even if the device is\nreportedly unhealthy, the idea is to detect this situation with the pod watcher\nand apply some remediation. It often involves obtaining device health status and\nits mapping to the Pod using Pod Resources API on the node. If a device fails,\nit can then delete the attached Pod as a remediation. The replica set will\nhandle the Pod recreation on a healthy device.</p><p>The other reasons to implement this watcher:</p><ul><li>Without it, the Pod will keep being assigned to the failed device forever.</li><li>There is no  for a pod with .</li><li>There are no built-in controllers that delete Pods in CrashLoopBackoff.</li></ul><p>Problems with the :</p><ul><li>The signal for the pod watcher is expensive to get, and involves some\nprivileged actions.</li><li>It is a custom solution and it assumes the importance of a device for a Pod.</li><li>The pod watcher relies on external controllers to reschedule a Pod.</li></ul><p>There are more variations of DIY solutions for handling device failures or\nupcoming maintenance. Overall, Kubernetes has enough extension points to\nimplement these solutions. However, some extension points require higher\nprivilege than users may be comfortable with or are too disruptive. The roadmap\nsection goes into more details on specific improvements in handling the device\nfailures.</p><h3>Failure modes: container code failed</h3><p>When the container code fails or something bad happens with it, like out of\nmemory conditions, Kubernetes knows how to handle those cases. There is either\nthe restart of a container, or a crash of a Pod if it has \nand scheduling it on another node. Kubernetes has limited expressiveness on what\nis a failure (for example, non-zero exit code or liveness probe failure) and how\nto react on such a failure (mostly either Always restart or immediately fail the\nPod).</p><p>This level of expressiveness is often not enough for the complicated AI/ML\nworkloads. AI/ML pods are better rescheduled locally or even in-place as that\nwould save on image pulling time and device allocation. AI/ML pods are often\ninterconnected and need to be restarted together. This adds another level of\ncomplexity and optimizing it often brings major savings in running AI/ML\nworkloads.</p><p>There are various DIY solutions to handle Pod failures orchestration. The most\ntypical one is to wrap a main executable in a container by some orchestrator.\nAnd this orchestrator will be able to restart the main executable whenever the\njob needs to be restarted because some other pod has failed.</p><p>Solutions like this are very fragile and elaborate. They are often worth the\nmoney saved comparing to a regular JobSet delete/recreate cycle when used in\nlarge training jobs. Making these solutions less fragile and more streamlined\nby developing new hooks and extension points in Kubernetes will make it\neasy to apply to smaller jobs, benefiting everybody.</p><h3>Failure modes: device degradation</h3><p>Not all device failures are terminal for the overall workload or batch job.\nAs the hardware stack gets more and more\ncomplex, misconfiguration on one of the hardware stack layers, or driver\nfailures, may result in devices that are functional, but lagging on performance.\nOne device that is lagging behind can slow down the whole training job.</p><p>We see reports of such cases more and more often. Kubernetes has no way to\nexpress this type of failures today and since it is the newest type of failure\nmode, there is not much of a best practice offered by hardware vendors for\ndetection and third party tooling for remediation of these situations.</p><p>Typically, these failures are detected based on observed workload\ncharacteristics. For example, the expected speed of AI/ML training steps on\nparticular hardware. Remediation for those issues is highly depend on a workload needs.</p><p>As outlined in a section above, Kubernetes offers a lot of extension points\nwhich are used to implement various DIY solutions. The space of AI/ML is\ndeveloping very fast, with changing requirements and usage patterns. SIG Node is\ntaking a measured approach of enabling more extension points to implement the\nworkload-specific scenarios over introduction of new semantics to support\nspecific scenarios. This means prioritizing making information about failures\nreadily available over implementing automatic remediations for those failures\nthat might only be suitable for a subset of workloads.</p><p>This approach ensures there are no drastic changes for workload handling which\nmay break existing, well-oiled DIY solutions or experiences with the existing\nmore traditional workloads.</p><p>Many error handling techniques used today work for AI/ML, but are very\nexpensive. SIG Node will invest in extension points to make those cheaper, with\nthe understanding that the price cutting for AI/ML is critical.</p><p>The following is the set of specific investments we envision for various failure\nmodes.</p><h3>Roadmap for failure modes: K8s infrastructure</h3><p>The area of Kubernetes infrastructure is the easiest to understand and very\nimportant to make right for the upcoming transition from Device Plugins to DRA.\nSIG Node is tracking many work items in this area, most notably the following:</p><p>Basically, every interaction of Kubernetes components must be reliable via\neither the kubelet improvements or the best practices in plugins development\nand deployment.</p><h3>Roadmap for failure modes: device failed</h3><p>For the device failures some patterns are already emerging in common scenarios\nthat Kubernetes can support. However, the very first step is to make information\nabout failed devices available easier. The very first step here is the work in\n<a href=\"https://kep.k8s.io/4680\">KEP 4680</a> (Add Resource Health Status to the Pod Status for\nDevice Plugin and DRA).</p><p>Longer term ideas include to be tested:</p><ul><li>Integrate device failures into Pod Failure Policy.</li><li>Node-local retry policies, enabling pod failure policies for Pods with\nrestartPolicy=OnFailure and possibly beyond that.</li><li>Ability to  pod, including with the , so it can\nget a new device allocated.</li><li>Add device health to the ResourceSlice used to represent devices in DRA,\nrather than simply withdrawing an unhealthy device from the ResourceSlice.</li></ul><h3>Roadmap for failure modes: container code failed</h3><p>The main improvements to handle container code failures for AI/ML workloads are\nall targeting cheaper error handling and recovery. The cheapness is mostly\ncoming from reuse of pre-allocated resources as much as possible. From reusing\nthe Pods by restarting containers in-place, to node local restart of containers\ninstead of rescheduling whenever possible, to snapshotting support, and\nre-scheduling prioritizing the same node to save on image pulls.</p><p>Consider this scenario: A big training job needs 512 Pods to run. And one of the\npods failed. It means that all Pods need to be interrupted and synced up to\nrestart the failed step. The most efficient way to achieve this generally is to\nreuse as many Pods as possible by restarting them in-place, while replacing the\nfailed pod to clear up the error from it. Like demonstrated in this picture:</p><p>It is possible to implement this scenario, but all solutions implementing it are\nfragile due to lack of certain extension points in Kubernetes. Adding these\nextension points to implement this scenario is on the Kubernetes roadmap.</p><h3>Roadmap for failure modes: device degradation</h3><p>There is very little done in this area - there is no clear detection signal,\nvery limited troubleshooting tooling, and no built-in semantics to express the\n\"degraded\" device on Kubernetes. There has been discussion of adding data on\ndevice performance or degradation in the ResourceSlice used by DRA to represent\ndevices, but it is not yet clearly defined. There are also projects like\n<a href=\"https://github.com/medik8s/node-healthcheck-operator\">node-healthcheck-operator</a>\nthat can be used for some scenarios.</p><p>We expect developments in this area from hardware vendors and cloud providers, and we expect to see mostly DIY\nsolutions in the near future. As more users get exposed to AI/ML workloads, this\nis a space needing feedback on patterns used here.</p><p>The Kubernetes community encourages feedback and participation in shaping the\nfuture of device failure handling. Join SIG Node and contribute to the ongoing\ndiscussions!</p><p>This blog post provides a high-level overview of the challenges and future\ndirections for device failure management in Kubernetes. By addressing these\nissues, Kubernetes can solidify its position as the leading platform for AI/ML\nworkloads, ensuring resilience and reliability for applications that depend on\nspecialized hardware.</p>","contentLength":18095,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lightning Talk: Optimizing Web Applications by Offloading Heavy Processing To Kuberne... Asami Okina","url":"https://www.youtube.com/watch?v=8pVt9dhHEVc","date":1751497305,"author":"CNCF [Cloud Native Computing Foundation]","guid":181437,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nLightning Talk: Optimizing Web Applications by Offloading Heavy Processing To Kubernetes Jobs - Asami Okina, Craftsman Software, Inc.\n\nWhile typical web applications do not require large amounts of resources constantly, there are cases where specific processes consume significant CPU and memory.\n\nIn this session, we will introduce an architecture that offloads such resource-intensive processes to Kubernetes Jobs.\n\nWe will explain specific methods for Job management, how to integrate web applications (Next.js, @kubernetes/client-node) with the Kubernetes API, methods for data integration between Jobs and web applications, and real-time tracking of Job progress in the UI, all while sharing practical examples. Furthermore, we will provide a detailed introduction to a pattern where Kubernetes Job definitions generated from applications are managed using ConfigMaps, enabling quick configuration switching between environments, and offer hints to optimize your applications in terms of cost, performance, and management.</article>","contentLength":1410,"flags":null,"enclosureUrl":"https://www.youtube.com/v/8pVt9dhHEVc?version=3","enclosureMime":"","commentsUrl":null},{"title":"Platform Engineering Day 2: Why Service Iterations Are the Crux of Developer Platfor... Puja Abbassi","url":"https://www.youtube.com/watch?v=Xr0Eb-ybvck","date":1751401964,"author":"CNCF [Cloud Native Computing Foundation]","guid":179271,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nPlatform Engineering Day 2: Why Service Iterations Are the Crux of Developer Platforms - Puja Abbassi, Giant Swarm\n\nEveryone is talking about platform engineering. You see smooth demos of golden paths and self-service platforms. However, there’s a significant area of challenges that is less talked about and thus often neglected when designing developer platforms.\n\nIn this talk, we’ll explore the often-overlooked day 2 challenges that platform teams face. We’ll dissect the area of day 2 into the many sub-areas and challenges they pose. Drawing on real-world experiences, including notable migrations that many in this community have faced, we'll shed light on the pain behind developer platforms and discuss solutions to these issues. Among others, we’ll delve into practical strategies for managing versioning and rollouts, and highlight the significant hurdles encountered, such as dependencies on end user teams or GitOps.\n\nJoin us for insights, strategies, and stories from the trenches that will help you navigate the complexities of service iteration in developer platforms.</article>","contentLength":1476,"flags":null,"enclosureUrl":"https://www.youtube.com/v/Xr0Eb-ybvck?version=3","enclosureMime":"","commentsUrl":null},{"title":"Keynote: OpenTelemetry And The Future of Open Source Observability - Austin Parker, Honeycomb","url":"https://www.youtube.com/watch?v=hERRANApN5c","date":1751391324,"author":"CNCF [Cloud Native Computing Foundation]","guid":179127,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nKeynote: OpenTelemetry And The Future of Open Source Observability - Austin Parker, Honeycomb</article>","contentLength":476,"flags":null,"enclosureUrl":"https://www.youtube.com/v/hERRANApN5c?version=3","enclosureMime":"","commentsUrl":null},{"title":"Sponsored Keynote: Why Semantic Conventions are OpenTelemetry’s Most Important Con... Gordon Radlein","url":"https://www.youtube.com/watch?v=dlDTX-aDNzg","date":1751391324,"author":"CNCF [Cloud Native Computing Foundation]","guid":179128,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nSponsored Keynote: Why Semantic Conventions are OpenTelemetry’s Most Important Contribution - Gordon Radlein, Datadog\n\nOpenTelemetry has accelerated the commoditization of instrumentation. Telemetry generation is becoming a solved problem, an implementation detail. But this has created a new challenge: a wealth of standardized signals with no standard meaning. Different systems instrumented with different semantics generating telemetry in their own unique language. And while signal correlation connects specific workloads, it fails when we need to understand our systems at a macro scale by joining disparate datasets.\nThat is, until we all agreed to speak the same language.\n\nJust as English as a lingua franca fueled progress across the internet, OpenTelemetry Semantic Conventions are providing a shared language for our systems. In this talk we’ll discuss why semantic interoperability is the real connective tissue, how it’s fueling deeper insights into our production environments, and the key role it plays in enabling the AI systems that are rapidly ushering in the next revolution of our industry.</article>","contentLength":1500,"flags":null,"enclosureUrl":"https://www.youtube.com/v/dlDTX-aDNzg?version=3","enclosureMime":"","commentsUrl":null},{"title":"Welcome + Opening Remarks - Austin Parker, Honeycomb","url":"https://www.youtube.com/watch?v=_rqgWHaEvgc","date":1751391324,"author":"CNCF [Cloud Native Computing Foundation]","guid":179129,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nWelcome + Opening Remarks - Austin Parker, Honeycomb</article>","contentLength":435,"flags":null,"enclosureUrl":"https://www.youtube.com/v/_rqgWHaEvgc?version=3","enclosureMime":"","commentsUrl":null},{"title":"Sponsored Keynote: Manage Logging Costs While Preserving Value - Alok Bhide, Chronosphere","url":"https://www.youtube.com/watch?v=Z4umnlRdLtA","date":1751391324,"author":"CNCF [Cloud Native Computing Foundation]","guid":179130,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nSponsored Keynote: Manage Logging Costs While Preserving Value - Alok Bhide, Chronosphere\n\nLogs can get very expensive and often how useful all those logs are is unknown, some are but many are not. It is very difficult to know which logs are useful and how exactly they are used. With Chronosphere's Control plane for logs users can now get a comprehensive analysis of value and usage patterns, along with sophisticated recommendations and control actions that allow some or most of the value derived from those logs to be preserved. In order to achieve our goals we have enhanced Fluent Bit to be more flexible in which logs are actioned upon and will share useful future additions to it.</article>","contentLength":1072,"flags":null,"enclosureUrl":"https://www.youtube.com/v/Z4umnlRdLtA?version=3","enclosureMime":"","commentsUrl":null},{"title":"Keynote: Hybrid Cloud Architecture: Making Big Bets on Open Standards - Margaret Dawson","url":"https://www.youtube.com/watch?v=J_hHiwa_3QU","date":1751391324,"author":"CNCF [Cloud Native Computing Foundation]","guid":179131,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nKeynote: Hybrid Cloud Architecture: Making Big Bets on Open Standards - Margaret Dawson, Chronosphere\n\nHybrid cloud isn’t a stepping stone—it’s a destination. With 39% of CNCF survey respondents already operating in hybrid environments, this model is here to stay. But as teams pursue cloud-native architectures, many skip a critical step: developing a clear cloud strategy and an observability approach to match.\nThe result is predictable— widening visibility gaps, redundant tooling and data, and spiraling costs as teams try to stitch together disconnected, vendor-specific systems never meant to work in concert. Hybrid environments expose these issues quickly, especially when workloads span multiple platforms without a unified way to observe and understand them.\nModernization efforts demand open observability from the start—not as an add-on. Technologies like OpenTelemetry, Fluent Bit, and Prometheus act as connective tissue across clouds, clusters, and on-prem infrastructure, enabling standardization where it’s needed most.\nThis talk outlines how to center open observability in your modernization journey: where to standardize architectural layers, how to maintain a more open approach, and why these decisions have long-term payoff. \nHybrid complexity is inevitable. Leading with open observability is how you stay in control—now and in the future.</article>","contentLength":1761,"flags":null,"enclosureUrl":"https://www.youtube.com/v/J_hHiwa_3QU?version=3","enclosureMime":"","commentsUrl":null},{"title":"Sponsored Keynote: Foundation-Led Innovation: OpenSearch's Impact on Modern Data I... Dotan Horovits","url":"https://www.youtube.com/watch?v=C5Y3qnEJSY8","date":1751391324,"author":"CNCF [Cloud Native Computing Foundation]","guid":179132,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nSponsored Keynote: Foundation-Led Innovation: OpenSearch's Impact on Modern Data Insights - Dotan Horovits, AWS OpenSearch</article>","contentLength":505,"flags":null,"enclosureUrl":"https://www.youtube.com/v/C5Y3qnEJSY8?version=3","enclosureMime":"","commentsUrl":null},{"title":"Building Resilient Telemetry Pipelines: Mastering the OpenTelemetry Collector's Per... Denton Krietz","url":"https://www.youtube.com/watch?v=zgnY8szpKUw","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179118,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nBuilding Resilient Telemetry Pipelines: Mastering the OpenTelemetry Collector's Persistent Queue - Denton Krietz, Bindplane\n\nThe OpenTelemetry Collector’s persistent queue provides a robust mechanism for handling data bursts, destination outages, and processing delays, ensuring no telemetry data is lost—but from experience, it’s consistently one of the collector's least understood features.\n\nIn this talk, we’ll explore the inner workings of the OTel Collector’s persistent queue, including how it buffers data, ensures durability, and enables replay after failures. Attendees will learn how to configure persistent queues for their unique workloads, optimize their telemetry pipeline performance, and troubleshoot common pitfalls.\n\nWhether you’re a site reliability engineer, developer, or observability enthusiast, this talk will equip you with the knowledge to deeply understand persistent queues to optimize your telemetry pipeline in production.</article>","contentLength":1348,"flags":null,"enclosureUrl":"https://www.youtube.com/v/zgnY8szpKUw?version=3","enclosureMime":"","commentsUrl":null},{"title":"Introducing a Lightweight Rust OpenTelemetry Collector - Mike Heffner & Ray Jenkins, Streamfold","url":"https://www.youtube.com/watch?v=xeQnP8Ct7qY","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179119,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nIntroducing a Lightweight Rust OpenTelemetry Collector - Mike Heffner &amp; Ray Jenkins, Streamfold\n\nIn this talk, we'll introduce Rotel—an open-source OpenTelemetry collector built in Rust. Rotel is lightweight and resource-efficient, integrating seamlessly into your development workflow. Its compact design lets you package it with your Python or NodeJS projects, so telemetry collection runs alongside your code without needing additional sidecars.\n\nWe'll explore how rethinking telemetry collection at the edge can empower developers right from the early stages of development, paving the way for broader OpenTelemetry adoption. You’ll learn how Rust’s low-overhead FFI enables native extensions for telemetry filtering, transformation, and enrichment using Python and Typescript.\n\nBy leveraging Rust’s performance strengths, Rotel avoids the overhead of garbage collection, resulting in lower memory usage and reduced latency. Its quick cold start times make it a natural fit for modern cloud-native, serverless, and edge computing environments. Join us to discover how moving telemetry collection closer to the source can help you analyze high-volume, high-fidelity signals more effectively.</article>","contentLength":1585,"flags":null,"enclosureUrl":"https://www.youtube.com/v/xeQnP8Ct7qY?version=3","enclosureMime":"","commentsUrl":null},{"title":"Lightning Talk: From Zero To Developer: My One Year Serendipity Journey With OpenTele... Diana Todea","url":"https://www.youtube.com/watch?v=wWON2NT41lE","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179120,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nLightning Talk: From Zero To Developer: My One Year Serendipity Journey With OpenTelemetry - Diana Todea, Aircall\n\nBecoming a contributor to an open-source project is a transformative step in any developer's career. This session explores the journey from first-time contributor to active developer, covering best practices for navigating project communities, understanding codebases, and making meaningful contributions. Learn strategies for selecting the right project, mastering collaboration tools, and embracing the culture of open-source development. The audience will be inspired about my one year journey with the open source project OpenTelemetry and how I have built a proof of concept for it and achieved developer status for this project. By the end of this talk, the public will gain insights into the tools to become a better developer and how to build more engagement with the community.</article>","contentLength":1284,"flags":null,"enclosureUrl":"https://www.youtube.com/v/wWON2NT41lE?version=3","enclosureMime":"","commentsUrl":null},{"title":"Telemetry Showdown: Fluent Bit Vs. OpenTelemetry Collector - A Comprehensive Benchma... Henrik Rexed","url":"https://www.youtube.com/watch?v=tZho5W9L_Z8","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179121,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nTelemetry Showdown: Fluent Bit Vs. OpenTelemetry Collector - A Comprehensive Benchmark Analysis - Henrik Rexed, Dynatrace\n\nIn a push to standardize observability practices, the cloud-native community has embraced OpenTelemetry, offering a unified framework for metrics, logs, and traces. Prior to this, log processing relied on agents like fluent, evolving into fluentbit. With fluentbit's recent expansion to support additional signals and the OpenTelemetry Collector's emergence, a pertinent question arises: Which is the superior choice for performance?\n\nThis session delves into:\n- Unveiling the distinctions between Fluent Bit and the OpenTelemetry Collector.\n- Sharing the findings derived from a series of benchmark tests.\n- Providing valuable insights to empower the community in selecting the most fitting agent for their cloud-native environments.</article>","contentLength":1240,"flags":null,"enclosureUrl":"https://www.youtube.com/v/tZho5W9L_Z8?version=3","enclosureMime":"","commentsUrl":null},{"title":"The Spec-tacular Game Show - Liudmila Molkova, Ted Young, Tyler Helmuth, Jamie Danielson, Alex Boten","url":"https://www.youtube.com/watch?v=ipFVu0dl5Bw","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179122,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nPanel: The Spec-tacular Game Show - Liudmila Molkova, Microsoft; Ted Young, Grafana Labs; Tyler Helmuth, Jamie Danielson &amp; Alex Boten, Honeycomb\n\nFrom OTLP to OTTL, engineers are excited about a lot of things. But there is one thing that excites them above all else and that is correcting people. Welcome to “The Spec-tacular Game Show”.\n\nIn this fun game show our panelists will be given incorrect statements about the OpenTelemetry Specification or Semantic Convention. The panelists will buzz in, identify what’s wrong, and state the correction. If none of the panelists know the answer the audience will get a chance to answer to steal the point. The panelist (or audience) with the most points wins!\n\nAfter each question we’ll spend a time explaining why the Spec and Semconv is the way it is and highlight how it produces the production-quality telemetry you know and love. Join us for a fun, relaxing, (snarky) panel about everyone’s favorite part of Otel!</article>","contentLength":1356,"flags":null,"enclosureUrl":"https://www.youtube.com/v/ipFVu0dl5Bw?version=3","enclosureMime":"","commentsUrl":null},{"title":"How To Think About Instrumentation Overhead - Jason Plumb, Splunk","url":"https://www.youtube.com/watch?v=fvmzAX_ZyvM","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179123,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nHow To Think About Instrumentation Overhead - Jason Plumb, Splunk\n\nNovice observability practitioners are often overly obsessed with performance. They might approach instrumentation with skepticism and have concerns about latency degradation or resource consumption. This talk is a primer on the topic of instrumentation overhead, and it will teach you how to think about overhead in an observability context. We will cover the causes of overhead and why overhead is so hard to measure and even harder to predict reliably. Lastly, we will present some practical techniques for understanding overhead in your environment and some strategies for coping with it.</article>","contentLength":1042,"flags":null,"enclosureUrl":"https://www.youtube.com/v/fvmzAX_ZyvM?version=3","enclosureMime":"","commentsUrl":null},{"title":"No Dependencies. No Plugins. Just Native OpenTelemetry - Liudmila Molkova, Microsoft","url":"https://www.youtube.com/watch?v=fU6jsw0yaVU","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179124,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nNo Dependencies. No Plugins. Just Native OpenTelemetry - Liudmila Molkova, Microsoft\n\nThe best telemetry starts at the source—inside the client libraries.\nBut in most cases, that means taking a dependency on the OpenTelemetry API from your library. And while it’s stable, minimal, reliable, and safely no-op unless configured—transitive dependencies are still the bane of any library developer’s existence, and most of us try to avoid them.\n\nTo work around this, people reach for abstractions, plugins, bridges, or even OTel forks that break context propagation. The result? A poor user experience. Users must find the right plugin, install it, wire it up—and still hit the diamond dependency problem, now it just affects a subset of users.\n\nBut what if you could take a truly optional dependency? If OpenTelemetry is on the classpath, instrumentation kicks in. If it’s not, no harm done.\nHow hard is that to pull off? How reliable? How performant?\n\nLet’s explore that—through the lens of the next generation of Azure SDKs for Java. Spoiler: it’s easy and fast, and as a side-bonus, we can fall back to logs-based tracing if OTel is not found.</article>","contentLength":1544,"flags":null,"enclosureUrl":"https://www.youtube.com/v/fU6jsw0yaVU?version=3","enclosureMime":"","commentsUrl":null},{"title":"Closing Remarks - Austin Parker, Honeycomb","url":"https://www.youtube.com/watch?v=eDbQfZ9eoNI","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179125,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nClosing Remarks - Austin Parker, Honeycomb</article>","contentLength":425,"flags":null,"enclosureUrl":"https://www.youtube.com/v/eDbQfZ9eoNI?version=3","enclosureMime":"","commentsUrl":null},{"title":"Lightning Talk: Beyond Good Enough: Why We Want a Kotlin API and SDK - Hanson Ho, Embrace","url":"https://www.youtube.com/watch?v=di5nhYvUh6w","date":1751391275,"author":"CNCF [Cloud Native Computing Foundation]","guid":179126,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nLightning Talk: Beyond Good Enough: Why We Want a Kotlin API and SDK - Hanson Ho, Embrace\n\nThe OTel Java API, SDK, and ecosystem are perfectly adequate for Android developer to get OTel instrumentation into their apps. But for a host of reasons, the match is not perfect, especially for developers who only write in Kotlin, which is the recommended development language for Android by Google, not the least of which is the emergence of Kotlin Multiple Platform (KMP) as a means to share code between Android, iOS, and many other platforms.\n\nThis session will outline the reasons why we at Embrace is trying to kick-start the development of a pure Kotlin ecosystem for OTel, starting with an API and SDK implementation, and how we are doing it in a way where mobile developers can get value incrementally without having to wait until every aspect is fully built out.\n\nWe want OTel to feel natural and idiomatic for Android developers, and this is the first step towards that end.</article>","contentLength":1361,"flags":null,"enclosureUrl":"https://www.youtube.com/v/di5nhYvUh6w?version=3","enclosureMime":"","commentsUrl":null}],"tags":["k8s"]}