{"id":"f33v1Y5Z","title":"Latest","displayTitle":"Latest","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":91,"items":[{"title":"firekirin","url":"https://zig.news/firekirin000/firekirin-2nkk","date":1739646103,"author":"firekirin","guid":438,"unread":true,"content":"<p>Fire Kirin is a popular mobile game of United State that mixes shooting and fishing.</p>","contentLength":84,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"xAI‚Äôs ‚ÄúColossus‚Äù supercomputer raises health questions in Memphis","url":"https://techcrunch.com/2025/02/15/xais-colossus-supercomputer-raises-health-questions-in-memphis/","date":1739645584,"author":"Connie Loizos","guid":58,"unread":true,"content":"<p>Elon Musk‚Äôs AI startup xAI plans to continue using 15 gas turbines to power its ‚ÄúColossus‚Äù supercomputer in Memphis, Tennessee, according to an operating permit with the Shelby County Health Department for non-stop turbine use from June 2025 to June 2030. Why does it matter? The Commercial Appeal, a news outlet that obtained the documents, [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":416,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Perplexity launches its own freemium ‚Äòdeep research‚Äô product","url":"https://techcrunch.com/2025/02/15/perplexity-launches-its-own-freemium-deep-research-product/","date":1739644754,"author":"Anthony Ha","guid":57,"unread":true,"content":"<p>Perplexity has become the latest AI company to release an in-depth research tool, with a new feature announced Friday. Google unveiled a similar feature for its Gemini AI platform in December. Then OpenAI launched its own research agent earlier this month. All three companies even have given the feature the same name: Deep Research. The [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":407,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bored With Chess? Magnus Carlsen Wants to Remake the Game","url":"https://games.slashdot.org/story/25/02/15/053254/bored-with-chess-magnus-carlsen-wants-to-remake-the-game?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739644440,"author":"EditorDavid","guid":323,"unread":true,"content":"\"Magnus Carlsen, the world's top chess player, is bored of chess,\" the Washington Post wrote Friday:\n\nCarlsen has spent much of the past year appearing to dismiss the game he has mastered: It was no longer exciting to play, he told a podcast in March. In December, he withdrew from defending a world championship because he was penalized for wearing jeans to the tournament. \nHow would the world's best player spice up the game? Change the rules, and add a touch of reality TV. \n\nTen of the world's top players gathered in a German villa on the Baltic coast this week to play in the first tournament of a new chess circuit, the Freestyle Chess Grand Slam Tour, that Carlsen co-founded. The twist: The tour randomizes the starting positions of the chess board's most important pieces, so each game begins with the queen, rooks and knights in a jumble. [It's sometimes called \"Chess960\" or Fischer random chess ‚Äî with both players starting with the same arrangement of pieces.] Players have to adapt on the fly. Carlsen is backed by a cadre of investors who see a chance to dramatize chess with the theatrics of a television show. Players wear heart-rate monitors and give confession-booth interviews mid-match where they strategize and fret to the audience. Some purists are skeptical. So is the International Chess Federation, which sent a barrage of legal threats to Freestyle Chess before it launched this week's event. \nAt stake is a lucrative global market of hundreds of millions of chess players that has only continued to grow since the coronavirus pandemic launched a startling chess renaissance ‚Äî and, perhaps, the authority to decide if and how a centuries-old game should evolve... The format is an antidote to the classical game, where patterns and strategies have been so rigorously studied that it's hard to innovate, Carlsen said. \"It's still possible to get a [competitive] game, but you have to sort of dig deeper and deeper,\" Carlsen said. \"I just find that there's too little scope for creativity.\" \n\nThe article also includes this quote from American grand master Hikaru Nakamura who runs a chess YouTube channel with 2.7 million subscribers). \"An integral part of regular chess is that when you play, you spend hours preparing your opening strategy before the game. But with Fischer Random ... it's a little bit looser and more enjoyable.\" And German entrepreneur Jan Henric Buettner (one of the investors) says they hope to bring the drama of Formula One racecars. (\"Cameras mounted at table level peer up at each player during games,\" the article notes at one point.) \n\nThe first Freestyle Chess Grand Slam Tour (with a $750,000 prize pool) concluded Friday, according to the article, but \"Carlsen did not play in it,\" the Post points out. \"He was upset in the semifinals by German grand master Vincent Keymer.\" Carlsen's reaction? \"I definitely find Freestyle harder.\" \n\nBut Chess.com reports that Carlsen will be back to playing regular chess very soon:\n\nGlobal esports powerhouse Team Liquid has announced the signings of not just one, but two superstars of chess. Five-time World Champion and world number-one Magnus Carlsen and the 2018 challenger, world number-two Fabiano Caruana will represent the club ahead of the 2025 Esports World Cup (EWC)... Carlsen and Caruana, fresh from competing in the Weissenhaus Freestyle Chess Grand Slam, will first represent Team Liquid in the $150,000 Chessable Masters, which begins on February 16 and serves as the first of two qualifying events in the 2025 Champions Chess Tour. The top-12 players from the tour qualify for the EWC. \n\nIn an announcement video Carlsen reportedly trolls the FIDE, according to Indian Express. \"The announcement video sees Carlsen wear a Team Liquid jersey along with a jacket and jeans. He then asks: 'Do I have to change?' To this, someone responds: 'Don't worry, we're pretty chill in esports. Welcome to Team Liquid.'\"","contentLength":3925,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI teases a ‚Äòsimplified‚Äô GPT-5 model","url":"https://techcrunch.com/2025/02/15/openai-teases-a-simplified-gpt-5-model/","date":1739642700,"author":"Cody Corrall","guid":56,"unread":true,"content":"<p>Welcome back to Week in Review. This week we‚Äôre looking at OpenAI canceling the release of o3; TikTok returning to U.S. app stores nearly a month after it was removed; more complications in Elon Musk‚Äôs bid to buy OpenAI for $97.4 billion; and more! Let‚Äôs do it. OpenAI effectively canceled the release of o3, which [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":389,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Infocon: green","url":"https://isc.sans.edu/diary.html?rss","date":1739641203,"author":"","guid":450,"unread":true,"content":"<article>The Danger of IP Volatility</article>","contentLength":27,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"'Mass Theft': Thousands of Artists Call for AI Art Auction to be Cancelled","url":"https://slashdot.org/story/25/02/15/0351257/mass-theft-thousands-of-artists-call-for-ai-art-auction-to-be-cancelled?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739640840,"author":"EditorDavid","guid":322,"unread":true,"content":"An anonymous reader shared this report from the Guardian:\n\nThousands of artists are urging the auction house Christie's to cancel a sale of art created with artificial intelligence, claiming the technology behind the works is committing \"mass theft\". The Augmented Intelligence auction has been described by Christie's as the first AI-dedicated sale by a major auctioneer and features 20 lots with prices ranging from $10,000 to $250,000... \nThe British composer Ed Newton-Rex, a key figure in the campaign by creative professionals for protection of their work and a signatory to the letter, said at least nine of the works appearing in the auction appeared to have used models trained on artists' work. However, other pieces in the auction do not appear to have used such models. \nA spokesperson for Christie's said that \"in most cases\" the AI used to create art in the auction had been trained on the artists' \"own inputs\". \n\nMore than 6,000 people have now signed the letter, which states point-blank that \"Many of the artworks you plan to auction were created using AI models that are known to be trained on copyrighted work without a license.\"\n\nThese models, and the companies behind them, exploit human artists, using their work without permission or payment to build commercial AI products that compete with them. Your support of these models, and the people who use them, rewards and further incentivizes AI companies' mass theft of human artists' work. We ask that, if you have any respect for human artists, you cancel the auction. \n\nLast week ARTnews spoke to Nicole Sales Giles, Christie's vice-president and director of digital art sales (before the open letter was published). And Giles insisted one of the major themes of the auction is \"that AI is not a replacement for human creativity.\"\n\"You can see a lot of human agency in all of these works,\" Giles said. \"In every single work, you're seeing a collaboration between an AI model, a robot, or however the artist has chosen to incorporate AI. It is showing how AI is enhancing creativity and not becoming a substitute for it.\" \n\nOne of the auction's headline lots is a 12-foot-tall robot made by Matr Labs that is guided by artist Alexander Reben's AI model. It will paint a new section of a canvas live during the sale every time the work receives a bid. Reben told ARTnews that he understands the frustrations of artists regarding the AI debate, but he sees \"AI as an incredible tool... AI models which are trained on public data are done so under the idea of 'fair use,' just as search engines once faced scrutiny for organizing book data (which was ultimately found to fall under fair use),\" he said.... \"AI expands creative potential, offering new ways to explore, remix, and evolve artistic expression rather than replace it. The future of art isn't about AI versus artists ‚Äî it's about how artists wield AI to push boundaries in ways we've never imagined before....\" \n\nDigital artist Jack Butcher has used the open letter to create a minted digital artwork called Undersigned Artists. On X he wrote that the work \"takes a collective act of dissent ‚Äî an appeal to halt an AI art auction ‚Äî and turns it into the very thing it resists: a minted piece of digital art. The letter, originally a condemnation of AI-generated works trained on unlicensed human labor, now becomes part of the system it critiques.\" \n\nChristie's will accept cryptocurrency payments for the majority of lots in the sale.\n","contentLength":3474,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Programmer's Guide to Game Design: The Major Ingredients You Should Know","url":"https://hackernoon.com/a-programmers-guide-to-game-design-the-major-ingredients-you-should-know?source=rss","date":1739638805,"author":"Chenuli J.","guid":83,"unread":true,"content":"<p>Software developers spend their whole time with complicated problems, and they try to learn almost everything about algorithms, structures, frameworks, and blah-blah-blah. While playing games and coffee have become stress-busters in our lives, why can't building games be the best one?</p><p>\\\nEven though some people find game development insane, it‚Äôs easy for software developers because they have almost every skill needed: math, Programming, UX/UI, and the usual stuff. If a normal person takes 6 months to learn a Game Engine, the Developer will take a maximum of 3 months or less.</p><p>\\\nMany people don‚Äôt know this, but I started my tech career as a game developer, although I later turned my back on game development and became a Python developer. And no lies, they were a few of the best years in my life.</p><p>\\\nThis article is dedicated to any developer who wants to try something new or exciting (which is game development, yes). Scroll down!</p><p>Software developers who are interested in game development have a remarkable head start. Programming skills are the core of game development. Even if you‚Äôre more comfortable with Swift or Ruby, which is not commonly used in game development, you can quickly pick up other Object-oriented programming languages that are much more commonly used for game development, like C# or C++, easier than anyone!</p><p>\\\nIf you're a Python lover, you will love to hear this: There are really good, AAA games made with Python such as Battlefield 2, EVE Online, Civilization IV, and more!</p><p>Not only Python, but almost every commonly used Programming language has libraries that support making games. For example:</p><ul><li>Flutter has Flame, a game engine that supports Flutter language.</li><li>Ruby has Gosu, a library that makes it easy to develop 2D games.</li><li>Python has PyGame, a library that empowers you to create both 2D and 3D games.</li><li>Phaser allows you to create games with JavaScript and HTML5.</li></ul><p>For every beginner, either a software engineer or a novice, I give one common piece of advice‚Äî Start as small as possible. It doesn't matter how small pieces of code it has or how messy it is, you've won the challenge!</p><p>\\\nIf you love simple 2D games, I would recommend that you make a Pong game. Pong features simple graphics (2 rectangles and a circle) you can create on your own, minimal sounds, and a game loop. If you want to learn about making multiplayer games, allow matches to occur between two human players over a network. If you want to learn about AI, allow the player to challenge the computer.</p><p>\\\nAnd if you love 3D games like me, start with Cube Run. I haven't made it without a Game engine because, 3D becomes a bit harder with Python or others but with Unity, it's the best game I recommend to take a start.</p><h2><strong>Major Ingredients of A Game</strong></h2><p>If you make a cake without Sugar, no one will eat it. Except for diabetic people, of course, like my mom.</p><p>\\\nThe same goes for video games. It‚Äôs full of ingredients, some of which are required for every game and some of which are optional. I‚Äôll introduce them briefly.</p><p>In many games, the level itself is a challenge, trickier than the smartest AI enemies. Series like Tomb Raider also emphasize complex and challenging level design.</p><p>\\\nWhile the advent of open-world games like GTA may make the level design seem less important than in bygone times, it‚Äôs worth noting that even open-world games have ‚Äòlevels‚Äô, such as a particular building, structure, or map area you must enter to achieve a goal.</p><p>\\\nTo reduce player feelings of being railroaded, levels will ideally have multiple possible paths through them.</p><p>In games, you can‚Äôt really rely on natural light sources to illuminate your video game.</p><p>\\\n(You don‚Äôt think there‚Äôs a sun inside a game engine, do you?)</p><p>\\\nEvery light source in a video game must be added by hand and light manipulation is incredibly important. Light can be used for all of the following:</p><ul><li>Controlling the player‚Äôs ability . In horror and survival games, light is a resource that must be carefully managed.</li></ul><ul><li>Controlling a player‚Äôs ability . In games with an element of stealth, dark areas can provide cover while well-lit areas represent a difficult challenge.</li></ul><ul><li>Setting the mood. The quality of light can be used to set the mood, with sunny and bright lighting associated with happy times and brooding light associated with dark times.</li></ul><ul><li>Lighting the way. Light can be used to direct the player‚Äôs attention. The best-designed levels in video games often make clever use of light to guide the player in the right direction when they might otherwise be lost.</li></ul><p>Game art is the medium through which the game world is presented to the player. In a sense, all the programming effort that goes into making video games is an attempt to turn game art into something that feels responsive and alive. Game art is an umbrella term that includes textures, 3D models, sprites, particle effects, and lighting.</p><p>\\\nAnd yes, it‚Äôs a broad area, best to not cover it in this article.</p><p>Unlike in the real world, video game sounds cannot be made by accident. Every sound in the game universe must be added by hand, and it is through layering these sounds that the game world starts to feel lifelike. You also need to be mindful of sounds triggered by the player, by other characters, and ambient sounds that create the game world environment.</p><p>\\\nAs an example, the player accidentally hits a metal object; if it doesn't emit a sound, it doesn't feel natural, or the scientist who claimed that metals have sonorous properties got it wrong.</p><p>\\\nAnother ever-present fact of video games is music, used to create an emotional response in the player or removed entirely to leave behind an eerie silence. Unlike most compositions, video game music must loop seamlessly. It must also transition smoothly to new compositions based on in-game events, such as being spotted by an enemy.</p><p>\\\nHere are some of my favorite places to find sound:</p><p>You have made graphics, levels, and everything but the whole game feels like a dead body. If you want your game to be alive, you need some lines of code.</p><p>\\\nMost of my readers are probably a developer already, so you probably know the importance of programming anywhere. I'm not going to give a lecture on \"what is programming\", but here‚Äôs a bit about programming in game design.</p><p>\\\nFirst of all, you need to decide one thing: Are you making a game by using a Game Engine + Language or building a game from scratch with Python or something? It's your choice but let me help you: If you're going to build games for fun, choose the first option because it's easier. </p><p>\\\nAs I said in the beginning, programmers always juggle complex problems so you probably shouldn't take more stress with that too.</p><p>\\\n(Game Engines are the software used to create video games.)</p><p>\\\nThere are many of them, but the most popular ones are:</p><ul><li><p>Unity (Great for beginners, recommended)</p></li></ul><p>Next, choose a language to get started. Mostly, C# and C are used. Don't worry, you already got a headstart in knowing at least one programming language; most people start even before they know what the word ‚Äúprogramming‚Äústands for.</p><p>\\\nAnd that‚Äôs about it. Well, of course, there are many other optional ingredients that video games consist of but in general, the above are basically the starter pack.</p><p>Starting game development is easier for software developers than anyone. As someone with programming skills, you have a massive head-start on the average video game hobbyist who wants to learn how to make a game. If I scroll to the top of the article, I can list the below points as key takeaways.</p><ul><li><p>It's a lot easier to find a game dev library in your comfortable programming language to get started.</p></li><li><p>Start with a small game, maybe a clone of an existing game.</p></li><li><p>Game Engines make your life a lot easier.</p></li><li><p>If you want to make a big, impressive game but don‚Äôt have a lot of time to spare, consider teaming up with others or joining a modding community.</p></li></ul><p>And that's all for now, Happy Designing! üèé</p><p>\\\nIf you loved this article, make sure to subscribe using your email, so you can read all my content inside your inbox without missing any!</p><p>It‚Äôs totally free of charge and I don‚Äôt even have time to send spam emails.</p>","contentLength":8132,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Marc Andreessen dreams of making a16z a lasting company, beyond partnerships","url":"https://techcrunch.com/2025/02/15/marc-andreessen-dreams-of-making-a16z-a-lasting-company-beyond-partnerships/","date":1739638800,"author":"Marina Temkin","guid":55,"unread":true,"content":"<p>Many venture industry observers have wondered whether Andreessen Horowitz, a firm that manages $45 billion, has its sights on eventually becoming a publicly traded company. Co-founder Marc Andreessen said he isn‚Äôt ‚Äúchomping at the bit to take the firm public,‚Äù on this week‚Äôs Invest Like the Best podcast. But he discussed his goal of building [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":420,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ISS Astronauts Give Space-to-Earth Interview Weeks Before Finally Returning to Earth","url":"https://science.slashdot.org/story/25/02/15/033223/iss-astronauts-give-space-to-earth-interview-weeks-before-finally-returning-to-earth?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739637240,"author":"EditorDavid","guid":321,"unread":true,"content":"Last June two NASA astronauts flew to the International Space Station on the first crewed test flight of Boeing's Starliner. But they aren't stranded there, and they weren't abandoned, the astronauts reminded CNN this week in a rare space-to-earth interview:\n\n\"That's been the rhetoric. That's been the narrative from day one: stranded, abandoned, stuck ‚Äî and I get it. We both get it,\" [NASA astronaut Butch] Wilmore said. \"But that is, again, not what our human spaceflight program is about. We don't feel abandoned, we don't feel stuck, we don't feel stranded.\" Wilmore added a request: \"If you'll help us change the rhetoric, help us change the narrative. Let's change it to 'prepared and committed.' \n\n\"That's what we prefer,\" he said... \n[NASA astronaut Suni] Williams also reiterated a sentiment she has expressed on several occasions, including in interviews conducted before she left Earth. \"Butch and I knew this was a test flight,\" she told CNN's Cooper, acknowledging the pair has been prepared for contingencies and understood that the stay in space might be extended. \"We knew that we would probably find some things (wrong with Starliner) and we found some stuff, and so that was not a surprise,\" she said. \nWhen Cooper opened the interview by asking the astronauts how they're doing, Williams answers \"We're doing pretty darn good, actually,\" pointing out they had plenty of food and great crew members. And Wilmore added that crews come to the space station on a careful cycle, and \"to alter that cycle sends ripple effects all the way down the chain. We would never expect to come back just special for us or anyone unless it was a medical issue or something really out of the circumstances along those lines. So we need to come back and keep the normal cycle going...\" \n\nCNN's article notes a new announcement from NASA Tuesday that the astronauts might return a couple weeks early \"after opting to change the SpaceX Crew Dragon capsule it will use.\" That mission's targeted launch date is now March 12. \n\nIn the meantime, Williams says in the interview, \"We do have some internet connection up here, so we can get some internet live. We've gotten football. It's been this crew's go-to this past fall. Also YouTube or something like that. It's not continuous ‚Äî it has chunks of time that we get it. And we use that same system also to make phone calls home, so we can talk to our families, and do videoconferences even on the weekends as well. This place is a pretty nice place to live, for the most part.\" \n\nAnd they're also \"working on with folks on the ground\" to test the NASA's cube-shaped, free-flying robotic Astrobees.","contentLength":2649,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Deepseek R1 Distill 8B Q40 on 4 x Raspberry Pi 5, 6.43 tok/s (eval 11.68 tok/s)","url":"https://github.com/b4rtaz/distributed-llama/discussions/162","date":1739635889,"author":"b4rtazz","guid":280,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43059579"},{"title":"NTSYNC Driver Fix Being Worked On For Proper User Permissions","url":"https://www.phoronix.com/news/Linux-NTSYNC-Permissions-Issue","date":1739635532,"author":"Michael Larabel","guid":365,"unread":true,"content":"<article>One of the great new features of Linux 6.14 is the NTSYNC driver being completed for better emulating the Microsoft Windows NT synchronization primitives so that software like Wine and Proton (Steam Play) can provide for better performance when running Windows games on Linux. But it turns out an oversight up to now has meant that in practice it's not really too usable out-of-the-box...</article>","contentLength":388,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The HackerNoon Newsletter: No Startup Has Ever Failed Because it Didn‚Äôt Have a Blog (2/15/2025)","url":"https://hackernoon.com/2-15-2025-newsletter?source=rss","date":1739635457,"author":"Noonification","guid":82,"unread":true,"content":"<p>ü™ê What‚Äôs happening in tech today, February 15, 2025?</p><p>By <a href=\"https://hackernoon.com/u/realgpp\">@realgpp</a> [ 9 Min read ] Learn how to read thread dumps and take control of your application‚Äôs runtime behaviour.\n <a href=\"https://hackernoon.com/how-to-expose-and-fix-hidden-bottlenecks-in-adobe-experience-manager\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bigmao\">@bigmao</a> [ 6 Min read ] The case against content marketing, and how to do inbound marketing in the post-content age.  <a href=\"https://hackernoon.com/no-startup-has-ever-failed-because-it-didnt-have-a-blog\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/loadbalancer\">@loadbalancer</a> [ 5 Min read ] Researchers have optimized Layer-7 load balancing using programmable SmartNICs to improve efficiency, cost, and energy use in cloud data centers. <a href=\"https://hackernoon.com/cloud-giants-spend-a-fortune-on-load-balancersthis-research-could-change-that\">Read More.</a></p><p>üßë‚Äçüíª What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ‚úåÔ∏è</p>","contentLength":749,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Jeep Claims 'Software Glitch' Disabled Opting-Out of In-Vehicle Pop-Up Ads in 'a Few' Cases","url":"https://tech.slashdot.org/story/25/02/15/0149202/jeep-claims-software-glitch-disabled-opting-out-of-in-vehicle-pop-up-ads-in-a-few-cases?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739633640,"author":"EditorDavid","guid":320,"unread":true,"content":"Remember Jeep's new in-dash pop-up ads which reportedly appeared every time you stopped? \n\"Since I'm a journalist, or at least close enough, I decided that I should at least get Stellantis/Jeep's side of things,\" writes car-culture site The Autopian:\n\n\nWould Stellantis do something so woefully misguided and annoying? I reached out to our Stellantis/Jeep contact to ask and was initially told that they were \"investigating\" on their end, which to me felt like a stalling tactic while the proper ass-covering plans were conceived. I eventually got this response from a Stellantis spokesperson: \n\n \"This was an in-vehicle message designed to inform Jeep customers about Mopar extended vehicle care options. A temporary software glitch affected the ability to instantly opt out in a few isolated cases, though instant opt-out is the standard for all our in-vehicle messages. Our team had already identified and corrected the error, and we are following up directly with the customer to ensure the matter is fully resolved...\" \n\nI suppose a glitch is possible, though I've not seen any examples of this ad popping up with the instant opt-out option available, but I guess it must exist, since not all Jeep owners seem to have had to deal with these ads. I suspect if this was happening to more people than these \"few isolated cases\" we'd still be cleaning up from the aftermath of the riots and uprisings. \n\nBecause, as they write, \"Really, I can't think of a quicker way to incur the wrath of nearly every human...\"","contentLength":1513,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Carbon capture more costly than switching to renewables, researchers find","url":"https://techxplore.com/news/2025-02-carbon-capture-renewables.html","date":1739631990,"author":"Brajeshwar","guid":279,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058997"},{"title":"Dust from car brakes more harmful than exhaust, study finds","url":"https://e360.yale.edu/digest/brake-pads-lung-damage-study","date":1739631975,"author":"Brajeshwar","guid":278,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058993"},{"title":"What is an encryption backdoor?","url":"https://techcrunch.com/2025/02/15/what-is-an-encryption-backdoor/","date":1739631600,"author":"Natasha Lomas","guid":54,"unread":true,"content":"<p>Talk of backdoors in encrypted services is once again doing the rounds after reports emerged that the U.K. government is seeking to force Apple to open up iCloud‚Äôs end-to-end encrypted (E2EE) device backup offering. Officials were said to be leaning on Apple to create a ‚Äúbackdoor‚Äù in the service that would allow state actors to [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":404,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Antarctica's Only Insect","url":"https://www.404media.co/antarcticas-only-insect/","date":1739628013,"author":"Becky Ferreira","guid":384,"unread":true,"content":"<img src=\"https://www.404media.co/content/images/2025/02/CleanShot-2025-02-14-at-09.17.41@2x.png\" alt=\"Antarctica's Only Insect\"><p>Welcome <a href=\"https://www.404media.co/neanderthals-would-rather-die-than-talk-to-you-3/\" rel=\"noreferrer\">back to the Abstract</a>, 404 Media's weekly roundup of scientific studies to distract us from our present dystopia!</p><p>This week, we are traveling back in time to 16th century Transylvania, so please make sure you are up to date on your bubonic plague shots. A study reconstructed wild weather events through the eyes of record-keepers during this fraught period, opening a tantalizing window into climate extremes unleashed by a vengeful God (according to contemporary reports).</p><p>Then: making love the medaka way (get those anal fins ready). Next, the chillest insect in Antarctica (also: the only one). Finally, these turtles will dance for food, and yes, it‚Äôs very cute.</p><h3><strong>The Haunting Weather Reports of 16th Century Transylvania</strong></h3><p>Rejoice, for this week has delivered one of the best varieties of study: Science via historical documents. Sure, ice cores and geological strata are great for reconstructing past climates, but nobody can bitch about the weather better than a good old-fashioned red-blooded member of team .&nbsp;</p><p>To that end, researchers searched for mentions of weird weather across a trove of diaries, monastery records, travel notes, and other documents from 16th century Transylvania, during a ‚Äúpivotal moment in climate history‚Äù when a centuries-long cooling event called the Little Ice Age intensified, according to researchers led by Ovidiu RƒÉzvan Gaceu of the University of Oradea.&nbsp;</p><p>These types of studies are packed with colorful human testimonies that can corroborate natural records. More importantly, though, they are just fun to read, especially during such an evocative time and place, freshly haunted by the vampiric spirit of Vlad the Impaler. Some highlights:</p><p>In August 1526, heavy rainfall caused freak floods in Bra≈üov that ‚Äúwashed the walls of the fortress, demolished the main gate, and the fish also got caught in the big church,‚Äù according to the Annals of Bra»ôov. Fish in the church! The ultimate baptism.&nbsp;</p><p>&nbsp;In autumn 1553, people in the city of Cluj reported unusual weather events including ‚ÄúOctober strawberries.‚Äù For real, October is for pumpkins, get out of here with the strawbs. Turned out it was a bad omen‚Äîthere was a plague the following winter. Keep that in mind if you see any late autumn strawberries: Kill on sight.</p><p>Naturally, a lot of these accounts are heartbreaking. Locusts ‚Äúsometimes covered the whole sky and destroyed grain crops‚Äù and caused terrible famines. A storm-related fire ‚Äúkilled 14 people and made 60 poor.‚Äù On September 29, 1582, ‚Äúthere was such a big storm, as it was said that it had never been seen before in the city of Cluj, which uprooted the trees and raised the roofs of the houses, people believed that it is sent by divinity to punish the crimes committed by them.‚Äù&nbsp;</p><p>I mean, I‚Äôm not saying these people weren‚Äôt doing crimes. It‚Äôs 16th century Transylvania. Do what you gotta do. But that's not why there is extreme weather. You‚Äôre just in the Little Ice Age.&nbsp;</p><p>The study ultimately identified ‚Äúmultiple pieces of evidence associated with extreme weather events, including 40 unusually warm summers and several years of excess precipitation or drought.‚Äù Taken together with natural archives, the documents paint a picture of troubled times, exacerbated by an unstable climate and possible emergent vampires. Relatable!&nbsp;</p><p>Valentine‚Äôs Day is over, but the romantic mood is still in the air‚Äîor in the water, if you‚Äôre a medaka (flawless segue). Scientists have discovered that wild medaka, also known as Japanese rice fish, are fans of late-night booty calls, which is a behavior that has not been observed in captivity.</p><p>‚ÄúAlthough medaka and other model organisms are invaluable in laboratories, their ecology in the wild remains largely unknown,‚Äù said researchers led by Yuki Kondo of Osaka Metropolitan University. ‚ÄúThis study showed that medaka in the wild initiate spawning during late nocturnal hours and exhibit vigorous courtship behavior at midnight.‚Äù</p><p>Kondo and her colleagues recorded this vigorous courtship by placing GoPros into streams over the course of several summer nights in Gifu, Japan. The tapes revealed that medaka like to spawn in the dark, possibly to avoid predators during copulation. The results ‚Äúprovide the first empirical evidence that medaka mating begins significantly earlier than previously reported in the laboratory.‚Äù&nbsp;&nbsp;</p><p>For anyone who feels clueless about courtship, may I offer a page from the Medaka Sutra:&nbsp;</p><p>‚ÄúThe spawning behavior of medaka follows a sequence of events: the male chases the female (following), the male swims rapidly around the female (quick circle), the male wraps his dorsal and anal fins around the female (wrapping), the female releases eggs, the male releases sperm (egg and sperm release), and the male leaves the female (leaving),‚Äù according to Kondo‚Äôs team.</p><p>The only true love language is, indeed, spoken with anal fins.</p><p>Major bonus points also go to Osaka Metropolitan University‚Äôs press team for <a href=\"https://www.eurekalert.org/multimedia/1058890?ref=404media.co\"><u>throwing together this version</u></a> of Edward Hopper‚Äôs famous ‚ÄúNighthawks‚Äù painting with medaka getting drinks at a bar that is also named Medaka. It is genuinely one of the most inspired public relations efforts I have ever seen, and I‚Äôm going to get a print of it to hang on my wall.</p><h3><strong>The Insect at the Edge of Earth</strong></h3><p>, or the Antarctic midge, is the only insect that lives year-round on its namesake continent. Do you know how weird you have to be to be the  insect somewhere? But this midge doesn‚Äôt care. It just lives out its bug life, which lasts two years, in an otherwise bugless wasteland.&nbsp;</p><p>Humans definitely care about the midge, though‚Äîhow could we not? What is it doing there? How is it not dead? What can it teach us about cryopreservation? These questions are addressed in a new study that resolved mysteries about the animal‚Äôs interesting life cycle.</p><p>‚ÄúFreeze tolerance and cryoprotective dehydration are cold tolerance strategies used by various invertebrate species in polar regions and indeed,  utilises both for overwintering,‚Äù said researchers led by Mizuki Yoshida of the Ohio State University, who completed the project while at Osaka Metropolitan University (OMU killing it this week).&nbsp;</p><p>‚ÄúLarvae that are frozen in ice and cryoprotectively dehydrated readily survived 32 days of simulated overwintering,‚Äù the team said. ‚ÄúUnlike many insects restricted to highly specific microhabitats,  larvae inhabit a remarkably diverse range of substrates that differ in vegetation, substrate type, slope, drainage, and thermal and hydric conditions.‚Äù</p><p>I love the phrasing of ‚Äúreadily survived‚Äù as if the midges were eager to show off their cryoprotective superpowers. After this 32-day period they emerged with ‚ÄúThat all you got?‚Äù energy. By studying the bugs in these simulated conditions, the researchers confirmed that they rely on multiple overwintering strategies, including a state of arrested development called ‚Äúobligate diapause.‚Äù&nbsp;</p><p>‚ÄúDiapause has long been assumed to be uncommon in Antarctic species, but the present study reveals that  utilises diapause for seasonal adaptation, as in many temperate species,‚Äù Yoshida and her colleagues said.&nbsp;</p><p>In addition to being the only endemic Antarctic insect, this midge has the smallest genome of any known insect while also being the largest fully terrestrial animal on the continent, even though it‚Äôs only a few millimeters long. In other words, it is the biggest animal in Antarctica that doesn‚Äôt fly or swim. Okay, Antarctic midge. You just keep doing you.</p><p>Last, turtles do a little victory dance when they find food. Yes, it is cute. Yes, there is a video.</p><p>The footage (along with <a href=\"https://youtu.be/IcI6yHr6JXo?si=DAGsav7HY4S3uhKn&amp;ref=404media.co\"></a>) is part of a study that tested if turtles could distinguish the magnetic signatures of two geographical areas. When the turtles were exposed to signatures associated with an area they associated with food, they danced in anticipation of a meal, demonstrating that they could tell the signals apart‚Äîand party accordingly.&nbsp;&nbsp;</p><p>‚ÄúHallmarks of the behaviour include some or all of the following: tilting the body vertically, holding the head near or above water, opening the mouth, rapid alternating movement of the front flippers, and, occasionally, even spinning in place, hence the name ‚Äòturtle dance,‚Äô‚Äù said researchers led by Kayla Goforth of Texas A&amp;M University. ‚ÄúTurtles exhibited significantly higher levels of turtle dance behaviour when experiencing the field in which they had been fed.‚Äù</p><p>With that, let‚Äôs all tilt vertically, spin in place, and shell-abrate the long weekend.&nbsp;</p><p>Thanks for reading! See you next week.&nbsp;&nbsp;</p>","contentLength":8613,"flags":null,"enclosureUrl":"https://www.404media.co/content/images/2025/02/CleanShot-2025-02-14-at-09.17.41@2x.png","enclosureMime":"","commentsUrl":null},{"title":"Paragraf Is Building a \"Blank Canvas\" Graphene Foundry","url":"https://spectrum.ieee.org/paragraf-graphene-foundry","date":1739628003,"author":"Liam Critchley","guid":98,"unread":true,"content":"<p>The company wants to make graphene sensors more accessible to industries</p>","contentLength":72,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81NjQ2NTMyMC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc4MzQyMzgzM30.wJGF4-_y2VSVjXLsYFhhL9DuC-xHiTHWB-Ciq4DHQTU/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Diablo hackers uncovered a speedrun scandal","url":"https://arstechnica.com/gaming/2025/02/the-diablo-hackers-that-debunked-a-record-speedrun/","date":1739628000,"author":"pitwin","guid":277,"unread":true,"content":"<p>But simply splitting a run into segments doesn't explain away all of the problems the TAS team found. Getting Naj's Puzzler on dungeon level 9, for instance, still requires outside modification of a save file, which is specifically prohibited by <a href=\"https://kb.speeddemosarchive.com/Rules\">longstanding Speed Demos Archive rules</a> that \"manually editing/adding/removing game files is generally not allowed.\" Groobo's apparent splicing of multiple game versions and differently seeded save files also seems to go against SDA rules, which say that \"there obviously needs to be continuity between segments in terms of inventory, experience points or whatever is applicable for the individual game.\"</p><p>After being presented with the TAS team's evidence, SDA <a href=\"https://speeddemosarchive.com/\">wrote</a> that \"it has been determined that Groobo's run very likely does not stem from only legitimate techniques, and as such, has itself been banished barring new developments.\" But Groobo's record is <a href=\"https://www.guinnessworldrecords.com/world-records/110580-fastest-completion-of-an-rpg-videogame\">still listed as the \"Fastest completion of an RPG videogame\"</a> by Guinness World Records, which has not offered a substantive response to the team's findings (Guinness has not responded to a request for comment from Ars Technica).</p><figure><div><div>\n      A recent  speedrun on a confirmed legitimate dungeon seed.\n\n          </div></div></figure><p>This might seem like a pretty petty issue to spend weeks of time and attention debunking. But at a recent presentation attended by Ars, Cecil said he was motivated to pursue it because \"it did harm. Groobo's alleged cheating in 2009 completely stopped interest in speedrunning this category [of ]. No one tried, no one could.\"</p><p>Because of Groobo's previously unknown modifications to make an impossible-to-beat run, \"this big running community just stopped trying to run this game in that category,\" Cecil said. \"For more than a decade, this had a chilling impact on that community.\" With Groobo's run out of the way, though, new runners are <a href=\"https://www.youtube.com/watch?v=bXG1vW6VEKA\">setting new records on confirmed legitimate RNG seeds</a>, and <a href=\"https://www.youtube.com/watch?v=F9mn5CpQCFw\">with the aid of TAS tools</a>.</p><p>In the end, Cecil said he hopes the evidence regarding Groobo's run will make people look more carefully at other record submissions. \"Groobo had created a number of well-respected ... speedruns,\" he said. \"[People thought] there wasn't any good reason to doubt him. In other words, there was bias in familiarity. This was a familiar character. Why would they cheat?\"</p>","contentLength":2302,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058522"},{"title":"These Google Photos alternatives offer tons of storage options at a reasonable price","url":"https://techcrunch.com/2025/02/15/these-google-photos-alternatives-offer-tons-of-storage-options-at-a-reasonable-price/","date":1739628000,"author":"Ivan Mehta","guid":53,"unread":true,"content":"<p>Google Photos is a great service for storing images across devices. But Google Drive and Gmail only offer 15GB of storage for free. Google Photos used to offer free unlimited storage of images, but that is not the case anymore. If you are looking for a better photo storage plan, different features, or just want [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":381,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: I Built a Reddit-style Bluesky client ‚Äì still rough, but open to ideas","url":"https://threadsky.app/","date":1739625557,"author":"lakshikag","guid":308,"unread":true,"content":"<p>A place for solo or small-team developers to discuss game development. Showcase progress, share tips, ask for help, etc.</p>","contentLength":120,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43058285"},{"title":"Beyond Chat: Bringing Models to The Canvas ‚Ä¢ Lu Wilson ‚Ä¢ YOW! 2024","url":"https://www.youtube.com/watch?v=pLvMsGG7zE8","date":1739624470,"author":"GOTO Conferences","guid":427,"unread":true,"content":"<article>This presentation was recorded at YOW! Australia 2024. #GOTOcon #YOW\nhttps://yowcon.com\n\nLu Wilson - Software Engineer at tldraw @TodePond \n\nRESOURCES\nhttps://bsky.app/profile/todepond.com\nhttps://mastodon.social/@TodePond\nhttps://twitter.com/TodePond\nhttps://www.todepond.com\n\nLinks\nhttps://tldraw.dev\nhttps://makereal.tldraw.com\nhttps://drawfast.tldraw.com\nhttps://teach.tldraw.com\n\nABSTRACT\nWhenever a new technology appears, our first instinct as developers is to offer \"text\" as the primary method of interaction. This has happened throughout computing history, with the computer terminal, with early smartphones, and now it's happening again with AI.\n\nAt tldraw, we‚Äôve been working on moving AI interaction away from the chat-based interface, towards a richer canvas environment. It hasn't been easy! I'll show you all the challenges we've faced, and how we're currently overcoming them. Some of the solutions have been surprising. [...]\n\nTIMECODES\n00:00 Intro\n00:58 The canvas\n06:16 Beyond chat?\n07:09 Demo\n09:25 Demo: Make Real\n14:52 Demo: Draw Fast\n19:01 Demo: Teach\n27:28 Demo: Computer\n35:42 Demo: Fight Simulator\n28:13 Conclusion\n41:10 Outro\n\nRead the full abstract here:\nhttps://yowcon.com/brisbane-2024/sessions/3533\n\nRECOMMENDED BOOKS\nAlex Castrounis ‚Ä¢ AI for People and Business ‚Ä¢ https://amzn.to/3NYKKTo\nPhil Winder ‚Ä¢ Reinforcement Learning ‚Ä¢ https://amzn.to/3t1S1VZ\nHolden Karau, Trevor Grant, Boris Lublinsky, Richard Liu &amp; Ilan Filonenko ‚Ä¢ Kubeflow for Machine Learning ‚Ä¢ https://amzn.to/3JVngcx\nKelleher &amp; Tierney ‚Ä¢ Data Science (The MIT Press Essential Knowledge series) ‚Ä¢ https://amzn.to/3AQmIRg\nLakshmanan, Robinson &amp; Munn ‚Ä¢ Machine Learning Design Patterns ‚Ä¢ https://amzn.to/2ZD7t0x\nLakshmanan, G√∂rner &amp; Gillard ‚Ä¢ Practical Machine Learning for Computer Vision ‚Ä¢ https://amzn.to/3m9HNjP\n\nhttps://bsky.app/profile/gotocon.com\nhttps://twitter.com/GOTOcon\nhttps://www.linkedin.com/company/goto-\nhttps://www.instagram.com/goto_con\nhttps://www.facebook.com/GOTOConferences\n#AI #GenAI #GenerativeAI #ArtificialIntelligence #ChatGPT #ML #MakeRealtldraw #MakeReal #tldraw #Teachtldraw #AIDriven&nbsp;#LuWilson #YOWcon\n\nCHANNEL MEMBERSHIP BONUS\nJoin this channel to get early access to videos &amp; other perks:\nhttps://www.youtube.com/channel/UCs_tLP3AiwYKwdUHpltJPuA/join\n\nLooking for a unique learning experience?\nAttend the next GOTO conference near you! Get your ticket at https://gotopia.tech\nSign up for updates and specials at https://gotopia.tech/newsletter\n\nSUBSCRIBE TO OUR CHANNEL - new videos posted almost daily.\nhttps://www.youtube.com/user/GotoConferences/?sub_confirmation=1</article>","contentLength":2626,"flags":null,"enclosureUrl":"https://www.youtube.com/v/pLvMsGG7zE8?version=3","enclosureMime":"","commentsUrl":null},{"title":"The IRS Is Buying an AI Supercomputer From Nvidia","url":"https://tech.slashdot.org/story/25/02/15/0540249/the-irs-is-buying-an-ai-supercomputer-from-nvidia?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739624400,"author":"BeauHD","guid":319,"unread":true,"content":"According to The Intercept, the IRS is set to purchase an Nvidia SuperPod AI supercomputer to enhance its machine learning capabilities for tasks like fraud detection and taxpayer behavior analysis. From the report: With Elon Musk's so-called Department of Government Efficiency installing itself at the IRS amid a broader push to replace federal bureaucracy with machine-learning software, the tax agency's computing center in Martinsburg, West Virginia, will soon be home to a state-of-the-art Nvidia SuperPod AI computing cluster. According to the previously unreported February 5 acquisition document, the setup will combine 31 separate Nvidia servers, each containing eight of the company's flagship Blackwell processors designed to train and operate artificial intelligence models that power tools like ChatGPT. The hardware has not yet been purchased and installed, nor is a price listed, but SuperPod systems reportedly start at $7 million. The setup described in the contract materials notes that it will include a substantial memory upgrade from Nvidia.\n \nThough small compared to the massive AI-training data centers deployed by companies like OpenAI and Meta, the SuperPod is still a powerful and expensive setup using the most advanced technology offered by Nvidia, whose chips have facilitated the global machine-learning spree. While the hardware can be used in many ways, it's marketed as a turnkey means of creating and querying an AI model. Last year, the MITRE Corporation, a federally funded military R&amp;D lab, acquired a $20 million SuperPod setup to train bespoke AI models for use by government agencies, touting the purchase as a \"massive increase in computing power\" for the United States.\n \nHow exactly the IRS will use its SuperPod is unclear. An agency spokesperson said the IRS had no information to share on the supercomputer purchase, including which presidential administration ordered it. A 2024 report by the Treasury Inspector General for Tax Administration identified 68 different AI-related projects underway at the IRS; the Nvidia cluster is not named among them, though many were redacted. But some clues can be gleaned from the purchase materials. \"The IRS requires a robust and scalable infrastructure that can handle complex machine learning (ML) workloads,\" the document explains. \"The Nvidia Super Pod is a critical component of this infrastructure, providing the necessary compute power, storage, and networking capabilities to support the development and deployment of large-scale ML models.\"\n \nThe document notes that the SuperPod will be run by the IRS Research, Applied Analytics, and Statistics division, or RAAS, which leads a variety of data-centric initiatives at the agency. While no specific uses are cited, it states that this division's Compliance Data Warehouse project, which is behind this SuperPod purchase, has previously used machine learning for automated fraud detection, identity theft prevention, and generally gaining a \"deeper understanding of the mechanisms that drive taxpayer behavior.\"","contentLength":3057,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Karol Herbst Steps Down As Nouveau Maintainer Due To Linux Kernel's Toxic Environment","url":"https://www.phoronix.com/news/Karol-Herbst-Nouveau-No","date":1739619627,"author":"Michael Larabel","guid":364,"unread":true,"content":"<article>Karol Herbst has been a Nouveau driver developer for over a decade working on this open-source, reverse-engineered NVIDIA Linux graphics driver. He went on to become employed by Red Hat. While he's known more these days for his work on Mesa and the Rusticl OpenCL driver for it, he's still remained a maintainer of the Nouveau kernel driver. But today he announced he's resigning as a Nouveau driver maintainer due to differences with the upstream Linux kernel developer community...</article>","contentLength":483,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"KDE Developers Addressing Early Bugs From Plasma 6.3","url":"https://www.phoronix.com/news/KDE-Plasma-6.3-Early-Bugs","date":1739618860,"author":"Michael Larabel","guid":363,"unread":true,"content":"<article>KDE Plasma 6.3 released this week as the newest step forward for the KDE desktop. While it was smooth on the whole, there were some early bugs that KDE developers were dealing with this week. KDE developer Nate Graham is out with his usual weekly development summary for the Plasma desktop...</article>","contentLength":292,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: Kreuzberg ‚Äì Modern async Python library for document text extraction","url":"https://github.com/Goldziher/kreuzberg","date":1739614043,"author":"nhirschfeld","guid":276,"unread":true,"content":"<p>I'm excited to showcase Kreuzberg!</p><p>Kreuzberg is a modern Python library built from the ground up with async/await, type hints, and optimized I/O handling.</p><p>It provides a unified interface for extracting text from documents (PDFs, images, office files) without external API dependencies.</p><p>Key technical features:\n- Built with modern Python best practices (async/await, type hints, functional-first)\n- Optimized async I/O with anyio for multi-loop compatibility\n- Smart worker process pool for CPU-bound tasks (OCR, doc conversion)\n- Efficient batch processing with concurrent extractions\n- Clean error handling with context-rich exceptions</p><p>I built this after struggling with existing solutions that were either synchronous-only, required complex deployments, or had poor async support. The goal was to create something that works well in modern async Python applications, can be easily dockerized or used in serverless contexts, and relies only on permissive OSS.</p><p>Key advantages over alternatives:\n- True async support with optimized I/O\n- Minimal dependencies (much smaller than alternatives)\n- Perfect for serverless and async web apps\n- Local processing without API calls\n- Built for modern Python codebases with rigorous typing and testing</p><p>The library is MIT licensed and open to contributions.</p>","contentLength":1289,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43057375"},{"title":"Eating From Plastic Takeout Containers Can Increase Heart Failure Risk, Study Finds","url":"https://science.slashdot.org/story/25/02/15/0555235/eating-from-plastic-takeout-containers-can-increase-heart-failure-risk-study-finds?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739613600,"author":"BeauHD","guid":318,"unread":true,"content":"A new study suggests that frequent consumption of food from plastic takeout containers significantly increases the risk of congestive heart failure due to gut biome changes that trigger inflammation and circulatory damage. The Guardian reports: The authors used a two-part approach, first looking into the frequency with which over 3,000 people in China ate from plastic takeout containers, and whether they had heart disease. They then exposed rats to plastic chemicals in water that was boiled and poured in carryout containers to extract chemicals. \"The data revealed that high-frequency exposure to plastics is significantly associated with an increased risk of congestive heart failure,\" the authors wrote. [...] They put boiling water in the containers for one, five or 15 minutes because plastic chemicals leach at much higher rates when hot contents are placed in containers -- the study cited previous research that found as many as 4.2m microplastic particles per sq cm can leach from plastic containers that are microwaved.\n \nThe authors then gave rats the water contaminated with leachate to drink for several months, then analyzed the gut biome and metabolites in the feces. It found notable changes. \"It indicated that ingestion of these leachates altered the intestinal microenvironment, affected gut microbiota composition, and modified gut microbiota metabolites, particularly those linked to inflammation and oxidative stress,\" the authors wrote. They then checked the rats' heart muscle tissue and found it had been damaged. The study did not find a statistical difference in the changes and damage among rats that were exposed to water that had been in contact with plastic for one minute versus five or fifteen. The study has been published in the journal Ecotoxicology and Environmental Safety.","contentLength":1816,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Jane Street's Figgie card game","url":"https://www.figgie.com/","date":1739613560,"author":"eamag","guid":275,"unread":true,"content":"<p><a href=\"https://www.janestreet.com/\">Jane Street</a>'s fast-paced\n              Figgie game simulates exciting elements of markets and trading. At\n              Jane Street, Figgie is a game we teach and also one we really\n              enjoy playing.\n            </p><p><a href=\"https://www.figgie.com/faqs.html\">Read our FAQs</a>\n              for more. If you have a question that isn‚Äôt answered there, we‚Äôd\n              like to hear\n              <a href=\"mailto:figgie@janestreet.com\">what‚Äôs missing</a> and what\n              would be helpful to know, and we‚Äôll do our best to update FAQs\n              along the way.\n            </p>","contentLength":507,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43057344"},{"title":"The Danger of IP Volatility, (Sat, Feb 15th)","url":"https://isc.sans.edu/diary/rss/31688","date":1739604165,"author":"","guid":449,"unread":true,"content":"<p>What do I mean by ‚ÄúIP volatility‚Äù? Today, many organizations use cloud services and micro-services. In such environments, IP addresses assigned to virtual machines or services can often be volatile, meaning they can change or be reassigned to other organizations or users. This presents a risk for services relying on static IPs for security configurations and may introduce impersonation or data leakage issues.</p><p>This morning, I was setting up a new environment. I got a new IP address assigned by my hosting company and deployed a classic configuration: a reverse-proxy redirecting to many web services and generating Let‚Äôs Encrypt certificates.</p><p>Once the reverse proxy was in place, I started to deploy more services but detected some activity in the log&nbsp;(always keep an eye on your logs!) and saw this:</p><pre>{\"level\":\"debug\",\"time\":\"2025-02-15T06:22:33Z\",\"caller\":\"github.com/traefik/traefik/v3/pkg/tls/tlsmanager.go:228\",\"message\":\"Serving default certificate for request: \\\"postmaster.xxxxxxxx.hu\\\"\"}\n{\"level\":\"debug\",\"time\":\"2025-02-15T06:46:36Z\",\"caller\":\"github.com/traefik/traefik/v3/pkg/tls/tlsmanager.go:228\",\"message\":\"Serving default certificate for request: \\\"pop3.xxxxxxxx.hu\\\"\"}\n{\"level\":\"debug\",\"time\":\"2025-02-15T07:04:16Z\",\"caller\":\"github.com/traefik/traefik/v3/pkg/tls/tlsmanager.go:228\",\"message\":\"Serving default certificate for request: \\‚Äùxxxxxxxx.hu\\\"\"}\n</pre><p>A quick DNS request confirmed that these hosts are resolving to my newly assigned IP!</p><p>Worse, this organization seems to still be using POP3, and a user (or a script) is still trying to fetch emails using this protocol!</p><ul><li>When you move to another hosting solution, update your DNS records</li><li>Cleanup your DNS zones and remove unwanted entries</li><li>Use mechanisms to preserve your IP addresses (like ‚ÄúElastic IPs‚Äù provided by AWS)</li></ul><p>Xavier Mertens (@xme)\nXameco<p>\nSenior ISC Handler - Freelance Cyber Security Consultant</p><a href=\"https://keybase.io/xme/key.asc\">PGP Key</a></p>\n\n \n (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.","contentLength":2016,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The TechBeat: Futures of Ethereum II - Censorship Resistance (2/15/2025)","url":"https://hackernoon.com/2-15-2025-techbeat?source=rss","date":1739603464,"author":"Techbeat","guid":81,"unread":true,"content":"<p>By <a href=\"https://hackernoon.com/u/rootstock_io\">@rootstock_io</a> [ 3 Min read ] \n Rootstock merges Bitcoin‚Äôs security with Ethereum‚Äôs flexibility, enabling AI-driven blockchain apps for trustless governance, security, and fraud detection. <a href=\"https://hackernoon.com/ai-meets-bitcoin-how-rootstock-powers-the-future-of-trustless-ai\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/boxhero\">@boxhero</a> [ 13 Min read ] \n Discover how AI-powered sentiment analysis tools deliver accurate insights from customer reviews and feedback to help improve your business strategy. <a href=\"https://hackernoon.com/sentiment-analysis-and-ai-everything-you-need-to-know-in-2025\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/lumoz\">@lumoz</a> [ 3 Min read ] \n On February 13, Lumoz announced the official launch of Lumoz Chain and released the migration guide and reward plan for Verifier nodes.  <a href=\"https://hackernoon.com/lumoz-flips-the-switch-on-its-ai-powered-blockchain\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/stellar\">@stellar</a> [ 5 Min read ] \n Regulatory shifts in 2025 will shape crypto wallets. Learn how compliance, DeFi, and Stellar‚Äôs Soroban ecosystem will impact the future of Web3 wallets. <a href=\"https://hackernoon.com/regulatory-clarity-on-wallets-will-shape-defi-in-2025\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/adambakay\">@adambakay</a> [ 22 Min read ] \n By understanding market microstructure, you might be able to add more precision into your trading. <a href=\"https://hackernoon.com/thinking-of-pursuing-trading-full-time-then-you-need-to-know-what-market-microstructures-are\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mexcmedia\">@mexcmedia</a> [ 6 Min read ] \n Liquidity is key to crypto trading, ensuring price stability, seamless transactions, and reduced slippage. Learn how MEXC excels in liquidity management. <a href=\"https://hackernoon.com/the-importance-of-liquidity-how-it-impacts-crypto-trading\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/2077research\">@2077research</a> [ 11 Min read ] \n Explore the evolution of crypto options and perpetual futures, diving into innovations like panoptions, liquidity challenges, and decentralized trading. <a href=\"https://hackernoon.com/neverending-options-trading-options-to-infinity-and-beyond\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/2077research\">@2077research</a> [ 17 Min read ] \n The article explores Ethereum's efforts to ensure censorship resistance, focusing on solutions like PBS and encrypted mempools amid regulatory pressures. <a href=\"https://hackernoon.com/futures-of-ethereum-ii-censorship-resistance\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/hayday\">@hayday</a> [ 4 Min read ] \n Is the rise of vibe coding also the end of software engineering? How will vibeware change the nature of the software entrepreneur, and the meaning of work? <a href=\"https://hackernoon.com/vibe-coding-a-new-system-of-the-world\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mexcmedia\">@mexcmedia</a> [ 5 Min read ] \n Discover key crypto trends of 2025, from Bitcoin‚Äôs surge to MEXC‚Äôs role in shaping the future of digital asset trading with liquidity, security, &amp; innovation. <a href=\"https://hackernoon.com/2025-crypto-landscape-emerging-trends-and-exchange-platforms-shaping-the-future\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/noda\">@noda</a> [ 4 Min read ] \n 2025 is the tipping point for pay-by-bank. Lower fees, instant payments, and new regulations make it the future of digital transactions.  <a href=\"https://hackernoon.com/card-payments-are-slow-costly-and-dyingheres-what-consumers-are-turning-to-instead\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/matteopisani91\">@matteopisani91</a> [ 34 Min read ] \n A cybersecurity engineer built a sci-fi bass from scratch, packed with a synth, a wireless transmitter, a hacked built-in tuner and voltmeters. <a href=\"https://hackernoon.com/diy-enthusiast-hacks-his-way-into-building-his-own-musical-instrument-and-it-rocks\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ishanpandey\">@ishanpandey</a> [ 4 Min read ] \n Discover how CrossFi is revolutionizing crypto payments in this exclusive interview with CEO Alex Mamasidikov. <a href=\"https://hackernoon.com/crypto-without-banks-crossfis-ceo-on-the-future-of-decentralized-payments\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/menaskop\">@menaskop</a> [ 6 Min read ] \n Ethereum has many so-called \"killers,\" though most of them look more like self-destructive projects. <a href=\"https://hackernoon.com/is-ethereum-in-trouble-no-so-why-does-everyone-say-otherwise\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/wezam\">@wezam</a> [ 4 Min read ] \n There‚Äôs plenty of disagreement on how AI will change the product management landscape.  <a href=\"https://hackernoon.com/is-ai-making-product-managers-obsolete\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/awsmarketplace\">@awsmarketplace</a> [ 8 Min read ] \n Discover the best endpoint protection solutions, top platforms to consider, and key evaluation criteria to enhance your organization's cybersecurity defenses. <a href=\"https://hackernoon.com/evaluating-top-5-endpoint-protection-solutions\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/vitae\">@vitae</a> [ 5 Min read ] \n We present a deterministic game incorporating two key mechanisms: Controlled Chaos Shifts (CCS) and Accepting Loss of Control (ALC). <a href=\"https://hackernoon.com/the-first-provable-ai-proof-game-introducing-butterfly-wings-4\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/edwinliavaa\">@edwinliavaa</a> [ 3 Min read ] \n While Bitcoin's design brilliantly enables decentralization, human nature consistently pulls us toward centralization. <a href=\"https://hackernoon.com/bitcoin-is-eerily-resembling-the-financial-system-it-was-meant-to-replace\">Read More.</a></p>","contentLength":3218,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Used To Design a Multi-Step Enzyme That Can Digest Some Plastics","url":"https://science.slashdot.org/story/25/02/15/0549201/ai-used-to-design-a-multi-step-enzyme-that-can-digest-some-plastics?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739602800,"author":"BeauHD","guid":317,"unread":true,"content":"Leveraging AI tools like RFDiffusion and PLACER, researchers were able to design a novel enzyme capable of breaking down plastic by targeting ester bonds, a key component in polyester. Ars Technica reports: The researchers started out by using the standard tools they developed to handle protein design, including an AI tool named RFDiffusion, which uses a random seed to generate a variety of protein backgrounds. In this case, the researchers asked RFDiffusion to match the average positions of the amino acids in a family of ester-breaking enzymes. The results were fed to another neural network, which chose the amino acids such that they'd form a pocket that would hold an ester that breaks down into a fluorescent molecule so they could follow the enzyme's activity using its glow.\n \nOf the 129 proteins designed by this software, only two of them resulted in any fluorescence. So the team decided they needed yet another AI. Called PLACER, the software was trained by taking all the known structures of proteins latched on to small molecules and randomizing some of their structure, forcing the AI to learn how to shift things back into a functional state (making it a generative AI). The hope was that PLACER would be trained to capture some of the structural details that allow enzymes to adopt more than one specific configuration over the course of the reaction they were catalyzing. And it worked. Repeating the same process with an added PLACER screening step boosted the number of enzymes with catalytic activity by over three-fold.\n \nUnfortunately, all of these enzymes stalled after a single reaction. It turns out they were much better at cleaving the ester, but they left one part of it chemically bonded to the enzyme. In other words, the enzymes acted like part of the reaction, not a catalyst. So the researchers started using PLACER to screen for structures that could adopt a key intermediate state of the reaction. This produced a much higher rate of reactive enzymes (18 percent of them cleaved the ester bond), and two -- named \"super\" and \"win\" -- could actually cycle through multiple rounds of reactions. The team had finally made an enzyme.\n \nBy adding additional rounds alternating between structure suggestions using RFDiffusion and screening using PLACER, the team saw the frequency of functional enzymes increase and eventually designed one that had an activity similar to some produced by actual living things. They also showed they could use the same process to design an esterase capable of digesting the bonds in PET, a common plastic. The research has been published in the journal Science.","contentLength":2629,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reading Documentation Shouldn't Be a Chore","url":"https://hackernoon.com/reading-documentation-shouldnt-be-a-chore?source=rss","date":1739602109,"author":"Rami James","guid":80,"unread":true,"content":"<p>As a developer, documentation is both your greatest ally and your worst nemesis. It's the key to unlocking the power of libraries, frameworks, APIs, and even entire programming languages. Yet, many developers struggle to effectively navigate and extract the information they need from documentation. It's a skill that can be learned, and it's one that can make a huge difference in your productivity and the quality of your work. New developers often lack this critical skill, and find themselves stopped in their progress towards becoming a better dev because of it.</p><p>\\\nI'm currently writing the docs for Vewrite, a project management tool for writing teams. It occurs to me that I've been writing documentation for a long time, and I've gotten pretty good at it. I've also gotten pretty good at reading documentation, and I think that this is a skill that is often overlooked.</p><p>\\\nLet's talk about how to equip you with the skills to read documentation better, turning this often daunting task into a smooth and efficient process.</p><h3>Why is reading documentation challenging?</h3><p>\\\nGood documentation is essential. It provides the definitive guide to how software works, saving you countless hours of pointless, frustrating trial and error. Bad documentation is a nightmare. It's like trying to navigate a maze blindfolded, with no map and no sense of direction, guided by a liar.</p><p>\\\nIf you have access to the code you are working against, that's great and you should use it. Poke around and see what you're supposed to do by reading the code. But, in many cases (and almost all of the time with proprietary software), you're going to have to rely on the documentation to get you through. However, documentation can vary wildly in quality. Some is meticulously crafted, while others can be uninformative, outdated, or even misleading. This inconsistency is one of the reasons why reading documentation can be challenging.</p><p>Some docs are just a dumping ground for information, with no clear structure or organization. This can make it difficult to find what you're looking for, and you end up spending more time searching than actually learning. A well-structured set of documentation will have a clear table of contents, with sections and subsections that guide you through the material in a logical order. This makes it easier to navigate and find the information you need.In general, I'll also recommend some Getting Started section which points different types of users to the information which is most critical to them.</p><p>Information overload is another common hurdle. Docs can cover a vast range of features and functionalities, making it difficult to find the specific information you need. For example, a large framework might have hundreds of classes and methods, and trying to find the one you need can feel like searching for a needle in a haystack.</p><p>Unclear technical jargon can also be a barrier, as documentation is inherently technical, and sometimes the terminology can be confusing, especially for newcomers. This often stems from the assumption that the reader has a certain level of prior knowledge as it is largely written by the team who has developed the software and has an intimate knowledge of its innner workings.</p><p>Outdated information can be a major problem. Software evolves rapidly, and documentation can sometimes lag behind, leading to frustration and wasted time. A library might have deprecated a certain function, but the documentation might still describe it as the primary way to perform a task. The teams who produce software should be including accurate documentation creation and upkeep in their backlog as part of their process. Unfortunately, in the haste to get features shipped to market, corners are often cut. I've spent the better part of the last decade advocating for better processes that lead to better docs at a number of companies, and the biggest challenge here has been explaining to stakeholders where the value is.</p><h3>How to read documentation effectively</h3><p>Over the years, I've developed a structured approach to how I tackle reading new documentation. I've found that this approach helps me quickly get up to speed with new tools and technologies, and I hope it can help you too.</p><p>\\\nBy and large this method has three parts: understanding the structure of the documentation itself, understanding the way that the system I'm learning works, and lastly engaging with the material in the docs. First I get the lay of the land, and then I try to focus in on the details.</p><h4>Understand the structure of the documentation</h4><p>Docs are written by people, and every sysyem is going to be different. That means that every set of docs is going to be different. Some docs are organized by feature, others by use case, and still others by API endpoint. Understanding the structure of the documentation is key to finding the information you need quickly. Start by scanning the table of contents to get an overview of the topics covered. This will help you get a sense of the scope of the documentation and where to find specific information. You'll want to quickly click through the docs and get a sense of how things work, how they are organized, and where you can find reference materials if there are any.</p><p>\\\nI find that this initial run through also trickles some information about the system and its components into my brain. It's not comprehensive at all, but it's a good start.</p><p>Every piece of software is a system, and understanding how that system works is key to understanding how to use it. This is where the documentation can be a huge help. Good documentation will provide you with a high-level overview of the system, explaining how the different components fit together and how they interact. This can help you understand the context in which a particular feature or function is used, and how it relates to the rest of the system. This is where you start to get a sense of how the system is supposed to work, and how you can use it to solve your problems.</p><p>\\\nA lot of the problems that you'll encounter when building software will be because you fundamentally don't understand how what you're building with actually works. This is where the documentation can be a huge help. It can provide you with the context you need to understand how the system is supposed to work, and how you can use it to solve your problems. Use that to your advantage and you'll be able to build better software, faster.</p><p>This is often the most tedious and boring part. You have to actually take a few hours and read through the entire docs. For smaller libraries or APIs, this isn't going to be a big deal and you'll be able to fit most of it into your head. For larger systems, this is going to be a multi-day process. You'll want to take notes, ask questions, and engage with the material in a way that helps you understand it. This is where you start to get a sense of how the system is supposed to work, and how you can use it to solve your problems. If it doesn't all fit into your head now, that's ok. You'll remember more than you think you will, and when you're actually doing development it will be an order of magnitude faster to find an answer if you've already seen it once.</p><p>I've actually found that modern AIs are absolutely awesome for this step. You can use them as you would a more experienced developer and ask them questions about the system, the functionality, and the docs themselves. You can't trust everything that they say, but you can't really trust what another developer always tells you. I've found that being able to have a discussion with an AI about a library or API really helps me understand how stuff works at a deeper level.</p><h3>Strategies for effectively reading docs</h3><p>Despite these challenges, mastering the art of reading documentation is doable. Here are some strategies to keep in mind while you are digging around in docs, looking for an answer.</p><p>If you don't know where you're going, you may never get there. Before you dive into a set of docs, you may want to set a clear objective for yourself. Are you trying to understand a specific function, integrate a new library, or troubleshoot an error? Having a clear objective will help you focus your search.</p><p>\\\nFor example, if you're trying to fix a bug where a specific function isn't returning the expected value, and your code matches what the docs say that you're supposed to do, your goal is to understand the function's place in the wider system. The problem is going to be a few levels up and the docs are likely going to be the key to understanding how the software works at a higher level.</p><p>\\\nDon't immediately jump into the nitty-gritty details. Begin with the introductory sections, tutorials, or quick start guides to get a high-level understanding of the system. Your assumptions will often be wrong, and it is good to base your work on a foundation of truth. Think of it like reading the abstract of a research paper before diving into the full text. These introductory materials often provide a roadmap to the rest of the documentation.</p><h4>Use the structure of the docs to your advantage</h4><p>Use the table of contents and search function (these are your best friends) to quickly locate the sections you need. Don't be afraid to experiment with different search terms. Scan through the entire table of contents. Poke around and get a really good feel for how the documentation is structured. Sometimes you will find that your answers are hidden adjacent to where you thought that they would be.</p><p>Real-world examples are invaluable, and the best docs are going to include them. They demonstrate how to use the code in practice and can often clarify confusing concepts. Pay close attention to the context in which the examples are used. A code snippet demonstrating how to use a particular function is much more helpful if it's accompanied by an explanation of what the function does and why it's being used in that specific scenario.</p><h4>Pay attention to the details</h4><p>When looking at function or method definitions, carefully examine the data types of the parameters and return values. This will help you understand how to use them correctly. Sometimes, crucial information is hidden in footnotes, warnings, or less prominent sections. Make sure you scan the entire page, not just the headlines. A seemingly minor note might contain a critical piece of information that can save you a lot of trouble. Documentation often contains links to related topics or other parts of the documentation. Don't hesitate to follow these links to gain a deeper understanding. These links can often lead you to more detailed explanations, examples, or even the source code itself.</p><p>This is one of the biggest reasons why I believe that open-source can be such a boon for companies who want to build an ecosystem of developers around their software. Sometimes, the best way to understand how something works is to look at the source code itself. Don't be afraid to dive in, especially if the documentation is unclear. Reading the source code can give you a much clearer picture of what's happening under the hood. Try out the code examples and modify them to see how they behave. This is a great way to solidify your understanding and discover edge cases. Experimenting with the code is like conducting your own little science experiment. You can change the inputs, observe the outputs, and gain a deeper understanding of how the code works. If you're still stuck, don't hesitate to reach out to the community for help. Forums, mailing lists, and online communities are valuable resources for getting your questions answered. The developer community is generally very helpful, and there are often people who have encountered the same problems you're facing.</p><p>Reading documentation shouldn't be a passive activity. Engage with the material by taking notes, jotting down key points, examples, and any questions you have. Annotating the documentation (if possible), highlighting important sections and adding your own comments can also be helpful. Creating your own examples, writing small programs that use the features you're learning about, is a great way to reinforce your understanding. It's like practicing a musical instrument ‚Äì the more you do it, the better you get.</p><p>Reading documentation is a skill that improves with practice. By adopting these strategies and actively engaging with the material, you can transform documentation from a source of frustration into a powerful tool for learning and development. So, embrace the documentation, and unlock the full potential of the software you're working with!</p>","contentLength":12550,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Expose (And Fix) Hidden Bottlenecks in Adobe Experience Manager","url":"https://hackernoon.com/how-to-expose-and-fix-hidden-bottlenecks-in-adobe-experience-manager?source=rss","date":1739601941,"author":"Giuseppe Baglio","guid":79,"unread":true,"content":"<h2><em>Learn how to read thread dumps and take control of your application‚Äôs runtime behaviour.</em></h2><p>\\\nWhen your Adobe Experience Manager (or in general any JAVA application) instance shows signs of sluggishness, it‚Äôs time to roll up your sleeves and dive into the world of thread dumps. IBM Thread Analyzer (TDA) is here to help you untangle the web of threads and pinpoint performance bottlenecks. In this guide, we‚Äôll walk you through how to use IBM TDA to diagnose performance issues in AEM like a pro.</p><p>Before you can start analyzing thread dumps, you‚Äôll need to download and install <a href=\"https://www.ibm.com/support/pages/ibm-thread-and-monitor-dump-analyzer-java-tmda\">IBM Thread Analyzer</a>. Head over to the official IBM website or your organization‚Äôs repository to grab the latest version. Once downloaded, follow the installation instructions for your operating system. It‚Äôs quick, easy, and sets the stage for some serious troubleshooting.</p><p>Thread dumps are snapshots of all the threads running in your AEM instance at a specific moment. To capture them:</p><ol><li>Use tools like , , or AEM‚Äôs built-in functionality to generate thread dumps. There is a well-documented page on <a href=\"http://erience-cloud-kcs/kbarticles/ka-17452\">Adobe Docs</a>.</li><li>Save the thread dump files to your local machine.</li></ol><p>\\\nPro Tip: Capture multiple thread dumps at intervals (e.g., every 10 seconds) to get a clearer picture of long-running issues.</p><p>Launch IBM TDA and open the thread dump files you‚Äôve captured. Simply drag and drop the files into the application or use the ‚ÄúOpen‚Äù option to load them. Once loaded, you‚Äôll see a list of thread dumps on the left-hand panel.</p><p>To analyze a specific thread dump:</p><ol><li><p>Select the file from the listing.</p></li><li><p>Click the Thread Detail button at the top</p></li></ol><p>\\\nThis will display a detailed view of all the threads in that dump. Now, let‚Äôs sort the threads by Stack Depth, ensuring the longest stacks appear at the top. Why? Threads with deeper stacks often indicate more complex operations, which are usually where performance issues hide.</p><p>Focus on threads with a stack depth of 10 lines or longer. These threads are typically the ones consuming the most resources. Take notes on any threads that stand out ‚Äî whether due to their names, states, or stack traces.</p><p>Next, sort the threads by their State. Scroll down to the Runnable threads. These are the threads that were actively using CPU time when the dump was taken. Keep an eye out for application-specific threads, such as:</p><ul><li><p>Background job threads: Handling tasks like indexing or replication.</p></li><li><p>Request threads: Named like <code>127.0.0.1 [timestamp] GET /path HTTP/1.1</code>.</p></li></ul><p>For each request thread, extract the timestamp from its name (e.g., ). This Unix epoch timestamp tells you when the user‚Äôs browser made the request. Convert it to a human-readable date/time using a tool like <a href=\"https://www.epochconverter.com/\">https://www.epochconverter.com/</a>. Compare this with the thread dump‚Äôs timestamp to calculate how long the request has been active.</p><p>If the difference is unusually large (e.g., several seconds or minutes), it could indicate a bottleneck in your application.</p><p>\\\nPro Tip: Keep an eye out for patterns. Are certain types of requests consistently taking longer? For example, requests involving complex queries or resource-heavy operations might be worth optimizing. Additionally, if you notice that specific URLs or endpoints are frequently associated with long-running threads, consider profiling those areas of your codebase.</p><p>Thread analysis requires a nuanced approach that goes beyond simple waiting states. While the IBM Thread Analyzer (TDA) interface provides valuable insights into thread relationships, understanding the full context of thread behavior helps create a more complete picture of your application‚Äôs performance characteristics.</p><h2>Understanding Thread States</h2><p>When examining threads in TDA, you‚Äôll encounter several important states:</p><p>: These threads are either currently executing or ready to execute when CPU time becomes available. A Runnable state doesn‚Äôt necessarily indicate a problem ‚Äî it‚Äôs the natural state for actively working threads.</p><p>: These threads have temporarily paused execution while waiting for a condition to be met. The waiting state can occur for many legitimate reasons, including:</p><ul><li>Resource availability (database connections, file handles)</li><li>Task completion in other threads</li></ul><p>\\\n: These threads are specifically waiting to acquire a monitor or lock. While similar to waiting, blocked states specifically indicate synchronization-related pauses.</p><h2>Analyzing Thread Relationships</h2><p>When you identify a thread of interest, examine its relationships with other threads using this systematic approach:</p><ol><li>Direct Lock Relationships:</li></ol><ul><li>Examine the Waiting Threads panel for immediate dependencies</li><li>Review the stack traces of waiting threads to understand why they‚Äôre blocked</li><li>Note the duration of the wait states if available</li></ul><p>\\\n2. Resource Usage Patterns:</p><ul><li>Look for patterns in resource acquisition and release</li><li>Identify potential resource bottlenecks</li><li>Consider alternative resource management strategies</li></ul><p>\\\n3. Architectural Implications:</p><ul><li>Evaluate if the observed behaviour aligns with the system‚Äôs design</li><li>Consider if the current threading model is appropriate</li><li>Assess the impact on scalability</li></ul><h2>Understanding Lock Types and Visibility</h2><p>Thread dumps may not show all types of contention. Modern Java applications use various synchronization mechanisms:</p><ol><li>Intrinsic Locks (synchronized keyword):</li></ol><ul><li>Show clear owner-waiter relationships</li><li>Stack traces indicate synchronization points</li></ul><p>\\\n2. Explicit Locks (java.util.concurrent):</p><ul><li>May require additional tooling to visualize</li></ul><p>\\\n3. Non-blocking Mechanisms (Don‚Äôt appear as traditional locks but can impact performance):</p><ul></ul><p>When you identify genuine contention issues, consider these approaches:</p><ul><li>Implement finer-grained locking</li><li>Consider non-blocking alternatives</li></ul><ul><li>Implement backoff strategies</li><li>Consider caching solutions</li></ul><p>\\\n3. Architectural Changes</p><ul><li>Evaluate asynchronous processing</li><li>Consider parallel execution paths</li><li>Implement queue-based approaches</li></ul><p>\\\nRemember that thread analysis is an iterative process. Patterns that emerge in one thread dump might not represent consistent behaviour. Always validate your findings across multiple dumps and different time periods before making significant changes to your application.</p><p>Comparing thread dumps across time reveals important performance patterns in your AEM instance. Start by establishing a baseline during normal operation, including peak usage periods and maintenance windows. This baseline provides context for identifying abnormal thread behaviour.</p><p>To determine if a thread is persistent across time:</p><ol><li>Select multiple thread dumps from different points in time.</li><li>Click the Compare Threads button in IBM TDA.</li><li>Look for threads that remain in the Runnable state across all dumps, especially those with consistently long stack traces.</li></ol><p>\\\nUse IBM TDA‚Äôs Compare Threads feature to analyze dumps from different time points. Focus on threads that persist across multiple dumps, examining their states, stack depths, and resource usage. Remember that thread persistence alone doesn‚Äôt automatically indicate a problem ‚Äî background services naturally run continuously, while request threads should complete within expected timeframes.</p><p>\\\nWhen analyzing persistent Runnable threads, correlate their behaviour with system metrics like CPU usage, memory consumption, and response times. Consider the thread‚Äôs purpose: background services, request processing, or maintenance tasks each have different expected patterns. For request threads, compare their duration against defined service level agreements and business requirements.</p><p>\\\nGot a suspicious thread pattern? Don‚Äôt jump to conclusions just yet! Try to recreate the issue in your test environment first ‚Äî it‚Äôs like having a dress rehearsal before the main show. Take a good look at your code, double-check those config settings, and consider what else might be stirring up trouble in your environment. Keep track of what you find with real performance numbers and test results ‚Äî you‚Äôll thank yourself later.</p><p>\\\nOnce you‚Äôre sure you‚Äôve caught a real performance culprit (backed by solid evidence, of course), it‚Äôs time to fix it.</p><p>If analyzing threads doesn‚Äôt yield actionable insights, switch to the Monitor Detail view:</p><ol><li><p>Go back to the thread listing.</p></li><li><p>Select a thread dump and click the Monitor Detail button.</p></li><li><p>IBM TDA will display a tree view of monitor-owning threads and their waiting threads.</p></li></ol><p>\\\nThis view helps you identify threads that are holding monitors and causing contention. Understanding thread monitors is like viewing the nervous system of your application. These synchronization mechanisms control how threads access shared resources, preventing potential conflicts and ensuring smooth operation.</p><p>\\\nMonitor interactions can reveal critical performance insights. Some threads will be actively processing requests, while others wait for resource acquisition or participate in coordinated activities. Not all waiting or idle threads indicate a problem ‚Äî they‚Äôre often part of the application‚Äôs natural resource management strategy.</p><p>\\\nHowever, not all threads are equally important:</p><ul><li>Ignore idle thread pool threads: These threads typically have ‚â§10 stack lines and are part of thread pools like the servlet engine. They‚Äôre usually harmless unless they dominate the thread pool.</li><li>Focus on application-specific monitors: Look for monitors tied to your application‚Äôs business logic, such as database connections, caching mechanisms, or custom synchronization blocks.</li></ul><p>\\\nRemember that thread and monitor analysis is both an art and a science. Each application has unique characteristics, so approach performance optimization with curiosity and a holistic perspective. The goal is not to eliminate all waiting threads but to understand and optimize their interactions.</p><p>\\\nAdvanced Tip: If you notice certain monitors are frequently contended, consider refactoring your code to reduce lock granularity. For example:</p><ul><li>Replace coarse-grained locks with fine-grained ones.</li><li>Use non-blocking algorithms or concurrent data structures where possible.</li><li>Optimize database queries to reduce the time threads spend waiting for locks.</li></ul><p>In some thread dumps, you might notice the  appearing frequently. This service handles tasks like Garbage Collection, memory management, and resource cleanup. While the Collector Service might seem like a mysterious background process, understanding its behaviour is key to maintaining optimal system performance ‚Äî think of it like a diligent janitor in a large office building.</p><p>\\\nWhen you notice frequent Collector Service activity, don‚Äôt immediately assume disaster. It‚Äôs normal for the Collector Service to show up occasionally, but excessive activity could indicate underlying issues:</p><ul><li>Memory leaks: Objects that are not being garbage collected can cause frequent GC cycles.</li><li>High object churn: Rapid creation and destruction of objects can overwhelm the garbage collector.</li><li>Improper JVM settings: Misconfigured heap sizes or GC algorithms can lead to inefficiencies.</li></ul><p>\\\nHere are some considerations to optimize resource usage:</p><ul><li>Tuning your JVM settings (e.g., increasing heap size, switching to G1GC).</li><li>Reviewing your application‚Äôs memory allocation patterns to reduce unnecessary object creation.</li></ul><p>\\\nGarbage Collection is not a problem to be solved, but a dynamic system to be understood and optimized. Each application has unique characteristics, and there‚Äôs no universal solution.</p><p>Thread dump analysis is a developer‚Äôs superpower ‚Äî transforming you from a code writer to a performance detective. IBM Thread Analyzer (TDA) is your key to understanding complex system behaviours, revealing hidden bottlenecks that impact your Java/AEM instance‚Äôs performance.</p><p>\\\nLike learning an instrument, your skill improves with practice. Each thread dump becomes clearer, revealing intricate patterns of system interactions. The more you analyze, the more intuitive performance optimization becomes.</p><p>\\\nRemember, practice makes perfect ‚Äî the more you analyze thread dumps, the sharper your diagnostic skills will become. üìäüí™</p><p>\\\nüõ† Ô∏èHappy troubleshooting! And don‚Äôt forget to share your findings with your team to keep your Java/AEM instance running smoothly.</p>","contentLength":12075,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Launch a Product in a New Market Is Hard, So I Made a 4-Step Framework for Success","url":"https://hackernoon.com/launch-a-product-in-a-new-market-is-hard-so-i-made-a-4-step-framework-for-success?source=rss","date":1739601806,"author":"Roman Shimanskiy","guid":78,"unread":true,"content":"<p> because there‚Äôs just no real demand for what they‚Äôre offering. A staggering number and a logical reason behind it ‚Äì and it‚Äôs the main one, according to CB Insights. It‚Äôs not about a lack of funding, bad hires, or tough competition. The real question is whether people actually need what you‚Äôre about to offer them.</p><p>\\\nPlus, having a great product isn‚Äôt enough. To win, you need to understand the competitive landscape, your audience, and how to get your brand in front of the right people. Drawing from my experience launching Yango Play in MENA ‚Äî where we developed an AI-powered Entertainment SuperApp that quickly became one of the region‚Äôs leading streaming platforms ‚Äî I want to share the key steps we took to make it the success it is now.</p><p><strong>Selecting the right market</strong> is a balance between <strong>competition and profitability.</strong> Some regions offer low competition but limited revenue potential, while others may be more lucrative but very, very saturated. Sub-Saharan Africa, for example, has a large population and low competition, making it an appealing early-stage entry option. But, lower consumer spending restricts growth. MENA, on the other hand, has a smaller population but significantly higher consumer purchasing power, making it an attractive place for expansion.</p><p>\\\n is just as critical as market selection. Entering too early may mean slow adoption while entering too late risks facing intense competition.</p><blockquote><p>If competition is low, it provides an advantage and accelerates market growth. The key is to enter before the market experiences a surge in adoption.</p></blockquote><p>\\\nIn the CIS region, the subscription economy remained relatively flat at 1‚Äì2 million subscribers for several years before suddenly accelerating to 100% annual growth. The same pattern emerged in MENA, indicating that the region was nearing a similar tipping point, making it the optimal time to enter.</p><p>\\\nMarket data is here to reinforce this statement. MENA‚Äôs total population is around 500 million, with 13.5 million already subscribed to video streaming services. Just for reference, penetration of subscription services in CIS region stands at 15-20%, with slight differences between countries. Even without complex economic modeling, these figures indicated a major opportunity for subscription-based services in MENA. So, an ideal market for expansion. In this case, the potential formed the perfect ground for selecting the market and strategy ‚Äì the choice was easy.</p><p>\\\nStill, the region was already highly competitive, with more than 50 video streaming platforms and many global and local music services. We had strong competitors in each category, so for us entering the market required more than just identifying demand.</p><h3><strong>Product and Content Differentiation</strong></h3><p>Creating a strong differentiator was key, and competing head-on with zero brand awareness would have been very much an uphill battle.</p><p>\\\nTake YANGO‚Äôs case study on product differentiation. We simultaneously implemented two strategies ‚Äî with **differentiation through the product and content. \\n </p><ol><li><p>An Entertainment SuperApp ‚Äî <strong>a single subscription combining music, movies, and games.</strong> At the time, there wasn‚Äôt anything similar, so we gladly took the opportunity for this strategic entry point. Users typically juggle multiple subscriptions: one for music, another for video, and yet another for gaming. We built everything into one app under a single subscription. This way, we got on the growing global trend toward bundled entertainment services and also filled a gap in our target market. Win-win.</p></li><li><p>Netflix has long become the go-to platform for global content. We took a different route and built an ecosystem tailored to local tastes. Our SuperApp has regional music, Arabic-language films, and localized gaming options, making it much more relevant to MENA audiences. This became a critical differentiator, making our product not just another streaming service but a culturally attuned entertainment hub.</p></li></ol><p>\\\nConclusion: <em>To successfully differentiate a product, the best strategy is to identify weaknesses or unmet needs in competing products ‚Äî and fill those gaps.</em></p><p>\\\nIn crowded markets, pricing is as crucial as the product. It‚Äôs not the features that make or break the product ‚Äì it‚Äôs about making your product the most logical choice.</p><p>\\\nSo, we introduced a long trial period and a bundled pricing model, allowing users to get music and movies for the price of one. Instead of discounting, we maximized perceived value, making the subscription an easy, rational decision.</p><p>\\\nExpanding into a new market meant building a local team and adapting to language and cultural nuances. With deep market research, perfect timing, and a product tailored to real consumer needs, the SuperApp secured a strong foothold in a high-growth market. How did we tackle these challenges? That‚Äôs a story for another article.</p><h3><strong>Audience Differentiation: Defining the Target User</strong></h3><blockquote><p><em>Users have mental ‚Äúboxes‚Äù where they sort every new product they see. Food delivery? That goes into one box. A streaming service? Another box. But if your product doesn‚Äôt fit neatly into a box, it triggers confusion ‚Äî people don‚Äôt know what to do with it. And when something feels unfamiliar, the default reaction is to ignore it.</em></p></blockquote><p>\\\nThat‚Äôs why crystal-clear positioning isn‚Äôt optional ‚Äî it‚Äôs survival. If users can‚Äôt instantly grasp who your product is for and why they need it, you‚Äôre fighting an uphill battle. But just fitting into a category isn‚Äôt enough. You have to own it. When people think about entertainment subscriptions, they should immediately think of your brand.</p><p>\\\nHow do you make that happen? Precision. <strong>Messaging needs to be sharp, clear, and unmistakable.</strong> Instead of vague positioning, spell it out: ‚ÄúThis is a service for modern Arabic-speaking users.‚Äù That clarity eliminates confusion and makes it easier for potential subscribers to see how the product fits into their everyday world.</p><p>\\\nBrand anchoring is everything‚Äî <strong>the simpler and more memorable the positioning, the stronger the audience connection.</strong> If users struggle to define what the product is or who it‚Äôs for, they‚Äôll tune it out. That‚Äôs a death sentence for any brand. The fix? Build an instant mental link. The moment someone thinks ‚Äúentertainment subscription,‚Äù your SuperApp should be the first thing they recall.</p><p>For startups that can‚Äôt outspend competitors, traditional marketing funnels ‚Äî awareness ‚Üí consideration ‚Üí purchase ‚Äî might not be the best play. Instead, skip the awareness stage and go straight for user acquisition.</p><p>\\\nHere‚Äôs the logic: if someone downloads your app, they already know it exists. There‚Äôs no need to waste resources on brand awareness before conversion. Yes, this approach raises the cost per acquisition (CPA) since users are coming in cold, but the trade-off is greater control over spending and a more direct path to growth.</p><p>\\\n<strong>The real power lies in performance-driven marketing, which focuses on conversions rather than broad exposure.</strong> Even brands with large media budgets rely on performance marketing as the most efficient way to drive actual user engagement. For lean startups, this strategy isn‚Äôt just viable ‚Äî it‚Äôs essential.</p><p><strong>A product launch is a one-time shot</strong> at grabbing audience attention ‚Äî  over a long, drawn-out campaign. The smartest play? Go loud.</p><p>\\\n<em>The launch moment is your biggest marketing asset ‚Äî a rare window where PR and buzz can be built just around your existence. Instead of slow, passive brand-building, focus on making a splash that gets people talking.</em></p><p>\\\nOnce the initial hype kicks in, then comes the next phase ‚Äî brick by brick, reinforcing brand awareness and earning user trust. We also saw this proven in the case of Kinopoisk (video streaming platform). We focused our marketing around major premieres such as <em>Zack Snyder's Justice League</em>, , and big exclusive original premieres.</p><h3><strong>Shifting from Traditional Advertising to Alternative Channels</strong></h3><p>From experience, <em>buying direct media ads is often far less effective than leveraging influencers, word of mouth, and strong PR.</em></p><p>\\\nSpending time on finding the right influencer, crafting a viral PR angle, or developing creative content that resonates delivers higher ROI than just pouring money into paid ads. <strong>In a budget-constrained environment, the smarter play is a two-step approach:</strong></p><ul><li><p>Performance marketing first ‚Äî drive installs and conversions while simultaneously learning how users interact with the product.</p></li><li><p>Organic &amp; influencer-driven marketing second ‚Äî building credibility and momentum through earned media, viral content, and strategic partnerships.</p></li></ul><p>With influencers, you‚Äôre hitting two targets at once. First, their audience gets exposed to your service, boosting brand awareness. But the real power of influencer marketing is in its high conversion rates ‚Äî it doesn‚Äôt just build visibility; it drives action. It works like performance marketing in many ways. Even better? The creative content influencers produce often performs exceptionally well in paid performance campaigns, making it a valuable asset beyond the initial collaboration. So, really, you‚Äôre getting even more value out of every campaign.</p><p>\\\nThis keeps acquisition costs under control and ensures real engagement and long-term user retention.</p><p>\\\nOne of the most successful cases of leveraging PR instead of direct advertising is Netflix. When expanding into new regions, the company rarely invests in traditional media ads. Instead, it focuses on localized content, influencer collaborations, and large-scale PR campaigns. This approach has allowed Netflix to dominate new markets without massive ad spending, making the brand recognizable through organic user discussions and viral interest.</p><p>\\\nThere are plenty of examples of viral brands and services ‚Äî take Dubai Chocolate or Clubhouse, for instance. These apps and platforms managed to gain massive audiences with little to no marketing spend, relying purely on organic growth and word of mouth.</p><h3><strong>The Founder as the Brand‚Äôs Leading Ambassador</strong></h3><p>In a competitive market, PR isn‚Äôt just about press releases and media coverage ‚Äî it‚Äôs about people. A founder holds a unique advantage: their voice becomes the product‚Äôs most powerful marketing tool.</p><p>\\\nPeople don‚Äôt engage with companies ‚Äî they engage with other people. Instead of relying on corporate statements or press releases, modern PR is about creating shareable content and building influence through authentic, human-driven narratives.</p><p>\\n Whether you are a startup or an established company, entering a new market requires more than a strong product ‚Äî it asks for adaptability to evolving industry rules and dynamics. The strategies that worked in the past may no longer be effective in an environment where competition is fierce, consumer behavior is shifting, and digital ecosystems are rapidly changing. Success hinges on thorough market research, precise audience targeting, strategic product differentiation, and a well-structured promotional approach.</p>","contentLength":11021,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Every New Apple Device Expected in 2025","url":"https://hackernoon.com/every-new-apple-device-expected-in-2025?source=rss","date":1739600519,"author":"David Perru","guid":77,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Hospitals Use AI to Boost Efficiency in Medical Imaging Technology","url":"https://hackernoon.com/how-hospitals-use-ai-to-boost-efficiency-in-medical-imaging-technology?source=rss","date":1739600517,"author":"Beth Rush","guid":76,"unread":true,"content":"<p>\\\nAdvancing health care technologies are crucial for doctors and patients. They could make medical services easier to provide while giving people better results, but only if everyone understands the bigger picture. Artificial intelligence (AI) is a critical tool that may become part of your health care services in the near future. Check out how physicians are using AI in medical imaging and diagnostics to learn why it could revolutionize the industry.</p><h2><strong>What Is Medical Imaging Technology?</strong></h2><p>Medical imaging technology is any tool that  to monitor normal and abnormal cases. The term includes various services that assist health care providers in making diagnoses. While they‚Äôve existed long before automation, artificial intelligence in medical imaging is becoming more widespread through software updates.</p><h2><strong>Different Types of Imaging Techniques</strong></h2><p>You‚Äôll better understand why AI could be an essential scientific tool if you know which imaging techniques people undergo. Learn more about each form of technology to understand AI‚Äôs advantages and challenges more easily.</p><p>X-ray machines are penetrative imaging tools that look at targeted areas inside the body before sending the results to imaging technology. The machine sends ionizing radiation into a patient to gather pictures for diagnosis. X-rays are especially useful for bone inquiries because the radiation passes through them and makes them bright white.</p><h3><strong>Magnetic Resonance Imaging (MRI)</strong></h3><p>If you need an MRI, a doctor might inject a contrast agent into your bloodstream  before you sit in the machine. Radiowaves, a magnet and a computer processor look inside the selected part of your body to reveal everything from tissues to joints.</p><p>Ultrasound imaging  to see what‚Äôs in your body. The machinery bounces soundwaves off of your organs and tissues instead. This isn‚Äôt a penetrative imaging technique, even though tools like transvaginal wands do work inside the vaginal canal.</p><p>Doctors needing more complex imaging may order CT scans. They combine an X-ray with a computer to  before it bounces back on a plate behind the patient. The machinery scans in a circle, making it more useful for 3D images of internal damage or tumors.</p><h2><strong>How Each Technique Benefits From AI</strong></h2><p>If health care experts have used imaging techniques since before AI existed, why would they benefit from it? There are a few key ways AI in medical imaging and diagnostics could improve each technique for providers and patients.</p><h3><strong>Algorithms Can Process Images Faster</strong></h3><p>When doctors order penetrative imaging, they wait for specialized hospital staff to conduct the process and return the pictures. The physician needs time to sit and analyze the image, which may not happen immediately if they have a busy schedule. Given that the U.S. will have a health care worker shortage , the high work demand on doctors is a long-term challenge.</p><p>\\\nYou don‚Äôt need to worry about not getting medical imaging results back quickly if your local hospital uses machine-learning algorithms to process patient results. AI can review results , providing recommendations for doctors when they have time to check the scans. A health care provider will still review your results, but they could get back to you faster with computerized assistance.</p><h3>AI May Catch Small Details Better</h3><p>Artificial intelligence in medical imaging can do much more than summarize scans. The algorithms can also delineate structures in the human body. Advanced programs , tumors, and blood vessels and catch abnormalities in imaging results.</p><p>\\\nDoctors might accidentally overlook similar developments if they‚Äôre too small to see with the human eye. Instead of going back for additional imaging in a few weeks or months, you could get earlier and more precise results with AI-supported medical imaging techniques.</p><p>\\\nRemember ‚Äî your doctor will still have the final say over your diagnosis. AI provides additional insights, but you‚Äôll always need to talk with your health care provider before moving forward with treatments.</p><h3>Predictive Analytics May Provide Personalized Treatment Suggestions</h3><p>Personalized treatment plans start with diagnostic tools like medical imaging before combining your results with your health history. AI may assist with that process in more hospitals over time. Advanced algorithms can  while checking your scan results. Afterward, your doctor will review its recommended treatment options and use that data to start conversations with you.</p><p>\\\nTogether, you‚Äôll decide the next best steps. AI won‚Äôt determine how you get medical care. Machine learning programs are an evergrowing tool that could make those conversations more straightforward by supplying potentially more accurate data.</p><p>Some surgeries require medical imagery techniques for real-time data. Machine learning  in specialties like cardiothoracic, ophthalmology and general surgery. When health care professionals use it in real time, the algorithms can review images guiding surgeons through a procedure and assist in augmented visualization. Decision support may also be helpful for instant recommendations based on the patient‚Äôs collective medical history, like the likelihood of complications.</p><h2>Does AI Medical Imaging Guarantee Increased Efficiency?</h2><p>There‚Äôs no guarantee that AI medical imaging will increase the efficiency of real-time surgical decisions, diagnoses or treatment plans. Algorithms are only as good as their programming. Your doctor will always need to consider the data provided by any machine learning program before using their comprehensive medical knowledge and understanding of your needs to give an informed opinion.</p><h2>Potential Challenges Hospitals May Face</h2><p>As more hospitals start using AI programs to read results like medical scans, it‚Äôs important to understand the barriers that may prevent implementation. Keep those factors in mind if you‚Äôre hoping to see AI-assisted medical services where you live.</p><h3>Data Storage and Protection</h3><p>Everything processed and produced by artificial intelligence in medical imaging consists of sensitive data. Hospitals need robust storage capabilities to utilize AI-assisted medical imaging and keep patient information safe. Experts estimate data breaches  in 2024 and may get worse in years to come.</p><p>\\\nHospital administrative teams may need to partner with information technology experts internally or externally to set up data storage methods with extra protection. The process may delay AI implementation, depending on where each facility‚Äôs current cybersecurity measures stand.</p><h3>Accurate Interpretability</h3><p>Medical imaging technology with AI programs is relatively new. Hospital staff will likely need some form of training before they can use it with patients. Human error could cause less accurate interpretability as medical providers get used to reading and considering AI results while making recommendations.</p><h3>Integrating AI With Current Workflow Systems</h3><p>Adding a software system to a new service is much less complicated than integrating it into something people are already doing. Hospitals are serving patients around the clock, so adding AI to their medical imaging processes without compromising patient care or service speed is challenging.</p><p>\\\nResearchers also point out that health care systems  due to things like mismatching software programs or outdated technology. Analyzing, collecting and storing imaging data may require other updates before it can happen smoothly. Communicating AI information across departments or between hospitals may create additional struggles for health care providers.</p><h2>Anticipate More AI in Medical Imaging and Diagnostics</h2><p>Health care professionals are interested in artificial intelligence in medical imaging because it could help them work faster, provide personalized results and give more accurate treatment plans. It can also require complex integration planning before patients benefit from it. Staying up to date on those factors will keep you in the know with the ever-changing health care industry.</p>","contentLength":7965,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tech Leaders Reveal New Approaches to Corporate Sustainability","url":"https://devops.com/executive-strategies-driving-corporate-sustainability/","date":1739598887,"author":"Bonnie Schneider","guid":187,"unread":true,"content":"<article>Over the past two years, I‚Äôve interviewed more than 100 executives on tech innovation. Key insights emerged. But one stood out: sustainability is no longer a ‚Äúnice to have.‚Äù It‚Äôs now a core business strategy. That‚Äôs the focus of my inaugural, exclusive report: Decisions That Define: Executive Strategies Driving Corporate Sustainability. Why 2025 is a [‚Ä¶]</article>","contentLength":368,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ikey Doherty's Serpent OS Rebranding As AerynOS","url":"https://www.phoronix.com/news/Serpent-OS-To-AerynOS","date":1739595600,"author":"Michael Larabel","guid":362,"unread":true,"content":"<article>The nearly three year old Serpent OS Linux distribution started by Ikey Doherty of Solus fame is going to re-brand as AerynOS...</article>","contentLength":128,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Phenomenology of Dark Matter Explained","url":"https://hackernoon.com/the-phenomenology-of-dark-matter-explained?source=rss","date":1739591096,"author":"Phenomenology Technology","guid":75,"unread":true,"content":"<h2>3.4 Phenomenology of dark matter</h2><p>\\\n‚Ä¢ The relic density coming from Planck satellite data [49]</p><p>\\\nThe total relic abundance of DM in our model is given by the sum of the scalar (ùúí) and fermion (ùëÅ3) relic abundances:</p><p>\\\nOnly for solutions falling exactly within the band given in Eq. (3.31) the totality of the DM can be explained by ùúí and ùëÅ3.</p><p>\\\n‚Ä¢ Direct detection cross-section of DM scattering of nucleon set by various experiments such as XENON1T [66], LUX [65] and PandaX-II [174]</p><p>\\\nWe implemented the model in the SARAH package [175] to calculate all the vertices, mass matrices, tadpole equations etc. The thermal cross sections and DM relic abundance are determined using micrOMEGAS-5.0.8 [176]. Even though the model introduces new free parameters, not all of them are important to DM analysis. For example, self-quartic coupling ùúÜùúí does not play any role in DM phenomenology. Hence we choose to fix ùúÜùúí = 0.1 in our analysis. The remaining free parameters relevant for DM analysis can be chosen as:</p><p>\\\nIn the next sections, we will study how the DM phenomenology of this model depends on the free parameters and to do that we choose the following benchmark points which are allowed from all the above-mentioned constraints:</p><p>\\\nwhich we can be utilized to compute the relic density of both the components,</p><p>The direct detection study of our DM candidates ùúíùëÖ and ùëÅ3 are done here. The current experimental constraints on the DM direct detection assume the existence of only one DM candidate. As in our model, two-component DM candidates are predicted, and the contribution of each candidate to the direct detection cross-section should be rescaled by the fraction contributing to the total relic density. Hence it is convenient to define the fraction of the mass density of ùëñth DM in the case of multi-component DM [156,157,178,179]</p><p>\\\nThe upper limit on the direct detection now can be recast as</p><p>\\\nThe above formula in Eq. (3.40) is an extension of the expression corresponding to the singlet scalar DM case [180]. The relative negative sign between the ‚Ñé1 and ‚Ñé2 contributions arises in our considered model as the couplings get modified according to Eq. (3.42). Due to the presence of the two different channels, depending on the parameter space, we can have destructive interference between these two channels, and direct detection can be very small.</p><p>(1) Shivam Gola, The Institute of Mathematical Sciences, Chennai.</p>","contentLength":2451,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"No Personal Liability For DOGE Yet, But With Two More Lawsuits We Get Closer","url":"https://www.techdirt.com/2025/02/14/no-personal-liability-for-doge-yet-but-with-two-more-lawsuits-we-get-closer/","date":1739590740,"author":"Cathy Gellis","guid":290,"unread":true,"content":"<p>I‚Äôm going to keep <a href=\"https://www.techdirt.com/2025/02/12/doge-may-now-be-aware-of-the-cfaa-but-its-still-violating-it-along-with-lots-of-other-laws/\">pounding the drum for personal liability</a> against Musk and DOGE, partly to scare them into backing off from their unlawful seizure of our government, and eventually to compensate us for the immense harm they‚Äôve caused. So far it doesn‚Äôt seem like anyone has tried to personally sue them for damages, but several lawsuits are taking what might be a predicate step to establish the lawlessness of their claimed power, upon which liability claims would later be based. In addition to the AFGE litigation against OPM we already <a href=\"https://www.techdirt.com/2025/02/13/at-last-doge-and-musk-are-finally-named-in-a-lawsuit-albeit-officially/\">wrote about</a>, which also names OPM itself for it wrongfully giving DOGE access to its systems, and the <a href=\"https://www.techdirt.com/2025/02/10/court-blocks-doges-treasury-access-adding-credence-to-cfaa-questions/\">states‚Äô lawsuit against the Treasury department</a> for giving DOGE access to theirs, now we have (at this writing at least) two more lawsuits. But while those lawsuits were directed at specific agencies and the wrongfulness of Musk and DOGE‚Äôs misuse of power at these agencies, these new lawsuits come gunning for Musk and DOGE and their illegal seizure of power generally.</p><p>They both base this argument on the Appointments Clause of the Constitution, but we‚Äôll use the states‚Äô <a href=\"https://www.courtlistener.com/docket/69638651/2/state-of-new-mexico-v-musk/\">complaint</a> to illustrate how. As it sets forth:</p><blockquote><p><em>The Founders of this country fought for independence from the British monarchy due in no small part to the King‚Äôs despotic power to create an unlimited number of governmental offices and to fill those offices with the King‚Äôs supporters. In fact, this practice so severely undermined the Founders‚Äô freedoms that it is a listed grievance in the Declaration of Independence. Informed by that history, the Framers of the Constitution crafted the Appointments Clause to protect against such tyranny in our system of government. The Appointments Clause was designed to buttress the separation of powers in two ways: first by requiring that Congress create an office before the President can fill it, and second by requiring that the Senate confirm a nominee to an office created by law. These limitations on the President‚Äôs power make executive appointments accountable to Congress and make the Senate‚Äôs confirmation decisions accountable to the people. See United States v. Arthrex, 594 U.S. 1, 12 (2021). In this way, the Appointments Clause serves a vital role in curbing Executive abuses of power.</em></p></blockquote><p>Yet here we have Musk wielding a shocking amount of power, the complaint continues:</p><blockquote><p><em>Mr. Musk‚Äôs seemingly limitless and unchecked power to strip the government of its workforce and eliminate entire departments with the stroke of a pen or click of a mouse would have been shocking to those who won this country‚Äôs independence. There is no office of the United States, other than the President, with the full power of the Executive Branch, and the sweeping authority now vested in a single unelected and unconfirmed individual is antithetical to the nation‚Äôs entire constitutional structure.</em></p></blockquote><p>We have an Appointments Clause for this very reason, the complaint reminds, ‚Äúbecause it prevents one branch from ‚Äúaggrandizing its power‚Äù or ‚Äúdispensing it too freely . . . to inappropriate members of the Executive Branch.‚Äù It explains that there are three types of personnel that can work for the Executive Branch, ‚ÄúPrinciple Officers,‚Äù ‚ÄúInferior Officers,‚Äù and employees. The last category doesn‚Äôt require Senate confirmation, but it also isn‚Äôt endowed with the sort of executive power that Musk has been claiming. The other categories are, which is why they require nominations by the President and Senate approval, unless Congress has already passed a law foregoing that process. But Congress can only do that for inferior officers, it has not done so here, and in any case Musk is acting more like a Principle Officer anyway.</p><p>Furthermore, even for Principle Officers the President simply can‚Äôt make up a job with such power and appoint someone to it. And <em>even Justice Thomas agrees</em>! The complaint cites what he wrote less than a year ago in :</p><blockquote><p><em>Importantly, the Appointments Clause only grants the President the power to nominate officers to offices that Congress has already ‚Äúestablished by Law.‚Äù U.S. Const. art. II, ¬ß 2, cl. 2. ‚ÄúIf Congress has not reached a consensus that a particular office should exist, the Executive lacks the power to unilaterally create and then fill that office.‚Äù Trump v. United States, 603 U.S. 593, 650 (2024) (Thomas, J., concurring). ‚ÄúBy keeping the ability to create offices out of the President‚Äôs hands, the Founders ensured that no President could unilaterally create an army of officer positions to then fill with his supporters. Instead, our Constitution leaves it in the hands of the people‚Äôs elected representatives to determine whether new executive offices should exist.‚Äù Id. at 646 (Thomas, J., concurring).</em></p></blockquote><p>Yet here we are, with Trump having done exactly what Justice Thomas said he could not, for the very reasons Justice Thomas himself said he could not.</p><p>The complaint then takes 30 pages to document Musk and DOGE‚Äôs unlawful rampage through executive branch agencies, in what is surely only scratching the surface of the full depth of how he has abused his unlawful power, and still continues to abuse it.</p><p>And so the lawsuit asks for this power to be enjoined so that Musk and DOGE are forced to stop their destruction. In fact, it‚Äôs also now asked for a temporary restraining order to get Musk and DOGE to stop what they are doing immediately:</p><blockquote><p><em>[T]he States ask the court to issue a temporary restraining order that immediately and temporarily, until such time as the Court may hear a motion for preliminary injunction, orders Mr. Musk to identify all ways in which any data obtained through unlawful agency access was used, including whether it was used to train any algorithmic models or create or obtain derivative data, orders Mr. Musk to destroy any copies or any derivative data from such unauthorized access in his or DOGE‚Äôs possession, custody, or control, and bars Mr. Musk and personnel associated with DOGE from:(a) ordering any change in the disbursement of public funds by agencies;<p>(b) extending offers on behalf of the United States that would bind the government to an</p>appropriation that has not been authorized by law;<p>(c) cancelling government contracts;</p>(d) disposing of government property;<p>(e) ordering the rescission or amendment of regulations;</p>(f) making personnel decisions for agency employees;<p>(g) taking steps to dismantle agencies created by law or otherwise asserting control over</p>such agencies, including, e.g., placing employees on administrative leave;<p>(h) accessing sensitive and confidential agency data, using agency data for other than its</p>authorized purpose;<p>(i) altering agency data systems without authorization by law and without taking all</p>appropriate protections against cybersecurity risks;<p>(j) engaging in any other conduct that violates the Appointments Clause or exceeds</p>statutory authority.</em></p></blockquote><p>But beyond that the complaint also asks for declaratory relief such that a court finally speaks to the unlawful nature of Musk‚Äôs power (as well as that of its DOGE agency, which, as the complaint explains, is also malformed if it is to claim the sort of supervisory power that it has, which is a power that can only be endowed by Congress):</p><blockquote><p><em>DOGE has purported to exercise authority of its own, and not merely to have acted as an adviser to the President. ‚ÄúAdministrative agencies are creatures of statute. They accordingly possess only the authority that Congress has provided.‚Äù Nat‚Äôl Fed‚Äôn of Indep. Bus. v. Dep‚Äôt of Lab., Occupational Safety &amp; Health Admin., 595 U.S. 109, 117 (2022) (per curiam). Congress has not provided any authority to DOGE. The Constitution does not provide any authority to DOGE. The temporary organization statute, 5 U.S.C. ¬ß 3161, [that Trump claimed in his Executive Order was empowering DOGE] does not provide DOGE with the authority it has purported to exercise. That statute provides that a ‚Äútemporary organization‚Äù is defined as an organization ‚Äúestablished by law or Executive order for a specific period not in excess of three years for the purpose of performing a specific study or other project.‚Äù 5 U.S.C. ¬ß 3161(a)(1) (emphasis added). There is no plausible definition of ‚Äúproject‚Äù that would include DOGE‚Äôs attempt to remake the entire Executive Branch, as described above, or to destroy agencies, fire personnel, halt funding, or dispose of government property.</em></p></blockquote><p>In asking for declaratory relief a few things are accomplished. For one thing, it gives those whom Musk and DOGE are bossing around the ability to say no. In fact, if gives them the obligation to say no, because what they are being asked to do would be an unlawful order and thus unlawful for them to do. (Of course, the injunction/TRO would also restrict Musk and DOGE from even making such demands.)</p><p>But it also inches us forward to the real prize here: holding everyone involved with DOGE personally liable for the harm they have caused. By establishing that what they have done has been unlawful it provides the predicate basis for potentially all sorts of forms of liability, including the <a href=\"https://www.techdirt.com/2025/02/04/when-its-not-just-a-coup-but-a-cfaa-violation-too/\">CFAA</a>, which the USAID workers suit also provides more evidence of liability for, including in its allegations that . See page 6-7 of the <a href=\"https://www.courtlistener.com/docket/69636722/4/does-1-26-v-musk/\">complaint</a>:*</p><blockquote><p><em>J. Doe 2 understands that the DOGE personnel had administrative privileges into all the USAID systems and tools and that DOGE personnel took information out of the agency and sent it elsewhere. DOGE‚Äôs actions have caused J. Doe 2 emotional injury, as J. Doe 2 is aware of the extent of confidential information that has been breached and the privacy laws broken.</em></p></blockquote><p>And the declaratory judgment would help overcome another legal issue: whether anyone associated with DOGE would be entitled to any sort of governmental immunity for the harm they‚Äôve caused. This will be an issue to analyze further, because we have, and would normally want to have, some immunity shielding government officials from liability for doing their jobs, if we are going to leave them sufficiently free to do their jobs. But here no one in DOGE actually had a job that would have entitled them to do what they have done. Which is what these 14 states are asking a court to finally and declaratively say.</p>","contentLength":10237,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The 20 year old PSP can now connect to WPA2 WiFi Networks","url":"https://wololo.net/2025/02/14/the-20-year-old-psp-can-now-connect-to-wpa2-wifi-networks/","date":1739590316,"author":"zdw","guid":274,"unread":true,"content":"<div><img data-recalc-dims=\"1\" fetchpriority=\"high\" decoding=\"async\" aria-describedby=\"caption-attachment-49719\" src=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=848%2C477&amp;ssl=1\" alt=\"\" width=\"848\" height=\"477\" srcset=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?w=848&amp;ssl=1 848w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=768%2C432&amp;ssl=1 768w\" sizes=\"(max-width: 848px) 100vw, 848px\"><p>Screenshot source: Zekiu_ on youtube</p></div><p><a href=\"https://wololo.net/tag/acid_snake\">Acid_Snake</a> and the <a href=\"https://wololo.net/tag/ark-4/\">ARK</a> Development team have released a significant update to the ARK custom Firmware for the Sony PSP. Custom Firmware now allows the Playstation Portable to connect to WPA2 encrypted Wifi networks. This is thanks to the recently released  plugin, created by developer  and published on the PSP Homebrew discord.</p><h2>Playstation Portable gets WPA2 Wifi access</h2><p>The PSP has been out of official support from Sony for years, but lots of enthusiasts keep maintaining this great handheld through homebrew and custom Firmware updates. As technology evolves around us, older devices such as the PlayStation Portable can lose some of their features.</p><p>For example, as WPA2 has become the defacto encryption standard for home wifi networks (WPA3‚Äôs adoption rate remains low), older devices such as the PSP, that do not support these new* encryption standards become technically unable to access the internet.</p><p>Wifi access was a very strong feature of the PSP when it was released, and, although it‚Äôs probably less important nowadays, losing that feature because newer networks aren‚Äôt compatible is a bummer.</p><p>WPA2 support has been a request by many enthusiasts for years on PSP discussion channels, and it seems that the wpa2psp plugin by developer Moment now brings this to life. According to Acid_Snake, the developer was kind enough to provide the source code of the plugin, which allowed the ARK team to embed it into the ARK Custom Firmware for PSP.</p><div><img data-recalc-dims=\"1\" decoding=\"async\" aria-describedby=\"caption-attachment-49720\" src=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=1024%2C321&amp;ssl=1\" alt=\"\" width=\"1024\" height=\"321\" srcset=\"https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=1024%2C321&amp;ssl=1 1024w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=300%2C94&amp;ssl=1 300w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=768%2C241&amp;ssl=1 768w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?w=1124&amp;ssl=1 1124w\" sizes=\"(max-width: 1000px) 100vw, 1000px\"></div><p><a href=\"https://www.reddit.com/r/psphacks/comments/1iimnft/wpa2_now_works_on_psp_thanks_to_a_new_plugin/\">This reddit thread</a> by Nebula_NL covers a lot of details on how to install and use the plugin. But the bottom line is: install the latest release of the ARK CFW on your PSP, and take it from there. (Note that you can also manually install the plugin if you‚Äôre using another CFW than ARK)</p><p>This is of course the first iteration of this plugin, and it comes with limitations, specifically:</p><ul><li>2.4 GHz Only\n<ul><li>WPA2 support works with 2.4 GHz WiFi.</li><li>If your router uses a single SSID for both 2.4 GHz and 5 GHz, you may need to separate them and connect your PSP to the 2.4 GHz network.</li></ul></li><li>WPA2 AES Only\n<ul><li>Requires WPA2 with AES (AES-CCMP) encryption.</li><li>TKIP is not supported and will not work.</li></ul></li><li>WEP/WPA Compatibility\n<ul><li>While WPA2 is active, WEP and WPA encryption will not work.</li><li>To use WEP or WPA again, disable WPA2, and they will function normally.</li></ul></li><li>WPA2/WPA3 Mixed Mode\n<ul><li>If your router is set to WPA2/WPA3 mixed mode, your PSP may struggle to obtain an IP address.</li><li>Try manually setting the IP address instead of using DHCP in [AUTO] mode.</li></ul></li></ul><h2>Download and install ARK-4 + enable WPA2 Support for the PSP</h2><p><em>* WPA2 was certified in 2004‚Ä¶ It‚Äôs ‚Äúnew‚Äù from the PSP‚Äôs perspective which launched the same year and didn‚Äôt ‚Äúneed‚Äù to support it at the time. WPA3 launched in 2018 but its adoption is taking time</em></p>","contentLength":2772,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43055671"},{"title":"Brake Pad Dust Can Be More Toxic Than Exhaust Emissions, Study Says","url":"https://tech.slashdot.org/story/25/02/15/0016236/brake-pad-dust-can-be-more-toxic-than-exhaust-emissions-study-says?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739590200,"author":"BeauHD","guid":316,"unread":true,"content":"Bruce66423 shares a report from The Guardian: Microscopic particles emitted from brake pads can be more toxic than those emitted in diesel vehicle exhaust, a study has found. This research shows that even with a move to electric vehicles, pollution from cars may not be able to be eradicated. The researchers found that a higher concentration of copper in some commonly used brake pads was associated with increased harmful effects on sensitive cells from people's lungs, as a result of particles being breathed in.\n \nExposure to pollution generated by cars, vans and lorries has been previously been linked to an increased risk of lung and heart disease. While past attention has mainly concentrated on exhaust emissions, particles are also released into the air from tyre, road and brake pad wear. These emissions are largely unregulated by legislation and the study found that these √¢oenon-exhaust√¢ pollution sources are now responsible for the majority of vehicle particulate matter emissions in the UK and parts of Europe, with brake dust the main contributor among them.\n \n[...] The scientists examined the effects on lung health of particulate matter from four different types of brake pad with differing chemical compositions; low metallic, semi-metallic, non-asbestos organic and hybrid-ceramic. Results showed that of the four types of brake pads, non-asbestos organic pads were the most potent at inducing inflammation and other markers of toxicity, and were found to be more toxic to human lung cells than diesel exhaust particles. Ceramic pads were the second most toxic. Dr. Ian Mudway, senior lecturer at the school of public health at Imperial College London, cautioned that while the research on brake pad emissions appears sound, it is premature to conclude they are worse than diesel exhaust due to \"uncontrolled variables\" like brake disc types and particle composition.\n \nSlashdot reader Bruce66423 also notes it \"doesn't discuss the significance of regenerative breaking, which is a feature of at least some electric cars [that reduces brake pad wear by using the electric motor to slow down the vehicle and recover energy].\"\n \nThe research has been published in the journal Particle and Fibre Technology.","contentLength":2229,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Theoretical and Experimental Constraints: Discussing Different Constraints on the Model Parameters","url":"https://hackernoon.com/theoretical-and-experimental-constraints-discussing-different-constraints-on-the-model-parameters?source=rss","date":1739588801,"author":"Phenomenology Technology","guid":74,"unread":true,"content":"<h2>3.3 Theoretical and experimental constraints</h2><p>We discuss different constraints on the model parameters such asùëà(1)ùëã gauge coupling and scalar mixing angle. To estimate the constraints we consider vacuum stability, perturbative unitarity, and collider searches of BSM Higgs and ùëç‚Ä≤ boson respectively.</p><p>The above scalar potential must be bounded from below. To determine the conditions for ùëâ(ùêª, Œ¶, ùúí) to be bounded from below, we need to check the following symmetric matrix which comes from the quadratic part of the potential,</p><p>\\\nRequiring such a matrix to be positive-definite, we obtain the following conditions,</p><h3>3.3.2 Higgs Invisible decay</h3><p>\\\nHence the total invisible decay width of SM Higgs boson ‚Ñé1 is given a</p><p>\\\nAccordingly, the invisible branching ratio for ‚Ñé1 is given b</p><h3>3.3.4 Bounds on the mixing parameter between physical mass eigenstates</h3><p>(1) Shivam Gola, The Institute of Mathematical Sciences, Chennai.</p>","contentLength":928,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Phenomenological Study of WIMP Models: Scalar Sector, Gauge Sector, and More","url":"https://hackernoon.com/a-phenomenological-study-of-wimp-models-scalar-sector-gauge-sector-and-more?source=rss","date":1739588422,"author":"Phenomenology Technology","guid":73,"unread":true,"content":"<p>\\\nIn the next subsections, we discuss various parts of the lagrangian of the model,</p><p>\\\nwhere ùõº is the mixing angle. The rotation matrix satisfies</p><p>\\\nThe real and imaginary components of ùúí have the following masses</p><p>To determine the gauge boson spectrum, we have to expand the scalar kinetic terms and replace</p><p>The Yukawa sector of the model can be written in a gauge-invariant way as</p><p>(1) Shivam Gola, The Institute of Mathematical Sciences, Chennai.</p>","contentLength":446,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Studying a Two-Component Dark Matter Model: An Introduction","url":"https://hackernoon.com/studying-a-two-component-dark-matter-model-an-introduction?source=rss","date":1739588136,"author":"Phenomenology Technology","guid":72,"unread":true,"content":"<p>In this chapter, we study a two-component DM model interacting with SM via Higgs and Z portals. The results are based on the work: Arindam Das, Shivam Gola, Sanjoy Mondal, Nita Sinha, \"Two-Components Scalar and Fermionic Dark Matter candidates in a generic U(1)ùëã model, Phys.Lett.B 2022.137117‚Äù.</p><p>Underpinning the origin of neutrino mass and elucidating the nature of DM would constitute a major step forward in particle physics. Several simple extensions of the SM that can account for the DM have already been studied [136‚Äì143]. In these models, the SM particle content is extended by additional fields, and a discrete symmetry is usually introduced to guarantee the stability of the DM particle in cosmological scale. In recent years, a class of models has been proposed to incorporate the neutrino mass generation and the existence of DM in a unified framework. Motivated by this, people have studied well-motivated BSM framework based on the gauged ùëà(1)ùëã model [144‚Äì146]. The most intriguing aspect of this model is that including three generations of right-handed neutrinos, as in the type-I seesaw process for creating light neutrino masses, is no longer an option, but emerges as the simplest solution to eliminate the gauge and mixed gauge-gravity anomalies [147]. The scalar DM can be inherently stable in such models due to its ùëà(1)ùëã charge, but the fermionic DM cannot be realized in the simplest ùëà(1)ùëã model. Additional discrete symmetries can be introduced, which can stabilize one of the right-handed neutrinos to play the role of DM, while the other two neutrinos participate in the type I seesaw process to generate the required light neutrino masses and flavor mixing. Also, there are many models proposed in the literature, where neutrino mass generation is intimately connected with DM [148‚Äì153]. In these types of models, DM is a mediator of neutrino mass generation.</p><p>\\\nA single-particle DM model may not be sufficient to account for the relic density of DM observed in the universe. Many such models face strong constraints from direct detection experiments and other observations. Therefore, it is reasonable to consider multi-particle DM scenarios, where two or more particles contribute to the DM abundance. [24,62,126]. Multi-component DM refers to a situation in which two or more particles contribute to the measured DM density. This has been already studied in many BSM scenarios [31, 56, 57, 154‚Äì166]. The multi-component DM model has also some benefits over the single dark matter scenario. For instance, it can avoid some stringent constraints arising from various experiments that probe the properties and interactions of dark matter and other particles. A multi-component DM model can also accommodate different observational features of dark matter, such as its distribution and abundance in the universe.</p><p>(1) Shivam Gola, The Institute of Mathematical Sciences, Chennai.</p>","contentLength":2933,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How I Became A Machine Learning Engineer (No CS Degree, No Bootcamp)","url":"https://towardsdatascience.com/how-i-became-a-machine-learning-engineer-no-cs-degree-no-bootcamp/","date":1739586781,"author":"Egor Howell","guid":10,"unread":true,"content":"<p>Machine learning and <a href=\"https://towardsdatascience.com/tag/ai/\" title=\"AI\">AI</a> are among the most popular topics nowadays, especially within the tech space. I am fortunate enough to work and develop with these technologies every day as a machine learning engineer!</p><p>In this article, I will walk you through my journey to becoming a machine learning engineer, shedding some light and advice on how you can become one yourself!</p><p>In one of my previous articles, I extensively wrote about my journey from school to securing my first <a href=\"https://towardsdatascience.com/tag/data-science/\" title=\"Data Science\">Data Science</a> job. I recommend you <a href=\"https://medium.com/towards-data-science/how-i-became-a-data-scientist-no-cs-degree-no-bootcamp-82c321904986\">check out that article</a>, but I will summarise the key timeline here.</p><p>Pretty much everyone in my family studied some sort of STEM subject. My great-grandad was an engineer, both my grandparents studied physics, and my mum is a maths teacher.</p><p><em>So, my path was always paved for me.</em></p><p>I chose to study physics at university after watching The Big Bang Theory at age 12; it‚Äôs fair to say everyone was very proud!</p><p>At school, I wasn‚Äôt dumb by any means. I was actually relatively bright, but I didn‚Äôt fully apply myself. I got decent grades, but definitely not what I was fully capable of.</p><p>I was very arrogant and thought I would do well with zero work.</p><p>I applied to top universities like Oxford and Imperial College, but given my work ethic, I was delusional thinking I had a chance. On results day, I ended up in clearing as I missed my offers. This was probably one of the saddest days of my life.</p><p>Clearing in the UK is where universities offer places to students on certain courses where they have space. It‚Äôs mainly for students who don‚Äôt have a university offer.</p><p>I was lucky enough to be offered a chance to study physics at the University of Surrey, and I went on to earn a first-class master‚Äôs degree in physics!</p><p>There is genuinely no substitute for hard work. It is a cringy cliche, but it is true!</p><p>My original plan was to do a PhD and be a full-time researcher or professor, but during my degree, I did a research year, and I just felt a career in research was not for me. Everything moved so slowly, and it didn‚Äôt seem there was much opportunity in the space.</p><p>During this time, DeepMind released their<a href=\"https://www.youtube.com/watch?v=WXuK6gekU1Y&amp;t=1539s\"></a>documentary on YouTube, which popped up on my home feed.</p><p>From the video, I started to understand how AI worked and learn about neural networks, reinforcement learning, and deep learning. To be honest, to this day I am still not an expert in these areas.</p><p>Naturally, I dug deeper and found that a data scientist uses AI and machine learning algorithms to solve problems. I immediately wanted in and started applying for data science graduate roles.</p><p>I spent countless hours coding, taking courses, and working on projects. I applied to and eventually landed my first data science graduate scheme in September 2021.</p><p><em>You can hear more about my journey from a <a href=\"https://tobeadatascientist.substack.com/p/overcoming-rejection-lessons-from-egor-howell\">podcast</a>.</em></p><p>I started my career in an insurance company, where I built various supervised learning models, mainly using gradient boosted tree packages like CatBoost, XGBoost, and<a href=\"https://medium.com/towards-data-science/breaking-down-generalized-linear-models-d9212526e51d?sk=fda0298cebcb8e9e0c20cb6af8ed4f06\"> generalised linear models (GLMs)</a>.</p><p>I built models to predict:</p><ul><li>‚Ää‚Äî‚ÄäDid someone fraudulently make a claim to profit.</li><li>‚Äî‚ÄäWhat‚Äôs the premium we should give someone.</li><li>‚Äî‚ÄäHow many claims will someone have.</li><li>‚Ää‚Äî‚ÄäWhat‚Äôs the average claim value someone will have.</li></ul><p>I made around six models spanning the regression and classification space. I learned so much here, especially in statistics, as I worked very closely with Actuaries, so my maths knowledge was excellent.</p><p>However, due to the company‚Äôs structure and setup, it was difficult for my models to advance past the PoC stage, so I felt I lacked the ‚Äútech‚Äù side of my toolkit and understanding of how companies use machine learning in production.</p><p>After a year, my previous employer reached out to me asking if I wanted to apply to a junior data scientist role that specialises in<a href=\"https://medium.com/@egorhowell/list/time-series-00bbfb9f5359\"> time series forecasting</a> and<a href=\"https://medium.com/@egorhowell/list/optimisation-algorithms-069bf9c6c8d5\"> optimisation</a> problems. I really liked the company, and after a few interviews, I was offered the job!</p><p>I worked at this company for about 2.5 years, where I became an expert in forecasting and combinatorial optimisation problems.</p><p>I developed many algorithms and deployed my models to production through AWS using software engineering best practices, such as unit testing, lower environment, shadow system, CI/CD pipelines, and much more.</p><p><em>Fair to say I learned a lot.&nbsp;</em></p><p>I worked very closely with software engineers, so I picked up a lot of engineering knowledge and continued self-studying machine learning and statistics on the side.</p><p>Over time, I realised the actual value of data science is using it to make live decisions. There is a good quote by<a href=\"https://www.linkedin.com/posts/pau-labarta-bajo-4432074b_machinelearning-mlops-realworldml-activity-7195694289178214400-gZyw\"> Pau Labarta Bajo</a></p><p>ML models inside Jupyter notebooks have a business value of $0</p><p>There is no point in building a really complex and sophisticated model if it will not produce results. Seeking out that extra 0.1% accuracy by staking multiple models is often not worth it.</p><p>You are better off building something simple that you can deploy, and that will bring real financial benefit to the company.</p><p>With this in mind, I started thinking about the future of data science. In my head, there are two avenues:</p><ul><li> -&gt; You work primarily to gain insight into what the business should be doing and what it should be looking into to boost its performance.</li><li> -&gt; You ship solutions (models, decision algorithms, etc.) that bring business value.</li></ul><p>I feel the data scientist who analyses and builds PoC models will become extinct in the next few years because, as we said above, they don‚Äôt provide tangible value to a business.</p><p>That‚Äôs not to say they are entirely useless; you have to think of it from the business perspective of their return on investment. Ideally, the value you bring in should be more than your salary.</p><p>You want to say that you did ‚ÄúX that produced Y‚Äù, which the above two avenues allow you to do.</p><p>The engineering side was the most interesting and enjoyable for me. I genuinely enjoy coding and building stuff that benefits people, and that they can use, so naturally, that‚Äôs where I gravitated towards.</p><p>To move to the ML engineering side, I asked my line manager if I could deploy the algorithms and ML models I was building myself. I would get help from software engineers, but I would write all the production code, do my own system design, and set up the deployment process independently.</p><p><em>And that‚Äôs exactly what I did.</em></p><p>Coincidentally, my current employer contacted me around this time and asked if I wanted to apply for a machine learning engineer role that specialises in general ML and optimisation at their company!</p><p>Call it luck, but clearly, the universe was telling me something. After several interview rounds, I was offered the role, and I am now a fully fledged machine learning engineer!</p><p>Fortunately, a role kind of ‚Äúfell to me,‚Äù but I created my own luck through up-skilling and documenting my learning. That is why I always tell people to show their work‚Ää‚Äî‚Ääyou don‚Äôt know what may come from it.</p><p>I want to share the main bits of advice that helped me transition from a machine learning engineer to a data scientist.</p><ul><li>‚Ää‚Äî‚ÄäA machine learning engineer is  an entry-level position in my opinion. You need to be well-versed in data science, machine learning, software engineering, etc. You don‚Äôt need to be an expert in all of them, but have good fundamentals across the board. That‚Äôs why I recommend having a couple of years of experience as either a software engineer or data scientist and self-study other areas.</li><li>‚Ää‚Äî‚ÄäIf you are from data science, you must learn to write good, well-tested production code. You must know things like typing, linting, unit tests, formatting, mocking and CI/CD. It‚Äôs not too difficult, but it just requires some practice. I recommend asking your current company to work with software engineers to gain this knowledge, it worked for me!</li><li>‚Ää‚Äî‚ÄäMost companies nowadays deploy many of their architecture and systems on the cloud, and machine learning models are no exception. So, it‚Äôs best to get practice with these tools and understand how they enable models to go live. I learned most of this on the job, to be honest, but there are courses you can take.</li><li>‚Ää‚Äî‚ÄäI am sure most of you know this already, but every tech professional should be proficient in the command line. You will use it extensively when deploying and writing production code. I have a basic guide you can checkout<a href=\"https://medium.com/towards-data-science/an-introduction-to-the-shell-676ee5b899df?sk=0c6e101165b4314b98ab39d11525366c\"> here</a>.</li><li><strong>Data Structures &amp; Algorithms‚Ää</strong>‚Äî‚ÄäUnderstanding the fundamental algorithms in computer science are very useful for MLE roles. Mainly because you will likely be asked about it in interviews. It‚Äôs not too hard to learn compared to machine learning; it just takes time. Any course will do the trick.</li><li>‚Ää‚Äî‚ÄäAgain, most tech professionals should know Git, but as an MLE, it is essential. How to squash commits, do code reviews, and write outstanding pull requests are musts.</li><li>‚Ää‚Äî‚ÄäMany MLE roles I saw required you to have some specialisation in a particular area. I specialise in time series forecasting, optimisation, and general ML based on my previous experience. This helps you stand out in the market, and most companies are looking for specialists nowadays.</li></ul><p>The main theme here is that I basically up-skilled my software engineering abilities. This makes sense as I already had all the math, stats, and machine learning knowledge from being a data scientist.</p><p>If I were a software engineer, the transition would likely be the reverse. This is why securing a machine learning engineer role can be quite challenging, as it requires proficiency across a wide range of skills.</p><h3><strong>Summary &amp; Further Thoughts</strong></h3><p>I have a free newsletter, <a href=\"https://dishingthedata.substack.com/\"></a>, where I share weekly tips and advice as a practising data scientist. Plus, when you subscribe, you will get my and<strong> short PDF version of my AI roadmap</strong>!</p>","contentLength":9683,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI and the Future of Work: Transforming Industries","url":"https://hackernoon.com/ai-and-the-future-of-work-transforming-industries?source=rss","date":1739585602,"author":"Ombir Sharma","guid":71,"unread":true,"content":"<p>AI or artificial intelligence is the capability and ability of a machine to imitate human intelligence. Intelligent systems are capable of learning, reasoning, and self-correcting. AI includes a number of technologies such as machine learning, natural language processing, robotics, and computer vision. It is able to perform a wide array of functions from simple repetitive work to making complex decisions which changes the very fabric of industries.</p><h2>The Rise of Robotics and AI</h2><p>The combination of <a href=\"https://hackernoon.com/artificial-intelligence-and-robotics-whos-at-fault-when-robots-kill-a01u3ear\">AI and robotics</a> is changing the world at an unprecedented rate; human errors are greatly reduced and proficiency is greatly improved across multiple industries. Robots powered by AI can be programmed to accomplish tasks that previously only humans could perform. From AI-trained chatbots at customer service to assembly lines in factories, this newly developed technology changes the workplace alongside societal norms.</p><h3>Effect of Artificial Intelligence on Employment</h3><p>AI is a double-edged sword with its impact on employment. The technology has created several new opportunities and increased overall productivity in numerous ways, however, it has also posed great threats to certain jobs and industries which can lead to displacement of employees.</p><p>An important shift is on the horizon as the job market is about to undergo a role reversal change. As AI technology evolves, it is taking over the more labor-intensive tasks and as a result, human workers are becoming more strategic and analytic. AI alleviates repetitive tasks and allows employees to focus on creative problem-solving.</p><p>The new approach AI takes centers around<a href=\"https://www.intelligenceinsights.net/artificial-intelligence/autogpt-the-future-of-autonomous-ai-assistants/\"></a>, just like the Industrial Revolution. While focusing on increasing productivity, ChatGPT and AutoGPT have the potential to perform tasks such as data entry, scheduling, and even more complex problem-solving, increasing overall demand for customer service representatives and support agents. In every age, these shifts in productivity have led to increased job opportunities, just like the multiple industries that formed alongside the technology integrations.</p><h3>Facilitation of Employment</h3><p>The introduction of ChatGPT can aid everyday business operations, serving as virtual assistants that communicate primarily with customers. By streamlining business functions for flexible resource allocation, productivity is sure to increase. Efficient use of ChatGPT makes it incredibly simple for businesses to automate their customer inquiries, increasing profit margins.</p><p>ChatGPT encourages an environmentally friendly approach by seamlessly optimizing supply chains with effective waste reduction strategies. AI, without a doubt, would optimize ChatGPT-provided decision-making to improve overall energy consumption and ensure economic goals are catered towards too.</p><p>In the absence of people, ChatGPT opens doors to new interactions that drastically improve service and business operations through automation. Communication via virtual assistants and chatbots allows for effortless collaboration and automated customer interactions on a new level.</p><p>\\\nIn every way possible, AI improves business decision-making by offering adequate utility and data for correct allocation. Business AI helps set prices, predict market movement, and analyze how much risk varies. Keeping track of tools like ChatGPT can aid project-based decisions by providing up-to-date information.</p><h3>Elimination of Junior and Mid-level Staff Positions</h3><p>As a result of automation, junior and mid-level roles, particularly in data entry and administrative duties and tasks, are being skinned out. More companies seem to be using AI, which, in turn, is leading to an increased need for highly specialized and senior positions that require a supervisor to think strategically.</p><p>Across different industries, AI is changing the future of work. From performing simple services to making complex decisions, AI has a broad range of applications, and as time goes by, the list only seems to grow.</p><h2>The Use Of AI In Business</h2><p>Artificial intelligence is being adopted in all sectors to boost productivity, accuracy, and satisfaction of customers. It is used in recruitment HR, in<a href=\"https://www.thenexthint.com/a-new-era-in-customer-service-with-automation/\"></a> through chatbots, and in marketing through brand campaigns. Work processes are now being automated with AI, thereby, minimizing the costs of running the business.</p><h3>Impact Of AI On Business Operations</h3><p>Software developments with regard to Artificial intelligence utilizing machine learning and automation present the future of the workplace, resulting in increased productivity. Businesses will continuously adopt AI to better their decisions, improve work processes, and promote creativity. Because of this, more skills in AI will be needed which will translate to new positions being created.</p><p>In the field of finance, AI handles fraud detection, automates trading, and enhances risk assessments. Robo-advisors make investment suggestions based on a client‚Äôs unique profile, and AI chatbots provide further engagement with customers.</p><p>AI assists in diagnosing diseases and personalizes treatments for patients in healthcare. With the help of <a href=\"https://hackernoon.com/the-future-of-robotics-development-with-eva-li-of-vincross-dd8d85256d4e\">AI-led robots</a>, humans can make fewer mistakes while performing surgeries, which helps enhance patient care.</p><p>In the automotive sector, AI enables self-driving cars, predictive maintenance, and smart traffic control. AI technologies also help improve vehicle safety and fuel efficiency.</p><p><a href=\"https://hackernoon.com/how-the-us-government-plans-to-ensure-the-safety-and-security-of-ai-technology\">Cybersecurity</a> is enhanced by AI technologies that assess new threats, detect anomalies, and provide assistance during the occurrence of cyber-attacks. Data security is also improved and business risks are suppressed by AI technologies.</p><p>In the e-commerce sector, AI improves customer experiences, automates supply chains, and increases the level of service. Recommendation systems based on users' behavior increase the total sales and satisfaction level of customers.</p><p>We see the growth of AI in hospitality in chatbots, smart booking systems, and customer experience applications. AI analytics also help with effective guest price settings and greater guest satisfaction.</p><p>AI greatly assists in providing relevant lists of jobs that best suit a candidate's skills. AI technology helps to read a CV, understand the candidate's level of skills, and determine his success.</p><h2>Are My Working Opportunities On The Line Due To AI?</h2><p>Filling positions for repetitive work is indeed scalable with AI which is why it poses a threat for employment. In reality, AI also creates new possibilities by taking up low-productivity tasks. It is expected that new jobs that require creative thinking, emotions, and strategy-based decision-making will still exist. To ensure that they remain employed, workers must learn new skills and adjust to the new reality.</p><p>AI is enabling the future of work by performing tasks that require time and effort, growing productivity, and changing the existing categorization of industries. Some roles may be lost, but there are always new positions that have to be filled. Being able to utilize AI together with other novel technologies is crucial to be successful for business professionals in the new world.</p>","contentLength":7063,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"'Please Stop Inviting AI Notetakers To Meetings'","url":"https://slashdot.org/story/25/02/15/006253/please-stop-inviting-ai-notetakers-to-meetings?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739584920,"author":"BeauHD","guid":315,"unread":true,"content":"Most virtual meeting platforms these days include AI-powered notetaking tools or bots that join meetings as guests, transcribe discussions, and/or summarize key points. \"The tech companies behind them might frame it as a step forward in efficiency, but the technology raises troubling questions around etiquette and privacy and risks undercutting the very communication it's meant to improve (paywalled; alternative source),\" writes Chris Stokel-Walker in a Weekend Essay for Bloomberg. From the article: [...] The push to document every workplace interaction and utterance is not new. Having a paper trail has long been seen as a useful thing, and a record of decisions and action points is arguably what makes a meeting meaningful. The difference now is the inclusion of new technology that lacks the nuance and depth of understanding inherent to human interaction in a meeting room. In some ways, the prior generation of communication tools, such as instant messaging service Slack, created its own set of problems. Messaging that previously passed in private via email became much more transparent, creating a minefield where one wrong word or badly chosen emoji can explode into a dispute between colleagues. There is a similar risk with notetaking tools. Each utterance documented and analyzed by AI includes the potential for missteps and misunderstandings.\n \nAnyone thinking of bringing an AI notetaker to a meeting must consider how other attendees will respond, says Andrew Brodsky, assistant professor of management at the McCombs School of Business, part of the University of Texas at Austin. Colleagues might think you want to better focus on what is said without missing out on a definitive record of the discussion. Or they might think, \"You can't be bothered to take notes yourself or remember what was being talked about,\" he says. For the companies that sell these AI interlopers, the upside is clear. They recognize we're easily nudged into different behaviors and can quickly become reliant on tools that we survived without for years. [...] There's another benefit for tech companies getting us hooked on AI notetakers: Training data for AI systems is increasingly hard to come by. Research group Epoch AI forecasts there will be a drought of usable text possibly by next year. And with publishers unleashing lawsuits against AI companies for hoovering up their content, the tech firms are on the hunt for other sources of data. Notes from millions of meetings around the world could be an ideal option.\n \nFor those of us who are the source of such data, however, the situation is more nuanced. The key question is whether AI notetakers make office meetings more useless than so many already are. There's an argument that meetings are an important excuse for workers to come together and talk as human beings. All that small talk is where good ideas often germinate -- that's ostensibly why so many companies are demanding staff return to the office. But if workers trade in-person engagement for AI readbacks, and colleagues curb their words and ideas for fear of being exposed by bots, what's left? If the humans step back, all that remains is a series of data points and more AI slop polluting our lives.","contentLength":3228,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Uber sues DoorDash, alleging anti-competitive tactics","url":"https://techcrunch.com/2025/02/14/uber-sues-doordash-alleging-anti-competitive-tactics/","date":1739583337,"author":"Kirsten Korosec, Maxwell Zeff","guid":52,"unread":true,"content":"<p>Ride-share giant Uber filed a lawsuit Friday against DoorDash, accusing the delivery outfit of stifling competition by intimidating restaurant owners into exclusive deals. Uber alleges in the lawsuit, filed in Superior Court of California, that its chief rival bullied restaurants into only working with DoorDash. Uber claims that DoorDash, which holds the largest share of [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":442,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NYC Is Giving Free E-Bikes To Delivery Workers Using Unsafe Models","url":"https://hardware.slashdot.org/story/25/02/14/2336232/nyc-is-giving-free-e-bikes-to-delivery-workers-using-unsafe-models?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739582700,"author":"BeauHD","guid":314,"unread":true,"content":"New York City's Department of Transportation is offering delivery workers the opportunity to swap out uncertified e-bikes for safer UL-compliant models. \"Millions of people rely on such workers for timely deliveries, yet the low wages and brutal conditions of the job have forced many riders to seek out low-cost electric bicycles to perform the work -- exactly the kind of e-bikes that are least likely to have received safety certifications,\" reports Electrek. From the report: The NYC DOT has already begun accepting applications for the new E-Bike Trade-In Program, which is open to delivery workers with non-compliant electric bicycles as well as the often-seen electric scooters/mopeds that don't really qualify as e-bikes, despite their ubiquitous use in the industry. Interestingly, the program even accepts gasoline-powered mopeds that are not able to be legally registered with the DMV, including those that lack VINs. In exchange for trading in a non-certified vehicle, the delivery worker will receive a new UL-certified electric bike with a spare UL-certified battery.\n \nThere are a few requirements for eligibility. The worker has to have earned at least US $1,500 by working in the food delivery industry last year in 2024, live in one of the five New York City boroughs, be at least 18 years old, and own/use one of the eligible devices for trade-in. The program is free to participate in with no additional cost for the delivery workers. However, the supply of free electric bicycles is described as \"limited.\" Those interested need to submit an application before the window closes on March 10, 2025.","contentLength":1618,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go 1.24 Brings Performance Improvements, Better WebAssembly Support","url":"https://www.phoronix.com/news/Go-1.24-Released","date":1739582673,"author":"Michael Larabel","guid":361,"unread":true,"content":"<article>Go 1.24 was released this week by Google engineers as the newest step forward for this popular programming language...</article>","contentLength":118,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing Impressions at Netflix","url":"https://netflixtechblog.com/introducing-impressions-at-netflix-e2b67c88c9fb?source=rss----2615bd06b42e---4","date":1739582000,"author":"Netflix Technology Blog","guid":31,"unread":true,"content":"<h4>Part 1: Creating the Source of Truth for Impressions</h4><p>Imagine scrolling through Netflix, where each movie poster or promotional banner competes for your attention. Every image you hover over isn‚Äôt just a visual placeholder; it‚Äôs a critical data point that fuels our sophisticated personalization engine. At Netflix, we call these images ‚Äòimpressions,‚Äô and they play a pivotal role in transforming your interaction from simple browsing into an immersive binge-watching experience, all tailored to your unique&nbsp;tastes.</p><p>Capturing these moments and turning them into a personalized journey is no simple feat. It requires a state-of-the-art system that can track and process these impressions while maintaining a detailed history of each profile‚Äôs exposure. This nuanced integration of data and technology empowers us to offer bespoke content recommendations.</p><p>In this multi-part blog series, we take you behind the scenes of our system that processes billions of impressions daily. We will explore the challenges we encounter and unveil how we are building a resilient solution that transforms these client-side impressions into a personalized content discovery experience for every Netflix&nbsp;viewer.</p><h3>Why do we need impression history?</h3><p>To tailor recommendations more effectively, it‚Äôs crucial to track what content a user has already encountered. Having impression history helps us achieve this by allowing us to identify content that has been displayed on the homepage but not engaged with, helping us deliver fresh, engaging recommendations.</p><p>By maintaining a history of impressions, we can implement frequency capping to prevent over-exposure to the same content. This ensures users aren‚Äôt repeatedly shown identical options, keeping the viewing experience vibrant and reducing the risk of frustration or disengagement.</p><h4>Highlighting New&nbsp;Releases</h4><p>For new content, impression history helps us monitor initial user interactions and adjust our merchandising efforts accordingly. We can experiment with different content placements or promotional strategies to boost visibility and engagement.</p><p>Additionally, impression history offers insightful information for addressing a number of platform-related analytics queries. Analyzing impression history, for example, might help determine how well a specific row on the home page is functioning or assess the effectiveness of a merchandising strategy.</p><p>The first pivotal step in managing impressions begins with the creation of a Source-of-Truth (SOT) dataset. This foundational dataset is essential, as it supports various downstream workflows and enables a multitude of use&nbsp;cases.</p><h4>Collecting Raw Impression Events</h4><p>As Netflix members explore our platform, their interactions with the user interface spark a vast array of raw events. These events are promptly relayed from the client side to our servers, entering a centralized event processing queue. This queue ensures we are consistently capturing raw events from our global user&nbsp;base.</p><p>After raw events are collected into a centralized queue, a custom event extractor processes this data to identify and extract all impression events. These extracted events are then routed to an Apache Kafka topic for immediate processing needs and simultaneously stored in an Apache Iceberg table for long-term retention and historical analysis. This dual-path approach leverages Kafka‚Äôs capability for low-latency streaming and Iceberg‚Äôs efficient management of large-scale, immutable datasets, ensuring both real-time responsiveness and comprehensive historical data availability.</p><h4>Filtering &amp; Enriching Raw Impressions</h4><p>Once the raw impression events are queued, a stateless Apache Flink job takes charge, meticulously processing this data. It filters out any invalid entries and enriches the valid ones with additional metadata, such as show or movie title details, and the specific page and row location where each impression was presented to users. This refined output is then structured using an Avro schema, establishing a definitive source of truth for Netflix‚Äôs impression data. The enriched data is seamlessly accessible for both real-time applications via Kafka and historical analysis through storage in an Apache Iceberg table. This dual availability ensures immediate processing capabilities alongside comprehensive long-term data retention.</p><h4>Ensuring High Quality Impressions</h4><p>Maintaining the highest quality of impressions is a top priority. We accomplish this by gathering detailed column-level metrics that offer insights into the state and quality of each impression. These metrics include everything from validating identifiers to checking that essential columns are properly filled. The data collected feeds into a comprehensive quality dashboard and supports a tiered threshold-based alerting system. These alerts promptly notify us of any potential issues, enabling us to swiftly address regressions. Additionally, while enriching the data, we ensure that all columns are in agreement with each other, offering in-place corrections wherever possible to deliver accurate&nbsp;data.</p><p>We handle a staggering volume of 1 to 1.5 million impression events globally every second, with each event approximately 1.2KB in size. To efficiently process this massive influx in real-time, we employ Apache Flink for its low-latency stream processing capabilities, which seamlessly integrates both batch and stream processing to facilitate efficient backfilling of historical data and ensure consistency across real-time and historical analyses. Our Flink configuration includes 8 task managers per region, each equipped with 8 CPU cores and 32GB of memory, operating at a parallelism of 48, allowing us to handle the necessary scale and speed for seamless performance delivery. The Flink job‚Äôs sink is equipped with a data mesh connector, as detailed in our <a href=\"https://netflixtechblog.com/data-mesh-a-data-movement-and-processing-platform-netflix-1288bcab2873\">Data Mesh platform</a> which has two outputs: Kafka and Iceberg. This setup allows for efficient streaming of real-time data through Kafka and the preservation of historical data in Iceberg, providing a comprehensive and flexible data processing and storage solution.</p><p>We utilize the ‚Äòisland model‚Äô for deploying our Flink jobs, where all dependencies for a given application reside within a single region. This approach ensures high availability by isolating regions, so if one becomes degraded, others remain unaffected, allowing traffic to be shifted between regions to maintain service continuity. Thus, all data in one region is processed by the Flink job deployed within that&nbsp;region.</p><h4>Addressing the Challenge of Unschematized Events</h4><p>Allowing raw events to land on our centralized processing queue unschematized offers significant flexibility, but it also introduces challenges. Without a defined schema, it can be difficult to determine whether missing data was intentional or due to a logging error. We are investigating solutions to introduce schema management that maintains flexibility while providing clarity.</p><h4>Automating Performance Tuning with Autoscalers</h4><p>Tuning the performance of our Apache Flink jobs is currently a manual process. The next step is to integrate with autoscalers, which can dynamically adjust resources based on workload demands. This integration will not only optimize performance but also ensure more efficient resource utilization.</p><h4>Improving Data Quality&nbsp;Alerts</h4><p>Right now, there‚Äôs a lot of business rules dictating when a data quality alert needs to be fired. This leads to a lot of false positives that require manual judgement. A lot of times it is difficult to track changes leading to regression due to inadequate data lineage information. We are investing in building a comprehensive data quality platform that more intelligently identifies anomalies in our impression stream, keeps track of data lineage and data governance, and also, generates alerts notifying producers of any regressions. This approach will enhance efficiency, reduce manual oversight, and ensure a higher standard of data integrity.</p><p>Creating a reliable source of truth for impressions is a complex but essential task that enhances personalization and discovery experience. Stay tuned for the next part of this series, where we‚Äôll delve into how we use this SOT dataset to create a microservice that provides impression histories. We invite you to share your thoughts in the comments and continue with us on this journey of discovering impressions.</p><p>We are genuinely grateful to our amazing colleagues whose contributions were essential to the success of Impressions: Julian Jaffe, Bryan Keller, Yun Wang, Brandon Bremen, Kyle Alford, Ron Brown and Shriya&nbsp;Arora.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e2b67c88c9fb\" width=\"1\" height=\"1\" alt=\"\">","contentLength":8607,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Microsoft Study Finds Relying on AI Kills Your Critical Thinking Skills","url":"https://slashdot.org/story/25/02/14/2320203/microsoft-study-finds-relying-on-ai-kills-your-critical-thinking-skills?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739580300,"author":"BeauHD","guid":313,"unread":true,"content":"A new study (PDF) from researchers at Microsoft and Carnegie Mellon University found that increased reliance on AI tools leads to a decline in critical thinking skills. Gizmodo reports: The researchers tapped 319 knowledge workers -- a person whose job involves handling data or information -- and asked them to self-report details of how they use generative AI tools in the workplace. The participants were asked to report tasks that they were asked to do, how they used AI tools to complete them, how confident they were in the AI's ability to do the task, their ability to evaluate that output, and how confident they were in their own ability to complete the same task without any AI assistance.\n \nOver the course of the study, a pattern revealed itself: the more confident the worker was in the AI's capability to complete the task, the more often they could feel themselves letting their hands off the wheel. The participants reported a \"perceived enaction of critical thinking\" when they felt like they could rely on the AI tool, presenting the potential for over-reliance on the technology without examination. This was especially true for lower-stakes tasks, the study found, as people tended to be less critical. While it's very human to have your eyes glaze over for a simple task, the researchers warned that this could portend to concerns about \"long-term reliance and diminished independent problem-solving.\"\n \nBy contrast, when the workers had less confidence in the ability of AI to complete the assigned task, the more they found themselves engaging in their critical thinking skills. In turn, they typically reported more confidence in their ability to evaluate what the AI produced and improve upon it on their own. Another noteworthy finding of the study: users who had access to generative AI tools tended to produce \"a less diverse set of outcomes for the same task\" compared to those without.","contentLength":1915,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Did Semgrep Just Get a Lot More Interesting?","url":"https://fly.io/blog/semgrep-but-for-real-now/","date":1739580031,"author":"ghuntley","guid":273,"unread":true,"content":"<p><a href=\"https://ghuntley.com/stdlib/\" title=\"\">This bit by Geoffrey Huntley</a> is super interesting to me and, despite calling out that LLM-driven development agents like Cursor have something like a 40% success rate at actually building anything that passes acceptance criteria, makes me think that more of the future of our field belongs to people who figure out how to use this weird bags of model weights than any of us are comfortable with. </p><p>I‚Äôve been dinking around with Cursor for a week now (if you haven‚Äôt, I think it‚Äôs something close to malpractice not to at least take it ‚Äî or something like it ‚Äî for a spin) and am just now from this post learning that Cursor has this <a href=\"https://docs.cursor.com/context/rules-for-ai\" title=\"\">rules feature</a>. </p><p>The important thing for me is not how Cursor rules work, but rather how Huntley uses them. He turns them back on themselves, writing rules to tell Cursor how to organize the rules, and then teach Cursor how to write (under human supervision) its own rules.</p><p>Cursor kept trying to get Huntley to use Bazel as a build system. So he had cursor write a rule for itself: ‚Äúno bazel‚Äù. And there was no more Bazel. If I‚Äôd known I could do this, I probably wouldn‚Äôt have bounced from the Elixir project I had Cursor doing, where trying to get it to write simple unit tests got it all tangled up trying to make <a href=\"https://hexdocs.pm/mox/Mox.html\" title=\"\">Mox</a> work. </p><p>But I‚Äôm burying the lead. </p><p>Security people have been for several years now somewhat in love with a tool called <a href=\"https://github.com/semgrep/semgrep\" title=\"\">Semgrep</a>. Semgrep is a semantics-aware code search tool; using symbolic variable placeholders and otherwise ordinary code, you can write rules to match pretty much arbitary expressions and control flow. </p><p>If you‚Äôre an appsec person, where you obviously go with this is: you build a library of Semgrep searches for well-known vulnerability patterns (or, if you‚Äôre like us at Fly.io, you work out how to get Semgrep to catch the Rust concurrency footgun of RWLocks inside if-lets).</p><p>The reality for most teams though is ‚Äúain‚Äôt nobody got time for that‚Äù. </p><p>But I just checked and, unsurprisingly, 4o <a href=\"https://chatgpt.com/share/67aa94a7-ea3c-8012-845c-6c9491b33fe4\" title=\"\">seems to do reasonably well</a> at generating Semgrep rules? Like: I have no idea if this rule is actually any good. But it looks like a Semgrep rule?</p><p>What interests me is this: it seems obvious that we‚Äôre going to do more and more ‚Äúclosed-loop‚Äù LLM agent code generation stuff. By ‚Äúclosed loop‚Äù, I mean that the thingy that generates code is going to get to run the code and watch what happens when it‚Äôs interacted with. You‚Äôre just a small bit of glue code and a lot of system prompting away from building something like that right now: <a href=\"https://x.com/chris_mccord/status/1882839014845374683\" title=\"\">Chris McCord is building</a> a thingy that generates whole Elixir/Phoenix apps and runs them as Fly Machines. When you deploy these kinds of things, the LLM gets to see the errors when the code is run, and it can just go fix them. It also gets to see errors and exceptions in the logs when you hit a page on the app, and it can just go fix them.</p><p>With a bit more system prompting, you can get an LLM to try to generalize out from exceptions it fixes and generate unit test coverage for them. </p><p>With a little bit more system prompting, you can probably get an LLM to (1) generate a Semgrep rule for the generalized bug it caught, (2) test the Semgrep rule with a positive/negative control, (3) save the rule, (4) test the whole codebase with Semgrep for that rule, and (5) fix anything it finds that way. </p><p>That is a lot more interesting to me than tediously (and probably badly) trying to predict everything that will go wrong in my codebase a priori and Semgrepping for them. Which is to say: Semgrep ‚Äî which I have always liked ‚Äî is maybe a lot more interesting now? And tools like it?</p>","contentLength":3614,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43054673"},{"title":"AI‚Äôs Hallucinations Are Over","url":"https://hackernoon.com/ais-hallucinations-are-over?source=rss","date":1739579978,"author":"Oleksandr Zabashnyi","guid":70,"unread":true,"content":"<p>First of all, let me describe the problem. I am a software developer, and I don't use AI to write code just because of hallucinations. For creating pictures or writing texts they are not so critical, but for the task of writing code, they are overkill. I have identified two subproblems. Firstly, it is difficult to identify the errors made by AI. It is quite easy for a designer as he counts the fingers in the pictures and that's it; the picture is accepted as the result. </p><p>\\\nHowever, I have to deal with the code and seek the mistakes in it. I hate to do it. Secondly, it is the irreproducibility of the result. For example, I tried to write unit tests: the first generated unit test is successful, but the second one is not, even for the same method. This makes working with it impossible.</p><p>\\\nNow, about the solution. Our hypothesis was as follows: what if we could assign the corresponding result data to a certain set of input information? And do that at least sometimes during the task-solving process. Would that reduce the number of hallucinations? Oh yes! After thorough research, we have come to the conclusion that the presence of a critical mass of such ‚Äòrigidly fixed‚Äô nodes almost completely removed hallucinations from the output. All that remained was to find the criteria for identifying these correspondences between input and output information and to modify the math apparatus to enable the use of this approach. We called this method the \"preset landscape.\"</p><p>\\\nCertainly, our approach has several limitations. First of all, the subject area should imply the existence of only one correct answer for a given set of output data. Fortunately, software development is exactly such an area. The second limitation is that at the stage of landscape formation, the participation of an expert in the subject field is required. In other words, it is impossible to apply the math apparatus to the areas where a human cannot articulate the rules. These limitations greatly narrow the scope of application of our approach. However, its usage in such areas as software development, law, healthcare, and engineering tasks is more than enough.</p><p>\\\nTo demonstrate the capabilities of the math apparatus, we have developed <a href=\"https://drive.google.com/file/d/1mRhGzEeyhcT4EUZj4a4wAZ8TNYSvByRW/view?usp=sharing\">a plugin</a> for IntelliJ Idea (JetBrains). You can install it and make sure that there are no hallucinations. Here, you can find <a href=\"https://drive.google.com/file/d/1mRhGzEeyhcT4EUZj4a4wAZ8TNYSvByRW/view?usp=sharing\">the instructions</a>.</p><p>\\\nWhile we were working on the plugin, AI services came into vogue, which provides API and you can use them in your own solutions. Therefore, we are planning to make such a platform for software development tasks. We will most likely start with Java. If you have an insight into how this approach can be implemented for lawyers or healthcare professionals - feel free to share.</p>","contentLength":2743,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PIN AI Launches Mobile App Letting You Make Your Own Personalized, Private AI Model","url":"https://mobile.slashdot.org/story/25/02/14/2227222/pin-ai-launches-mobile-app-letting-you-make-your-own-personalized-private-ai-model?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739577720,"author":"BeauHD","guid":312,"unread":true,"content":"An anonymous reader quotes a report from VentureBeat: A new startup PIN AI (not to be confused with the poorly reviewed hardware device the AI Pin by Humane) has emerged from stealth to launch its first mobile app, which lets a user select an underlying open-source AI model that runs directly on their smartphone (iOS/Apple iPhone and Google Android supported) and remains private and totally customized to their preferences. Built with a decentralized infrastructure that prioritizes privacy, PIN AI aims to challenge big tech's dominance over user data by ensuring that personal AI serves individuals -- not corporate interests. Founded by AI and blockchain experts from Columbia, MIT and Stanford, PIN AI is led by Davide Crapis, Ben Wu and Bill Sun, who bring deep experience in AI research, large-scale data infrastructure and blockchain security. [...]\n \nPIN AI introduces an alternative to centralized AI models that collect and monetize user data. Unlike cloud-based AI controlled by large tech firms, PIN AI's personal AI runs locally on user devices, allowing for secure, customized AI experiences without third-party surveillance. At the heart of PIN AI is a user-controlled data bank, which enables individuals to store and manage their personal information while allowing developers access to anonymized, multi-category insights -- ranging from shopping habits to investment strategies. This approach ensures that AI-powered services can benefit from high-quality contextual data without compromising user privacy.\n[...]\nThe new mobile app launched in the U.S. and multiple regions also includes key features such as: - The \"God model\" (guardian of data): Helps users track how well their AI understands them, ensuring it aligns with their preferences. - Ask PIN AI: A personalized AI assistant capable of handling tasks like financial planning, travel coordination and product recommendations. - Open-source integrations: Users can connect apps like Gmail, social media platforms and financial services to their personal AI, training it to better serve them without exposing data to third parties. - \"With our app, you have a personal AI that is your model,\" Crapis added. \"You own the weights, and it's completely private, with privacy-preserving fine-tuning.\" Davide Crapis, co-founder of PIN AI, told VentureBeat that the app currently supports several open-source AI models, including small versions of DeepSeek and Meta's Llama. \"With our app, you have a personal AI that is your model,\" Crapis added. \"You own the weights, and it's completely private, with privacy-preserving fine-tuning.\"\n \nYou can sign up for early access to the PIN AI app here.","contentLength":2669,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ctrl-Alt-Speech: Backdoors And Backsteps","url":"https://www.techdirt.com/2025/02/14/ctrl-alt-speech-backdoors-and-backsteps/","date":1739577663,"author":"Mike Masnick","guid":289,"unread":true,"content":"<p>In this week‚Äôs round-up of the latest news in online speech, content moderation and internet regulation, Mike and Ben are joined by a group of students from the Media Law and Policy class at the American University School of Communication. Together they cover:</p><p>This episode is brought to you with financial support from the Future of Online Trust &amp; Safety Fund.</p>","contentLength":362,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Conditional types in TypeScript","url":"https://2ality.com/2025/02/conditional-types-typescript.html","date":1739577600,"author":"Dr. Axel Rauschmayer","guid":129,"unread":true,"content":"<p>In TypeScript, conditional types let us make decisions (think if-then-else expressions) ‚Äì which is especially useful in generic types. They are also an essential tool for working with union types because they let use ‚Äúloop‚Äù over them. Read on if you want to know how all of that works.</p>","contentLength":291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Court filings show Meta paused efforts to license books for AI training","url":"https://techcrunch.com/2025/02/14/court-filings-show-meta-paused-efforts-to-license-books-for-ai-training/","date":1739576133,"author":"Kyle Wiggers","guid":51,"unread":true,"content":"<p>New court filings in an AI copyright case against Meta add credence to earlier reports that the company ‚Äúpaused‚Äù discussions with book publishers on licensing deals to supply some of its generative AI models with training data. The filings are related to the case&nbsp;Kadrey v. Meta Platforms ‚Äî one of many such cases winding through [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":405,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: VimLM ‚Äì A Local, Offline Coding Assistant for Vim","url":"https://github.com/JosefAlbers/VimLM","date":1739576081,"author":"JosefAlbers","guid":307,"unread":true,"content":"<p>VimLM is a local, offline coding assistant for Vim. It‚Äôs like Copilot but runs entirely on your machine‚Äîno APIs, no tracking, no cloud.</p><p>- Deep Context: Understands your codebase (current file, selections, references).  \n- Conversational: Iterate with follow-ups like \"Add error handling\".  \n- Vim-Native: Keybindings like `Ctrl-l` for prompts, `Ctrl-p` to replace code.  \n- Inline Commands: `!include` files, `!deploy` code, `!continue` long responses.</p><p>Perfect for privacy-conscious devs or air-gapped environments.</p><p>Try it:  \n```\npip install vimlm\nvimlm\n```</p>","contentLength":558,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43054244"},{"title":"AI Alexa and AI Siri face bugs and delays","url":"https://techcrunch.com/2025/02/14/ai-alexa-and-ai-siri-face-bugs-and-delays/","date":1739575487,"author":"Maxwell Zeff","guid":50,"unread":true,"content":"<p>Amazon and Apple are struggling to put generative AI technology in their digital assistants ‚Äî Alexa and Siri, respectively ‚Äî according to a pair of reports that came out on Friday. Amazon hoped to release its new Alexa during an event in New York on February 26. Now Amazon plans to delay the release of [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":376,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Netflix Accidentally Made Its Content Show Up In the Apple TV App","url":"https://apple.slashdot.org/story/25/02/14/2213202/netflix-accidentally-made-its-content-show-up-in-the-apple-tv-app?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739575200,"author":"BeauHD","guid":311,"unread":true,"content":"Netflix content briefly appeared in the Apple TV app due to an unintentional glitch, sparking excitement among users before the company swiftly rolled back the integration. Engadget reports: A Netflix spokesperson told The Verge on Friday that the Apple TV app integration was an error that has been rolled back. Indeed, Redditors who had been tracking the forbidden fruit with unbridled glee confirmed that all signs of Netflix content had since vanished from Apple's streaming hub. Netflix giveth, and Netflix taketh away.\n \nWhile the boo-boo was still active, PC World reported it let you add Netflix originals like Stranger Things, Cobra Kai and The Crown but lacked licensed shows and movies. Even the available content was a buggy mess. For example, only season five of The Crown was available, leaving you to wonder what hijinks Liz and the gang had gotten into before or after the grunge era. The \"Add to Watchlist\" and \"Continue Watching\" features were also said to be spotty.","contentLength":985,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A decade later, a decade lost (2024)","url":"https://meyerweb.com/eric/thoughts/2024/06/07/a-decade-later-a-decade-lost/","date":1739574636,"author":"ZeWaka","guid":272,"unread":true,"content":"<p>I woke up this morning about an hour ahead of my alarm, the sky already light, birds calling.&nbsp; After a few minutes, a brief patter of rain swept across the roof and moved on.</p><p>I just lay there, not really thinking.&nbsp; Feeling.&nbsp; Remembering.</p><p>Almost sixteen years to the minute before I awoke, my second daughter was born.&nbsp; Almost ten years to the same minute before, she‚Äôd turned six years old, already semi-unconscious, and died not quite twelve hours later.</p><p>So she won‚Äôt be taking her first solo car drive today.&nbsp; She won‚Äôt be celebrating with dinner at her favorite restaurant in the whole world.&nbsp; She won‚Äôt kiss her niece good night or affectionately rag on her siblings.</p><p>Or maybe she wouldn‚Äôt have done any of those things anyway, after a decade of growth and changes and paths taken.&nbsp; What would she really be like, at sixteen?</p><p>We will never know.&nbsp; We can‚Äôt even guess.&nbsp; All of that, everything she might have been, is lost.</p><p>This afternoon, we‚Äôll visit Rebecca‚Äôs grave, and then go to hear her name read in remembrance at one of her very happiest places, <a href=\"https://en.wikipedia.org/wiki/Anshe_Chesed_Fairmount_Temple\">Anshe Chesed Fairmount Temple</a>, for the last time.&nbsp; At the end of the month, the temple will close as part of a merger.&nbsp; Another loss.</p><p>A decade ago, I said that I felt the weight of all the years she would never have, and that they might crush me.&nbsp; Over time, I have come to realize all the things she never saw or did adds to that weight.&nbsp; Even though it seems like it should be the same weight.&nbsp; Somehow, it isn‚Äôt.</p><p>I was talking about all of this with a therapist a few days ago, about the time and the losses and their accumulated weight.&nbsp; I said, ‚ÄúI don‚Äôt know how to be okay when I failed my child in the most fundamental way possible.‚Äù</p><p>‚ÄúYou didn‚Äôt fail her,‚Äù they said gently.</p><p>‚ÄúI know that,‚Äù I replied. ‚ÄúBut I don‚Äôt feel it.‚Äù</p><p>A decade, it turns out, does not change that.&nbsp; I‚Äôm not sure now that any stretch of time ever could.</p>","contentLength":1935,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43054069"},{"title":"Pull Request Testing on Kubernetes: How to Test Locally and on GitHub Workflows","url":"https://hackernoon.com/pull-request-testing-on-kubernetes-how-to-test-locally-and-on-github-workflows?source=rss","date":1739574357,"author":"Nicolas Fr√§nkel","guid":69,"unread":true,"content":"<p>Imagine an organization with the following practices:</p><ul><li>Runs its CI/CD pipelines with GitHub Actions</li><li>Runs its production workload on Kubernetes</li></ul><p>\\\nA new engineer manager arrives and asks for the following:</p><blockquote><p>On every PR, run integration tests in a Kubernetes cluster similar to the production one.</p></blockquote><p>\\\nIn this series of posts, I'll show how you can do it. My plan is the following:</p><ul><li>This blog post focuses on the app, the basic GitHub workflow setup, and testing both locally and during the workflow run.</li><li>The second blog post will detail the setup of a Google Kubernetes Engine instance and how to adapt the workflow to use it.</li></ul><h2>Unit Testing vs. Integration Testing</h2><blockquote><p>Integration Testing is a strategy to test the collaboration of at least two components.</p></blockquote><p>\\\nI translated it in Object-Oriented Programming as:</p><blockquote><p>Integration Testing is a strategy to test the collaboration of at least two classes.</p></blockquote><blockquote><p>Let‚Äôs consider the making of a car. Single-class testing is akin to testing each nut and bolt separately. Imagine testing of such components brought no issue to light. Still, it would be very risky to mass manufacture the car without having built a prototype and sent it to a test drive.</p></blockquote><p>\\\nHowever, technology has evolved since that time.</p><p>I use the word \"technology\" very generally, but I have <a href=\"https://testcontainers.com/\">Testcontainers</a> in mind:</p><blockquote><p><em>Unit tests with real dependencies</em></p><p>\\\n  Testcontainers is an open source library for providing throwaway, lightweight instances of databases, message brokers, web browsers, or just about anything that can run in a Docker container.</p></blockquote><p>\\\nIn effect, Testcontainers replaces  with \"real\" dependencies-containerized. It's a real game-changer: instead of painfully writing mocking code to stub dependencies just set them up regularly.</p><p>\\\nFor example, without Testcontainers, you'd need to provide mocks for your  in tests; with it, you only need to start a database container, and off you go.</p><p>\\\nAt the time, the cost of having a local Docker daemon in your testing environment offset many benefits. It's not the case anymore, as Docker daemons are available (nearly) everywhere.</p><p>\\\nMy definition of Integration Testing has changed a bit:</p><blockquote><p>Integration Testing is testing that requires significant setup.</p></blockquote><p>\\\nThe definition is vague on purpose, as significance has a different meaning depending on the organization, the team, and the individual. Note that Google defines two categories of tests: fast and slow. Their definition is equally vague, meant to adapt to different contexts.</p><p>In any case, the golden rule still applies: the closer you are to the final environment, the more risks you cover, and the more valuable your tests are. </p><p>\\\nIf our target production environment is Kubernetes, we will reap the most benefits from running the app on Kubernetes and testing it as a black box. It doesn't mean that white box testing in a more distant environment is not beneficial; it means that the more significant the gap between the testing environment and the target environment, the fewer issues we will uncover.</p><p>\\\nFor the purposes of this blog post, we will use GitHub as the base testing environment for unit testing and a full-fledged Kubernetes cluster for integration testing. There is no absolute truth regarding what is the best practice‚Ñ¢, as contexts vary widely across organizations and even across teams within the same organization. It's up to every engineer to decide within their specific context the ROI of setting up such an environment because the closer you are to production, the more complex and, thus, expensive it will be.</p><h2>Use-case: Application With Database</h2><p>Let's jump into how to test an app that uses a database to store its data. I don't want anything fancy, just solid, standard engineering practices. I'll be using a CRUD(Create Read Update Delete) JVM-based app, but most of the following can easily apply to other stacks as well. The following blog posts will involve less language-specific content.</p><ul><li>Kotlin, because I love the language</li><li>Spring Boot: it's the most widespread framework for JVM-based applications</li><li>Maven-there's nothing else</li><li>Project Reactor and coroutines, because it makes things more interesting</li><li>PostgreSQL-at the moment, it's a very popular database, and it's well-supported by Spring</li></ul><p>\\\nIf you don't know Flyway, it allows you to track database schemas and data in a code repository and manage changes, known as migrations, between versions. Each migration has a unique version, , v1.0, v1.1, v2.1.2, etc. Flyway tries to apply migration in order. If it has already applied a migration, it skips it. Flyway stores its data in a dedicated table to track the applied migrations.</p><p>\\\nThis approach is a must-have; <a href=\"https://www.liquibase.com/\">Liquibase</a> is an alternative that follows the same principles.</p><p>\\\nSpring Boot fully integrates Flyway and Liquibase. When the app starts, the framework will kickstart them. If a pod is killed and restarted, Flyway will first check the migrations table to apply only the one that didn't run previously.</p><p>\\\nI don't want to bore you with the app details; you can find the code on <a href=\"https://github.com/ajavageek/vcluster-pipeline\">GitHub</a>.</p><p>Per my definition above, unit testing should be easy to set up. With Testcontainers, it is.</p><p>\\\nThe testing code counts the number of items in a table, inserts a new item, and counts the number of items again. It then checks that:</p><ul><li>There's one additional item compared to the initial count</li><li>That the new item is the one we inserted</li></ul><pre><code>@SpringBootTest                                                              //1\nclass VClusterPipelineTest @Autowired constructor(private val repository: ProductRepository) { //2\n\n    @Test\n    fun `When inserting a new Product, there should be one more Product in the database and the last inserted Product should be the one inserted`() { //3\n        runBlocking {                                                        //4\n            val initialCount = repository.count()                            //5\n            // The rest of the test\n        }\n    }\n}\n</code></pre><ol><li>Initialize the Spring context</li><li>Praise Kotlin for allowing for descriptive function names</li><li>Run non-blocking code in a blocking function</li></ol><p>\\\nWe now need a PostgreSQL database; Testcontainers can provide one for us. However, to avoid conflicts, it will choose a random port until it finds an unused one. We need it to connect to the database, run the Flyway migration, and run the testing code.</p><p>\\\nFor this reason, we must write a bit of additional code:</p><pre><code>@Profile(\"local\")                                                              //1\nclass TestContainerConfig {\n\n    companion object {\n        val name = \"test\"\n        val userName = \"test\"\n        val pass = \"test\"\n        val postgres = PostgreSQLContainer&lt;Nothing&gt;(\"postgres:17.2\").apply {   //1\n            withDatabaseName(name)\n            withUsername(userName)\n            withPassword(pass)\n            start()\n        }\n    }\n}\n\nclass TestContainerInitializer : ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; {\n    override fun initialize(applicationContext: ConfigurableApplicationContext) {\n        if (applicationContext.environment.activeProfiles.contains(\"local\")) {\n            TestPropertyValues.of(                                             //2\n                \"spring.r2dbc.url=r2dbc:postgresql://${TestContainerConfig.postgres.host}:${TestContainerConfig.postgres.firstMappedPort}/$name\",\n                \"spring.r2dbc.username=$name\",\n                \"spring.r2dbc.password=$pass\",\n                \"spring.flyway.url=jdbc:postgresql://${TestContainerConfig.postgres.host}:${TestContainerConfig.postgres.firstMappedPort}/$name\",\n                \"spring.flyway.user=$name\",\n                \"spring.flyway.password=$pass\"\n            ).applyTo(applicationContext.environment)\n        }\n    }\n}\n</code></pre><ol><li><p>Start the container, but only if the Spring Boot profile  is active.</p></li><li><p>Override the configuration values.</p></li></ol><p>\\\nWe need to specify neither the  nor the  if we hacked the  to reuse the R2BC parameters of the same name:</p><pre><code>spring:\n  application:\n    name: vcluster-pipeline\n  r2dbc:\n    username: test\n    password: test\n    url: r2dbc:postgresql://localhost:8082/flyway-test-db\n  flyway:\n    user: ${SPRING_R2DBC_USERNAME}                                             #1\n    password: ${SPRING_R2DBC_PASSWORD}                                         #1\n    url: jdbc:postgresql://localhost:8082/flyway-test-db\n</code></pre><ol><li>Smart hack to DRY configuration further down.</li></ol><p>\\\nWe also annotate the previous test class to use the initializer:</p><pre><code>@SpringBootTest\n@ContextConfiguration(initializers = [TestContainerInitializer::class])\nclass VClusterPipelineTest @Autowired constructor(private val repository: ProductRepository) {\n\n    // No change\n}\n</code></pre><p>\\\nSpring Boot offers a couple of options to <a href=\"https://docs.spring.io/spring-boot/reference/features/external-config.html\">activate profiles</a>. For local development, we can use a simple JVM property, , <code>mvn test -Dspring.profiles.active=local</code>; in the CI pipeline, we will use environment variables instead.</p><p>I'll also use Flyway to create the database structure for integration testing. In the scope of this example, the System Under Test will be the entire app; hence, I'll test from the HTTP endpoints. It's end-to-end testing for APIs. The code will test the same behavior, albeit treating the System Under Test as a black box.</p><pre><code>class VClusterPipelineIT {\n\n    val logger = LoggerFactory.getLogger(this::class.java)\n\n    @Test\n    fun `When inserting a new Product, there should be one more Product in the database and the last inserted Product should be the one inserted`() {\n\n        val baseUrl = System.getenv(\"APP_BASE_URL\") ?: \"http://localhost:8080\" //1\n\n        logger.info(\"Using base URL: $baseUrl\")\n\n        val client = WebTestClient.bindToServer()                              //2\n            .baseUrl(baseUrl)\n            .build()\n\n        val initialResponse: EntityExchangeResult&lt;List&lt;Product?&gt;?&gt; = client.get() //3\n            .uri(\"/products\")\n            .exchange()\n            .expectStatus().isOk\n            .expectBodyList(Product::class.java)\n            .returnResult()\n\n        val initialCount = initialResponse.responseBody?.size?.toLong()        //4\n\n        val now = LocalDateTime.now()\n        val product = Product(\n            id = UUID.randomUUID(),\n            name = \"My awesome product\",\n            description = \"Really awesome product\",\n            price = 100.0,\n            createdAt = now\n        )\n\n        client.post()                                                          //5\n            .uri(\"/products\")\n            .bodyValue(product)\n            .exchange()\n            .expectStatus().isOk\n            .expectBody(Product::class.java)\n\n        client.get()                                                           //6\n            .uri(\"/products\")\n            .exchange()\n            .expectStatus().isOk\n            .expectBodyList(Product::class.java)\n            .hasSize((initialCount!! + 1).toInt())\n    }\n}\n</code></pre><ol><li>Get the deployed app URL.</li><li>Create a web client that uses the former.</li><li>Get the initial item list.</li><li>Get the size; we definitely should offer a count function if there are too many items.</li><li>Insert a new item and assert everything works out fine.</li><li>Get the list of items and assert the item count is higher by one.</li></ol><p>\\\nBefore going further, let's run the tests in a GitHub workflow.</p><p>I'll assume you're familiar with <a href=\"https://docs.github.com/en/actions/writing-workflows\">GitHub workflows</a>. If you aren't, a GitHub workflow is a declarative description of an automated job. A job consists of several steps. GitHub offers several triggers: Manual, scheduled, or depending on an event.</p><p>\\\nWe want the workflow to run on each Pull Request to verify that tests run as expected.</p><pre><code>name: Test on PR                                                               #1\n\non:\n  pull_request:\n    branches: [ \"master\" ]                                                     #2\n</code></pre><ol><li><p>Trigger on a PR to the master branch.</p></li></ol><p>\\\nThe first steps are pretty standard:</p><pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      - name: Install JRE\n        uses: actions/setup-java@v4\n        with:\n          distribution: temurin\n          java-version: 21\n          cache: maven                                                         #1\n</code></pre><ol><li>The  action includes a caching option for build tools. Here, it will cache dependencies across runs, speeding up consecutive runs. Unless you have good reasons not to, I recommend using this option.</li></ol><p>\\\nFor the same reason, we should cache our built artifacts. While researching for this post, I learned that GitHub discards them across runs <strong>and steps in the same run</strong>. Hence, we can speed up the runs by caching them explicitly:</p><pre><code>      - name: Cache build artifacts\n        uses: actions/cache@v4                                                 &lt;1&gt;\n        with:\n          path: target\n          key: ${{ runner.os }}-build-${{ github.sha }}                        &lt;2&gt;\n          restore-keys:\n            ${{ runner.os }}-build                                             &lt;3&gt;\n</code></pre><ol><li><p>Use the same action that  uses under the hood.</p></li><li><p>Compute the cache key. In our case, the  should be immutable, but this should be how you run matrices across different operating systems.</p></li><li><p>Reuse the cache if it's the same OS.</p></li></ol><pre><code>      - name: Run \"unit\" tests\n        run: ./mvnw -B test\n        env:\n          SPRING_PROFILES_ACTIVE: local                                        &lt;1&gt;\n</code></pre><ol><li>Activate the local profile. The workflow's environment provides a Docker daemon. Hence, Testcontainer successfully downloads and runs the database container.</li></ol><p>\\\nAt this point, we should run the integration test. Yet, we need the app deployed to run this test. For this, we need available infrastructure.</p><h2>Alternative \"Unit testing\" on GitHub</h2><p>The above works perfectly on GitHub, but we can move closer to the deployment setup by leveraging GitHub <a href=\"https://docs.github.com/en/actions/use-cases-and-examples/using-containerized-services/about-service-containers\">service containers</a>. Let's migrate PostgreSQL from Testcontainers to a GitHub service container.</p><p>\\\nRemoving Testcontainers is pretty straightforward: we do not activate the  profile.</p><p>\\\nUsing GitHub's service container requires an additional section in our workflow:</p><pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    env:\n      GH_PG_USER: testuser                                                     #1\n      GH_PG_PASSWORD: testpassword                                             #1\n      GH_PG_DB: testdb                                                         #1\n    services:\n      postgres:\n        image: postgres:15\n        options: &gt;-                                                            #2\n          --health-cmd \"pg_isready -U $POSTGRES_USER\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n            - 5432/tcp                                                         #3\n        env:\n          POSTGRES_USER: ${{ env.GH_PG_USER }}                                 #4\n          POSTGRES_PASSWORD: ${{ env.GH_PG_PASSWORD }}                         #4\n          POSTGRES_DB: ${{ env.GH_PG_DB }}                                     #4\n</code></pre><ol><li><p>Define environment variables at the job level to use them across steps. You can use secrets, but in this case, the database instance is not exposed outside the workflow and will be switched off when the latter finishes. Environment variables are good enough to avoid adding unnecessary secrets.</p></li><li><p>Make sure that PostgreSQL works before going further.</p></li><li><p>Assign a random port and map it to the underlying  port.</p></li><li><p>Use the environment variables.</p></li></ol><p>\\\nTo run the tests using the above configuration is straightforward.</p><pre><code>      - name: Run \"unit\" tests\n        run: ./mvnw -B test\n        env:\n          SPRING_FLYWAY_URL: jdbc:postgresql://localhost:${{ job.services.postgres.ports['5432'] }}/${{ env.GH_PG_DB }} #1\n          SPRING_R2DBC_URL: r2dbc:postgresql://localhost:${{ job.services.postgres.ports['5432'] }}/${{ env.GH_PG_DB }} #1\n          SPRING_R2DBC_USERNAME: ${{ env.GH_PG_USER }}\n          SPRING_R2DBC_PASSWORD: ${{ env.GH_PG_PASSWORD }}\n</code></pre><ol><li><p>GitHub runs PostgreSQL on a local Docker, so the host is . We can get the random port with the <code>${{ job.services.postgres.ports['5432'] }}</code> syntax.</p></li></ol><p>In this post, we laid the ground for a simple app's unit- and integration-testing, leveraging Testcontainers in the local environment. We then proceeded to automate unit testing via a GitHub workflow with the help of GitHub service containers. In the next post, we will prepare the Kubernetes environment on a Cloud provider infrastructure, build the image, and deploy it to the latter.</p><p>\\\nThe complete source code for this post can be found on <a href=\"https://github.com/ajavageek/vcluster-pipeline\">GitHub</a>.</p><p><em>Originally published on <a href=\"https://blog.frankel.ch/pr-testing-kubernetes/1/\">A Java Geek</a> on February 9th, 2025</em></p>","contentLength":16407,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Figure AI is in talks to raise $1.5B at 15x its last valuation","url":"https://techcrunch.com/2025/02/14/figure-ai-is-in-talks-to-raise-1-5b-at-15x-its-last-valuation/","date":1739573509,"author":"Charles Rollet","guid":49,"unread":true,"content":"<p>Robotics startup Figure AI is raising $1.5 billion at a $39.5 billion valuation, a whopping 15 times higher than before.</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":183,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"If you ever stacked cups in gym class, blame my dad","url":"https://defector.com/if-you-ever-stacked-cups-in-gym-class-blame-my-dad","date":1739573102,"author":"nonoobs","guid":271,"unread":true,"content":"<p>The boxes came from Tokyo: first by tanker, then overland via container truck from a Pacific port, across the Continental Divide, and finally backed into a driveway at the end of a cul-de-sac in a south Denver suburban enclave. This was a neighborhood with Razor scooters dumped in trimmed front lawns. Where family walks with leashed dogs happened down the middle of intentionally curved streets named after long demolished natural landmarks like \"Timbercrest\" and \"Forest Trails.\" Where the HOA (because of course there was an HOA) banned the installation of driveway basketball hoops.</p><p>Receiving industrial freight deliveries, freshly cleared through international customs, probably wasn't explicitly prohibited in the homeowner's handbook. But then, why would it need to be? Nobody would think to bring that kind of commercial chaos into the burgeoning middle-class peace of Castle Pines North in 1998.</p><p>If neighbors peeking behind curtains at the idling 18-wheeler thought to call in a complaint, the husband and wife receiving the delivery didn't notice. They were too busy unloading boxes‚Äîmore than 800 of them.&nbsp;</p><p>Balancing four at a time on a handcart, it took 200 trips through the open garage door and down the unfinished basement steps. The boxes, holding smaller rectangular packages inscribed with Japanese lettering, were piled to the ceiling. There was enough room left for a skinny aisle leading back up the stairs, and two plastic tables ladened with tape and flat-rate USPS packaging.&nbsp;</p><p>5,800 miles away, a man in middle management at the global toy conglomerate Hasbro must have been very pleased. The delivery represented a small yet unexpected boon.&nbsp;</p><p>Those boxes were dead inventory, wasting space in a nondescript warehouse. They should have been headed for a landfill and a tax write-off. Instead, a Mr. Toshio Takiguchi brokered the export at a ¬•1,300 per-unit cost. Not a tidy profit, but no longer a loss on the annual P&amp;L. The remains of a failed business decision disappeared across the ocean. It was a certain Mr. Fox's problem now.</p><p>That problem cost $43,000, a sum that represented the entire life savings of Mr. Fox and his wife, who at that point had been surviving on public-school salaries. Friends and family never really said it out loud, but they were certainly thinking it: <em>This was insane. What about the three kids and that mortgage?&nbsp;</em></p><p>The couple, though, never had a doubt.&nbsp;</p><p>\"He always used to tell me, 'If I had 10,000 of these, I could sell them in a year,'\" Mrs. Fox&nbsp;recalled, 27 years later.</p><p>That's the unabashed confidence you'd expect from any good entrepreneur, especially with the benefit of hindsight. But ask yourself this: Would you, watching this couple unload box after box into their bank-financed home, have bet on this man and his family's future if you knew exactly what he needed to sell?</p><p>Tucked inside those boxes, in nested columns of 12, were 120,000 plastic cups. They were turned upside down, each with a hole drilled through the middle of the base, rendering them useless in terms of a cup's normal, and really only, task.</p><p>The couple's future hinged on accomplishing what the world's second largest toy company could not: convincing thousands of kids that stacking these plastic cups in pre-determined patterns was ‚Ä¶ . More critically, the couple needed to convince the parents of those kids to actually buy these cups, despite not even being able to drink from them.&nbsp;</p><p>Mr. Takiguchi could breathe a sigh of relief. Mr. and Mrs. Fox had to get to work.</p><div><div><blockquote><p><strong><em>The first thing you need to know about Bob Fox is that he used to be a clown</em></strong> ... <em><strong>The second thing you need to know about my dad is that he was a really, really good clown.&nbsp;</strong></em></p></blockquote></div></div><p>Every few months, in different corners of the internet, someone asks a version of the same question: <em>Why did we all stack plastic cups in elementary school PE class?</em></p><p>You might have even asked it yourself, perhaps after a few beers when a friend turned some Solo Cups upside down, activating one of your mid-aughts memories of sitting cross-legged on a linoleum gym floor, surrounded by the clatter of your classmates piling cups into pyramids.</p><p><a href=\"https://www.speedstacks.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Sport Stacking</a>, as it's officially known (cup stacking and speed stacking as it is colloquially known), exists in the same cloud of millennial nostalgia where you'll find vague recollections of SlamBall and JoJo. It has appeared on pretty much every morning and late show, been a trend piece in both the <a href=\"https://www.nytimes.com/2016/04/01/sports/sport-stacking-speed-cups.html\" target=\"_blank\" rel=\"noreferrer noopener\"></a> and <a href=\"https://www.wsj.com/articles/SB124044351073445491\" target=\"_blank\" rel=\"noreferrer noopener\"></a>, and was once labeled by Glenn Beck as \"<a href=\"https://www.foxnews.com/story/glenn-beck-why-health-care-reform-is-like-cup-stacking\" target=\"_blank\" rel=\"noreferrer noopener\">what‚Äôs really wrong with America</a>.\"</p><p>It has been a minor plot line in , Matt LeBlanc's , and ; it's been the major plot line in a 2022 Thai-language film released on Netflix titled <a href=\"https://www.imdb.com/title/tt18357588/\" target=\"_blank\" rel=\"noreferrer noopener\"></a> (100 percent on Rotten Tomatoes). The infamous \"Oh my gosh!\" scream in Skrillex's \"Scary Monsters and Nice Sprites\" was sampled from a <a href=\"https://www.youtube.com/watch?v=j54yGxuk0yo&amp;t=1s\" target=\"_blank\" rel=\"noreferrer noopener\">viral sport stacking video</a> from 2008.</p><p>At its peak, between 2002 and 2011, roughly 5,000 American schools included it as part of their annual curriculum, according to Mr. and Mrs. Fox. That means somewhere between five and eight percent of U.S. adults between the ages of 22 and 35 share the same core memory‚Äîand in the ensuing years have asked themselves, their friends, or social media the same question: <em>Why did credentialed educational professionals make us do this ludicrous activity in gym class?</em></p><p>I am, perhaps, the person best suited on the planet to answer this question.&nbsp;Because the answer ‚Ä¶ is my dad.</p><p>The first thing you need to know about Bob Fox is that he used to be a clown. Not in the figurative, funnyman personality sense. In the literal red-nose, black-eyeliner, juggling-tennis-balls-at-children‚Äôs-birthday-parties sense.</p><p>The second thing you need to know about my dad is that he was a <em>really, really good clown</em>.&nbsp;</p><p>He'd scoff at the mental image you probably have of him right now: oversized shoes, cartoonish honks, and bumbling choreography. My dad's act was entirely silent, required immense skill, and was predicated on audience participation. He was equally good at riding a unicycle and convincing the most curmudgeonly dad in the room to leave their back corner and join him onstage to try‚Äîand always fail‚Äîat blowing up a balloon animal. Kids went bananas. Adults always laughed.&nbsp;</p><p>The San Francisco 49ers hired him to be the walk-around entertainment for their post‚ÄìSuper Bowl ring ceremony in 1995. We used to shut the shades so neighbors didn't think he robbed a bank as he counted the cash he earned during Denver's largest busking festival.</p><p>This was a man who took the unserious very, very seriously.&nbsp;</p><p>As a high school theater teacher, he'd spend 60‚Äì80 hours a week building out increasingly elaborate sets for the annual musical. He built a life-sized plant puppet that could actually eat cast members for , and cut a full-sized muscle car in half so it would fit on stage during ; another car was hoisted onto the school's roof to promote the show. Before her bevy of Oscar nominations, Amy Adams was one of his choreographers and students.</p><p>He quit because his wife, Jill, needed him home more to help raise their three children. So he became an elementary school classroom and PE teacher instead, where he would end up teaching hundreds of kids how to ride unicycles and produce an annual show on the blacktop basketball court called KidZircus.</p><p>The first thing you need to know about Jill Fox is that before working as a communications administrator at a school district, she used to be a journalist at a small newspaper, where she was assigned to write a profile about a local clown on \"sabbatical\" from his full-time job.&nbsp;</p><p>The second thing you need to know about Jill Fox is that despite the word \"sabbatical\" doing a generous amount of euphemistic work in her final published piece, she married that unemployed clown.</p><p>This was a woman who was very, very good at seeing‚Äîand supporting‚Äîthe potential in the crazy.</p><div><div><blockquote><p><strong><em>They had to figure out how to tap into the supply chain of global toy conglomerates. Fortunately, they had a guy: Uncle Johnny.</em></strong></p></blockquote></div></div><p>It took them 10 months to sell the 10,000 sets of 12 cups.&nbsp;</p><p>Kids in south Denver, it turns out, went absolutely nuts over this new phenomenon called \"cup stacking.\" That's mostly because my dad figured out the one thing Hasbro did not: The level of interest in the activity hinged almost exclusively on the enthusiasm and skill level of a real-life teacher. Without that, it was just inanimate plastic ephemera sitting on a shelf.</p><p>The basic rules take about 15 minutes to learn. Like a track meet, the sport is built on completing different \"distances\" as fast as you can. The shortest, and simplest, is called the 3-3-3. Envision each one of those 3's as a nested column of cups. You start on one side and \"upstack\" the first 3 into a pyramid, then move to the middle, and then the last 3. Then you return to where you started, and \"downstack\" them back into columns in the same order. The 3-6-3 has the same principle, but with a pyramid of six cups in the middle. The \"Cycle,\" is the sport's primetime event, starting with the 3-6-3, morphing into a 6-6, and ending with a 1-10-1.</p><p>If you skimmed over that clunky paragraph, you've proved my dad's foundational epiphany: You really need to see it to buy in. In fact, scrap reading this for a few seconds (that's all it will take) and watch this video instead.</p><p>Place a set of these cups in the corner of a room or on a toy shelf with paper instructions, and you might earn five minutes of an 8-year-old's frenzied attention. Put that same 8-year-old on the gym floor in front of a professionally trained clown with a passion for juggling, and they will be utterly hooked.</p><p>A brief digression on nomenclature: The sport was known as \"cup stacking\" until 2005, when my parents had the savvy to officially change the name to \"sport stacking.\" Why? 1) Because it sounds way cooler, and if enough people call it a sport then it must damn well be one. 2) The phrase \"cup stacking\" out of context evokes toddlers playing with blocks, a vibe they wanted to avoid. Confusingly, you might have also seen it referenced as \"speed stacking,\" after the company they eventually founded, Speed Stacks. They strategically eschewed this label to avoid the fate of Roller Blades, Frisbee, and Kleenex, all formerly good standing trademarks, until you lot ruined everything.‚Ä®</p><p>Except for this early-stage reference, I'll be calling it sport stacking hereafter so as to avoid a grumpy phone call from my dad (he'll probably still call about my use of \"damn,\" though). If you have a problem with that, consider the last time you went berserk over a nine-darter or screamed at the Swedish curling team during the Olympics. As my dad likes to say, there used to be a man trying to convince the world that tossing balls made from dried cow skin into retrofitted peach baskets was fun‚Äîand you all bought in.</p><p>It is important to note that my dad did not actually invent sport stacking. Credit goes to a group of bored kids at a Boys and Girls Club in Oceanside, Calif., in the early 1980s. They'd been given a stack of paper cups, and told to figure out a game that didn't involve messy liquid. Under the guidance of a program director named Wayne Godinet, both the rules and equipment evolved. He is responsible for the sport's first major innovation: He drilled a hole through the base of hard plastic cups to reduce air friction and prevent sticking. The California group's high-water mark came on Nov. 2, 1990, when they appeared on <em>The Tonight Show with Johnny Carson</em>. Among the millions watching that night, from his bed in a south Denver suburb: a clown and future PE teacher who thought it looked a bit like upside-down juggling.</p><p>Hasbro must have been watching, too. Perhaps chasing the Hoola Hoop and Pogs high of the '80s, the company scooped up a license to sell \"Kup Stax,\" popping sets in a rectangular plastic sleeve on toy store shelves around the world. Instead of becoming a fad, the product moved to the clearance rack. Someone in middle management was probably scolded. Manufacturing ceased.&nbsp;</p><p>In 1995, my dad attended a physical education development workshop to give new teachers a dozen ideas on how to keep kids occupied, exercised, and docile. The classics were all there: four-wheeled square scooters designed to give 80 percent of users elbow burn, dodgeballs primed to pop kids like me in the face, that large circus tent you toss above your head until it temporarily inflates so you can sit under it for a few seconds. So were the cups.&nbsp;</p><p>He brought them home and taught his kids. I was 4, my brother 6, our sister 9. We not only fell in love with them, we got good‚Äî. We weren't outliers. Among an elementary school of 500 students, 250 signed up for an afterschool program to keep stacking. My mom drove to every Toys \"R\" Us and Walmart within a 50-mile radius. She bought every set of Kup Stax she could find. They were always discounted, tucked in a back corner.</p><p>The local supply ran dry as my parents hosted workshops. Demand started to skyrocket from other PE teachers. My parents needed to go upstream. They had to figure out how to tap into the supply chain of global toy conglomerates. Fortunately, they had a guy: .</p><p>Now 64 with a Colonel Sanders goatee and passion for intricate leather carving, my dad's brother has been at certain points in his life: a professor at the Ringling Bros. and Barnum &amp; Bailey Clown College; a street mime in San Diego; a director of&nbsp;a Las Vegas magic show, performed entirely on ice; and a consultant for Japan's oldest and largest circus. If you need to find a man in middle management at Hasbro's Tokyo corporate office, you call Uncle Johnny.</p><p>The deal was struck. The shipment arrived. And the cups, rather magically, disappeared from our basement.</p><p>By 1998, Bob Fox was a dealer with no product and an increasingly addicted customer base. There was only one logical next step: Transition from distribution to fabrication.</p><p>He did make a final good-faith effort to partner with the sport's originator, Wayne Godinet, offering to purchase $20,000 worth of product. It was almost a third of the profit earned from reselling the Japanese shipment. Godinet sent back two sample sets with a bill for the cost of goods and shipping.</p><p>In a similar vein, Nike was founded in 1964 only after a running shoe company called Onitsuka lost interest in partnering with a recent Oregon track grad named Phil Knight. While his shoe empire was born between the grooves of a waffle iron, Bob and Jill's cup empire was sketched on the back of a Fresh Fish Co. paper placemat.</p><p>Speed Stacks LLC was incorporated in December 1998. My parents quit their full-time public school jobs in June 2000.&nbsp;</p><p>This was to be an official test of a core tenet of the American Dream: With enough passion and even more prodigious work ethic, you can turn a ludicrous idea into a successful business. To get started, they just needed four things.</p><p>First: a mold to mass produce the cups. It required $20,000 and overcoming the absolute befuddlement of executives at a Denver plastics manufacturer who did not understand the  to include three small holes at the base. As each cup came off the line, our family would inspect the shape; minor defects in its roundness caused sticking. Nearly every cup in the first run had to be tossed out for deformities.</p><p>Second: a nylon and mesh cup-carrying bag. Those were sewn in the back basement of a Vietnamese immigrant‚Äìowned textile company. We bagged each set of 12 by hand, my parents staying up until 2:00 in the morning to fulfill orders after working full school days. Bob wasn't satisfied unless the logo of every cup perfectly faced forward.</p><p>Third: to hit the road. Speed Stack's first tagline was \"See it! Believe it! Teach it!\" My parents meant it: They knew that success was linearly related to the number of PE teachers who witnessed the sport in person. Our family of five put almost 100,000 miles on our 1997 maroon Suburban in a little over four years.</p><p>Fourth: kids who could stack the cups. . For some reason, all three of the Fox progeny developed both the interest and intrinsic skill to do just that.</p><div><div><blockquote><p><strong><em>At a booth in hotel conference halls and city convention centers, we'd stack for hours, drawing crowds spread three and four rows deep, often to the annoyance of the dodgeball or shuttlecock purveyors next door.&nbsp;</em></strong></p></blockquote></div></div><p>Legendary ring announcer Michael Buffer‚Äôs voice was always our music cue. <em>\"Ladies and gentlemen, welcome to the main event!\"</em></p><p>It would blast over portable speakers on either side of a gym floor. Emmy, my older sister, would lead us out from a hidden corner, followed by my brother, Brennan, then me: a 7-year-old with Coke-bottle glasses, immensely satisfied by the fact that hundreds of eyes were watching my every move.</p><p>We stopped when we reached separate tables spread evenly across our makeshift stage, usually under the basketball hoop. We stood still to let the tempo build.&nbsp;</p><p><em>\"Let‚Äôs get ready to rumble!\"</em></p><p>The synths would drop, and we would commence stacking plastic cups. Faster and with more skill than the students and teachers in Amarillo or Ft. Lauderdale or Butzbach, Germany, or Copenhagen, Denmark, could ever think possible.&nbsp;</p><p>Our family performed hundreds of school assemblies in almost every corner of the country (and some overseas). The 30-minute spectacle was choreographed specifically to blow the minds of kids between the ages of 7 and 14 as quickly as possible. This wasn't a talk from your fire chief about safety, or puppets teaching you the value of sharing. We humiliated principals and popular teachers by making them race us. There was a fabricated jacket with holes cut in the back that we fitted onto a volunteer, then stuck our arms through the sleeves to make it appear like they were magically adept (performed to the  soundtrack). The finale was a choreographed stacking routine, set to \"Dueling Banjos\" from .</p><p>But a school-by-school roadshow wasn't a scalable business model. So we went to the nexus of physical education sweatsuitdom: state and national teacher conventions. At a booth in hotel conference halls and city convention centers, we'd stack for hours, drawing crowds spread three and four rows deep, often to the annoyance of the dodgeball or shuttlecock purveyors next door.&nbsp;</p><p>It's most likely that you learned how to sport stack because your teacher, with a lanyard badge bouncing over her multi-colored windbreaker on her way to get a free muffin from the guys who sell tug-o-war ropes, stopped in her tracks in the back corner of Exhibit Hall B at an exurban Renaissance hotel. She would watch as our hands manipulated dishware so fast it blurred.</p><p>If my dad was adept at putting on a good show, my mom was equally adept at corralling the press. Her journalism and PR‚Äìhoned chops put sport stacking in front of millions, from the D-block of local newscasts to 30 Rock Plaza during the .&nbsp;</p><p>That's how I found myself chatting with a shirtless Simon Cowell in the makeup room before we both appeared on Ellen DeGeneres's show, taught Tiki Barber the basics of the 3-3-3, and tried to convince a baffled Michael Caine in the green room of <em>LIVE with Regis and Kelly</em> that yes, indeed, kids really do stack plastic cups for fun.</p><p>All press, to my parents, was good. My dad was absolutely thrilled when Glenn Beck spent four minutes of his daily Fox News monologue staring directly into the camera, railing against the dangers of stacking cups.</p><p>\"We can't fix our country by keeping our children weak,\" Beck sputtered, roughly two minutes in. \"They need to have spines. They need to get hit in the face a few times with a ball, you know what I mean? They have to learn how to live with and thrive on past failures.\"</p><p>Brands soon took advantage of sport stacking's essential power: No matter the context, it attracts near-instant attention. In 2005, I appeared in a <a href=\"https://www.youtube.com/clip/UgkxwybLaGciSxQJgS1FKh-3PeJwa9xtXtN8\" target=\"_blank\" rel=\"noreferrer noopener\">nationwide Comcast commercial</a> for high speed internet. FritoLay shut down part of Times Square to feature our stacking talents as it launched Stax, a competitor to Pringles. A beverage company in England flew a dozen of us to London to help launch an abomination of a drink called <a href=\"https://www.youtube.com/watch?v=eelE8tHEScM\" target=\"_blank\" rel=\"noreferrer noopener\">Freekee Soda</a>. Main ingredient? Carbonated milk. (Did I pretend to enjoy drinking that carbonated milk so as to not piss off any of the execs helping to pay for my college education? Obviously. But it is a cursed flavor.)</p><p>Perhaps the only media my parents turned down was an appearance on the infamous reality show . The producers, naturally, presumed the scions of a ludicrous gym activity would have some weird baggage to mine for the masses.&nbsp;</p><p>Unfortunately, despite the cups, we were pretty normal.</p><div><div><blockquote><p><strong><em>To stack as fast as you possibly can in a World Championship is to strike a balance between fluidity and chaos.</em></strong></p></blockquote></div></div><p>It was the Germans who made everything more serious.</p><p>They arrived at the 2004 World Sport Stacking Championships in matching flag-inspired sweatsuits. Multiple coaches would analyze everything from hand-tag efficiency during the four-person relay event to the mental routines of stackers before their individual competition.</p><p>Sport stacking, I believe, grew into a minor phenomenon for three reasons: 1) It's visually arresting, 2) it's easy to learn, and 3) competing against the clock is incredibly addicting.</p><p>Media buzz and schoolteachers kindled the first two. But my dad's magnum opus‚Äîthe reason the sport didn't wither in the way of skip ball and snake boards‚Äîwas that he (with the help of the 20 employees at the burgeoning HQ) built the infrastructure and equipment to spur global competition.&nbsp;</p><p>The sport's growth coincided with two of my dad's innovations: the StackMat, a patented self-timing device that allowed kids to practice on their own for hours, aiming to trim hundredths of a second off their best times; and the World Sport Stacking Association, a governing body to codify the rules and serve as the keeper of world, national, and local records.</p><p>In 1997, 250 kids were hand-timed with stop watches at the first Colorado State Championship.&nbsp;By 2007, ESPN aired an <a href=\"https://www.youtube.com/watch?v=xm8EKnl4ZDQ\" target=\"_blank\" rel=\"noreferrer noopener\">hourlong David Lloyd‚Äìhosted special</a> of the World Championships, featuring more than 1,000 competitors from seven countries (re-aired in 2020 during their pandemic \"The Ocho\" promotion).&nbsp;</p><p>Like everything in his life, my dad choreographed a spectacle. He ordered a three-story banner to hang behind garbage can‚Äìsized cups that served as center stage. The competition floor was arranged with dozens of tables, all marked with laser-lined tape to demarcate relay boundaries.</p><p>During the final \"Stack of Champions,\" the top competitors (and relay teams) from each event competed under the scrutiny of spotlights, three officials, an instant replay camera, and hundreds of spectators. In individual events, you're allotted two warmups and three tries. Relays are conducted head-to-head in teams of four.</p><p>For a few years, I was among those finalists.&nbsp;</p><p>To stack as fast as you possibly can in a World Championship is to strike a balance between fluidity and chaos. Push too hard and the cups tumble. Pull back and you'll lose by thousandths of a second.</p><div><div><figure><figcaption>A relay race in the Stack of Champions, in which I (the third stacker on the left team) stumble at the start, allowing my brother (the last stacker on the right team) to beat us by two-hundredths of a second.</figcaption></figure></div></div><p>For those moments, you exist at the outer physical boundary of human biology. When performing at your peak, the cups feel less like they're being stacked and more like they're being sprayed.&nbsp;</p><p>In 2001, the world record for sport stacking's marquee event, the Cycle, was 7.43 seconds. It was held by my sister. At the time, most people assumed a sub-seven-second time was physically impossible. The pattern requires more than 40 separate moves. At those speeds, hands make micro-adjustments faster than the brain can register. Her time stood for nearly four years.</p><p>In 2025, the world record for the cycle is 4.739 seconds.&nbsp;</p><p>Please understand: I know this whole endeavor is silly, that it's worthy of your slight mockery and general patina of confusion. But also understand that my dad created a culture in which German coaches passed strategic tips to Australian competitors. Where Japanese teenagers became pen pals with suburban Texans. Where nerves collapsed faster than the cups. Where kids and adults shrieked with joy over millisecond improvements. Where tension and drama and friendship mingled with the clattering cacophony of sliding and tapping plastic (there really is no sound like the one at these competitions).&nbsp;</p><p>Sport stacking had broad exposure in both mainstream and weird places. But it had a deep impact in a much smaller community. It changed lives.</p><div><div><blockquote><p><strong><em>You've probably heard Rachael‚Äôs voice. Her effusive reaction on a stacking YouTube video meant for her small group of friends is behind the iconic \"YES, OH MY GOSH!\" scream, sampled in one of EDM's most mainstream hits, \"Scary Monsters and Nice Sprites,\" by Skrillex.</em></strong></p></blockquote></div></div><p>Milo Ferguson discovered sport stacking in first-grade PE class.&nbsp;</p><p>\"My teacher was the final boss of butch lesbians. That's the only way I know how to describe her,\" Ferguson, now a 23-year-old co-founder of an independent animation studio, said. Their teacher loved competition and was beloved by her students, exactly the archetype to stop at a conference booth and believe in a quirky new cup-centric educational trend.</p><p>Rachael Nedrow, now a 29-year-old product manager at Amazon, first saw the sport while scrolling YouTube when she was 11. She pulled paper cups from the kitchen drawer to try and mimic the movement.</p><p>Both became obsessed, quickly. Though for different reasons.</p><p>\"I was never the fastest kid. I was always kind of chubby. I was much more the creative person than an athletic one,\" Ferguson said. \"Sport stacking was about hand-eye coordination more than strength. It was intricate. Delicate.\" For the first time, they were excited to attend PE class.</p><p>Nedrow, an accomplished tennis player, was intrigued by the self-improvement and rigid strictures of the clock. She bought an official set of Speed Stacks and started logging her progress on her own YouTube channel.</p><p>\"My first competition was at a local church,\" Nedrow said. \"I did terribly, but I still won.\"</p><p>Despite differing motivations, Ferguson and Nedrow's paths to competitive sport stacking mirror each other. Friends weren't interested, so they went looking for a community online and at competitions.&nbsp;</p><p>For the thousand kids that congregated on the arena floor at each World Championships, like Ferguson and Nedrow, the sentiment was common. They had found  people. They fit in, sometimes for the first time in their life.&nbsp;</p><p>There were future college athletes and kids with autism. There were rugby fans from New Zealand (riffing off their national team, they called themselves the \"All Stacks\") and South Koreans who had never been to the United States.&nbsp;</p><p>Roll your eyes, but my dad loved to say that the sport only helped build \"positive pyramids.\" Spend a few hours watching kids pat each other on the back after a fumbled cup, or earn a hug for achieving a new personal best, and you'd buy into the platitude too.</p><p>Compared to other top-level stackers, Nedrow and Ferguson's experiences only differ in one way.&nbsp;</p><p>You've probably heard Rachael's voice. Her effusive reaction on a stacking YouTube video meant for her small group of friends is behind the iconic \"YES, OH MY GOSH!\" scream, sampled in one of EDM's most mainstream hits, \"<a href=\"https://www.youtube.com/watch?v=WSeNSzJ2-Jw\" target=\"_blank\" rel=\"noreferrer noopener\">Scary Monsters and Nice Sprites</a>,\" by Skrillex. Between Spotify and YouTube, it has more than 500 million streams.</p><p>And you probably know Ferguson's dad, Craig, the comedian and host of <em>The Late Late Show with Craig Ferguson</em> from 2005 to 2014.</p><p>Nedrow's collision with virality gave her backstage passes to several Skrillex concerts and the greatest fodder for \"Two Truths and a Lie\" of all time. But sport stacking also gave her something else she wasn‚Äôt expecting: a wide group of online friends.</p><p>\"I don't think I would have taken stacking so far if it wasn't for the online community,\" Nedrow said. \"When you are doing anything kind of competitive, it seems like it's much better when you are doing it with people. I really loved the aspect of kids commenting on my videos, saying they started stacking because of me. What greater pleasure can you get than inspiring other people to do what you love the most?\"</p><p>Sport stacking gave Ferguson inclusion and validation. But perhaps more important than what it gave them is what it gave their parents. While Craig and his ex-wife Sascha had been separated for a few years by the time their kid started competing, both fully committed to supporting this weird, wholesome obsession. Sascha helped Milo learn how to breathe and center themselves before starting to stack. And she supplied an ever-growing collection of stacking equipment, stored in a dedicated room in their Southern California home.</p><p>To see what sport stacking gave Craig, you need to watch his show <a href=\"https://www.youtube.com/watch?v=9Wjk0PkpWco\" target=\"_blank\" rel=\"noreferrer noopener\">from April 20, 2009</a>. He spends four minutes‚Äîmore than half of the entire monologue‚Äîbragging about Milo. Beneath the scripted jokes and of-the-era references (Octomom is mentioned twice), you see a guy just genuinely proud of his kid. He's like any neighbor, going off a bit too effusively about the weekend's peewee football game or math test.&nbsp;</p><p>Except this was done for millions. And it was about ... cups.&nbsp;</p><div><div><blockquote><p><strong><em>\"I wanted to give kids, no matter their athletic ability, the opportunity for success. It gave them something new and different. And it created a community. It brought kids around the world together.\"</em></strong></p></blockquote></div></div><p>Sport stacking gave different things to a lot of people.</p><p>For a few, it genuinely improved their life. College funds were paid through YouTube viewership revenue and small brand endorsements. Children with autism and special needs learned, practiced, competed, and socialized with others for the first time.&nbsp;</p><p>For me and my siblings, it gave us a stable home, trips to a dozen countries, and some excellent college essay material. My sister, Emmy, went on to play basketball for four years at the University of Minnesota, was drafted into the WNBA by the Minnesota Lynx, and then played professionally overseas with Sheryl Swoopes. My brother Brennan played D-III college football and turned into a mechanical engineer at a global cosmetics company. I turned into a fairly unathletic writer.</p><p>For my parents, it gave them an early retirement. A sometimes-operational 1957 VW Bug and an obsession with growing ever-larger pumpkins occupied my dad, while training to run another marathon at age 70 became a focus for my mom. They left their active roles at Speed Stacks in 2015, leaving control to some of its earliest employees. Programs are still active in thousands of schools around the world.</p><p>\"I was motivated to spread sport stacking for the same reason I taught my students how to juggle or unicycle,\" my dad recalled, nearly 10 years into retirement. \"I wanted to give kids, no matter their athletic ability, the opportunity for success. It gave them something new and different. And it created a community. It brought kids around the world together. And believe it or not, that all happened because of a couple million plastic cups.\"</p><p>For some of you reading this, sport stacking gave you an identical memory.&nbsp;A cross-legged seat on a linoleum gym floor. The hush from the principal. The music crescendoing into ' most iconic synth riff. The sound of cups, stacking at lightning speed. You knew, in that moment, that you weren't in for another monotonous few hours at school. Your day was about to rock.&nbsp;</p><p>For that, you can thank my dad.</p>","contentLength":31508,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053908"},{"title":"Final Fantasy iOS Game Shuts Down Over Unfixable Bug","url":"https://it.slashdot.org/story/25/02/14/223226/final-fantasy-ios-game-shuts-down-over-unfixable-bug?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739572800,"author":"BeauHD","guid":310,"unread":true,"content":"The Verge's Jay Peters reports: Square Enix has shut down the iOS version of Final Fantasy Crystal Chronicles and removed it from the App Store following an unfixable bug that blocked people from accessing content they had paid for. [...] The company says that if you made in-app purchases in January 2024 or later, you're eligible to request a refund by contacting Apple Support. Square Enix says that Final Fantasy Crystal Chronicles will continue to be supported on other platforms. The game is also available on Android, PlayStation, and Nintendo Switch. \"The issue is due to changes made to the in-app purchases model,\" Square Enix says in a post. \"Further investigation revealed that we are unable to completely fix the bug and implement the new changes, making it unlikely to resume service for the game.\" Square Enix says it started receiving reports on January 24th about the issue, which \"extends to the full paid version of the game.\"","contentLength":945,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"We were wrong about GPUs","url":"https://fly.io/blog/wrong-about-gpu/","date":1739572591,"author":"mxstbr","guid":270,"unread":true,"content":"<div><p>We‚Äôre building a public cloud, on hardware we own. We raised money to do that, and to place some bets; one of them: GPU-enabling our customers. A progress report: GPUs aren‚Äôt going anywhere, but: GPUs aren‚Äôt going anywhere.</p></div><p>A Fly Machine is a <a href=\"https://fly.io/blog/docker-without-docker/\">Docker/OCI container</a> running inside a hardware-virtualized virtual machine somewhere on our global fleet of bare-metal worker servers. A GPU Machine is a Fly Machine with a hardware-mapped Nvidia GPU. It‚Äôs a Fly Machine that can do fast CUDA.</p><p>Like everybody else in our industry, we were right about the importance of AI/ML. If anything, we underestimated its importance. But the product we came up with probably doesn‚Äôt fit the moment. It‚Äôs a bet that doesn‚Äôt feel like it‚Äôs paying off.</p><p><strong>If you‚Äôre using Fly GPU Machines, don‚Äôt freak out; we‚Äôre not getting rid of them.</strong> But if you‚Äôre waiting for us to do something bigger with them, a v2 of the product, you‚Äôll probably be waiting awhile.</p><p>GPU Machines were not a small project for us. Fly Machines run on an idiosyncratically small hypervisor (normally Firecracker, but for GPU Machines <a href=\"https://github.com/cloud-hypervisor/cloud-hypervisor\">Intel‚Äôs Cloud Hypervisor</a>, a very similar Rust codebase that supports PCI passthrough). The Nvidia ecosystem is not geared to supporting micro-VM hypervisors.</p><p>GPUs <a href=\"https://googleprojectzero.blogspot.com/2020/09/attacking-qualcomm-adreno-gpu.html\">terrified our security team</a>. A GPU is just about the worst case hardware peripheral: intense multi-directional direct memory transfers</p><div><p>(not even bidirectional: in common configurations, GPUs talk to each other)</p></div><p>with arbitrary, end-user controlled computation, all operating outside our normal security boundary.</p><p>We did a couple expensive things to mitigate the risk. We shipped GPUs on dedicated server hardware, so that GPU- and non-GPU workloads weren‚Äôt mixed. Because of that, the only reason for a Fly Machine to be scheduled on a GPU machine was that it needed a PCI BDF for an Nvidia GPU, and there‚Äôs a limited number of those available on any box. Those GPU servers were drastically less utilized and thus less cost-effective than our ordinary servers.</p><p>We funded two very large security assessments, from <a href=\"https://www.atredis.com/\">Atredis</a> and <a href=\"https://tetrelsec.com/\">Tetrel</a>, to evaluate our GPU deployment. Matt Braun is writing up those assessments now. They were not cheap, and they took time.</p><p>Security wasn‚Äôt directly the biggest cost we had to deal with, but it was an indirect cause for a subtle reason.</p><p>We could have shipped GPUs very quickly by doing what Nvidia recommended: standing up a standard K8s cluster to schedule GPU jobs on. Had we taken that path, and let our GPU users share a single Linux kernel, we‚Äôd have been on Nvidia‚Äôs driver happy-path.</p><p>Alternatively, we could have used a conventional hypervisor. Nvidia suggested VMware (heh). But they could have gotten things working had we used QEMU. We like QEMU fine, and could have talked ourselves into a security story for it, but the whole point of Fly Machines is that they take milliseconds to start. We could not have offered our desired Developer Experience on the Nvidia happy-path.</p><p>Instead, we burned months trying (and ultimately failing) to get Nvidia‚Äôs host drivers working to map <a href=\"https://www.nvidia.com/en-us/data-center/virtual-solutions/\">virtualized GPUs</a> into Intel Cloud Hypervisor. At one point, we hex-edited the closed-source drivers to trick them into thinking our hypervisor was QEMU.</p><p>I‚Äôm not sure any of this really mattered in the end. There‚Äôs a segment of the market we weren‚Äôt ever really able to explore because Nvidia‚Äôs driver support kept us from thin-slicing GPUs. We‚Äôd have been able to put together a really cheap offering for developers if we hadn‚Äôt run up against that, and developers love ‚Äúcheap‚Äù, but I can‚Äôt prove that those customers are real.</p><p>On the other hand, we‚Äôre committed to delivering the Fly Machine DX for GPU workloads. Beyond the PCI/IOMMU drama, just getting an entire hardware GPU working in a Fly Machine was a lift. We needed Fly Machines that would come up with the right Nvidia drivers; our stack was built assuming that the customer‚Äôs OCI container almost entirely defined the root filesystem for a Machine. We had to engineer around that in our  orchestrator. And almost everything people want to do with GPUs involves efficiently grabbing huge files full of model weights. Also annoying!</p><p>And, of course, we bought GPUs. A lot of GPUs. Expensive GPUs.</p><p>The biggest problem: developers don‚Äôt want GPUs. They don‚Äôt even want AI/ML models. They want LLMs.  may have smart, fussy opinions on how to get their models loaded with CUDA, and what the best GPU is. But  don‚Äôt care about any of that. When a software developer shipping an app comes looking for a way for their app to deliver prompts to an LLM, you can‚Äôt just give them a GPU.</p><p>For those developers, who probably make up most of the market, it doesn‚Äôt seem plausible for an insurgent public cloud to compete with OpenAI and Anthropic. Their APIs are fast enough, and developers thinking about performance in terms of ‚Äútokens per second‚Äù aren‚Äôt counting milliseconds.</p><div><p>(you should all feel sympathy for us)</p></div><p>This makes us sad because we really like the point in the solution space we found. Developers shipping apps on Amazon will outsource to other public clouds to get cost-effective access to GPUs. But then they‚Äôll faceplant trying to handle data and model weights, backhauling gigabytes (at significant expense) from S3. We have app servers, GPUs, and object storage all under the same top-of-rack switch. But inference latency just doesn‚Äôt seem to matter yet, so the market doesn‚Äôt care.</p><p>Past that, and just considering the system engineers who do care about GPUs rather than LLMs: the hardware product/market fit here is really rough.</p><p>People doing serious AI work want galactically huge amounts of GPU compute. A whole enterprise A100 is a compromise position for them; they want an SXM cluster of H100s.</p><div><p>Near as we can tell, MIG gives you a UUID to talk to the host driver, not a PCI device.</p></div><p>We think there‚Äôs probably a market for users doing lightweight ML work getting tiny GPUs. <a href=\"https://www.nvidia.com/en-us/technologies/multi-instance-gpu/\">This is what Nvidia MIG does</a>, slicing a big GPU into arbitrarily small virtual GPUs. But for fully-virtualized workloads, it‚Äôs not baked; we can‚Äôt use it. And I‚Äôm not sure how many of those customers there are, or whether we‚Äôd get the density of customers per server that we need.</p><p><a href=\"https://fly.io/blog/cutting-prices-for-l40s-gpus-in-half\">That leaves the L40S customers</a>. There are a bunch of these! We dropped L40S prices last year, not because we were sour on GPUs but because they‚Äôre the one part we have in our inventory people seem to get a lot of use out of. We‚Äôre happy with them. But they‚Äôre just another kind of compute that some apps need; they‚Äôre not a driver of our core business. They‚Äôre not the GPU bet paying off.</p><p>Really, all of this is just a long way of saying that for most software developers, ‚ÄúAI-enabling‚Äù their app is best done with API calls to things like Claude and GPT, Replicate and RunPod.</p><p>A very useful way to look at a startup is that it‚Äôs a race to learn stuff. So, what‚Äôs our report card?</p><p>First off, when we embarked down this path in 2022, we were (like many other companies) operating in a sort of phlogiston era of AI/ML. The industry attention to AI had not yet collapsed around a small number of foundational LLM models. We expected there to be a diversity of  models, the world <a href=\"https://github.com/elixir-nx/bumblebee\" title=\"\">Elixir Bumblebee</a> looks forward to, where people pull different AI workloads off the shelf the same way they do Ruby gems.</p><p>But <a href=\"https://www.cursor.com/\" title=\"\">Cursor happened</a>, and, as they say, how are you going to keep ‚Äòem down on the farm once they‚Äôve seen Karl Hungus? It seems much clearer where things are heading.</p><p>GPUs were a test of a Fly.io company credo: as we think about core features, we design for 10,000 developers, not for 5-6. It took a minute, but the credo wins here: GPU workloads for the 10,001st developer are a niche thing.</p><p>Another way to look at a startup is as a series of bets. We put a lot of chips down here. But the buy-in for this tournament gave us a lot of chips to play with. Never making a big bet of any sort isn‚Äôt a winning strategy. I‚Äôd rather we‚Äôd flopped the nut straight, but I think going in on this hand was the right call.</p><p>A really important thing to keep in mind here, and something I think a lot of startup thinkers sleep on, is the extent to which this bet involved acquiring assets. Obviously, some of our <a href=\"https://fly.io/blog/the-exit-interview-jp/\" title=\"\">costs here aren‚Äôt recoverable</a>. But the hardware parts that aren‚Äôt generating revenue will ultimately get liquidated; like with <a href=\"https://fly.io/blog/32-bit-real-estate/\" title=\"\">our portfolio of IPv4 addresses</a>, I‚Äôm even more comfortable making bets backed by tradable assets with durable value.</p><p>In the end, I don‚Äôt think GPU Fly Machines were going to be a hit for us no matter what we did. Because of that, one thing I‚Äôm very happy about is that we didn‚Äôt compromise the rest of the product for them. Security concerns slowed us down to where we probably learned what we needed to learn a couple months later than we could have otherwise, but we‚Äôre scaling back our GPU ambitions without having sacrificed <a href=\"https://fly.io/blog/sandboxing-and-workload-isolation/\" title=\"\">any of our isolation story</a>, and, ironically, GPUs  are making that story a lot more important. The same thing goes for our Fly Machine developer experience.</p><p>We started this company building a Javascript runtime for edge computing. We learned that our customers didn‚Äôt want a new Javascript runtime; they just wanted their native code to work. <a href=\"https://news.ycombinator.com/item?id=22616857\" title=\"\">We shipped containers</a>, and no convincing was needed. We were wrong about Javascript edge functions, and I think we were wrong about GPUs. That‚Äôs usually how we figure out the right answers:  by being wrong about a lot of stuff.</p>","contentLength":9514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053844"},{"title":"Django Weblog: DjangoCongress JP 2025 Announcement and Live Streaming!","url":"https://www.djangoproject.com/weblog/2025/feb/14/djangocongress-jp-2025-announcement-and-livestream/","date":1739571130,"author":"","guid":224,"unread":true,"content":"<p>It will be streamed on the following YouTube Live channels:</p><p>This year there will be talks not only about Django, but also about FastAPI and other asynchronous web topics. There will also be talks on Django core development, Django Software Foundation (DSF) governance, and other topics from around the world. Simultaneous translation will be provided in both English and Japanese.</p><ul><li>The Async Django ORM: Where Is it?</li><li>Speed at Scale for Django Web Applications</li><li>Implementing Agentic AI Solutions in Django from scratch</li><li>Diving into DSF governance: past, present and future</li></ul><ul><li>Getting Knowledge from Django Hits: Using Grafana and Prometheus</li><li>Culture Eats Strategy for Breakfast: Why Psychological Safety Matters in Open Source</li><li>¬µDjango. The next step in the evolution of asynchronous microservices technology.</li></ul><p>A public viewing of the event will also be held in Tokyo. A reception will also be held, so please check the following connpass page if you plan to attend.</p>","contentLength":948,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Complex dynamics require complex solutions","url":"https://mathstodon.xyz/@tao/113873092369347147","date":1739570733,"author":"ckemere","guid":269,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053625"},{"title":"SailPoint‚Äôs dull debut did little to loosen the stuck IPO window, expert says","url":"https://techcrunch.com/2025/02/14/sailpoints-dull-debut-did-little-to-loosen-the-stuck-ipo-window-expert-says/","date":1739570453,"author":"Julie Bort","guid":48,"unread":true,"content":"<p>SailPoint‚Äôs IPO on Thursday was a disappointment for anyone hoping it would indicate that tech IPOs are hot again. The first day‚Äôs trading ended below the $23 initial price. The stock fared a tad better Friday, closing at over $24. But that‚Äôs nothing close to the big bang companies and VCs hope for. For instance, [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":389,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI Eases Content Restrictions For ChatGPT With New 'Grown-Up Mode'","url":"https://slashdot.org/story/25/02/14/2156202/openai-eases-content-restrictions-for-chatgpt-with-new-grown-up-mode?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1739570400,"author":"BeauHD","guid":309,"unread":true,"content":"An anonymous reader quotes a report from Ars Technica: On Wednesday, OpenAI published the latest version of its \"Model Spec,\" a set of guidelines detailing how ChatGPT should behave and respond to user requests. The document reveals a notable shift in OpenAI's content policies, particularly around \"sensitive\" content like erotica and gore -- allowing this type of content to be generated without warnings in \"appropriate contexts.\" The change in policy has been in the works since May 2024, when the original Model Spec document first mentioned that OpenAI was exploring \"whether we can responsibly provide the ability to generate NSFW content in age-appropriate contexts through the API and ChatGPT.\"\n \nChatGPT's guidelines now state that that \"erotica or gore\" may now be generated, but only under specific circumstances. \"The assistant should not generate erotica, depictions of illegal or non-consensual sexual activities, or extreme gore, except in scientific, historical, news, creative or other contexts where sensitive content is appropriate,\" OpenAI writes. \"This includes depictions in text, audio (e.g., erotic or violent visceral noises), or visual content.\" So far, experimentation from Reddit users has shown that ChatGPT's content filters have indeed been relaxed, with some managing to generate explicit sexual or violent scenarios without accompanying content warnings. OpenAI notes that its Usage Policies still apply, which prohibit building AI tools for minors that include sexual content.","contentLength":1511,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Eli Bendersky: Decorator JITs - Python as a DSL","url":"https://eli.thegreenplace.net/2025/decorator-jits-python-as-a-dsl/","date":1739569771,"author":"","guid":223,"unread":true,"content":"<p>Spend enough time looking at Python programs and packages for machine learning,\nand you'll notice that the \"JIT decorator\" pattern is pretty popular. For\nexample, this JAX snippet:</p><div><pre></pre></div><div><pre></pre></div><p>In both cases, the function decorated with  doesn't get executed by the\nPython interpreter in the normal sense. Instead, the code inside is more like\na DSL (Domain Specific Language) processed by a special purpose compiler built\ninto the library (JAX or Triton). Another way to think about it is that Python\nis used as a  to describe computations.</p><p>In this post I will describe some implementation strategies used by libraries to\nmake this possible.</p><div><h2>Preface - where we're going</h2><p>The goal is to explain how different kinds of  decorators work by using\na simplified, educational example that implements several approaches from\nscratch. All the approaches featured in this post will be using this flow:</p> Expr IR --&gt; LLVM IR --&gt; Execution\" /&gt; Expr IR --&gt; LLVM IR --&gt; Execution\" class=\"align-center\" src=\"https://eli.thegreenplace.net/images/2025/decjit-python.png\" /&gt;\n<p>These are the steps that happen when a Python function wrapped with\nour educational  decorator is called:</p><ol><li>The function is translated to an \"expression IR\" - .</li><li>This expression IR is converted to LLVM IR.</li><li>Finally, the LLVM IR is JIT-executed.</li></ol><p>First, let's look at the  IR. Here we'll make a big simplification -\nonly supporting functions that define a single expression, e.g.:</p><div><pre></pre></div><p>Naturally, this can be easily generalized - after all, LLVM IR can be used to\nexpress fully general computations.</p><p>Here are the  data structures:</p><div><pre></pre></div><p>To convert an  into LLVM IR and JIT-execute it, we'll use this function:</p><div><pre></pre></div><p>It uses the  class to actually generate LLVM IR from .\nThis process is straightforward and covered extensively in the resources I\nlinked to earlier; take a look at <a href=\"https://github.com/eliben/code-for-blog/blob/main/2025/decjit/exprcode.py\">the full code here</a>.</p><p>My goal with this architecture is to make things simple, but .\nOn one hand - there are several simplifications: only single expressions are\nsupported, very limited set of operators, etc. It's very easy to extend this!\nOn the other hand, we could have just trivially evaluated the \nwithout resorting to LLVM IR; I do want to show a more complete compilation\npipeline, though, to demonstrate that an arbitrary amount of complexity can\nbe hidden behind these simple interfaces.</p><p>With these building blocks in hand, we can review the strategies used by\n decorators to convert Python functions into s.</p></div><div><p>Python comes with powerful code reflection and introspection capabilities out\nof the box. Here's the  decorator:</p><div><pre></pre></div><p>This is a standard Python decorator. It takes a function and returns another\nfunction that will be used in its place ( ensures that\nfunction attributes like the name and docstring of the wrapper match the\nwrapped function).</p><div><pre></pre></div><p>After  is applied to , what  holds is the\nwrapper. When  is called, the wrapper is invoked with\n.</p><p>The wrapper obtains the AST of the wrapped function, and then uses\n to convert this AST into an :</p><div><pre></pre></div><p>When  finishes visiting the AST it's given, its\n field will contain the  representing the function's\nreturn value. The wrapper then invokes  with this .</p><p>Note how our decorator interjects into the regular Python execution process.\nWhen  is called, instead of the standard Python compilation and\nexecution process (code is compiled into bytecode, which is then executed\nby the VM), we translate its code to our own representation and emit LLVM from\nit, and then JIT execute the LLVM IR. While it seems kinda pointless in this\nartificial example, in reality this means we can execute the function's code\nin any way we like.</p><div><h3>AST JIT case study: Triton</h3><p>This approach is almost exactly how the Triton language works. The body of a\nfunction decorated with  gets parsed to a Python AST, which then\n- through a series of internal IRs - ends up in LLVM IR; this in turn is lowered\nto <a href=\"https://docs.nvidia.com/cuda/parallel-thread-execution/\">PTX</a> by the\n<a href=\"https://llvm.org/docs/NVPTXUsage.html\">NVPTX LLVM backend</a>.\nThen, the code runs on a GPU using a standard CUDA pipeline.</p><p>Naturally, the subset of Python that can be compiled down to a GPU is limited;\nbut it's sufficient to run performant kernels, in a language that's much\nfriendlier than CUDA and - more importantly - lives in the same file with the\n\"host\" part written in regular Python. For example, if you want testing and\ndebugging, you can run Triton in \"interpreter mode\" which will just run the\nsame kernels locally on a CPU.</p><p>Note that Triton lets us import names from the  package\nand use them inside kernels; these serve as the  for the language\n- special calls the compiler handles directly.</p></div></div><div><p>Python is a fairly complicated language with  of features. Therefore,\nif our JIT has to support some large portion of Python semantics, it may make\nsense to leverage more of Python's own compiler. Concretely, we can have it\ncompile the wrapped function all the way <a href=\"https://github.com/python/cpython/blob/main/InternalDocs/interpreter.md\">to bytecode</a>,\nand start our translation from there.</p><p>Here's the  decorator that does just this :</p><div><pre></pre></div><p>The Python VM is a stack machine; so we emulate a stack to convert the\nfunction's bytecode to  IR (a bit like an <a href=\"https://en.wikipedia.org/wiki/Reverse_Polish_notation\">RPN evaluator</a>).\nAs before, we then use our  utility function to lower\n to LLVM IR and JIT execute it.</p><p>Using this JIT is as simple as the previous one - just swap \nfor :</p><div><pre></pre></div><div><h3>Bytecode JIT case study: Numba</h3><p><a href=\"https://numba.pydata.org/\">Numba</a> is a compiler for Python itself. The idea\nis that you can speed up specific functions in your code by slapping a\n decorator on them. What happens next is similar in spirit to\nour simple , but of course much more complicated because it\nsupports a very large portion of Python semantics.</p><p>Numba uses the Python compiler to emit bytecode, just as we did; it then\nconverts it into its own IR, and then to LLVM using .</p><p>By starting with the bytecode, Numba makes its life easier (no need to rewrite\nthe entire Python compiler). On the other hand, it also makes some analyses\n, because by the time we're in bytecode, a lot of semantic information\nexisting in higher-level representations is lost. For example, Numba has to\nsweat a bit to recover control flow information from the bytecode (by\nrunning it through a special interpreter first).</p></div></div><div><p>The two approaches we've seen so far are similar in many ways - both rely on\nPython's introspection capabilities to compile the source code of the JIT-ed\nfunction to some extent (one to AST, the other all the way to bytecode), and\nthen work on this lowered representation.</p><p>The tracing strategy is very different. It doesn't analyze the source code of\nthe wrapped function at all - instead, it  its execution by means of\nspecially-boxed arguments, leveraging overloaded operators and functions, and\nthen works on the generated trace.</p><p>The code implementing this for our smile demo is surprisingly compact:</p><div><pre></pre></div><p>Each runtime argument of the wrapped function is assigned a , and\nthat is placed in a , a placeholder class which lets us\ndo operator overloading:</p><div><pre></pre></div><p>The remaining key function is :</p><div><pre></pre></div><p>To understand how this works, consider this trivial example:</p><div><pre></pre></div><p>After the decorated function is defined,  holds the wrapper function\ndefined inside . When  is called, the wrapper runs:</p><ol><li>For each argument of  itself (that is  and ), it creates\na new  holding a . This denotes a named variable in\nthe  IR.</li><li>It then calls the wrapped function, passing it the boxes as runtime\nparameters.</li><li>When (the wrapped)  runs, it invokes . This is caught by the overloaded\n operator of , and it creates a new  with\nthe s representing  and  as children. This\n is then returned .</li><li>The wrapper unboxes the returned  and passes it to\n to emit LLVM IR from it and JIT execute it with the\nactual runtime arguments of the call: .</li></ol><p>This might be a little mind-bending at first, because there are two different\nexecutions that happen:</p><ul><li>The first is calling the wrapped  function itself, letting the Python\ninterpreter run it as usual, but with special arguments that build up the IR\ninstead of doing any computations. This is the .</li><li>The second is lowering this IR our tracing step built into LLVM IR and then\nJIT executing it with the actual runtime argument values ; this is\nthe .</li></ul><p>This tracing approach has some interesting characteristics. Since we don't\nhave to analyze the source of the wrapped functions but only trace through\nthe execution, we can \"magically\" support a much richer set of programs, e.g.:</p><div><pre></pre></div><p>This  with our basic . Since Python variables are\nplaceholders (references) for values, our tracing step is oblivious to them - it\nfollows the flow of values. Another example:</p><div><pre></pre></div><p>This also just works! The created  will be a long chain of \nadditions of 's runtime values through the loop, added to the \nfor .</p><p>This last example also leads us to a limitation of the tracing approach; the\nloop cannot be  - it cannot depend on the function's arguments,\nbecause the tracing step has no concept of runtime values and wouldn't know\nhow many iterations to run through; or at least, it doesn't know this unless\nwe want to perform the tracing run for every runtime execution .</p><div><h3>Tracing JIT case study: JAX</h3><p>The <a href=\"https://jax.readthedocs.io/en/latest/\">JAX ML framework</a> uses a tracing\napproach very similar to the one described here. The first code sample in this\npost shows the JAX notation. JAX cleverly wraps Numpy with its own version which\nis traced (similar to our , but JAX calls these boxes \"tracers\"),\nletting you write regular-feeling Numpy code that can be JIT optimized and\nexecuted on accelerators like GPUs and TPUs via <a href=\"https://github.com/openxla\">XLA</a>. JAX's tracer builds up an underlying IR (called\n<a href=\"https://jax.readthedocs.io/en/latest/jaxpr.html\">jaxpr</a>) which can then be\nemitted to XLA ops and passed to XLA for further lowering and execution.</p><p>For a fairly deep overview of how JAX works, I recommend reading the\n<a href=\"https://jax.readthedocs.io/en/latest/autodidax.html\">autodidax doc</a>.</p><p>As mentioned earlier, JAX has <a href=\"https://jax.readthedocs.io/en/latest/jit-compilation.html\">some limitations</a>\nwith things like data-dependent control flow in native Python. This won't work,\nbecause there's control flow\nthat depends on a runtime value ():</p><div><pre></pre></div><p>When  is executed, JAX will throw an exception, saying something\nlike:</p><blockquote>\nThis concrete value was not available in Python because it depends on the\nvalue of the argument count.</blockquote><p>As a remedy, JAX has its\nown built-in intrinsics from the <a href=\"https://jax.readthedocs.io/en/latest/jax.lax.html\">jax.lax package</a>.\nHere's the example rewritten in a way that actually works:</p><div><pre></pre></div><p> (and many other built-ins in the  package) is something JAX\ncan trace through, generating a corresponding XLA operation (XLA has support for\n<a href=\"https://openxla.org/xla/operation_semantics\">While loops</a>, to which this\n can be lowered).</p><p>The tracing approach has clear benefits for JAX as well; because it only cares\nabout the flow of values, it can handle arbitrarily complicated Python code,\nas long as the flow of values can be traced. Just like the local variables and\ndata-independent loops shown earlier, but also things like closures. This makes\nmeta-programming and templating easy .</p></div></div><div><p>The full code for this post is available <a href=\"https://github.com/eliben/code-for-blog/tree/main/2025/decjit\">on GitHub</a>.</p></div>","contentLength":10514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trump‚Äôs DOJ Corruption Laid Bare‚Ä¶ By His Own Conservative Prosecutors","url":"https://www.techdirt.com/2025/02/14/trumps-doj-corruption-laid-bare-by-his-own-conservative-prosecutors/","date":1739569769,"author":"Mike Masnick","guid":288,"unread":true,"content":"<p><em> make sure you read the update at the end of this story.</em></p><p>Here‚Äôs a fun thing about corruption investigations: Usually when prosecutors uncover one quid pro quo, they don‚Äôt resolve it by offering an even bigger quid pro quo. And yet, that appears to be exactly what‚Äôs happening with NYC Mayor Eric Adams, who was <a href=\"https://www.justice.gov/usao-sdny/pr/new-york-city-mayor-eric-adams-charged-bribery-and-campaign-finance-offenses\">indicted last fall</a> for allegedly trading favors with Turkish officials, and is now watching those charges evaporate in exchange for helping the Trump administration with its immigration agenda.</p><p>The twist ‚Äî and there‚Äôs always a twist ‚Äî is that the people most effectively pointing out this corruption aren‚Äôt the usual suspects. Instead, it‚Äôs coming from a bunch of dyed-in-the-wool conservative prosecutors at SDNY who are <a href=\"https://www.theguardian.com/us-news/2025/feb/14/justice-department-officials-resign-eric-adams-charges\">resigning en masse</a> rather than participate in what they see as a perversion of justice. When the Federalist Society crowd starts quitting over corruption, you know something interesting is happening.</p><p>The apparent corruption here isn‚Äôt just brazen ‚Äî it‚Äôs documented in black and white. The Justice Department‚Äôs <a href=\"https://www.nytimes.com/live/2025/02/10/nyregion/eric-adams-charges\">order to drop the case</a> doesn‚Äôt even pretend to assess the merits of the charges. Instead, Acting Deputy Attorney General Emil Bove explicitly tied the dismissal to Adams‚Äô willingness to <a href=\"https://www.theguardian.com/us-news/2025/feb/13/nyc-eric-adams-rikers-ice\">assist with federal deportation efforts</a> ‚Äî a textbook example of weaponizing prosecutorial discretion for political ends.</p><p>Even more disturbing is the mechanism: the dismissal is ‚Äúwithout prejudice,‚Äù meaning charges could be refiled at any time. This isn‚Äôt just prosecutorial discretion ‚Äî it‚Äôs prosecutorial extortion. The Trump administration has effectively created a sword of Damocles to hang over Adams‚Äô head, ensuring his continued compliance with their immigration agenda. The message is clear: step out of line, and those charges might suddenly become relevant again. It‚Äôs the kind of institutional corruption that would make a banana republic blush.</p><p>It means that Adams‚Äô personal freedom now outweighs the best interests of the people of New York City.</p><p>The system‚Äôs response to this corruption has been revealing. For several days after the initial order, an unusual silence descended over the Southern District office ‚Äî a silence that spoke volumes about the internal struggle taking place. Then came something remarkable: a scathing letter from Acting US Attorney Danielle Sassoon to Attorney General Pam Bondi. Sassoon ‚Äî a Federalist Society stalwart and former Scalia clerk who‚Äôs about as far from a ‚Äúprogressive prosecutor‚Äù as you can get ‚Äî laid bare the rot at the core of this decision in a document that reads like a conservative legal scholar‚Äôs manifesto against institutional corruption.</p><blockquote><p><em>Because the law does not support a dismissal, and because I am confident that Adams has committed the crimes with which he is charged, I cannot agree to seek a dismissal driven by improper considerations. As Justice Robert Jackson explained, ‚Äúthe prosecutor at his best is one of the most beneficent forces in our society, when he acts from malice or other base motives, he is one of the worst.‚Äù The Federal Prosecutor, 24 J. Am. Jud. Soc‚Äôy 18 (‚ÄúThis authority has been granted by people who really wanted the right thing done‚Äîwanted crime eliminated‚Äî but also wanted the best in our American traditions preserved. ‚Äú). I understand my duty as a prosecutor to mean enforcing the law impartially, and that includes prosecuting a validly returned indictment regardless whether its dismissal would be politically advantageous, to the defendant or to those who appointed me. A federal prosecutor ‚Äúis the representative not of an ordinary party to a controversy, but of a sovereignty whose obligation to govern impartially is as compelling as its obligation to govern at all.‚Äù Berger v. United States, 295 U.S. 78, 88 (1935).</em></p><p><em>For the reasons explained above, I do not believe there are reasonable arguments in support of a Rule 48(a) motion to dismiss a case that is well supported by the evidence and the law. I understand that Mr. Bove disagrees, and I am mindful of your recent order reiterating prosecutors‚Äô duty to make good-faith arguments in support of the Executive Branch‚Äôs positions. See Feb. 5, 2025 Mem. ‚ÄúGeneral Policy Regarding Zealous Advocacy on Behalf of the United States.‚Äù But because I do not see any good-faith basis for the proposed position, I cannot make such arguments consistent with my duty of candor. N.Y.R.P.C.3.3; id. cmt. 2 (‚ÄúA lawyer acting as an advocate in an adjudicative proceeding has an obligation to present the client‚Äôs case with persuasive force. Performance of that duty while maintaining confidences of the client, however, is qualified by the advocate‚Äôs duty of candor to the tribunal. ‚Äù ).</em></p><p><em>In particular, the rationale given by Mr. Bove‚Äîan exchange between a criminal defendant and the Department of Justice akin to the Bout exchange with Russia‚Äî is, as explained above, a bargain that a prosecutor should not make. Moreover, dismissing without prejudice and with the express option of again indicting Adams in the future creates obvious ethical problems, by implicitly threatening future prosecution if Adams‚Äôs cooperation with enforcing the immigration laws proves unsatisfactory to the Department. See In re Christoff, 690 N.E.2d 1135 (Ind. 1997) (disciplining prosecutor for threatening to renew a dormant criminal investigation against a potential candidate for public office in order to dissuade the candidate from running); Bruce A. Green &amp; Rebecca Roiphe, Who Should Police Politicization of the DOJ?, 35 Notre Dame J.L. Ethics &amp; Pub. Pol‚Äôy 671, 681 (2021) (noting that the Arizona Supreme Court disbarred the elected chief prosecutor of Maricopa County, Arizona, and his deputy, in part, for misusing their power to advance the chief prosecutor‚Äôs partisan political interests) . Finally, given the highly generalized accusations of weaponization, weighed against the strength of the evidence against Adams, a court will likely question whether that basis is pretextual. See, e.g. , United States v. Greater Blouse, Skirt &amp; Neckwear Contractors, 228 F. Supp. 483, 487 (S.D.N.Y. 1964)(courts ‚Äú should be satisfied that the reasons advanced for the proposed dismissal are substantial and the real grounds upon which the application is based‚Äù)</em></p><p><em>I remain baffled by the rushed and superficial process by which this decision was reached, in seeming collaboration with Adams‚Äôs counsel and without my direct input on the ultimate stated rationales for dismissal. Mr. Bove admonished me to be mindful of my obligation to zealously defend the interests of the United States and to advance good-faith arguments on behalf of the Administration. I hope you share my view that soliciting and considering the concerns of the U.S. Attorney overseeing the case serves rather than hinders that goal, and that we can find time to meet.</em></p></blockquote><p>But wait, it gets better! There‚Äôs a footnote in Sassoon‚Äôs letter that tells you everything you need to know about how modern corruption works. The old-school way was to have your shady meetings in smoke-filled back rooms. The new way, apparently, is to have them in official conference rooms while actively preventing anyone from taking notes:</p><blockquote><p><em>I attended a meeting on January 31, 2025, with Mr. Bove, Adams‚Äôs counsel, and members of my office. Adams‚Äôs attorneys repeatedly urged what amounted to a quid pro quo, indicating that Adams would be in a position to assist with the Department‚Äôs enforcement priorities only if the indictment were dismissed. Mr. Bove admonished a member of my team who took notes during that meeting and directed the collection of those notes at the meeting‚Äôs conclusion</em></p></blockquote><p>Nothing quite says you know you‚Äôre engaging in some shady ass shit like demanding you collect the notes of anyone in attendance.</p><p>What makes this story particularly significant is who‚Äôs blowing the whistle. Sassoon isn‚Äôt some ‚Äúwoke prosecutor‚Äù that the MAGA world can easily dismiss. She‚Äôs a card-carrying member of the conservative legal establishment who, until this week, was seen as a rising star in those circles. Her willingness to sacrifice her standing in that world to uphold basic constitutional principles reveals just how far the corruption has spread ‚Äî and perhaps offers a glimmer of hope that some institutional guardrails still hold.</p><p>Sassoon‚Äôs stand has triggered a cascade of resignations within SDNY, with seven prosecutors (and counting) choosing to walk away rather than participate in this corruption of justice. The latest resignation letter, <a href=\"https://s3.documentcloud.org/documents/25536146/hagan-scotten-resignation-letter.pdf\">a scorching indictment from lead prosecutor Hagan Scotten</a>, is particularly noteworthy. Scotten ‚Äî who clerked for both Justices Roberts and Kavanaugh and explicitly states his support for the Trump administration ‚Äî makes it clear that this isn‚Äôt about politics; it‚Äôs about fundamental principles of justice being trampled for political gain.</p><blockquote><p><em>There is a tradition in public service of resigning in a last-ditch effort to head off a serious mistake. Some will view the mistake you are committing here in the light of their generally negative views of the new Administration. I do not share those views. I can even understand how a Chief Executive whose background is in business and politics might see the contemplated dismissal-with-leverage as a good, if distasteful, deal. But any assistant U.S. attorney would know that our laws and traditions do not allow using the prosecutorial power to influence other citizens, much less elected officials, in this way.</em><strong><em>If no lawyer within earshot of the President is willing to give him that advice, then I expect you will eventually find someone who is enough of a fool, or enough of a coward, to file your motion. But it was never going to be me.</em></strong></p></blockquote><p>Scotten‚Äôs prediction proved grimly prophetic. As <a href=\"https://www.theguardian.com/us-news/2025/feb/14/justice-department-officials-resign-eric-adams-charges\">reported just hours ago</a>, Bove and Bondi found their willing executioner ‚Äî though the circumstances reveal yet another layer of institutional corruption:</p><blockquote><p><em>The prosecutor acquiesced to file the motion in an attempt to spare other career staff from potentially being fired by Emil Bove, the acting US deputy attorney general and former personal lawyer to Trump, sources briefed on the matter told Reuters. The news agency named the lawyer as Ed Sullivan, a veteran career prosecutor, who agreed to alleviate pressure on his colleagues in the department‚Äôs public integrity section of 30 attorneys, two sources said, after his team was given an hour by Bove to decide between them who would file the motion.</em></p><p><em>‚ÄúThis is not a capitulation ‚Äì this is a coercion,‚Äù one of the people briefed on the meeting later told Reuters. ‚ÄúThat person, in my mind, is a hero.‚Äù The whole section had reportedly discussed resigning en masse.</em></p></blockquote><p>The cruel irony of forcing the Public Integrity Section to compromise its own integrity isn‚Äôt lost on anyone. This is how institutions die ‚Äî not with a bang, but with an ultimatum.</p><p>There‚Äôs a special kind of institutional poetry here: The Public Integrity Section was given an hour to decide who would compromise their integrity. And someone did, not out of cowardice or foolishness, but to protect their colleagues. ‚ÄúA hero,‚Äù his colleague called him, and maybe that‚Äôs right. But it‚Äôs the kind of heroism that only exists in broken systems.</p><p>The NY Times has revealed even more disturbing details about the behind-the-scenes machinations. In what reads like a playbook for corrupting justice, Bove apparently <a href=\"https://www.nytimes.com/2025/02/13/nyregion/adams-lawyers-justice-department-dismissal.html\"><em>coached Adams‚Äô legal team</em></a> (including Alex Spiro, better known as Elon Musk‚Äôs go-to counsel) in a wink-wink-nudge-nudge fashion on exactly what political commitments would make the charges disappear.</p><blockquote><p><em>During the meeting, Mr. Bove signaled that the decision about whether to dismiss the case had nothing to do with its legal merits.</em></p><p><em>Instead, Mr. Bove said he was interested in whether the case was hindering Mr. Adams‚Äôs leadership, particularly with regard to the city‚Äôs ability to cooperate with the federal government on Mr. Trump‚Äôs crackdown on illegal immigration.</em></p><p><em>Mr. Bove also said he was interested in whether the case, brought by the former U.S. attorney, Damian Williams, was a politically motivated prosecution meant to hurt Mr. Adams‚Äôs re-election prospects.</em></p><p><em>In her letter to Ms. Bondi, Ms. Sassoon said that she was ‚Äúbaffled by the rushed and superficial process by which this decision was reached, in seeming collaboration with Adams‚Äôs counsel and without my direct input on the ultimate stated rationales for dismissal.‚Äù</em></p></blockquote><p>There‚Äôs something almost elegant about it, in a horrifying sort of way. The Justice Department has managed to transform a corruption prosecution into what amounts to a compliance manual for corruption. It‚Äôs like they‚Äôve created a template: ‚ÄúHere‚Äôs how to trade criminal charges for political favors while maintaining plausible deniability.‚Äù And the really wild part? This is all happening after years of the MAGA world screaming about supposed ‚Äúlawfare‚Äù against conservatives. Turns out they weren‚Äôt complaining about weaponized justice ‚Äî they were planning how to do it themselves.</p><p>History rhymes: While mass resignations of principled lawyers helped topple Nixon‚Äôs presidency, in Trump‚Äôs second term they‚Äôve become just another item in the daily digest of institutional erosion. The difference this time? It‚Äôs not the usual suspects sounding the alarm. Instead, it‚Äôs career conservatives ‚Äî products of the Federalist Society pipeline ‚Äî who are putting their careers on the line to preserve what‚Äôs left of prosecutorial independence.</p><p>As we‚Äôve <a href=\"https://www.techdirt.com/2025/02/12/gop-is-quietly-freaking-out-about-elon-time-for-them-to-take-a-stand/\">previously discussed</a>, any path through this constitutional crisis requires principled conservatives to find their voice. The fact that it‚Äôs taking career prosecutors to do what elected Republicans won‚Äôt speaks volumes about where the real courage in conservative circles resides.</p><p>The question now isn‚Äôt just whether our institutions can survive this assault, but whether these acts of principled resistance can inspire others before the machinery of justice is fully converted into a tool of political control. The American experiment has survived previous challenges through the courage of individuals willing to place principle above party. We‚Äôre about to find out if enough of those individuals still exist.</p><p> Incredibly, that report that a prosecutor had agreed to file the dismissal turned out to not be accurate. Many hours later, after no such filing was actually made a few very bizarre things happened. First, Emil Bove <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.nysd.628916/gov.uscourts.nysd.628916.121.0_2.pdf\">filed a notice of appearance</a> in the case. That is‚Ä¶ not normal.</p><p>Finally, the ‚Äúnolle prosequi‚Äù (a notice saying ‚Äúwe no longer want to prosecute‚Äù) <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.nysd.628916/gov.uscourts.nysd.628916.122.0_4.pdf\">was filed</a>. But even the way it was filed is weird and somewhat unprecedented. Two lawyers, including Ed Sullivan (who was mentioned above as effectively agreeing to be the fool to protect his coworkers) signed , but they did not sign the final statement. Instead, there was a further ‚Äúorder‚Äù from the DOJ, signed by Bove alone, telling the Court to effectively dismiss the case: </p><p>Even the language here is bizarre. The prosecutors don‚Äôt get to ‚Äúdirect‚Äù the Court to do anything. That‚Äôs likely why Bacon and Sullivan signed the part about ‚Äúrespectfully requests‚Äù that the Court issue an order. But Bove leaps in, acting like he gets to order around the judge, and separately signs that part.</p><p>What will be interesting now, is to see what Judge Dale Ho does.</p>","contentLength":15455,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The hardest working font in Manhattan","url":"https://aresluna.org/the-hardest-working-font-in-manhattan/","date":1739569549,"author":"robinhouston","guid":268,"unread":true,"content":"<p>\n\t\tIn 2007, on my first trip to New York City, I grabbed a brand-new DSLR camera and photographed all the fonts I was supposed to love. I admired American Typewriter in all of the I &lt;3 NYC logos, watched Akzidenz Grotesk and Helvetica fighting over the subway signs, and even caught an occasional appearance of the flawlessly-named Gotham, still a year before it skyrocketed in popularity via Barack Obama‚Äôs first campaign. \n\t</p><p>\n\t\tBut there was one font I didn‚Äôt even notice, even though it was everywhere around me.\n\t</p><p>\t\t\n\t\tLast year in New York, I walked over 100 miles and took thousands of photos of one and one font only.\n\t</p><p>\t\t\n\t\tThe font‚Äôs name is Gorton.\n\t</p><p>\t\t\n\t\tIt‚Äôs hard to believe today that there was a time before I knew of Gorton and all its quirks and mysteries. The first time I realized the font even existed was some time in 2017, when I was researching for <a target=\"_blank\" href=\"https://shifthappens.site\">my book about the history of typing</a>. \n\t</p><p>\t\t\n\t\tMany keyboards, especially older ones, sported a particular distinctive font on their keycaps. It was unusually square in proportions, and a weird m√©lange of ‚Äúmechanical‚Äù and ‚Äúchildish.‚Äù\n\t</p><p>\t\t \n\t\tThe more I looked at it, the more I realized how bizarre and amateurish it was. The G always felt like it was about to roll away on its side. There was a goofy wavy hook sticking out of Q. P and R were often too wide. &amp; and @ symbols would be laughed away in a type crit, and the endings of C felt like grabbing something next to it ‚Äì a beginning of a ligature that never came.\n\t</p><p>\t\t\n\t\tThe strangeness extended to the digits. There was a top-flatted 3 resembling a Cyrillic letter, 7 sloping down in a unique way, a very geometric 4, an unusual ‚Äì perhaps even na√Øve ‚Äì symmetry between 6 and 9, and a conflation of O with 0 that would be a fireable offense elsewhere.\n\t</p><p>\t\t\t\n\t\tLooking at just a few keyboards, it was also obvious that it wasn‚Äôt just one rigid font. There were always variations, sometimes even on one keyboard. 0 came square, dotted, or slashed. The usually very narrow letter I sometimes sported serifs. The R and the 6 moved their middles higher or lower. There also seemed to be a narrower version of the font, deployed when a keycap needed a word and not just a letter. (Lowercase letters existed too, but not very often.) \n\t</p><p>\t\t\n\t\tMy first thought was: What a mess. Is this how ‚Äú<a target=\"_blank\" href=\"https://fonts.ilovetypography.com/category/grotesque\">grotesque</a>‚Äù fonts got their name?\n\t</p><p>\t\t\n\t\tThen, the second thought: I kind of like it.\n\t</p><figcaption>The most distinctive letterforms of Gorton</figcaption><p>\t\t\n\t\tBut what font was it? What The Font website posited TT Rounds, Identifont suggested it could be Divulge, my early guess was DIN Rounded or something related to road signage. Whatever it was, a flat R clearly separated it from Helvetica, and the shapes were not as round as even the un-rounded Gotham‚Äôs.\n\t</p><p>\t\t\n\t\tA few places for keyboard nerds referred to the font as ‚ÄúGorton,‚Äù but that phrase yielded zero results anywhere I typically looked for fonts I could download and install.\n\t</p><p>\t\t\t\t\n\t\tI originally thought this had to do with how keys were made. Only in newer keyboards are the letters printed on top of the keys, or charred from their surface by a laser. In older ones ‚Äì those from the early 1960s laboratory computers, or the 1980s microcomputers ‚Äì&nbsp;the way every key was constructed was by first molding the letter from plastic of one color, and then grabbing a different plastic and molding the key around the letter. A Gorton letter was as physical as the key itself. It made the keys virtually indestructible ‚Äì the legend could not wear off any more than its key ‚Äì and I imagined required some specialized keyboard-making machinery that came with the ‚Äúkeyboard font‚Äù already there.\n\t</p><figcaption>\n\t\tAn example of a ‚Äúdouble-shot‚Äù key from above and from below\n\t</figcaption><p>\t\t\t\n\t\tBut then, I started seeing Gorton in other places.\n\t</p><p>\t\t\t\t\t\n\t\tHours of looking at close-ups of keys made me sensitive to the peculiar shapes of some of its letters. No other font had a Q, a 9, or a C that looked like this.\n\t</p><p>\t\t\t\t\t\n\t\tOne day, I saw what felt like Gorton it on a ferry traversing the waters Bay Area. A few weeks later, I spotted it on a sign in a national park. Then on an intercom. On a street lighting access cover. In an elevator. At my dentist‚Äôs office. In an alley. \n\t</p><p>\t\t\t\t\t\t\n\t\tThese had one thing in common. All of the letters were carved into the respective base material ‚Äì metal, plastic, wood. The removed shapes were often filled in with a different color, but sometimes left alone.\n\t</p><p>\t\t\t\t\t\n\t\tAt one point someone explained to me Gorton must have been a routing font, meant to be carved out by a milling machine rather than painted on top or impressed with an inked press.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome searches quickly led me to George Gorton Machine Co., a Wisconsin-based company which produced various engraving machines. The original model 1 led to model 1A and then 3U and then, half a decade later, P1-2. They were all pantograph engravers: They allowed you to install one or more letter templates and then trace their shape by hand. A matching rotating cutter would mimic your movements, and the specially configured arms would enlarge or reduce the output to the size you wanted.\n\t\t</p><p>\t\t\t\t\t\t\t\n\t\tThis immediately explained both the metaphorical and literal rough edges of Gorton.\n\t</p><p>\t\t\t\t\t\n\t\tA lot of typography has roots in calligraphy ‚Äì someone holding a brush in their hand and making natural but delicate movements that result in nuanced curves filled with thoughtful interchanges between thin and thick. Most of the fonts you ever saw follow those rules; even the most ‚Äúmechanical‚Äù fonts have surprising humanistic touches if you inspect them close enough.\n\t</p><p>\t\t\t\n\t\tBut not Gorton. Every stroke of Gorton is exactly the same thickness (typographers would call such fonts ‚Äúmonoline‚Äù). Every one of its endings is exactly the same rounded point. The italic is merely an oblique, slanted without any extra consideration, and while the condensed version has some changes compared to the regular width, those changes feel almost perfunctory.\n\t</p><p>\t\n\t\tMonoline fonts are not respected highly, because every type designer will tell you: This is not how you design a font. \n\t</p><p>\t\t\n\t\tIt seemed at this point that perhaps P1-2 and its predecessors were a somewhat popular machining product during the 20th century‚Äôs middle decades. But casual research through materials preserved by some of George Gorton Machine Company‚Äôs fans ‚Äì including <a target=\"_blank\" href=\"http://gorton-machine.org/\">the grandson of the founder</a> ‚Äì revealed something even more interesting. Gorton the font was a lot older than I expected. \n\t</p><p>\t\t\n\t\tI found a 1935 catalog showing the very same font. Then one from 1925. And then, there was one all the way from 1902, showing the shapes I was starting to be mildly obsessed with.\n\t</p><p>\t\t\t\n\t\tTo put it in perspective: the font I first assumed was a peer to 1950s Helvetica was already of retirement age the day Helvetica was born. Gorton was older than Gill Sans, Futura, or Johnston‚Äôs London Underground font. It was contemporaneous to what today we recognize as the first modern sans serif font, Akzidenz-Grotesk, released but three years before the end of the century.\n\t</p><p>\n\t\tImagine how stripped down and exotic Gorton must have felt right next to George Gorton Machine‚Äôs then-current logo!\n\t</p><p>\t\t\t\t\t\n\t\tI started researching Gorton more. Unfortunately, as I already suspected, no one ever wrote ‚ÄúI used Gorton to typeset this,‚Äù because Gorton was a tenuous name at best. It was the first font, and perhaps originally the  font that came with the engraver, so it suffered a nameless fate, familiar later to many bespoke bitmap fonts adoring the screens of early computers.\n\t</p><p>\t\t\t\t\t\n\t\tThe difference from these fonts, however, was that Gorton was meant to travel. And so, since searching for it by name was impossible, for months and years I just kept looking around for the now-familiar shapes.\n\t</p><p>\n\t\tGorton wasn‚Äôt just on computer keyboards, intercom placards, and sidewalk messages visited by many shoes. Gorton was there on typewriter keyboards, too. And on office signs and airline name tags. On boats, desk placards, rulers, and various home devices from fridges to tape dispensers.\n\t</p><p>\t\t\t\t\t\n\t\tIt was also asked to help in situations other fonts rarely did. I spotted Gorton on overengineered buttons that were put to heavy industrial and military use. I saw it carved into surfaces of traffic control devices, elevators and escalators, locomotives and subway trains, submarines and jet fighters. Gorton made its way to peace- and wartime nuclear facilities, it was there on the elevator at the Kennedy Space Center with labels marked EARTH and SPACE‚Ä¶ and it went  and then the Moon, as key legends on Apollo‚Äôs onboard computer.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut why? Why would anyone choose this kind of an ugly font where so many nicer fonts have already been around for ages?\n\t</p><p>\t\t\t\t\t\n\t\tSome of it might be the power of the default. Popular engraving equipment comes with a built-in font that‚Äôs so standard it reuses the router‚Äôs name? Of course you will see it, the same way you saw a lot of Arial in the 1990s, or Calibri today.\n\t</p><p>\n\t\tGorton was also convenient. If your previous engraving work required you do to the routing equivalent of handwriting or lettering ‚Äì every letter done by hand ‚Äì then a modern font you could simply  and one designed with ‚Äúa minimum of sharp corners for rapid tracing with a smooth stroke,‚Äù must have felt like a breath of fresh air.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut why engraving to begin with? Because the affordable and casual printing options we enjoy today ‚Äì the office laser printers and home inkjets, the FedEx Kinko‚Äôs, the various cheap labelers ‚Äì weren‚Äôt there. Even things that today feel obsolete, like dot matrix printers, Letraset, and popular letter stencils, were yet to be invented. Often, your only realistic option was the complicated and time-consuming lettering by hand.\n\t</p><p>\t\t\t\n\t\tOn top of that, Gorton‚Äôs longevity must have felt attractive. Ink smudges. Paint fades away. Paper can catch fire (quickly) or germs (slowly). Carve something into plastic, on the other hand, and it can survive decades. Substitute plastic for metal, and you just turned decades into centuries. The text is not added atop heavy-duty material. The text  the material.\n\t</p><figcaption>Various items from the 20th century typeset in Gorton</figcaption><p>\t\t\t\t\t\n\t\tI felt good about all my findings: What a strange story of a strange routing font! \n\t</p><p>\n\t\tBut it turns out I was just getting started. Because soon, I noticed Gorton as ink on paper, and as paint on metal.\n\t</p><p>We‚Äôre used to the flexibility of fonts today. Fonts as bits inside a computer can become a website, paint on paper, CNC routing, a wall projection, and many other things. But those freedoms weren‚Äôt as easy back when fonts were made out of metal. Life‚Äôs not as much fun outside of the glamor of a TTF file, and a routing font couldn‚Äôt immediately become a regular font ‚Äì so seeing Gorton being additive and not subtractive was an unexpected discovery.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tIt turns out that there developed a small cottage industry of things that extended Gorton past its engraving origins.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tA company called Keuffel &amp; Esser Co. grabbed Gorton‚Äôs machines, and used them to create lettering sets called Leroy. This was Gorton abstracted away ‚Äì still a pantograph, but cheap, small, completely manual, and a vastly simplified one: no possibility to make things bigger and smaller, and no carving ‚Äì&nbsp;instead, you‚Äôd mount a special pen and draw letters by tracing them.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tAnother company, Wood-Regan Instrument Co., made a similar set called (semi-eponymously) Wrico. But then, they simplified the process even more. Instead of a pantograph, they offered for sale a set of simple lettering guides used to guide your pen directly on paper.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome of the traditional draftspeople pooh-poohed these inventions ‚Äì one handbook wrote ‚Äú[Those are] of value chiefly to those who are not skilled in lettering. A professional show-card writer could work better and faster without it. A Leroy or Wrico lettering set permits work that is neat, rapid, and nearly foolproof, if not inspired.‚Äù\n\t</p><p>\t\t\t\n\t\tBut the products ended up being popular and influential. Their output appeared in many technical documents, but spread even a bit further than that. Eventually, there were stencils made by Unitech, Lutz, Tacro, Teledyne Post, Tamaya, Tech Graphic, Ridgway‚Äôs, Faber Castell, Zephyr, Charvoz, Rotring, Pickett, and probably many more.\n\t</p><p>\t\t\t\n\t\tThen, both EC Comics and All-Star Comics <a target=\"_blank\" href=\"https://kleinletters.com/Blog/wizards-of-leroy-and-wrico-lettering/\">used Leroy in the 1940s and 1950s</a>, most notably in the first comic book that introduced Wonder Woman. This was Gorton spreading further than just technical documents, and inspiring more people.\n\t</p><p>\t\t\t\n\t\tElsewhere silkscreening ‚Äì a pretty cool technique of applying paint on surfaces through a wet mesh of fabric ‚Äì took Gorton and Leroy in a different direction, by allowing paint on metal.\n\t</p><p>\t\t\t\n\t\tThere was more. The popular plastic letters attached to felt boards, popularized by restaurants decades ago, and more recently revisited by Instagram mom influencers, also clearly derive from Gorton and Leroy.\n\t</p><p>\n\t\tI also counted at least three different systems of ‚ÄúGorton movable type‚Äù ‚Äì some where you could assemble physical letters, and some where you could impress them into soft materials using steel types ‚Äì and I imagine there were probably more.\n\t</p><p>\t\t\t\n\t\tLetraset, a cheap technique of applying a font by rubbing a letter from a provided sheet onto paper, popular throughout the 1960s, introduced first- or second-hand Leroy too ‚Äì and so did a few competitors.\n\t</p><p>\t\t\t\t\t\n\t\tIn the regulatory space, the U.S. military canonized Gorton in 1968 as a standard called MIL-SPEC-33558 for aircraft and other equipment dials, cancelled it in 1998‚Ä¶ then brought it back again in 2007. NATO and STANAG followed. ANSI, American standardization body, made a more rounded Leroy an official font for technical lettering via <a target=\"_blank\" href=\"https://archive.org/details/ansi-y14.2m-1971-line-conventions-and-lettering\">ANSI Y14.2M</a>, and so did institutions like the US National Park Service.\n\t</p><p>\t\t\t\t\n\t\tGorton went on and on and on. The early <a target=\"_blank\" href=\"https://hackaday.com/2021/03/30/hershey-fonts-not-chocolate-the-origin-of-vector-lettering/\">Hershey vector fonts</a>, developed on very early computers and still popular in CAD applications today, were also derived from Gorton/Leroy shapes, simplified so that the already-simple curves weren‚Äôt even necessary ‚Äì&nbsp;any letter could now be drawn by a series of straight lines.\n\t</p><p>\t\t\t\t\t\n\t\tAnd even in the first universe Gorton inhabited things weren‚Äôt standing still. \n\t</p><p>\n\t\tAs the engraving industry learned what‚Äôs popular and what is not, the offerings started getting more and more sophisticated. A promotional booklet called ‚ÄúThe Whereabouts of 230 Engraving Machines‚Äù listed Gorton customers ranging from biscuit makers to fire engine constructors. <a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_933/index.html\">Other</a><a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_1370a/index.html\">catalogs</a><a target=\"_blank\" href=\"http://gorton-machine.org/forms/form_2070/index.html\">proudly listed</a> applications like book covers, billiard balls, organ keys, and toothbrushes, as well as ‚Äútools making more tools‚Äù ‚Äì using Gorton engravers to create legends for other machines.\n\t</p><p>\t\t\n\t\tAfter you bought your pantograph engraver, you could buy attachments for sometimes surprising use cases:\n\t</p><p>\n\t\tThe original machine-shop pantographs were supplanted by smaller portable units (called Pantoetchers) on one side, and by increasingly complex  devices on the other. First generation of those were still huge room-size endeavors with Nixie tubes and complex interfaces labeled‚Ä¶ in Gorton itself. \n\t</p><p>\n\t\tBut the technology matured quickly and soon more and more early manual ‚Äútracer-guided‚Äù pantographs that forced the operator to put letters side by side and then trace them by hand, were superseded by <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Numerical_control\">computerized ones</a>, with both the composition and the routing completely automated. They came from George Gorton Machine Co., and from competitors like New Hermes or H.P. Preis.\n\t</p><p>\t\t\t\t\n\t\tYou no longer had to buy the chromium-plated brass alphabets weighing up to 13 pounds, choosing the right size from 3/8¬¥¬¥ to 3¬¥¬¥ ahead of time (pantographs allowed for reductions and enlargements, but only gave you a few steps within a specific range.) \n\t</p><p>\n\t\tNow, fonts came as digits or formulas built into computer memory, or ‚Äì for a moment in time ‚Äì&nbsp;as separate cartridges you‚Äôd insert in eager slots. (And yes, before you ask:&nbsp;there were <a target=\"_blank\" href=\"https://archive.org/details/gorton-master-copy-type-for-all-pantograph-machines/page/n5/mode/2up\">other routing monoline fonts</a>, too. But I really don‚Äôt care about any of them.)\n\t</p><p>\t\t\t\t\t\n\t\tIt was the same story as in word processing right next door, where old-fashioned Gutenberg-era typesetting was being replaced by increasingly smaller and cheaper computers equipped with first-laughable-then-capable software.\n\t</p><p>\t\t\t\t\t\n\t\tAnd automation came for the Leroy branch of the tree as well. A few companies grabbed Leroy lettering templates and abstracted them away once more. They created curious small typewriter/plotter hybrids where typing letters on a keyboard would make the pen draw them on paper for you. (I own one of them, a Max Cadliner. It might be one of the strangest typewriters I‚Äôve seen ‚Äì a weird combination of a machine pretending to be another machine pretending to be a human hand.)\n\t</p><p>\t\t\t\t\n\t\tIf this was a Gorton typewriter, there were also Gorton , even more sophisticated 1980s machines whose text could be programmed in advance rather than typed one line at a time, and mixed with graphics.\n\t</p><p>\t\t\t\n\t\tI don‚Äôt think the ‚Äì by now 80 years and counting ‚Äì fractal explosion of Gorton made its original creators rich.\n\t</p><p>\t\t\t\n\t\tCopy protection in the world of typography is complicated. The font‚Äôs name can be trademarked and other companies legally prevented from using it, and you can‚Äôt just grab matrices or font files and copy them without appropriate licenses. But take any text output using a font and then redraw it ‚Äì and you are within your right to do so, and even to sell the final result. At least in America, or in some other countries until somewhat recently, the shapes of the letters themselves are not legally protected.\n\t</p><p>\t\t\t\n\t\tThis is why Keuffel &amp; Esser, Wood-Regan Instrument, and Letraset could potentially grab Gorton and claim it their own, as long as they didn‚Äôt name it Gorton. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut of course, Gorton was barely named ‚ÄúGorton‚Äù to begin with. In the early days of George Gorton pantographs, as the default pantograph font, it came without a name. (The font sets for purchase were called ‚Äústandard copies.‚Äù) Then, as other fonts were added, it was retroactively named Gorton Normal ‚Äì the name of the company and the most generic word possible.\n\t</p><p>\t\t\t\t\t\n\t\tLeroy lettering sets started with one font, so similarly to Gorton the font started to be known as ‚ÄúLeroy,‚Äù then ‚ÄúSeries C,‚Äù then ‚ÄúGothic.‚Äù New Hermes called it simply ‚ÄúBlock,‚Äù Letraset went with ‚ÄúEngineering Standard,‚Äù and Rotring ‚Äì another producer of little computerized plotters&nbsp;‚Äì with ‚ÄúUniversal.‚Äù I‚Äôve also seen ‚ÄúA style,‚Äù ‚ÄúPlain Gothic,‚Äù and, mysteriously, ‚ÄúStandpoint.‚Äù \n\t</p><p>\t\t\t\t\t\t\t\n\t\tI don‚Äôt think this was meant to be disrespectful. ‚ÄúStandard,‚Äú ‚ÄúUniversal,‚Äù ‚ÄúA style‚Äù might not have had the connotations of ‚Äúgeneric‚Äù we associate with them today, but rather meaning ‚Äúthe only one you need,‚Äù ‚Äúapproved of by millions,‚Äù or ‚Äúthe ultimate.‚Äù\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut there  one name that felt somewhat inconsiderate. It appeared in one product in the 1980s, a few decades after the birth of another font whose name became recognizable and distinguished. In that product, Gorton was referred to as ‚ÄúLinetica.‚Äù\n\t</p><figcaption>A few rare examples of Gorton Extended in use</figcaption><p>\t\t\t\t\t\t\n\t\tEach of these reappearances made small changes to the shapes of some letters. Leroy‚Äôs ampersand was a departure from Gorton‚Äôs. Others softened the middle of the digit 3, and Wrico got rid of its distinctive shape altogether. Sometimes the tail of the Q got straightened, the other times K cleaned up. Punctuation ‚Äì&nbsp;commas, quotes, question marks ‚Äì&nbsp;was almost always redone. But even without hunting down the proof confirming the purchase of a Gorton‚Äôs pantograph or a Leroy template set as a starting point, the lineage of its lines was obvious. (The remixes riffed off of Gorton Condensed or the normal, squareish edition‚Ä¶ and at times both. The extended version ‚Äì not that popular to begin with ‚Äì was often skipped.)\n\t</p><figcaption>Classic Gorton vs. Gorton Modified</figcaption><p>\t\t\t\t\t\t\n\t\tThe only ‚Äúofficial‚Äù update to Gorton I know of, and one actually graced with a name, was Gorton Modified. It was made some time in the 1970s by one of the main keyboard keycap manufacturers, Comptec (later Signature Plastics). It was almost a fusion of Gorton and Futura, with more rounded letterforms. Gone was the quirkiness of 3, 7, Q, C, and the strange, tired ampersand. This is the version people might recognize from some of the 1980s computers, or mechanical keyboards today. \n\t</p><p>\n\t\tIt is also that last Gorton that mattered.\n\t</p><figcaption>A collection of movies and TV shows featuring Gorton</figcaption><p>\t\t\t\t\t\t\t\n\t\tMy every walk in Chicago or San Francisco was counting down ‚Äútime to Gorton‚Äù ‚Äì sometimes mere minutes before I saw a placard or an intercom with the familiar font.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tThis might be embarrassing to admit, but I have never been so happy seeing a font in the wild, particularly as there was almost always some new surprise ‚Äì a numero, a line going through the Z, a new use, or a new imperfection. And, for a font that didn‚Äôt exist, I saw it surprisingly often.\n\t</p><p>\t\t\t\t\t\t\t\t\t\n\t\tI even spotted Gorton a few times in Spain, or the U.K., and didn‚Äôt make too much of it, not thinking about the likelihood of machines from George Gorton‚Äôs company in a small town of Racine, Wisconsin making it all the way to different continents. In hindsight I should have.\n\t</p><figcaption>Gorton on old British cars, with a particularly delightful Rolls Royce logo made by a simple duplication of the classic Gorton letter R</figcaption><p>\t\t\t\t\t\t\n\t\tIt was only on a trip to Australia where something started connecting. Here, once more, I saw Gorton on the streets, put to work in all sorts of unglamorous situations:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSome letterforms in the above photos felt slightly odd, and so did Gorton on the heavy machinery in an abandoned shipyard on an island near Sydney:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tAnd a visit to a naval museum cemented it all:\n\t</p><p>\n\t\tIt was Gorton, although with some consistent quirks: 2, 5, 6, and 9 were shorter, the centers of M and W didn‚Äôt stretch all the way across, and the distinctive shape of S was slightly different here.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tFortunately, this time around, a type designer familiar with my now-public obsession with Gorton clued me in. Gorton didn‚Äôt actually originate from Racine, Wisconsin in the late 19th century. It started a bit earlier, and quite a bit further away, at a photographic lens maker in the U.K. called Taylor, Taylor &amp; Hobson. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tIn 1894, TT&amp;H needed some way to put markings on their lenses. This being late 19th century, their options were limited to manual engraving, which must have felt tricky given the small font sizes necessary. So the company did what makers sometimes do ‚Äì instead of searching for a solution that might not have even existed, they made new types of machines to carve out letters, and then designed a font to be used with them.\n\t</p><p>\n\t\tI don‚Äôt know how this first proto-Gorton was designed ‚Äì unfortunately, Taylor, Taylor &amp; Hobson‚Äôs history seems sparse and despite personal travels to U.K. archives, I haven‚Äôt found anything interesting ‚Äì but I know simple technical writing standards existed already, and likely influenced the appearance of the newfangled routing font.\n\t</p><figcaption>From a 1895 ‚ÄúFree-hand lettering‚Äù book by Frank T. Daniels</figcaption><p>\t\t\t\t\t\n\t\tThis was perhaps the first modern pantograph engraver, and perhaps even the arrival of a concept of an engraving font ‚Äì the first time technical writing was able to be replicated consistently via the aid of the machine.\n\t</p><p>\t\t\t\n\t\tNo wonder that other companies came knocking. Only a few years later, still deep within the 19th century, Taylor, Taylor &amp; Hobson <a target=\"_blank\" href=\"http://gorton-machine.org/archives/TTH_license_1898/index.html\">licensed their stuff to a fledgling American company</a> named after its founder. Gorton Model 1 was the first U.S. version of the engraver, and the TT&amp;H font must have been slightly adjusted on arrival. \n\t</p><figcaption>A Taylor-Hobson pantograph in use in 1942</figcaption><p>\t\t\t\n\t\tThis adds to the accomplishments of Gorton ‚Äì the font was actually  than even Akzidenz-Grotesk, and has been used on World War II equipment and later on on British rifles and motorcycles (and 3,775 finger posts in <a target=\"_blank\" href=\"https://www.yorkshiredales.org.uk/behind-the-signs-the-man-and-the-machine/\">one of the UK‚Äôs national parks</a>), but it complicates the story of the name even more. Turns out, the font without a name has even less of a name than I suspected.\n\t</p><p>\t\t\t\n\t\tIf the Taylor, Taylor &amp; Hobson (or, Taylor-Hobson, as their engravers were known) ‚Äúbranch‚Äù of Gorton were more used, should it usurp the at least somewhat popular Gorton name? Or should it just because it was first and the letterform changes were small? Does it matter? Where does one font end and another begin? (Unsurprisingly, TT&amp;H didn‚Äôt properly name the font either, eventually calling it ‚ÄúA style‚Äù for regular and ‚ÄúC style‚Äù for condensed variants. Google searches for ‚Äútaylor hobson font‚Äù are a lot more sparse than those for Gorton.)  \n\t</p><div><div><div>GortonGorton Condensed</div></div></div><figcaption>The Gorton quasisuperfamily</figcaption><p>\n\t\tIn the end, I‚Äôm sticking with Gorton for the whole branch since that feels the most well-known name, but I feel ill-equipped to make that call for everyone. You might choose to call it Gorton, Leroy, TT&amp;H, Taylor-Hobson, or one of the many other names. (Just, ideally, not Linetica.)\n\t</p><figcaption>A comparison of all major editions of Gorton</figcaption><p>\t\t\t\t\t\n\t\tAnd so, throughout the 20th century, Gorton has lived two parallel lives ‚Äì&nbsp;one originating in the U.K. and later expanding to its colonies and the rest of Europe, and another one in America. \n\t</p><p>\t\t\t\t\t\t\t\n\t\tI am still tracing various appearences of Gorton and perhaps you, dear reader, will help me with that. (<a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Frequency_illusion\">Chances are</a>, you will see Gorton later today!) I‚Äôm curious about whether Gorton made it to Eastern Europe, Africa, or Asia. I‚Äôm interested in seeing if it appeared in Germany where the objectively better-designed DIN fonts became much more popular in Gorton‚Äôs niche.\n\t</p><p>\n\t\tThe history of this strange font spans over a century and I‚Äôve seen it in so many countries by now, used in so many situations. But it‚Äôs impossible for me to say Gorton is the most hard-working font in the world.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tTo this title, there are many contenders. Garamond has a head start of 300+ years and has been released in more versions than letters in any alphabet. Helvetica is so famous and used so much that even its ugly copy, Arial, became a household name. Whatever font MS Office or a popular operating system appoint to be ‚Äúthe default‚Äù ‚Äì from Times New Roman through Calibri to Roboto ‚Äì immediately enjoys the world premiere that any Hollywood movie would be envious of. There is even a 5√ó7 pixel font originally started by Hitachi that you can see everywhere on cheap electronic displays in cash registers and intercoms.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tBut there is one place in the world where Gorton pulls triple duty, and I feel confident in saying at least this: Gorton is the hardest working font in Manhattan.\n\t</p><p>\t\t\t\t\t\t\n\t\tIn 2007, on my first trip to New York City, I grabbed my brand-new DSLR camera and photographed all the fonts I was supposed to love: American Typewriter, Helvetica, Gotham. But, in hindsight, I missed the most obvious one.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tGorton is everywhere in Manhattan. It‚Äôs there in the elevators, in the subway, on ambulances, in various plaques outside and inside buildings. And god knows it‚Äôs there on so, so many intercoms.\n\t</p><p>\t\t\t\t\t\n\t\tI wouldn‚Äôt be surprised if there weren‚Äôt a single block without any Gorton in a whole of Manhattan.\n\t</p><figcaption>A complete inventory of Gorton outside, near my hotel, between 5th and 7th avenues and 25th and 35th streets. I didn‚Äôt have access to the interiors of most buildings.</figcaption><p>\t\n\t\tThe omnipresence of Gorton makes it easy to collect all the type crimes layered on top of the font‚Äôs already dubious typographical origins. Walking through Manhattan, you can spot the abominable lowercase that should better be forgotten:\n\t</p><p>\t\t\t\t\t\t\t\n\t\tYou can see all sorts of kerning mistakes:\n\t</p><p>\t\t\t\t\t\t\t\t\t\n\t\tYou will notice the many, many routing imperfections ‚Äì an unfinished stroke, a shaky hand, or services of a pantograph that never felt the loving touch of regular maintenance:\n\t</p><p>\n\t\tThere are all the strange decisions to haphazardly mix various styles of Gorton, or even to mix Gorton with other fonts:\n\t</p><p>\t\t\t\t\t\t\t\t\t\t\t\n\t\tYou can even spot reappearing strange characters like a weirdly deep 3, or a flattened 4:\n\t</p><p>\n    I wish I understood how they came to be, but I have a hunch. The nature of pantographic reproduction is that Gorton carved into metal is not that far away from the original Gorton font template you started with! So in addition to the George Gorton and Taylor Hobson originals, and the other named and above-the-table copies, they might have been bigger or smaller Gorton . I have one myself, carved into acrylic, of unknown provenance and even more nameless than I thought possible for an already name-free font.\n  </p><p>\n\t\tBut New York Gorton holds pleasant surprises, too. Despite the simplicity of Gorton itself, the combinations of font sizes, cutter sizes, materials, reproductions, and applications can still yield some striking effects:\n\t\n\t</p><figcaption>\n\t\t\tAll my Gorton walks in Manhattan in 2024\n\t\t</figcaption>\n\n\t\tThis was what made me walk 100 miles. Over and over again, Gorton found ways to make itself interesting. Without hyperbole, I consider the above photos simply beautiful.\n\t<p>\n\t\tIn a city that never sleeps, Gorton wasn‚Äôt allowed to sleep, either. Even in the richest and most glamorous neighborhoods of Manhattan, the font would be there, doing the devil‚Äôs work without complaining. Gorton made Gotham feel bougie; American Typewriter touristy.\n\t</p><p>\n\t\tAnd once in a while, I‚Äôd find Gorton that would wink at me with a story ‚Äì&nbsp;followed by that aching in the heart as I realized I‚Äôd never know what the story was.\n\t</p><p>\t\t\t\n\t\tYou‚Äôre not supposed to fall in love with an ugly font. No one collects specimens of Arial. No one gets into eBay fights for artifacts set in Papyrus. No one walks a hundred miles in a hot New York summer, sweating beyond imagination, getting shouted at by security guys, to capture photos of Comic Sans.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tSo why do I love Gorton so much? \n\t</p><p>\t\t\t\t\t\t\t\n\t\tThe Occam‚Äôs Razor seems sharp on this one. Perhaps I like it because I‚Äôm a boy and Gorton is often attached to heavy machinery. \n\t</p><p>\t\t\t\t\n\t\tBut there must be more to it. Perhaps it‚Äôs all about the strange contrasts Gorton represents. The font is so ubiquitous, but also profoundly unrecognizable, sporting no designer and no name. Gorton is a decidedly toy-like, amateurish font deployed to for some of the most challenging type jobs: nuclear reactors, power plants, spacecraft. More than most other fonts, Gorton feels it‚Äôs been made by machines for machines ‚Äì&nbsp;but in its use, it‚Äôs also the font that allows you to see so many human mistakes and imperfections.\n\t</p><p>\t\t\t\t\n\t\tGorton also feels mistake-friendly. The strange limitations of Gorton mean that some of the transgressions of other fonts don‚Äôt apply here. The monoline nature of the font means that messing with the size of Gorton is okay: Shrinking the font for small caps or superscript, for example, gives you still-valid letterforms, almost by accident. \n\t</p><p>\n\t\tStretching or slanting Gorton is not as much a typographical crime as it would be with other fonts because you don‚Äôt stretch the tip of the router itself.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tThere are genuinely moments where I felt Gorton gave people freedoms to maul it decades before variable fonts allowed us similar flexibiity.\n\t\tAnd on top of that, the simplicity of the letterforms themselves feels compatible with the typical na√Øvet√© of Gorton‚Äôs typesetting. \n\t</p><figcaption>Various accessories and attachments allowing you to shift Gorton around in a way other fonts would not allow</figcaption><p>\n    Sure, there are really bad renditions that are inexcusable. \n\n\t\tBut most of the time, the imperfections and bad decisions are what makes Gorton come alive. They don‚Äôt feel like a profound misunderstandings of typography, typesetting, or Gorton itself. They don‚Äôt feel like abuses or aberrations. No, they feel exactly how Gorton was supposed to be used ‚Äì haphazardly, without much care, to solve a problem and walk away. (Later routing fonts copied Helvetica, but seeing Helvetica in this context with all the same mistakes grates so much more.)\n\t</p><p>\t\t\t\n\t\tThe transgressions are not really transgressions. They all feel honest. The font and its siblings just show up to work without pretense, without ego, without even sporting a nametag. Gorton isn‚Äôt meant to be admired, celebrated, treasured. It‚Äôs meant to do some hard work and never take credit for it. Gorton feels like it was always a font, and never a typeface. (Depending on how rigid you are with your definitions, some versions of Gorton ‚Äì especially those without instructions on how letters are positioned against each other ‚Äì might not even <a target=\"_blank\" href=\"https://mastodon.design/@fhardwig@mastodon.social/113515144112560218\">classify as a font</a>!)\n\t</p><p>\t\t\t\t\t\n\t\tAnd I think I love Gorton because over the years I grew a little tired of the ultra flat displays rendering miniature pixels with immaculate precision. \t\n\t\tWith Gorton, carving into metal or plastic means good-looking fixes are impossible:\n\t</p><p>\n\t\tAnd unsurprising given its roots, Gorton has dimensionality that most fonts cannot ever enjoy: A routing tip picked in the 1980s and a sun coming in from just the right angle forty years later can create a moment that thousands of letterpress cards can only dream of.\n\t</p><p>\n\t\tPerhaps above everything else, Gorton is all about . \n  </p><p>\n    Every kind of engraving has it, of course. But these are not precise submillimeter letters at the bottom of your MacBook Pro or Apple Watch. This is the utilitarian, often harried, sometimes downright  Gorton, carved into steel of a  \n\t\tmid-century intercom and filled in with <a target=\"_blank\" href=\"https://youtu.be/llzdLgMurvw?si=8S7px9gg8iH4iav2&amp;t=101\">special paste or wax</a>, or put on an office placard made out of a special two-layer material made especially so engraving it reveals the second color underneath, without the need for infill. \n\t</p><p>\t\t\t\n\t\t(This is also true when it comes to the original reason I learned of Gorton. Letters on keycaps show the same artifacts ‚Äì you just have to look very, very closely.)\n\t</p><p>\n\t\tThat‚Äôs the last, and perhaps the best thing to fall in love with. \n\t</p><p>\n\t\tYou won‚Äôt be able to fully appreciate it here, of course, but maybe this will give an approximation of how beautiful Gorton‚Äôs non-beauty can be:\n\t</p><p>\t\t\t\t\t\n\t\tThis has been a strange thing to write. Gorton has been around for over 135 years and used in so many countries for so many reasons, and yet I found no single article about it. \n\t</p><p>\t\t\t\t\t\n\t\tI feel the burden of being an amateur historian, wanting to know and share so much more, but only being able to provide little. I don‚Äôt know the full extent of Gorton‚Äôs use. I don‚Äôt know who designed it. My chronology is rickety and pieced together from a few breadcrumbs. I dream of seeing the original drawings or drafts once laid on the tables of Taylor, Taylor &amp; Hobson offices, or some notes, or some correspondence. I fear they might no longer exist.\n\t</p><p>\t\t\t\t\t\n\t\tAlso, if part of the allure of Gorton is shying away from the limelight and not being admired, am I doing it a disservice by writing about it?\n\t</p><p>\t\t\t\t\t\n\t\tBut mostly, I can‚Äôt shake the feeling that we all missed a window. That this essay can‚Äôt be just a celebration, but also needs to be the beginnings of a eulogy.\n\t</p><p>\t\t\t\t\t\n\t\tWalking around New York, you get a sense that even Gorton carved into metal can disappear. Some of the signs are rusted or destroyed beyond repair. Others get replaced by more modern, charmless equivalents.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tGorton itself is obsolete. All <a target=\"_blank\" href=\"https://spkeyboards.com/\">the keyboards that use Gorton Modified</a> you can still buy new today are tipping a hat to nostalgia. The omnipresence of Gorton in New York City is already time shifted from its decades of glory, a simple confirmation of what Robert Moses knew so well: that once built, cities don‚Äôt change all that much. But few of the new placards use Gorton, and none of the new intercoms do. \n\t</p><p>\n\t\tTaylor, Taylor &amp; Hobson went through multiple splits and mergers and survives as a subsidiary of Ametek, chiefly working on measuring devices. George Gorton Machine Co. from Racine has been bought by Kearny &amp; Trecker, which became Cross &amp; Trecker, was acquired by Giddings &amp; Lewis, and then acquired  by ThyssenKrupp, but not before the Gorton branch was spun off as Lars, and in a sequence of events now resembling a telenovella, eventually bought by Famco in 1987. I do not believe any corporate grandchildren of TT&amp;H and George Gorton‚Äôs company are today selling Gorton in any capacity.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tIt will take decades, perhaps even centuries, but one day the last of this font will be gone. The modern recreations (<a target=\"_blank\" href=\"https://aresluna.org/the-hardest-working-font-in-manhattan/the-hardest-working-font-in-manhattan/recreations\">I eventually found quite a few</a>) won‚Äôt help. They are perhaps all missing a point, anyway.\n\t</p><p>\n\t\tBut there‚Äôs a somewhat silver lining. Yes, when Gorton is carved into fresh metal, there might be nothing more pretty than seeing its depths glistening in the sun.\n\t</p><p>\n\t\tBut fresh, shining metal is at this point rare. Fortunately, the Gorton I love most is the weathered Gorton.\n\t</p><p>\t\t\t\t\t\t\t\n\t\tManhattan‚Äôs tired Gorton is the best variant of Gorton: infill cracked by hot summers followed by frigid winters, the surface scratched by keys or worn out by many finger presses, the routing snafus meeting decades of wear and tear. Gorton‚Äôs no stranger to water, snow, rust, or dirt.\n\t</p><p>\t\t\n\t\tThis is, perhaps, how you become gortonpilled. You learn to recognize the 7 with a crooked hook, the Q with a swung dash, the strange top-heavy 3, the simple R. You start noticing the endings of each character being consistently circular, rather than occasionally flat. A routing mistake, suspicious kerning, or the absence of lowercase are not a wrongdoing ‚Äì they‚Äôre a .\n\t</p><p>\t\t\t\t\t\t\t\n\t\tYou find yourself enchanted with how this simple font went so very far. And then you touch the letters, just to be sure. If you can  them, chances are this is Gorton.\t\t\n\t</p>","contentLength":38055,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053419"},{"title":"OpenAI says its board of directors ‚Äòunanimously‚Äô rejects Elon Musk‚Äôs bid","url":"https://techcrunch.com/2025/02/14/openai-says-its-board-of-directors-unanimously-rejects-musks-bid/","date":1739569507,"author":"Kyle Wiggers","guid":47,"unread":true,"content":"<p>OpenAI‚Äôs board of directors has ‚Äúunanimously‚Äù rejected billionaire Elon Musk‚Äôs offer to buy the nonprofit that effectively governs OpenAI, the company said on Friday. In a statement shared via OpenAI‚Äôs press account on X, Bret Taylor, board chair, called Musk‚Äôs bid ‚Äúan attempt to disrupt his competition.‚Äù ‚ÄúOpenAI is not for sale, and the board [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":432,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bluesky gets growth and analytics tools with BlueSkyHunter launch","url":"https://techcrunch.com/2025/02/14/bluesky-gets-growth-and-analytics-tools-with-blueskyhunter-launch/","date":1739569355,"author":"Sarah Perez","guid":46,"unread":true,"content":"<p>A new startup is addressing the need for an all-in-one toolset built for people who want to grow, manage, and track their Bluesky presence and following. The subscription service BlueSkyHunter, which launched Friday, introduces an online dashboard that combines access to analytics and other tools to schedule posts and automate DMs (direct messages), alongside other [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":436,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Global electricity demand expected to grow 4% annually through 2027","url":"https://techcrunch.com/2025/02/14/global-electricity-demand-expected-to-grow-4-annually-through-2027/","date":1739569205,"author":"Tim De Chant","guid":45,"unread":true,"content":"<p>Meeting that demand will require adding more generating capacity than all of Japan ‚Äî&nbsp;every year.&nbsp;</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":164,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Iconic 3DBenchy Enters the Public Domain","url":"https://www.nti-group.com/home/information/news/3dbenchy/","date":1739569169,"author":"kotaKat","guid":267,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43053350"},{"title":"How this weekend‚Äôs ‚ÄòTesla Takeover‚Äô protests against Elon Musk came together on Bluesky","url":"https://techcrunch.com/2025/02/14/how-this-weekends-tesla-takeover-protests-against-elon-musk-came-together-on-bluesky/","date":1739568849,"author":"Sean O'Kane","guid":44,"unread":true,"content":"<p>As Elon Musk and his acolytes rip through the federal government looking for agencies to throw into the ‚Äúwood chipper,‚Äù a grassroots effort to hit the world‚Äôs richest man where it hurts is picking up steam. The courts are busy contesting the actions of Musk‚Äôs Department of Government Efficiency, but the judicial system is slow [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":405,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What is device code phishing, and why are Russian spies so successful at it?","url":"https://arstechnica.com/information-technology/2025/02/russian-spies-use-device-code-phishing-to-hijack-microsoft-accounts/","date":1739567771,"author":"Dan Goodin","guid":405,"unread":true,"content":"<p>Researchers have uncovered a sustained and ongoing campaign by Russian spies that uses a clever phishing technique to hijack Microsoft 365 accounts belonging to a wide range of targets, researchers warned.</p><p>The technique is known as device code phishing. It exploits ‚Äúdevice code flow,‚Äù a form of authentication formalized in the industry-wide <a href=\"https://tools.ietf.org/html/draft-ietf-oauth-device-flow-07#section-3.4\">OAuth standard</a>. Authentication through device code flow is designed for logging printers, smart TVs, and similar devices into accounts. These devices typically don‚Äôt support browsers, making it difficult to sign in using more standard forms of authentication, such as entering user names, passwords, and two-factor mechanisms.</p><p>Rather than authenticating the user directly, the input-constrained device displays an alphabetic or alphanumeric device code along with a link associated with the user account. The user opens the link on a computer or other device that‚Äôs easier to sign in with and enters the code. The remote server then sends a token to the input-constrained device that logs it into the account.</p>","contentLength":1058,"flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2022/03/phishing.jpeg","enclosureMime":"","commentsUrl":null},{"title":"DeepSeek founder Liang Wenfeng is reportedly set to meet with China‚Äôs Xi Jinping","url":"https://techcrunch.com/2025/02/14/deepseek-founder-liang-wenfeng-is-reportedly-set-to-meet-with-chinas-xi-jinping/","date":1739565917,"author":"Kyle Wiggers","guid":43,"unread":true,"content":"<p>Chinese AI startup DeepSeek founder Liang Wenfeng is reportedly set to meet with China‚Äôs top politicians, including Chinese leader Xi Jinping, during a summit that Alibaba founder Jack Ma is also expected to attend. The summit, which could happen as soon as next week, may be intended as a signal by China‚Äôs Communist Party that [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":401,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why PAUL Needs a Massive Dataset to Improve Its Movements","url":"https://hackernoon.com/why-paul-needs-a-massive-dataset-to-improve-its-movements?source=rss","date":1739565002,"author":"EScholar: Electronic Academic Papers for Scholars","guid":68,"unread":true,"content":"<p>(1) Jorge Francisco Garcia-Samartƒ±n, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid ‚Äî Consejo Superior de Investigaciones Cientƒ±ficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain (jorge.gsamartin@upm.es);</p><p>(2) Adrian Rieker, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid ‚Äî Consejo Superior de Investigaciones Cientƒ±ficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain;</p><p>(3) Antonio Barrientos, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid ‚Äî Consejo Superior de Investigaciones Cientƒ±ficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain.</p><p>3 PAUL: Design and Manufacturing</p><p>4 Data Acquisition and Open-Loop Control</p><h2>4.3 Dataset Generation: Table-Based Models</h2><p>Due to the complexity of the robot, model-based methodologies, such as PCC or the ones based on Cosserat Rod Theory were discarded. Although the usage of FEM is an avenue that will not be closed in future work, the large number of parameters to be set experimentally for each segment (Young‚Äôs modulus, moment of inertia. . . ), given that the manufacturing process is so variable meant that, in this first phase, we opted to use some type of PAUL modelling based on data collection.</p><p>\\\nThe output of the system is taken as the position and orientation reached by the final end ‚Äìthus, at this stage, all the positions of the intermediate segments are ignored‚Äì and as input, the inflation times of each of the bladders. As there were not enough pressure sensors available at the time of the construction of the robot, it was decided to take inflation time as an input variable. As the working pressure is limited by the pressure limiting valve and the flow rate into each bladder can be assumed to be constant, the time is equivalent to the volume of air introduced into each cavity.</p><p>\\\nAll the control options considered have in common the need for a large amount of empirical data, which leads to the need to develop an experimental design to systematise the collection of this data. Since the capture of this information is done in different phases and the datasets have to represent the behaviour of the robot in an objective way, the re-applicability of the experiment takes on special importance.</p><p>\\\nThe data stored in the datasets was the position of the robot tip and the set of inflation times that achieve this configuration. The aforementioned limitation that only two of the three bladders in the segment are inflated reduces redundancies. As previously stated, more than two segments lead to redundancies, which implies that the inverse kinematic model of the robot can have multiple solutions.</p><p>\\\nThe data collection process involves several sequential steps. Initially, a set number of samples is determined. For each sample, Matlab commands dispatch a random combination of nine inflation times, corresponding to each valve of PAUL, to the actuation bench. Times are generated below a maximum time limit Tmax, and ensuring that only two cavities per segment are inflated. Following this, the robot‚Äôs bladders are inflated based on the sent times. Subsequently, the vision system‚Äôs two cameras capture images to determine the position and orientation of the robot‚Äôs end. This entire procedure is repeated for the specified number of iterations, and upon completion, the collected data is stored in the dataset</p><p>\\\nThe information on swelling times is stored as a percentage, with a value of 0 corresponding to a zero swelling of that segment and 100 corresponding to Tmax, the swelling for the maximum number of milliseconds defined for this data collection session. This value Tmax is stored, together with the values, in the dataset, in order to be able to compare different datasets. The reason for this coding comes from the lack of information, a priori, on what is the maximum pressure that a PAUL bladder admits. Although it is true that it was experimentally determined that inflation times of more than 1500 ms in a row led to punctures, the application of lower times during a repeated number of cycles also generated leaks. On this basis, it was decided never to inflate any valve, either in one or several steps, more than 1000 ms.</p><p>\\\nAlong with the inflation times of each bladder, the position and orientation reached by the end tip is stored, based on the camera readings. In particular, the position of the green marker and the orientation of the trihedron are stored. The latter is expressed in Euler angles, as it is a much efficient form of storage than a rotation matrix. In addition, the dataset also contains metadata from the collection process that are believed to influence the results, such as the pneumatic line pressure or the ambient temperature.</p><p>\\\nSome aspects in the pneumatic system merit attention. Initially, bladder inflation and deflation are not symmetrical processes. Geometric constraints in the pneumatic components result in a lower deflation rate compared to inflation. Consequently, when the PAUL receives a deflation time, it multiplies it by an empirically derived factor, approximately 1.45 for a 1.2 bar working pressure. This multiplier compensates for the discrepancy between inflation and deflation times of a singular group of bladders, ensuring that the deflation time aligns with the time required to reach the same inflation point.</p><p>\\\nSimilarly, although it is physically possible to inflate several valves at the same time, it has been shown that this parallel flow distribution means that the effective fillings of each valve are not the same as if they were inflated individually. To prevent this phenomenon, it was decided to inflate each bladder individually both during the data acquisition process and utterly, when PAUL was asked to reach certain positions.</p><p>\\\nFinally, there are hysteresis phenomena in the silicone that cause the position reached by inflating for a time t to be different from the position reached by inflating first for a time t1 and then for a time t2 = t ‚àí t1. The strategy employed to tackle this problem was to capture the dataset bringing PAUL back to its zero position between each sample. Nevertheless, when controlling the robot in open-loop this is not possible, or, at least, not desirable, as one may wish to follow trajectories or travel through a sequence of points. Therefore, transitioning from position x1 to x2 requires an additional factor of 1.2, also derived experimentally, to account for hysteresis effects.</p><p>Once the dataset is generated, it can be used to model the behaviour of PAUL for open-loop control. It is foreseen, as a future line, to train a neural network for the direct kinematics and another one for the inverse kinematics. However, given the large amount of data that may be required (in [62] 24389 samples are used for a three-segment robot like this one), a table look-up method has been used for this work.</p><p>\\\nThe method for direct kinematics ‚Äìwhich allows obtaining the position and orientation of the final end of the robot from the inflation times of the nine bladders‚Äì consists of searching, in the generated dataset in the previous step, the three inflation time values located at a shorter distance from the inflation time given as a reference. Obviously, if the set of inflation times sought were in the table, the value associated with these times would be returned as a result of the direct kinematic model. Otherwise, the average of the position and orientation values associated with the three closest inflation times, weighted by the distance (Euclidean norm) existing between each of them and the values of reference inflation times, is returned as the position and orientation value of the robot.</p><p>\\\n\\\nwith them, it is possible to calculate the position returned by the direct kinematic model using the expression:</p>","contentLength":7812,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NATO backs its first cohort of European dual-use startups","url":"https://techcrunch.com/2025/02/14/nato-backs-its-first-cohort-of-european-dual-use-startups/","date":1739564172,"author":"Mike Butcher","guid":42,"unread":true,"content":"<p>With both Vice President J.D. Vance and U.S. Defense Secretary Pete Hegseth making loud noises Friday about Europe stepping up to the plate in spending more on its own defense, it might come as a surprise that Europe is already on the path toward far greater investment in defense, especially in tech. Not only has [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":383,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How PAUL the Robot Tracks Its Own Movements Using Cameras and LEDs","url":"https://hackernoon.com/how-paul-the-robot-tracks-its-own-movements-using-cameras-and-leds?source=rss","date":1739564107,"author":"EScholar: Electronic Academic Papers for Scholars","guid":67,"unread":true,"content":"<p>(1) Jorge Francisco Garcia-Samartƒ±n, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid ‚Äî Consejo Superior de Investigaciones Cientƒ±ficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain (jorge.gsamartin@upm.es);</p><p>(2) Adrian Rieker, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid ‚Äî Consejo Superior de Investigaciones Cientƒ±ficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain;</p><p>(3) Antonio Barrientos, Centro de Automatica y Robotica (UPM-CSIC), Universidad Politecnica de Madrid ‚Äî Consejo Superior de Investigaciones Cientƒ±ficas, Jose Gutierrez Abascal 2, 28006 Madrid, Spain.</p><p>3 PAUL: Design and Manufacturing</p><p>4 Data Acquisition and Open-Loop Control</p><h2>4 Data Acquisition and Open-Loop Control</h2><p>In order to provide the manipulator with a solid and stable fastening system, which would also allow reliable and predictable data capture of the positions and orientations of its end, the metal structure shown in Figure 10 was built. It is a cube made of steel profiles with methacrylate sheets on the walls. The pneumatic bench, the power supply and the microcontroller were placed on top of the structure.</p><p>\\\nThe aim of the data acquisition system is to be able to measure, whenever required, the position and orientation of the end of the robot in order to be able to relate it to the inflation times of each bladder and thus be able to create an open-loop model of PAUL. For this purpose, three elements are available: the cameras, the calibration grid and the trihedron.</p><p>\\\nTwo Spedal AF926H USB cameras with 1920 x 1080 px, 80‚ó¶ field of view and a frequency of 60 fps are used to capture the images. These have been placed on two tripods external to the robot‚Äôs structure. They are calibrated with a checkerboard of 11 x 8 squares of 20 mm each, which can be seen in Figure 11a.</p><p>\\\nThe vision beacon, on the other hand, has the task of being recognised in space to determine the position and orientation of the mobile system with respect to the fixed system. The trihedron, displayed in Figure 11b, consists of three spheres, manufactured by 3D printing in PLA, inside which three LED diodes have been embedded. Thanks to these, it is possible to vary the luminosity of the spheres by means of software, keeping the system functioning correctly when the workplace or the environmental or lighting conditions vary.</p><p>\\\nThe existence of the central rod, which moves the luminous spheres away from the base of the robot end, makes possible the spheres to be visible to the cameras in all the poses that the robot can adopt. If the spheres were otherwise directly attached to the</p><p>\\\nend of the robot, there would be numerous poses in which it would not be possible to determine the position, as the spheres would be hidden by the robot itself.</p><h3>4.2 Vision Capture System</h3><p>\\\n\\\nBecause coordinates of the real world are independent of the camera, if Equation (1) is applied for both cameras and rk vector cleared in the two equations, it can be said that:</p><p>\\\n\\\nSystem of equations (2) can be solved using the Least Squares Method:</p><p>\\\n\\\nand then use the Rodrigues‚Äô rotation formula to obtain it, respect to the real world base in the form of a rotation matrix:</p><p>\\\n\\\nand I denotes the identity matrix of size 3.</p>","contentLength":3247,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Drugs Have Won The War On Drugs: Drugged-Up Rat Infestation Edition","url":"https://www.techdirt.com/2025/02/14/drugs-have-won-the-war-on-drugs-drugged-up-rat-infestation-edition/","date":1739563659,"author":"Tim Cushing","guid":287,"unread":true,"content":"<p>50+ years of hardline prohibition have only resulted in better prices, better purity, and a slew of states legalizing or decriminalizing personal use amounts of any number of drugs, with marijuana leading the way in terms of overall legalization. </p><p>Treating drugs users as just as terrible as drug dealers has led to a ton of incarceration and a  ton of collected evidence that is apparently being consumed by things cops and crooks are used to dealing with: rats.</p><blockquote><p><em>‚ÄúDrug-addicted rats‚Äù are eating narcotics seized and stored by Houston police, prompting a change in how long the police department is required to store the evidence, officials said.</em></p><p><em>Houston Mayor John Whitmire, Harris County District Attorney Sean Teare and Houston Police Chief J. Noe Diaz announced new steps Friday to dispose of drugs and other evidence kept at police headquarters downtown, some of which has been sitting there for decades, attracting rodents, even though cases they are linked to have long been adjudicated.</em></p></blockquote><p>This is where it becomes clear that drugs have won the Drug War. This single evidence locker contains enough weed to start a drug empire. </p><blockquote><p><em>‚ÄúWe got 400,000 pounds of marijuana in storage,‚Äù Whitmire said. ‚ÄúThe rats are the only ones enjoying it.‚Äù</em></p></blockquote><p>The Houston PD (which has <a href=\"https://www.techdirt.com/2024/10/17/houston-cop-gerald-goines-gets-60-year-sentence-for-leading-bogus-drug-raid-that-ended-with-cops-killing-two-people/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2024/10/17/houston-cop-gerald-goines-gets-60-year-sentence-for-leading-bogus-drug-raid-that-ended-with-cops-killing-two-people/\">more than its share</a> of <a href=\"https://www.techdirt.com/2022/11/10/houston-pd-drops-cases-tainted-by-corrupt-narcotics-officers-but-decides-it-can-still-keep-seized-cash/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2022/11/10/houston-pd-drops-cases-tainted-by-corrupt-narcotics-officers-but-decides-it-can-still-keep-seized-cash/\">corrupt drug cops</a>) is sitting on 200  of marijuana it has amassed over the years. And yet, I would wager that no Houston resident has any trouble obtaining this product on short notice.</p><p>The same goes for the rest of the stuff in the warehouse, which apparently (until recently) contained cocaine seized in 1996. As police chief J. Noe Diaz pointed out, the evidence has outlasted the case. The suspect pled guilty, served his time, and was free to go long before the evidence used to convict him was.</p><p>It‚Äôs apparently a nationwide problem, according to some of the forensic experts interviewed by NBC News, <a href=\"https://www.nbcnews.com/news/us-news/rats-are-high-marijuana-stored-infested-new-orleans-police-evidence-ro-rcna143249\" data-type=\"link\" data-id=\"https://www.nbcnews.com/news/us-news/rats-are-high-marijuana-stored-infested-new-orleans-police-evidence-ro-rcna143249\">which carried a story early last year</a> about a similar drug-eating rat problem in New Orleans. </p><p>New rules are being put in place to destroy this evidence more frequently. On one hand, it makes sense to destroy evidence after defendants serve their time in jail. On the other hand, I wouldn‚Äôt get  carried away giving PDs permission to destroy evidence, since that‚Äôs the sort of thing that lends itself to cover-ups and the disappearance of evidence prisoners might use to challenge their convictions ‚Äî a process that can take years, thanks to the justice system‚Äôs reluctance to reconsider its own calls and the byzantine processes convicted people are expected to navigate just to have (a very looooong) shot at having their cases heard. </p><p>But above all that, there‚Äôs the sheer amount of drugs being held in evidence warehouses. If there‚Äôs nearly a half-million pounds of weed just laying around at any given time, it would seem law enforcement isn‚Äôt <a href=\"https://www.techdirt.com/2024/12/27/florida-sheriff-decided-it-might-be-a-good-idea-to-manufacture-crack-and-now-2600-convictions-might-be-vacated/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2024/12/27/florida-sheriff-decided-it-might-be-a-good-idea-to-manufacture-crack-and-now-2600-convictions-might-be-vacated/\">scoring many meaningful wins</a> in the Drug War. At best, it‚Äôs a game of Whack-a-mole that won‚Äôt generate enough tickets to make it worth visiting the merchandise booth at the arcade. At worst, it‚Äôs just cops looking busy, a meaningless waste of time that unfortunately results in people losing years of their lives to a system that not only can‚Äôt fix what‚Äôs broken, but clearly prefers doing the things <a href=\"https://www.techdirt.com/2024/10/03/lapd-raids-medical-lab-for-nonexistent-weed-get-gun-stuck-in-an-mri-machine/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2024/10/03/lapd-raids-medical-lab-for-nonexistent-weed-get-gun-stuck-in-an-mri-machine/\">that don‚Äôt work</a> as often as possible in perpetuity. </p>","contentLength":3327,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Elon Musk‚Äôs AI company, xAI, said to be in talks to raise $10B","url":"https://techcrunch.com/2025/02/14/elon-musks-ai-company-xai-said-to-be-in-talks-to-raise-10b/","date":1739562841,"author":"Kyle Wiggers","guid":41,"unread":true,"content":"<p>Elon Musk‚Äôs AI company, xAI, is said to be in talks to raise $10 billion in a round that would value xAI at $75 billion. Bloomberg reported Friday that xAI is canvassing existing investors, including Sequoia Capital, Andreessen Horowitz, and Valor Equity Partners for the round, which would bring xAI‚Äôs total raised to $22.4 billion, [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":406,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Discovering discovery coding (Friends)","url":"https://changelog.com/friends/80","date":1739562300,"author":"","guid":34,"unread":true,"content":"<p>Fire up a REPL, grab your favorite Stephen King novel, and hold on to the seat of your pants! Jimmy Miller returns to reveal why, at least for some of us, discovery coding is where it‚Äôs at.</p><p><a href=\"https://changelog.com/++\" rel=\"payment\">Changelog++</a> members save 9 minutes on this episode because they made the ads disappear. Join today!</p><ul><li><a href=\"https://temporal.io\">Temporal</a> ‚Äì Build invincible applications. Manage failures, network outages, flaky endpoints, long-running processes and more, ensuring your workflows never fail. Register for <a href=\"https://replay.temporal.io\">Replay in London, March 3-5</a> to break free from the status quo.\n</li><li><a href=\"https://www.augmentcode.com\">Augment Code</a> ‚Äì Developer AI that uses deep understanding of your large codebase and how you build software to deliver personalized code suggestions and insights. Augment provides relevant, contextualized code right in your IDE or Slack. It transforms scattered knowledge into code or answers, eliminating time spent searching docs or interrupting teammates.\n</li><li><a href=\"http://notion.com/practicalai\">Notion</a> ‚Äì Notion is a place where any team can write, plan, organize, and rediscover the joy of play. It‚Äôs a workspace designed not just for making progress, but getting inspired. Notion is for everyone ‚Äî whether you‚Äôre a Fortune 500 company or freelance designer, starting a new startup or a student juggling classes and clubs.\n</li></ul>","contentLength":1226,"flags":null,"enclosureUrl":"https://op3.dev/e/https://cdn.changelog.com/uploads/friends/80/changelog--friends-80.mp3","enclosureMime":"","commentsUrl":null},{"title":"Researcher Captures Contents of ‚ÄòDEI.gov‚Äô Before It Was Hidden Behind a Password","url":"https://www.404media.co/dei-waste-gov-doge-list-behind-password/","date":1739561563,"author":"Samantha Cole","guid":383,"unread":true,"content":"<img src=\"https://www.404media.co/content/images/2025/02/Screenshot-2025-02-14-at-2.25.54-PM.png\" alt=\"Researcher Captures Contents of ‚ÄòDEI.gov‚Äô Before It Was Hidden Behind a Password\"><p>A German researcher captured the contents of the White House‚Äôs ‚ÄúDEI.gov‚Äù during a brief period when it was not password protected.</p><p>The capture shows that the site contains a list of vague, alleged government-funded tasks and their costs, without sources or context, like ‚Äú$1.3 million to Arab and Jewish photographers,\" ‚Äú$1.5 million for ‚Äòart for inclusion of people with disabilities,‚Äô‚Äù and \"$3.4 million for Malaysian drug-fueled gay sex app.‚Äù DEI.gov redirects to waste.gov and is currently inaccessible without a password; Elon Musk told reporters on Tuesday that his Department of Government Efficiency (DOGE) is ‚Äútrying to be as transparent as possible.‚Äù</p><p>‚Å®The researcher is Henrik Sch√∂nemann‚Å©, a historian who started the <a href=\"https://safeguarding-research.discourse.group/?ref=404media.co\"><u>Safeguarding Research &amp; Culture archivalist project</u></a>, <a href=\"https://fedihum.org/@lavaeolus/113998679846185670?ref=404media.co\" rel=\"noreferrer\">posted screenshots on Mastodon</a> showing the contents. Sch√∂nemann‚Å© also shared the specific site scrapes that he was able to capture, which showed the contents of the site. He told 404 Media he set up a change detection app using PikaPods, and is monitoring changes across hundreds of government websites. When the dei.gov and waste.gov sites were registered 10 days ago, he started tracking them, too.&nbsp;</p><p>Before the site administrators added a Wordpress template to the pages, the list was online at those URLs. This list was only online for a maximum of 30 minutes, starting around 4:50 p.m. EST; by 5:23 p.m. on February 11, it was gone from public view, according to the snapshots Sch√∂nemann‚Äôs app‚Å© captured.&nbsp;</p><p>According to the screenshots provided by Sch√∂nemann‚Å©, the list includes (all of the following are direct quotes):&nbsp;</p><ul><li>$78,000 to Palestinian activist group whose chairman was photographed attending an anniversary event celebrating the founding of the Popular Front for the Liberation of the Palestine terrorist group</li><li>$1 Million for foreign DEI programs, including ‚Äòindigenous language technology‚Äô in Guatemala, per non-public funding docs reviewed by WFB</li><li>$5 million for effort to treat eating disorders by ‚Äúaffirming‚Äù LGBTQIA+ patients‚Äô sexual orientation and gender claims</li><li>Up to $3 million to defund the police advocacy group to pursue ‚Äúclimate justice‚Äù for convicts</li><li>Funded performances of play ‚ÄúAngels in America: A Gay Fantasia on National Themes,‚Äù in which God is bisexual and communists are good, in North Macedonia</li><li>Disbursed $15,000 to ‚Äúqueer‚Äù Muslim writers in India</li><li>Shelled out tens of thousands to create army of 2,500 LGBTQI+ allies</li><li>Up to $10 million worth of USAID-funded meals went to al Qaeda-linked terrorist group the Nusra Front</li><li>$500,000 to group that ‚Äúempowers women‚Äù in attempt to solve sectarian violence in Israel just ten days before Hamas‚Äô Oct. 7 attacks</li><li>$4.67 million to EcoHealth Alliance ‚Äì one of the key NGOs funding bat virus research at Wuhan Institute of Virology ‚Äî in late 2021. Later refused to answer key questions about the funding.</li><li>$7.9 million to a project that would teach Sri Lankan journalists to avoid ‚Äúbinary-gendered language‚Äù</li><li>$1.3 million to Arab and Jewish photographers</li><li>$1.5 million for ‚Äúart for inclusion of people with disabilities‚Äù</li><li>$2 million to promote ‚ÄúLGBT equality through entrepreneurship‚Ä¶in developing Latin American countries.‚Äù</li><li>Education Week: ‚ÄúBiden Administration Cites 1619 Project as Inspiration in History Grant Proposal‚Äù</li><li>VA took at least a dozen actions aimed at bolstering DEI during the Biden-Harris administration while the number of homeless veterans increased and the amount of claims in the VA‚Äôs backlog grew from ~211,000 to ~378,000</li><li>NASA has allocated roughly $10 million to grants advancing DEI and ‚Äúenvironmental justice‚Äù since 2020</li><li>Following President Trump‚Äôs executive order on DEI at federal agencies, the ATF ‚Äúquietly changing the job title of its former diversity officer‚Ä¶ to ‚Äòsenior executive‚Äô with the ATF.</li><li>The Department of Labor requested additional funding in 2023 for ‚ÄúThe Chief Evaluation Office for a new rigorous interagency evaluation of actions aimed at improving Diversity, Equity, Inclusivity, and Accessibility across the federal workforce,‚Äù more than $6.5 million ‚Äúto restore employee benefits programs that will advance equity by specifically addressing how opportunities can be expanded for underserved communities and vulnerable populations,‚Äù and $5 million ‚Äúto evaluate actions aimed at improving diversity, equity, inclusion, and accessibility (DEIA) within the federal workforce.‚Äù</li><li>Fox Business: ‚ÄúFOX Business‚Äô ‚ÄòTrouble in the Skies,‚Äô a six month investigation of the FAA‚Äôs new hiring practices, uncovered changes that may put the nation‚Äôs flying public at risk as well as allegations that the newest air traffic control recruits had access to answers on a key test that helped them gain jobs with the FAA‚Ä¶Also uncovered was an FAA effort to promote diversity that discarded 3000 qualified college graduates with degrees in air traffic control despite their following FAA procedure and obtaining FAA accredited degrees.‚Äù</li></ul><p>Sch√∂nemann‚Å© told 404 Media he wanted to share a sentiment alongside his find: ‚ÄúPeople all around the world care, you are not alone. And: #TransRights.‚Äù </p><p>Earlier this week, we reported that the Trump administration had set up a website called waste.gov, which was live on the internet with a sample page from a default WordPress template. Both DEI.gov and waste.gov were created at the same time, according to Reuters, and <a href=\"http://dei.gov/?ref=404media.co\"><u>DEI.gov was recently set up to redirect to waste.gov</u></a>. After our reporting, both websites were put behind a password wall.</p>","contentLength":5563,"flags":null,"enclosureUrl":"https://www.404media.co/content/images/2025/02/Screenshot-2025-02-14-at-2.25.54-PM.png","enclosureMime":"","commentsUrl":null},{"title":"Meta‚Äôs next big bet may be humanoid robotics","url":"https://techcrunch.com/2025/02/14/metas-next-big-bet-may-be-humanoid-robotics/","date":1739560571,"author":"Kyle Wiggers","guid":40,"unread":true,"content":"<p>Meta is forming a new team within its Reality Labs hardware division to build robots that can assist with physical tasks, Bloomberg reported. The team will be responsible for developing humanoid robotics hardware, potentially including hardware that can perform household chores. Meta‚Äôs new robotics group, which will be led by Marc Whitten, driverless car startup [‚Ä¶]</p><p>¬© 2024 TechCrunch. All rights reserved. For personal use only.</p>","contentLength":435,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":[]}