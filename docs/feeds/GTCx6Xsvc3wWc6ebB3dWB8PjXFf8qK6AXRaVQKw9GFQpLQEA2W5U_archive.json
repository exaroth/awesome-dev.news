{"id":"GTCx6Xsvc3wWc6ebB3dWB8PjXFf8qK6AXRaVQKw9GFQpLQEA2W5U","title":"Google Developers Blog","displayTitle":"Google Developers","url":"https://developers.googleblog.com/rss/","feedLink":"https://developers.googleblog.com/rss/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":22,"items":[{"title":"Level Up Your Dev Game: The Jules API is Here!","url":"https://developers.googleblog.com/en/level-up-your-dev-game-the-jules-api-is-here/","date":1761937513,"author":"","guid":323697,"unread":true,"content":"<article>Google has released the Jules API, a new tool for developers to automate and integrate the software development lifecycle. The API is based on \"Source,\" \"Session,\" and \"Activity\" concepts, and Google has provided a quickstart guide to help developers begin using it.</article>","contentLength":266,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Your AI is now a local expert: Grounding with Google Maps is now GA","url":"https://developers.googleblog.com/en/your-ai-is-now-a-local-expert-grounding-with-google-maps-is-now-ga/","date":1761916423,"author":"","guid":323539,"unread":true,"content":"<article>Grounding with Google Maps in Vertex AI is now generally available, helping developers build factual and reliable generative AI applications connected to real-world, up-to-date information from Google Maps. This unlocks better, more personal results and is useful across industries like travel, real estate, devices, and social media.</article>","contentLength":334,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apigee Operator for Kubernetes and GKE Inference Gateway integration for Auth and AI/LLM policies","url":"https://developers.googleblog.com/en/apigee-operator-for-kubernetes-and-gke-inference-gateway-integration-for-auth-and-aillm-policies/","date":1761912569,"author":"","guid":323500,"unread":true,"content":"<article>The GKE Inference Gateway now integrates with Apigee, allowing enterprises to unify AI serving and API governance. This enables GKE users to leverage Apigee's API management, security, and monetization features for their AI workloads, including API keys, quotas, rate limiting, and Model Armor security.</article>","contentLength":303,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Delight users by combining ADK Agents with Fancy Frontends using AG-UI","url":"https://developers.googleblog.com/en/delight-users-by-combining-adk-agents-with-fancy-frontends-using-ag-ui/","date":1761912569,"author":"","guid":323501,"unread":true,"content":"<article>The ADK and AG-UI integration enables developers to build interactive AI applications by combining a powerful backend (ADK) with a flexible frontend protocol (AG-UI). This unlocks features like Generative UI, Shared State, Human-in-the-Loop, and Frontend Tools, allowing for seamless collaboration between AI and human users.</article>","contentLength":325,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Continuing to bring you our latest models, with an improved Gemini 2.5 Flash and Flash-Lite release","url":"https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/","date":1761858336,"author":"","guid":322334,"unread":true,"content":"<article>Google is releasing updated Gemini 2.5 Flash and Flash-Lite preview models with improved quality, speed, and efficiency. These releases introduce a \"-latest\" alias for easy access to the newest versions, allowing developers to test and provide feedback to shape future stable releases.</article>","contentLength":285,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meet Jules Tools: A Command Line Companion for Google’s Async Coding Agent","url":"https://developers.googleblog.com/en/meet-jules-tools-a-command-line-companion-for-googles-async-coding-agent/","date":1761858336,"author":"","guid":322335,"unread":true,"content":"<article>You can now work with Jules directly in your command line. Jules is our asynchronous coding agent th...</article>","contentLength":103,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building the Next Generation of Physical Agents with Gemini Robotics-ER 1.5","url":"https://developers.googleblog.com/en/building-the-next-generation-of-physical-agents-with-gemini-robotics-er-15/","date":1761854780,"author":"","guid":322323,"unread":true,"content":"<article>Gemini Robotics-ER 1.5, now available to developers, is a state-of-the-art embodied reasoning model for robots. It excels in visual, spatial understanding, task planning, and progress estimation, allowing robots to perform complex, multi-step tasks.</article>","contentLength":249,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gemini 2.5 Flash Image now ready for production with new aspect ratios","url":"https://developers.googleblog.com/en/gemini-2-5-flash-image-now-ready-for-production-with-new-aspect-ratios/","date":1761851106,"author":"","guid":322301,"unread":true,"content":"<article>Our state-of-the-art image generation and editing model which has captured the imagination of the wo...</article>","contentLength":103,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Beyond Request-Response: Architecting Real-time Bidirectional Streaming Multi-agent System","url":"https://developers.googleblog.com/en/beyond-request-response-architecting-real-time-bidirectional-streaming-multi-agent-system/","date":1761840406,"author":"","guid":322212,"unread":true,"content":"<article>The blog post argues the request-response model fails for advanced multi-agent AI. It advocates for a real-time bidirectional streaming architecture, implemented by the Agent Development Kit (ADK). This streaming model enables true concurrency, natural interruptibility, and unified multimodal processing. ADK's core features are real-time I/O management, stateful sessions for agent handoffs, and streaming-native tools.</article>","contentLength":421,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Unlocking Multi-Spectral Data with Gemini","url":"https://developers.googleblog.com/en/unlocking-multi-spectral-data-with-gemini/","date":1761783671,"author":"","guid":321012,"unread":true,"content":"<article>Multi-spectral imagery, which captures wavelengths beyond human vision, offers a \"superhuman\" way to understand the world, and Google's Gemini models make this accessible without specialized training. By mapping invisible bands to RGB channels and providing context in the prompt, developers can leverage Gemini's power for tasks like environmental monitoring and agriculture.</article>","contentLength":376,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Own your AI: Learn how to fine-tune Gemma 3 270M and run it on-device","url":"https://developers.googleblog.com/en/own-your-ai-fine-tune-gemma-3-270m-for-on-device/","date":1761783671,"author":"","guid":321013,"unread":true,"content":"<article>This guide shows you how to fine-tune the Gemma 3 270M model for custom tasks, like an emoji translator. Learn to quantize and convert the model for on-device use, deploying it in a web app with MediaPipe or Transformers.js for a fast, private, and offline-capable user experience.</article>","contentLength":281,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing the Data Commons Model Context Protocol (MCP) Server: Streamlining Public Data Access for AI Developers","url":"https://developers.googleblog.com/en/datacommonsmcp/","date":1761779180,"author":"","guid":320991,"unread":true,"content":"<article>Data Commons announces the availability of its MCP Server, which is a major milestone in making all of Data Commons’ vast public datasets instantly accessible and actionable for AI developers worldwide.</article>","contentLength":204,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing Veo 3.1 and new creative capabilities in the Gemini API","url":"https://developers.googleblog.com/en/introducing-veo-3-1-and-new-creative-capabilities-in-the-gemini-api/","date":1761757675,"author":"","guid":320838,"unread":true,"content":"<article>Google is releasing Veo 3.1 and Veo 3.1 Fast, an updated video generation model, in paid preview via the Gemini API. This version offers richer native audio, greater narrative control, and enhanced image-to-video capabilities. New features include guiding generation with reference images, extending existing Veo videos, and generating transitions between frames. Companies like Promise Studios, Latitude, and Whering are already using Veo 3.1 for various applications.</article>","contentLength":469,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Say hello to a new level of interactivity in Gemini CLI","url":"https://developers.googleblog.com/en/say-hello-to-a-new-level-of-interactivity-in-gemini-cli/","date":1761757675,"author":"","guid":320839,"unread":true,"content":"<article>We're excited to announce an enhancement to Gemini CLI that makes your workflow more powerful a...</article>","contentLength":98,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing the Jules extension for Gemini CLI","url":"https://developers.googleblog.com/en/introducing-the-jules-extension-for-gemini-cli/","date":1761757675,"author":"","guid":320840,"unread":true,"content":"<article>Introducing the Jules extension for Gemini CLI, an autonomous sidekick for developers. It accelerates coding workflows by offloading tasks like asynchronous work, bug fixes, and changes in new branches to Jules, while you stay in flow with Gemini CLI. Get started by installing the extension and using the /jules command to initiate and check task statuses.</article>","contentLength":357,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Announcing the Genkit Extension for Gemini CLI","url":"https://developers.googleblog.com/en/announcing-the-genkit-extension-for-gemini-cli/","date":1761750411,"author":"","guid":320753,"unread":true,"content":"<article>The new Genkit Extension for Gemini CLI gives the command line deep knowledge of Genkit's architecture. It helps you build, debug, and iterate on AI apps with intelligent code generation, context-aware assistance, and tools to run flows and analyze traces directly from your terminal.</article>","contentLength":284,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google Colab Adds More Back to School Improvements!","url":"https://developers.googleblog.com/en/google-colab-adds-more-back-to-school-improvements/","date":1761746833,"author":"","guid":320734,"unread":true,"content":"<article>The new Colab features simplify and enhance notebook-based class materials. Instructors can now freeze runtime versions, and seamlessly present and copy notebooks. This improves reproducibility, stability, and shareability, making Colab ideal for researchers, educators, and developers. Slideshow mode and URL linking are also enhanced.</article>","contentLength":336,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gemini for Home: Expanding the Platform for a New Era of Smart Home AI","url":"https://developers.googleblog.com/en/gemini-for-home-expanding-the-platform-for-a-new-era-of-smart-home-ai/","date":1761728773,"author":"","guid":320577,"unread":true,"content":"<article>Google Home is enabling new Gemini-powered features for our partners’ devices and launching a new program to help them build the next generation of AI cameras.</article>","contentLength":161,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing Coral NPU: A full-stack platform for Edge AI","url":"https://developers.googleblog.com/en/introducing-coral-npu-a-full-stack-platform-for-edge-ai/","date":1761725261,"author":"","guid":320555,"unread":true,"content":"<article>Coral NPU is a full-stack platform for Edge AI, addressing performance, fragmentation, and user trust deficits. It's an AI-first architecture, prioritizing ML matrix engines, and offers a unified developer experience. Designed for ultra-low-power, always-on AI in wearables and IoT, it enables contextual awareness, audio/image processing, and user interaction with hardware-enforced privacy. Synaptics is the first partner to implement Coral NPU.</article>","contentLength":447,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building High-Performance Data Pipelines with Grain and ArrayRecord","url":"https://developers.googleblog.com/en/building-high-performance-data-pipelines-with-grain-and-arrayrecord/","date":1761653340,"author":"","guid":319116,"unread":true,"content":"<article>To avoid data bottlenecks when training large models, this guide introduces Grain and ArrayRecord for building high-performance data pipelines.</article>","contentLength":143,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing Tunix: A JAX-Native Library for LLM Post-Training","url":"https://developers.googleblog.com/en/introducing-tunix-a-jax-native-library-for-llm-post-training/","date":1761645988,"author":"","guid":319066,"unread":true,"content":"<article>Tunix is a new JAX-native, open-source library for LLM post-training. It offers comprehensive tools for aligning models at scale, including SFT, preference tuning (DPO), advanced RL methods (PPO, GRPO, GSPO), and knowledge distillation. Designed for TPUs and seamless JAX integration, Tunix emphasizes developer control and shows a 12% relative improvement in pass@1 accuracy on GSM8K.</article>","contentLength":385,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gemma explained: EmbeddingGemma Architecture and Recipe","url":"https://developers.googleblog.com/en/gemma-explained-embeddinggemma-architecture-and-recipe/","date":1761570893,"author":"","guid":316785,"unread":true,"content":"<article>EmbeddingGemma, built from Gemma 3, transforms text into numerical embeddings for tasks like search and retrieval. It learns through Noise-Contrastive Estimation, Global Orthogonal Regularizer, and Geometric Embedding Distillation. Matryoshka Representation Learning allows flexible embedding dimensions. The development recipe includes encoder-decoder training, pre-fine-tuning, fine-tuning, model souping, and quantization-aware training.</article>","contentLength":440,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["googledev"]}