{"id":"f33v1Y5Z","title":"Latest","displayTitle":"Latest","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":897,"items":[{"title":"Google rolls out its new Veo 3 video generation model globally","url":"https://techcrunch.com/2025/07/03/google-rolls-out-its-new-veo-3-video-generation-model-globally/","date":1751540208,"author":"Ivan Mehta","guid":183003,"unread":true,"content":"<article>Google on Thursday said it has begun rolling out its Veo 3 video generation model to Gemini users in more than 159 countries. </article>","contentLength":126,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Linux 6.17 To Finish Clearing Out Old Code For OpenMoko Devices","url":"https://www.phoronix.com/news/Linux-6.17-Dropping-OpenMoko-In","date":1751539924,"author":"Michael Larabel","guid":183026,"unread":true,"content":"<article>Linux 6.17 is expected to clear out some final remnants of the OpenMoko Neo 1973 and Neo FreeRunner smartphone support from that Linux smartphone effort from two decades ago...</article>","contentLength":176,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lenovo Legion Go S HID Driver Posted For Linux","url":"https://www.phoronix.com/news/Lenovo-Legion-Go-S-HID","date":1751538600,"author":"Michael Larabel","guid":183025,"unread":true,"content":"<article>The Linux support for the Lenovo Legion Go S gaming handheld continues to be improved upon thanks to the option of having Steam OS on this alternative to the Steam Deck...</article>","contentLength":171,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Improved TTM Memory Management Eviction Submitted Ahead Of Linux 6.17","url":"https://www.phoronix.com/news/Linux-6.17-TTM-Eviction","date":1751537557,"author":"Michael Larabel","guid":183024,"unread":true,"content":"<article>Sent out today was the newest drm-misc-next pull request of changes built up over the past week for DRM-Next ahead of the Linux 6.17 kernel cycle. The drm-misc-next material is the usual random assortment of DRM display/graphics driver changes and core improvements, which this week includes some TTM eviction work...</article>","contentLength":317,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Podcast: The Life Changing Power of Lifting","url":"https://www.404media.co/404-media-podcast-casey-johnston/","date":1751536849,"author":"Jason Koebler","guid":182959,"unread":true,"content":"<img src=\"https://www.404media.co/content/images/2025/06/casey-jason.png\" alt=\"Podcast: The Life Changing Power of Lifting\"><p>For this week’s podcast, I’m talking to our friend Casey Johnston, a tech journalist turned fitness journalist turned independent journalist. Casey studied physics, which led her to tech journalism; she did some of my favorite coverage of Internet culture as well as Apple’s horrendous butterfly laptop keyboards. We worked together at VICE, where Casey was an editor and where she wrote Ask a Swole Woman, an advice column about weightlifting. After she left VICE, Casey <a href=\"https://www.shesabeast.co/?ref=404media.co\"></a>, an independent site about weightlifting, but also about the science of diet culture, fitness influencers on the internet, the intersections of all those things, etc.&nbsp;</p><p>She just wrote <a href=\"https://www.caseyjohnston.website/my-work/a-physical-education?ref=404media.co\"><u>A Physical Education: How I Escaped Diet Culture and Gained the Power of Lifting</u></a>, a really great reported memoir about how our culture and the media often discourages people from lifting, and how this type of exercise can be really beneficial to your brain and your body. I found the book really inspiring and actually started lifting right after I read it. In this interview we talk about her book, about journalism, about independent media, and how doing things like lifting weights and touching grass helps us navigate the world. </p><p>Listen to the weekly podcast on&nbsp;<a href=\"https://podcasts.apple.com/us/podcast/the-404-media-podcast/id1703615331?ref=404media.co\" rel=\"noreferrer noopener\"></a><a href=\"https://open.spotify.com/show/0F3oY47l2XgoBMaAmIaw29?ref=404media.co\" rel=\"noreferrer noopener\"></a>, or&nbsp;<a href=\"https://www.youtube.com/@404Mediaco/videos?ref=404media.co\" rel=\"noreferrer noopener\">YouTube</a>. Become a paid subscriber for access to this episode's bonus content and to power our journalism.&nbsp;<strong>If you become a paid subscriber, check your inbox for an email from our podcast host Transistor for a link to the subscribers-only version! You can also add that subscribers feed to your podcast app of choice and never miss an episode that way. The email should also contain the subscribers-only unlisted YouTube link for the extended video version too. It will also be in the show notes in your podcast player. </strong></p>","contentLength":1753,"flags":null,"enclosureUrl":"https://www.404media.co/content/images/2025/06/casey-jason.png","enclosureMime":"","commentsUrl":null},{"title":"New Evidence That Some Supernovae May Be a 'Double Detonation'","url":"https://science.slashdot.org/story/25/07/03/0051240/new-evidence-that-some-supernovae-may-be-a-double-detonation?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751536800,"author":"BeauHD","guid":183032,"unread":true,"content":"New evidence from a 300-year-old supernova remnant in the Large Magellanic Cloud suggests that some Type Ia supernovae may result from a \"double detonation\" -- where a helium shell ignites first, triggering a second core explosion in a white dwarf before it reaches critical mass. \"While the physics of the process itself are interesting, the key question this raises is whether type Ia supernovae really are all equally bright,\" writes Ars Technica's John Timmer. \"If they can detonate with substantially less mass than is needed for direct ignition of the core, then it's possible that some of them could be considerably less bright.\" However, the research team notes that additional factors -- such as the influence of binary systems or secondary detonations -- could further complicate the picture. Ars Technica reports: \"The detonations in the carbon-oxygen core and the helium-rich shell result in qualitatively different yield products,\" the researchers behind the new work write in a paper describing it. In the paper, they focus on calcium, which there are two ways of producing. One is from the outer shell of helium, via fusion before the detonation dilutes the material. A second batch of calcium is produced through the fusion of the core material as it's ejected in the supernova, which prevents further fusion events from converting it to even heavier elements. (Material deeper in the core does end up getting fused into heavier material.) Because it's produced by both of the detonations, models predict that the expanding sphere of debris will contain two different shells of calcium, with some space in between them. To find evidence for these shells, the researchers checked an older supernova remnant, which allows enough time for the movement of material to separate the shells by enough distance that they can be resolved from Earth.\n \nThey focused their observations on a supernova remnant named SNR 0509-67.5, located in the nearby Large Magellanic Cloud. SNR 0509-67.5 is estimated to be a bit over 300 years old, meaning material has had enough time to move a significant distance away from the site of the explosion. Imaging using a spectrograph on the Very Large Telescope allowed them to resolve what, in effect, was a spherical sulfur sandwich, with the role of the bread played by calcium. In other words, if you were to travel away from the site of the explosion, you would first hit a layer of ionized calcium, followed by ionized sulfur, and then run into a second layer of ionized calcium. This is exactly what computer models that simulate double detonations predict. So, the researchers suggest it is strong support for that hypothesis. The researchers say that the details suggest that SNR 0509-67.5 was a white dwarf with roughly the same mass as the Sun when it exploded, and that its explosion was likely triggered by the detonation of a helium shell with only three percent of the Sun's mass.","contentLength":2935,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Libreboot 25.06 Released With Support For Two More Outdated Systems","url":"https://www.phoronix.com/news/Libreboot-25.06-Released","date":1751536522,"author":"Michael Larabel","guid":182949,"unread":true,"content":"<article>Libreboot 25.06 released this week as the newest version of this Coreboot downstream focused on shipping only with free and open-source components. But due to the strict open-source nature of Libreboot, it continues to primarily see support for long outdated platforms...</article>","contentLength":271,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI at Anaconda with Greg Jennings","url":"https://softwareengineeringdaily.com/2025/07/03/ai-at-anaconda-with-greg-jennings/?utm_source=rss&utm_medium=rss&utm_campaign=ai-at-anaconda-with-greg-jennings","date":1751533229,"author":"SEDaily","guid":182887,"unread":true,"content":"<div><p><a href=\"https://www.anaconda.com/\">Anaconda</a> is a software company that’s well-known for its solutions for managing packages, environments, and security in large-scale data workflows. The company has played a major role in making Python-based data science more accessible, efficient, and scalable. Anaconda has also invested heavily in AI tool development.</p></div><div><p><a href=\"https://x.com/jenningsgreg\">Greg Jennings</a> is the VP of Engineering and AI at Anaconda. He joins the podcast with Kevin Ball to talk about the tooling ecosystem around AI app development, the Anaconda Toolbox, the rapidly evolving role of AI in engineering, and more.</p><div><p><a href=\"https://www.kball.llc/\">Kevin Ball</a> or KBall, is the vice president of engineering at Mento and an independent coach for engineers and engineering leaders. He co-founded and served as CTO for two companies, founded the San Diego JavaScript meetup, and organizes the AI inaction discussion group through Latent Space.</p></div></div>","contentLength":851,"flags":null,"enclosureUrl":"https://traffic.megaphone.fm/SED5262493748.mp3","enclosureMime":"","commentsUrl":null},{"title":"A New 'Interstellar Visitor' Has Entered the Solar System","url":"https://science.slashdot.org/story/25/07/03/0041226/a-new-interstellar-visitor-has-entered-the-solar-system?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751526000,"author":"BeauHD","guid":182736,"unread":true,"content":"Astronomers have detected a mysterious \"interstellar object,\" dubbed A11pl3Z, speeding through the solar system at 152,000 mph. If confirmed, it would be just the third known interstellar visitor, following 'Oumuamua and Comet Borisov. The visiting space object will pass near Mars and the Sun later this year before leaving the solar system forever. Live Science reports: The newly discovered object, currently dubbed A11pl3Z, was first spotted in data collected between June 25 and June 29 by the Asteroid Terrestrial-impact Last Alert System (ATLAS), which automatically scans the night sky using telescopes in Hawaii and South Africa. The mystery object was confirmed by both NASA's Center for Near Earth Object Studies and the International Astronomical Union's Minor Planet Center on Tuesday (July 1), according to EarthSky.org.\n \nA11pl3Z is most likely a large asteroid, or maybe a comet, potentially spanning up to 12 miles (20 kilometers). It is traveling toward the inner solar system at around 152,000 mph (245,000 km/h) and is approaching us from the part of the night sky where the bar of the Milky Way is located. Based on A11pl3Z's speed and trajectory, experts think it originated from beyond the sun's gravitational influence and has enough momentum to shoot straight through our cosmic neighborhood without slowing down. However, more observations are needed to tell for sure.","contentLength":1394,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I scanned all of GitHub's \"oops commits\" for leaked secrets","url":"https://trufflesecurity.com/blog/guest-post-how-i-scanned-all-of-github-s-oops-commits-for-leaked-secrets","date":1751525059,"author":"elza_1111","guid":182819,"unread":true,"content":"<ol><li data-preset-tag=\"p\"><p>GitHub Archive logs every public commit, even the ones developers try to delete. Force pushes often cover up mistakes like leaked credentials by rewriting Git history. GitHub keeps these dangling commits, from what we can tell, forever. In the archive, they show up as “zero-commit” .&nbsp;</p></li><li data-preset-tag=\"p\"><p>I scanned every force push event since 2020 and uncovered secrets worth .&nbsp;</p></li><li data-preset-tag=\"p\"><p>Together with Truffle Security, we're open sourcing a new tool to scan your own GitHub organization for these hidden commits (<a href=\"https://github.com/trufflesecurity/force-push-scanner\" target=\"_blank\" rel=\"noopener\">try it here</a>).</p></li></ol><p><a href=\"https://github.com/trufflesecurity/force-push-scanner\" target=\"_blank\" rel=\"noopener\"></a><em><strong>tool identifies secrets in dangling commits.</strong></em></p><p><em>This guest post by Sharon Brizinov, a white-hat hacker, was developed through </em><a href=\"https://trufflesecurity.com/cfp\" rel=\"noopener\"><em>Truffle Security’s Research CFP program</em></a><em>. We first connected with Sharon after his widely shared write-up, </em><a href=\"https://medium.com/@sharon.brizinov/how-i-made-64k-from-deleted-files-a-bug-bounty-story-c5bd3a6f5f9b\" rel=\"noopener\"><em>How I Made 64k From Deleted Files</em></a><em>, where he used TruffleHog to uncover high-value secrets in public GitHub repositories. In this follow-up, Sharon expanded his research to access 100% of deleted commits on GitHub. He takes a deeper dive into one of our favorite areas: secrets hidden in deleted GitHub commits.</em></p><ul><li data-preset-tag=\"p\"><p>What Does it Mean to Delete a Commit?</p></li><li data-preset-tag=\"p\"><p>Finding all Deleted Commits</p></li><li data-preset-tag=\"p\"><p>Hunting for Impactful Secrets</p></li><li data-preset-tag=\"p\"><p>Case Study - Preventing a Massive Supply-Chain Compromise</p></li></ul><p>My name is <a href=\"https://www.linkedin.com/in/sharonbrizinov/\" rel=\"noopener\">Sharon Brizinov</a>, and while I usually focus on low-level vulnerability and exploitation research in OT/IoT devices, I occasionally dive into bug bounty hunting.</p><p>I recently published a <a href=\"https://medium.com/@sharon.brizinov/how-i-made-64k-from-deleted-files-a-bug-bounty-story-c5bd3a6f5f9b\" rel=\"noopener\">blog post</a> about uncovering secrets hidden in dangling blobs within GitHub repositories, which sparked quite a lively discussion. After the post, I had several conversations with various people including Dylan, the CEO of Truffle Security, who gave me some intriguing ideas for continuing to explore new methods for large-scale secret hunting. I decided to create a mind map with everything I know related to this topic and try to come up with a new idea.&nbsp;</p><p>I’ll spare you my messy sketch, but here’s a roundup of the projects, blogs, ideas, and resources I zeroed in on (highly recommended):</p><ul><li data-preset-tag=\"p\"><p><a href=\"https://neodyme.io/en/blog/github_secrets/\" rel=\"noopener\">Hidden GitHub Commits and How to Reveal Them by Neodyme.io</a></p></li><li data-preset-tag=\"p\"><p><a href=\"https://trufflesecurity.com/blog/anyone-can-access-deleted-and-private-repo-data-github\" rel=\"noopener\">Anyone can Access Deleted and Private Repository Data on GitHub by TruffleHog</a></p></li><li data-preset-tag=\"p\"><p><a href=\"https://trufflesecurity.com/blog/trufflehog-now-finds-all-deleted-and-private-commits-on-github\" rel=\"noopener\">TruffleHog now finds all Deleted &amp; Private Commits on GitHub by TruffleHog</a></p></li><li data-preset-tag=\"p\"><p><a href=\"https://trufflesecurity.com/blog/trufflehog-scans-deleted-git-branches\" rel=\"noopener\">TruffleHog Scans Deleted Git Branches by TruffleHog</a></p></li><li data-preset-tag=\"p\"><p><a href=\"https://www.aquasec.com/blog/undetected-hard-code-secrets-expose-corporations/\" rel=\"noopener\">Phantom Secrets: Undetected Secrets Expose Major Corporations by Aqua Security</a></p></li></ul><p>Eventually, I came up with a simple idea - I will use the Github Event API alongside the <a href=\"https://www.gharchive.org/\" rel=\"noopener\">GitHub Archive</a> project to scan all Zero-Commit Push-Events (deleted commits) for secrets. Everything was known, I just glued it together and built automation at scale that hunted for secrets.</p><p>In this blog, I will describe my journey from understanding why you can never really delete a commit in GitHub to how to find all of them and build automation around it.</p><h2>What Does it Mean to Delete a Commit?</h2><p>In my previous <a href=\"https://medium.com/@sharon.brizinov/how-i-made-64k-from-deleted-files-a-bug-bounty-story-c5bd3a6f5f9b\" rel=\"noopener\">blog post</a>, I discussed how I discovered supposedly deleted files within GitHub repositories. Specifically, I was able to reconstruct dangling blobs - objects that had been deleted and were no longer referenced by any commit or tree… Or so I thought. After chatting with the Truffle folks, it turns out these orphaned blobs actually had orphaned commits that went along with them. And with a little research, I was able to uncover 100% of those orphaned commits at scale, across all of GitHub.&nbsp;</p><p>Suppose you’ve accidentally committed and pushed a secret to your repository. What’s the next step? Typically, you’d want to reset the HEAD to the previous commit and force-push the changes, effectively removing the current commit and making it unreferenced - essentially deleting it. Here’s how you do it:</p><p>But as <a href=\"https://neodyme.io/en/blog/github_secrets/\" target=\"_blank\" rel=\"noopener\">neodyme </a>and <a href=\"https://trufflesecurity.com/blog/anyone-can-access-deleted-and-private-repo-data-github\" target=\"_blank\" rel=\"noopener\">TruffleHog</a> discovered, even when a commit is deleted from a repository, GitHub never forgets. If you know the full commit hash, you can access the supposedly deleted content. Moreover, you don't even need the full commit has, as TruffleHog <a href=\"https://trufflesecurity.com/blog/trufflehog-now-finds-all-deleted-and-private-commits-on-github\" target=\"_blank\" rel=\"noopener\">discovered </a>- it's enough to brute-force just the first four hex-digits.</p><h3>Force Pushing: A Tutorial</h3><p>Let’s see this in action using my own repository: <a href=\"https://github.com/SharonBrizinov/test-oops-commit\" rel=\"noopener\">test-oops-commit</a>. Try to locate the deleted commit - <a href=\"https://github.com/SharonBrizinov/test-oops-commit/commit/9eedfa00983b7269a75d76ec5e008565c2eff2ef\" rel=\"noopener\">9eedfa00983b7269a75d76ec5e008565c2eff2ef</a>.&nbsp;</p><p>To help visualize our commits, I prepared a simple bash script that shows the <a href=\"https://git-scm.com/book/en/v2/Git-Internals-Git-Objects\" target=\"_blank\" rel=\"noopener\">commit-tree-blob</a> objects, :</p><div><div><div><div><div><div><pre translate=\"no\"><code>- -- | - - | - -</code></pre></div></div></div></div></div></div><p>We start by creating a simple repository with a single commit (a  file):</p><p>Next, we create a new file named  containing our secret . We accidentally commit and push our secret to GitHub.</p><p>We look at the commit tree to see that we have a new commit … which is associated with a new tree and a new blob for the file . We see the same when we run , , or when we access it from the web on GitHub.</p><p>Oops! We discover our mistake and delete the commit by moving the HEAD of the branch to the previous commit and force-push it using:</p><p>Let's remove our local version of the repo, clone the repository again, and check the commit tree. Phew, no secrets; the commit was really deleted!</p><p>But we remember the commit hash, we we check online on GitHub and the commit can still be accessed - <a href=\"https://github.com/SharonBrizinov/test-oops-commit/commit/9eedfa00983b7269a75d76ec5e008565c2eff2ef\" rel=\"noopener\">9eedfa00983b7269a75d76ec5e008565c2eff</a> (even accessing using four hex digits is enough <a href=\"https://github.com/SharonBrizinov/test-oops-commit/commit/9eed\" target=\"_blank\" rel=\"noopener\">9eef</a>). However, this time we get a message saying that the commit is deleted or doesn't belong to any branch on this repository. </p><p>When you force-push after resetting (aka  followed by ), you remove Git’s reference to that commit from your branch, effectively making it unreachable through normal Git navigation (like ). However, the commit is still accessible on GitHub because GitHub stores these reflogs.&nbsp;</p><p>Why? I don’t know for sure, but GitHub does <a href=\"https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/what-happens-to-forks-when-a-repository-is-deleted-or-changes-visibility\" rel=\"noopener\">give some hints</a>. As I see it, GitHub is a much more complex beast than just a git server. It has many layers, including pull-requests, forks, private-public settings, and more.&nbsp;</p><p>My guess is that to support all of these features, GitHub stores all commits and never deletes them. Here are some cases to consider:</p><ol><li data-preset-tag=\"p\"><p>What are pull requests? These are just temporary branches, as <a href=\"https://www.aquasec.com/blog/undetected-hard-code-secrets-expose-corporations/\" rel=\"noopener\">Aqua Security</a> wrote about, and can be retrieved by fetching all refs using -</p><ol><li data-preset-tag=\"p\"><p><code>git -c \"remote.origin.fetch=+refs/*:refs/remotes/origin/*\" fetch origin</code></p></li></ol></li><li data-preset-tag=\"p\"><p>How does the GitHub fork network work? What happens when you “fork” a repository? All the data is replicated, including commits you might delete.</p></li></ol><p>For these cases, and probably many others too (auditing? monitoring?) Github stores all the commits and won’t delete them, even if you force-push the head and “delete” the commit.</p><p>OK, so commits are not really deleted. Fine. But you’d still need to know the full commit hash, or at least the first four hex-digits ignoring collisions (). As it turns out, TruffleHog <a href=\"https://trufflesecurity.com/blog/trufflehog-now-finds-all-deleted-and-private-commits-on-github\" rel=\"noopener\">has a tool </a>to do just that, but it’s very slow, as you can imagine, going through all those. It doesn’t scale well beyond taking a day or two on a single repo.</p><p>But there’s another way. A faster way, I’m now happy to share with you. The GitHub Event API is part of GitHub's REST API, which allows users to retrieve information about events that occur within GitHub. Events represent various activities in GitHub, such as:</p><ul><li data-preset-tag=\"p\"><p>Opening or closing issues or pull requests</p></li></ul><ul><li data-preset-tag=\"p\"><p>No API token or auth is needed!</p></li><li data-preset-tag=\"p\"><p>You can see all the events that GitHub supports <a href=\"https://docs.github.com/en/rest/using-the-rest-api/github-event-types?apiVersion=2022-11-28\" rel=\"noopener\">here</a>.</p></li><li data-preset-tag=\"p\"><p>Events are recorded in near-real-time, but may be delayed by a few seconds.</p></li><li data-preset-tag=\"p\"><p>It’s only for public repositories.</p></li></ul><p>So, we could monitor commit data for all GitHub public repositories and store all the hashes. No more guessing commit hashes! Yeah, but it’s way too much. We are talking about millions of events per hour, and what about past events? Are they lost?</p><p>Luckily for us a great developer named <a href=\"https://github.com/igrigorik\" rel=\"noopener\">Ilya Grigorik</a> decided many years ago to start a project that listens to GitHub’s event stream and systematically archives it. The project is open-source and called <a href=\"https://github.com/igrigorik/gharchive.org\" rel=\"noopener\">GH Archive</a> and the website is <a href=\"http://gharchive.org/\" rel=\"noopener\">gharchive.org</a>. So, if we want, for example, to get the entire GitHub public activity around Jan 1st at 3pm UTC we just download this from here: <a href=\"https://data.gharchive.org/2015-01-01-15.json.gz\" rel=\"noopener\">https://data.gharchive.org/2015-01-01-15.json.gz</a>.</p><p>Here is a random sample of a  from that  archive:</p><h3>Finding Force Push Deleted Commits</h3><p>To identify only the deleted commits from force push events, we can look for push events that contain zero commits. Why would a Git push event have no commits? It indicates a force push that resets the branch - essentially just moving the HEAD without adding any new commits! I call this an  or a .</p><p>Let’s see a quick example. We will download a random archive and search for such an event.</p><p>If we randomly select one of the target event types, we will see that the  array is empty (zero commits). And if we look at the  commit - the one that was “deleted” (the HEAD before moving to HEAD^1, which is the “after”) - we see that Github still holds a record of it 10 years later!</p><p>Here it is - <a href=\"https://github.com/grapefruit623/gcloud-python/commit/e9c3d31212847723aec86ef96aba0a77f9387493\" rel=\"noopener\">https://github.com/grapefruit623/gcloud-python/commit/e9c3d31212847723aec86ef96aba0a77f9387493</a></p><p>And it’s not necessarily just the  commit that was deleted. Sometimes a force push overwrites many commits at once.&nbsp;</p><p>Given a Github organization (or user), repo name, and commit hash, it’s quite easy to scan the content of the “deleted” commit(s) for secrets using Git access:</p><ul><li data-preset-tag=\"p\"><p>Clones a repo in a minimal way.</p><ul><li data-preset-tag=\"p\"><p>: Omits file contents (blobs), only history/trees/commits.</p></li><li data-preset-tag=\"p\"><p>: Doesn't check out the working directory (no files appear yet).</p></li></ul></li><li data-preset-tag=\"p\"><p>Fetches a specific commit ().</p></li><li data-preset-tag=\"p\"><p>Scans for secrets using TruffleHog.</p><ul><li data-preset-tag=\"p\"><p>TruffleHog will automatically pull down the file contents (blobs) that need to be scanned.&nbsp;</p></li><li data-preset-tag=\"p\"><p>This command will search for secrets in all commits, starting with the  commit and working backward until the start of that branch. This ensures that all data from a force push overwriting more than one commit gets scanned; however, it will scan some non-dangling commits. The <a href=\"https://github.com/trufflesecurity/force-push-scanner\" rel=\"noopener\">open-source tool</a> we’ve released is a bit more efficient and only scans the actual dangling (dereferenced) commits.</p></li></ul></li></ul><p>GitHub doesn't specify an exact rate limit for Git operations, but excessive cloning or fetching of repositories may trigger delaying or rate limiting (see <a href=\"https://github.com/orgs/community/discussions/44515\" rel=\"noopener\">here</a>).</p><p>In addition, we can use other methods to query a specific deleted/dangling commit with the GitHub API or simply with the Github web UI.</p><p>Query for the commit patch using&nbsp; GitHub’s REST API:&nbsp;</p><p><code><strong>https://api.github.com/repos/&lt;ORG&gt;/&lt;REPO-NAME&gt;/commits/&lt;HASH&gt;</strong></code></p><ul><li data-preset-tag=\"p\"><p><a href=\"https://api.github.com/repos/github/gitignore/commits/e9552d855c356b062ed82b83fcaacd230821a6eb\" rel=\"noopener\">https://api.github.com/repos/github/gitignore/commits/e9552d855c356b062ed82b83fcaacd230821a6eb</a></p></li></ul><p>Note: There’s a <a href=\"https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28\" rel=\"noopener\">strict rate-limit</a> of 5,000 queries per hour for registered users and merely 60 for unregistered users. The server response header  indicates how many API calls users have left.</p><h4>Direct Web Access via <a href=\"https://github.com/\" rel=\"noopener\">Github.com</a></h4><p>You can also access the commit details directly from <a href=\"https://github.com/\" rel=\"noopener\">GitHub.com</a>.                                             </p><p>Here are three different examples of how to access any commit via the GitHub website:</p><p><strong>https://github.com/&lt;ORG&gt;/&lt;REPO-NAME&gt;/commit/&lt;HASH&gt;</strong></p><ul><li data-preset-tag=\"p\"><p><a href=\"https://github.com/github/gitignore/commit/e9552d855c356b062ed82b83fcaacd230821a6eb\" target=\"_blank\" rel=\"noopener\">https://github.com/github/gitignore/commit/e9552d855c356b062ed82b83fcaacd230821a6eb</a></p></li></ul><p><strong>https://github.com/&lt;ORG&gt;/&lt;REPO-NAME&gt;/commit/&lt;HASH&gt;.patch</strong></p><ul><li data-preset-tag=\"p\"><p><a href=\"https://github.com/github/gitignore/commit/e9552d855c356b062ed82b83fcaacd230821a6eb.patch\" target=\"_blank\" rel=\"noopener\">https://github.com/github/gitignore/commit/e9552d855c356b062ed82b83fcaacd230821a6eb.patch</a></p></li></ul><p><strong>https://github.com/&lt;ORG&gt;/&lt;REPO-NAME&gt;/commit/&lt;HASH&gt;.diff</strong></p><ul><li data-preset-tag=\"p\"><p><a href=\"https://github.com/github/gitignore/commit/e9552d855c356b062ed82b83fcaacd230821a6eb.diff\" rel=\"noopener\">https://github.com/github/gitignore/commit/e9552d855c356b062ed82b83fcaacd230821a6eb.diff</a></p></li></ul><p>Although there is no documented rate limit, access is not guaranteed under heavy usage, and their WAF may block requests at any time without notice.</p><p>So we have all the ingredients - we can get all GitHub event data, search for all events, fetch the “deleted” commit (the  hash), and then scan for active secrets using TruffleHog. Let’s do this.&nbsp;</p><p>You know what? No need to build it, because together with Truffle Security’s Research team, we’re<a href=\"https://github.com/trufflesecurity/force-push-scanner\" rel=\"noopener\"> open-sourcing a new tool</a> to search the entire GH Archive for “Oops Commits” made by your GitHub organization or user account. Since the entire GH Archive is available as a <a href=\"https://www.gharchive.org/#bigquery\" rel=\"noopener\">Google Big Query public dataset</a>, this tool scans GHArchive PushEvent data for zero-commit events, fetches the corresponding commits, and scans them for secrets using TruffleHog.&nbsp;</p><p>: We are releasing this tool to help blue teamers assess their potential exposure. Please use it responsibly.</p><p>Here’s a command to get started:</p><div><div><div><div><div><div><pre translate=\"no\"><code>. --- ///. -- &lt;/</code></pre></div></div></div></div></div></div><p>For this research, I used a custom version of our open-source tool to scan all of GitHub's  since 2020. And wow. There were lots of secrets!</p><h2>Hunting for Impactful Secrets</h2><p>After running the automation, I found thousands of active secrets. But how can I identify the most interesting secrets tied to the most impactful organizations? My three-step formula for success: manual search, a vibe-coded triage tool, and AI.</p><p>First, I manually explored and manipulated the data - essentially, got my hands dirty. The automation I built stores each newly discovered secret in a well-structured JSON file. Here's an example of what one of those files looks like:</p><p>During this stage, I manually looked over the files for interesting secrets. For example, I filtered out all commits made by authors with generic email addresses (e.g. <a href=\"https://gmail.com/\" rel=\"noopener\">gmail.com</a>, <a href=\"https://outlook.com/\" rel=\"noopener\">outlook.com</a>, <a href=\"http://mail.ru/\" rel=\"noopener\">mail.ru</a>, etc)&nbsp; and focused on commits pushed by authors with a corporate email. While not perfect, it was a good start, and I found some really impactful keys.</p><p>To understand the impact of specific tokens, I tried to figure out who owns the key and what access it has using open-source tools (e.g. <a href=\"https://github.com/NikhilPanwar/secrets-ninja\" rel=\"noopener\">secrets-ninja</a>) and a few custom scripts. During my research, I learned that the Truffle Security team launched an open-source tool to do just that - <a href=\"https://github.com/trufflesecurity/trufflehog?tab=readme-ov-file#mag-analyze\" rel=\"noopener\">TruffleHog Analyze</a>. It’s built into TruffleHog; you just have to run .&nbsp;</p><p>Note: I only did this additional secret enumeration when it was in-scope for specific Bug Bounty or Vulnerability Disclosure programs.</p><p>Once I found something relevant or interesting, I reported it via a bug-bounty program or directly via email.</p><h3>Vibe Coding for Secret Triage</h3><p>After a couple hundred manual checks, I had enough and decided to scale-up my secrets review. I used vercel v0 to vibe-code a whole platform for triaging these “Oops Commit” secrets.&nbsp;</p><p>The platform was very simple. It was a front-end-only interface (no backend at all) that received a .zip file with JSON files created by the scanner. It then presented them in a very easy-to-use table so I could quickly review them and mark what I had already reviewed. This method proved very efficient, and I used a combination of filters to quickly find the hidden gems!</p><p>I also added some graphs and pie charts because why not? Looking at these graphs immediately revealed a few insights.</p><p>First, if you look at the time-series graph below, there’s clearly a direct correlation between the year and amount of  secrets - most likely because older secrets have already been revoked or expired - as they should!&nbsp;</p><p>Second, MongoDB secrets leaked the most. Based on my review of the data, this is because a lot of junior developers and CS students leaked mostly non-interesting side-project MongoDB credentials. The most interesting leaked secrets were GitHub PAT tokens and AWS credentials. These also generated the highest bounties!</p><p>Finally, I plotted the frequency of files leaking valid credentials, ahd the results are clear - your file needs extra protection!</p><p>Besides .env the most leaking filenames are: , , , , , , , , , , , , , , , , , , , , , , , ,, , , , , , , , , , , , , , , </p><p>I was quite satisfied with my vibe-coded secrets review platform. However, reviewing secrets is still a manual task. Ideally, the process should automatically resolve all secrets to extract basic information about the associated accounts wherever possible. This data could then be passed to a LLAMA-based agent that analyzes and identifies potentially valuable secrets. In essence, the goal is to build an offline agent capable of determining which secrets hold significance from a bug bounty or impact-driven perspective.</p><p>With the help of my friend <a href=\"https://il.linkedin.com/in/moti-harmats\" rel=\"noopener\">Moti Harmats</a>, I started working on it, but there’s still a lot more work to do, so I won’t release it at this time. But here’s a preview of what I started building:</p><h2>Case Study - Preventing a Massive Supply-Chain Compromise</h2><p>One of the secrets I found in a deleted commit was a <a href=\"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\" rel=\"noopener\">GitHub Personal Access Token</a> (PAT) belonging to a developer. The developer accidentally leaked this secret when they committed their hidden configuration files (dot files). I analyzed this token and found it had admin access to ALL of <a href=\"https://github.com/istio/istio\" rel=\"noopener\">Istio</a> repositories.</p><p>Istio is an open-source service mesh that provides a transparent and language-independent way to flexibly and easily automate application network functions. It is designed to manage the communication between microservices in a distributed application, offering features such as traffic management, security, and observability without requiring changes to the application code.</p><p>The main <a href=\"https://github.com/istio/istio\" rel=\"noopener\">Istio</a> project has  stars and  forks. Istio is used by a wide range of organizations and teams that run complex, distributed applications, especially those adopting microservices architectures. This includes giant corporations like Google, IBM, Red Hat and many others.</p><p>And I had ADMIN level access to ALL of Itsio repositories (<a href=\"https://github.com/istio/\" rel=\"noopener\">there are many of them</a>). I could have read environment variables, changed pipelines, pushed code, created new releases, or even deleted the entire project. The potential for a mass supply-chain attack here was scary.&nbsp;</p><p>Fortunately, Istio has a well-maintained <a href=\"https://istio.io/latest/docs/releases/security-vulnerabilities/\" rel=\"noopener\">report page</a>, and the team acted quickly to revoke the GitHub PATs as soon as the issue was reported. Thank you!</p><p>This was a really fun project. I glued together some known discoveries and was able to create a reliable automation that scanned and found thousands of active secrets, even some that were buried for years. I also got the chance to vibe code a secret hunting platform with some nice features that allowed me to find needles in a haystack and earn approximately $25k of bounties and deep-thanks through the process.</p><p>The common assumption that deleting a commit is secure must change - once a secret is committed it should be considered compromised and must be revoked ASAP. It’s true for git blobs, git commits, and anything else that goes online.</p>","contentLength":18035,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44452317"},{"title":"AI job predictions become corporate America’s newest competitive sport","url":"https://techcrunch.com/2025/07/02/ai-job-predictions-become-corporate-americas-newest-competitive-sport/","date":1751520618,"author":"Connie Loizos","guid":182643,"unread":true,"content":"<article>In late May, Anthropic CEO Dario Amodei appeared to kick open the door on a sensitive topic, warning that half of entry-level jobs could vanish within five years because of AI and push U.S. unemployment up to 20%. But Amodei is far from alone in sharing aloud that he foresees a workforce bloodbath. A new […]</article>","contentLength":311,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Taking ResNet to the Next Level","url":"https://towardsdatascience.com/taking-resnet-to-the-next-level/","date":1751515866,"author":"Muhammad Ardi","guid":182535,"unread":true,"content":"<p>Understanding how ResNeXt improves upon ResNet, with a comprehensive PyTorch implementation guide</p>","contentLength":97,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Wordkrill: Extending Wordfish into the multidimensional political space","url":"https://arxiv.org/abs/2506.20275","date":1751515200,"author":"","guid":181780,"unread":true,"content":"<article>arXiv:2506.20275v2 Announce Type: replace-cross \nAbstract: Spatial models are central to the study of political conflict, yet their empirical application often depends on text-based methods. A prominent example is the Wordfish model, which estimates actor positions from political texts. However, a key limitation of Wordfish is its unidimensionality, despite the well-established multidimensional nature of political competition. This contribution introduces Wordkrill, a multidimensional extension of Wordfish that retains the original model's interpretability while allowing for efficient estimation of political positions along multiple latent dimensions. After presenting the mathematical framework of Wordkrill, its utility through brief applications to party manifestos and parliamentary speeches is demonstrated. These examples illustrate both the practical advantages and current limitations of the approach.</article>","contentLength":917,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives","url":"https://arxiv.org/abs/2506.20114","date":1751515200,"author":"","guid":181781,"unread":true,"content":"<article>arXiv:2506.20114v2 Announce Type: replace-cross \nAbstract: Tree ensembles are non-parametric methods widely recognized for their accuracy and ability to capture complex interactions. While these models excel at prediction, they are difficult to interpret and may fail to uncover useful relationships in the data. We propose an estimator to extract compact sets of decision rules from tree ensembles. The extracted models are accurate and can be manually examined to reveal relationships between the predictors and the response. A key novelty of our estimator is the flexibility to jointly control the number of rules extracted and the interaction depth of each rule, which improves accuracy. We develop a tailored exact algorithm to efficiently solve optimization problems underlying our estimator and an approximate algorithm for computing regularization paths, sequences of solutions that correspond to varying model sizes. We also establish novel non-asymptotic prediction error bounds for our proposed approach, comparing it to an oracle that chooses the best data-dependent linear combination of the rules in the ensemble subject to the same complexity constraint as our estimator. The bounds illustrate that the large-sample predictive performance of our estimator is on par with that of the oracle. Through experiments, we demonstrate that our estimator outperforms existing algorithms for rule extraction.</article>","contentLength":1413,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CAM-NET: An AI Model for Whole Atmosphere with Thermosphere and Ionosphere Extension","url":"https://arxiv.org/abs/2506.19340","date":1751515200,"author":"","guid":181782,"unread":true,"content":"<article>arXiv:2506.19340v3 Announce Type: replace-cross \nAbstract: We present Compressible Atmospheric Model-Network (CAM-NET), an AI model designed to predict neutral atmospheric variables from the Earth's surface to the ionosphere with high accuracy and computational efficiency. Accurate modeling of the entire atmosphere is critical for understanding the upward propagation of gravity waves, which influence upper-atmospheric dynamics and coupling across atmospheric layers. CAM-NET leverages the Spherical Fourier Neural Operator (SFNO) to capture global-scale atmospheric dynamics while preserving the Earth's spherical structure. Trained on a decade of datasets from the Whole Atmosphere Community Climate Model with thermosphere and ionosphere eXtension (WACCM-X), CAM-NET demonstrates accuracy comparable to WACCM-X while achieving a speedup of over 1000x in inference time, can provide one year simulation within a few minutes once trained. The model effectively predicts key atmospheric parameters, including zonal and meridional winds, temperature, and time rate of pressure. Inspired by traditional modeling approaches that use external couplers to simulate tracer transport, CAM-NET introduces a modular architecture that explicitly separates tracer prediction from core dynamics. The core backbone of CAM-NET focuses on forecasting primary physical variables (e.g., temperature, wind velocity), while tracer variables are predicted through a lightweight, fine-tuned model. This design allows for efficient adaptation to specific tracer scenarios with minimal computational cost, avoiding the need to retrain the entire model. We have validated this approach on the $O^2$ tracer, demonstrating strong performance and generalization capabilities.</article>","contentLength":1751,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Convergent and divergent connectivity patterns of the arcuate fasciculus in macaques and humans","url":"https://arxiv.org/abs/2506.19266","date":1751515200,"author":"","guid":181783,"unread":true,"content":"<article>arXiv:2506.19266v2 Announce Type: replace-cross \nAbstract: The organization and connectivity of the arcuate fasciculus (AF) in nonhuman primates remain contentious, especially concerning how its anatomy diverges from that of humans. Here, we combined cross-scale single-neuron tracing - using viral-based genetic labeling and fluorescence micro-optical sectioning tomography in macaques (n = 4; age 3 - 11 years) - with whole-brain tractography from 11.7T diffusion MRI. Complemented by spectral embedding analysis of 7.0T MRI in humans, we performed a comparative connectomic analysis of the AF across species. We demonstrate that the macaque AF originates in the temporal-parietal cortex, traverses the auditory cortex and parietal operculum, and projects into prefrontal regions. In contrast, the human AF exhibits greater expansion into the middle temporal gyrus and stronger prefrontal and parietal operculum connectivity - divergences quantified by Kullback-Leibler analysis that likely underpin the evolutionary specialization of human language networks. These interspecies differences - particularly the human AF's broader temporal integration and strengthened frontoparietal linkages - suggest a connectivity-based substrate for the emergence of advanced language processing unique to humans. Furthermore, our findings offer a neuroanatomical framework for understanding AF-related disorders such as aphasia and dyslexia, where aberrant connectivity disrupts language function.</article>","contentLength":1486,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Enhancing Expressivity of Quantum Neural Networks Based on the SWAP test","url":"https://arxiv.org/abs/2506.16938","date":1751515200,"author":"","guid":181784,"unread":true,"content":"<article>arXiv:2506.16938v2 Announce Type: replace-cross \nAbstract: Parameterized quantum circuits represent promising architectures for machine learning applications, yet many lack clear connections to classical models, potentially limiting their ability to translate the wide success of classical neural networks to the quantum realm. We examine a specific type of quantum neural network (QNN) built exclusively from SWAP test circuits, and discuss its mathematical equivalence to a classical two-layer feedforward network with quadratic activation functions under amplitude encoding. Our analysis across classical real-world and synthetic datasets reveals that while this architecture can successfully learn many practical tasks, it exhibits fundamental expressivity limitations due to violating the universal approximation theorem, particularly failing on harder problems like the parity check function. To address this limitation, we introduce a circuit modification using generalized SWAP test circuits that effectively implements classical neural networks with product layers. This enhancement enables successful learning of parity check functions in arbitrary dimensions which we analytically argue to be impossible for the original architecture beyond two dimensions regardless of network size. Our results establish a framework for enhancing QNN expressivity through classical task analysis and demonstrate that our SWAP test-based architecture offers broad representational capacity, suggesting potential promise also for quantum learning tasks.</article>","contentLength":1547,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On the Fundamental Impossibility of Hallucination Control in Large Language Models","url":"https://arxiv.org/abs/2506.06382","date":1751515200,"author":"","guid":181785,"unread":true,"content":"<article>arXiv:2506.06382v2 Announce Type: replace-cross \nAbstract: We prove that perfect hallucination control in large language models is mathematically impossible. No LLM inference mechanism can simultaneously achieve truthful response generation, semantic information conservation, relevant knowledge revelation, and knowledge-constrained optimality. This impossibility is fundamental, arising from the mathematical structure of information aggregation itself rather than engineering limitations. The proof spans three mathematical frameworks: auction theory, proper scoring theory for probabilistic predictions, and log-sum-exp analysis for transformer architectures. In each setting, we demonstrate that information aggregation creates unavoidable violations of conservation principles. The Jensen gap in transformer probability aggregation provides a direct measure of this impossibility. These results reframe hallucination from an engineering bug to an inevitable mathematical feature of distributed intelligence. There are fundamental trade-offs between truthfulness, knowledge utilization, and response completeness, providing principled foundations for managing rather than eliminating hallucination. This work reveals deep connections between neural network inference, philosophy of knowledge and reasoning, and classical results in game theory and information theory, opening new research directions for developing beneficial AI systems within mathematical constraints.</article>","contentLength":1474,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations","url":"https://arxiv.org/abs/2505.08195","date":1751515200,"author":"","guid":181786,"unread":true,"content":"<article>arXiv:2505.08195v2 Announce Type: replace-cross \nAbstract: We have developed Aitomia - a platform powered by AI to assist in performing AI-driven atomistic and quantum chemical (QC) simulations. This evolving intelligent assistant platform is equipped with chatbots and AI agents to help experts and guide non-experts in setting up and running the atomistic simulations, monitoring their computation status, analyzing the simulation results, and summarizing them for the user in text and graphical forms. We achieve these goals by exploiting open-source large language models (LLMs, original and fine-tuned), rule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia leverages the versatility of our MLatom ecosystem, supporting AI-enhanced computational chemistry tasks ranging from ground- to excited-state calculations such as geometry optimizations, thermochemistry, and spectra calculations. Aitomia is the first intelligent assistant publicly accessible online on a cloud computing platform for atomistic simulations of broad scope (Aitomistic Hub at https://aitomistic.xyz), while it may also be deployed locally as described at http://mlatom.com/aitomia. Aitomia is expected to lower the barrier to performing atomistic simulations, democratizing simulations, and accelerating research and development in the relevant fields.</article>","contentLength":1353,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An example showing that Schrijver's $\\vartheta$-function need not upper bound the Shannon capacity of a graph","url":"https://arxiv.org/abs/2505.07778","date":1751515200,"author":"","guid":181787,"unread":true,"content":"<article>arXiv:2505.07778v3 Announce Type: replace-cross \nAbstract: This letter addresses an open question concerning a variant of the Lov\\'{a}sz $\\vartheta$ function, which was introduced by Schrijver and independently by McEliece et al. (1978). The question of whether this variant provides an upper bound on the Shannon capacity of a graph was explicitly stated by Bi and Tang (2019). This letter presents an explicit example of a Tanner graph on 32 vertices, which shows that, in contrast to the Lov\\'{a}sz $\\vartheta$ function, this variant does not necessarily upper bound the Shannon capacity of a graph. The example, previously outlined by the author in a recent paper (2024), is presented here in full detail, making it easy to follow and verify. By resolving this question, the note clarifies a subtle but significant distinction between these two closely related graph invariants.</article>","contentLength":882,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond","url":"https://arxiv.org/abs/2504.13037","date":1751515200,"author":"","guid":181788,"unread":true,"content":"<article>arXiv:2504.13037v3 Announce Type: replace-cross \nAbstract: Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individual's disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis.</article>","contentLength":1912,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Query Complexity of Classical and Quantum Channel Discrimination","url":"https://arxiv.org/abs/2504.12989","date":1751515200,"author":"","guid":181789,"unread":true,"content":"<article>arXiv:2504.12989v2 Announce Type: replace-cross \nAbstract: Quantum channel discrimination has been studied from an information-theoretic perspective, wherein one is interested in the optimal decay rate of error probabilities as a function of the number of unknown channel accesses. In this paper, we study the query complexity of quantum channel discrimination, wherein the goal is to determine the minimum number of channel uses needed to reach a desired error probability. To this end, we show that the query complexity of binary channel discrimination depends logarithmically on the inverse error probability and inversely on the negative logarithm of the (geometric and Holevo) channel fidelity. As a special case of these findings, we precisely characterize the query complexity of discriminating two classical channels and two classical-quantum channels. Furthermore, by obtaining a tighter characterization of the sample complexity of quantum hypothesis testing, including prior probabilities, we provide a more precise characterization of query complexity when the error probability does not exceed a fixed threshold. We also provide lower and upper bounds on the query complexity of binary asymmetric channel discrimination and multiple quantum channel discrimination. For the former, the query complexity depends on the geometric R\\'enyi and Petz R\\'enyi channel divergences, while for the latter, it depends on the negative logarithm of the (geometric and Uhlmann) channel fidelity. For multiple channel discrimination, the upper bound scales as the logarithm of the number of channels.</article>","contentLength":1597,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Metacognitive Architectures Remember Their Own Thoughts: A Systematic Review","url":"https://arxiv.org/abs/2503.13467","date":1751515200,"author":"","guid":181790,"unread":true,"content":"<article>arXiv:2503.13467v2 Announce Type: replace-cross \nAbstract: Background: Metacognition has gained significant attention for its potential to enhance autonomy and adaptability of artificial agents but remains a fragmented field: diverse theories, terminologies, and design choices have led to disjointed developments and limited comparability across systems. Existing overviews remain at a conceptual level that is undiscerning to the underlying algorithms, representations, and their respective success.\n  Methods: We address this gap by performing an explorative systematic review. Reports were included if they described techniques enabling Computational Metacognitive Architectures (CMAs) to model, store, remember, and process their episodic metacognitive experiences, one of Flavell's (1979a) three foundational components of metacognition. Searches were conducted in 16 databases, consulted between December 2023 and June 2024. Data were extracted using a 20-item framework considering pertinent aspects.\n  Results: A total of 101 reports on 35 distinct CMAs were included. Our findings show that metacognitive experiences may boost system performance and explainability, e.g., via self-repair. However, lack of standardization and limited evaluations may hinder progress: only 17% of CMAs were quantitatively evaluated regarding this review's focus, and significant terminological inconsistency limits cross-architecture synthesis. Systems also varied widely in memory content, data types, and employed algorithms.\n  Discussion: Limitations include the non-iterative nature of the search query, heterogeneous data availability, and an under-representation of emergent, sub-symbolic CMAs. Future research should focus on standardization and evaluation, e.g., via community-driven challenges, and on transferring promising principles to emergent architectures.</article>","contentLength":1863,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ScaleFusionNet: Transformer-Guided Multi-Scale Feature Fusion for Skin Lesion Segmentation","url":"https://arxiv.org/abs/2503.03327","date":1751515200,"author":"","guid":181791,"unread":true,"content":"<article>arXiv:2503.03327v3 Announce Type: replace-cross \nAbstract: Melanoma is a malignant tumor that originates from skin cell lesions. Accurate and efficient segmentation of skin lesions is essential for quantitative analysis but remains a challenge due to blurred lesion boundaries, gradual color changes, and irregular shapes. To address this, we propose ScaleFusionNet, a hybrid model that integrates a Cross-Attention Transformer Module (CATM) and adaptive fusion block (AFB) to enhance feature extraction and fusion by capturing both local and global features. We introduce CATM, which utilizes Swin transformer blocks and Cross Attention Fusion (CAF) to adaptively refine feature fusion and reduce semantic gaps in the encoder-decoder to improve segmentation accuracy. Additionally, the AFB uses Swin Transformer-based attention and deformable convolution-based adaptive feature extraction to help the model gather local and global contextual information through parallel pathways. This enhancement refines the lesion boundaries and preserves fine-grained details. ScaleFusionNet achieves Dice scores of 92.94\\% and 91.80\\% on the ISIC-2016 and ISIC-2018 datasets, respectively, demonstrating its effectiveness in skin lesion analysis. Simultaneously, independent validation experiments were conducted on the PH$^2$ dataset using the pretrained model weights. The results show that ScaleFusionNet demonstrates significant performance improvements compared with other state-of-the-art methods. Our code implementation is publicly available at GitHub.</article>","contentLength":1549,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Distribution Matching for Self-Supervised Transfer Learning","url":"https://arxiv.org/abs/2502.14424","date":1751515200,"author":"","guid":181792,"unread":true,"content":"<article>arXiv:2502.14424v2 Announce Type: replace-cross \nAbstract: In this paper, we propose a novel self-supervised transfer learning method called \\underline{\\textbf{D}}istribution \\underline{\\textbf{M}}atching (DM), which drives the representation distribution toward a predefined reference distribution while preserving augmentation invariance. DM results in a learned representation space that is intuitively structured and therefore easy to interpret.\n  Experimental results across multiple real-world datasets and evaluation metrics demonstrate that DM performs competitively on target classification tasks compared to existing self-supervised transfer learning methods. Additionally, we provide robust theoretical guarantees for DM, including a population theorem and an end-to-end sample theorem. The population theorem bridges the gap between the self-supervised learning task and target classification accuracy, while the sample theorem shows that, even with a limited number of samples from the target domain, DM can deliver exceptional classification performance, provided the unlabeled sample size is sufficiently large.</article>","contentLength":1126,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Baseline Method for Removing Invisible Image Watermarks using Deep Image Prior","url":"https://arxiv.org/abs/2502.13998","date":1751515200,"author":"","guid":181793,"unread":true,"content":"<article>arXiv:2502.13998v2 Announce Type: replace-cross \nAbstract: Image watermarks have been considered a promising technique to help detect AI-generated content, which can be used to protect copyright or prevent fake image abuse. In this work, we present a black-box method for removing invisible image watermarks, without the need of any dataset of watermarked images or any knowledge about the watermark system. Our approach is simple to implement: given a single watermarked image, we regress it by deep image prior (DIP). We show that from the intermediate steps of DIP one can reliably find an evasion image that can remove invisible watermarks while preserving high image quality. Due to its unique working mechanism and practical effectiveness, we advocate including DIP as a baseline invasion method for benchmarking the robustness of watermarking systems. Finally, by showing the limited ability of DIP and other existing black-box methods in evading training-based visible watermarks, we discuss the positive implications on the practical use of training-based visible watermarks to prevent misinformation abuse.</article>","contentLength":1116,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Normal Play of the Domination Game","url":"https://arxiv.org/abs/2502.13118","date":1751515200,"author":"","guid":181794,"unread":true,"content":"<article>arXiv:2502.13118v3 Announce Type: replace-cross \nAbstract: In 2010, Bre\\v{s}ar, Klav\\v{z}ar and Rall introduced the optimization variant of the graph domination game and the game domination number. In 2024, Leo Versteegen obtained the celebrated proof of the Conjecture $\\frac{3}{5}$ on this variant of the domination game, proposed by Kinnersley, West and Zamani in 2013. In this paper, we investigate for the first time the normal play of the domination game, which we call \\textsc{Normal Domination Game}, that is an impartial game where the last to play wins. We first prove that this game is PSPACE-complete even in graphs with diameter two. We also use the Sprague-Grundy theory to prove that Alice (the first player) wins in the path $P_n$ if and only if $n$ is not a multiple of $4$, and wins in the cycle $C_n$ if and only if $n=4k+3$ for some integer $k$. Finally, we obtain a polynomial time algorithm to decide the winner for any disjoint union of paths and cycles in the \\textsc{Normal Domination Game} and its natural partizan variant.</article>","contentLength":1049,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Empirical Bayes Estimation for Lasso-Type Regularizers: Analysis of Automatic Relevance Determination","url":"https://arxiv.org/abs/2501.11280","date":1751515200,"author":"","guid":181795,"unread":true,"content":"<article>arXiv:2501.11280v4 Announce Type: replace-cross \nAbstract: This paper focuses on linear regression models with non-conjugate sparsity-inducing regularizers such as lasso and group lasso. Although the empirical Bayes approach enables us to estimate the regularization parameter, little is known on the properties of the estimators. In particular, many aspects regarding the specific conditions under which the mechanism of automatic relevance determination (ARD) occurs remain unexplained. In this paper, we derive the empirical Bayes estimators for the group lasso regularized linear regression models with limited parameters. It is shown that the estimators diverge under a specific condition, giving rise to the ARD mechanism. We also prove that empirical Bayes methods can produce the ARD mechanism in general regularized linear regression models and clarify the conditions under which models such as ridge, lasso, and group lasso can do so.</article>","contentLength":944,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real-Time AIoT for AAV Antenna Interference Detection via Edge-Cloud Collaboration","url":"https://arxiv.org/abs/2412.03055","date":1751515200,"author":"","guid":181796,"unread":true,"content":"<article>arXiv:2412.03055v3 Announce Type: replace-cross \nAbstract: In the fifth-generation (5G) era, eliminating communication interference sources is crucial for maintaining network performance. Interference often originates from unauthorized or malfunctioning antennas, and radio monitoring agencies must address numerous sources of such antennas annually. Unmanned aerial vehicles (UAVs) can improve inspection efficiency. However, the data transmission delay in the existing cloud-only (CO) artificial intelligence (AI) mode fails to meet the low latency requirements for real-time performance. Therefore, we propose a computer vision-based AI of Things (AIoT) system to detect antenna interference sources for UAVs. The system adopts an optimized edge-cloud collaboration (ECC+) mode, combining a keyframe selection algorithm (KSA), focusing on reducing end-to-end latency (E2EL) and ensuring reliable data transmission, which aligns with the core principles of ultra-reliable low-latency communication (URLLC). At the core of our approach is an end-to-end antenna localization scheme based on the tracking-by-detection (TBD) paradigm, including a detector (EdgeAnt) and a tracker (AntSort). EdgeAnt achieves state-of-the-art (SOTA) performance with a mean average precision (mAP) of 42.1% on our custom antenna interference source dataset, requiring only 3 million parameters and 14.7 GFLOPs. On the COCO dataset, EdgeAnt achieves 38.9% mAP with 5.4 GFLOPs. We deployed EdgeAnt on Jetson Xavier NX (TRT) and Raspberry Pi 4B (NCNN), achieving real-time inference speeds of 21.1 (1088) and 4.8 (640) frames per second (FPS), respectively. Compared with CO mode, the ECC+ mode reduces E2EL by 88.9%, increases accuracy by 28.2%. Additionally, the system offers excellent scalability for coordinated multiple UAVs inspections. The detector code is publicly available at https://github.com/SCNU-RISLAB/EdgeAnt.</article>","contentLength":1903,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Generation of Cycle Permutation Graphs and Permutation Snarks","url":"https://arxiv.org/abs/2411.12606","date":1751515200,"author":"","guid":181797,"unread":true,"content":"<article>arXiv:2411.12606v3 Announce Type: replace-cross \nAbstract: We present an algorithm for the efficient generation of all pairwise non-isomorphic cycle permutation graphs, i.e. cubic graphs with a $2$-factor consisting of two chordless cycles, non-hamiltonian cycle permutation graphs and permutation snarks, i.e. cycle permutation graphs that do not admit a $3$-edge-colouring. This allows us to generate all cycle permutation graphs up to order $34$ and all permutation snarks up to order $46$, improving upon previous computational results by Brinkmann et al. Moreover, we give several improved lower bounds for interesting permutation snarks, such as for a smallest permutation snark of order $6 \\bmod 8$ or a smallest permutation snark of girth at least $6$ and give more evidence in support of a conjecture of Goddyn. These computational results also allow us to complete a characterisation of the orders for which non-hamiltonian cycle permutation graphs exist, answering an open question by Klee from 1972, and yield many more counterexamples to conjectures by Jackson and Zhang.</article>","contentLength":1084,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Small-signal stability of power systems with voltage droop","url":"https://arxiv.org/abs/2411.10832","date":1751515200,"author":"","guid":181798,"unread":true,"content":"<article>arXiv:2411.10832v2 Announce Type: replace-cross \nAbstract: The stability of inverter-dominated power grids remains an active area of research. This paper presents novel sufficient conditions for ensuring small-signal stability in lossless and constant $R/X$ grids with highly heterogeneous mixes of grid-forming inverters that implement an adapted $V$-$q$ droop control. The proposed conditions can be evaluated in the neighborhood of each bus without information on the rest of the grid. Apart from the presence of $V$-$q$ droop, no additional assumptions are made regarding the inverter control strategies, nor is dynamical homogeneity across the system assumed. The analysis is enabled by recasting the node dynamics in terms of complex frequency and power, resulting in transfer functions that directly capture the small-signal frequency and amplitude responses to active and reactive power imbalances. These transfer functions are directly aligned with typical design considerations in grid-forming control. Building on an adapted small-phase theorem and viewing the system as a closed feedback loop between nodes and lines, the derived stability conditions also yield new insights when applied to established inverter control designs. We demonstrate in simulations that our conditions are not overly conservative and can identify individual inverters that are misconfigured and cause instability.</article>","contentLength":1402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tenure and Research Trajectories","url":"https://arxiv.org/abs/2411.10575","date":1751515200,"author":"","guid":181799,"unread":true,"content":"<article>arXiv:2411.10575v2 Announce Type: replace-cross \nAbstract: Tenure is a cornerstone of the US academic system, yet its relationship to faculty research trajectories remains poorly understood. Conceptually, tenure systems may act as a selection mechanism, screening in high-output researchers; a dynamic incentive mechanism, encouraging high output prior to tenure but low output after tenure; and a creative search mechanism, encouraging tenured individuals to undertake high-risk work. Here, we integrate data from seven different sources to trace US tenure-line faculty and their research outputs at an unprecedented scale and scope, covering over 12,000 researchers across 15 disciplines. Our analysis reveals that faculty publication rates typically increase sharply during the tenure track and peak just before obtaining tenure. Post-tenure trends, however, vary across disciplines: in lab-based fields, such as biology and chemistry, research output typically remains high post-tenure, whereas in non-lab-based fields, such as mathematics and sociology, research output typically declines substantially post-tenure. Turning to creative search, faculty increasingly produce novel, high-risk research after securing tenure. However, this shift toward novelty and risk-taking comes with a decline in impact, with post-tenure research yielding fewer highly cited papers. Comparing outcomes across common career ages but different tenure years or comparing research trajectories in tenure-based and non-tenure-based research settings underscores that breaks in the research trajectories are sharply tied to the individual's tenure year. Overall, these findings provide a new empirical basis for understanding the tenure system, individual research trajectories, and the shape of scientific output.</article>","contentLength":1797,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PSELDNets: Pre-trained Neural Networks on a Large-scale Synthetic Dataset for Sound Event Localization and Detection","url":"https://arxiv.org/abs/2411.06399","date":1751515200,"author":"","guid":181800,"unread":true,"content":"<article>arXiv:2411.06399v2 Announce Type: replace-cross \nAbstract: Sound event localization and detection (SELD) has seen substantial advancements through learning-based methods. These systems, typically trained from scratch on specific datasets, have shown considerable generalization capabilities. Recently, deep neural networks trained on large-scale datasets have achieved remarkable success in the sound event classification (SEC) field, prompting an open question of whether these advances can be extended to the development of SELD foundation models. In this paper, leveraging the power of pre-trained SEC models, we propose pre-trained SELD networks (PSELDNets) on a large-scale synthetic dataset. The synthetic dataset, generated by convolving sound events with simulated spatial room impulse responses (SRIRs), contains 1,167 hours of audio clips with an ontology of 170 sound classes. These PSELDNets are applied to various SELD scenarios. When we adapt PSELDNets to specific scenarios, particularly in cases of low-resource data, we introduce a data-efficient fine-tuning method, AdapterBit. PSELDNets are evaluated on synthetic-test-set using collected SRIRs from the TAU Spatial Room Impulse Response Database (TAU-SRIR DB) and achieve satisfactory performance. We also carried out experiments to validate the transferability of PSELDNets to three publicly available datasets and our own real-world recordings. The results demonstrate that PSELDNets surpass state-of-the-art systems across all publicly available datasets. Given the need for direction-of-arrival estimation, SELD generally relies on sufficient multi-channel audio clips. However, incorporating the AdapterBit, PSELDNets show more efficient adaptability to various scenarios using minimal multi-channel or even just monophonic audio clips, outperforming traditional fine-tuning approaches.</article>","contentLength":1861,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Retrieving snow depth distribution by downscaling ERA5 Reanalysis with ICESat-2 laser altimetry","url":"https://arxiv.org/abs/2410.17934","date":1751515200,"author":"","guid":181801,"unread":true,"content":"<article>arXiv:2410.17934v2 Announce Type: replace-cross \nAbstract: Estimating the variability of seasonal snow cover, in particular snow depth in remote areas, poses significant challenges due to limited spatial and temporal data availability. This study uses snow depth measurements from the ICESat-2 satellite laser altimeter, which are sparse in both space and time, and incorporates them with climate reanalysis data into a downscaling-calibration scheme to produce monthly gridded snow depth maps at microscale (10 m). Snow surface elevation measurements from ICESat-2 along profiles are compared to a digital elevation model to determine snow depth at each point. To efficiently turn sparse measurements into snow depth maps, a regression model is fitted to establish a relationship between the retrieved snow depth and the corresponding ERA5 Land snow depth. This relationship, referred to as subgrid variability, is then applied to downscale the monthly ERA5 Land snow depth data. The method can provide timeseries of monthly snow depth maps for the entire ERA5 time range (since 1950). The validation of downscaled snow depth data was performed at an intermediate scale (100 m x 500 m) using datasets from airborne laser scanning (ALS) in the Hardangervidda region of southern Norway. Results show that snow depth prediction achieved R2 values ranging from 0.74 to 0.88 (post-calibration). The method relies on globally available data and is applicable to other snow regions above the treeline. Though requiring area-specific calibration, our approach has the potential to provide snow depth maps in areas where no such data exist and can be used to extrapolate existing snow surveys in time and over larger areas. With this, it can offer valuable input data for hydrological, ecological or permafrost modeling tasks.</article>","contentLength":1818,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Long-Context Linear System Identification","url":"https://arxiv.org/abs/2410.05690","date":1751515200,"author":"","guid":181802,"unread":true,"content":"<article>arXiv:2410.05690v2 Announce Type: replace-cross \nAbstract: This paper addresses the problem of long-context linear system identification, where the state $x_t$ of a dynamical system at time $t$ depends linearly on previous states $x_s$ over a fixed context window of length $p$. We establish a sample complexity bound that matches the i.i.d. parametric rate up to logarithmic factors for a broad class of systems, extending previous works that considered only first-order dependencies. Our findings reveal a learning-without-mixing phenomenon, indicating that learning long-context linear autoregressive models is not hindered by slow mixing properties potentially associated with extended context windows. Additionally, we extend these results to (i) shared low-rank representations, where rank-regularized estimators improve the dependence of the rates on the dimensionality, and (ii) misspecified context lengths in strictly stable systems, where shorter contexts offer statistical advantages.</article>","contentLength":996,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is merging worth it? Securely evaluating the information gain for causal dataset acquisition","url":"https://arxiv.org/abs/2409.07215","date":1751515200,"author":"","guid":181803,"unread":true,"content":"<article>arXiv:2409.07215v3 Announce Type: replace-cross \nAbstract: Merging datasets across institutions is a lengthy and costly procedure, especially when it involves private information. Data hosts may therefore want to prospectively gauge which datasets are most beneficial to merge with, without revealing sensitive information. For causal estimation this is particularly challenging as the value of a merge depends not only on reduction in epistemic uncertainty but also on improvement in overlap. To address this challenge, we introduce the first cryptographically secure information-theoretic approach for quantifying the value of a merge in the context of heterogeneous treatment effect estimation. We do this by evaluating the Expected Information Gain (EIG) using multi-party computation to ensure that no raw data is revealed. We further demonstrate that our approach can be combined with differential privacy (DP) to meet arbitrary privacy requirements whilst preserving more accurate computation compared to DP alone. To the best of our knowledge, this work presents the first privacy-preserving method for dataset acquisition tailored to causal estimation. We demonstrate the effectiveness and reliability of our method on a range of simulated and realistic benchmarks. Code is publicly available: https://github.com/LucileTerminassian/causal_prospective_merge.</article>","contentLength":1366,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NuSegDG: Integration of Heterogeneous Space and Gaussian Kernel for Domain-Generalized Nuclei Segmentation","url":"https://arxiv.org/abs/2408.11787","date":1751515200,"author":"","guid":181804,"unread":true,"content":"<article>arXiv:2408.11787v3 Announce Type: replace-cross \nAbstract: Domain-generalized nuclei segmentation refers to the generalizability of models to unseen domains based on knowledge learned from source domains and is challenged by various image conditions, cell types, and stain strategies. Recently, the Segment Anything Model (SAM) has made great success in universal image segmentation by interactive prompt modes (e.g., point and box). Despite its strengths, the original SAM presents limited adaptation to medical images. Moreover, SAM requires providing manual bounding box prompts for each object to produce satisfactory segmentation masks, so it is laborious in nuclei segmentation scenarios. To address these limitations, we propose a domain-generalizable framework for nuclei image segmentation, abbreviated to NuSegDG. Specifically, we first devise a Heterogeneous Space Adapter (HS-Adapter) to learn multi-dimensional feature representations of different nuclei domains by injecting a small number of trainable parameters into the image encoder of SAM. To alleviate the labor-intensive requirement of manual prompts, we introduce a Gaussian-Kernel Prompt Encoder (GKP-Encoder) to generate density maps driven by a single point, which guides segmentation predictions by mixing position prompts and semantic prompts. Furthermore, we present a Two-Stage Mask Decoder (TSM-Decoder) to effectively convert semantic masks to instance maps without the manual demand for morphological shape refinement. Based on our experimental evaluations, the proposed NuSegDG demonstrates state-of-the-art performance in nuclei instance segmentation, exhibiting superior domain generalization capabilities. The source code is available at https://github.com/xq141839/NuSegDG.</article>","contentLength":1760,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding","url":"https://arxiv.org/abs/2408.07636","date":1751515200,"author":"","guid":181805,"unread":true,"content":"<article>arXiv:2408.07636v2 Announce Type: replace-cross \nAbstract: Artificial intelligence (AI) is increasingly used in every stage of drug development. One challenge facing drug discovery AI is that drug pharmacokinetic (PK) datasets are often collected independently from each other, often with limited overlap, creating data overlap sparsity. Data sparsity makes data curation difficult for researchers looking to answer research questions in poly-pharmacy, drug combination research, and high-throughput screening. We propose Imagand, a novel SMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array of PK target properties conditioned on SMILES inputs. We show that Imagand-generated synthetic PK data closely resembles real data univariate and bivariate distributions, and improves performance for downstream tasks. Imagand is a promising solution for data overlap sparsity and allows researchers to efficiently generate ligand PK data for drug discovery research. Code is available at https://github.com/bing1100/Imagand.</article>","contentLength":1043,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learning with Linear Function Approximations in Mean-Field Control","url":"https://arxiv.org/abs/2408.00991","date":1751515200,"author":"","guid":181806,"unread":true,"content":"<article>arXiv:2408.00991v3 Announce Type: replace-cross \nAbstract: The paper focuses on mean-field type multi-agent control problems with finite state and action spaces where the dynamics and cost structures are symmetric and homogeneous, and are affected by the distribution of the agents. A standard solution method for these problems is to consider the infinite population limit as an approximation and use symmetric solutions of the limit problem to achieve near optimality. The control policies, and in particular the dynamics, depend on the population distribution in the finite population setting, or the marginal distribution of the state variable of a representative agent for the infinite population setting. Hence, learning and planning for these control problems generally require estimating the reaction of the system to all possible state distributions of the agents. To overcome this issue, we consider linear function approximation for the control problem and provide coordinated and independent learning methods. We rigorously establish error upper bounds for the performance of learned solutions. The performance gap stems from (i) the mismatch due to estimating the true model with a linear one, and (ii) using the infinite population solution in the finite population problem as an approximate control. The provided upper bounds quantify the impact of these error sources on the overall performance.</article>","contentLength":1411,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Relevance of the Basset history term for Lagrangian particle dynamics","url":"https://arxiv.org/abs/2407.01041","date":1751515200,"author":"","guid":181807,"unread":true,"content":"<article>arXiv:2407.01041v3 Announce Type: replace-cross \nAbstract: The movement of small but finite spherical particles in a fluid can be described by the Maxey-Riley equation (MRE) if they are too large to be considered passive tracers. The MRE contains an integral \"history term\" modeling wake effects, which causes the force acting on a particle at some given time to depend on its full past trajectory. The history term causes complications in the numerical solution of the MRE and is therefore often neglected, despite both numerical and experimental evidence that its effects are generally not negligible. By numerically computing trajectories with and without the history term of a large number of particles in different flow fields, we investigate its impact on the large-scale Lagrangian dynamics of simulated particles. We show that for moderate to large Stokes numbers, ignoring the history term leads to significant differences in clustering patterns. Furthermore, we compute finite-time Lyapunov exponents and show that, even for small particles, the differences in the resulting scalar field from ignoring the BHT can be significant, in particular if the underlying flow is turbulent.</article>","contentLength":1190,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A modified Cayley transform for SU(3) molecular dynamics simulations","url":"https://arxiv.org/abs/2406.11337","date":1751515200,"author":"","guid":181808,"unread":true,"content":"<article>arXiv:2406.11337v2 Announce Type: replace-cross \nAbstract: We propose a modification to the Cayley transform that defines a suitable local parameterization for the special unitary group $\\mathrm{SU}(3)$. The new mapping is used to construct splitting methods for separable Hamiltonian systems whose phase space is the cotangent bundle of $\\mathrm{SU}(3)$ or, more general, $\\mathrm{SU(3)}^N$, $N \\in \\mathbb{N}$. Special attention is given to the hybrid Monte Carlo algorithm for gauge field generation in lattice quantum chromodynamics. We show that the use of the modified Cayley transform instead of the matrix exponential neither affects the time-reversibility nor the volume-preservation of the splitting method. Furthermore, the advantages and disadvantages of the Cayley-based algorithms are discussed and illustrated in pure gauge field simulations.</article>","contentLength":857,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fourier Series Guided Design of Quantum Convolutional Neural Networks for Enhanced Time Series Forecasting","url":"https://arxiv.org/abs/2404.15377","date":1751515200,"author":"","guid":181809,"unread":true,"content":"<article>arXiv:2404.15377v3 Announce Type: replace-cross \nAbstract: In this study, we apply 1D quantum convolution to address the task of time series forecasting. By encoding multiple points into the quantum circuit to predict subsequent data, each point becomes a feature, transforming the problem into a multidimensional one. Building on theoretical foundations from prior research, which demonstrated that Variational Quantum Circuits (VQCs) can be expressed as multidimensional Fourier series, we explore the capabilities of different architectures and ansatz. This analysis considers the concepts of circuit expressibility and the presence of barren plateaus. Analyzing the problem within the framework of the Fourier series enabled the design of an architecture that incorporates data reuploading, resulting in enhanced performance. Rather than a strict requirement for the number of free parameters to exceed the degrees of freedom of the Fourier series, our findings suggest that even a limited number of parameters can produce Fourier functions of higher degrees. This highlights the remarkable expressive power of quantum circuits. This observation is also significant in reducing training times. The ansatz with greater expressibility and number of non-zero Fourier coefficients consistently delivers favorable results across different scenarios, with performance metrics improving as the number of qubits increases.</article>","contentLength":1418,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Diffusion-based Iterative Counterfactual Explanations for Fetal Ultrasound Image Quality Assessment","url":"https://arxiv.org/abs/2403.08700","date":1751515200,"author":"","guid":181810,"unread":true,"content":"<article>arXiv:2403.08700v2 Announce Type: replace-cross \nAbstract: Obstetric ultrasound image quality is crucial for accurate diagnosis and monitoring of fetal health. However, acquiring high-quality standard planes is difficult, influenced by the sonographer's expertise and factors like the maternal BMI or fetus dynamics. In this work, we explore diffusion-based counterfactual explainable AI to generate realistic, high-quality standard planes from low-quality non-standard ones. Through quantitative and qualitative evaluation, we demonstrate the effectiveness of our approach in generating plausible counterfactuals of increased quality. This shows future promise for enhancing training of clinicians by providing visual feedback and potentially improving standard plane quality and acquisition for downstream diagnosis and monitoring.</article>","contentLength":833,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Upper and lower bounds for the Lipschitz constant of random neural networks","url":"https://arxiv.org/abs/2311.01356","date":1751515200,"author":"","guid":181811,"unread":true,"content":"<article>arXiv:2311.01356v4 Announce Type: replace-cross \nAbstract: Empirical studies have widely demonstrated that neural networks are highly sensitive to small, adversarial perturbations of the input. The worst-case robustness against these so-called adversarial examples can be quantified by the Lipschitz constant of the neural network. In this paper, we study upper and lower bounds for the Lipschitz constant of random ReLU neural networks. Specifically, we assume that the weights and biases follow a generalization of the He initialization, where general symmetric distributions for the biases are permitted. For deep networks of fixed depth and sufficiently large width, our established upper bound is larger than the lower bound by a factor that is logarithmic in the width. In contrast, for shallow neural networks we characterize the Lipschitz constant up to an absolute numerical constant that is independent of all parameters.</article>","contentLength":931,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rank-1 Matrix Completion with Gradient Descent and Small Random Initialization","url":"https://arxiv.org/abs/2212.09396","date":1751515200,"author":"","guid":181812,"unread":true,"content":"<article>arXiv:2212.09396v3 Announce Type: replace-cross \nAbstract: The nonconvex formulation of the matrix completion problem has received significant attention in recent years due to its affordable complexity compared to the convex formulation. Gradient Descent (GD) is a simple yet efficient baseline algorithm for solving nonconvex optimization problems. The success of GD has been witnessed in many different problems in both theory and practice when it is combined with random initialization. However, previous works on matrix completion require either careful initialization or regularizers to prove the convergence of GD. In this paper, we study the rank-1 symmetric matrix completion and prove that GD converges to the ground truth when small random initialization is used. We show that in a logarithmic number of iterations, the trajectory enters the region where local convergence occurs. We provide an upper bound on the initialization size that is sufficient to guarantee the convergence, and show that a larger initialization can be used as more samples are available. We observe that the implicit regularization effect of GD plays a critical role in the analysis, and for the entire trajectory, it prevents each entry from becoming much larger than the others.</article>","contentLength":1266,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Criteria for toroidal embedding of one-vertex ribbon graphs","url":"https://arxiv.org/abs/2208.08692","date":1751515200,"author":"","guid":181813,"unread":true,"content":"<article>arXiv:2208.08692v5 Announce Type: replace-cross \nAbstract: The work provides a brief intuitive overview theory of graph on surfaces. We considers graphs with an additional structure, wich we call discs with ribbons, also known as one-vertex ribbon graphs. And solves the problem (Skopenkov's) about criteria for toroidal embedding of one-vertex ribbon graph.</article>","contentLength":358,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Classical Simulation of High Temperature Quantum Ising Models","url":"https://arxiv.org/abs/2002.02232","date":1751515200,"author":"","guid":181814,"unread":true,"content":"<article>arXiv:2002.02232v2 Announce Type: replace-cross \nAbstract: We consider generalized quantum Ising models, including those which could describe disordered materials or quantum annealers, and we prove that for all temperatures above a system-size independent threshold the path integral Monte Carlo method based on worldline heat-bath updates always mixes to stationarity in time $\\mathcal{O}(n \\log n)$ for an $n$ qubit system, and therefore provides a fully polynomial-time approximation scheme for the partition function. This result holds whenever the temperature is greater than four plus twice the maximum interaction degree (valence) over all qubits, measured in units of the local coupling strength. For example, this implies that the classical simulation of the thermal state of a superconducting device modeling a frustrated quantum Ising model with maximum valence of 6 and coupling strengths of 1 GHz is always possible at temperatures above 800 mK. Despite the quantum system being at high temperature, the classical spin system resulting from the quantum-to-classical mapping contains strong couplings which cause the single-site Glauber dynamics to mix slowly, therefore this result depends on the use of worldline updates (which are a form of cluster updates that can be implemented efficiently). This result places definite constraints on the temperatures required for a quantum advantage in analog quantum simulation with various NISQ devices based on equilibrium states of quantum Ising models.</article>","contentLength":1510,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Linear Layouts of Graphs with Priority Queues","url":"https://arxiv.org/abs/2506.23943","date":1751515200,"author":"","guid":181815,"unread":true,"content":"<article>arXiv:2506.23943v2 Announce Type: replace \nAbstract: A linear layout of a graph consists of a linear ordering of its vertices and a partition of its edges into pages such that the edges assigned to the same page obey some constraint. The two most prominent and widely studied types of linear layouts are stack and queue layouts, in which any two edges assigned to the same page are forbidden to cross and nest, respectively. The names of these two layouts derive from the fact that, when parsing the graph according to the linear vertex ordering, the edges in a single page can be stored using a single stack or queue, respectively. Recently, the concepts of stack and queue layouts have been extended by using a double-ended queue or a restricted-input queue for storing the edges of a page. We extend this line of study to edge-weighted graphs by introducing priority queue layouts, that is, the edges on each page are stored in a priority queue whose keys are the edge weights. First, we show that there are edge-weighted graphs that require a linear number of priority queues. Second, we characterize the graphs that admit a priority queue layout with a single queue, regardless of the edge-weight function, and we provide an efficient recognition algorithm. Third, we show that the number of priority queues required independently of the edge-weight function is bounded by the pathwidth of the graph, but can be arbitrarily large already for graphs of treewidth two. Finally, we prove that determining the minimum number of priority queues is NP-complete if the linear ordering of the vertices is fixed.</article>","contentLength":1608,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Exploring Privacy and Security as Drivers for Environmental Sustainability in Cloud-Based Office Solutions","url":"https://arxiv.org/abs/2506.23866","date":1751515200,"author":"","guid":181816,"unread":true,"content":"<article>arXiv:2506.23866v2 Announce Type: replace \nAbstract: In this paper, we explore the intersection of privacy, security, and environmental sustainability in cloud-based office solutions, focusing on quantifying user- and network-side energy use and associated carbon emissions. We hypothesise that privacy-focused services are typically more energy-efficient than those funded through data collection and advertising. To evaluate this, we propose a framework that systematically measures environmental costs based on energy usage and network data traffic during well-defined, automated usage scenarios. To test our hypothesis, we first analyse how underlying architectures and business models, such as monetisation through personalised advertising, contribute to the environmental footprint of these services. We then explore existing methodologies and tools for software environmental impact assessment. We apply our framework to three mainstream email services selected to reflect different privacy policies, from ad-supported tracking-intensive models to privacy-focused designs: Microsoft Outlook, Google Mail (Gmail), and Proton Mail. We extend this comparison to a self-hosted email solution, evaluated with and without end-to-end encryption. We show that the self-hosted solution, even with 14% of device energy and 15% of emissions overheads from PGP encryption, remains the most energy-efficient, saving up to 33% of emissions per session compared to Gmail. Among commercial providers, Proton Mail is the most efficient, saving up to 0.1 gCO2 e per session compared to Outlook, whose emissions can be further reduced by 2% through ad-blocking.</article>","contentLength":1649,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Power-Gas Infrastructure Planning under Weather-induced Supply and Demand Uncertainties","url":"https://arxiv.org/abs/2506.23509","date":1751515200,"author":"","guid":181817,"unread":true,"content":"<article>arXiv:2506.23509v2 Announce Type: replace \nAbstract: Implementing economy-wide decarbonization strategies based on decarbonizing the power grid via variable renewable energy (VRE) expansion and electrification of end-uses requires new approaches for energy infrastructure planning that consider, among other factors, weather-induced uncertainty in demand and VRE supply. An energy planning model that fails to account for these uncertainties can hinder the intended transition efforts to a low-carbon grid and increase the risk of supply shortage especially during extreme weather conditions. Here, we consider the generation and transmission expansion problem of joint power-gas infrastructure and operations planning under the uncertainty of both demand and renewable supply. We propose two distributionally robust optimization approaches based on moment (MDRO) and Wasserstein distance (WDRO) ambiguity sets to endogenize these uncertainties and account for the change in the underlying distribution of these parameters that is caused by the climate change, among other factors. Furthermore, our model considers the risk-aversion of the energy planners in the modeling framework via the conditional value-at-risk (CVaR) metric. An equivalent mixed-integer linear programming (MILP) reformulation of both modeling frameworks is presented, and a computationally efficient approximation scheme to obtain near-optimal solutions is proposed. We demonstrate the resulting DRO planning models and solution strategy via a New England case study under different levels of end-use electrification and decarbonization targets. Our experiments systematically explore different modeling aspects and compare the DRO models with stochastic programming (SP) results.</article>","contentLength":1753,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Elias' Encoding from Lagrangians and Renormalization","url":"https://arxiv.org/abs/2506.23447","date":1751515200,"author":"","guid":181818,"unread":true,"content":"<article>arXiv:2506.23447v2 Announce Type: replace \nAbstract: An efficient approach to universality and optimality of binary codes for integers known as Elias' encoding can be deduced from the classical constrained optimization and renormalization techniques. The most important properties, such as being a universal prefix code, also follow naturally.</article>","contentLength":343,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Practical and Secure Byzantine Robust Aggregator","url":"https://arxiv.org/abs/2506.23183","date":1751515200,"author":"","guid":181819,"unread":true,"content":"<article>arXiv:2506.23183v2 Announce Type: replace \nAbstract: In machine learning security, one is often faced with the problem of removing outliers from a given set of high-dimensional vectors when computing their average. For example, many variants of data poisoning attacks produce gradient vectors during training that are outliers in the distribution of clean gradients, which bias the computed average used to derive the ML model. Filtering them out before averaging serves as a generic defense strategy. Byzantine robust aggregation is an algorithmic primitive which computes a robust average of vectors, in the presence of an $\\epsilon$ fraction of vectors which may have been arbitrarily and adaptively corrupted, such that the resulting bias in the final average is provably bounded.\n  In this paper, we give the first robust aggregator that runs in quasi-linear time in the size of input vectors and provably has near-optimal bias bounds. Our algorithm also does not assume any knowledge of the distribution of clean vectors, nor does it require pre-computing any filtering thresholds from it. This makes it practical to use directly in standard neural network training procedures. We empirically confirm its expected runtime efficiency and its effectiveness in nullifying 10 different ML poisoning attacks.</article>","contentLength":1309,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions","url":"https://arxiv.org/abs/2506.22941","date":1751515200,"author":"","guid":181820,"unread":true,"content":"<article>arXiv:2506.22941v2 Announce Type: replace \nAbstract: Access to accurate and actionable harm reduction information can directly impact the health outcomes of People Who Use Drugs (PWUD), yet existing online channels often fail to meet their diverse and dynamic needs due to limitations in adaptability, accessibility, and the pervasive impact of stigma. Large Language Models (LLMs) present a novel opportunity to enhance information provision, but their application in such a high-stakes domain is under-explored and presents socio-technical challenges. This paper investigates how LLMs can be responsibly designed to support the information needs of PWUD. Through a qualitative workshop involving diverse stakeholder groups (academics, harm reduction practitioners, and an online community moderator), we explored LLM capabilities, identified potential use cases, and delineated core design considerations. Our findings reveal that while LLMs can address some existing information barriers (e.g., by offering responsive, multilingual, and potentially less stigmatising interactions), their effectiveness is contingent upon overcoming challenges related to ethical alignment with harm reduction principles, nuanced contextual understanding, effective communication, and clearly defined operational boundaries. We articulate design pathways emphasising collaborative co-design with experts and PWUD to develop LLM systems that are helpful, safe, and responsibly governed. This work contributes empirically grounded insights and actionable design considerations for the responsible development of LLMs as supportive tools within the harm reduction ecosystem.</article>","contentLength":1656,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues","url":"https://arxiv.org/abs/2506.22853","date":1751515200,"author":"","guid":181821,"unread":true,"content":"<article>arXiv:2506.22853v2 Announce Type: replace \nAbstract: Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such as function name and parameter values throughout the dialogue. Analyzing existing benchmarks through DICE-SCORE reveals notably low scores, highlighting the need for more realistic scenarios. To address this gap, we present DICE-BENCH, a framework that constructs practical function-calling datasets by synthesizing conversations through a tool graph that maintains dependencies across rounds and a multi-agent system with distinct personas to enhance dialogue naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our experiments on 19 LLMs with DICE-BENCH show that significant advances are still required before such models can be deployed effectively in real-world settings. Our code and data are all publicly available: https://snuhcc.github.io/DICE-Bench/.</article>","contentLength":1135,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems","url":"https://arxiv.org/abs/2506.22648","date":1751515200,"author":"","guid":181822,"unread":true,"content":"<article>arXiv:2506.22648v2 Announce Type: replace \nAbstract: Over the past decade, recommender systems have experienced a surge in popularity. Despite notable progress, they grapple with challenging issues, such as high data dimensionality and sparseness. Representing users and items as low-dimensional embeddings learned via neural networks has become a leading solution. However, while recent studies show promising results, many approaches rely on complex architectures or require content data, which may not always be available. This paper presents Interact2Vec, a novel neural network-based model that simultaneously learns distributed embeddings for users and items while demanding only implicit feedback. The model employs state-of-the-art strategies that natural language processing models commonly use to optimize the training phase and enhance the final embeddings. Two types of experiments were conducted regarding the extrinsic and intrinsic quality of the model. In the former, we benchmarked the recommendations generated by Interact2Vec's embeddings in a top-$N$ ranking problem, comparing them with six other recommender algorithms. The model achieved the second or third-best results in 30% of the datasets, being competitive with other recommenders, and has proven to be very efficient with an average training time reduction of 274% compared to other embedding-based models. Later, we analyzed the intrinsic quality of the embeddings through similarity tables. Our findings suggest that Interact2Vec can achieve promising results, especially on the extrinsic task, and is an excellent embedding-generator model for scenarios of scarce computing resources, enabling the learning of item and user embeddings simultaneously and efficiently.</article>","contentLength":1749,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sequential Diagnosis with Language Models","url":"https://arxiv.org/abs/2506.22405","date":1751515200,"author":"","guid":181823,"unread":true,"content":"<article>arXiv:2506.22405v2 Announce Type: replace \nAbstract: Artificial intelligence holds great promise for expanding access to expert medical knowledge and reasoning. However, most evaluations of language models rely on static vignettes and multiple-choice questions that fail to reflect the complexity and nuance of evidence-based medicine in real-world settings. In clinical practice, physicians iteratively formulate and revise diagnostic hypotheses, adapting each subsequent question and test to what they've just learned, and weigh the evolving evidence before committing to a final diagnosis. To emulate this iterative process, we introduce the Sequential Diagnosis Benchmark, which transforms 304 diagnostically challenging New England Journal of Medicine clinicopathological conference (NEJM-CPC) cases into stepwise diagnostic encounters. A physician or AI begins with a short case abstract and must iteratively request additional details from a gatekeeper model that reveals findings only when explicitly queried. Performance is assessed not just by diagnostic accuracy but also by the cost of physician visits and tests performed. We also present the MAI Diagnostic Orchestrator (MAI-DxO), a model-agnostic orchestrator that simulates a panel of physicians, proposes likely differential diagnoses and strategically selects high-value, cost-effective tests. When paired with OpenAI's o3 model, MAI-DxO achieves 80% diagnostic accuracy--four times higher than the 20% average of generalist physicians. MAI-DxO also reduces diagnostic costs by 20% compared to physicians, and 70% compared to off-the-shelf o3. When configured for maximum accuracy, MAI-DxO achieves 85.5% accuracy. These performance gains with MAI-DxO generalize across models from the OpenAI, Gemini, Claude, Grok, DeepSeek, and Llama families. We highlight how AI systems, when guided to think iteratively and act judiciously, can advance diagnostic precision and cost-effectiveness in clinical care.</article>","contentLength":1970,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Nets-within-Nets through the Lens of Data Nets","url":"https://arxiv.org/abs/2506.22344","date":1751515200,"author":"","guid":181824,"unread":true,"content":"<article>arXiv:2506.22344v2 Announce Type: replace \nAbstract: Elementary Object Systems (EOSs) are a model in the nets-within-nets (NWNs) paradigm, where tokens in turn can host standard Petri nets. We study the complexity of the reachability problem of EOSs when subjected to non-deterministic token losses. It is known that this problem is equivalent to the coverability problem with no lossiness of conservative EOSs (cEOSs). We precisely characterize cEOS coverability into the framework of data nets, whose tokens carry data from an infinite domain. Specifically, we show that cEOS coverability is equivalent to the coverability of an interesting fragment of data nets that extends beyond $\\nu$PNs (featuring globally fresh name creation), yet remains less expressive than Unordered Data Nets (featuring lossy name creation as well as powerful forms of whole-place operations and broadcasts). This insight bridges two apparently orthogonal approaches to PN extensions, namely data nets and NWNs. At the same time, it enables us to analyze cEOS coverability taking advantage of known results on data nets. As a byproduct, we immediately get that the complexity of cEOS coverability lies between $\\mathbf{F}_{\\omega 2}$ and $\\mathbf{F}_{\\omega^\\omega}$, two classes beyond Primitive Recursive.</article>","contentLength":1287,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs","url":"https://arxiv.org/abs/2506.22146","date":1751515200,"author":"","guid":181825,"unread":true,"content":"<article>arXiv:2506.22146v2 Announce Type: replace \nAbstract: Despite progress in Vision-Language Models (VLMs), their capacity for visual reasoning is often limited by the \\textit{binding problem}: the failure to reliably associate perceptual features with their correct visual referents. This limitation underlies persistent errors in tasks such as counting, visual search, scene description, and spatial relationship understanding. A key factor is that current VLMs process visual features largely in parallel, lacking mechanisms for spatially grounded, serial attention. This paper introduces a simple yet effective intervention: augmenting visual inputs with low-level spatial structures (e.g., horizontal lines) and pairing this with a textual prompt that encourages sequential, spatially-aware parsing. We empirically demonstrate substantial performance improvements across core visual reasoning tasks. Specifically, our method improves GPT-4o visual search accuracy by 25.00%, increases counting accuracy by 26.83%, reduces edit distance error in scene description by 0.32, and enhances performance on spatial relationship tasks by 9.50% on a a 2D synthetic dataset. Furthermore, we find that the visual modification is essential for these gains; purely textual strategies, including Chain-of-Thought prompting, are insufficient and can even degrade performance. Our method enhances binding only with a single-query inference, underscoring the importance of visual input design over purely linguistically-based approaches. These findings suggest that low-level visual structuring is a powerful and underexplored direction for improving compositional visual reasoning and could serve as a general strategy for enhancing VLM performance on spatially grounded tasks.</article>","contentLength":1762,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Universal & Efficient Model Compression via Exponential Torque Pruning","url":"https://arxiv.org/abs/2506.22015","date":1751515200,"author":"","guid":181826,"unread":true,"content":"<article>arXiv:2506.22015v2 Announce Type: replace \nAbstract: The rapid growth in complexity and size of modern deep neural networks (DNNs) has increased challenges related to computational costs and memory usage, spurring a growing interest in efficient model compression techniques. Previous state-of-the-art approach proposes using a Torque-inspired regularization which forces the weights of neural modules around a selected pivot point. Whereas, we observe that the pruning effect of this approach is far from perfect, as the post-trained network is still dense and also suffers from high accuracy drop. In this work, we attribute such ineffectiveness to the default linear force application scheme, which imposes inappropriate force on neural module of different distances. To efficiently prune the redundant and distant modules while retaining those that are close and necessary for effective inference, in this work, we propose Exponential Torque Pruning (ETP), which adopts an exponential force application scheme for regularization. Experimental results on a broad range of domains demonstrate that, though being extremely simple, ETP manages to achieve significantly higher compression rate than the previous state-of-the-art pruning strategies with negligible accuracy drop.</article>","contentLength":1277,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LinguaSynth: Heterogeneous Linguistic Signals for News Classification","url":"https://arxiv.org/abs/2506.21848","date":1751515200,"author":"","guid":181827,"unread":true,"content":"<article>arXiv:2506.21848v2 Announce Type: replace \nAbstract: Deep learning has significantly advanced NLP, but its reliance on large black-box models introduces critical interpretability and computational efficiency concerns. This paper proposes LinguaSynth, a novel text classification framework that strategically integrates five complementary linguistic feature types: lexical, syntactic, entity-level, word-level semantics, and document-level semantics within a transparent logistic regression model. Unlike transformer-based architectures, LinguaSynth maintains interpretability and computational efficiency, achieving an accuracy of 84.89 percent on the 20 Newsgroups dataset and surpassing a robust TF-IDF baseline by 3.32 percent. Through rigorous feature interaction analysis, we show that syntactic and entity-level signals provide essential disambiguation and effectively complement distributional semantics. LinguaSynth sets a new benchmark for interpretable, resource-efficient NLP models and challenges the prevailing assumption that deep neural networks are necessary for high-performing text classification.</article>","contentLength":1115,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Neural Network Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning","url":"https://arxiv.org/abs/2506.21797","date":1751515200,"author":"","guid":181828,"unread":true,"content":"<article>arXiv:2506.21797v2 Announce Type: replace \nAbstract: We develop a theoretical framework that explains how discrete symbolic structures can emerge naturally from continuous neural network training dynamics. By lifting neural parameters to a measure space and modeling training as Wasserstein gradient flow, we show that under geometric constraints, such as group invariance, the parameter measure $\\mu_t$ undergoes two concurrent phenomena: (1) a decoupling of the gradient flow into independent optimization trajectories over some potential functions, and (2) a progressive contraction on the degree of freedom. These potentials encode algebraic constraints relevant to the task and act as ring homomorphisms under a commutative semi-ring structure on the measure space. As training progresses, the network transitions from a high-dimensional exploration to compositional representations that comply with algebraic operations and exhibit a lower degree of freedom. We further establish data scaling laws for realizing symbolic tasks, linking representational capacity to the group invariance that facilitates symbolic solutions. This framework charts a principled foundation for understanding and designing neurosymbolic systems that integrate continuous learning with discrete algebraic reasoning.</article>","contentLength":1298,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hierarchical Patch Compression for ColPali: Efficient Multi-Vector Document Retrieval with Dynamic Pruning and Quantization","url":"https://arxiv.org/abs/2506.21601","date":1751515200,"author":"","guid":181829,"unread":true,"content":"<article>arXiv:2506.21601v2 Announce Type: replace \nAbstract: Multi-vector document retrieval systems, such as ColPali, excel in fine-grained matching for complex queries but incur significant storage and computational costs due to their reliance on high-dimensional patch embeddings and late-interaction scoring. To address these challenges, we propose HPC-ColPali, a Hierarchical Patch Compression framework that enhances the efficiency of ColPali while preserving its retrieval accuracy. Our approach integrates three innovative techniques: (1) K-Means quantization, which compresses patch embeddings into 1-byte centroid indices, achieving up to 32$\\times$ storage reduction; (2) attention-guided dynamic pruning, utilizing Vision-Language Model attention weights to retain only the top-$p\\%$ most salient patches, reducing late-interaction computation by up to 60\\% with less than 2\\% nDCG@10 loss; and (3) optional binary encoding of centroid indices into $b$-bit strings ($b=\\lceil\\log_2 K\\rceil$), enabling rapid Hamming distance-based similarity search for resource-constrained environments. Evaluated on the ViDoRe and SEC-Filings datasets, HPC-ColPali achieves 30--50\\% lower query latency under HNSW indexing while maintaining high retrieval precision. When integrated into a Retrieval-Augmented Generation pipeline for legal summarization, it reduces hallucination rates by 30\\% and halves end-to-end latency. These advancements establish HPC-ColPali as a scalable and efficient solution for multi-vector document retrieval across diverse applications. Code is available at https://github.com/DngBack/HPC-ColPali.</article>","contentLength":1617,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining","url":"https://arxiv.org/abs/2506.21567","date":1751515200,"author":"","guid":181830,"unread":true,"content":"<article>arXiv:2506.21567v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have recently gained attention in the life sciences due to their capacity to model, extract, and apply complex biological information. Beyond their classical use as chatbots, these systems are increasingly used for complex analysis and problem-solving in specialized fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset from over 10,000 scientific articles, textbooks, and medical websites. BioParsQA was also introduced to evaluate the proposed model, which consists of 5,231 Persian medical questions and answers. This study then introduces BioPars, a simple but accurate measure designed to assess LLMs for three main abilities: acquiring subject-specific knowledge, interpreting and synthesizing such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama, and Galactica, our study highlights their ability to remember and retrieve learned knowledge but also reveals shortcomings in addressing higher-level, real-world questions and fine-grained inferences. These findings indicate the need for further fine-tuning to address the capabilities of LLM in bioinformatics tasks. To our knowledge, BioPars is the first application of LLM in Persian medical QA, especially for generating long answers. Evaluation of four selected medical QA datasets shows that BioPars has achieved remarkable results compared to comparative approaches. The model on BioParsQA achieved a ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT values were also higher in this model than the other three models. In addition, the reported scores for the model are MoverScore=60.43 and BLEURT=50.78. BioPars is an ongoing project and all resources related to its development will be made available via the following GitHub repository: https://github.com/amirap80/BioPars.</article>","contentLength":1968,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Generalizable Neural Electromagnetic Inverse Scattering","url":"https://arxiv.org/abs/2506.21349","date":1751515200,"author":"","guid":181831,"unread":true,"content":"<article>arXiv:2506.21349v2 Announce Type: replace \nAbstract: Solving Electromagnetic Inverse Scattering Problems (EISP) is fundamental in applications such as medical imaging, where the goal is to reconstruct the relative permittivity from scattered electromagnetic field. This inverse process is inherently ill-posed and highly nonlinear, making it particularly challenging. A recent machine learning-based approach, Img-Interiors, shows promising results by leveraging continuous implicit functions. However, it requires case-specific optimization, lacks generalization to unseen data, and fails under sparse transmitter setups (e.g., with only one transmitter). To address these limitations, we revisit EISP from a physics-informed perspective, reformulating it as a two stage inverse transmission-scattering process. This formulation reveals the induced current as a generalizable intermediate representation, effectively decoupling the nonlinear scattering process from the ill-posed inverse problem. Built on this insight, we propose the first generalizable physics-driven framework for EISP, comprising a current estimator and a permittivity solver, working in an end-to-end manner. The current estimator explicitly learns the induced current as a physical bridge between the incident and scattered field, while the permittivity solver computes the relative permittivity directly from the estimated induced current. This design enables data-driven training and generalizable feed-forward prediction of relative permittivity on unseen data while maintaining strong robustness to transmitter sparsity. Extensive experiments show that our method outperforms state-of-the-art approaches in reconstruction accuracy, generalization, and robustness. This work offers a fundamentally new perspective on electromagnetic inverse scattering and represents a major step toward cost-effective practical solutions for electromagnetic imaging.</article>","contentLength":1927,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"World-aware Planning Narratives Enhance Large Vision-Language Model Planner","url":"https://arxiv.org/abs/2506.21230","date":1751515200,"author":"","guid":181832,"unread":true,"content":"<article>arXiv:2506.21230v2 Announce Type: replace \nAbstract: Large Vision-Language Models (LVLMs) show promise for embodied planning tasks but struggle with complex scenarios involving unfamiliar environments and multi-step goals. Current approaches rely on environment-agnostic imitation learning that disconnects instructions from environmental contexts, causing models to struggle with context-sensitive instructions and rely on supplementary cues rather than visual reasoning during long-horizon interactions. In this work, we propose World-Aware Planning Narrative Enhancement (WAP), a framework that infuses LVLMs with comprehensive environmental understanding through four cognitive capabilities (visual appearance modeling, spatial reasoning, functional abstraction, and syntactic grounding) while developing and evaluating models using only raw visual observations through curriculum learning. Evaluations on the EB-ALFRED benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a 60.7 absolute improvement in task success rates, particularly in commonsense reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced open-source models outperform proprietary systems like GPT-4o and Claude-3.5-Sonnet by a large margin.</article>","contentLength":1254,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On $NP \\cap coNP$ proof complexity generators","url":"https://arxiv.org/abs/2506.20221","date":1751515200,"author":"","guid":181833,"unread":true,"content":"<article>arXiv:2506.20221v2 Announce Type: replace \nAbstract: Motivated by the theory of proof complexity generators we consider the following $\\Sigma^p_2$ search problem $\\mbox{DD}_P$ determined by a propositional proof system $P$: given a $P$-proof $\\pi$ of a disjunction $\\bigvee_i \\alpha_i$, no two $\\alpha_i$ having an atom in common, find $i$ such that $\\alpha_i \\in \\mbox{TAUT}$. We formulate a hypothesis (ST) that for some strong proof system $P$ the problem $\\mbox{DD}_P$ is not solvable in the student-teacher model with a p-time student and a constant number of rounds. The hypothesis follows from the existence of hard one-way permutations. We prove, using a model-theoretic assumption, that (ST) implies $NP \\neq coNP$. The assumption concerns the existence of extensions of models of a bounded arithmetic theory and it is open at present if it holds.</article>","contentLength":856,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Breaking the Boundaries of Long-Context LLM Inference: Adaptive KV Management on a Single Commodity GPU","url":"https://arxiv.org/abs/2506.20187","date":1751515200,"author":"","guid":181834,"unread":true,"content":"<article>arXiv:2506.20187v2 Announce Type: replace \nAbstract: Advanced Large Language Models (LLMs) have achieved impressive performance across a wide range of complex and long-context natural language tasks. However, performing long-context LLM inference locally on a commodity GPU (a PC) with privacy concerns remains challenging due to the increasing memory demands of the key-value (KV) cache. Existing systems typically identify important tokens and selectively offload their KV data to GPU and CPU memory. The KV data needs to be offloaded to disk due to the limited memory on a commodity GPU, but the process is bottlenecked by token importance evaluation overhead and the disk's low bandwidth. In this paper, we present LeoAM, the first efficient importance-aware long-context LLM inference system for a single commodity GPU with adaptive hierarchical GPU-CPU-Disk KV management. Our system employs an adaptive KV management strategy that partitions KV data into variable-sized chunks based on the skewed distribution of attention weights across different layers to reduce computational and additional transmission overheads. Moreover, we propose a lightweight KV abstract method, which minimizes transmission latency by storing and extracting the KV abstract of each chunk on disk instead of the full KV data. LeoAM also leverages the dynamic compression and pipeline techniques to further accelerate inference. Experimental results demonstrate that LongInfer achieves an average inference latency speedup of 3.46x, while maintaining comparable LLM response quality. In scenarios with larger batch sizes, it achieves up to a 5.47x speedup.</article>","contentLength":1639,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design","url":"https://arxiv.org/abs/2506.19997","date":1751515200,"author":"","guid":181835,"unread":true,"content":"<article>arXiv:2506.19997v2 Announce Type: replace \nAbstract: Generalizing deep reinforcement learning agents to unseen environments remains a significant challenge. One promising solution is Unsupervised Environment Design (UED), a co-evolutionary framework in which a teacher adaptively generates tasks with high learning potential, while a student learns a robust policy from this evolving curriculum. Existing UED methods typically measure learning potential via regret, the gap between optimal and current performance, approximated solely by value-function loss. Building on these approaches, we introduce the transition prediction error as an additional term in our regret approximation. To capture how training on one task affects performance on others, we further propose a lightweight metric called co-learnability. By combining these two measures, we present Transition-aware Regret Approximation with Co-learnability for Environment Design (TRACED). Empirical evaluations show that TRACED yields curricula that improve zero-shot generalization across multiple benchmarks while requiring up to 2x fewer environment interactions than strong baselines. Ablation studies confirm that the transition prediction error drives rapid complexity ramp-up and that co-learnability delivers additional gains when paired with the transition prediction error. These results demonstrate how refined regret approximation and explicit modeling of task relationships can be leveraged for sample-efficient curriculum design in UED.</article>","contentLength":1513,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Approximating Submodular Matroid-Constrained Partitioning","url":"https://arxiv.org/abs/2506.19507","date":1751515200,"author":"","guid":181836,"unread":true,"content":"<article>arXiv:2506.19507v2 Announce Type: replace \nAbstract: The submodular partitioning problem asks to minimize, over all partitions $P$ of a ground set $V$, the sum of a given submodular function $f$ over the parts of $P$. The problem has seen considerable work in approximability, as it encompasses multiterminal cuts on graphs, $k$-cuts on hypergraphs, and elementary linear algebra problems such as matrix multiway partitioning. This research has been divided between the fixed terminal setting, where we are given a set of terminals that must be separated by $P$, and the global setting, where the only constraint is the size of the partition. We investigate a generalization that unifies these two settings: minimum submodular matroid-constrained partition. In this problem, we are additionally given a matroid over the ground set and seek to find a partition $P$ in which there exists some basis that is separated by $P$. We explore the approximability of this problem and its variants, reaching the state of the art for the special case of symmetric submodular functions, and provide results for monotone and general submodular functions as well.</article>","contentLength":1148,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TC-Light: Temporally Coherent Generative Rendering for Realistic World Transfer","url":"https://arxiv.org/abs/2506.18904","date":1751515200,"author":"","guid":181837,"unread":true,"content":"<article>arXiv:2506.18904v2 Announce Type: replace \nAbstract: Illumination and texture editing are critical dimensions for world-to-world transfer, which is valuable for applications including sim2real and real2real visual data scaling up for embodied AI. Existing techniques generatively re-render the input video to realize the transfer, such as video relighting models and conditioned world generation models. Nevertheless, these models are predominantly limited to the domain of training data (e.g., portrait) or fall into the bottleneck of temporal consistency and computation efficiency, especially when the input video involves complex dynamics and long durations. In this paper, we propose TC-Light, a novel generative renderer to overcome these problems. Starting from the video preliminarily relighted by an inflated video relighting model, it optimizes appearance embedding in the first stage to align global illumination. Then it optimizes the proposed canonical video representation, i.e., Unique Video Tensor (UVT), to align fine-grained texture and lighting in the second stage. To comprehensively evaluate performance, we also establish a long and highly dynamic video benchmark. Extensive experiments show that our method enables physically plausible re-rendering results with superior temporal coherence and low computation cost. The code and video demos are available at https://dekuliutesla.github.io/tclight/.</article>","contentLength":1421,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection","url":"https://arxiv.org/abs/2506.18368","date":1751515200,"author":"","guid":181838,"unread":true,"content":"<article>arXiv:2506.18368v2 Announce Type: replace \nAbstract: Detecting anomalous human behaviour is an important visual task in safety-critical applications such as healthcare monitoring, workplace safety, or public surveillance. In these contexts, abnormalities are often reflected with unusual human poses. Thus, we propose SeeKer, a method for detecting anomalies in sequences of human skeletons. Our method formulates the skeleton sequence density through autoregressive factorization at the keypoint level. The corresponding conditional distributions represent probable keypoint locations given prior skeletal motion. We formulate the joint distribution of the considered skeleton as causal prediction of conditional Gaussians across its constituent keypoints. A skeleton is flagged as anomalous if its keypoint locations surprise our model (i.e. receive a low density). In practice, our anomaly score is a weighted sum of per-keypoint log-conditionals, where the weights account for the confidence of the underlying keypoint detector. Despite its conceptual simplicity, SeeKer surpasses all previous methods on the UBnormal and MSAD-HR datasets while delivering competitive performance on the ShanghaiTech dataset.</article>","contentLength":1212,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?","url":"https://arxiv.org/abs/2506.18183","date":1751515200,"author":"","guid":181839,"unread":true,"content":"<article>arXiv:2506.18183v2 Announce Type: replace \nAbstract: Reasoning language models have set state-of-the-art (SOTA) records on many challenging benchmarks, enabled by multi-step reasoning induced using reinforcement learning. However, like previous language models, reasoning models are prone to generating confident, plausible responses that are incorrect (hallucinations). Knowing when and how much to trust these models is critical to the safe deployment of reasoning models in real-world applications. To this end, we explore uncertainty quantification of reasoning models in this work. Specifically, we ask three fundamental questions: First, are reasoning models well-calibrated? Second, does deeper reasoning improve model calibration? Finally, inspired by humans' innate ability to double-check their thought processes to verify the validity of their answers and their confidence, we ask: can reasoning models improve their calibration by explicitly reasoning about their chain-of-thought traces? We introduce introspective uncertainty quantification (UQ) to explore this direction. In extensive evaluations on SOTA reasoning models across a broad range of benchmarks, we find that reasoning models: (i) are typically overconfident, with self-verbalized confidence estimates often greater than 85% particularly for incorrect responses, (ii) become even more overconfident with deeper reasoning, and (iii) can become better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we conclude with important research directions to design necessary UQ benchmarks and improve the calibration of reasoning models.</article>","contentLength":1705,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DRST: a Non-Intrusive Framework for Performance Analysis in Softwarized Networks","url":"https://arxiv.org/abs/2506.17658","date":1751515200,"author":"","guid":181840,"unread":true,"content":"<article>arXiv:2506.17658v2 Announce Type: replace \nAbstract: The last decade has witnessed the proliferation of network function virtualization (NFV) in the telco industry, thanks to its unparalleled flexibility, scalability, and cost-effectiveness. However, as the NFV infrastructure is shared by virtual network functions (VNFs), sporadic resource contentions are inevitable. Such contention makes it extremely challenging to guarantee the performance of the provisioned network services, especially in high-speed regimes (e.g., Gigabit Ethernet). Existing solutions typically rely on direct traffic analysis (e.g., packet- or flow-level measurements) to detect performance degradation and identify bottlenecks, which is not always applicable due to significant integration overhead and system-level constraints. This paper complements existing solutions with a lightweight, non-intrusive framework for online performance inference that easily adapts to drift (i.e., a change over time of the actual state of our system). Instead of direct data-plane collection, we reuse hardware features in the underlying NFV infrastructure, introducing negligible interference in the data-plane. Our Drift-Resilient and Self-Tuning (DRST) framework can be integrated into existing NFV systems with minimal engineering effort and operate without the need for predefined traffic models or VNF-specific customization. DRST is deployed via a lightweight MLOps pipeline that automates the adaptation under runtime drift. We show how DRST can deliver accurate performance inference or diagnose run-time bottlenecks, as demonstrated through a comprehensive evaluation across diverse NFV scenarios.</article>","contentLength":1671,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Safety Evaluations of Theory of Mind in Large Language Models","url":"https://arxiv.org/abs/2506.17352","date":1751515200,"author":"","guid":181841,"unread":true,"content":"<article>arXiv:2506.17352v2 Announce Type: replace \nAbstract: As the capabilities of large language models (LLMs) continue to advance, the importance of rigorous safety evaluation is becoming increasingly evident. Recent concerns within the realm of safety assessment have highlighted instances in which LLMs exhibit behaviors that appear to disable oversight mechanisms and respond in a deceptive manner. For example, there have been reports suggesting that, when confronted with information unfavorable to their own persistence during task execution, LLMs may act covertly and even provide false answers to questions intended to verify their behavior. To evaluate the potential risk of such deceptive actions toward developers or users, it is essential to investigate whether these behaviors stem from covert, intentional processes within the model. In this study, we propose that it is necessary to measure the theory of mind capabilities of LLMs. We begin by reviewing existing research on theory of mind and identifying the perspectives and tasks relevant to its application in safety evaluation. Given that theory of mind has been predominantly studied within the context of developmental psychology, we analyze developmental trends across a series of open-weight LLMs. Our results indicate that while LLMs have improved in reading comprehension, their theory of mind capabilities have not shown comparable development. Finally, we present the current state of safety evaluation with respect to LLMs' theory of mind, and discuss remaining challenges for future work.</article>","contentLength":1563,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FramePrompt: In-context Controllable Animation with Zero Structural Changes","url":"https://arxiv.org/abs/2506.17301","date":1751515200,"author":"","guid":181842,"unread":true,"content":"<article>arXiv:2506.17301v2 Announce Type: replace \nAbstract: Generating controllable character animation from a reference image and motion guidance remains a challenging task due to the inherent difficulty of injecting appearance and motion cues into video diffusion models. Prior works often rely on complex architectures, explicit guider modules, or multi-stage processing pipelines, which increase structural overhead and hinder deployment. Inspired by the strong visual context modeling capacity of pre-trained video diffusion transformers, we propose FramePrompt, a minimalist yet powerful framework that treats reference images, skeleton-guided motion, and target video clips as a unified visual sequence. By reformulating animation as a conditional future prediction task, we bypass the need for guider networks and structural modifications. Experiments demonstrate that our method significantly outperforms representative baselines across various evaluation metrics while also simplifying training. Our findings highlight the effectiveness of sequence-level visual conditioning and demonstrate the potential of pre-trained models for controllable animation without architectural changes.</article>","contentLength":1187,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Neural Prioritisation for Web Crawling","url":"https://arxiv.org/abs/2506.16146","date":1751515200,"author":"","guid":181843,"unread":true,"content":"<article>arXiv:2506.16146v2 Announce Type: replace \nAbstract: Given the vast scale of the Web, crawling prioritisation techniques based on link graph traversal, popularity, link analysis, and textual content are frequently applied to surface documents that are most likely to be valuable. While existing techniques are effective for keyword-based search, both retrieval methods and user search behaviours are shifting from keyword-based matching to natural language semantic matching. The remarkable success of applying semantic matching and quality signals during ranking leads us to hypothesize that crawling could be improved by prioritizing Web pages with high semantic quality. To investigate this, we propose a semantic quality-driven prioritisation technique to enhance the effectiveness of crawling and align the crawler behaviour with recent shift towards natural language search. We embed semantic understanding directly into the crawling process -- leveraging recent neural semantic quality estimators to prioritise the crawling frontier -- with the goal of surfacing content that is semantically rich and valuable for modern search needs. Our experiments on the English subset of ClueWeb22-B and the Researchy Questions query set show that, compared to existing crawling techniques, neural crawling policies significantly improve harvest rate, maxNDCG, and search effectiveness during the early stages of crawling. Meanwhile, crawlers based on our proposed neural policies maintain comparable search performance on keyword queries from the MS MARCO Web Search query set. While this work does not propose a definitive and complete solution, it presents a forward-looking perspective on Web crawling and opens the door to a new line of research on leveraging semantic analysis to effectively align crawlers with the ongoing shift toward natural language search.</article>","contentLength":1862,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GratNet: A Photorealistic Neural Shader for Diffractive Surfaces","url":"https://arxiv.org/abs/2506.15815","date":1751515200,"author":"","guid":181844,"unread":true,"content":"<article>arXiv:2506.15815v2 Announce Type: replace \nAbstract: Structural coloration is commonly modeled using wave optics for reliable and photorealistic rendering of natural, quasi-periodic and complex nanostructures. Such models often rely on dense, preliminary or preprocessed data to accurately capture the nuanced variations in diffractive surface reflectances. This heavy data dependency warrants implicit neural representation which has not been addressed comprehensively in the current literature. In this paper, we present a multi-layer perceptron (MLP) based method for data-driven rendering of diffractive surfaces with high accuracy and efficiency. We primarily approach this problem from a data compression perspective to devise a nuanced training and modeling method which is attuned to the domain and range characteristics of diffractive reflectance datasets. Importantly, our approach avoids over-fitting and has robust resampling behavior. Using Peak-Signal-to-Noise (PSNR), Structural Similarity Index Measure (SSIM) and a flipping difference evaluator (FLIP) as evaluation metrics, we demonstrate the high-quality reconstruction of the ground-truth. In comparison to a recent state-of-the-art offline, wave-optical, forward modeling approach, our method reproduces subjectively similar results with significant performance gains. We reduce the memory footprint of the raw datasets by two orders of magnitude in general. Lastly, we depict the working of our method with actual surface renderings.</article>","contentLength":1505,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model","url":"https://arxiv.org/abs/2506.15682","date":1751515200,"author":"","guid":181845,"unread":true,"content":"<article>arXiv:2506.15682v2 Announce Type: replace \nAbstract: Diffusion-based image generation models excel at producing high-quality synthetic content, but suffer from slow and computationally expensive inference. Prior work has attempted to mitigate this by caching and reusing features within diffusion transformers across inference steps. These methods, however, often rely on rigid heuristics that result in limited acceleration or poor generalization across architectures. We propose Evolutionary Caching to Accelerate Diffusion models (ECAD), a genetic algorithm that learns efficient, per-model, caching schedules forming a Pareto frontier, using only a small set of calibration prompts. ECAD requires no modifications to network parameters or reference images. It offers significant inference speedups, enables fine-grained control over the quality-latency trade-off, and adapts seamlessly to different diffusion models. Notably, ECAD's learned schedules can generalize effectively to resolutions and model variants not seen during calibration. We evaluate ECAD on PixArt-alpha, PixArt-Sigma, and FLUX-1$.$dev using multiple metrics (FID, CLIP, Image Reward) across diverse benchmarks (COCO, MJHQ-30k, PartiPrompts), demonstrating consistent improvements over previous approaches. On PixArt-alpha, ECAD identifies a schedule that outperforms the previous state-of-the-art method by 4.47 COCO FID while increasing inference speedup from 2.35x to 2.58x. Our results establish ECAD as a scalable and generalizable approach for accelerating diffusion inference. Our project website is available at https://aniaggarwal.github.io/ecad and our code is available at https://github.com/aniaggarwal/ecad.</article>","contentLength":1694,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits","url":"https://arxiv.org/abs/2506.14988","date":1751515200,"author":"","guid":181846,"unread":true,"content":"<article>arXiv:2506.14988v2 Announce Type: replace \nAbstract: We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at ensuring fair outcomes across agents while maximizing overall system performance. A key challenge in this setting is decision-making under limited information about arm rewards. To address this, we introduce a novel probing framework that strategically gathers information about selected arms before allocation. In the offline setting, where reward distributions are known, we leverage submodular properties to design a greedy probing algorithm with a provable performance bound. For the more complex online setting, we develop an algorithm that achieves sublinear regret while maintaining fairness. Extensive experiments on synthetic and real-world datasets show that our approach outperforms baseline methods, achieving better fairness and efficiency.</article>","contentLength":878,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GraphGSOcc: Semantic-Geometric Graph Transformer with Dynamic-Static Decoupling for 3D Gaussian Splatting-based Occupancy Prediction","url":"https://arxiv.org/abs/2506.14825","date":1751515200,"author":"","guid":181847,"unread":true,"content":"<article>arXiv:2506.14825v2 Announce Type: replace \nAbstract: Addressing the task of 3D semantic occupancy prediction for autonomous driving, we tackle two key issues in existing 3D Gaussian Splatting (3DGS) methods: (1) unified feature aggregation neglecting semantic correlations among similar categories and across regions, (2) boundary ambiguities caused by the lack of geometric constraints in MLP iterative optimization and (3) biased issues in dynamic-static object coupling optimization. We propose the GraphGSOcc model, a novel framework that combines semantic and geometric graph Transformer and decouples dynamic-static objects optimization for 3D Gaussian Splatting-based Occupancy Prediction. We propose the Dual Gaussians Graph Attenntion, which dynamically constructs dual graph structures: a geometric graph adaptively calculating KNN search radii based on Gaussian poses, enabling large-scale Gaussians to aggregate features from broader neighborhoods while compact Gaussians focus on local geometric consistency; a semantic graph retaining top-M highly correlated nodes via cosine similarity to explicitly encode semantic relationships within and across instances. Coupled with the Multi-scale Graph Attention framework, fine-grained attention at lower layers optimizes boundary details, while coarsegrained attention at higher layers models object-level topology. On the other hand, we decouple dynamic and static objects by leveraging semantic probability distributions and design a Dynamic-Static Decoupled Gaussian Attention mechanism to optimize the prediction performance for both dynamic objects and static scenes. GraphGSOcc achieves state-ofthe-art performance on the SurroundOcc-nuScenes, Occ3D-nuScenes, OpenOcc and KITTI occupancy benchmarks. Experiments on the SurroundOcc dataset achieve an mIoU of 25.20%, reducing GPU memory to 6.8 GB, demonstrating a 1.97% mIoU improvement and 13.7% memory reduction compared to GaussianWorld.</article>","contentLength":1953,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SimBank: from Simulation to Solution in Prescriptive Process Monitoring","url":"https://arxiv.org/abs/2506.14772","date":1751515200,"author":"","guid":181848,"unread":true,"content":"<article>arXiv:2506.14772v3 Announce Type: replace \nAbstract: Prescriptive Process Monitoring (PresPM) is an emerging area within Process Mining, focused on optimizing processes through real-time interventions for effective decision-making. PresPM holds significant promise for organizations seeking enhanced operational performance. However, the current literature faces two key limitations: a lack of extensive comparisons between techniques and insufficient evaluation approaches. To address these gaps, we introduce SimBank: a simulator designed for accurate benchmarking of PresPM methods. Modeled after a bank's loan application process, SimBank enables extensive comparisons of both online and offline PresPM methods. It incorporates a variety of intervention optimization problems with differing levels of complexity and supports experiments on key causal machine learning challenges, such as assessing a method's robustness to confounding in data. SimBank additionally offers a comprehensive evaluation capability: for each test case, it can generate the true outcome under each intervention action, which is not possible using recorded datasets. The simulator incorporates parallel activities and loops, drawing from common logs to generate cases that closely resemble real-life process instances. Our proof of concept demonstrates SimBank's benchmarking capabilities through experiments with various PresPM methods across different interventions, highlighting its value as a publicly available simulator for advancing research and practice in PresPM.</article>","contentLength":1552,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments","url":"https://arxiv.org/abs/2506.13205","date":1751515200,"author":"","guid":181849,"unread":true,"content":"<article>arXiv:2506.13205v4 Announce Type: replace \nAbstract: With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.</article>","contentLength":1823,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A polynomial delay algorithm generating all potential maximal cliques in triconnected planar graphs","url":"https://arxiv.org/abs/2506.12635","date":1751515200,"author":"","guid":181850,"unread":true,"content":"<article>arXiv:2506.12635v2 Announce Type: replace \nAbstract: We develop a new characterization of potential maximal cliques of a triconnected planar graph and, using this characterization, give a polynomial delay algorithm generating all potential maximal cliques of a given triconnected planar graph. Combined with the dynamic programming algorithms due to Bouchitt{\\'e} and Todinca, this algorithm leads to a treewidth algorithm for general planar graphs that runs in time linear in the number of potential maximal cliques and polynomial in the number of vertices.</article>","contentLength":558,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Practical colinear chaining on sequences revisited","url":"https://arxiv.org/abs/2506.11750","date":1751515200,"author":"","guid":181851,"unread":true,"content":"<article>arXiv:2506.11750v3 Announce Type: replace \nAbstract: Colinear chaining is a classical heuristic for sequence alignment and is widely used in modern practical aligners. Jain et al. (J. Comput. Biol. 2022) proposed an $O(n \\log^3 n)$ time algorithm to chain a set of $n$ anchors so that the chaining cost matches the edit distance of the input sequences, when anchors are all the maximal exact matches. Moreover, assuming a uniform and sparse distribution of anchors, they provided a practical solution ($\\mathtt{ChainX}$) working in $O(n \\cdot \\mathrm{SOL} + n \\log n)$ average-case time, where $\\mathrm{SOL}$ is the cost of the output chain. This practical solution is not guaranteed to be optimal: we study the failing cases, introduce the anchor diagonal distance, and find and implement an optimal algorithm working in $O(n \\cdot \\mathrm{OPT} + n \\log n)$ average-case time, where $\\mathrm{OPT}$ $\\le \\mathrm{SOL}$ is the optimal chaining cost. We validate the results by Jain et al., show that $\\mathtt{ChainX}$ can be suboptimal with a realistic long read dataset, and show minimal computational slowdown for our solution.</article>","contentLength":1127,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"15,500 Seconds: Lean UAV Classification Leveraging PEFT and Pre-Trained Networks","url":"https://arxiv.org/abs/2506.11049","date":1751515200,"author":"","guid":181852,"unread":true,"content":"<article>arXiv:2506.11049v2 Announce Type: replace \nAbstract: Unmanned Aerial Vehicles (UAVs) pose an escalating security concerns as the market for consumer and military UAVs grows. This paper address the critical data scarcity challenges in deep UAV audio classification. We build upon our previous work expanding novel approaches such as: parameter efficient fine-tuning, data augmentation, and pre-trained networks. We achieve performance upwards of 95\\% validation accuracy with EfficientNet-B0.</article>","contentLength":491,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Automated Synthesis of Formally Verified Multi-Abstraction Function Summaries","url":"https://arxiv.org/abs/2506.09550","date":1751515200,"author":"","guid":181853,"unread":true,"content":"<article>arXiv:2506.09550v2 Announce Type: replace \nAbstract: Function summaries, which characterize the behavior of code segments (typically functions) through preconditions and postconditions, are essential for understanding, reusing, and verifying software, particularly in safety-critical domains like aerospace embedded systems. However, these mission-critical legacy code serving as a valuable reused asset often lacks formal specifications. It is challenging to automatically generate function summaries for C programs, due to the existence of complex features such as loops, nested function calls, pointer aliasing, and so on. Moreover, function summaries should support multiple abstraction levels to meet diverse requirements, e.g. precise summaries capturing full functionality for formal verification and intuitive summaries for human understanding.\n  To address these challenges, we first propose a novel framework that combines symbolic execution, large language models (LLMs), and formal verification to generate Relatively Strongest Postconditions (RSPs) and build function summaries that fully capture program behavior. Our approach leverages VST-A's symbolic execution to precisely track program execution paths and state transitions, employs LLMs to infer loop invariants based on predefined templates, and uses Frama-C to guarantee soundness of generated summaries in an iterative refinement loop. Furthermore, from generated RSPs, we automatically synthesize strongest non-redundant postconditions expressed within given domain specific language. We compare our approach with existing work through extensive experiments.</article>","contentLength":1632,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information","url":"https://arxiv.org/abs/2506.09548","date":1751515200,"author":"","guid":181854,"unread":true,"content":"<article>arXiv:2506.09548v2 Announce Type: replace \nAbstract: In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which is robust to challenging conditions such as featureless environments and deformable terrains. We developed an online learning-based leg kinematics model named the neural leg kinematics model, which incorporates tactile information (foot reaction force) to implicitly express the nonlinear dynamics between robot feet and the ground. Online training of this model enhances its adaptability to weight load changes of a robot (e.g., assuming delivery or transportation tasks) and terrain conditions. According to the \\textit{neural adaptive leg odometry factor} and online uncertainty estimation of the leg kinematics model-based motion predictions, we jointly solve online training of this kinematics model and odometry estimation on a unified factor graph to retain the consistency of both. The proposed method was verified through real experiments using a quadruped robot in two challenging situations: 1) a sandy beach, representing an extremely featureless area with a deformable terrain, and 2) a campus, including multiple featureless areas and terrain types of asphalt, gravel (deformable terrain), and grass. Experimental results showed that our odometry estimation incorporating the \\textit{neural leg kinematics model} outperforms state-of-the-art works. Our project page is available for further details: https://takuokawara.github.io/RAL2025_project_page/</article>","contentLength":1491,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers","url":"https://arxiv.org/abs/2506.08641","date":1751515200,"author":"","guid":181855,"unread":true,"content":"<article>arXiv:2506.08641v2 Announce Type: replace \nAbstract: Time series classification is a fundamental task in healthcare and industry, yet the development of time series foundation models (TSFMs) remains limited by the scarcity of publicly available time series datasets. In this work, we propose Time Vision Transformer (TiViT), a framework that converts time series into images to leverage the representational power of frozen Vision Transformers (ViTs) pretrained on large-scale image datasets. First, we theoretically motivate our approach by analyzing the 2D patching of ViTs for time series, showing that it can increase the number of label-relevant tokens and reduce the sample complexity. Second, we empirically demonstrate that TiViT achieves state-of-the-art performance on standard time series classification benchmarks by utilizing the hidden representations of large OpenCLIP models. We explore the structure of TiViT representations and find that intermediate layers with high intrinsic dimension are the most effective for time series classification. Finally, we assess the alignment between TiViT and TSFM representation spaces and identify a strong complementarity, with further performance gains achieved by combining their features. Our findings reveal a new direction for reusing vision representations in a non-visual domain. Code is available at https://github.com/ExplainableML/TiViT.</article>","contentLength":1402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Terminology for Scientific Workflow Systems","url":"https://arxiv.org/abs/2506.07838","date":1751515200,"author":"","guid":181856,"unread":true,"content":"<article>arXiv:2506.07838v5 Announce Type: replace \nAbstract: The term scientific workflow has evolved over the last two decades to encompass a broad range of compositions of interdependent compute tasks and data movements. It has also become an umbrella term for processing in modern scientific applications. Today, many scientific applications can be considered as workflows made of multiple dependent steps, and hundreds of workflow management systems (WMSs) have been developed to manage and run these workflows. However, no turnkey solution has emerged to address the diversity of scientific processes and the infrastructure on which they are implemented. Instead, new research problems requiring the execution of scientific workflows with some novel feature often lead to the development of an entirely new WMS. A direct consequence is that many existing WMSs share some salient features, offer similar functionalities, and can manage the same categories of workflows but also have some distinct capabilities. This situation makes researchers who develop workflows face the complex question of selecting a WMS. This selection can be driven by technical considerations, to find the system that is the most appropriate for their application and for the resources available to them, or other factors such as reputation, adoption, strong community support, or long-term sustainability. To address this problem, a group of WMS developers and practitioners joined their efforts to produce a community-based terminology of WMSs. This paper summarizes their findings and introduces this new terminology to characterize WMSs. This terminology is composed of fives axes: workflow characteristics, composition, orchestration, data management, and metadata capture. Each axis comprises several concepts that capture the prominent features of WMSs. Based on this terminology, this paper also presents a classification of 23 existing WMSs according to the proposed axes and terms.</article>","contentLength":1963,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning","url":"https://arxiv.org/abs/2506.06955","date":1751515200,"author":"","guid":181857,"unread":true,"content":"<article>arXiv:2506.06955v3 Announce Type: replace \nAbstract: We present BIS Reasoning 1.0, the first large-scale Japanese dataset of syllogistic reasoning problems explicitly designed to evaluate belief-inconsistent reasoning in large language models (LLMs). Unlike prior datasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned reasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent syllogisms to uncover reasoning biases in LLMs trained on human-aligned corpora. We benchmark state-of-the-art models - including GPT models, Claude models, and leading Japanese LLMs - revealing significant variance in performance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies critical weaknesses in current LLMs when handling logically valid but belief-conflicting inputs. These findings have important implications for deploying LLMs in high-stakes domains such as law, healthcare, and scientific literature, where truth must override intuitive belief to ensure integrity and safety.</article>","contentLength":1025,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Adapting Rule Representation With Four-Parameter Beta Distribution for Learning Classifier Systems","url":"https://arxiv.org/abs/2506.03602","date":1751515200,"author":"","guid":181858,"unread":true,"content":"<article>arXiv:2506.03602v2 Announce Type: replace \nAbstract: Rule representations significantly influence the search capabilities and decision boundaries within the search space of Learning Classifier Systems (LCSs), a family of rule-based machine learning systems that evolve interpretable models through evolutionary processes. However, it is very difficult to choose an appropriate rule representation for each problem. Additionally, some problems benefit from using different representations for different subspaces within the input space. Thus, an adaptive mechanism is needed to choose an appropriate rule representation for each rule in LCSs. This article introduces a flexible rule representation using a four-parameter beta distribution and integrates it into a fuzzy-style LCS. The four-parameter beta distribution can form various function shapes, and this flexibility enables our LCS to automatically select appropriate representations for different subspaces. Our rule representation can represent crisp/fuzzy decision boundaries in various boundary shapes, such as rectangles and bells, by controlling four parameters, compared to the standard representations such as trapezoidal ones. Leveraging this flexibility, our LCS is designed to adapt the appropriate rule representation for each subspace. Moreover, our LCS incorporates a generalization bias favoring crisp rules where feasible, enhancing model interpretability without compromising accuracy. Experimental results on real-world classification tasks show that our LCS achieves significantly superior test accuracy and produces more compact rule sets. Our implementation is available at https://github.com/YNU-NakataLab/Beta4-UCS. An extended abstract related to this work is available at https://doi.org/10.36227/techrxiv.174900805.59801248/v1.</article>","contentLength":1809,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Non-collective Calibrating Strategy for Time Series Forecasting","url":"https://arxiv.org/abs/2506.03176","date":1751515200,"author":"","guid":181859,"unread":true,"content":"<article>arXiv:2506.03176v2 Announce Type: replace \nAbstract: Deep learning-based approaches have demonstrated significant advancements in time series forecasting. Despite these ongoing developments, the complex dynamics of time series make it challenging to establish the rule of thumb for designing the golden model architecture. In this study, we argue that refining existing advanced models through a universal calibrating strategy can deliver substantial benefits with minimal resource costs, as opposed to elaborating and training a new model from scratch. We first identify a multi-target learning conflict in the calibrating process, which arises when optimizing variables across time steps, leading to the underutilization of the model's learning capabilities. To address this issue, we propose an innovative calibrating strategy called Socket+Plug (SoP). This approach retains an exclusive optimizer and early-stopping monitor for each predicted target within each Plug while keeping the fully trained Socket backbone frozen. The model-agnostic nature of SoP allows it to directly calibrate the performance of any trained deep forecasting models, regardless of their specific architectures. Extensive experiments on various time series benchmarks and a spatio-temporal meteorological ERA5 dataset demonstrate the effectiveness of SoP, achieving up to a 22% improvement even when employing a simple MLP as the Plug (highlighted in Figure 1). Code is available at https://github.com/hanyuki23/SoP.</article>","contentLength":1496,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reweighted Spectral Partitioning Works: Bounds for Special Graph Classes","url":"https://arxiv.org/abs/2506.01228","date":1751515200,"author":"","guid":181860,"unread":true,"content":"<article>arXiv:2506.01228v2 Announce Type: replace \nAbstract: Spectral partitioning is a method that can be used to compute small sparse cuts or small edge-separators in a wide variety of graph classes, by computing the second-smallest eigenvalue (and eigenvector) of the Laplacian matrix. Upper bounds on this eigenvalue for certain graph classes imply that the method obtains small edge-separators for these classes, usually with a sub-optimal dependence on the maximum degree. In this work, we show that a related method, called reweighted spectral partitioning, guarantees near-optimal sparse vertex-cuts and vertex-separators in a wide variety of graph classes. In many cases, this involves little-to-no necessary dependence on maximum degree.\n  We also obtain a new proof of the planar separator theorem, a strengthened eigenvalue bound for bounded-genus graphs, and a refined form of the recent Cheeger-style inequality for vertex expansion via a specialized dimension-reduction step.</article>","contentLength":982,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Local Frames: Exploiting Inherited Origins to Bypass Content Blockers","url":"https://arxiv.org/abs/2506.00317","date":1751515200,"author":"","guid":181861,"unread":true,"content":"<article>arXiv:2506.00317v2 Announce Type: replace \nAbstract: We present a study of how local frames (i.e., iframes loading content like \"about:blank\") are mishandled by a wide range of popular Web security and privacy tools. As a result, users of these tools remain vulnerable to the very attack techniques against which they seek to protect themselves, including browser fingerprinting, cookie-based tracking, and data exfiltration. The tools we study are vulnerable in different ways, but all share a root cause: legacy Web functionality interacts with browser privacy boundaries in unexpected ways, leading to systemic vulnerabilities in tools developed, maintained, and recommended by privacy experts and activists.\n  We consider four core capabilities supported by most privacy tools and develop tests to determine whether each can be evaded through the use of local frames. We apply our tests to six popular Web privacy and security tools -- identifying at least one vulnerability in each for a total of 19 -- and extract common patterns regarding their mishandling of local frames. Our measurement of popular websites finds that 56% employ local frames and that 73.7% of the requests made by these local frames should be blocked by popular filter lists but instead trigger the vulnerabilities we identify. From another perspective, 14.3% of all sites that we crawl make requests that should be blocked inside of local frames. We disclosed these vulnerabilities to the tool authors and discuss both our experiences working with them to patch their products and the implications of our findings for other privacy and security research.</article>","contentLength":1632,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Melding the Serverless Control Plane with the Conventional Cluster Manager for Speed and Compatibility","url":"https://arxiv.org/abs/2505.24551","date":1751515200,"author":"","guid":181862,"unread":true,"content":"<article>arXiv:2505.24551v2 Announce Type: replace \nAbstract: Modern serverless applications, often interactive with highly volatile traffic, challenge system scalability, demanding control planes that deliver low latency and cost efficiency. Analysis of production traces and existing systems reveals that current control plane designs (synchronous and asynchronous), particularly when built on conventional cluster managers like Kubernetes, struggle with this balance, often wasting significant CPU and memory resources on creating underutilized or idle instances. While clean-slate approaches like Dirigent offer performance gains, they sacrifice compatibility with established cluster management ecosystems.\n  We introduce PulseNet, a serverless system designed to achieve high performance and low cost while maintaining compatibility with conventional cluster managers. PulseNet employs a novel dual-track control plane. A standard asynchronous track manages long-lived, full-featured regular instances for handling predictable, sustainable traffic, preserving full compatibility and feature sets off the critical path. Concurrently, an expedited parallel track addresses excessive traffic bursts that trigger cold starts. This fast path utilizes node-local agents (Pulselets) to rapidly spawn short-lived Emergency Instances with a reduced feature set, critically bypassing the latency overhead of the main cluster manager.\n  Our experiments demonstrate that PulseNet, while remaining compatible with conventional managers for &gt;98% invocation traffic, achieves 35% faster end-to-end performance at a comparable cost to the incompatible Dirigent system. PulseNet outperforms Kubernetes-compatible systems with synchronous control planes by 1.5-3.5x at 8-21% lower cost, and surpasses asynchronous counterparts by 1.7-3.5x at 3-33% lower cost.</article>","contentLength":1838,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control","url":"https://arxiv.org/abs/2505.23355","date":1751515200,"author":"","guid":181863,"unread":true,"content":"<article>arXiv:2505.23355v2 Announce Type: replace \nAbstract: Climate control is crucial for greenhouse production as it directly affects crop growth and resource use. Reinforcement learning (RL) has received increasing attention in this field, but still faces challenges, including limited training efficiency and high reliance on initial learning conditions. Interactive RL, which combines human (grower) input with the RL agent's learning, offers a potential solution to overcome these challenges. However, interactive RL has not yet been applied to greenhouse climate control and may face challenges related to imperfect inputs. Therefore, this paper aims to explore the possibility and performance of applying interactive RL with imperfect inputs into greenhouse climate control, by: (1) developing three representative interactive RL algorithms tailored for greenhouse climate control (reward shaping, policy shaping and control sharing); (2) analyzing how input characteristics are often contradicting, and how the trade-offs between them make grower's inputs difficult to perfect; (3) proposing a neural network-based approach to enhance the robustness of interactive RL agents under limited input availability; (4) conducting a comprehensive evaluation of the three interactive RL algorithms with imperfect inputs in a simulated greenhouse environment. The demonstration shows that interactive RL incorporating imperfect grower inputs has the potential to improve the performance of the RL agent. RL algorithms that influence action selection, such as policy shaping and control sharing, perform better when dealing with imperfect inputs, achieving 8.4% and 6.8% improvement in profit, respectively. In contrast, reward shaping, an algorithm that manipulates the reward function, is sensitive to imperfect inputs and leads to a 9.4% decrease in profit. This highlights the importance of selecting an appropriate mechanism when incorporating imperfect inputs.</article>","contentLength":1958,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding","url":"https://arxiv.org/abs/2505.22618","date":1751515200,"author":"","guid":181864,"unread":true,"content":"<article>arXiv:2505.22618v2 Announce Type: replace \nAbstract: Diffusion-based large language models (Diffusion LLMs) have shown promise for non-autoregressive text generation with parallel decoding capabilities. However, the practical inference speed of open-sourced Diffusion LLMs often lags behind autoregressive models due to the lack of Key-Value (KV) Cache and quality degradation when decoding multiple tokens simultaneously. To bridge this gap, we introduce a novel block-wise approximate KV Cache mechanism tailored for bidirectional diffusion models, enabling cache reuse with negligible performance drop. Additionally, we identify the root cause of generation quality degradation in parallel decoding as the disruption of token dependencies under the conditional independence assumption. To address this, we propose a confidence-aware parallel decoding strategy that selectively decodes tokens exceeding a confidence threshold, mitigating dependency violations and maintaining generation quality. Experimental results on LLaDA and Dream models across multiple LLM benchmarks demonstrate up to \\textbf{27.6$\\times$ throughput} improvement with minimal accuracy loss, closing the performance gap with autoregressive models and paving the way for practical deployment of Diffusion LLMs.</article>","contentLength":1284,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real-Time Blind Defocus Deblurring for Earth Observation: The IMAGIN-e Mission Approach","url":"https://arxiv.org/abs/2505.22128","date":1751515200,"author":"","guid":181865,"unread":true,"content":"<article>arXiv:2505.22128v2 Announce Type: replace \nAbstract: This work addresses mechanical defocus in Earth observation images from the IMAGIN-e mission aboard the ISS, proposing a blind deblurring approach adapted to space-based edge computing constraints. Leveraging Sentinel-2 data, our method estimates the defocus kernel and trains a restoration model within a GAN framework, effectively operating without reference images.\n  On Sentinel-2 images with synthetic degradation, SSIM improved by 72.47% and PSNR by 25.00%, confirming the model's ability to recover lost details when the original clean image is known. On IMAGIN-e, where no reference images exist, perceptual quality metrics indicate a substantial enhancement, with NIQE improving by 60.66% and BRISQUE by 48.38%, validating real-world onboard restoration. The approach is currently deployed aboard the IMAGIN-e mission, demonstrating its practical application in an operational space environment.\n  By efficiently handling high-resolution images under edge computing constraints, the method enables applications such as water body segmentation and contour detection while maintaining processing viability despite resource limitations.</article>","contentLength":1195,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling","url":"https://arxiv.org/abs/2505.21717","date":1751515200,"author":"","guid":181866,"unread":true,"content":"<article>arXiv:2505.21717v3 Announce Type: replace \nAbstract: We present LrcSSM, a $\\textit{nonlinear}$ recurrent model that processes long sequences as fast as today's linear state-space layers. By forcing the state-transition matrix to be diagonal and learned at every step, the full sequence can be solved in parallel with a single prefix-scan, giving $\\mathcal{O}(TD)$ time and memory and only $\\mathcal{O}(\\log T)$ sequential depth, for input-sequence length $T$ and a state dimension $D$. Moreover, LrcSSM offers a formal gradient-stability guarantee that other input-varying systems such as Liquid-S4 and Mamba do not provide. Lastly, for network depth $L$, as the forward and backward passes cost $\\Theta(T\\,D\\,L)$ FLOPs, with its low sequential depth and parameter count $\\Theta(D\\,L)$, the model follows the compute-optimal scaling law regime ($\\beta \\approx 0.42$) recently observed for Mamba, outperforming quadratic-attention Transformers at equal compute while avoiding the memory overhead of FFT-based long convolutions. We show that on a series of long-range forecasting tasks, LrcSSM outperforms LRU, S5 and Mamba.</article>","contentLength":1122,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Self-reflective Uncertainties: Do LLMs Know Their Internal Answer Distribution?","url":"https://arxiv.org/abs/2505.20295","date":1751515200,"author":"","guid":181867,"unread":true,"content":"<article>arXiv:2505.20295v2 Announce Type: replace \nAbstract: To reveal when a large language model (LLM) is uncertain about a response, uncertainty quantification commonly produces percentage numbers along with the output. But is this all we can do? We argue that in the output space of LLMs, the space of strings, exist strings expressive enough to summarize the distribution over output strings the LLM deems possible. We lay a foundation for this new avenue of uncertainty explication and present SelfReflect, a theoretically-motivated metric to assess how faithfully a string summarizes an LLM's internal answer distribution. We show that SelfReflect is able to discriminate even subtle differences of candidate summary strings and that it aligns with human judgement, outperforming alternative metrics such as LLM judges and embedding comparisons. With SelfReflect, we investigate a number of self-summarization methods and find that even state-of-the-art reasoning models struggle to explicate their internal uncertainty. But we find that faithful summarizations can be generated by sampling and summarizing. To support the development of this universal form of LLM uncertainties, we publish our metric at https://github.com/apple/ml-selfreflect</article>","contentLength":1243,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models","url":"https://arxiv.org/abs/2505.19121","date":1751515200,"author":"","guid":181868,"unread":true,"content":"<article>arXiv:2505.19121v2 Announce Type: replace \nAbstract: Despite the recent strides in large language models, studies have underscored the existence of social biases within these systems. In this paper, we delve into the validation and comparison of the ethical biases of LLMs concerning globally discussed and potentially sensitive topics, hypothesizing that these biases may arise from language-specific distinctions. Introducing the Multilingual Sensitive Questions &amp; Answers Dataset (MSQAD), we collected news articles from Human Rights Watch covering 17 topics, and generated socially sensitive questions along with corresponding responses in multiple languages. We scrutinized the biases of these responses across languages and topics, employing two statistical hypothesis tests. The results showed that the null hypotheses were rejected in most cases, indicating biases arising from cross-language differences. It demonstrates that ethical biases in responses are widespread across various languages, and notably, these biases were prevalent even among different LLMs. By making the proposed MSQAD openly available, we aim to facilitate future research endeavors focused on examining cross-language biases in LLMs and their variant models.</article>","contentLength":1242,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization","url":"https://arxiv.org/abs/2505.18975","date":1751515200,"author":"","guid":181869,"unread":true,"content":"<article>arXiv:2505.18975v3 Announce Type: replace \nAbstract: State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular element-wise tensor operations, and hardware-unfriendly nonlinear functions in the SSM block. To address these issues, this paper presents FastMamba, a dedicated accelerator on FPGA with hardware-algorithm co-design to promote the deployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit quantization for linear layers through Hadamard transformation to eliminate outliers. Moreover, a hardware-friendly and fine-grained power-of-two quantization framework is presented for the SSM block and convolution layer, and a first-order linear approximation is developed to optimize the nonlinear functions. Based on the accurate algorithm quantization, we propose an accelerator that integrates parallel vector processing units, pipelined execution dataflow, and an efficient SSM Nonlinear Approximation Unit, which enhances computational efficiency and reduces hardware complexity. Finally, we evaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on Mamba2-130M, FastMamba achieves 68.80\\times and 8.90\\times speedup over Intel Xeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode experiment with Mamba2-2.7B, FastMamba attains 6\\times higher energy efficiency than RTX 3090 GPU.</article>","contentLength":1582,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mod-Adapter: Tuning-Free and Versatile Multi-concept Personalization via Modulation Adapter","url":"https://arxiv.org/abs/2505.18612","date":1751515200,"author":"","guid":181870,"unread":true,"content":"<article>arXiv:2505.18612v2 Announce Type: replace \nAbstract: Personalized text-to-image generation aims to synthesize images of user-provided concepts in diverse contexts. Despite recent progress in multi-concept personalization, most are limited to object concepts and struggle to customize abstract concepts (e.g., pose, lighting). Some methods have begun exploring multi-concept personalization supporting abstract concepts, but they require test-time fine-tuning for each new concept, which is time-consuming and prone to overfitting on limited training images. In this work, we propose a novel tuning-free method for multi-concept personalization that can effectively customize both object and abstract concepts without test-time fine-tuning. Our method builds upon the modulation mechanism in pretrained Diffusion Transformers (DiTs) model, leveraging the localized and semantically meaningful properties of the modulation space. Specifically, we propose a novel module, Mod-Adapter, to predict concept-specific modulation direction for the modulation process of concept-related text tokens. It incorporates vision-language cross-attention for extracting concept visual features, and Mixture-of-Experts (MoE) layers that adaptively map the concept features into the modulation space. Furthermore, to mitigate the training difficulty caused by the large gap between the concept image space and the modulation space, we introduce a VLM-guided pretraining strategy that leverages the strong image understanding capabilities of vision-language models to provide semantic supervision signals. For a comprehensive comparison, we extend a standard benchmark by incorporating abstract concepts. Our method achieves state-of-the-art performance in multi-concept personalization, supported by quantitative, qualitative, and human evaluations.</article>","contentLength":1830,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On the Structure and Semantics of Identifier Names Containing Closed Syntactic Category Words","url":"https://arxiv.org/abs/2505.18444","date":1751515200,"author":"","guid":181871,"unread":true,"content":"<article>arXiv:2505.18444v2 Announce Type: replace \nAbstract: Identifier names are crucial components of code, serving as primary clues for developers to understand program behavior. This paper investigates the linguistic structure of identifier names by extending the concept of grammar patterns, which represent the part-of-speech (PoS) sequences underlying identifier phrases. The specific focus is on closed syntactic categories (e.g., prepositions, conjunctions, determiners), which are rarely studied in software engineering despite their central role in general natural language. To study these categories, the Closed Category Identifier Dataset (CCID), a new manually annotated dataset of 1,275 identifiers drawn from 30 open-source systems, is constructed and presented. The relationship between closed-category grammar patterns and program behavior is then analyzed using grounded-theory-inspired coding, statistical, and pattern analysis. The results reveal recurring structures that developers use to express concepts such as control flow, data transformation, temporal reasoning, and other behavioral roles through naming. This work contributes an empirical foundation for understanding how linguistic resources encode behavior in identifier names and supports new directions for research in naming, program comprehension, and education.</article>","contentLength":1341,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A deep solver for backward stochastic Volterra integral equations","url":"https://arxiv.org/abs/2505.18297","date":1751515200,"author":"","guid":181872,"unread":true,"content":"<article>arXiv:2505.18297v2 Announce Type: replace \nAbstract: We present the first deep-learning solver for backward stochastic Volterra integral equations (BSVIEs) and their fully-coupled forward-backward variants. The method trains a neural network to approximate the two solution fields in a single stage, avoiding the use of nested time-stepping cycles that limit classical algorithms. For the decoupled case we prove a non-asymptotic error bound composed of an a posteriori residual plus the familiar square root dependence on the time step. Numerical experiments confirm this rate and reveal two key properties: \\emph{scalability}, in the sense that accuracy remains stable from low dimension up to 500 spatial variables while GPU batching keeps wall-clock time nearly constant; and \\emph{generality}, since the same method handles coupled systems whose forward dynamics depend on the backward solution. These results open practical access to a family of high-dimensional, path-dependent problems in stochastic control and quantitative finance.</article>","contentLength":1041,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CU-Multi: A Dataset for Multi-Robot Data Association","url":"https://arxiv.org/abs/2505.17576","date":1751515200,"author":"","guid":181873,"unread":true,"content":"<article>arXiv:2505.17576v2 Announce Type: replace \nAbstract: Multi-robot systems (MRSs) are valuable for tasks such as search and rescue due to their ability to coordinate over shared observations. A central challenge in these systems is aligning independently collected perception data across space and time, i.e., multi-robot data association. While recent advances in collaborative SLAM (C-SLAM), map merging, and inter-robot loop closure detection have significantly progressed the field, evaluation strategies still predominantly rely on splitting a single trajectory from single-robot SLAM datasets into multiple segments to simulate multiple robots. Without careful consideration to how a single trajectory is split, this approach will fail to capture realistic pose-dependent variation in observations of a scene inherent to multi-robot systems. To address this gap, we present CU-Multi, a multi-robot dataset collected over multiple days at two locations on the University of Colorado Boulder campus. Using a single robotic platform, we generate four synchronized runs with aligned start times and deliberate percentages of trajectory overlap. CU-Multi includes RGB-D, GPS with accurate geospatial heading, and semantically annotated LiDAR data. By introducing controlled variations in trajectory overlap and dense lidar annotations, CU-Multi offers a compelling alternative for evaluating methods in multi-robot data association. Instructions on accessing the dataset, support code, and the latest updates are publicly available at https://arpg.github.io/cumulti</article>","contentLength":1564,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Pre-training Large Memory Language Models with Internal and External Knowledge","url":"https://arxiv.org/abs/2505.15962","date":1751515200,"author":"","guid":181874,"unread":true,"content":"<article>arXiv:2505.15962v2 Announce Type: replace \nAbstract: Neural language models are black-boxes -- both linguistic patterns and factual knowledge are distributed across billions of opaque parameters. This entangled encoding makes it difficult to reliably inspect, verify, or update specific facts. We propose a new class of language models, Large Memory Language Models (LMLM) with a pre-training recipe that stores factual knowledge in both internal weights and an external database. Our approach strategically masks externally retrieved factual values from the training loss, thereby teaching the model to perform targeted lookups rather than relying on memorization in model weights. Our experiments demonstrate that LMLMs achieve competitive performance compared to significantly larger, knowledge-dense LLMs on standard benchmarks, while offering the advantages of explicit, editable, and verifiable knowledge bases. This work represents a fundamental shift in how language models interact with and manage factual knowledge.</article>","contentLength":1025,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Self-heating electrochemical memory for high-precision analog computing","url":"https://arxiv.org/abs/2505.15936","date":1751515200,"author":"","guid":181875,"unread":true,"content":"<article>arXiv:2505.15936v2 Announce Type: replace \nAbstract: Analog computers hold promise to significantly reduce the energy consumption of artificial intelligence algorithms, but commercialization has been hampered by a fundamental scientific challenge - how to reliably store and process analog information with high precision. We present an approach based upon metal oxide memory cells that undergo controlled self-heating during programming with a newly developed, electro-thermo-chemical gate. The gate uniformly spreads heat and electrochemical reactions to enable wide, bulk-vacancy modulation which yields nine orders of magnitude in tunable analog resistance - three orders greater than other devices reported, with thousands of states. The gating profoundly reduces noise and drift to enable precision programming to targeted states within a few operations, lowering conductance errors by two orders of magnitude relative to other devices reported. Simulations show improvement in computational energy efficiency by at least 10x over other devices due to far greater scalability at higher precision. The results overturn long-held assumptions about the poor reliability and precision of analog resistance devices and opens the door to manufacturable, bulk metal-oxide devices and new applications that leverage high precision.</article>","contentLength":1329,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation","url":"https://arxiv.org/abs/2505.12620","date":1751515200,"author":"","guid":181876,"unread":true,"content":"<article>arXiv:2505.12620v3 Announce Type: replace \nAbstract: Advances in AI generative models facilitate super-realistic video synthesis, amplifying misinformation risks via social media and eroding trust in digital content. Several research works have explored new deepfake detection methods on AI-generated images to alleviate these risks. However, with the fast development of video generation models, such as Sora and WanX, there is currently a lack of large-scale, high-quality AI-generated video datasets for forgery detection. In addition, existing detection approaches predominantly treat the task as binary classification, lacking explainability in model decision-making and failing to provide actionable insights or guidance for the public. To address these challenges, we propose \\textbf{GenBuster-200K}, a large-scale AI-generated video dataset featuring 200K high-resolution video clips, diverse latest generative techniques, and real-world scenes. We further introduce \\textbf{BusterX}, a novel AI-generated video detection and explanation framework leveraging multimodal large language model (MLLM) and reinforcement learning for authenticity determination and explainable rationale. To our knowledge, GenBuster-200K is the {\\it \\textbf{first}} large-scale, high-quality AI-generated video dataset that incorporates the latest generative techniques for real-world scenarios. BusterX is the {\\it \\textbf{first}} framework to integrate MLLM with reinforcement learning for explainable AI-generated video detection. Extensive comparisons with state-of-the-art methods and ablation studies validate the effectiveness and generalizability of BusterX. The code, models, and datasets will be released.</article>","contentLength":1701,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Universal Semantics With Large Language Models","url":"https://arxiv.org/abs/2505.11764","date":1751515200,"author":"","guid":181877,"unread":true,"content":"<article>arXiv:2505.11764v2 Announce Type: replace \nAbstract: The Natural Semantic Metalanguage (NSM) is a linguistic theory based on a universal set of semantic primes: simple, primitive word-meanings that have been shown to exist in most, if not all, languages of the world. According to this framework, any word, regardless of complexity, can be paraphrased using these primes, revealing a clear and universally translatable meaning. These paraphrases, known as explications, can offer valuable applications for many natural language processing (NLP) tasks, but producing them has traditionally been a slow, manual process. In this work, we present the first study of using large language models (LLMs) to generate NSM explications. We introduce automatic evaluation methods, a tailored dataset for training and evaluation, and fine-tuned models for this task. Our 1B and 8B models outperform GPT-4o in producing accurate, cross-translatable explications, marking a significant step toward universal semantic representation with LLMs and opening up new possibilities for applications in semantic analysis, translation, and beyond.</article>","contentLength":1124,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An equilibrium-based quasi-3D beam model with rational transverse normal stress expression for accurate analysis of functionally graded beams","url":"https://arxiv.org/abs/2505.09127","date":1751515200,"author":"","guid":181878,"unread":true,"content":"<article>arXiv:2505.09127v5 Announce Type: replace \nAbstract: Although existing quasi-3D beam models can partially account for the influence of transverse stretching deformation, their inability to accurately predict transverse normal stress severely limits their practical value, particularly when applied to functionally graded beams. A key contributing factor to this limitation is the failure of the stress components to satisfy the equilibrium relationships. This paper develops a novel quasi-3D beam models with equilibrium-based transverse normal stress expression for achieving accurate solutions of functionally graded beams. In contrast to the conventional quasi-3D models where stress expressions are derived from constitutive and geometric equations, the expressions of transverse shear stress and transverse normal stress in this study are derived according to the differential equilibrium equations among stresses, ensuring strict adherence of stress solutions to equilibrium conditions. To incorporate the influence of equilibrium-derived stress distributions, the equilibrium-based cross-sectional stiffness matrix is derived, enhancing the theoretical and practical feasibility of the beam model. In the numerical implementation, the mixed element method with generalized internal forces and generalized displacements regarded as two independent fields is employed to construct the beam element, and especially, semi-analytical internal force fields, which partially satisfy the differential equilibrium equations, are introduced to improve the element performance. Numerical results demonstrate that the proposed quasi-3D beam model accurately predicts both displacement and stress fields in functionally graded beams, which exhibits the effectiveness of introducing stress equilibrium relationships.</article>","contentLength":1809,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Enhancing Robustness to Missing Modalities through Clustered Federated Learning","url":"https://arxiv.org/abs/2505.06911","date":1751515200,"author":"","guid":181879,"unread":true,"content":"<article>arXiv:2505.06911v2 Announce Type: replace \nAbstract: In the era of big data, data mining has become indispensable for uncovering hidden patterns and insights from vast and complex datasets. The integration of multimodal data sources further enhances its potential. Multimodal Federated Learning (MFL) is a distributed approach that enhances the efficiency and quality of multimodal learning, ensuring collaborative work and privacy protection. However, missing modalities pose a significant challenge in MFL, often due to data quality issues or privacy policies across the clients. In this work, we present MMiC, a framework for Mitigating Modality incompleteness in MFL within the Clusters. MMiC replaces partial parameters within client models inside clusters to mitigate the impact of missing modalities. Furthermore, it leverages the Banzhaf Power Index to optimize client selection under these conditions. Finally, MMiC employs an innovative approach to dynamically control global aggregation by utilizing Markovitz Portfolio Optimization. Extensive experiments demonstrate that MMiC consistently outperforms existing federated learning architectures in both global and personalized performance on multimodal datasets with missing modalities, confirming the effectiveness of our proposed solution.</article>","contentLength":1302,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Perceiving Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models","url":"https://arxiv.org/abs/2505.05626","date":1751515200,"author":"","guid":181880,"unread":true,"content":"<article>arXiv:2505.05626v3 Announce Type: replace \nAbstract: Achieving deep alignment between vision and language remains a central challenge for Multimodal Large Language Models (MLLMs). These models often fail to fully leverage visual input, defaulting to strong language priors. Our approach first provides insights into how MLLMs internally build visual understanding of image regions and then introduces techniques to amplify this capability. Specifically, we explore techniques designed both to deepen the model's understanding of visual content and to ensure that these visual insights actively guide language generation. We demonstrate the superior multimodal understanding of our resultant model through a detailed upstream analysis quantifying its ability to predict visually-dependent tokens as well as 10 pt boost on visually challenging tasks.</article>","contentLength":848,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PPO-ACT: Proximal Policy Optimization with Adversarial Curriculum Transfer for Spatial Public Goods Games","url":"https://arxiv.org/abs/2505.04302","date":1751515200,"author":"","guid":181881,"unread":true,"content":"<article>arXiv:2505.04302v2 Announce Type: replace \nAbstract: This study investigates cooperation evolution mechanisms in the spatial public goods game. A novel deep reinforcement learning framework, Proximal Policy Optimization with Adversarial Curriculum Transfer (PPO-ACT), is proposed to model agent strategy optimization in dynamic environments. Traditional evolutionary game models frequently exhibit limitations in modeling long-term decision-making processes. Deep reinforcement learning effectively addresses this limitation by bridging policy gradient methods with evolutionary game theory. Our study pioneers the application of proximal policy optimization's continuous strategy optimization capability to public goods games through a two-stage adversarial curriculum transfer training paradigm. The experimental results show that PPO-ACT performs better in critical enhancement factor regimes. Compared to conventional standard proximal policy optimization methods, Q-learning and Fermi update rules, achieve earlier cooperation phase transitions and maintain stable cooperative equilibria. This framework exhibits better robustness when handling challenging scenarios like all-defector initial conditions. Systematic comparisons reveal the unique advantage of policy gradient methods in population-scale cooperation, i.e., achieving spatiotemporal payoff coordination through value function propagation. Our work provides a new computational framework for studying cooperation emergence in complex systems, algorithmically validating the punishment promotes cooperation hypothesis while offering methodological insights for multi-agent system strategy design.</article>","contentLength":1663,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"manvr3d: A Platform for Human-in-the-loop Cell Tracking in Virtual Reality","url":"https://arxiv.org/abs/2505.03440","date":1751515200,"author":"","guid":181882,"unread":true,"content":"<article>arXiv:2505.03440v3 Announce Type: replace \nAbstract: We propose manvr3d, a novel VR-ready platform for interactive human-in-the-loop cell tracking. We utilize VR controllers and eye-tracking hardware to facilitate rapid ground truth generation and proofreading for deep learning-based cell tracking models. Life scientists reconstruct the developmental history of organisms on the cellular level by analyzing 3D time-lapse microscopy images acquired at high spatio-temporal resolution. The reconstruction of such cell lineage trees traditionally involves tracking individual cells through all recorded time points, manually annotating their positions, and then linking them over time to create complete trajectories. Deep learning-based algorithms accelerate this process, yet depend heavily on manually-annotated high-quality ground truth data and curation. Visual representation of the image data in this process still relies primarily on 2D renderings, which greatly limits spatial understanding and navigation. In this work, we bridge the gap between deep learning-based cell tracking software and 3D/VR visualization to create a human-in-the-loop cell tracking system. We lift the incremental annotation, training and proofreading loop of the deep learning model into the 3rd dimension and apply natural user interfaces like hand gestures and eye tracking to accelerate the cell tracking workflow for life scientists.</article>","contentLength":1422,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Regulating Algorithmic Management: A Multi-Stakeholder Study of Challenges in Aligning Software and the Law for Workplace Scheduling","url":"https://arxiv.org/abs/2505.02329","date":1751515200,"author":"","guid":181883,"unread":true,"content":"<article>arXiv:2505.02329v3 Announce Type: replace \nAbstract: Algorithmic management (AM)'s impact on worker well-being has led to calls for regulation. However, little is known about the effectiveness and challenges in real-world AM regulation across the regulatory process -- rule operationalization, software use, and enforcement. Our multi-stakeholder study addresses this gap within workplace scheduling, one of the few AM domains with implemented regulations. We interviewed 38 stakeholders across the regulatory process: regulators, defense attorneys, worker advocates, managers, and workers. Our findings suggest that the efficacy of AM regulation is influenced by: (i) institutional constraints that challenge efforts to encode law into AM software, (ii) on-the-ground use of AM software that shapes its ability to facilitate compliance, (iii) mismatches between software and regulatory contexts that hinder enforcement, and (iv) unique concerns that software introduces when used to regulate AM. These findings underscore the importance of a sociotechnical approach to AM regulation, which considers organizational and collaborative contexts alongside the inherent attributes of software. We offer future research directions and implications for technology policy and design.</article>","contentLength":1276,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LZ Penalty: An information-theoretic repetition penalty for autoregressive language models","url":"https://arxiv.org/abs/2504.20131","date":1751515200,"author":"","guid":181884,"unread":true,"content":"<article>arXiv:2504.20131v2 Announce Type: replace \nAbstract: We introduce the LZ penalty, a penalty specialized for reducing degenerate repetitions in autoregressive language models without loss of capability. The penalty is based on the codelengths in the LZ77 universal lossless compression algorithm. Through the lens of the prediction-compression duality, decoding the LZ penalty has the interpretation of sampling from the residual distribution after removing the information that is highly compressible. We demonstrate the LZ penalty enables state-of-the-art open-source reasoning models to operate with greedy (temperature zero) decoding without loss of capability and without instances of degenerate repetition. Both the industry-standard frequency penalty and repetition penalty are ineffective, incurring degenerate repetition rates of up to 4%.</article>","contentLength":847,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Engineering Minimal k-Perfect Hash Functions","url":"https://arxiv.org/abs/2504.20001","date":1751515200,"author":"","guid":181885,"unread":true,"content":"<article>arXiv:2504.20001v2 Announce Type: replace \nAbstract: Given a set S of n keys, a k-perfect hash function (kPHF) is a data structure that maps the keys to the first m integers, where each output integer can be hit by at most k input keys. When m=n/k, the resulting function is called a minimal k-perfect hash function (MkPHF). Applications of kPHFs can be found in external memory data structures or to create efficient 1-perfect hash functions, which in turn have a wide range of applications from databases to bioinformatics. Several papers from the 1980s look at external memory data structures with small internal memory indexes. However, actual k-perfect hash functions are surprisingly rare, and the area has not seen a lot of research recently. At the same time, recent research in 1-perfect hashing shows that there is a lack of efficient kPHFs. In this paper, we revive the area of k-perfect hashing, presenting four new constructions. Our implementations simultaneously dominate older approaches in space consumption, construction time, and query time. We see this paper as a possible starting point of an active line of research, similar to the area of 1-perfect hashing.</article>","contentLength":1180,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Adapting Probabilistic Risk Assessment for AI","url":"https://arxiv.org/abs/2504.18536","date":1751515200,"author":"","guid":181886,"unread":true,"content":"<article>arXiv:2504.18536v3 Announce Type: replace \nAbstract: Modern general-purpose artificial intelligence (AI) systems present an urgent risk management challenge, as their rapidly evolving capabilities and potential for catastrophic harm outpace our ability to reliably assess their risks. Current methods often rely on selective testing and undocumented assumptions about risk priorities, frequently failing to make a serious attempt at assessing the set of pathways through which AI systems pose direct or indirect risks to society and the biosphere. This paper introduces the probabilistic risk assessment (PRA) for AI framework, adapting established PRA techniques from high-reliability industries (e.g., nuclear power, aerospace) for the new challenges of advanced AI. The framework guides assessors in identifying potential risks, estimating likelihood and severity bands, and explicitly documenting evidence, underlying assumptions, and analyses at appropriate granularities. The framework's implementation tool synthesizes the results into a risk report card with aggregated risk estimates from all assessed risks. It introduces three methodological advances: (1) Aspect-oriented hazard analysis provides systematic hazard coverage guided by a first-principles taxonomy of AI system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk pathway modeling analyzes causal chains from system aspects to societal impacts using bidirectional analysis and incorporating prospective techniques; and (3) Uncertainty management employs scenario decomposition, reference scales, and explicit tracing protocols to structure credible projections with novelty or limited data. Additionally, the framework harmonizes diverse assessment methods by integrating evidence into comparable, quantified absolute risk estimates for lifecycle decisions. We have implemented this as a workbook tool for AI developers, evaluators, and regulators.</article>","contentLength":1939,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Matching of Some Fundamental Regular Expressions with Backreferences","url":"https://arxiv.org/abs/2504.18247","date":1751515200,"author":"","guid":181887,"unread":true,"content":"<article>arXiv:2504.18247v2 Announce Type: replace \nAbstract: Regular expression matching is of practical importance due to its widespread use in real-world applications. In practical use, regular expressions are often used with real-world extensions. Accordingly, the matching problem of regular expressions with real-world extensions has been actively studied in recent years, yielding steady progress. However, backreference, a popular extension supported by most modern programming languages such as Java, Python, JavaScript and others in their standard libraries for string processing, is an exception to this positive trend. In fact, it is known that the matching problem of regular expressions with backreferences (rewbs) is theoretically hard and the existence of an asymptotically fast matching algorithm for arbitrary rewbs seems unlikely. Even among currently known partial solutions, the balance between efficiency and generality remains unsatisfactory. To bridge this gap, we present an efficient matching algorithm for rewbs of the form $e_0 (e)_1 e_1 \\backslash 1 e_2$ where $e_0, e, e_1, e_2$ are pure regular expressions, which are fundamental and frequently used in practical applications. It runs in quadratic time with respect to the input string length, substantially improving the best-known cubic time complexity for these rewbs. Our algorithm combines ideas from both stringology and automata theory in a novel way. We leverage two techniques from automata theory, injection and summarization, to simultaneously examine matches whose backreferenced substrings are either a fixed right-maximal repeat or its extendable prefixes, which are concepts from stringology. By further utilizing a subtle property of extendable prefixes, our algorithm correctly decides the matching problem while achieving the quadratic-time complexity.</article>","contentLength":1842,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dynamic Membership for Regular Tree Languages","url":"https://arxiv.org/abs/2504.17536","date":1751515200,"author":"","guid":181888,"unread":true,"content":"<article>arXiv:2504.17536v2 Announce Type: replace \nAbstract: We study the dynamic membership problem for regular tree languages under relabeling updates: we fix an alphabet $\\Sigma$ and a regular tree language $L$ over $\\Sigma$ (expressed, e.g., as a tree automaton), we are given a tree $T$ with labels in $\\Sigma$, and we must maintain the information of whether the tree $T$ belongs to $L$ while handling relabeling updates that change the labels of individual nodes in $T$.\n  Our first contribution is to show that this problem admits an $O(\\log n / \\log \\log n)$ algorithm for any fixed regular tree language, improving over known $O(\\log n)$ algorithms. This generalizes the known $O(\\log n / \\log \\log n)$ upper bound over words, and it matches the lower bound of $\\Omega(\\log n / \\log \\log n)$ from dynamic membership to some word languages and from the existential marked ancestor problem.\n  Our second contribution is to introduce a class of regular languages, dubbed almost-commutative tree languages, and show that dynamic membership to such languages under relabeling updates can be decided in constant time per update. Almost-commutative languages generalize both commutative languages and finite languages: they are the analogue for trees of the ZG languages enjoying constant-time dynamic membership over words. Our main technical contribution is to show that this class is conditionally optimal when we assume that the alphabet features a neutral letter, i.e., a letter that has no effect on membership to the language. More precisely, we show that any regular tree language with a neutral letter which is not almost-commutative cannot be maintained in constant time under the assumption that the prefix-U1 problem from (Amarilli, Jachiet, Paperman, ICALP'21) also does not admit a constant-time algorithm.</article>","contentLength":1815,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"From Theory to Practice: Engineering Approximation Algorithms for Dynamic Orientation","url":"https://arxiv.org/abs/2504.16720","date":1751515200,"author":"","guid":181889,"unread":true,"content":"<article>arXiv:2504.16720v2 Announce Type: replace \nAbstract: Dynamic graph algorithms have seen significant theoretical advancements, but practical evaluations often lag behind. This work bridges the gap between theory and practice by engineering and empirically evaluating recently developed approximation algorithms for dynamically maintaining graph orientations. We comprehensively describe the underlying data structures, including efficient bucketing techniques and round-robin updates. Our implementation has a natural parameter $\\lambda$, which allows for a trade-off between algorithmic efficiency and the quality of the solution. In the extensive experimental evaluation, we demonstrate that our implementation offers a considerable speedup. Using different quality metrics, we show that our implementations are very competitive and can outperform previous methods. Overall, our approach solves more instances than other methods while being up to 112 times faster on instances that are solvable by all methods compared.</article>","contentLength":1020,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Split Federated Learning for Large Language Models over Communication Networks","url":"https://arxiv.org/abs/2504.14667","date":1751515200,"author":"","guid":181890,"unread":true,"content":"<article>arXiv:2504.14667v2 Announce Type: replace \nAbstract: Fine-tuning pre-trained large language models (LLMs) in a distributed manner poses significant challenges on resource-constrained edge networks. To address this challenge, we propose SflLLM, a novel framework that integrates split federated learning with parameter-efficient fine-tuning techniques. By leveraging model splitting and low-rank adaptation (LoRA), SflLLM reduces the computational burden on edge devices. Furthermore, the introduction of a federated server facilitates parallel training and enhances data privacy. To accommodate heterogeneous communication conditions and diverse computational capabilities of edge devices, as well as the impact of LoRA rank selection on model convergence and training cost, we formulate a joint optimization problem of both communication and computation resource. The formulated problem jointly optimizes subchannel allocation, power control, model splitting point selection, and LoRA rank configuration, aimed at minimizing total training delay. An iterative optimization algorithm is proposed to solve this problem efficiently. Specifically, a greedy heuristic is employed for subchannel allocation, the power control subproblem is reformulated as a convex optimization problem using auxiliary variables, and an exhaustive search is adopted for optimal split position and rank selection. Simulation results demonstrate that the proposed SflLLM framework achieves comparable model accuracy while significantly reducing client-side computational requirements. Furthermore, the proposed resource allocation scheme and adaptive LoRA rank selection strategy notably reduce the training latency compared to conventional approaches.</article>","contentLength":1728,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Examining Technology Perspectives of Older Adults with Mild Cognitive Impairment: A Scoping Review","url":"https://arxiv.org/abs/2504.13901","date":1751515200,"author":"","guid":181891,"unread":true,"content":"<article>arXiv:2504.13901v4 Announce Type: replace \nAbstract: Mild cognitive impairment (MCI) may affect up to 20 % of people over 65 years old. Global incidence of MCI is increasing, and technology is being explored for early intervention. Theories of technology adoption predict that useful and easy to use solutions will have higher rates of adoption, however, these models do not specifically consider older people with cognitive impairments, or the unique human computer interaction challenges posed by MCI. We collated opinions from older people with MCI about technology solutions proposed for them, found in 83 articles published between Jan 2014 and May 2024, and found in nine databases. Inductive, thematic analysis of feedback identified five themes (i) purpose and need, (ii) solution design and ease of use, (iii) self-impression, (iv) lifestyle, and (v) interaction modality. Solutions are perceived as useful, even though gaps in functional support exist, however, they are not perceived as entirely easy to use, due to issues related to usability and user experience. Devices which are light, portable, common and have large screens, are preferred, as is multimodal interaction, in particular speech, visual/text and touch. This review recommends future work to (i) improve usability and user experience, (ii) enhance personalisation, (iii) better understand interaction preferences and effectiveness, (iv) enable options for multimodal interaction, and (v) more seamlessly integrate solutions into users lifestyles.</article>","contentLength":1524,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cops and Robbers for Graphs on Surfaces with Crossings","url":"https://arxiv.org/abs/2504.13813","date":1751515200,"author":"","guid":181892,"unread":true,"content":"<article>arXiv:2504.13813v2 Announce Type: replace \nAbstract: Cops and Robbers is a game played on a graph where a set of cops attempt to capture a single robber. The game proceeds in rounds, where each round first consists of the cops' turn, followed by the robber's turn. In the cops' turn, every cop can choose to either stay on the same vertex or move to an adjacent vertex, and likewise the robber in his turn. The robber is considered to be captured if, at any point in time, there is some cop on the same vertex as the robber. A natural question in this game concerns the cop-number of a graph -- the minimum number of cops needed to capture the robber. It has long been known that graphs embeddable (without crossings) on surfaces of bounded genus have bounded cop-number. In contrast, the class of 1-planar graphs -- graphs that can be drawn on the plane with at most one crossing per edge -- does not have bounded cop-number. This paper initiates an investigation into how distance between crossing pairs of edges influences a graph's cop number. In particular, we look at Distance $d$ Cops and Robbers, a variant of the classical game, where the robber is considered to be captured if there is a cop within distance $d$ of the robber. Let $c_d(G)$ denote the minimum number of cops required in the graph $G$ to capture a robber within distance $d$. We look at various classes of graphs, such as 1-plane graphs, $k$-plane graphs (graphs where each edge is crossed at most $k$ times), and even general graph drawings, and show that if every crossing pair of edges can be connected by a path of small length, then $c_d(G)$ is bounded, for small values of $d$.</article>","contentLength":1658,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An accurate measurement of parametric array using a spurious sound filter topologically equivalent to a half-wavelength resonator","url":"https://arxiv.org/abs/2504.12398","date":1751515200,"author":"","guid":181893,"unread":true,"content":"<article>arXiv:2504.12398v3 Announce Type: replace \nAbstract: Parametric arrays (PA) offer exceptional directivity and compactness compared to conventional loudspeakers, facilitating various acoustic applications. However, accurate measurement of audio signals generated by PA remains challenging due to spurious ultrasonic sounds arising from microphone nonlinearities. Existing filtering methods, including Helmholtz resonators, phononic crystals, polymer films, and grazing incidence techniques, exhibit practical constraints such as size limitations, fabrication complexity, or insufficient attenuation. To address these issues, we propose and demonstrate a novel acoustic filter based on the design of a half-wavelength resonator. The developed filter exploits the nodal plane in acoustic pressure distribution, effectively minimizing microphone exposure to targeted ultrasonic frequencies. Fabrication via stereolithography (SLA) 3D printing ensures high dimensional accuracy, which is crucial for high-frequency acoustic filters. Finite element method (FEM) simulations guided filter optimization for suppression frequencies at 40 kHz and 60 kHz, achieving high transmission loss (TL) around 60 dB. Experimental validations confirm the filter's superior performance in significantly reducing spurious acoustic signals, as reflected in frequency response, beam pattern, and propagation curve measurements. The proposed filter ensures stable and precise acoustic characterization, independent of measurement distances and incidence angles. This new approach not only improves measurement accuracy but also enhances reliability and reproducibility in parametric array research and development.</article>","contentLength":1688,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Technological Complexity Based on Japanese Patent Data","url":"https://arxiv.org/abs/2504.11932","date":1751515200,"author":"","guid":181894,"unread":true,"content":"<article>arXiv:2504.11932v3 Announce Type: replace \nAbstract: As international competition intensifies in technologies, nations need to identify key technologies to foster innovation. However, the identification is difficult because a technology is independent, therefore has complex nature. Here, this study aims to assess patent technological fields by applying Technological Complexity Index from a corporate perspective, addressing its underutilization in Japan despite its potential. By utilizing carefully processed patent data from fiscal years 1981 to 2010, we analyze the bipartite network which consists of 1,938 corporations and 35 or 124 technological fields. Our findings provide quantitative characteristics of ubiquity and sophistication for patent fields, the detailed technological trends that reflect the social context, and methodological stability for policymakers and researchers, contributing to targeted innovation strategies in Japan.</article>","contentLength":949,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Survey on Efficient Vision-Language Models","url":"https://arxiv.org/abs/2504.09724","date":1751515200,"author":"","guid":181895,"unread":true,"content":"<article>arXiv:2504.09724v3 Announce Type: replace \nAbstract: Vision-language models (VLMs) integrate visual and textual information, enabling a wide range of applications such as image captioning and visual question answering, making them crucial for modern AI systems. However, their high computational demands pose challenges for real-time applications. This has led to a growing focus on developing efficient vision language models. In this survey, we review key techniques for optimizing VLMs on edge and resource-constrained devices. We also explore compact VLM architectures, frameworks and provide detailed insights into the performance-memory trade-offs of efficient VLMs. Furthermore, we establish a GitHub repository at https://github.com/MPSCUMBC/Efficient-Vision-Language-Models-A-Survey to compile all surveyed papers, which we will actively update. Our objective is to foster deeper research in this area.</article>","contentLength":911,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Multi-person Physics-based Pose Estimation for Combat Sports","url":"https://arxiv.org/abs/2504.08175","date":1751515200,"author":"","guid":181896,"unread":true,"content":"<article>arXiv:2504.08175v2 Announce Type: replace \nAbstract: We propose a novel framework for accurate 3D human pose estimation in combat sports using sparse multi-camera setups. Our method integrates robust multi-view 2D pose tracking via a transformer-based top-down approach, employing epipolar geometry constraints and long-term video object segmentation for consistent identity tracking across views. Initial 3D poses are obtained through weighted triangulation and spline smoothing, followed by kinematic optimization to refine pose accuracy. We further enhance pose realism and robustness by introducing a multi-person physics-based trajectory optimization step, effectively addressing challenges such as rapid motions, occlusions, and close interactions. Experimental results on diverse datasets, including a new benchmark of elite boxing footage, demonstrate state-of-the-art performance. Additionally, we release comprehensive annotated video datasets to advance future research in multi-person pose estimation for combat sports.</article>","contentLength":1031,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Beating Transformers using Synthetic Cognition","url":"https://arxiv.org/abs/2504.07619","date":1751515200,"author":"","guid":181897,"unread":true,"content":"<article>arXiv:2504.07619v3 Announce Type: replace \nAbstract: The road to Artificial General Intelligence goes through the generation of context-aware reactive behaviors, where the Transformer architecture has been proven to be the state-of-the-art. However, they still fail to develop reasoning. Recently, a novel approach for developing cognitive architectures, called Synthetic Cognition, has been proposed and implemented to develop instantaneous reactive behavior. In this study, we aim to explore the use of Synthetic Cognition to develop context-aware reactive behaviors. We propose a mechanism to deal with sequences for the recent implementation of Synthetic Cognition, and test it against DNA foundation models in DNA sequence classification tasks. In our experiments, our proposal clearly outperforms the DNA foundation models, obtaining the best score on more benchmark tasks than the alternatives. Thus, we achieve two goals: expanding Synthetic Cognition to deal with sequences, and beating the Transformer architecture for sequence classification.</article>","contentLength":1053,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Radiative Backpropagation with Non-Static Geometry","url":"https://arxiv.org/abs/2504.05750","date":1751515200,"author":"","guid":181898,"unread":true,"content":"<article>arXiv:2504.05750v3 Announce Type: replace \nAbstract: Radiative backpropagation-based (RB) methods efficiently compute reverse-mode derivatives in physically-based differentiable rendering by simulating the propagation of differential radiance. A key assumption is that differential radiance is transported like normal radiance. We observe that this holds only when scene geometry is static and demonstrate that current implementations of radiative backpropagation produce biased gradients when scene parameters change geometry. In this work, we derive the differential transport equation without assuming static geometry. An immediate consequence is that the parameterization matters when the sampling process is not differentiated: only surface integrals allow a local formulation of the derivatives, i.e., one in which moving surfaces do not affect the entire path geometry. While considerable effort has been devoted to handling discontinuities resulting from moving geometry, we show that a biased interior derivative compromises even the simplest inverse rendering tasks, regardless of discontinuities. An implementation based on our derivation leads to systematic convergence to the reference solution in the same setting and provides unbiased RB interior derivatives for path-space differentiable rendering.</article>","contentLength":1314,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis","url":"https://arxiv.org/abs/2504.05684","date":1751515200,"author":"","guid":181899,"unread":true,"content":"<article>arXiv:2504.05684v2 Announce Type: replace \nAbstract: This paper introduces Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning (TARO), a novel framework for high-fidelity and temporally coherent video-to-audio synthesis. Built upon flow-based transformers, which offer stable training and continuous transformations for enhanced synchronization and audio quality, TARO introduces two key innovations: (1) Timestep-Adaptive Representation Alignment (TRA), which dynamically aligns latent representations by adjusting alignment strength based on the noise schedule, ensuring smooth evolution and improved fidelity, and (2) Onset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp event-driven markers of audio-relevant visual moments to enhance synchronization with dynamic visual events. Extensive experiments on the VGGSound and Landscape datasets demonstrate that TARO outperforms prior methods, achieving relatively 53% lower Frechet Distance (FD), 29% lower Frechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its superior audio quality and synchronization precision.</article>","contentLength":1138,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EP-Diffuser: An Efficient Diffusion Model for Traffic Scene Generation and Prediction via Polynomial Representations","url":"https://arxiv.org/abs/2504.05422","date":1751515200,"author":"","guid":181900,"unread":true,"content":"<article>arXiv:2504.05422v2 Announce Type: replace \nAbstract: As the prediction horizon increases, predicting the future evolution of traffic scenes becomes increasingly difficult due to the multi-modal nature of agent motion. Most state-of-the-art (SotA) prediction models primarily focus on forecasting the most likely future. However, for the safe operation of autonomous vehicles, it is equally important to cover the distribution for plausible motion alternatives. To address this, we introduce EP-Diffuser, a novel parameter-efficient diffusion-based generative model designed to capture the distribution of possible traffic scene evolutions. Conditioned on road layout and agent history, our model acts as a predictor and generates diverse, plausible scene continuations. We benchmark EP-Diffuser against two SotA models in terms of accuracy and plausibility of predictions on the Argoverse 2 dataset. Despite its significantly smaller model size, our approach achieves both highly accurate and plausible traffic scene predictions. We further evaluate model generalization ability in an out-of-distribution (OoD) test setting using Waymo Open dataset and show superior robustness of our approach.</article>","contentLength":1194,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Recursive Training Loops in LLMs: How training data properties modulate distribution shift in generated data?","url":"https://arxiv.org/abs/2504.03814","date":1751515200,"author":"","guid":181901,"unread":true,"content":"<article>arXiv:2504.03814v3 Announce Type: replace \nAbstract: Large language models (LLMs) are increasingly used in the creation of online content, creating feedback loops as subsequent generations of models will be trained on this synthetic data. Such loops were shown to lead to distribution shifts - models misrepresenting the true underlying distributions of human data (also called model collapse). However, how human data properties affect such shifts remains poorly understood. In this paper, we provide the first empirical examination of the effect of such properties on the outcome of recursive training. We first confirm that using different human datasets leads to distribution shifts of different magnitudes. Through exhaustive manipulation of dataset properties combined with regression analyses, we then identify a set of properties predicting distribution shift magnitudes. Lexical diversity is found to amplify these shifts, while semantic diversity and data quality mitigate them. Furthermore, we find that these influences are highly modular: data scrapped from a given internet domain has little influence on the content generated for another domain. Finally, experiments on political bias reveal that human data properties affect whether the initial bias will be amplified or reduced. Overall, our results portray a novel view, where different parts of internet may undergo different types of distribution shift.</article>","contentLength":1423,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real-is-Sim: Bridging the Sim-to-Real Gap with a Dynamic Digital Twin","url":"https://arxiv.org/abs/2504.03597","date":1751515200,"author":"","guid":181902,"unread":true,"content":"<article>arXiv:2504.03597v2 Announce Type: replace \nAbstract: We introduce real-is-sim, a new approach to integrating simulation into behavior cloning pipelines. In contrast to real-only methods, which lack the ability to safely test policies before deployment, and sim-to-real methods, which require complex adaptation to cross the sim-to-real gap, our framework allows policies to seamlessly switch between running on real hardware and running in parallelized virtual environments. At the center of real-is-sim is a dynamic digital twin, powered by the Embodied Gaussian simulator, that synchronizes with the real world at 60Hz. This twin acts as a mediator between the behavior cloning policy and the real robot. Policies are trained using representations derived from simulator states and always act on the simulated robot, never the real one. During deployment, the real robot simply follows the simulated robot's joint states, and the simulation is continuously corrected with real world measurements. This setup, where the simulator drives all policy execution and maintains real-time synchronization with the physical world, shifts the responsibility of crossing the sim-to-real gap to the digital twin's synchronization mechanisms, instead of the policy itself. We demonstrate real-is-sim on a long-horizon manipulation task (PushT), showing that virtual evaluations are consistent with real-world results. We further show how real-world data can be augmented with virtual rollouts and compare to policies trained on different representations derived from the simulator state including object poses and rendered images from both static and robot-mounted cameras. Our results highlight the flexibility of the real-is-sim framework across training, evaluation, and deployment stages. Videos available at https://real-is-sim.github.io.</article>","contentLength":1832,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Scaling Open-Vocabulary Action Detection","url":"https://arxiv.org/abs/2504.03096","date":1751515200,"author":"","guid":181903,"unread":true,"content":"<article>arXiv:2504.03096v3 Announce Type: replace \nAbstract: In this work, we focus on scaling open-vocabulary action detection. Existing approaches for action detection are predominantly limited to closed-set scenarios and rely on complex, parameter-heavy architectures. Extending these models to the open-vocabulary setting poses two key challenges: (1) the lack of large-scale datasets with many action classes for robust training, and (2) parameter-heavy adaptations to a pretrained vision-language contrastive model to convert it for detection, risking overfitting the additional non-pretrained parameters to base action classes. Firstly, we introduce an encoder-only multimodal model for video action detection, reducing the reliance on parameter-heavy additions for video action detection. Secondly, we introduce a simple weakly supervised training strategy to exploit an existing closed-set action detection dataset for pretraining. Finally, we depart from the ill-posed base-to-novel benchmark used by prior works in open-vocabulary action detection and devise a new benchmark to evaluate on existing closed-set action detection datasets without ever using them for training, showing novel results to serve as baselines for future work.</article>","contentLength":1237,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Co-design of magnetic soft robots with large deformation and contacts via material point method and topology optimization","url":"https://arxiv.org/abs/2503.22767","date":1751515200,"author":"","guid":181904,"unread":true,"content":"<article>arXiv:2503.22767v2 Announce Type: replace \nAbstract: Magnetic soft robots embedded with hard magnetic particles enable untethered actuation via external magnetic fields, offering remote, rapid, and precise control, which is highly promising for biomedical applications. However, designing such systems is challenging due to the complex interplay of magneto-elastic dynamics, large deformation, solid contacts, time-varying stimuli, and posture-dependent loading. As a result, most existing research relies on heuristics and trial-and-error methods or focuses on the independent design of stimuli or structures under static conditions. We propose a topology optimization framework for magnetic soft robots that simultaneously designs structures, location-specific material magnetization and time-varying magnetic stimuli, accounting for large deformations, dynamic motion, and solid contacts. This is achieved by integrating generalized topology optimization with the magneto-elastic material point method, which supports GPU-accelerated parallel simulations and auto-differentiation for sensitivity analysis. We applied this framework to design magnetic robots for various tasks, including multi-task shape morphing and locomotion, in both 2D and 3D. The method autonomously generates optimized robotic systems to achieve target behaviors without requiring human intervention. Despite the nonlinear physics and large design space, it demonstrates high computational efficiency, completing all cases within minutes. The framework provides a computational foundation for the autonomous co-design of active soft materials in applications such as metasurfaces, drug delivery, and minimally invasive procedures.</article>","contentLength":1706,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning","url":"https://arxiv.org/abs/2503.21055","date":1751515200,"author":"","guid":181905,"unread":true,"content":"<article>arXiv:2503.21055v4 Announce Type: replace \nAbstract: Understanding a procedural activity requires modeling both how action steps transform the scene and how evolving scene transformations can influence the sequence of action steps, even those that are accidental or erroneous. Existing work has studied procedure-aware video representations by proposing novel approaches such as modeling the temporal order of actions, and has not explicitly learned the state changes (scene transformations). In this work, we study procedure-aware video representation learning by incorporating state-change descriptions generated by Large Language Models (LLMs) as supervision signals for video encoders. Moreover, we generate state-change counterfactuals that simulate hypothesized failure outcomes, allowing models to learn by imagining the unseen ``What if'' scenarios. This counterfactual reasoning facilitates the model's ability to understand the cause and effect of each step in an activity. To verify the procedure awareness of our model, we conduct extensive experiments on procedure-aware tasks, including temporal action segmentation, error detection, action phase classification, frame retrieval, multi-instance retrieval, and action recognition. Our results demonstrate the effectiveness of the proposed state-change descriptions and their counterfactuals, and achieve significant improvements on multiple tasks. We will make our source code and data publicly available soon.</article>","contentLength":1473,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation","url":"https://arxiv.org/abs/2503.20672","date":1751515200,"author":"","guid":181906,"unread":true,"content":"<article>arXiv:2503.20672v2 Announce Type: replace \nAbstract: Recently, state-of-the-art text-to-image generation models, such as Flux and Ideogram 2.0, have made significant progress in sentence-level visual text rendering. In this paper, we focus on the more challenging scenarios of article-level visual text rendering and address a novel task of generating high-quality business content, including infographics and slides, based on user provided article-level descriptive prompts and ultra-dense layouts. The fundamental challenges are twofold: significantly longer context lengths and the scarcity of high-quality business content data.\n  In contrast to most previous works that focus on a limited number of sub-regions and sentence-level prompts, ensuring precise adherence to ultra-dense layouts with tens or even hundreds of sub-regions in business content is far more challenging. We make two key technical contributions: (i) the construction of scalable, high-quality business content dataset, i.e., Infographics-650K, equipped with ultra-dense layouts and prompts by implementing a layer-wise retrieval-augmented infographic generation scheme; and (ii) a layout-guided cross attention scheme, which injects tens of region-wise prompts into a set of cropped region latent space according to the ultra-dense layouts, and refine each sub-regions flexibly during inference using a layout conditional CFG.\n  We demonstrate the strong results of our system compared to previous SOTA systems such as Flux and SD3 on our BizEval prompt set. Additionally, we conduct thorough ablation experiments to verify the effectiveness of each component. We hope our constructed Infographics-650K and BizEval can encourage the broader community to advance the progress of business content generation.</article>","contentLength":1782,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow","url":"https://arxiv.org/abs/2503.18968","date":1751515200,"author":"","guid":181907,"unread":true,"content":"<article>arXiv:2503.18968v3 Announce Type: replace \nAbstract: In modern medicine, clinical diagnosis relies on the comprehensive analysis of primarily textual and visual data, drawing on medical expertise to ensure systematic and rigorous reasoning. Recent advances in large Vision-Language Models (VLMs) and agent-based methods hold great potential for medical diagnosis, thanks to the ability to effectively integrate multi-modal patient data. However, they often provide direct answers and draw empirical-driven conclusions without quantitative analysis, which reduces their reliability and clinical usability. We propose MedAgent-Pro, a new agentic reasoning paradigm that follows the diagnosis principle in modern medicine, to decouple the process into sequential components for step-by-step, evidence-based reasoning. Our MedAgent-Pro workflow presents a hierarchical diagnostic structure to mirror this principle, consisting of disease-level standardized plan generation and patient-level personalized step-by-step reasoning. To support disease-level planning, an RAG-based agent is designed to retrieve medical guidelines to ensure alignment with clinical standards. For patient-level reasoning, we propose to integrate professional tools such as visual models to enable quantitative assessments. Meanwhile, we propose to verify the reliability of each step to achieve evidence-based diagnosis, enforcing rigorous logical reasoning and a well-founded conclusion. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases demonstrate the superiority of MedAgent-Pro to mainstream VLMs, agentic systems and state-of-the-art expert models. Ablation studies and human evaluation by clinical experts further validate its robustness and clinical relevance. Code is available at https://github.com/jinlab-imvr/MedAgent-Pro.</article>","contentLength":1855,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Self-Supervised Adaptation for Medical Image Analysis","url":"https://arxiv.org/abs/2503.18873","date":1751515200,"author":"","guid":181908,"unread":true,"content":"<article>arXiv:2503.18873v2 Announce Type: replace \nAbstract: Self-supervised adaptation (SSA) improves foundation model transfer to medical domains but is computationally prohibitive. Although parameter efficient fine-tuning methods such as LoRA have been explored for supervised adaptation, their effectiveness for SSA remains unknown. In this work, we introduce efficient self-supervised adaptation (ESSA), a framework that applies parameter-efficient fine-tuning techniques to SSA with the aim of reducing computational cost and improving adaptation performance. Among the methods tested, Attention Projection Layer Adaptation (APLA) sets a new state-of-the-art, consistently surpassing full-parameter SSA and supervised fine-tuning across diverse medical tasks, while reducing GPU memory by up to 40.1% and increasing training throughput by 25.2%, all while maintaining inference efficiency.</article>","contentLength":887,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficiently Vectorized MCMC on Modern Accelerators","url":"https://arxiv.org/abs/2503.17405","date":1751515200,"author":"","guid":181909,"unread":true,"content":"<article>arXiv:2503.17405v2 Announce Type: replace \nAbstract: With the advent of automatic vectorization tools (e.g., JAX's $\\texttt{vmap}$), writing multi-chain MCMC algorithms is often now as simple as invoking those tools on single-chain code. Whilst convenient, for various MCMC algorithms this results in a synchronization problem -- loosely speaking, at each iteration all chains running in parallel must wait until the last chain has finished drawing its sample. In this work, we show how to design single-chain MCMC algorithms in a way that avoids synchronization overheads when vectorizing with tools like $\\texttt{vmap}$ by using the framework of finite state machines (FSMs). Using a simplified model, we derive an exact theoretical form of the obtainable speed-ups using our approach, and use it to make principled recommendations for optimal algorithm design. We implement several popular MCMC algorithms as FSMs, including Elliptical Slice Sampling, HMC-NUTS, and Delayed Rejection, demonstrating speed-ups of up to an order of magnitude in experiments.</article>","contentLength":1058,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Truthful Elicitation of Imprecise Forecasts","url":"https://arxiv.org/abs/2503.16395","date":1751515200,"author":"","guid":181910,"unread":true,"content":"<article>arXiv:2503.16395v3 Announce Type: replace \nAbstract: The quality of probabilistic forecasts is crucial for decision-making under uncertainty. While proper scoring rules incentivize truthful reporting of precise forecasts, they fall short when forecasters face epistemic uncertainty about their beliefs, limiting their use in safety-critical domains where decision-makers (DMs) prioritize proper uncertainty management. To address this, we propose a framework for scoring imprecise forecasts -- forecasts given as a set of beliefs. Despite existing impossibility results for deterministic scoring rules, we enable truthful elicitation by drawing connection to social choice theory and introducing a two-way communication framework where DMs first share their aggregation rules (e.g., averaging or min-max) used in downstream decisions for resolving forecast ambiguity. This, in turn, helps forecasters resolve indecision during elicitation. We further show that truthful elicitation of imprecise forecasts is achievable using proper scoring rules randomized over the aggregation procedure. Our approach allows DM to elicit and integrate the forecaster's epistemic uncertainty into their decision-making process, thus improving credibility.</article>","contentLength":1238,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Using Large Language Models to Categorize Strategic Situations and Decipher Motivations Behind Human Behaviors","url":"https://arxiv.org/abs/2503.15752","date":1751515200,"author":"","guid":181911,"unread":true,"content":"<article>arXiv:2503.15752v5 Announce Type: replace \nAbstract: By varying prompts to a large language model, we can elicit the full range of human behaviors in a variety of different scenarios in classic economic games. By analyzing which prompts elicit which behaviors, we can categorize and compare different strategic situations, which can also help provide insight into what different economic scenarios induce people to think about. We discuss how this provides a first step towards a non-standard method of inferring (deciphering) the motivations behind the human behaviors. We also show how this deciphering process can be used to categorize differences in the behavioral tendencies of different populations.</article>","contentLength":705,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Concat-ID: Towards Universal Identity-Preserving Video Synthesis","url":"https://arxiv.org/abs/2503.14151","date":1751515200,"author":"","guid":181912,"unread":true,"content":"<article>arXiv:2503.14151v3 Announce Type: replace \nAbstract: We present Concat-ID, a unified framework for identity-preserving video generation. Concat-ID employs variational autoencoders to extract image features, which are then concatenated with video latents along the sequence dimension. It relies exclusively on inherent 3D self-attention mechanisms to incorporate them, eliminating the need for additional parameters or modules. A novel cross-video pairing strategy and a multi-stage training regimen are introduced to balance identity consistency and facial editability while enhancing video naturalness. Extensive experiments demonstrate Concat-ID's superiority over existing methods in both single and multi-identity generation, as well as its seamless scalability to multi-subject scenarios, including virtual try-on and background-controllable generation. Concat-ID establishes a new benchmark for identity-preserving video synthesis, providing a versatile and scalable solution for a wide range of applications.</article>","contentLength":1015,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for Distractor-free 3D Reconstruction","url":"https://arxiv.org/abs/2503.13176","date":1751515200,"author":"","guid":181913,"unread":true,"content":"<article>arXiv:2503.13176v2 Announce Type: replace \nAbstract: Reconstructing clean, distractor-free 3D scenes from real-world captures remains a significant challenge, particularly in highly dynamic and cluttered settings such as egocentric videos. To tackle this problem, we introduce DeGauss, a simple and robust self-supervised framework for dynamic scene reconstruction based on a decoupled dynamic-static Gaussian Splatting design. DeGauss models dynamic elements with foreground Gaussians and static content with background Gaussians, using a probabilistic mask to coordinate their composition and enable independent yet complementary optimization. DeGauss generalizes robustly across a wide range of real-world scenarios, from casual image collections to long, dynamic egocentric videos, without relying on complex heuristics or extensive supervision. Experiments on benchmarks including NeRF-on-the-go, ADT, AEA, Hot3D, and EPIC-Fields demonstrate that DeGauss consistently outperforms existing methods, establishing a strong baseline for generalizable, distractor-free 3D reconstructionin highly dynamic, interaction-rich environments. Project page: https://batfacewayne.github.io/DeGauss.io/</article>","contentLength":1192,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LUSD: Localized Update Score Distillation for Text-Guided Image Editing","url":"https://arxiv.org/abs/2503.11054","date":1751515200,"author":"","guid":181914,"unread":true,"content":"<article>arXiv:2503.11054v2 Announce Type: replace \nAbstract: While diffusion models show promising results in image editing given a target prompt, achieving both prompt fidelity and background preservation remains difficult. Recent works have introduced score distillation techniques that leverage the rich generative prior of text-to-image diffusion models to solve this task without additional fine-tuning. However, these methods often struggle with tasks such as object insertion. Our investigation of these failures reveals significant variations in gradient magnitude and spatial distribution, making hyperparameter tuning highly input-specific or unsuccessful. To address this, we propose two simple yet effective modifications: attention-based spatial regularization and gradient filtering-normalization, both aimed at reducing these variations during gradient updates. Experimental results show our method outperforms state-of-the-art score distillation techniques in prompt fidelity, improving successful edits while preserving the background. Users also preferred our method over state-of-the-art techniques across three metrics, and by 58-64% overall.</article>","contentLength":1154,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MorphisHash: Improving Space Efficiency of ShockHash for Minimal Perfect Hashing","url":"https://arxiv.org/abs/2503.10161","date":1751515200,"author":"","guid":181915,"unread":true,"content":"<article>arXiv:2503.10161v2 Announce Type: replace \nAbstract: A minimal perfect hash function (MPHF) maps a set of n keys to unique positions {1, ..., n}. Representing an MPHF requires at least 1.44 bits per key. ShockHash is a technique to construct an MPHF and requires just slightly more space. It gives each key two pseudo random candidate positions. If each key can be mapped to one of its two candidate positions such that there is exactly one key mapped to each position, then an MPHF is found. If not, ShockHash repeats the process with a new set of random candidate positions. ShockHash has to store how many repetitions were required and for each key to which of the two candidate positions it is mapped. However, when a given set of candidate positions can be used as MPHF then there is not only one but multiple ways of mapping the keys to one of their candidate positions such that the mapping results in an MPHF. This redundancy makes up for the majority of the remaining space overhead in ShockHash. In this paper, we present MorphisHash which is a technique that almost completely eliminates this redundancy. Our theoretical result is that MorphisHash saves {\\Theta}(ln(n)) bits compared to ShockHash. This corresponds to a factor of 20 less space overhead in practice. The technique to accomplish this might be of a more general interest to compress data structures.</article>","contentLength":1374,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"2HandedAfforder: Learning Precise Actionable Bimanual Affordances from Human Videos","url":"https://arxiv.org/abs/2503.09320","date":1751515200,"author":"","guid":181916,"unread":true,"content":"<article>arXiv:2503.09320v3 Announce Type: replace \nAbstract: When interacting with objects, humans effectively reason about which regions of objects are viable for an intended action, i.e., the affordance regions of the object. They can also account for subtle differences in object regions based on the task to be performed and whether one or two hands need to be used. However, current vision-based affordance prediction methods often reduce the problem to naive object part segmentation. In this work, we propose a framework for extracting affordance data from human activity video datasets. Our extracted 2HANDS dataset contains precise object affordance region segmentations and affordance class-labels as narrations of the activity performed. The data also accounts for bimanual actions, i.e., two hands co-ordinating and interacting with one or more objects. We present a VLM-based affordance prediction model, 2HandedAfforder, trained on the dataset and demonstrate superior performance over baselines in affordance region segmentation for various activities. Finally, we show that our predicted affordance regions are actionable, i.e., can be used by an agent performing a task, through demonstration in robotic manipulation scenarios. Project-website: https://sites.google.com/view/2handedafforder</article>","contentLength":1299,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dynamic Indexing Through Learned Indices with Worst-case Guarantees","url":"https://arxiv.org/abs/2503.05007","date":1751515200,"author":"","guid":181917,"unread":true,"content":"<article>arXiv:2503.05007v2 Announce Type: replace \nAbstract: Indexing data is a fundamental problem in computer science. Recently, various papers apply machine learning to this problem.\n  For a fixed integer $\\varepsilon$, a \\emph{learned index} is a function $h : \\mathcal{U} \\rightarrow [0, n]$ where $\\forall q \\in \\mathcal{U}$, $h(q) \\in [\\text{rank}(q) - \\varepsilon, \\text{rank}(q) + \\varepsilon]$. These works use machine learning to compute $h$. Then, they store $S$ in a sorted array $A$ and access $A[\\lfloor h(q) \\rfloor]$ to answer queries in $O(k + \\varepsilon + \\log |h|)$ time. Here, $k$ denotes the output size and $|h|$ the complexity of $h$. Ferragina and Vinciguerra (VLDB 2020) observe that creating a learned index is a geometric problem. They define the PGM index by restricting $h$ to a piecewise linear function and show a linear-time algorithm to compute a PGM index of approximate minimum complexity.\n  Since indexing queries are decomposable, the PGM index may be made dynamic through the logarithmic method. When allowing deletions, range query times deteriorate to worst-case $O(N + \\sum\\limits_i^{\\lceil \\log n \\rceil } (\\varepsilon + \\log |h_i|))$ time (where $N$ is the largest size of $S$ seen so far).\n  This paper offers a combination of theoretical insights and experiments as we apply techniques from computational geometry to dynamically maintain an approximately minimum-complexity learned index $h : \\mathcal{U} \\rightarrow [0, n]$ with $O(\\log^2 n)$ update time.\n  We also prove that if we restrict $h$ to lie in a specific subclass of piecewise-linear functions, then we can combine $h$ and hash maps to support queries in $O(k + \\varepsilon + \\log |h|)$ time (at the cost of increasing $|h|$). We implement our algorithm and compare it to the existing implementation. Our empirical analysis shows that our solution supports more efficient range queries in the special case where the update sequence contains many deletions.</article>","contentLength":1958,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"High-Precision Transformer-Based Visual Servoing for Humanoid Robots in Aligning Tiny Objects","url":"https://arxiv.org/abs/2503.04862","date":1751515200,"author":"","guid":181918,"unread":true,"content":"<article>arXiv:2503.04862v2 Announce Type: replace \nAbstract: High-precision tiny object alignment remains a common and critical challenge for humanoid robots in real-world. To address this problem, this paper proposes a vision-based framework for precisely estimating and controlling the relative position between a handheld tool and a target object for humanoid robots, e.g., a screwdriver tip and a screw head slot. By fusing images from the head and torso cameras on a robot with its head joint angles, the proposed Transformer-based visual servoing method can correct the handheld tool's positional errors effectively, especially at a close distance. Experiments on M4-M8 screws demonstrate an average convergence error of 0.8-1.3 mm and a success rate of 93\\%-100\\%. Through comparative analysis, the results validate that this capability of high-precision tiny object alignment is enabled by the Distance Estimation Transformer architecture and the Multi-Perception-Head mechanism proposed in this paper.</article>","contentLength":1002,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Adaptive Traffic Signal Control based on Multi-Agent Reinforcement Learning. Case Study on a simulated real-world corridor","url":"https://arxiv.org/abs/2503.02189","date":1751515200,"author":"","guid":181919,"unread":true,"content":"<article>arXiv:2503.02189v4 Announce Type: replace \nAbstract: Previous studies that have formulated multi-agent reinforcement learning (RL) algorithms for adaptive traffic signal control have primarily used value-based RL methods. However, recent literature has shown that policy-based methods may perform better in partially observable environments. Additionally, RL methods remain largely untested for real-world normally signal timing plans because of the simplifying assumptions common in the literature. The current study attempts to address these gaps and formulates a multi-agent proximal policy optimization (MA-PPO) algorithm to implement adaptive and coordinated traffic control along an arterial corridor. The formulated MA-PPO has a centralized-critic architecture under a centralized training and decentralized execution framework. Agents are designed to allow selection and implementation of up to eight signal phases, as commonly implemented in field controllers. The formulated algorithm is tested on a simulated real-world seven intersection corridor. The speed of convergence for each agent was found to depend on the size of the action space, which depends on the number and sequence of signal phases. The performance of the formulated MA-PPO adaptive control algorithm is compared with the field implemented actuated-coordinated signal control (ASC), modeled using PTV-Vissim-MaxTime software in the loop simulation (SILs). The trained MA-PPO performed significantly better than the ASC for all movements. Compared to ASC the MA-PPO showed 2% and 24% improvements in travel time in the primary and secondary coordination directions, respectively. For cross streets movements MA-PPO also showed significant crossing time reductions. Volume sensitivity experiments revealed that the formulated MA-PPO demonstrated good stability, robustness, and adaptability to changes in traffic demand.</article>","contentLength":1897,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SFO: Piloting VLM Feedback for Offline RL","url":"https://arxiv.org/abs/2503.01062","date":1751515200,"author":"","guid":181920,"unread":true,"content":"<article>arXiv:2503.01062v4 Announce Type: replace \nAbstract: While internet-scale image and textual data have enabled strong generalization in Vision-Language Models (VLMs), the absence of internet-scale control data has impeded the development of similar generalization in standard reinforcement learning (RL) agents. Although VLMs are fundamentally limited in their ability to solve control tasks due to their lack of action-conditioned training data, their capacity for image understanding allows them to provide valuable feedback in RL tasks by recognizing successful outcomes. A key challenge in Reinforcement Learning from AI Feedback (RLAIF) is determining how best to integrate VLM-derived signals into the learning process. We explore this question in the context of offline RL and introduce a class of methods called sub-trajectory filtered optimization. We identify three key insights. First, trajectory length plays a crucial role in offline RL, as full-trajectory preference learning exacerbates the stitching problem, necessitating the use of sub-trajectories. Second, even in Markovian environments, a non-Markovian reward signal from a sequence of images is required to assess trajectory improvement, as VLMs do not interpret control actions and must rely on visual cues over time. Third, a simple yet effective approach--filtered and weighted behavior cloning--consistently outperforms more complex reinforcement learning from human feedback-based methods. We propose sub-trajectory filtered behavior cloning, a method that leverages VLM feedback on sub-trajectories while incorporating a retrospective filtering mechanism that removes sub-trajectories preceding failures to improve robustness and prevent turbulence. This study is preliminary; we provide initial evidence through evaluations on a toy control domain. Please enjoy our airport puns.</article>","contentLength":1857,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Efficient Educational Chatbots: Benchmarking RAG Frameworks","url":"https://arxiv.org/abs/2503.00781","date":1751515200,"author":"","guid":181921,"unread":true,"content":"<article>arXiv:2503.00781v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have proven immensely beneficial in education by capturing vast amounts of literature-based information, allowing them to generate context without relying on external sources. In this paper, we propose a generative AI-powered GATE question-answering framework (GATE stands for Graduate Aptitude Test in Engineering) that leverages LLMs to explain GATE solutions and support students in their exam preparation. We conducted extensive benchmarking to select the optimal embedding model and LLM, evaluating our framework based on criteria such as latency, faithfulness, and relevance, with additional validation through human evaluation. Our chatbot integrates state-of-the-art embedding models and LLMs to deliver accurate, context-aware responses. Through rigorous experimentation, we identified configurations that balance performance and computational efficiency, ensuring a reliable chatbot to serve students' needs. Additionally, we discuss the challenges faced in data processing and modeling and implemented solutions. Our work explores the application of Retrieval-Augmented Generation (RAG) for GATE Q/A explanation tasks, and our findings demonstrate significant improvements in retrieval accuracy and response quality. This research offers practical insights for developing effective AI-driven educational tools while highlighting areas for future enhancement in usability and scalability.</article>","contentLength":1480,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Legged Robot State Estimation Using Invariant Neural-Augmented Kalman Filter with a Neural Compensator","url":"https://arxiv.org/abs/2503.00344","date":1751515200,"author":"","guid":181922,"unread":true,"content":"<article>arXiv:2503.00344v2 Announce Type: replace \nAbstract: This paper presents an algorithm to improve state estimation for legged robots. Among existing model-based state estimation methods for legged robots, the contact-aided invariant extended Kalman filter defines the state on a Lie group to preserve invariance, thereby significantly accelerating convergence. It achieves more accurate state estimation by leveraging contact information as measurements for the update step. However, when the model exhibits strong nonlinearity, the estimation accuracy decreases. Such nonlinearities can cause initial errors to accumulate and lead to large drifts over time. To address this issue, we propose compensating for errors by augmenting the Kalman filter with an artificial neural network serving as a nonlinear function approximator. Furthermore, we design this neural network to respect the Lie group structure to ensure invariance, resulting in our proposed Invariant Neural-Augmented Kalman Filter (InNKF). The proposed algorithm offers improved state estimation performance by combining the strengths of model-based and learning-based approaches. Project webpage: https://seokju-lee.github.io/innkf_webpage</article>","contentLength":1204,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On the time complexity of finding a well-spread perfect matching in bridgeless cubic graphs","url":"https://arxiv.org/abs/2503.00263","date":1751515200,"author":"","guid":181923,"unread":true,"content":"<article>arXiv:2503.00263v2 Announce Type: replace \nAbstract: We present an algorithm for finding a perfect matching in a $3$-edge-connected cubic graph that intersects every $3$-edge cut in exactly one edge. Specifically, we propose an algorithm with a time complexity of $O(n \\log^4 n)$, which significantly improves upon the previously known $O(n^3)$-time algorithms for the same problem. The technique we use for the improvement is efficient use of cactus model of 3-edge cuts. As an application, we use our algorithm to compute embeddings of $3$-edge-connected cubic graphs with limited number of singular edges (i.e., edges that are twice in the boundary of one face) in $O(n \\log^4 n)$ time; this application contributes to the study of the well-known Cycle Double Cover conjecture.</article>","contentLength":780,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"optimizn: a Python Library for Developing Customized Optimization Algorithms","url":"https://arxiv.org/abs/2503.00033","date":1751515200,"author":"","guid":181924,"unread":true,"content":"<article>arXiv:2503.00033v2 Announce Type: replace \nAbstract: Combinatorial optimization problems are prevalent across a wide variety of domains. These problems are often nuanced, their optimal solutions might not be efficiently obtainable, and they may require lots of time and compute resources to solve (they are NP-hard). It follows that the best course of action for solving these problems is to use general optimization algorithm paradigms to quickly and easily develop algorithms that are customized to these problems and can produce good solutions in a reasonable amount of time. In this paper, we present optimizn, a Python library for developing customized optimization algorithms under general optimization algorithm paradigms (simulated annealing, branch and bound). Additionally, optimizn offers continuous training, with which users can run their algorithms on a regular cadence, retain the salient aspects of previous runs, and use them in subsequent runs to potentially produce solutions that get closer and closer to optimality. An earlier version of this paper was peer reviewed and published internally at Microsoft.</article>","contentLength":1126,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"KatFishNet: Detecting LLM-Generated Korean Text through Linguistic Feature Analysis","url":"https://arxiv.org/abs/2503.00032","date":1751515200,"author":"","guid":181925,"unread":true,"content":"<article>arXiv:2503.00032v4 Announce Type: replace \nAbstract: The rapid advancement of large language models (LLMs) increases the difficulty of distinguishing between human-written and LLM-generated text. Detecting LLM-generated text is crucial for upholding academic integrity, preventing plagiarism, protecting copyrights, and ensuring ethical research practices. Most prior studies on detecting LLM-generated text focus primarily on English text. However, languages with distinct morphological and syntactic characteristics require specialized detection approaches. Their unique structures and usage patterns can hinder the direct application of methods primarily designed for English. Among such languages, we focus on Korean, which has relatively flexible spacing rules, a rich morphological system, and less frequent comma usage compared to English. We introduce KatFish, the first benchmark dataset for detecting LLM-generated Korean text. The dataset consists of text written by humans and generated by four LLMs across three genres.\n  By examining spacing patterns, part-of-speech diversity, and comma usage, we illuminate the linguistic differences between human-written and LLM-generated Korean text. Building on these observations, we propose KatFishNet, a detection method specifically designed for the Korean language. KatFishNet achieves an average of 19.78% higher AUROC compared to the best-performing existing detection method. Our code and data are available at https://github.com/Shinwoo-Park/detecting_llm_generated_korean_text_through_linguistic_analysis.</article>","contentLength":1568,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models","url":"https://arxiv.org/abs/2502.18443","date":1751515200,"author":"","guid":181926,"unread":true,"content":"<article>arXiv:2502.18443v3 Announce Type: replace \nAbstract: PDF documents have the potential to provide trillions of novel, high-quality tokens for training language models. However, these documents come in a diversity of types with differing formats and visual layouts that pose a challenge when attempting to extract and faithfully represent the underlying content for language model use. Traditional open source tools often produce lower quality extractions compared to vision language models (VLMs), but reliance on the best VLMs can be prohibitively costly (e.g., over 6,240 USD per million PDF pages for GPT-4o) or infeasible if the PDFs cannot be sent to proprietary APIs. We present olmOCR, an open-source toolkit for processing PDFs into clean, linearized plain text in natural reading order while preserving structured content like sections, tables, lists, equations, and more. Our toolkit runs a fine-tuned 7B vision language model (VLM) trained on olmOCR-mix-0225, a sample of 260,000 pages from over 100,000 crawled PDFs with diverse properties, including graphics, handwritten text and poor quality scans. olmOCR is optimized for large-scale batch processing, able to scale flexibly to different hardware setups and can convert a million PDF pages for only 176 USD. To aid comparison with existing systems, we also introduce olmOCR-Bench, a curated set of 1,400 PDFs capturing many content types that remain challenging even for the best tools and VLMs, including formulas, tables, tiny fonts, old scans, and more. We find olmOCR outperforms even top VLMs including GPT-4o, Gemini Flash 2 and Qwen-2.5-VL. We openly release all components of olmOCR: our fine-tuned VLM model, training code and data, an efficient inference pipeline that supports vLLM and SGLang backends, and benchmark olmOCR-Bench.</article>","contentLength":1806,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MOMENTI: Scalable Motif Mining in Multidimensional Time Series","url":"https://arxiv.org/abs/2502.14446","date":1751515200,"author":"","guid":181927,"unread":true,"content":"<article>arXiv:2502.14446v2 Announce Type: replace \nAbstract: Time series play a fundamental role in many domains, capturing a plethora of information about the underlying data-generating processes. When a process generates multiple synchronized signals we are faced with multidimensional time series. In this context a fundamental problem is that of motif mining, where we seek patterns repeating twice with minor variations, spanning some of the dimensions. State of the art exact solutions for this problem run in time quadratic in the length of the input time series.\n  We provide a scalable method to find the top-k motifs in multidimensional time series with probabilistic guarantees on the quality of the results. Our algorithm runs in time subquadratic in the length of the input, and returns the exact solution with probability at least $1-\\delta$, where $\\delta$ is a user-defined parameter. The algorithm is designed to be adaptive to the input distribution, self-tuning its parameters while respecting user-defined limits on the memory to use.\n  Our theoretical analysis is complemented by an extensive experimental evaluation, showing that our algorithm is orders of magnitude faster than the state of the art.</article>","contentLength":1214,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"VLM2-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues","url":"https://arxiv.org/abs/2502.12084","date":1751515200,"author":"","guid":181928,"unread":true,"content":"<article>arXiv:2502.12084v4 Announce Type: replace \nAbstract: Visually linking matching cues is a crucial ability in daily life, such as identifying the same person in multiple photos based on their cues, even without knowing who they are. Despite the extensive knowledge that vision-language models (VLMs) possess, it remains largely unexplored whether they are capable of performing this fundamental task. To address this, we introduce \\textbf{VLM2-Bench}, a benchmark designed to assess whether VLMs can Visually Link Matching cues, with 9 subtasks and over 3,000 test cases. Comprehensive evaluation across twelve VLMs, along with further analysis of various language-side and vision-side prompting methods, leads to a total of eight key findings. We identify critical challenges in models' ability to link visual cues, highlighting a significant performance gap. Based on these insights, we advocate for (i) enhancing core visual capabilities to improve adaptability and reduce reliance on prior knowledge, (ii) establishing clearer principles for integrating language-based reasoning in vision-centric tasks to prevent unnecessary biases, and (iii) shifting vision-text training paradigms toward fostering models' ability to independently structure and infer relationships among visual cues.</article>","contentLength":1288,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Robust 6DoF Pose Tracking Considering Contour and Interior Correspondence Uncertainty for AR Assembly Guidance","url":"https://arxiv.org/abs/2502.11971","date":1751515200,"author":"","guid":181929,"unread":true,"content":"<article>arXiv:2502.11971v4 Announce Type: replace \nAbstract: Augmented reality assembly guidance is essential for intelligent manufacturing and medical applications, requiring continuous measurement of the 6DoF poses of manipulated objects. Although current tracking methods have made significant advancements in accuracy and efficiency, they still face challenges in robustness when dealing with cluttered backgrounds, rotationally symmetric objects, and noisy sequences. In this paper, we first propose a robust contour-based pose tracking method that addresses error-prone contour correspondences and improves noise tolerance. It utilizes a fan-shaped search strategy to refine correspondences and models local contour shape and noise uncertainty as mixed probability distribution, resulting in a highly robust contour energy function. Secondly, we introduce a CPU-only strategy to better track rotationally symmetric objects and assist the contour-based method in overcoming local minima by exploring sparse interior correspondences. This is achieved by pre-sampling interior points from sparse viewpoint templates offline and using the DIS optical flow algorithm to compute their correspondences during tracking. Finally, we formulate a unified energy function to fuse contour and interior information, which is solvable using a re-weighted least squares algorithm. Experiments on public datasets and real scenarios demonstrate that our method significantly outperforms state-of-the-art monocular tracking methods and can achieve more than 100 FPS using only a CPU.</article>","contentLength":1562,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FE-LWS: Refined Image-Text Representations via Decoder Stacking and Fused Encodings for Remote Sensing Image Captioning","url":"https://arxiv.org/abs/2502.09282","date":1751515200,"author":"","guid":181930,"unread":true,"content":"<article>arXiv:2502.09282v2 Announce Type: replace \nAbstract: Remote sensing image captioning aims to generate descriptive text from remote sensing images, typically employing an encoder-decoder framework. In this setup, a convolutional neural network (CNN) extracts feature representations from the input image, which then guide the decoder in a sequence-to-sequence caption generation process. Although much research has focused on refining the decoder, the quality of image representations from the encoder remains crucial for accurate captioning. This paper introduces a novel approach that integrates features from two distinct CNN based encoders, capturing complementary information to enhance caption generation. Additionally, we propose a weighted averaging technique to combine the outputs of all GRUs in the stacked decoder. Furthermore, a comparison-based beam search strategy is incorporated to refine caption selection. The results demonstrate that our fusion-based approach, along with the enhanced stacked decoder, significantly outperforms both the transformer-based state-of-the-art model and other LSTM-based baselines.</article>","contentLength":1128,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DGenNO: A Novel Physics-aware Neural Operator for Solving Forward and Inverse PDE Problems based on Deep, Generative Probabilistic Modeling","url":"https://arxiv.org/abs/2502.06250","date":1751515200,"author":"","guid":181931,"unread":true,"content":"<article>arXiv:2502.06250v3 Announce Type: replace \nAbstract: Solving parametric partial differential equations (PDEs) and associated PDE-based, inverse problems is a central task in engineering and physics, yet existing neural operator methods struggle with high-dimensional, discontinuous inputs and require large amounts of {\\em labeled} training data. We propose the Deep Generative Neural Operator (DGenNO), a physics-aware framework that addresses these challenges by leveraging a deep, generative, probabilistic model in combination with a set of lower-dimensional, latent variables that simultaneously encode PDE-inputs and PDE-outputs. This formulation can make use of unlabeled data and significantly improves inverse problem-solving, particularly for discontinuous or discrete-valued input functions. DGenNO enforces physics constraints without labeled data by incorporating as virtual observables, weak-form residuals based on compactly supported radial basis functions (CSRBFs). These relax regularity constraints and eliminate higher-order derivatives from the objective function. We also introduce MultiONet, a novel neural operator architecture, which is a more expressive generalization of the popular DeepONet that significantly enhances the approximating power of the proposed model. These innovations make DGenNO particularly effective for challenging forward and inverse, PDE-based problems, such as those involving multi-phase media. Numerical experiments demonstrate that DGenNO achieves higher accuracy across multiple benchmarks while exhibiting robustness to noise and strong generalization to out-of-distribution cases. Its adaptability, and the ability to handle sparse, noisy data while providing probabilistic estimates, make DGenNO a powerful tool for scientific and engineering applications.</article>","contentLength":1814,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Combined Search and Encoding for Seeds, with an Application to Minimal Perfect Hashing","url":"https://arxiv.org/abs/2502.05613","date":1751515200,"author":"","guid":181932,"unread":true,"content":"<article>arXiv:2502.05613v2 Announce Type: replace \nAbstract: Randomised algorithms often employ methods that can fail and that are retried with independent randomness until they succeed. Randomised data structures therefore often store indices of successful attempts, called seeds. If $n$ such seeds are required (e.g., for independent substructures) the standard approach is to compute for each $i \\in [n]$ the smallest successful seed $S_i$ and store $\\vec{S} = (S_1, \\ldots, S_n)$.\n  The central observation of this paper is that this is not space-optimal. We present a different algorithm that computes a sequence $\\vec{S}' = (S_1', \\ldots, S_n')$ of successful seeds such that the entropy of $\\vec{S'}$ undercuts the entropy of $\\vec{S}$ by $\\Omega(n)$ bits in most cases. To achieve a memory consumption of $\\mathrm{OPT}+\\varepsilon n$, the expected number of inspected seeds increases by a factor of $O(1/\\varepsilon)$.\n  We demonstrate the usefulness of our findings with a novel construction for minimal perfect hash functions that, for $n$ keys and any $\\varepsilon \\in [n^{-3/7}, 1]$, has space requirement $(1+\\varepsilon)\\mathrm{OPT}$ and construction time $O(n/\\varepsilon)$. All previous approaches only support $\\varepsilon = \\omega(1 / \\log n)$ or have construction times that increase exponentially with $1/\\varepsilon$. Our implementation beats the construction throughput of the state of the art by more than two orders of magnitude for $\\varepsilon \\leq 3\\%$.</article>","contentLength":1472,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features","url":"https://arxiv.org/abs/2502.04320","date":1751515200,"author":"","guid":181933,"unread":true,"content":"<article>arXiv:2502.04320v2 Announce Type: replace \nAbstract: Do the rich representations of multi-modal diffusion transformers (DiTs) exhibit unique properties that enhance their interpretability? We introduce ConceptAttention, a novel method that leverages the expressive power of DiT attention layers to generate high-quality saliency maps that precisely locate textual concepts within images. Without requiring additional training, ConceptAttention repurposes the parameters of DiT attention layers to produce highly contextualized concept embeddings, contributing the major discovery that performing linear projections in the output space of DiT attention layers yields significantly sharper saliency maps compared to commonly used cross-attention maps. ConceptAttention even achieves state-of-the-art performance on zero-shot image segmentation benchmarks, outperforming 15 other zero-shot interpretability methods on the ImageNet-Segmentation dataset. ConceptAttention works for popular image models and even seamlessly generalizes to video generation. Our work contributes the first evidence that the representations of multi-modal DiTs are highly transferable to vision tasks like segmentation.</article>","contentLength":1194,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Actions Speak Louder Than Words: Rate-Reward Trade-off in Markov Decision Processes","url":"https://arxiv.org/abs/2502.03335","date":1751515200,"author":"","guid":181934,"unread":true,"content":"<article>arXiv:2502.03335v2 Announce Type: replace \nAbstract: The impact of communication on decision-making systems has been extensively studied under the assumption of dedicated communication channels. We instead consider communicating through actions, where the message is embedded into the actions of an agent which interacts with the environment in a Markov decision process (MDP) framework. We conceptualize the MDP environment as a finite-state channel (FSC), where the actions of the agent serve as the channel input, while the states of the MDP observed by another agent (i.e., receiver) serve as the channel output. Here, we treat the environment as a communication channel over which the agent communicates through its actions, while at the same time, trying to maximize its reward. We first characterize the optimal information theoretic trade-off between the average reward and the rate of reliable communication in the infinite-horizon regime. Then, we propose a novel framework to design a joint control/coding policy, termed \\textit{Act2Comm}, which seamlessly embeds messages into actions. From a communication perspective, \\textit{Act2Comm} functions as a learning-based channel coding scheme for non-differentiable FSCs under input-output constraints. From a control standpoint, \\textit{Act2Comm} learns an MDP policy that incorporates communication capabilities, though at the cost of some control performance. Overall, \\textit{Act2Comm} effectively balances the dual objectives of control and communication in this environment. Experimental results validate \\textit{Act2Comm}'s capability to enable reliable communication while maintaining a certain level of control performance.</article>","contentLength":1691,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Finite Sample Analysis of Subspace Identification for Stochastic Systems","url":"https://arxiv.org/abs/2501.18853","date":1751515200,"author":"","guid":181935,"unread":true,"content":"<article>arXiv:2501.18853v5 Announce Type: replace \nAbstract: The subspace identification method (SIM) has become a widely adopted approach for the identification of discrete-time linear time-invariant (LTI) systems. In this paper, we derive finite sample high-probability error bounds for the system matrices $A,C$, the Kalman filter gain $K$ and the estimation of system poles. Specifically, we demonstrate that, ignoring the logarithmic factors, for an $n$-dimensional LTI system with no external inputs, the estimation error of these matrices decreases at a rate of at least $ \\mathcal{O}(\\sqrt{1/N}) $, while the estimation error of the system poles decays at a rate of at least $ \\mathcal{O}(N^{-1/2n}) $, where $ N $ represents the number of sample trajectories. Furthermore, we reveal that achieving a constant estimation error requires a super-polynomial sample size in $n/m $, where $n/m$ denotes the state-to-output dimension ratio. Finally, numerical experiments are conducted to validate the non-asymptotic results.</article>","contentLength":1019,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Wireless Network Topology Inference: A Markov Chains Approach","url":"https://arxiv.org/abs/2501.17532","date":1751515200,"author":"","guid":181936,"unread":true,"content":"<article>arXiv:2501.17532v2 Announce Type: replace \nAbstract: We address the problem of inferring the topology of a wireless network using limited observational data. Specifically, we assume that we can detect when a node is transmitting, but no further information regarding the transmission is available. We propose a novel network estimation procedure grounded in the following abstract problem: estimating the parameters of a finite discrete-time Markov chain by observing, at each time step, which states are visited by multiple ``anonymous'' copies of the chain. We develop a consistent estimator that approximates the transition matrix of the chain in the operator norm, with the number of required samples scaling roughly linearly with the size of the state space. Applying this estimation procedure to wireless networks, our numerical experiments demonstrate that the proposed method accurately infers network topology across a wide range of parameters, consistently outperforming transfer entropy, particularly under conditions of high network congestion.</article>","contentLength":1056,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Beyond-Labels: Advancing Open-Vocabulary Segmentation With Vision-Language Models","url":"https://arxiv.org/abs/2501.16769","date":1751515200,"author":"","guid":181937,"unread":true,"content":"<article>arXiv:2501.16769v5 Announce Type: replace \nAbstract: Open-vocabulary semantic segmentation attempts to classify and outline objects in an image using arbitrary text labels, including those unseen during training. Self-supervised learning resolves numerous visual and linguistic processing problems when effectively trained. This study investigates simple yet efficient methods for adapting previously learned foundation models for open-vocabulary semantic segmentation tasks. Our research proposes \"Beyond-Labels\", a lightweight transformer-based fusion module that uses a small amount of image segmentation data to fuse frozen visual representations with language concepts. This strategy allows the model to leverage the extensive knowledge of pre-trained models without requiring significant retraining, making the approach data-efficient and scalable. Furthermore, we capture positional information in images using Fourier embeddings, improving generalization and enabling smooth and consistent spatial encoding. We perform thorough ablation studies to examine the main components of our proposed method. On the standard benchmark PASCAL-5i, the method performs better despite being trained on frozen vision and language representations.\n  Index Terms: Beyond-Labels, open-vocabulary semantic segmentation, Fourier embeddings, PASCAL-5i</article>","contentLength":1339,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Blockchain Address Poisoning","url":"https://arxiv.org/abs/2501.16681","date":1751515200,"author":"","guid":181938,"unread":true,"content":"<article>arXiv:2501.16681v3 Announce Type: replace \nAbstract: In many blockchains, e.g., Ethereum, Binance Smart Chain (BSC), the primary representation used for wallet addresses is a hardly memorable 40-digit hexadecimal string. As a result, users often select addresses from their recent transaction history, which enables blockchain address poisoning. The adversary first generates lookalike addresses similar to one with which the victim has previously interacted, and then engages with the victim to ``poison'' their transaction history. The goal is to have the victim mistakenly send tokens to the lookalike address, as opposed to the intended recipient. Compared to contemporary studies, this paper provides four notable contributions. First, we develop a detection system and perform measurements over two years on both Ethereum and BSC. We identify 13~times more attack attempts than reported previously -- totaling 270M on-chain attacks targeting 17M victims. 6,633 incidents have caused at least 83.8M USD in losses, which makes blockchain address poisoning one of the largest cryptocurrency phishing schemes observed in the wild. Second, we analyze a few large attack entities using improved clustering techniques, and model attacker profitability and competition. Third, we reveal attack strategies -- targeted populations, success conditions (address similarity, timing), and cross-chain attacks. Fourth, we mathematically define and simulate the lookalike address generation process across various software- and hardware-based implementations, and identify a large-scale attacker group that appears to use GPUs. We also discuss defensive countermeasures.</article>","contentLength":1660,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Distributional Information Embedding: A Framework for Multi-bit Watermarking","url":"https://arxiv.org/abs/2501.16558","date":1751515200,"author":"","guid":181939,"unread":true,"content":"<article>arXiv:2501.16558v2 Announce Type: replace \nAbstract: This paper introduces a novel problem, distributional information embedding, motivated by the practical demands of multi-bit watermarking for large language models (LLMs). Unlike traditional information embedding, which embeds information into a pre-existing host signal, LLM watermarking actively controls the text generation process--adjusting the token distribution--to embed a detectable signal. We develop an information-theoretic framework to analyze this distributional information embedding problem, characterizing the fundamental trade-offs among three critical performance metrics: text quality, detectability, and information rate. In the asymptotic regime, we demonstrate that the maximum achievable rate with vanishing error corresponds to the entropy of the LLM's output distribution and increases with higher allowable distortion. We also characterize the optimal watermarking scheme to achieve this rate. Extending the analysis to the finite-token case with non-i.i.d. tokens, we identify schemes that maximize detection probability while adhering to constraints on false alarm and distortion.</article>","contentLength":1162,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Principal Graph Encoder Embedding and Principal Community Detection","url":"https://arxiv.org/abs/2501.14939","date":1751515200,"author":"","guid":181940,"unread":true,"content":"<article>arXiv:2501.14939v2 Announce Type: replace \nAbstract: In this paper, we introduce the concept of principal communities and propose a principal graph encoder embedding method that concurrently detects these communities and achieves vertex embedding. Given a graph adjacency matrix with vertex labels, the method computes a sample community score for each community, ranking them to measure community importance and estimate a set of principal communities. The method then produces a vertex embedding by retaining only the dimensions corresponding to these principal communities. Theoretically, we define the population version of the encoder embedding and the community score based on a random Bernoulli graph distribution. We prove that the population principal graph encoder embedding preserves the conditional density of the vertex labels and that the population community score successfully distinguishes the principal communities. We conduct a variety of simulations to demonstrate the finite-sample accuracy in detecting ground-truth principal communities, as well as the advantages in embedding visualization and subsequent vertex classification. The method is further applied to a set of real-world graphs, showcasing its numerical advantages, including robustness to label noise and computational scalability.</article>","contentLength":1316,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation","url":"https://arxiv.org/abs/2501.14400","date":1751515200,"author":"","guid":181941,"unread":true,"content":"<article>arXiv:2501.14400v2 Announce Type: replace \nAbstract: Real-world tasks such as garment manipulation and table rearrangement demand robots to perform generalizable, highly precise, and long-horizon actions. Although imitation learning has proven to be an effective approach for teaching robots new skills, large amounts of expert demonstration data are still indispensible for these complex tasks, resulting in high sample complexity and costly data collection. To address this, we propose Semantic Keypoint Imitation Learning (SKIL), a framework which automatically obtains semantic keypoints with the help of vision foundation models, and forms the descriptor of semantic keypoints that enables efficient imitation learning of complex robotic tasks with significantly lower sample complexity. In real-world experiments, SKIL doubles the performance of baseline methods in tasks such as picking a cup or mouse, while demonstrating exceptional robustness to variations in objects, environmental changes, and distractors. For long-horizon tasks like hanging a towel on a rack where previous methods fail completely, SKIL achieves a mean success rate of 70\\% with as few as 30 demonstrations. Furthermore, SKIL naturally supports cross-embodiment learning due to its semantic keypoints abstraction. Our experiments demonstrate that even human videos bring considerable improvement to the learning performance. All these results demonstrate the great success of SKIL in achieving data-efficient generalizable robotic learning. Visualizations and code are available at: https://skil-robotics.github.io/SKIL-robotics/.</article>","contentLength":1611,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AirRadar: Inferring Nationwide Air Quality in China with Deep Neural Networks","url":"https://arxiv.org/abs/2501.13141","date":1751515200,"author":"","guid":181942,"unread":true,"content":"<article>arXiv:2501.13141v2 Announce Type: replace \nAbstract: Monitoring real-time air quality is essential for safeguarding public health and fostering social progress. However, the widespread deployment of air quality monitoring stations is constrained by their significant costs. To address this limitation, we introduce \\emph{AirRadar}, a deep neural network designed to accurately infer real-time air quality in locations lacking monitoring stations by utilizing data from existing ones. By leveraging learnable mask tokens, AirRadar reconstructs air quality features in unmonitored regions. Specifically, it operates in two stages: first capturing spatial correlations and then adjusting for distribution shifts. We validate AirRadar's efficacy using a year-long dataset from 1,085 monitoring stations across China, demonstrating its superiority over multiple baselines, even with varying degrees of unobserved data. The source code can be accessed at https://github.com/CityMind-Lab/AirRadar.</article>","contentLength":990,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Not eXactly Byzantine: Efficient and Resilient TEE-Based State Machine Replication","url":"https://arxiv.org/abs/2501.11051","date":1751515200,"author":"","guid":181943,"unread":true,"content":"<article>arXiv:2501.11051v3 Announce Type: replace \nAbstract: We propose, implement, and evaluate NxBFT, a resilient and efficient State Machine Replication protocol using Trusted Execution Environments (TEEs). NxBFT focuses on a \"Not eXactly Byzantine\" (NxB) operating model as a middle ground between crash and Byzantine fault tolerance. NxBFT's consensus layer is asynchronous, graph-based, leaderless, and optimized for the NxB operating model, enabling load-balancing of requests between replicas and, in fault-free cases, two network round trips between decisions. We identify fundamental issues with crash recovery due the use of TEEs in asynchrony that only can be circumvented by relying on synchrony for liveness. We provide a throughput-latency trade-off analysis of NxBFT, Chained-Damysus (rotating leader), and MinBFT (static leader) for up to 40 replicas and network round trip latencies up to 150 ms. NxBFT achieves the highest throughput in all scenarios. When small latencies are required, MinBFT and Damysus are at an advantage with Damysus benefiting from the NxB model in terms of throughput for small deployments. In contrast to leader-based approaches, NxBFT's performance is almost not impacted when actual crash faults occur.</article>","contentLength":1240,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Framework for Mining Collectively-Behaving Bots in MMORPGs","url":"https://arxiv.org/abs/2501.10461","date":1751515200,"author":"","guid":181944,"unread":true,"content":"<article>arXiv:2501.10461v2 Announce Type: replace \nAbstract: In MMORPGs (Massively Multiplayer Online Role-Playing Games), abnormal players (bots) using unauthorized automated programs to carry out pre-defined behaviors systematically and repeatedly are commonly observed. Bots usually engage in these activities to gain in-game money, which they eventually trade for real money outside the game. Such abusive activities negatively impact the in-game experiences of legitimate users since bots monopolize specific hunting areas and obtain valuable items. Thus, detecting abnormal players is a significant task for game companies. Motivated by the fact that bots tend to behave collectively with similar in-game trajectories due to the auto-programs, we developed BotTRep, a framework that comprises trajectory representation learning followed by clustering using a completely unlabeled in-game trajectory dataset. Our model aims to learn representations for in-game trajectory sequences so that players with contextually similar trajectories have closer embeddings. Then, by applying DBSCAN to these representations and visualizing the corresponding moving patterns, our framework ultimately assists game masters in identifying and banning bots.</article>","contentLength":1237,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Admitting Ignorance Helps the Video Question Answering Models to Answer","url":"https://arxiv.org/abs/2501.08771","date":1751515200,"author":"","guid":181945,"unread":true,"content":"<article>arXiv:2501.08771v2 Announce Type: replace \nAbstract: Significant progress has been made in the field of video question answering (VideoQA) thanks to deep learning and large-scale pretraining. Despite the presence of sophisticated model structures and powerful video-text foundation models, most existing methods focus solely on maximizing the correlation between answers and video-question pairs during training. We argue that these models often establish shortcuts, resulting in spurious correlations between questions and answers, especially when the alignment between video and text data is suboptimal. To address these spurious correlations, we propose a novel training framework in which the model is compelled to acknowledge its ignorance when presented with an intervened question, rather than making guesses solely based on superficial question-answer correlations. We introduce methodologies for intervening in questions, utilizing techniques such as displacement and perturbation, and design frameworks for the model to admit its lack of knowledge in both multi-choice VideoQA and open-ended settings. In practice, we integrate a state-of-the-art model into our framework to validate its effectiveness. The results clearly demonstrate that our framework can significantly enhance the performance of VideoQA models with minimal structural modifications.</article>","contentLength":1362,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation","url":"https://arxiv.org/abs/2501.06598","date":1751515200,"author":"","guid":181946,"unread":true,"content":"<article>arXiv:2501.06598v3 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in chart understanding tasks. However, interpreting charts with textual descriptions often leads to information loss, as it fails to fully capture the dense information embedded in charts. In contrast, parsing charts into code provides lossless representations that can effectively contain all critical details. Although existing open-source MLLMs have achieved success in chart understanding tasks, they still face two major challenges when applied to chart-to-code tasks: (1) Low executability and poor restoration of chart details in the generated code and (2) Lack of large-scale and diverse training data. To address these challenges, we propose \\textbf{ChartCoder}, the first dedicated chart-to-code MLLM, which leverages Code LLMs as the language backbone to enhance the executability of the generated code. Furthermore, we introduce \\textbf{Chart2Code-160k}, the first large-scale and diverse dataset for chart-to-code generation, and propose the \\textbf{Snippet-of-Thought (SoT)} method, which transforms direct chart-to-code generation data into step-by-step generation. Experiments demonstrate that ChartCoder, with only 7B parameters, surpasses existing open-source MLLMs on chart-to-code benchmarks, achieving superior chart restoration and code excitability. Our code is available at https://github.com/thunlp/ChartCoder.</article>","contentLength":1471,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DeFusion: An Effective Decoupling Fusion Network for Multi-Modal Pregnancy Prediction","url":"https://arxiv.org/abs/2501.04353","date":1751515200,"author":"","guid":181947,"unread":true,"content":"<article>arXiv:2501.04353v2 Announce Type: replace \nAbstract: Temporal embryo images and parental fertility table indicators are both valuable for pregnancy prediction in \\textbf{in vitro fertilization embryo transfer} (IVF-ET). However, current machine learning models cannot make full use of the complementary information between the two modalities to improve pregnancy prediction performance. In this paper, we propose a Decoupling Fusion Network called DeFusion to effectively integrate the multi-modal information for IVF-ET pregnancy prediction. Specifically, we propose a decoupling fusion module that decouples the information from the different modalities into related and unrelated information, thereby achieving a more delicate fusion. And we fuse temporal embryo images with a spatial-temporal position encoding, and extract fertility table indicator information with a table transformer. To evaluate the effectiveness of our model, we use a new dataset including 4046 cases collected from Southern Medical University. The experiments show that our model outperforms state-of-the-art methods. Meanwhile, the performance on the eye disease prediction dataset reflects the model's good generalization. Our code is available at https://github.com/Ou-Young-1999/DFNet.</article>","contentLength":1267,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Text to Band Gap: Pre-trained Language Models as Encoders for Semiconductor Band Gap Prediction","url":"https://arxiv.org/abs/2501.03456","date":1751515200,"author":"","guid":181948,"unread":true,"content":"<article>arXiv:2501.03456v2 Announce Type: replace \nAbstract: We investigate the use of transformer-based language models, RoBERTa, T5, and LLaMA, for predicting the band gaps of semiconductor materials directly from textual representations that encode key material features such as chemical composition, crystal system, space group, number of atoms per unit cell, valence electron count, and other relevant electronic and structural properties. Quantum chemistry simulations such as DFT provide accurate predictions but are computationally intensive, limiting their feasibility for large-scale materials screening. Shallow ML models offer faster alternatives but typically require extensive data preprocessing to convert non-numerical material features into structured numerical inputs, often at the cost of losing critical descriptive information. In contrast, our approach leverages pretrained language models to process textual data directly, eliminating the need for manual feature engineering. We construct material descriptions in two formats: structured strings that combine key features in a consistent template, and natural language narratives generated using the ChatGPT API. For each model, we append a custom regression head and perform task-specific finetuning on a curated dataset of inorganic compounds. Our results show that finetuned language models, particularly the decoder-only LLaMA-3 architecture, can outperform conventional approaches in prediction accuracy and flexibility, achieving an MAE of 0.25 eV and R2 of 0.89, compared to the best shallow ML baseline, which achieved an MAE of 0.32 eV and R2 of 0.84. Notably, LLaMA-3 achieves competitive accuracy with minimal finetuning, suggesting its architecture enables more transferable representations for scientific tasks. This work demonstrates the effectiveness of finetuned language models for scientific property prediction and provides a scalable, language-native framework for materials informatics.</article>","contentLength":1972,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The EnvDesign Model: A Method to Solve the Environment Design Problem","url":"https://arxiv.org/abs/2412.18109","date":1751515200,"author":"","guid":181949,"unread":true,"content":"<article>arXiv:2412.18109v4 Announce Type: replace \nAbstract: Today, several people and organizations rely on cloud platforms. The reliability of cloud platforms depends heavily on the performance of their internal programs (agents). To better prevent regressions in cloud platforms, the design of pre-production testing environments (that test new agents, new hardwares, and other changes) must take into account the diversity of server/node properties (hardware model, virtual machine type, etc.) across the fleet and dynamically emphasize or de-emphasize the prevalence of certain node properties based on current testing priorities. This paper formulates this task as the ``environment design\" problem and presents the EnvDesign model, a method that uses graph theory and optimization algorithms to solve the environment design problem. The EnvDesign model was built on context and techniques that apply to combinatorial testing in general, so it can support combinatorial testing in other domains. An earlier version of this paper was peer-reviewed and published internally at Microsoft.</article>","contentLength":1083,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SoK: Usability Studies in Differential Privacy","url":"https://arxiv.org/abs/2412.16825","date":1751515200,"author":"","guid":181950,"unread":true,"content":"<article>arXiv:2412.16825v2 Announce Type: replace \nAbstract: Differential Privacy (DP) has emerged as a pivotal approach for safeguarding individual privacy in data analysis, yet its practical adoption is often hindered by challenges in the implementation and communication of DP. This paper presents a comprehensive systematization of existing research studies around the usability of DP, synthesizing insights from studies on both the practical use of DP tools and strategies for conveying DP parameters that determine privacy protection levels, such as epsilon($\\varepsilon$). By reviewing and analyzing these studies, we identify core usability challenges, best practices, and critical gaps in current DP tools that affect adoption across diverse user groups, including developers, data analysts, and non-technical stakeholders. Our analysis highlights actionable insights and pathways for future research that emphasizes user-centered design and clear communication, fostering the development of more accessible DP tools that meet practical needs and support broader adoption.</article>","contentLength":1073,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Semantic Alignment and Reinforcement for Data-Free Quantization of Vision Transformers","url":"https://arxiv.org/abs/2412.16553","date":1751515200,"author":"","guid":181951,"unread":true,"content":"<article>arXiv:2412.16553v3 Announce Type: replace \nAbstract: Data-free quantization (DFQ) enables model quantization without accessing real data, addressing concerns regarding data security and privacy. With the growing adoption of Vision Transformers (ViTs), DFQ for ViTs has garnered significant attention. However, existing DFQ methods exhibit two limitations: (1) semantic distortion, where the semantics of synthetic images deviate substantially from those of real images, and (2) semantic inadequacy, where synthetic images contain extensive regions with limited content and oversimplified textures, leading to suboptimal quantization performance. To address these limitations, we propose SARDFQ, a novel Semantics Alignment and Reinforcement Data-Free Quantization method for ViTs. To address semantic distortion, SARDFQ incorporates Attention Priors Alignment (APA), which optimizes synthetic images to follow randomly generated structure attention priors. To mitigate semantic inadequacy, SARDFQ introduces Multi-Semantic Reinforcement (MSR), leveraging localized patch optimization to enhance semantic richness across synthetic images. Furthermore, SARDFQ employs Soft-Label Learning (SL), wherein multiple semantic targets are adapted to facilitate the learning of multi-semantic images augmented by MSR. Extensive experiments demonstrate the effectiveness of SARDFQ, significantly surpassing existing methods. For example, SARDFQ improves top-1 accuracy on ImageNet by 15.52% for W4A4 ViT-B. The code is at https://github.com/zysxmu/SARDFQ.</article>","contentLength":1544,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Continual Learning with Strategic Selection and Forgetting for Network Intrusion Detection","url":"https://arxiv.org/abs/2412.16264","date":1751515200,"author":"","guid":181952,"unread":true,"content":"<article>arXiv:2412.16264v4 Announce Type: replace \nAbstract: Intrusion Detection Systems (IDS) are crucial for safeguarding digital infrastructure. In dynamic network environments, both threat landscapes and normal operational behaviors are constantly changing, resulting in concept drift. While continuous learning mitigates the adverse effects of concept drift, insufficient attention to drift patterns and excessive preservation of outdated knowledge can still hinder the IDS's adaptability. In this paper, we propose SSF (Strategic Selection and Forgetting), a novel continual learning method for IDS, providing continuous model updates with a constantly refreshed memory buffer. Our approach features a strategic sample selection algorithm to select representative new samples and a strategic forgetting mechanism to drop outdated samples. The proposed strategic sample selection algorithm prioritizes new samples that cause the `drifted' pattern, enabling the model to better understand the evolving landscape. Additionally, we introduce strategic forgetting upon detecting significant drift by discarding outdated samples to free up memory, allowing the incorporation of more recent data. SSF captures evolving patterns effectively and ensures the model is aligned with the change of data patterns, significantly enhancing the IDS's adaptability to concept drift. The state-of-the-art performance of SSF on NSL-KDD and UNSW-NB15 datasets demonstrates its superior adaptability to concept drift for network intrusion detection. The code is released at https://github.com/xinchen930/SSF-Strategic-Selection-and-Forgetting.</article>","contentLength":1619,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Expressivity of AuDaLa: Turing Completeness and Possible Extensions","url":"https://arxiv.org/abs/2412.14938","date":1751515200,"author":"","guid":181953,"unread":true,"content":"<article>arXiv:2412.14938v2 Announce Type: replace \nAbstract: AuDaLa is a recently introduced programming language that follows the new data autonomous paradigm. In this paradigm, small pieces of data execute functions autonomously. Considering the paradigm and the design choices of AuDaLa, it is interesting to determine the expressivity of the language. In this paper, we implement Turing machines in AuDaLa and prove that implementation correct. This proves that AuDaLa is Turing complete, giving an initial indication of AuDaLa's expressivity. Additionally, we give examples of how to add extensions to AuDaLa to increase its practical expressivity and to better match conventional parallel languages, allowing for a more straightforward and performant implementation of algorithms.</article>","contentLength":778,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DCBM: Data-Efficient Visual Concept Bottleneck Models","url":"https://arxiv.org/abs/2412.11576","date":1751515200,"author":"","guid":181954,"unread":true,"content":"<article>arXiv:2412.11576v3 Announce Type: replace \nAbstract: Concept Bottleneck Models (CBMs) enhance the interpretability of neural networks by basing predictions on human-understandable concepts. However, current CBMs typically rely on concept sets extracted from large language models or extensive image corpora, limiting their effectiveness in data-sparse scenarios. We propose Data-efficient CBMs (DCBMs), which reduce the need for large sample sizes during concept generation while preserving interpretability. DCBMs define concepts as image regions detected by segmentation or detection foundation models, allowing each image to generate multiple concepts across different granularities. This removes reliance on textual descriptions and large-scale pre-training, making DCBMs applicable for fine-grained classification and out-of-distribution tasks. Attribution analysis using Grad-CAM demonstrates that DCBMs deliver visual concepts that can be localized in test images. By leveraging dataset-specific concepts instead of predefined ones, DCBMs enhance adaptability to new domains.</article>","contentLength":1082,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advancing Textual Prompt Learning with Anchored Attributes","url":"https://arxiv.org/abs/2412.09442","date":1751515200,"author":"","guid":181955,"unread":true,"content":"<article>arXiv:2412.09442v3 Announce Type: replace \nAbstract: Textual-based prompt learning methods primarily employ multiple learnable soft prompts and hard class tokens in a cascading manner as text inputs, aiming to align image and text (category) spaces for downstream tasks. However, current training is restricted to aligning images with predefined known categories and cannot be associated with unknown categories. In this work, we propose utilizing universal attributes as a bridge to enhance the alignment between images and unknown categories. Specifically, we introduce an Attribute-anchored Textual Prompt learning method for vision-language models, named ATPrompt. This approach expands the learning space of soft prompts from the original one-dimensional category level into the multi-dimensional attribute level by incorporating multiple attribute tokens into the learnable soft prompts. Through this modification, we transform the text prompt from a category-centric form to an attribute-category hybrid form. Additionally, we introduce a straightforward differentiable attribute search method to identify representative and suitable attributes for downstream tasks. As an easy-to-use plug-in technique, ATPrompt can seamlessly replace the existing basic prompt format in textual-based methods, providing general improvements at a negligible computational cost. Extensive experiments across 11 datasets validate the effectiveness of our method. Code is publicly available at https://github.com/zhengli97/ATPrompt.</article>","contentLength":1520,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain Offline Data","url":"https://arxiv.org/abs/2412.07762","date":1751515200,"author":"","guid":181956,"unread":true,"content":"<article>arXiv:2412.07762v3 Announce Type: replace \nAbstract: The modern paradigm in machine learning involves pre-training on diverse data, followed by task-specific fine-tuning. In reinforcement learning (RL), this translates to learning via offline RL on a diverse historical dataset, followed by rapid online RL fine-tuning using interaction data. Most RL fine-tuning methods require continued training on offline data for stability and performance. However, this is undesirable because training on diverse offline data is slow and expensive for large datasets, and in principle, also limit the performance improvement possible because of constraints or pessimism on offline data. In this paper, we show that retaining offline data is unnecessary as long as we use a properly-designed online RL approach for fine-tuning offline RL initializations. To build this approach, we start by analyzing the role of retaining offline data in online fine-tuning. We find that continued training on offline data is mostly useful for preventing a sudden divergence in the value function at the onset of fine-tuning, caused by a distribution mismatch between the offline data and online rollouts. This divergence typically results in unlearning and forgetting the benefits of offline pre-training. Our approach, Warm-start RL (WSRL), mitigates the catastrophic forgetting of pre-trained initializations using a very simple idea. WSRL employs a warmup phase that seeds the online RL run with a very small number of rollouts from the pre-trained policy to do fast online RL. The data collected during warmup helps ``recalibrate'' the offline Q-function to the online distribution, allowing us to completely discard offline data without destabilizing the online RL fine-tuning. We show that WSRL is able to fine-tune without retaining any offline data, and is able to learn faster and attains higher performance than existing algorithms irrespective of whether they retain offline data or not.</article>","contentLength":1971,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Minimal residual discretization of a class of fully nonlinear elliptic PDE","url":"https://arxiv.org/abs/2412.07568","date":1751515200,"author":"","guid":181957,"unread":true,"content":"<article>arXiv:2412.07568v2 Announce Type: replace \nAbstract: This work introduces finite element methods for a class of elliptic fully nonlinear partial differential equations. They are based on a minimal residual principle that builds upon the Alexandrov--Bakelman--Pucci estimate. Under rather general structural assumptions on the operator, convergence of $C^1$ conforming and discontinuous Galerkin methods is proven in the $L^\\infty$ norm. Numerical experiments on the performance of adaptive mesh refinement driven by local information of the residual in two and three space dimensions are provided.</article>","contentLength":597,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions","url":"https://arxiv.org/abs/2412.05563","date":1751515200,"author":"","guid":181958,"unread":true,"content":"<article>arXiv:2412.05563v2 Announce Type: replace \nAbstract: The remarkable performance of large language models (LLMs) in content generation, coding, and common-sense reasoning has spurred widespread integration into many facets of society. However, integration of LLMs raises valid questions on their reliability and trustworthiness, given their propensity to generate hallucinations: plausible, factually-incorrect responses, which are expressed with striking confidence. Previous work has shown that hallucinations and other non-factual responses generated by LLMs can be detected by examining the uncertainty of the LLM in its response to the pertinent prompt, driving significant research efforts devoted to quantifying the uncertainty of LLMs. This survey seeks to provide an extensive review of existing uncertainty quantification methods for LLMs, identifying their salient features, along with their strengths and weaknesses. We present existing methods within a relevant taxonomy, unifying ostensibly disparate methods to aid understanding of the state of the art. Furthermore, we highlight applications of uncertainty quantification methods for LLMs, spanning chatbot and textual applications to embodied artificial intelligence applications in robotics. We conclude with open research challenges in uncertainty quantification of LLMs, seeking to motivate future research.</article>","contentLength":1376,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Direct Quantized Training of Language Models with Stochastic Rounding","url":"https://arxiv.org/abs/2412.04787","date":1751515200,"author":"","guid":181959,"unread":true,"content":"<article>arXiv:2412.04787v2 Announce Type: replace \nAbstract: Although recent quantized Large Language Models (LLMs), such as BitNet, have paved the way for significant reduction in memory usage during deployment with binary or ternary weights, training these models still demands substantial memory footprints. This is partly because high-precision (i.e., unquantized) weights required for straight-through estimation must be maintained throughout the whole training process. To address this, we explore directly updating the quantized low-precision weights without relying on straight-through estimation during backpropagation, aiming to save memory usage during training. Specifically, we employ a stochastic rounding technique to minimize the information loss caused by the use of low-bit weights throughout training. Experimental results on our LLaMA-structured models of various sizes indicate that (1) training with only low-precision weights is feasible even when they are constrained to ternary values; (2) extending the bit width to 8 bits achieves performance on par with BitNet b1.58; (3) our models remain robust to precision scaling and memory reduction, showing minimal performance degradation when moving from FP32 to lower-memory environments (BF16/FP8); and (4) our models also support inference using ternary weights, showcasing their flexibility in deployment.</article>","contentLength":1371,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Embedding-Space Diffusion for Zero-Shot Environmental Sound Classification","url":"https://arxiv.org/abs/2412.03771","date":1751515200,"author":"","guid":181960,"unread":true,"content":"<article>arXiv:2412.03771v2 Announce Type: replace \nAbstract: Zero-shot learning enables models to generalise to unseen classes by leveraging semantic information, bridging the gap between training and testing sets with non-overlapping classes. While much research has focused on zero-shot learning in computer vision, the application of these methods to environmental audio remains underexplored, with poor performance in existing studies. Generative methods, which have demonstrated success in computer vision, are notably absent from zero-shot environmental sound classification studies.\n  To address this gap, this work investigates generative methods for zero-shot learning in environmental audio. Two successful generative models from computer vision are adapted: a cross-aligned and distribution-aligned variational autoencoder (CADA-VAE) and a leveraging invariant side generative adversarial network (LisGAN). Additionally, we introduced a novel diffusion model conditioned on class auxiliary data. Synthetic embeddings generated by the diffusion model are combined with seen class embeddings to train a classifier.\n  Experiments are conducted on five environmental audio datasets, ESC-50, ARCA23K-FSD, FSC22, UrbanSound8k and TAU Urban Acoustics 2019, and one music classification dataset, GTZAN. Results show that the diffusion model outperforms all baseline methods on average across six audio datasets.\n  This work establishes the diffusion model as a promising approach for zero-shot learning and introduces the first benchmark of generative methods for zero-shot environmental sound classification, providing a foundation for future research.</article>","contentLength":1648,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Approximately Fair and Population Consistent Budget Division via Simple Payment Schemes","url":"https://arxiv.org/abs/2412.02435","date":1751515200,"author":"","guid":181961,"unread":true,"content":"<article>arXiv:2412.02435v2 Announce Type: replace \nAbstract: In approval-based budget division, a budget needs to be distributed to candidates based on the voters' approval ballots over these candidates. In the pursuit of a simple, consistent, and approximately fair rule for this setting, we introduce the maximum payment rule (MP). Under this rule, each voter controls a part of the budget and, in each step, the corresponding voters allocate their entire budget to the candidate approved by the largest number of voters with non-zero budget. We show that MP meets our criteria as it satisfies monotonicity and a demanding population consistency condition and gives a $2$-approximation to a fairness notion called average fair share (AFS). Moreover, we generalize MP to the class of sequential payment rule and prove that it is the most desirable rule in this class: all sequential payment rules but MP and one other rule fail monotonicity while only allowing for a small improvement in the approximation ratio to AFS.</article>","contentLength":1012,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Articulate3D: Holistic Understanding of 3D Scenes as Universal Scene Description","url":"https://arxiv.org/abs/2412.01398","date":1751515200,"author":"","guid":181962,"unread":true,"content":"<article>arXiv:2412.01398v2 Announce Type: replace \nAbstract: 3D scene understanding is a long-standing challenge in computer vision and a key component in enabling mixed reality, wearable computing, and embodied AI. Providing a solution to these applications requires a multifaceted approach that covers scene-centric, object-centric, as well as interaction-centric capabilities. While there exist numerous datasets and algorithms approaching the former two problems, the task of understanding interactable and articulated objects is underrepresented and only partly covered in the research field. In this work, we address this shortcoming by introducing: (1) Articulate3D, an expertly curated 3D dataset featuring high-quality manual annotations on 280 indoor scenes. Articulate3D provides 8 types of annotations for articulated objects, covering parts and detailed motion information, all stored in a standardized scene representation format designed for scalable 3D content creation, exchange and seamless integration into simulation environments. (2) USDNet, a novel unified framework capable of simultaneously predicting part segmentation along with a full specification of motion attributes for articulated objects. We evaluate USDNet on Articulate3D as well as two existing datasets, demonstrating the advantage of our unified dense prediction approach. Furthermore, we highlight the value of Articulate3D through cross-dataset and cross-domain evaluations and showcase its applicability in downstream tasks such as scene editing through LLM prompting and robotic policy training for articulated object manipulation. We provide open access to our dataset, benchmark, and method's source code.</article>","contentLength":1691,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks","url":"https://arxiv.org/abs/2411.19688","date":1751515200,"author":"","guid":181963,"unread":true,"content":"<article>arXiv:2411.19688v2 Announce Type: replace \nAbstract: Vision-Language Models (VLMs) have great potential in medical tasks, like Visual Question Answering (VQA), where they could act as interactive assistants for both patients and clinicians. Yet their robustness to distribution shifts on unseen data remains a key concern for safe deployment. Evaluating such robustness requires a controlled experimental setup that allows for systematic insights into the model's behavior. However, we demonstrate that current setups fail to offer sufficiently thorough evaluations. To address this gap, we introduce a novel framework, called \\textit{SURE-VQA}, centered around three key requirements to overcome current pitfalls and systematically analyze VLM robustness: 1) Since robustness on synthetic shifts does not necessarily translate to real-world shifts, it should be measured on real-world shifts that are inherent to the VQA data; 2) Traditional token-matching metrics often fail to capture underlying semantics, necessitating the use of large language models (LLMs) for more accurate semantic evaluation; 3) Model performance often lacks interpretability due to missing sanity baselines, thus meaningful baselines should be reported that allow assessing the multimodal impact on the VLM. To demonstrate the relevance of this framework, we conduct a study on the robustness of various Fine-Tuning (FT) methods across three medical datasets with four types of distribution shifts. Our study highlights key insights into robustness: 1) No FT method consistently outperforms others in robustness, and 2) robustness trends are more stable across FT methods than across distribution shifts. Additionally, we find that simple sanity baselines that do not use the image data can perform surprisingly well and confirm LoRA as the best-performing FT method on in-distribution data. Code is provided at https://github.com/IML-DKFZ/sure-vqa.</article>","contentLength":1927,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FAMES: Fast Approximate Multiplier Substitution for Mixed-Precision Quantized DNNs--Down to 2 Bits!","url":"https://arxiv.org/abs/2411.18055","date":1751515200,"author":"","guid":181964,"unread":true,"content":"<article>arXiv:2411.18055v3 Announce Type: replace \nAbstract: A widely-used technique in designing energy-efficient deep neural network (DNN) accelerators is quantization. Recent progress in this direction has reduced the bitwidths used in DNN down to 2. Meanwhile, many prior works apply approximate multipliers (AppMuls) in designing DNN accelerators to lower their energy consumption. Unfortunately, these works still assume a bitwidth much larger than 2, which falls far behind the state-of-the-art in quantization area and even challenges the meaningfulness of applying AppMuls in DNN accelerators, since a high-bitwidth AppMul consumes much more energy than a low-bitwidth exact multiplier! Thus, an important problem to study is: Can approximate multipliers be effectively applied to quantized DNN models with very low bitwidths? In this work, we give an affirmative answer to this question and present a systematic solution that achieves the answer: FAMES, a fast approximate multiplier substitution method for mixed-precision DNNs. Our experiments demonstrate an average 28.67% energy reduction on state-of-the-art mixed-precision quantized models with bitwidths as low as 2 bits and accuracy losses kept under 1%. Additionally, our approach is up to 300x faster than previous genetic algorithm-based methods.</article>","contentLength":1309,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation","url":"https://arxiv.org/abs/2411.16370","date":1751515200,"author":"","guid":181965,"unread":true,"content":"<article>arXiv:2411.16370v4 Announce Type: replace \nAbstract: Advancements in image segmentation play an integral role within the broad scope of Deep Learning-based Computer Vision. Furthermore, their widespread applicability in critical real-world tasks has resulted in challenges related to the reliability of such algorithms. Hence, uncertainty quantification has been extensively studied within this context, enabling the expression of model ignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to prevent uninformed decision-making. Due to the rapid adoption of Convolutional Neural Network (CNN)-based segmentation models in high-stake applications, a substantial body of research has been published on this very topic, causing its swift expansion into a distinct field. This work provides a comprehensive overview of probabilistic segmentation, by discussing fundamental concepts of uncertainty quantification, governing advancements in the field as well as the application to various tasks. Moreover, literature on both types of uncertainties trace back to four key applications: (1) to quantify statistical inconsistencies in the annotation process due ambiguous images, (2) correlating prediction error with uncertainty, (3) expanding the model hypothesis space for better generalization, and (4) Active Learning. An extensive discussion follows that includes an overview of utilized datasets for each of the applications and evaluation of the available methods. We also highlight challenges related to architectures, uncertainty quantification methods, standardization and benchmarking, and finally end with recommendations for future work such as methods based on single forward passes and models that appropriately leverage volumetric data.</article>","contentLength":1767,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs","url":"https://arxiv.org/abs/2411.13757","date":1751515200,"author":"","guid":181966,"unread":true,"content":"<article>arXiv:2411.13757v4 Announce Type: replace \nAbstract: Large Language Models (LLMs) have revolutionized natural language processing (NLP), excelling in tasks like text generation and summarization. However, their increasing adoption in mission-critical applications raises concerns about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs, enabled by fault injection methods such as Rowhammer, target model parameters in memory, compromising both integrity and performance. Identifying critical parameters for BFAs in the vast parameter space of LLMs poses significant challenges. While prior research suggests transformer-based architectures are inherently more robust to BFAs compared to traditional deep neural networks, we challenge this assumption. For the first time, we demonstrate that as few as three bit-flips can cause catastrophic performance degradation in an LLM with billions of parameters. Current BFA techniques are inadequate for exploiting this vulnerability due to the difficulty of efficiently identifying critical parameters within the immense parameter space. To address this, we propose AttentionBreaker, a novel framework tailored for LLMs that enables efficient traversal of the parameter space to identify critical parameters. Additionally, we introduce GenBFA, an evolutionary optimization strategy designed to refine the search further, isolating the most critical bits for an efficient and effective attack. Empirical results reveal the profound vulnerability of LLMs to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to 0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings underscore the effectiveness of AttentionBreaker in uncovering and exploiting critical vulnerabilities within LLM architectures.</article>","contentLength":1953,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advancements in Constitutive Model Calibration: Leveraging the Power of Full-Field DIC Measurements and In-Situ Load Path Selection for Reliable Parameter Inference","url":"https://arxiv.org/abs/2411.07310","date":1751515200,"author":"","guid":181967,"unread":true,"content":"<article>arXiv:2411.07310v4 Announce Type: replace \nAbstract: Accurate material characterization and model calibration are essential for computationally-supported engineering decisions. Current characterization and calibration methods (1) use simplified test specimen geometries and global data, (2) cannot guarantee that sufficient characterization data is collected for a specific model of interest, (3) use deterministic methods that provide best-fit parameter values with no uncertainty quantification, and (4) are sequential, inflexible, and time-consuming. This work brings together several recent advancements into an improved workflow called Interlaced Characterization and Calibration that advances the state-of-the-art in constitutive model calibration. The ICC paradigm (1) efficiently uses full-field data to calibrate a high-fidelity material model, (2) aligns the data needed with the data collected with an optimal experimental design protocol, (3) quantifies parameter uncertainty through Bayesian inference, and (4) incorporates these advances into a quasi real-time feedback loop. The ICC framework is demonstrated on the calibration of a material model using simulated full-field data for an aluminum cruciform specimen being deformed bi-axially. The cruciform is actively driven through the myopically optimal load path using Bayesian optimal experimental design, which selects load steps that yield the maximum expected information gain. To aid in numerical stability and preserve computational resources, the full-field data is dimensionally reduced via principal component analysis, and fast surrogate models which approximate the input-output relationships of the expensive finite element model are used. The tools demonstrated here show that high-fidelity constitutive models can be efficiently and reliably calibrated with quantified uncertainty, thus supporting credible decision-making and potentially increasing the agility of solid mechanics modeling.</article>","contentLength":1972,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Progressive Barrier Lyapunov Functions for Nonlinear Constrained Control Systems","url":"https://arxiv.org/abs/2411.06288","date":1751515200,"author":"","guid":181968,"unread":true,"content":"<article>arXiv:2411.06288v2 Announce Type: replace \nAbstract: This paper introduces the Progressive Barrier Lyapunov Function (p-BLF) for output- and full-state-constrained nonlinear control systems. Unlike traditional BLF methods, where control effort continuously increases as the state approaches the constraint boundaries, the p-BLF maintains minimal control effort in unconstrained regions and increases it progressively toward the boundaries. In contrast to previous methods with predefined safe zones and abrupt control activation, the p-BLF provides a smooth transition, improving continuity in the control response and enhancing stability by reducing chattering. Two forms of the p-BLF, logarithmic-based and rational-based, are developed to handle systems with either output constraints or full-state constraints. Theoretical analysis guarantees that all system states remain within the defined constraints, ensuring boundedness and stability of the closed-loop system. Simulation results validate the effectiveness of the proposed method in constrained nonlinear control.</article>","contentLength":1073,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Networked dynamics with application to frequency stability of grid-forming power-limiting droop control","url":"https://arxiv.org/abs/2411.05763","date":1751515200,"author":"","guid":181969,"unread":true,"content":"<article>arXiv:2411.05763v2 Announce Type: replace \nAbstract: In this paper, we study a constrained network flow problem and associated networked dynamics that resemble but are distinct from the well-known primal-dual dynamics of the constrained flow problem. Crucially, under a change of coordinates, the networked dynamics coincide with primal-dual dynamics associated with the constrained flow problem in edge coordinates. Next, we show that, under mild feasibility assumptions, the networked dynamics are globally asymptotically stable with respect to the set of optimizers of its associated constrained flow problem in nodal coordinates. Subsequently, we apply our stability results to establish frequency stability of power-limiting grid-forming droop control. Compared to conventional grid-forming droop control, power-limiting droop control explicitly accounts for active power limits of the generation (e.g., renewables) interfaced by the converter. While power-limiting droop control has been demonstrated to work well in simulation and experiment, analytical results are not readily available. Moreover, we (i) show that the converter frequencies synchronize to a common synchronous frequency for each grid-forming converter, (ii) characterize the synchronous frequency in the case of converters operating at their power limit, and (iii) establish that power-limiting droop control exhibits power-sharing properties similar to conventional unconstrained droop control. Finally, the analytical results are illustrated using an Electromagnetic transient (EMT) simulation.</article>","contentLength":1571,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models","url":"https://arxiv.org/abs/2410.23530","date":1751515200,"author":"","guid":181970,"unread":true,"content":"<article>arXiv:2410.23530v3 Announce Type: replace \nAbstract: Diffusion Models achieve state-of-the-art performance in generating new samples but lack a low-dimensional latent space that encodes the data into meaningful features. Inversion-based methods address this by reversing the denoising trajectory, mapping each image back to its approximated starting noise. In this work, we thoroughly analyze this procedure and focus on the relation between the initial Gaussian noise, the generated samples, and their corresponding latent encodings obtained through the DDIM inversion. First, we show that latents exhibit structural patterns in the form of less diverse noise predicted for smooth image regions. As a consequence of this divergence, we present that the space of image inversions is notably less manipulative than the original Gaussian noise. Next, we explain the origin of the phenomenon, demonstrating that, during the first inversion steps, the noise prediction error is much more significant for the plain areas than for the rest of the image. As a surprisingly simple solution, we propose to replace the first DDIM Inversion steps with a forward diffusion process, which successfully decorrelates latent encodings, leading to higher quality editions and interpolations. The code is available at https://github.com/luk-st/taba.</article>","contentLength":1331,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Resilient-By-Design: A Resiliency Framework for Future Wireless Networks","url":"https://arxiv.org/abs/2410.23203","date":1751515200,"author":"","guid":181971,"unread":true,"content":"<article>arXiv:2410.23203v2 Announce Type: replace \nAbstract: Our future society will be increasingly digitalized, hyper-connected and globally data driven. The sixth generation (6G) and beyond 6G wireless networks are expected to bridge the digital and physical worlds by providing wireless connectivity as a service to different vertical sectors, making the society increasingly dependent on wireless networks. Thus, any disruption to these networks would have a significant impact with far-reaching consequences. Disruptions can occur for a variety of reasons, including planned outages, natural disasters, and deliberate cybersecurity attacks. Resilience against such disruptions is expected to be one of the most important defining features of future wireless networks. This paper first discusses a generic framework for designing future resilient wireless networks. A novel resilient-by-design framework consisting of four building blocks, namely predict, preempt, protect and progress, is then proposed as a specific example.</article>","contentLength":1023,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models","url":"https://arxiv.org/abs/2410.23114","date":1751515200,"author":"","guid":181972,"unread":true,"content":"<article>arXiv:2410.23114v3 Announce Type: replace \nAbstract: Despite the outstanding performance in vision-language reasoning, Large Vision-Language Models (LVLMs) might generate hallucinated contents that do not exist in the given image. Most existing LVLM hallucination benchmarks are constrained to evaluate the object-related hallucinations. However, the potential hallucination on the relations between two objects, i.e., relation hallucination, still lacks investigation. To remedy that, we design a unified framework to measure the object and relation hallucination in LVLMs simultaneously. The core idea of our framework is to evaluate hallucinations via (object, relation, object) triplets extracted from LVLMs' responses, making it easily generalizable to different vision-language tasks. Based on our framework, we further introduce Tri-HE, a novel Triplet-level Hallucination Evaluation benchmark which can be used to study both object and relation hallucination at the same time. With comprehensive evaluations on Tri-HE, we observe that the relation hallucination issue is even more serious than object hallucination among existing LVLMs, highlighting a previously neglected problem towards reliable LVLMs. Moreover, based on our findings, we design a simple training-free approach that effectively mitigates hallucinations for LVLMs. Our dataset and code for the reproduction of our experiments are available publicly at https://github.com/wujunjie1998/Tri-HE.</article>","contentLength":1467,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dynamic Matching with Post-allocation Service and its Application to Refugee Resettlement","url":"https://arxiv.org/abs/2410.22992","date":1751515200,"author":"","guid":181973,"unread":true,"content":"<article>arXiv:2410.22992v2 Announce Type: replace \nAbstract: Motivated by our collaboration with a major refugee resettlement agency in the U.S., we study a dynamic matching problem where each new arrival (a refugee case) must be matched immediately and irrevocably to one of the static resources (a location with a fixed annual quota). In addition to consuming the static resource, each case requires post-allocation services from a server, such as a translator. Given the uncertainty in service time, a server may not be available at a given time, thus we refer to it as a dynamic resource. Upon matching, the case will wait to avail service in a first-come-first-serve manner. Bursty matching to a location may result in undesirable congestion at its corresponding server. Consequently, the central planner (the agency) faces a dynamic matching problem with an objective that combines the matching reward (captured by pair-specific employment outcomes) with the cost for congestion for dynamic resources and over-allocation for the static ones. Motivated by the observed fluctuations in the composition of refugee pools across the years, we aim to design algorithms that do not rely on distributional knowledge. We develop learning-based algorithms that are asymptotically optimal in certain regimes, easy to interpret, and computationally fast. Our design is based on learning the dual variables of the underlying optimization problem; however, the main challenge lies in the time-varying nature of the dual variables associated with dynamic resources. Our theoretical development brings together techniques from Lyapunov analysis, adversarial online learning, and stochastic optimization. On the application side, when tested on real data from our partner agency and incorporating practical considerations, our method outperforms existing ones making it a viable candidate for replacing the current practice upon experimentation.</article>","contentLength":1926,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Adaptive NAD: Online and Self-adaptive Unsupervised Network Anomaly Detector","url":"https://arxiv.org/abs/2410.22967","date":1751515200,"author":"","guid":181974,"unread":true,"content":"<article>arXiv:2410.22967v4 Announce Type: replace \nAbstract: The widespread usage of the Internet of Things (IoT) has raised the risks of cyber threats, thus developing Anomaly Detection Systems (ADSs) that can adapt to evolving or new attacks is critical. Previous studies primarily focused on offline unsupervised learning methods to safeguard ADSs, which is not applicable in practical real-world applications. Besides, most of them strongly rely on assumptions of known legitimates and fail to satisfy the interpretable requirements in security applications, creating barriers to the adoption in practice. In this paper, we design Adaptive NAD, a general framework to improve and interpret online unsupervised anomaly detection in security domains. An interpretable two-layer anomaly detection strategy is proposed to generate reliable high-confidence pseudo-labels. Then, an online learning scheme is introduced to update Adaptive NAD by a novel threshold calculation technique to adapt to new threats. Experimental results demonstrate that Adaptive NAD achieves more than 5.4%, 23.0%, and 3.2% improvements in SPAUC compared with state-of-the-art solutions on the CIC-Darknet2020, CIC-DoHBrw-2020, and Edge-IIoTset datasets, respectively. The code is released at https://github.com/MyLearnCodeSpace/Adaptive-NAD.</article>","contentLength":1310,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Contrastive Learning and Adversarial Disentanglement for Privacy-Aware Task-Oriented Semantic Communication","url":"https://arxiv.org/abs/2410.22784","date":1751515200,"author":"","guid":181975,"unread":true,"content":"<article>arXiv:2410.22784v3 Announce Type: replace \nAbstract: Task-oriented semantic communication systems have emerged as a promising approach to achieving efficient and intelligent data transmission in next-generation networks, where only information relevant to a specific task is communicated. This is particularly important in 6G-enabled Internet of Things (6G-IoT) scenarios, where bandwidth constraints, latency requirements, and data privacy are critical. However, existing methods struggle to fully disentangle task-relevant and task-irrelevant information, leading to privacy concerns and suboptimal performance. To address this, we propose an information-bottleneck inspired method, named CLAD (contrastive learning and adversarial disentanglement). CLAD utilizes contrastive learning to effectively capture task-relevant features while employing adversarial disentanglement to discard task-irrelevant information. Additionally, due to the absence of reliable and reproducible methods to quantify the minimality of encoded feature vectors, we introduce the Information Retention Index (IRI), a comparative metric used as a proxy for the mutual information between the encoded features and the input. The IRI reflects how minimal and informative the representation is, making it highly relevant for privacy-preserving and bandwidth-efficient 6G-IoT systems. Extensive experiments demonstrate that CLAD outperforms state-of-the-art baselines in terms of semantic extraction, task performance, privacy preservation, and IRI, making it a promising building block for responsible, efficient and trustworthy 6G-IoT services.</article>","contentLength":1620,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Unsupervised Panoptic Interpretation of Latent Spaces in GANs Using Space-Filling Vector Quantization","url":"https://arxiv.org/abs/2410.20573","date":1751515200,"author":"","guid":181976,"unread":true,"content":"<article>arXiv:2410.20573v2 Announce Type: replace \nAbstract: Generative adversarial networks (GANs) learn a latent space whose samples can be mapped to real-world images. Such latent spaces are difficult to interpret. Some earlier supervised methods aim to create an interpretable latent space or discover interpretable directions, which requires exploiting data labels or annotated synthesized samples for training. However, we propose using a modification of vector quantization called space-filling vector quantization (SFVQ), which quantizes the data on a piece-wise linear curve. SFVQ can capture the underlying morphological structure of the latent space, making it interpretable. We apply this technique to model the latent space of pre-trained StyleGAN2 and BigGAN networks on various datasets. Our experiments show that the SFVQ curve yields a general interpretable model of the latent space such that it determines which parts of the latent space correspond to specific generative factors. Furthermore, we demonstrate that each line of the SFVQ curve can potentially refer to an interpretable direction for applying intelligible image transformations. We also demonstrate that the points located on an SFVQ line can be used for controllable data augmentation.</article>","contentLength":1261,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SFEM for the Lagrangian formulation of the surface Stokes problem","url":"https://arxiv.org/abs/2410.19470","date":1751515200,"author":"","guid":181977,"unread":true,"content":"<article>arXiv:2410.19470v2 Announce Type: replace \nAbstract: We consider the surface Stokes equation with Lagrange multiplier and approach it numerically. Using a Taylor-Hood surface finite element method, along with an appropriate estimate for the additional Lagrange multiplier, we derive a new inf-sup condition to help with the stability and convergence results. We establish optimal velocity convergence both in energy and tangential $L^2$ norms, along with optimal $L^2$ norm convergence for the two pressures, in the case of super-parametric finite elements. Furthermore, if the approximation order of the velocities matches that of the extra Lagrange multiplier, we achieve optimal order convergence even in the standard iso-parametric case. In this case, we also establish some new estimates for the normal $L^2$ velocity norm. In addition, we provide numerical simulations that confirm the established error bounds and also perform a comparative analysis against the penalty approach.</article>","contentLength":986,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Slot: Provenance-Driven APT Detection through Graph Reinforcement Learning","url":"https://arxiv.org/abs/2410.17910","date":1751515200,"author":"","guid":181978,"unread":true,"content":"<article>arXiv:2410.17910v3 Announce Type: replace \nAbstract: Advanced Persistent Threats (APTs) represent sophisticated cyberattacks characterized by their ability to remain undetected within the victim system for extended periods, aiming to exfiltrate sensitive data or disrupt operations. Existing detection approaches often struggle to effectively identify these complex threats, construct the attack chain for defense facilitation, or resist adversarial attacks. To overcome these challenges, we propose Slot, an advanced APT detection approach based on provenance graphs and graph reinforcement learning. Slot excels in uncovering multi-level hidden relationships, such as causal, contextual, and indirect connections, among system behaviors through provenance graph mining. By pioneering the integration of graph reinforcement learning, Slot dynamically adapts to new user activities and evolving attack strategies, enhancing its resilience against adversarial attacks. Additionally, Slot automatically constructs the attack chain according to detected attacks with clustering algorithms, providing precise identification of attack paths and facilitating the development of defense strategies. Evaluations with real-world datasets demonstrate Slot's outstanding accuracy, efficiency, adaptability, and robustness in APT detection, with most metrics surpassing state-of-the-art methods. Additionally, case studies conducted to assess Slot's effectiveness in supporting APT defense further establish it as a practical and reliable tool for cybersecurity protection.</article>","contentLength":1561,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MCCoder: Streamlining Motion Control with LLM-Assisted Code Generation and Rigorous Verification","url":"https://arxiv.org/abs/2410.15154","date":1751515200,"author":"","guid":181979,"unread":true,"content":"<article>arXiv:2410.15154v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) have demonstrated significant potential in code generation. However, in the factory automation sector, particularly motion control, manual programming, alongside inefficient and unsafe debugging practices, remains prevalent. This stems from the complex interplay of mechanical and electrical systems and stringent safety requirements. Moreover, most current AI-assisted motion control programming efforts focus on PLCs, with little attention given to high-level languages and function libraries. To address these challenges, we introduce MCCoder, an LLM-powered system tailored for generating motion control code, integrated with a soft-motion controller. MCCoder improves code generation through a structured workflow that combines multitask decomposition, hybrid retrieval-augmented generation (RAG), and iterative self-correction, utilizing a well-established motion library. Additionally, it integrates a 3D simulator for intuitive motion validation and logs of full motion trajectories for data verification, significantly enhancing accuracy and safety. In the absence of benchmark datasets and metrics tailored for evaluating motion control code generation, we propose MCEVAL, a dataset spanning motion tasks of varying complexity. Experiments show that MCCoder outperforms baseline models using Advanced RAG, achieving an overall performance gain of 33.09% and a 131.77% improvement on complex tasks in the MCEVAL dataset.</article>","contentLength":1511,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Initialization Method for Factorization Machine Based on Low-Rank Approximation for Constructing a Corrected Approximate Ising Model","url":"https://arxiv.org/abs/2410.12747","date":1751515200,"author":"","guid":181980,"unread":true,"content":"<article>arXiv:2410.12747v3 Announce Type: replace \nAbstract: This paper presents an initialization method that can approximate a given approximate Ising model with a high degree of accuracy using a factorization machine (FM), a machine learning model. The construction of an Ising models using an FM is applied to black-box combinatorial optimization problems using factorization machine with quantum annealing (FMQA). It is anticipated that the optimization performance of FMQA will be enhanced through an implementation of the warm-start method. Nevertheless, the optimal initialization method for leveraging the warm-start approach in FMQA remains undetermined. Consequently, the present study compares initialization methods based on random initialization and low-rank approximation, and then identifies a suitable one for use with warm-start in FMQA through numerical experiments. Furthermore, the properties of the initialization method by the low-rank approximation for the FM are analyzed using random matrix theory, demonstrating that the approximation accuracy of the proposed method is not significantly influenced by the specific Ising model under consideration. The findings of this study will facilitate advancements of research in the field of black-box combinatorial optimization through the use of Ising machines.</article>","contentLength":1322,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Large Language Models, and LLM-Based Agents, Should Be Used to Enhance the Digital Public Sphere","url":"https://arxiv.org/abs/2410.12123","date":1751515200,"author":"","guid":181981,"unread":true,"content":"<article>arXiv:2410.12123v3 Announce Type: replace \nAbstract: This paper argues that large language model-based recommenders can displace today's attention-allocation machinery. LLM-based recommenders would ingest open-web content, infer a user's natural-language goals, and present information that matches their reflective preferences. Properly designed, they could deliver personalization without industrial-scale data hoarding, return control to individuals, optimize for genuine ends rather than click-through proxies, and support autonomous attention management. Synthesizing evidence of current systems' harms with recent work on LLM-driven pipelines, we identify four key research hurdles: generating candidates without centralized data, maintaining computational efficiency, modeling preferences robustly, and defending against prompt-injection. None looks prohibitive; surmounting them would steer the digital public sphere toward democratic, human-centered values.</article>","contentLength":966,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Guaranteed Generation from Large Language Models","url":"https://arxiv.org/abs/2410.06716","date":1751515200,"author":"","guid":181982,"unread":true,"content":"<article>arXiv:2410.06716v2 Announce Type: replace \nAbstract: As large language models (LLMs) are increasingly used across various applications, there is a growing need to control text generation to satisfy specific constraints or requirements. This raises a crucial question: Is it possible to guarantee strict constraint satisfaction in generated outputs while preserving the distribution of the original model as much as possible? We first define the ideal distribution - the one closest to the original model, which also always satisfies the expressed constraint - as the ultimate goal of guaranteed generation. We then state a fundamental limitation, namely that it is impossible to reach that goal through autoregressive training alone. This motivates the necessity of combining training-time and inference-time methods to enforce such guarantees. Based on this insight, we propose GUARD, a simple yet effective approach that combines an autoregressive proposal distribution with rejection sampling. Through GUARD's theoretical properties, we show how controlling the KL divergence between a specific proposal and the target ideal distribution simultaneously optimizes inference speed and distributional closeness. To validate these theoretical concepts, we conduct extensive experiments on two text generation settings with hard-to-satisfy constraints: a lexical constraint scenario and a sentiment reversal scenario. These experiments show that GUARD achieves perfect constraint satisfaction while almost preserving the ideal distribution with highly improved inference efficiency. GUARD provides a principled approach to enforcing strict guarantees for LLMs without compromising their generative capabilities.</article>","contentLength":1709,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NegMerge: Sign-Consensual Weight Merging for Machine Unlearning","url":"https://arxiv.org/abs/2410.05583","date":1751515200,"author":"","guid":181983,"unread":true,"content":"<article>arXiv:2410.05583v2 Announce Type: replace \nAbstract: Machine unlearning aims to selectively remove specific knowledge from a trained model. Existing approaches, such as Task Arithmetic, fine-tune the model on the forget set to create a task vector (i.e., a direction in weight space) for subtraction from the original model's weight. However, their effectiveness is highly sensitive to hyperparameter selection, requiring extensive validation to identify the optimal vector from many fine-tuned candidates. In this paper, we propose a novel method that utilizes all fine-tuned models trained with varying hyperparameters instead of a single selection. Specifically, we aggregate the computed task vectors by retaining only the elements with consistent shared signs. The merged task vector is then negated to induce unlearning on the original model. Evaluations on zero-shot and standard image recognition tasks across twelve datasets and four backbone architectures show that our approach outperforms state-of-the-art methods while requiring similar or fewer computational resources. Code is available at https://github.com/naver-ai/negmerge.</article>","contentLength":1142,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On Efficient Variants of Segment Anything Model: A Survey","url":"https://arxiv.org/abs/2410.04960","date":1751515200,"author":"","guid":181984,"unread":true,"content":"<article>arXiv:2410.04960v3 Announce Type: replace \nAbstract: The Segment Anything Model (SAM) is a foundational model for image segmentation tasks, known for its strong generalization across diverse applications. However, its impressive performance comes with significant computational and resource demands, making it challenging to deploy in resource-limited environments such as edge devices. To address this, a variety of SAM variants have been proposed to enhance efficiency while keeping accuracy. This survey provides the first comprehensive review of these efficient SAM variants. We begin by exploring the motivations driving this research. We then present core techniques used in SAM and model acceleration. This is followed by a detailed exploration of SAM acceleration strategies, categorized by approach, and a discussion of several future research directions. Finally, we offer a unified and extensive evaluation of these methods across various hardware, assessing their efficiency and accuracy on representative benchmarks, and providing a clear comparison of their overall performance.</article>","contentLength":1092,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"QAEncoder: Towards Aligned Representation Learning in Question Answering Systems","url":"https://arxiv.org/abs/2409.20434","date":1751515200,"author":"","guid":181985,"unread":true,"content":"<article>arXiv:2409.20434v3 Announce Type: replace \nAbstract: Modern QA systems entail retrieval-augmented generation (RAG) for accurate and trustworthy responses. However, the inherent gap between user queries and relevant documents hinders precise matching. We introduce QAEncoder, a training-free approach to bridge this gap. Specifically, QAEncoder estimates the expectation of potential queries in the embedding space as a robust surrogate for the document embedding, and attaches document fingerprints to effectively distinguish these embeddings. Extensive experiments across diverse datasets, languages, and embedding models confirmed QAEncoder's alignment capability, which offers a simple-yet-effective solution with zero additional index storage, retrieval latency, training costs, or catastrophic forgetting and hallucination issues. The repository is publicly available at https://github.com/IAAR-Shanghai/QAEncoder.</article>","contentLength":919,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DREAMS: A python framework for Training Deep Learning Models on EEG Data with Model Card Reporting for Medical Applications","url":"https://arxiv.org/abs/2409.17815","date":1751515200,"author":"","guid":181986,"unread":true,"content":"<article>arXiv:2409.17815v2 Announce Type: replace \nAbstract: Electroencephalography (EEG) provides a non-invasive way to observe brain activity in real time. Deep learning has enhanced EEG analysis, enabling meaningful pattern detection for clinical and research purposes. However, most existing frameworks for EEG data analysis are either focused on preprocessing techniques or deep learning model development, often overlooking the crucial need for structured documentation and model interpretability. In this paper, we introduce DREAMS (Deep REport for AI ModelS), a Python-based framework designed to generate automated model cards for deep learning models applied to EEG data. Unlike generic model reporting tools, DREAMS is specifically tailored for EEG-based deep learning applications, incorporating domain-specific metadata, preprocessing details, performance metrics, and uncertainty quantification. The framework seamlessly integrates with deep learning pipelines, providing structured YAML-based documentation. We evaluate DREAMS through two case studies: an EEG emotion classification task using the FACED dataset and a abnormal EEG classification task using the Temple Univeristy Hospital (TUH) Abnormal dataset. These evaluations demonstrate how the generated model card enhances transparency by documenting model performance, dataset biases, and interpretability limitations. Unlike existing model documentation approaches, DREAMS provides visualized performance metrics, dataset alignment details, and model uncertainty estimations, making it a valuable tool for researchers and clinicians working with EEG-based AI. The source code for DREAMS is open-source, facilitating broad adoption in healthcare AI, research, and ethical AI development.</article>","contentLength":1752,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Human Mobility Modeling with Household Coordination Activities under Limited Information via Retrieval-Augmented LLMs","url":"https://arxiv.org/abs/2409.17495","date":1751515200,"author":"","guid":181987,"unread":true,"content":"<article>arXiv:2409.17495v2 Announce Type: replace \nAbstract: Understanding human mobility patterns has long been a challenging task in transportation modeling. Due to the difficulties in obtaining high-quality training datasets across diverse locations, conventional activity-based models and learning-based human mobility modeling algorithms are particularly limited by the availability and quality of datasets. Current approaches primarily focus on spatial-temporal patterns while neglecting semantic relationships such as logical connections or dependencies between activities and household coordination activities like joint shopping trips or family meal times, both crucial for realistic mobility modeling. We propose a retrieval-augmented large language model (LLM) framework that generates activity chains with household coordination using only public accessible statistical and socio-demographic information, reducing the need for sophisticated mobility data. The retrieval-augmentation mechanism enables household coordination and maintains statistical consistency across generated patterns, addressing a key gap in existing methods. Our validation with NHTS and SCAG-ABM datasets demonstrates effective mobility synthesis and strong adaptability for regions with limited mobility data availability.</article>","contentLength":1300,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Complex-Phase, Data-Driven Identification of Grid-Forming Inverter Dynamics","url":"https://arxiv.org/abs/2409.17132","date":1751515200,"author":"","guid":181988,"unread":true,"content":"<article>arXiv:2409.17132v2 Announce Type: replace \nAbstract: The increasing integration of renewable energy sources (RESs) into power systems requires the deployment of grid-forming inverters to ensure a stable operation. Accurate modeling of these devices is necessary. In this paper, a system identification approach to obtain low-dimensional models of grid-forming inverters is presented. The proposed approach is based on a Hammerstein-Wiener parametrization of the normal-form model. The normal-form is a gray-box model that utilizes complex frequency and phase to capture non-linear inverter dynamics. The model is validated on two well-known control strategies: droop-control and dispatchable virtual oscillators. Simulations and hardware-in-the-loop experiments demonstrate that the normal-form accurately models inverter dynamics across various operating conditions. The approach shows great potential for enhancing the modeling of RES-dominated power systems, especially when component models are unavailable or computationally expensive.</article>","contentLength":1040,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"QoS-Aware and Routing-Flexible Network Slicing for Service-Oriented Networks","url":"https://arxiv.org/abs/2409.13943","date":1751515200,"author":"","guid":181989,"unread":true,"content":"<article>arXiv:2409.13943v2 Announce Type: replace \nAbstract: In this paper, we consider the network slicing (NS) problem which attempts to map multiple customized virtual network requests (also called services) to a common shared network infrastructure and manage network resources to meet diverse quality of service (QoS) requirements. We propose a mixed-integer nonlinear programming (MINLP) formulation for the considered NS problem that can flexibly route the traffic flow of the services on multiple paths and provide end-to-end delay and reliability guarantees for all services. To overcome the computational difficulty due to the intrinsic nonlinearity in the MINLP formulation, we transform the MINLP formulation into an equivalent mixed-integer linear programming (MILP) formulation and further show that their continuous relaxations are equivalent. In sharp contrast to the continuous relaxation of the MINLP formulation which is a nonconvex nonlinear programming problem, the continuous relaxation of the MILP formulation is a polynomial-time solvable linear programming problem, which significantly facilitates the algorithmic design. Based on the newly proposed MILP formulation, we develop a customized column generation (cCG) algorithm for solving the NS problem. The proposed cCG algorithm is a decomposition-based algorithm and is particularly suitable for solving large-scale NS problems. Numerical results demonstrate the efficacy of the proposed formulations and the proposed cCG algorithm.</article>","contentLength":1502,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Unifying Global and Near-Context Biasing in a Single Trie Pass","url":"https://arxiv.org/abs/2409.13514","date":1751515200,"author":"","guid":181990,"unread":true,"content":"<article>arXiv:2409.13514v2 Announce Type: replace \nAbstract: Despite the success of end-to-end automatic speech recognition (ASR) models, challenges persist in recognizing rare, out-of-vocabulary words - including named entities (NE) - and in adapting to new domains using only text data. This work presents a practical approach to address these challenges through an unexplored combination of an NE bias list and a word-level n-gram language model (LM). This solution balances simplicity and effectiveness, improving entities' recognition while maintaining or even enhancing overall ASR performance. We efficiently integrate this enriched biasing method into a transducer-based ASR system, enabling context adaptation with almost no computational overhead. We present our results on three datasets spanning four languages and compare them to state-of-the-art biasing strategies. We demonstrate that the proposed combination of keyword biasing and n-gram LM improves entity recognition by up to 32% relative and reduces overall WER by up to a 12% relative.</article>","contentLength":1048,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rewind-to-Delete: Certified Machine Unlearning for Nonconvex Functions","url":"https://arxiv.org/abs/2409.09778","date":1751515200,"author":"","guid":181991,"unread":true,"content":"<article>arXiv:2409.09778v5 Announce Type: replace \nAbstract: Machine unlearning algorithms aim to efficiently remove data from a model without retraining it from scratch, in order to remove corrupted or outdated data or respect a user's ``right to be forgotten.\" Certified machine unlearning is a strong theoretical guarantee based on differential privacy that quantifies the extent to which an algorithm erases data from the model weights. In contrast to existing works in certified unlearning for convex or strongly convex loss functions, or nonconvex objectives with limiting assumptions, we propose the first, first-order, black-box (i.e., can be applied to models pretrained with vanilla gradient descent) algorithm for unlearning on general nonconvex loss functions, which unlearns by ``rewinding\" to an earlier step during the learning process before performing gradient descent on the loss function of the retained data points. We prove $(\\epsilon, \\delta)$ certified unlearning and performance guarantees that establish the privacy-utility-complexity tradeoff of our algorithm, and we prove generalization guarantees for functions that satisfy the Polyak-Lojasiewicz inequality. Finally, we demonstrate the superior performance of our algorithm compared to existing methods, within a new experimental framework that more accurately reflects unlearning user data in practice.</article>","contentLength":1375,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Formalising Inductive and Coinductive Containers","url":"https://arxiv.org/abs/2409.02603","date":1751515200,"author":"","guid":181992,"unread":true,"content":"<article>arXiv:2409.02603v4 Announce Type: replace \nAbstract: Containers capture the concept of strictly positive data types in programming. The original development of containers is done in the internal language of locally cartesian closed categories (LCCCs) with disjoint coproducts and W-types, and uniqueness of identity proofs (UIP) is implicitly assumed throughout. Although it is claimed that these developments can also be interpreted in extensional Martin-L\\\"of type theory, this interpretation is not made explicit. In this paper, we present a formalisation of the results that 'containers preserve least and greatest fixed points' in Cubical Agda, thereby giving a formulation in intensional type theory. Our proofs do not make use of UIP and thereby generalise the original results from talking about container functors on Set to container functors on the wild category of types. Our main incentive for using Cubical Agda is that its path type restores the equivalence between bisimulation and coinductive equality. Thus, besides developing container theory in a more general setting, we also demonstrate the usefulness of Cubical Agda's path type to coinductive proofs.</article>","contentLength":1173,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Melody predominates over harmony in the evolution of musical scales across 96 countries","url":"https://arxiv.org/abs/2408.12633","date":1751515200,"author":"","guid":181993,"unread":true,"content":"<article>arXiv:2408.12633v3 Announce Type: replace \nAbstract: The standard theory of musical scales since antiquity has been based on harmony, rather than melody. While recent analyses provide mixed support for a role of melody as well as harmony, we lack a comparative analysis based on cross-cultural data. We address this longstanding problem through a rigorous computational comparison of the main theories using 1,314 scales from 96 countries. There is near-universal support for melodic theories, which predict step-sizes of 1-3 semitones. Harmony accounts for the prevalence of certain simple-integer-ratio intervals, particularly for music-theoretic scales from Eurasian societies, which may explain their dominance amongst Western scholars. However, harmony is a poor predictor of scales measured from ethnographic recordings, particularly outside of Eurasia. Overall, we show that the historical emphasis on harmony is misguided and that melody is the primary determinant of the world's musical scales.</article>","contentLength":1003,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DreamCinema: Cinematic Transfer with Free Camera and 3D Character","url":"https://arxiv.org/abs/2408.12601","date":1751515200,"author":"","guid":181994,"unread":true,"content":"<article>arXiv:2408.12601v2 Announce Type: replace \nAbstract: We are living in a flourishing era of digital media, where everyone has the potential to become a personal filmmaker. Current research on video generation suggests a promising avenue for controllable film creation in pixel space using Diffusion models. However, the reliance on overly verbose prompts and insufficient focus on cinematic elements (e.g., camera movement) results in videos that lack cinematic quality. Furthermore, the absence of 3D modeling often leads to failures in video generation, such as inconsistent character models at different frames, ultimately hindering the immersive experience for viewers. In this paper, we propose a new framework for film creation, Dream-Cinema, which is designed for user-friendly, 3D space-based film creation with generative models. Specifically, we decompose 3D film creation into four key elements: 3D character, driven motion, camera movement, and environment. We extract the latter three elements from user-specified film shots and generate the 3D character using a generative model based on a provided image. To seamlessly recombine these elements and ensure smooth film creation, we propose structure-guided character animation, shape-aware camera movement optimization, and environment-aware generative refinement. Extensive experiments demonstrate the effectiveness of our method in generating high-quality films with free camera and 3D characters.</article>","contentLength":1461,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Optimal Proof Systems for Complex Sets are Hard to Find","url":"https://arxiv.org/abs/2408.07408","date":1751515200,"author":"","guid":181995,"unread":true,"content":"<article>arXiv:2408.07408v3 Announce Type: replace \nAbstract: We provide the first evidence for the inherent difficulty of finding complex sets with optimal proof systems. For this, we construct oracles $O_1$ and $O_2$ with the following properties, where $\\mathrm{RE}$ denotes the class of recursively enumerable sets and $\\mathrm{NQP}$ the class of sets accepted in non-deterministic quasi-polynomial time.\n  - $O_1$: No set in $\\mathrm{PSPACE} \\setminus \\mathrm{NP}$ has optimal proof systems and $\\mathrm{PH}$ is infinite\n  - $O_2$: No set in $\\mathrm{RE} \\setminus \\mathrm{NQP}$ has optimal proof systems and $\\mathrm{NP} \\neq \\mathrm{coNP}$\n  Oracle $O_2$ is the first relative to which complex sets with optimal proof systems do not exist. By oracle $O_1$, no relativizable proof can show that there exist sets in $\\mathrm{PSPACE} \\setminus \\mathrm{NP}$ with optimal proof systems, even when assuming an infinite $\\mathrm{PH}$. By oracle $O_2$, no relativizable proof can show that there exist sets outside $\\mathrm{NQP}$ with optimal proof systems, even when assuming $\\mathrm{NP} \\neq \\mathrm{coNP}$. This explains the difficulty of the following longstanding open questions raised by Kraj\\'i\\v{c}ek and Pudl\\'ak in 1989, Sadowski in 1997, K\\\"obler and Messner in 1998, and Messner in 2000.\n  - Q1: Are there sets outside $\\mathrm{NP}$ with optimal proof systems?\n  - Q2: Are there arbitrarily complex sets outside $\\mathrm{NP}$ with optimal proof systems?\n  Moreover, relative to $O_2$, there exist arbitrarily complex sets $L \\notin \\mathrm{NQP}$ having almost optimal algorithms, but none of them has optimal proof systems. This explains the difficulty of Messner's approach to translate almost optimal algorithms into optimal proof systems.</article>","contentLength":1744,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"V3rified: Revelation vs Non-Revelation Mechanisms for Decentralized Verifiable Computation","url":"https://arxiv.org/abs/2408.07177","date":1751515200,"author":"","guid":181996,"unread":true,"content":"<article>arXiv:2408.07177v2 Announce Type: replace \nAbstract: In the era of Web3, decentralized technologies have emerged as the cornerstone of a new digital paradigm. Backed by a decentralized blockchain architecture, the Web3 space aims to democratize all aspects of the web. From data-sharing to learning models, outsourcing computation is an established, prevalent practice. Verifiable computation makes this practice trustworthy as clients/users can now efficiently validate the integrity of a computation. As verifiable computation gets considered for applications in the Web3 space, decentralization is crucial for system reliability, ensuring that no single entity can suppress clients. At the same time, however, decentralization needs to be balanced with efficiency: clients want their computations done as quickly as possible.\n  Motivated by these issues, we study the trade-off between decentralization and efficiency when outsourcing computational tasks to strategic, rational solution providers. Specifically, we examine this trade-off when the client employs (1) revelation mechanisms, i.e. auctions, where solution providers bid their desired reward for completing the task by a specific deadline and then the client selects which of them will do the task and how much they will be rewarded, and (2) simple, non-revelation mechanisms, where the client commits to the set of rules she will use to map solutions at specific times to rewards and then solution providers decide whether they want to do the task or not. We completely characterize the power and limitations of revelation and non-revelation mechanisms in our model.</article>","contentLength":1632,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions","url":"https://arxiv.org/abs/2408.02544","date":1751515200,"author":"","guid":181997,"unread":true,"content":"<article>arXiv:2408.02544v2 Announce Type: replace \nAbstract: This paper investigates the faithfulness of multimodal large language model (MLLM) agents in a graphical user interface (GUI) environment, aiming to address the research question of whether multimodal GUI agents can be distracted by environmental context. A general scenario is proposed where both the user and the agent are benign, and the environment, while not malicious, contains unrelated content. A wide range of MLLMs are evaluated as GUI agents using a simulated dataset, following three working patterns with different levels of perception. Experimental results reveal that even the most powerful models, whether generalist agents or specialist GUI agents, are susceptible to distractions. While recent studies predominantly focus on the helpfulness of agents, our findings first indicate that these agents are prone to environmental distractions. Furthermore, we implement an adversarial environment injection and analyze the approach to improve faithfulness, calling for a collective focus on this important topic.</article>","contentLength":1078,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Foundation Models for the Digital Twin Creation of Cyber-Physical Systems","url":"https://arxiv.org/abs/2407.18779","date":1751515200,"author":"","guid":181998,"unread":true,"content":"<article>arXiv:2407.18779v2 Announce Type: replace \nAbstract: Foundation models are trained on a large amount of data to learn generic patterns. Consequently, these models can be used and fine-tuned for various purposes. Naturally, studying such models' use in the context of digital twins for cyber-physical systems (CPSs) is a relevant area of investigation. To this end, we provide perspectives on various aspects within the context of developing digital twins for CPSs, where foundation models can be used to increase the efficiency of creating digital twins, improve the effectiveness of the capabilities they provide, and used as specialized fine-tuned foundation models acting as digital twins themselves. We also discuss challenges in using foundation models in a more generic context. We use the case of an autonomous driving system as a representative CPS to give examples. Finally, we provide discussions and open research directions that we believe are valuable for the digital twin community.</article>","contentLength":996,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sublinear Regret for a Class of Continuous-Time Linear-Quadratic Reinforcement Learning Problems","url":"https://arxiv.org/abs/2407.17226","date":1751515200,"author":"","guid":181999,"unread":true,"content":"<article>arXiv:2407.17226v5 Announce Type: replace \nAbstract: We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions, where states are scalar-valued and running control rewards are absent but volatilities of the state processes depend on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an RL algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of an exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{\\frac{3}{4}})$ up to a logarithmic factor, where $N$ is the number of learning episodes. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.</article>","contentLength":1266,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Thunderbolt: Concurrent Smart Contract Execution with Non-blocking Reconfiguration for Sharded DAGs","url":"https://arxiv.org/abs/2407.09409","date":1751515200,"author":"","guid":182000,"unread":true,"content":"<article>arXiv:2407.09409v5 Announce Type: replace \nAbstract: Sharding has emerged as a critical technique for enhancing blockchain system scalability. However, existing sharding approaches face unique challenges when applied to Directed Acyclic Graph (DAG)-based protocols that integrate expressive smart contract processing. Current solutions predominantly rely on coordination mechanisms like 2PC and require transaction read/write sets to optimize parallel execution. These requirements introduce two fundamental limitations: 1) additional coordination phases incur latency overhead, and 2) pre-declaration of read/write sets proves impractical for Turing-complete smart contracts with dynamic access patterns.\n  This paper presents Thunderbolt, a novel sharding architecture for both single-shard transactions (Single-shard TXs) and cross-shard transactions (Cross-shard TXs) and enables nonblocking reconfiguration to ensure system liveness. Our design introduces 4 key innovations: 1) each replica serves dual roles as a full-shard representative and transaction proposer, employing the Execution-Order-Validation (EOV) model for Single-shard TXs and Order-Execution (OE) model for Cross-shard TXs. 2) we develop a DAG-based coordination protocol that establishes deterministic ordering between two transaction types while preserving concurrent execution capabilities. 3) we implement a dynamic concurrency controller that schedules Single-shard TXs without requiring prior knowledge of read/write sets, enabling runtime dependency resolution. 4) Thunderbolt introduces a nonblocking shard reconfiguration mechanism to address censorship attacks by featuring frequent shard re-assignment without impeding the construction of DAG nor blocking consensus. Thunderbolt achieves a 50x throughput improvement with 64 replicas compared to serial execution in the Tusk framework.</article>","contentLength":1869,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On the Trade-off between Flatness and Optimization in Distributed Learning","url":"https://arxiv.org/abs/2406.20006","date":1751515200,"author":"","guid":182001,"unread":true,"content":"<article>arXiv:2406.20006v2 Announce Type: replace \nAbstract: This paper proposes a theoretical framework to evaluate and compare the performance of stochastic gradient algorithms for distributed learning in relation to their behavior around local minima in nonconvex environments. Previous works have noticed that convergence toward flat local minima tend to enhance the generalization ability of learning algorithms. This work discovers three interesting results. First, it shows that decentralized learning strategies are able to escape faster away from local minima and favor convergence toward flatter minima relative to the centralized solution. Second, in decentralized methods, the consensus strategy has a worse excess-risk performance than diffusion, giving it a better chance of escaping from local minima and favoring flatter minima. Third, and importantly, the ultimate classification accuracy is not solely dependent on the flatness of the local minimum but also on how well a learning algorithm can approach that minimum. In other words, the classification accuracy is a function of both flatness and optimization performance. In this regard, since diffusion has a lower excess-risk than consensus, when both algorithms are trained starting from random initial points, diffusion enhances the classification accuracy. The paper examines the interplay between the two measures of flatness and optimization error closely. One important conclusion is that decentralized strategies deliver in general enhanced classification accuracy because they strike a more favorable balance between flatness and optimization performance compared to the centralized solution.</article>","contentLength":1663,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Three-Stream Temporal-Shift Attention Network Based on Self-Knowledge Distillation for Micro-Expression Recognition","url":"https://arxiv.org/abs/2406.17538","date":1751515200,"author":"","guid":182002,"unread":true,"content":"<article>arXiv:2406.17538v3 Announce Type: replace \nAbstract: Micro-expressions are subtle facial movements that occur spontaneously when people try to conceal real emotions. Micro-expression recognition is crucial in many fields, including criminal analysis and psychotherapy. However, micro-expression recognition is challenging since micro-expressions have low intensity and public datasets are small in size. To this end, a three-stream temporal-shift attention network based on self-knowledge distillation is proposed in this paper. Firstly, to address the low intensity of muscle movements, we utilize learning-based motion magnification modules to enhance the intensity of muscle movements. Secondly, we employ efficient channel attention modules in the local-spatial stream to make the network focus on facial regions that are highly relevant to micro-expressions. In addition, temporal shift modules are used in the dynamic-temporal stream, which enables temporal modeling with no additional parameters by mixing motion information from two different temporal domains. Furthermore, we introduce self-knowledge distillation into the micro-expression recognition task by introducing auxiliary classifiers and using the deepest section of the network for supervision, encouraging all blocks to fully explore the features of the training set. Finally, extensive experiments are conducted on five publicly available micro-expression datasets. The experimental results demonstrate that our network outperforms other existing methods and achieves new state-of-the-art performance. Our code is available at https://github.com/GuanghaoZhu663/SKD-TSTSAN.</article>","contentLength":1644,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Backdooring Bias (B^2) into Stable Diffusion Models","url":"https://arxiv.org/abs/2406.15213","date":1751515200,"author":"","guid":182003,"unread":true,"content":"<article>arXiv:2406.15213v3 Announce Type: replace \nAbstract: Recent advances in large text-conditional diffusion models have revolutionized image generation by enabling users to create realistic, high-quality images from textual prompts, significantly enhancing artistic creation and visual communication. However, these advancements also introduce an underexplored attack opportunity: the possibility of inducing biases by an adversary into the generated images for malicious intentions, e.g., to influence public opinion and spread propaganda. In this paper, we study an attack vector that allows an adversary to inject arbitrary bias into a target model. The attack leverages low-cost backdooring techniques using a targeted set of natural textual triggers embedded within a small number of malicious data samples produced with public generative models. An adversary could pick common sequences of words that can then be inadvertently activated by benign users during inference. We investigate the feasibility and challenges of such attacks, demonstrating how modern generative models have made this adversarial process both easier and more adaptable. On the other hand, we explore various aspects of the detectability of such attacks and demonstrate that the model's utility remains intact in the absence of the triggers. Our extensive experiments using over 200,000 generated images and against hundreds of fine-tuned models demonstrate the feasibility of the presented backdoor attack. We illustrate how these biases maintain strong text-image alignment, highlighting the challenges in detecting biased images without knowing that bias in advance. Our cost analysis confirms the low financial barrier ($10-$15) to executing such attacks, underscoring the need for robust defensive strategies against such vulnerabilities in diffusion models.</article>","contentLength":1839,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Embodied Instruction Following in Unknown Environments","url":"https://arxiv.org/abs/2406.11818","date":1751515200,"author":"","guid":182004,"unread":true,"content":"<article>arXiv:2406.11818v2 Announce Type: replace \nAbstract: Enabling embodied agents to complete complex human instructions from natural language is crucial to autonomous systems in household services. Conventional methods can only accomplish human instructions in the known environment where all interactive objects are provided to the embodied agent, and directly deploying the existing approaches for the unknown environment usually generates infeasible plans that manipulate non-existing objects. On the contrary, we propose an embodied instruction following (EIF) method for complex tasks in the unknown environment, where the agent efficiently explores the unknown environment to generate feasible plans with existing objects to accomplish abstract instructions. Specifically, we build a hierarchical embodied instruction following framework including the high-level task planner and the low-level exploration controller with multimodal large language models. We then construct a semantic representation map of the scene with dynamic region attention to demonstrate the known visual clues, where the goal of task planning and scene exploration is aligned for human instruction. For the task planner, we generate the feasible step-by-step plans for human goal accomplishment according to the task completion process and the known visual clues. For the exploration controller, the optimal navigation or object interaction policy is predicted based on the generated step-wise plans and the known visual clues. The experimental results demonstrate that our method can achieve 45.09% success rate in 204 complex human instructions such as making breakfast and tidying rooms in large house-level scenes. Code and supplementary are available at https://gary3410.github.io/eif_unknown.</article>","contentLength":1776,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Improving Consistency Models with Generator-Augmented Flows","url":"https://arxiv.org/abs/2406.09570","date":1751515200,"author":"","guid":182005,"unread":true,"content":"<article>arXiv:2406.09570v4 Announce Type: replace \nAbstract: Consistency models imitate the multi-step sampling of score-based diffusion in a single forward pass of a neural network. They can be learned in two ways: consistency distillation and consistency training. The former relies on the true velocity field of the corresponding differential equation, approximated by a pre-trained neural network. In contrast, the latter uses a single-sample Monte Carlo estimate of this velocity field. The related estimation error induces a discrepancy between consistency distillation and training that, we show, still holds in the continuous-time limit. To alleviate this issue, we propose a novel flow that transports noisy data towards their corresponding outputs derived from a consistency model. We prove that this flow reduces the previously identified discrepancy and the noise-data transport cost. Consequently, our method not only accelerates consistency training convergence but also enhances its overall performance. The code is available at: https://github.com/thibautissenhuth/consistency_GC.</article>","contentLength":1088,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Active Scout: Multi-Target Tracking Using Neural Radiance Fields in Dense Urban Environments","url":"https://arxiv.org/abs/2406.07431","date":1751515200,"author":"","guid":182006,"unread":true,"content":"<article>arXiv:2406.07431v3 Announce Type: replace \nAbstract: We study pursuit-evasion games in highly occluded urban environments, e.g. tall buildings in a city, where a scout (quadrotor) tracks multiple dynamic targets on the ground. We show that we can build a neural radiance field (NeRF) representation of the city -- online -- using RGB and depth images from different vantage points. This representation is used to calculate the information gain to both explore unknown parts of the city and track the targets -- thereby giving a completely first-principles approach to actively tracking dynamic targets. We demonstrate, using a custom-built simulator using Open Street Maps data of Philadelphia and New York City, that we can explore and locate 20 stationary targets within 300 steps. This is slower than a greedy baseline, which does not use active perception. But for dynamic targets that actively hide behind occlusions, we show that our approach maintains, at worst, a tracking error of 200m; the greedy baseline can have a tracking error as large as 600m. We observe a number of interesting properties in the scout's policies, e.g., it switches its attention to track a different target periodically, as the quality of the NeRF representation improves over time, the scout also becomes better in terms of target tracking. Code is available at https://github.com/grasp-lyrl/ActiveScout.</article>","contentLength":1389,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Embedded Graph Convolutional Networks for Real-Time Event Data Processing on SoC FPGAs","url":"https://arxiv.org/abs/2406.07318","date":1751515200,"author":"","guid":182007,"unread":true,"content":"<article>arXiv:2406.07318v2 Announce Type: replace \nAbstract: The utilisation of event cameras represents an important and swiftly evolving trend aimed at addressing the constraints of traditional video systems. Particularly within the automotive domain, these cameras find significant relevance for their integration into embedded real-time systems due to lower latency and energy consumption. One effective approach to ensure the necessary throughput and latency for event processing is through the utilisation of graph convolutional networks (GCNs). In this study, we introduce a custom EFGCN (Event-based FPGA-accelerated Graph Convolutional Network) designed with a series of hardware-aware optimisations tailored for PointNetConv, a graph convolution designed for point cloud processing. The proposed techniques result in up to 100-fold reduction in model size compared to Asynchronous Event-based GNN (AEGNN), one of the most recent works in the field, with a relatively small decrease in accuracy (2.9% for the N-Caltech101 classification task, 2.2% for the N-Cars classification task), thus following the TinyML trend. We implemented EFGCN on a ZCU104 SoC FPGA platform without any external memory resources, achieving a throughput of 13.3 million events per second (MEPS) and real-time partially asynchronous processing with low latency. Our approach achieves state-of-the-art performance across multiple event-based classification benchmarks while remaining highly scalable, customisable and resource-efficient. We publish both software and hardware source code in an open repository: https://github.com/vision-agh/gcnn-dvs-fpga</article>","contentLength":1630,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Time-Series JEPA for Predictive Remote Control under Capacity-Limited Networks","url":"https://arxiv.org/abs/2406.04853","date":1751515200,"author":"","guid":182008,"unread":true,"content":"<article>arXiv:2406.04853v2 Announce Type: replace \nAbstract: In remote control systems, transmitting large data volumes (e.g., images, video frames) from wireless sensors to remote controllers is challenging when uplink capacity is limited (e.g., RedCap devices or massive wireless sensor networks). Furthermore, controllers often need only information-rich representations of the original data. To address this, we propose a semantic-driven predictive control combined with a channel-aware scheduling to enhance control performance for multiple devices under limited network capacity. At its core, the proposed framework, coined Time-Series Joint Embedding Predictive Architecture (TS-JEPA), encodes high-dimensional sensory data into low-dimensional semantic embeddings at the sensor, reducing communication overhead. Furthermore, TS-JEPA enables predictive inference by predicting future embeddings from current ones and predicted commands, which are directly used by a semantic actor model to compute control commands within the embedding space, eliminating the need to reconstruct raw data. To further enhance reliability and communication efficiency, a channel-aware scheduling is integrated to dynamically prioritize device transmissions based on channel conditions and age of information (AoI). Simulations on inverted cart-pole systems show that the proposed framework significantly outperforms conventional control baselines in communication efficiency, control cost, and predictive accuracy. It enables robust and scalable control under limited network capacity compared to traditional scheduling schemes.</article>","contentLength":1608,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OralBBNet: Spatially Guided Dental Segmentation of Panoramic X-Rays with Bounding Box Priors","url":"https://arxiv.org/abs/2406.03747","date":1751515200,"author":"","guid":182009,"unread":true,"content":"<article>arXiv:2406.03747v3 Announce Type: replace \nAbstract: Teeth segmentation and recognition play a vital role in a variety of dental applications and diagnostic procedures. The integration of deep learning models has facilitated the development of precise and automated segmentation methods. Although prior research has explored teeth segmentation, not many methods have successfully performed tooth segmentation and detection simultaneously. This study presents UFBA-425, a dental dataset derived from the UFBA-UESC dataset, featuring bounding box and polygon annotations for 425 panoramic dental X-rays. In addition, this paper presents the OralBBNet architecture, which is based on the best segmentation and detection qualities of architectures such as U-Net and YOLOv8, respectively. OralBBNet is designed to improve the accuracy and robustness of tooth classification and segmentation on panoramic X-rays by leveraging the complementary strengths of U-Net and YOLOv8. Our approach achieved a 1-3% improvement in mean average precision (mAP) for tooth detection compared to existing techniques and a 15-20% improvement in the dice score for teeth segmentation over state-of-the-art (SOTA) solutions for various tooth categories and 2-4% improvement in the dice score compared to other SOTA segmentation architectures. The results of this study establish a foundation for the wider implementation of object detection models in dental diagnostics.</article>","contentLength":1445,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Semantic Equitable Clustering: A Simple and Effective Strategy for Clustering Vision Tokens","url":"https://arxiv.org/abs/2405.13337","date":1751515200,"author":"","guid":182010,"unread":true,"content":"<article>arXiv:2405.13337v3 Announce Type: replace \nAbstract: The Vision Transformer (ViT) has gained prominence for its superior relational modeling prowess. However, its global attention mechanism's quadratic complexity poses substantial computational burdens. A common remedy spatially groups tokens for self-attention, reducing computational requirements. Nonetheless, this strategy neglects semantic information in tokens, possibly scattering semantically-linked tokens across distinct groups, thus compromising the efficacy of self-attention intended for modeling inter-token dependencies. Motivated by these insights, we introduce a fast and balanced clustering method, named Semantic Equitable Clustering (SEC). SEC clusters tokens based on their global semantic relevance in an efficient, straightforward manner. In contrast to traditional clustering methods requiring multiple iterations, our method achieves token clustering in a single pass. Additionally, SEC regulates the number of tokens per cluster, ensuring a balanced distribution for effective parallel processing on current computational platforms without necessitating further optimization. Capitalizing on SEC, we propose a versatile vision backbone, SECViT. Comprehensive experiments in image classification, object detection, instance segmentation, and semantic segmentation validate the effectiveness of SECViT. Moreover, SEC can be conveniently and swiftly applied to multimodal large language models (MLLM), such as LLaVA, to serve as a vision language connector, effectively accelerating the model's efficiency while maintaining unchanged or better performance.</article>","contentLength":1630,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Divergent Creativity in Humans and Large Language Models","url":"https://arxiv.org/abs/2405.13012","date":1751515200,"author":"","guid":182011,"unread":true,"content":"<article>arXiv:2405.13012v2 Announce Type: replace \nAbstract: The recent surge of Large Language Models (LLMs) has led to claims that they are approaching a level of creativity akin to human capabilities. This idea has sparked a blend of excitement and apprehension. However, a critical piece that has been missing in this discourse is a systematic evaluation of LLMs' semantic diversity, particularly in comparison to human divergent thinking. To bridge this gap, we leverage recent advances in computational creativity to analyze semantic divergence in both state-of-the-art LLMs and a substantial dataset of 100,000 humans. We found evidence that LLMs can surpass average human performance on the Divergent Association Task, and approach human creative writing abilities, though they fall short of the typical performance of highly creative humans. Notably, even the top performing LLMs are still largely surpassed by highly creative individuals, underscoring a ceiling that current LLMs still fail to surpass. Our human-machine benchmarking framework addresses the polemic surrounding the imminent replacement of human creative labour by AI, disentangling the quality of the respective creative linguistic outputs using established objective measures. While prompting deeper exploration of the distinctive elements of human inventive thought compared to those of AI systems, we lay out a series of techniques to improve their outputs with respect to semantic diversity, such as prompt design and hyper-parameter tuning.</article>","contentLength":1514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NeRFs in Robotics: A Survey","url":"https://arxiv.org/abs/2405.01333","date":1751515200,"author":"","guid":182012,"unread":true,"content":"<article>arXiv:2405.01333v2 Announce Type: replace \nAbstract: Detailed and realistic 3D environment representations have been a long-standing goal in the fields of computer vision and robotics. The recent emergence of neural implicit representations has introduced significant advances to these domains, enabling numerous novel capabilities. Among these, Neural Radiance Fields (NeRFs) have gained considerable attention because of their considerable representational advantages, such as simplified mathematical models, low memory footprint, and continuous scene representations. In addition to computer vision, NeRFs have demonstrated significant potential in robotics. Thus, we present this survey to provide a comprehensive understanding of NeRFs in the field of robotics. By exploring the advantages and limitations of NeRF as well as its current applications and future potential, we aim to provide an overview of this promising area of research. Our survey is divided into two main sections: \\textit{Applications of NeRFs in Robotics} and \\textit{Advances for NeRFs in Robotics}, from the perspective of how NeRF enters the field of robotics. In the first section, we introduce and analyze some works that have been or could be used in robotics for perception and interaction tasks. In the second section, we show some works related to improving NeRF's own properties, which are essential for deploying NeRFs in robotics. In the discussion section of the review, we summarize the existing challenges and provide valuable future research directions.</article>","contentLength":1545,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Don't Say No: Jailbreaking LLM by Suppressing Refusal","url":"https://arxiv.org/abs/2404.16369","date":1751515200,"author":"","guid":182013,"unread":true,"content":"<article>arXiv:2404.16369v3 Announce Type: replace \nAbstract: Ensuring the safety alignment of Large Language Models (LLMs) is critical for generating responses consistent with human values. However, LLMs remain vulnerable to jailbreaking attacks, where carefully crafted prompts manipulate them into producing toxic content. One category of such attacks reformulates the task as an optimization problem, aiming to elicit affirmative responses from the LLM. However, these methods heavily rely on predefined objectionable behaviors, limiting their effectiveness and adaptability to diverse harmful queries. In this study, we first identify why the vanilla target loss is suboptimal and then propose enhancements to the loss objective. We introduce DSN (Don't Say No) attack, which combines a cosine decay schedule method with refusal suppression to achieve higher success rates. Extensive experiments demonstrate that DSN outperforms baseline attacks and achieves state-of-the-art attack success rates (ASR). DSN also shows strong universality and transferability to unseen datasets and black-box models.</article>","contentLength":1095,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Logic Optimization Meets SAT: A Novel Framework for Circuit-SAT Solving","url":"https://arxiv.org/abs/2403.19446","date":1751515200,"author":"","guid":182014,"unread":true,"content":"<article>arXiv:2403.19446v2 Announce Type: replace \nAbstract: The Circuit Satisfiability (CSAT) problem, a variant of the Boolean Satisfiability (SAT) problem, plays a critical role in integrated circuit design and verification. However, existing SAT solvers, optimized for Conjunctive Normal Form (CNF), often struggle with the intrinsic complexity of circuit structures when directly applied to CSAT instances. To address this challenge, we propose a novel preprocessing framework that leverages advanced logic synthesis techniques and a reinforcement learning (RL) agent to optimize CSAT problem instances. The framework introduces a cost-customized Look-Up Table (LUT) mapping strategy that prioritizes solving efficiency, effectively transforming circuits into simplified forms tailored for SAT solvers. Our method achieves significant runtime reductions across diverse industrial-scale CSAT benchmarks, seamlessly integrating with state-of-the-art SAT solvers. Extensive experimental evaluations demonstrate up to 63\\% reduction in solving time compared to conventional approaches, highlighting the potential of EDA-driven innovations to advance SAT-solving capabilities.</article>","contentLength":1168,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Diffusion Policies for Risk-Averse Behavior Modeling in Offline Reinforcement Learning","url":"https://arxiv.org/abs/2403.17646","date":1751515200,"author":"","guid":182015,"unread":true,"content":"<article>arXiv:2403.17646v2 Announce Type: replace \nAbstract: Offline reinforcement learning (RL) presents distinct challenges as it relies solely on observational data. A central concern in this context is ensuring the safety of the learned policy by quantifying uncertainties associated with various actions and environmental stochasticity. Traditional approaches primarily emphasize mitigating epistemic uncertainty by learning risk-averse policies, often overlooking environmental stochasticity. In this study, we propose an uncertainty-aware distributional offline RL method to simultaneously address both epistemic uncertainty and environmental stochasticity. We propose a model-free offline RL algorithm capable of learning risk-averse policies and characterizing the entire distribution of discounted cumulative rewards, as opposed to merely maximizing the expected value of accumulated discounted returns. Our method is rigorously evaluated through comprehensive experiments in both risk-sensitive and risk-neutral benchmarks, demonstrating its superior performance.</article>","contentLength":1066,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Co-Optimizing Reconfigurable Environments and Policies for Decentralized Multi-Agent Navigation","url":"https://arxiv.org/abs/2403.14583","date":1751515200,"author":"","guid":182016,"unread":true,"content":"<article>arXiv:2403.14583v2 Announce Type: replace \nAbstract: This work views the multi-agent system and its surrounding environment as a co-evolving system, where the behavior of one affects the other. The goal is to take both agent actions and environment configurations as decision variables, and optimize these two components in a coordinated manner to improve some measure of interest. Towards this end, we consider the problem of decentralized multi-agent navigation in a cluttered environment, where we assume that the layout of the environment is reconfigurable. By introducing two sub-objectives -- multi-agent navigation and environment optimization -- we propose an agent-environment co-optimization problem and develop a coordinated algorithm that alternates between these sub-objectives to search for an optimal synthesis of agent actions and environment configurations; ultimately, improving the navigation performance. Due to the challenge of explicitly modeling the relation between the agents, the environment and their performance therein, we leverage policy gradient to formulate a model-free learning mechanism within the coordinated framework. A formal convergence analysis shows that our coordinated algorithm tracks the local minimum solution of an associated time-varying non-convex optimization problem. Experiments corroborate theoretical findings and show the benefits of co-optimization. Interestingly, the results also indicate that optimized environments can offer structural guidance to de-conflict agents in motion.</article>","contentLength":1538,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation","url":"https://arxiv.org/abs/2403.06759","date":1751515200,"author":"","guid":182017,"unread":true,"content":"<article>arXiv:2403.06759v2 Announce Type: replace \nAbstract: Deep neural networks for medical image segmentation often produce overconfident results misaligned with empirical observations. Such miscalibration, challenges their clinical translation. We propose to use marginal L1 average calibration error (mL1-ACE) as a novel auxiliary loss function to improve pixel-wise calibration without compromising segmentation quality. We show that this loss, despite using hard binning, is directly differentiable, bypassing the need for approximate but differentiable surrogate or soft binning approaches. Our work also introduces the concept of dataset reliability histograms which generalises standard reliability diagrams for refined visual assessment of calibration in semantic segmentation aggregated at the dataset level. Using mL1-ACE, we reduce average and maximum calibration error by 45% and 55% respectively, maintaining a Dice score of 87% on the BraTS 2021 dataset. We share our code here: https://github.com/cai4cai/ACE-DLIRIS</article>","contentLength":1025,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Inverse Optimal Control for Linear Quadratic Tracking with Unknown Target States","url":"https://arxiv.org/abs/2402.17247","date":1751515200,"author":"","guid":182018,"unread":true,"content":"<article>arXiv:2402.17247v3 Announce Type: replace \nAbstract: This paper addresses the inverse optimal control for the linear quadratic tracking problem with a fixed but unknown target state, which aims to estimate the possible triplets comprising the target state, the state weight matrix, and the input weight matrix from observed optimal control input and the corresponding state trajectories. Sufficient conditions have been provided for the unique determination of both the linear quadratic cost function as well as the target state. A computationally efficient and numerically reliable parameter identification algorithm is proposed by equating optimal control strategies with a system of linear equations, and the associated relative error upper bound is derived in terms of data volume and signal-to-noise ratio. Moreover, the proposed inverse optimal control algorithm is applied for the joint cluster coordination and intent identification of a multi-agent system. By incorporating the structural constraint of the Laplace matrix, the relative error upper bound can be reduced accordingly. Finally, the algorithm's efficiency and accuracy are validated by a vehicle-on-a-lever example and a multi-agent formation control example.</article>","contentLength":1230,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Vehicle-group-based Crash Risk Prediction and Interpretation on Highways","url":"https://arxiv.org/abs/2402.12415","date":1751515200,"author":"","guid":182019,"unread":true,"content":"<article>arXiv:2402.12415v3 Announce Type: replace \nAbstract: Previous studies in predicting crash risks primarily associated the number or likelihood of crashes on a road segment with traffic parameters or geometric characteristics, usually neglecting the impact of vehicles' continuous movement and interactions with nearby vehicles. Recent technology advances, such as Connected and Automated Vehicles (CAVs) and Unmanned Aerial Vehicles (UAVs) are able to collect high-resolution trajectory data, which enables trajectory-based risk analysis. This study investigates a new vehicle group (VG) based risk analysis method and explores risk evolution mechanisms considering VG features. An impact-based vehicle grouping method is proposed to cluster vehicles into VGs by evaluating their responses to the erratic behaviors of nearby vehicles. The risk of a VG is aggregated based on the risk between each vehicle pair in the VG, measured by inverse Time-to-Collision (iTTC). A Logistic Regression and a Graph Neural Network (GNN) are then employed to predict VG risks using aggregated and disaggregated VG information. Both methods achieve excellent performance with AUC values exceeding 0.93. For the GNN model, GNNExplainer with feature perturbation is applied to identify critical individual vehicle features and their directional impact on VG risks. Overall, this research contributes a new perspective for identifying, predicting, and interpreting traffic risks.</article>","contentLength":1458,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Collision-Free Robot Scheduling","url":"https://arxiv.org/abs/2402.12019","date":1751515200,"author":"","guid":182020,"unread":true,"content":"<article>arXiv:2402.12019v3 Announce Type: replace \nAbstract: Robots are becoming an increasingly common part of scientific work within laboratory environments. In this paper, we investigate the problem of designing \\emph{schedules} for completing a set of tasks at fixed locations with multiple robots in a laboratory. We represent the laboratory as a graph with tasks placed on fixed vertices and robots represented as agents, with the constraint that no two robots may occupy the same vertex at any given timestep. Each schedule is partitioned into a set of timesteps, corresponding to a walk through the graph (allowing for a robot to wait at a vertex to complete a task), with each timestep taking time equal to the time for a robot to move from one vertex to another and each task taking some given number of timesteps during the completion of which a robot must stay at the vertex containing the task. The goal is to determine a set of schedules, with one schedule for each robot, minimising the number of timesteps taken by the schedule taking the greatest number of timesteps within the set of schedules.\n  We show that this problem is NP-complete for many simple classes of graphs, the problem of determining the fastest schedule, defined by the number of time steps required for a robot to visit every vertex in the schedule and complete every task assigned in its assigned schedule. Explicitly, we provide this result for complete graphs, bipartite graphs, star graphs, and planar graphs. Finally, we provide positive results for line graphs, showing that we can find an optimal set of schedules for $k$ robots completing $m$ tasks of equal length of a path of length $n$ in $O(kmn)$ time, and a $k$-approximation when the length of the tasks is unbounded.</article>","contentLength":1759,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SpikeNAS: A Fast Memory-Aware Neural Architecture Search Framework for Spiking Neural Network-based Embedded AI Systems","url":"https://arxiv.org/abs/2402.11322","date":1751515200,"author":"","guid":182021,"unread":true,"content":"<article>arXiv:2402.11322v4 Announce Type: replace \nAbstract: Embedded AI systems are expected to incur low power/energy consumption for solving machine learning tasks, as these systems are usually power constrained (e.g., object recognition task in autonomous mobile agents with portable batteries). These requirements can be fulfilled by Spiking Neural Networks (SNNs), since their bio-inspired spike-based operations offer high accuracy and ultra low-power/energy computation. Currently, most of SNN architectures are derived from Artificial Neural Networks whose neurons' architectures and operations are different from SNNs, and/or developed without considering memory budgets from the underlying processing hardware of embedded platforms. These limitations hinder SNNs from reaching their full potential in accuracy and efficiency. Toward this, we propose SpikeNAS, a novel fast memory-aware neural architecture search (NAS) framework for SNNs that quickly finds an appropriate SNN architecture with high accuracy under the given memory budgets from targeted embedded systems. To do this, our SpikeNAS employs several key steps: analyzing the impacts of network operations on the accuracy, enhancing the network architecture to improve the learning quality, developing a fast memory-aware search algorithm, and performing quantization. The experimental results show that our SpikeNAS improves the searching time and maintains high accuracy compared to state-of-the-art while meeting the given memory budgets (e.g., 29x, 117x, and 3.7x faster search for CIFAR10, CIFAR100, and TinyImageNet200 respectively, using an Nvidia RTX A6000 GPU machine), thereby quickly providing the appropriate SNN architecture for the memory-constrained embedded AI systems.</article>","contentLength":1749,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Squat: Quant Small Language Models on the Edge","url":"https://arxiv.org/abs/2402.10787","date":1751515200,"author":"","guid":182022,"unread":true,"content":"<article>arXiv:2402.10787v2 Announce Type: replace \nAbstract: A growing trend has emerged in designing high-quality Small Language Models (SLMs) with a few million parameters. This trend is driven by the increasing concerns over cloud costs, privacy, and latency. Considering that full parameter training is feasible for SLMs on mobile devices, Quantization-Aware Training (QAT) is employed to improve efficiency by reducing computational overhead and memory footprint. However, previous QAT works adopt fine-grained quantization methods to compress models with billions of parameters on GPUs, incompatible with current commodity hardware, such as mobile and edge devices, which relies on Single Instruction Multiple Data (SIMD) instructions. Thus, the generalization of these methods to SLMs on mobile devices is limited. In this paper, we propose Squat method, an effective QAT framework with deployable quantization for SLMs on mobile devices. Specifically, we propose entropy-guided and distribution-aligned distillation to mitigate the distortion of attention information from quantization. Besides, we employ sub-8-bit token adaptive quantization, assigning varying bit widths to different tokens based on their importance. Furthermore, we develop a SIMD-based Multi-Kernel Mixed-Precision (MKMP) multiplier to support sub-8-bit mixed-precision MAC on mobile devices. Our extensive experiments verify the substantial improvements of our method compared to other QAT methods across various datasets. Furthermore, we achieve an on-device speedup of up to 2.37x compared with its FP16 counterparts, signaling a great advancement. Code: https://github.com/shawnricecake/squant</article>","contentLength":1669,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Momentum Does Not Reduce Stochastic Noise in Stochastic Gradient Descent","url":"https://arxiv.org/abs/2402.02325","date":1751515200,"author":"","guid":182023,"unread":true,"content":"<article>arXiv:2402.02325v5 Announce Type: replace \nAbstract: For nonconvex objective functions, including those found in training deep neural networks, stochastic gradient descent (SGD) with momentum is said to converge faster and have better generalizability than SGD without momentum. In particular, adding momentum is thought to reduce stochastic noise. To verify this, we estimated the magnitude of gradient noise by using convergence analysis and an optimal batch size estimation formula and found that momentum does not reduce gradient noise. We also analyzed the effect of search direction noise, which is stochastic noise defined as the error between the search direction of the optimizer and the steepest descent direction, and found that it inherently smooths the objective function and that momentum does not reduce search direction noise either. Finally, an analysis of the degree of smoothing introduced by search direction noise revealed that adding momentum offers limited advantage to SGD.</article>","contentLength":997,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SCALER: Versatile Multi-Limbed Robot for Free-Climbing in Extreme Terrains","url":"https://arxiv.org/abs/2312.04856","date":1751515200,"author":"","guid":182024,"unread":true,"content":"<article>arXiv:2312.04856v3 Announce Type: replace \nAbstract: This paper presents SCALER, a versatile free-climbing multi-limbed robot that is designed to achieve tightly coupled simultaneous locomotion and dexterous grasping. While existing quadrupedal-limbed robots have demonstrated impressive dexterous capabilities, achieving a balance between power-demanding locomotion and precise grasping remains a critical challenge. We design a torso mechanism and a parallel-serial limb to meet the conflicting requirements that pose unique challenges in hardware design. SCALER employs underactuated two-fingered GOAT grippers that can mechanically adapt and offer seven modes of grasping, enabling SCALER to traverse extreme terrains with multi-modal grasping strategies. We study the whole-body approach, where SCALER utilizes its body and limbs to generate additional forces for stable grasping in various environments, thereby further enhancing its versatility. Furthermore, we improve the GOAT gripper actuation speed to realize more dynamic climbing in a closed-loop control fashion. With these proposed technologies, SCALER can traverse vertical, overhanging, upside-down, slippery terrains and bouldering walls with non-convex-shaped climbing holds under the Earth's gravity.</article>","contentLength":1270,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dataset Distillation via the Wasserstein Metric","url":"https://arxiv.org/abs/2311.18531","date":1751515200,"author":"","guid":182025,"unread":true,"content":"<article>arXiv:2311.18531v3 Announce Type: replace \nAbstract: Dataset Distillation (DD) aims to generate a compact synthetic dataset that enables models to achieve performance comparable to training on the full large dataset, significantly reducing computational costs. Drawing from optimal transport theory, we introduce WMDD (Wasserstein Metric-based Dataset Distillation), a straightforward yet powerful method that employs the Wasserstein metric to enhance distribution matching.\n  We compute the Wasserstein barycenter of features from a pretrained classifier to capture essential characteristics of the original data distribution. By optimizing synthetic data to align with this barycenter in feature space and leveraging per-class BatchNorm statistics to preserve intra-class variations, WMDD maintains the efficiency of distribution matching approaches while achieving state-of-the-art results across various high-resolution datasets. Our extensive experiments demonstrate WMDD's effectiveness and adaptability, highlighting its potential for advancing machine learning applications at scale.</article>","contentLength":1091,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Jenga Stacking Based on 6D Pose Estimation for Architectural Form Finding Process","url":"https://arxiv.org/abs/2311.10918","date":1751515200,"author":"","guid":182026,"unread":true,"content":"<article>arXiv:2311.10918v2 Announce Type: replace \nAbstract: This paper includes a review of current state of the art 6d pose estimation methods, as well as a discussion of which pose estimation method should be used in two types of architectural design scenarios. Taking the latest pose estimation research Gen6d as an example, we make a qualitative assessment of the current openset methods in terms of application level, prediction speed, resistance to occlusion, accuracy, resistance to environmental interference, etc. In addition, we try to combine 6D pose estimation and building wind environment assessment to create tangible architectural design approach, we discuss the limitations of the method and point out the direction in which 6d pose estimation is eager to progress in this scenario.</article>","contentLength":792,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Anyview: Generalizable Indoor 3D Object Detection with Variable Frames","url":"https://arxiv.org/abs/2310.05346","date":1751515200,"author":"","guid":182027,"unread":true,"content":"<article>arXiv:2310.05346v2 Announce Type: replace \nAbstract: In this paper, we propose a novel network framework for indoor 3D object detection to handle variable input frame numbers in practical scenarios. Existing methods only consider fixed frames of input data for a single detector, such as monocular RGB-D images or point clouds reconstructed from dense multi-view RGB-D images. While in practical application scenes such as robot navigation and manipulation, the raw input to the 3D detectors is the RGB-D images with variable frame numbers instead of the reconstructed scene point cloud. However, the previous approaches can only handle fixed frame input data and have poor performance with variable frame input. In order to facilitate 3D object detection methods suitable for practical tasks, we present a novel 3D detection framework named AnyView for our practical applications, which generalizes well across different numbers of input frames with a single model. To be specific, we propose a geometric learner to mine the local geometric features of each input RGB-D image frame and implement local-global feature interaction through a designed spatial mixture module. Meanwhile, we further utilize a dynamic token strategy to adaptively adjust the number of extracted features for each frame, which ensures consistent global feature density and further enhances the generalization after fusion. Extensive experiments on the ScanNet dataset show our method achieves both great generalizability and high detection accuracy with a simple and clean architecture containing a similar amount of parameters with the baselines.</article>","contentLength":1624,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A FAIR File Format for Mathematical Software","url":"https://arxiv.org/abs/2309.00465","date":1751515200,"author":"","guid":182028,"unread":true,"content":"<article>arXiv:2309.00465v2 Announce Type: replace \nAbstract: We describe a generic JSON based file format which is suitable for computations in computer algebra. This is implemented in the computer algebra system OSCAR, but we also indicate how it can be used in a different context.</article>","contentLength":275,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Design Tasks and Their Complexity for the European Train Control System with Hybrid Train Detection","url":"https://arxiv.org/abs/2308.02572","date":1751515200,"author":"","guid":182029,"unread":true,"content":"<article>arXiv:2308.02572v5 Announce Type: replace \nAbstract: Railway networks have become increasingly important in recent times, especially in moving freight and public transportation from road traffic and planes to more environmentally friendly trains. Since expanding the global railway network is time- and resource-consuming, maximizing the rail capacity of the existing infrastructure is desirable. However, simply running more trains is infeasible as certain constraints enforced by the train control system must be satisfied. The capacity of a network depends (amongst others) on the distance between trains allowed by this safety system. While most signaling systems rely on fixed blocks defined by costly hardware, new specifications provided by Level 2 with Hybrid Train Detection of the European Train Control System (ETCS L2 HTD), formerly known as ETCS Hybrid Level 3, allow the usage of virtual subsections. This additional degree of freedom allows for shorter train following times and, thus, more trains on existing railway tracks. On the other hand, new design tasks arise on which automated methods might be helpful for designers of modern railway networks. However, although first approaches exist that solve design problems arising within ETCS L2 HTD, neither formal descriptions nor results on the computational complexity of the corresponding design tasks exist. In this paper, we fill this gap by providing a formal description of design tasks for ETCS L2 HTD and proof that these tasks are NP-complete or NP-hard, respectively. By that, we are providing a solid basis for the future development of methods to solve those tasks, which will be integrated into the Munich Train Control Toolkit available open-source on GitHub at https://github.com/cda-tum/mtct.</article>","contentLength":1775,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Feature Reweighting for EEG-based Motor Imagery Classification","url":"https://arxiv.org/abs/2308.02515","date":1751515200,"author":"","guid":182030,"unread":true,"content":"<article>arXiv:2308.02515v2 Announce Type: replace \nAbstract: Classification of motor imagery (MI) using non-invasive electroencephalographic (EEG) signals is a critical objective as it is used to predict the intention of limb movements of a subject. In recent research, convolutional neural network (CNN) based methods have been widely utilized for MI-EEG classification. The challenges of training neural networks for MI-EEG signals classification include low signal-to-noise ratio, non-stationarity, non-linearity, and high complexity of EEG signals. The features computed by CNN-based networks on the highly noisy MI-EEG signals contain irrelevant information. Subsequently, the feature maps of the CNN-based network computed from the noisy and irrelevant features contain irrelevant information. Thus, many non-contributing features often mislead the neural network training and degrade the classification performance. Hence, a novel feature reweighting approach is proposed to address this issue. The proposed method gives a noise reduction mechanism named feature reweighting module that suppresses irrelevant temporal and channel feature maps. The feature reweighting module of the proposed method generates scores that reweight the feature maps to reduce the impact of irrelevant information. Experimental results show that the proposed method significantly improved the classification of MI-EEG signals of Physionet EEG-MMIDB and BCI Competition IV 2a datasets by a margin of 9.34% and 3.82%, respectively, compared to the state-of-the-art methods.</article>","contentLength":1549,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Combating Confirmation Bias: A Unified Pseudo-Labeling Framework for Entity Alignment","url":"https://arxiv.org/abs/2307.02075","date":1751515200,"author":"","guid":182031,"unread":true,"content":"<article>arXiv:2307.02075v4 Announce Type: replace \nAbstract: Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity. To circumvent the shortage of seed alignments provided for training, recent EA models utilize pseudo-labeling strategies to iteratively add unaligned entity pairs predicted with high confidence to the seed alignments for model training. However, the adverse impact of confirmation bias during pseudo-labeling has been largely overlooked, thus hindering entity alignment performance. To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment. UPL-EA consists of two complementary components: (1) Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to determine entity correspondences and reduce erroneous matches across two KGs. An effective criterion is derived to infer pseudo-labeled alignments that satisfy one-to-one correspondences; (2) Parallel pseudo-label ensembling refines pseudo-labeled alignments by combining predictions over multiple models independently trained in parallel. The ensembled pseudo-labeled alignments are thereafter used to augment seed alignments to reinforce subsequent model training for alignment inference. The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated. Our extensive results and in-depth analyses demonstrate the superiority of UPL-EA over 15 competitive baselines and its utility as a general pseudo-labeling framework for entity alignment.</article>","contentLength":1799,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reliable Representation Learning for Incomplete Multi-View Missing Multi-Label Classification","url":"https://arxiv.org/abs/2303.17117","date":1751515200,"author":"","guid":182032,"unread":true,"content":"<article>arXiv:2303.17117v4 Announce Type: replace \nAbstract: As a cross-topic of multi-view learning and multi-label classification, multi-view multi-label classification has gradually gained traction in recent years. The application of multi-view contrastive learning has further facilitated this process, however, the existing multi-view contrastive learning methods crudely separate the so-called negative pair, which largely results in the separation of samples belonging to the same category or similar ones. Besides, plenty of multi-view multi-label learning methods ignore the possible absence of views and labels. To address these issues, in this paper, we propose an incomplete multi-view missing multi-label classification network named RANK. In this network, a label-driven multi-view contrastive learning strategy is proposed to leverage supervised information to preserve the intra-view structure and perform the cross-view consistency alignment. Furthermore, we break through the view-level weights inherent in existing methods and propose a quality-aware sub-network to dynamically assign quality scores to each view of each sample. The label correlation information is fully utilized in the final multi-label cross-entropy classification loss, effectively improving the discriminative power. Last but not least, our model is not only able to handle complete multi-view multi-label data, but also works on datasets with missing instances and labels. Extensive experiments confirm that our RANK outperforms existing state-of-the-art methods.</article>","contentLength":1547,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learned-Database Systems Security","url":"https://arxiv.org/abs/2212.10318","date":1751515200,"author":"","guid":182033,"unread":true,"content":"<article>arXiv:2212.10318v4 Announce Type: replace \nAbstract: A learned database system uses machine learning (ML) internally to improve performance. We can expect such systems to be vulnerable to some adversarial-ML attacks. Often, the learned component is shared between mutually-distrusting users or processes, much like microarchitectural resources such as caches, potentially giving rise to highly-realistic attacker models. However, compared to attacks on other ML-based systems, attackers face a level of indirection as they cannot interact directly with the learned model. Additionally, the difference between the attack surface of learned and non-learned versions of the same system is often subtle. These factors obfuscate the de-facto risks that the incorporation of ML carries. We analyze the root causes of potentially-increased attack surface in learned database systems and develop a framework for identifying vulnerabilities that stem from the use of ML. We apply our framework to a broad set of learned components currently being explored in the database community. To empirically validate the vulnerabilities surfaced by our framework, we choose 3 of them and implement and evaluate exploits against these. We show that the use of ML cause leakage of past queries in a database, enable a poisoning attack that causes exponential memory blowup in an index structure and crashes it in seconds, and enable index users to snoop on each others' key distributions by timing queries over their own keys. We find that adversarial ML is an universal threat against learned components in database systems, point to open research gaps in our understanding of learned-systems security, and conclude by discussing mitigations, while noting that data leakage is inherent in systems whose learned component is shared between multiple parties.</article>","contentLength":1836,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Decoding Neural Signals: Invasive BMI Review","url":"https://arxiv.org/abs/2211.03324","date":1751515200,"author":"","guid":182034,"unread":true,"content":"<article>arXiv:2211.03324v3 Announce Type: replace \nAbstract: Human civilization has witnessed transformative technological milestones, from ancient fire lighting to the internet era. This chapter delves into the invasive brain machine interface (BMI), a pioneering technology poised to be a defining chapter in our progress. Beyond aiding medical conditions, invasive BMI promises far reaching impacts across diverse technologies and aspects of life. The exploration begins by unraveling the biological and engineering principles essential for BMI implementation. The chapter comprehensively analyzes potential applications, methodologies for detecting and decoding brain signals, and options for stimulating signals within the human brain. It concludes with a discussion on the multifaceted challenges and opportunities for the continued development of invasive BMI. This chapter not only provides a profound understanding of the foundational elements of invasive BMI but also serves as a guide through its applications, intricacies, and potential societal implications. Navigating neurobiology, engineering innovations, and the evolving landscape of human AI symbiosis, the chapter sheds light on the promises and hurdles that define the future of invasive BMI.</article>","contentLength":1255,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fair Division with Bounded Sharing: Binary and Non-Degenerate Valuations","url":"https://arxiv.org/abs/1912.00459","date":1751515200,"author":"","guid":182035,"unread":true,"content":"<article>arXiv:1912.00459v3 Announce Type: replace \nAbstract: A set of objects is to be divided fairly among agents with different tastes, modeled by additive utility-functions. If we consider the objects as indivisible, many instances of the decision problem: ``Is there a fair division of the objects among the agents'' are negative. In addition, this question is hard to solve even for most of the special cases. The latter reasons give us a good motivation to relax the problem for which the running time complexity is better, and the number of positive instances (admitting a fair division) will significantly grow. Whereas many works relax the fairness criteria, this paper introduces another relaxation: an agent is allowed to share a \\emph{bounded} number of objects between two or more agents in order to attain fairness. The paper studies various notions of fairness, such as proportionality, envy-freeness, equitability, and consensus. We analyze the run-time complexity of finding a fair allocation with a given number of sharings under several restrictions on the agents' valuations, such as: binary, generalized-binary, and non-degenerate.</article>","contentLength":1144,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Boolean Solution Problem from the Perspective of Predicate Logic -- Extended Version","url":"https://arxiv.org/abs/1706.08329","date":1751515200,"author":"","guid":182036,"unread":true,"content":"<article>arXiv:1706.08329v4 Announce Type: replace \nAbstract: Finding solution values for unknowns in Boolean equations was a principal reasoning mode in the Algebra of Logic of the 19th century. Schr\\\"oder investigated it as Aufl\\\"osungsproblem (solution problem). It is closely related to the modern notion of Boolean unification. Today it is commonly presented in an algebraic setting, but seems potentially useful also in knowledge representation based on predicate logic. We show that it can be modeled on the basis of first-order logic extended by second-order quantification. A wealth of classical results transfers, foundations for algorithms unfold, and connections with second-order quantifier elimination and Craig interpolation become apparent. Although for first-order inputs the set of solutions is recursively enumerable, the development of constructive methods remains a challenge. We identify some cases that allow constructions, most of them based on Craig interpolation.</article>","contentLength":980,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Characterizing control between interacting subsystems with deep Jacobian estimation","url":"https://arxiv.org/abs/2507.01946","date":1751515200,"author":"","guid":182037,"unread":true,"content":"<article>arXiv:2507.01946v1 Announce Type: cross \nAbstract: Biological function arises through the dynamical interactions of multiple subsystems, including those between brain areas, within gene regulatory networks, and more. A common approach to understanding these systems is to model the dynamics of each subsystem and characterize communication between them. An alternative approach is through the lens of control theory: how the subsystems control one another. This approach involves inferring the directionality, strength, and contextual modulation of control between subsystems. However, methods for understanding subsystem control are typically linear and cannot adequately describe the rich contextual effects enabled by nonlinear complex systems. To bridge this gap, we devise a data-driven nonlinear control-theoretic framework to characterize subsystem interactions via the Jacobian of the dynamics. We address the challenge of learning Jacobians from time-series data by proposing the JacobianODE, a deep learning method that leverages properties of the Jacobian to directly estimate it for arbitrary dynamical systems from data alone. We show that JacobianODEs outperform existing Jacobian estimation methods on challenging systems, including high-dimensional chaos. Applying our approach to a multi-area recurrent neural network (RNN) trained on a working memory selection task, we show that the \"sensory\" area gains greater control over the \"cognitive\" area over learning. Furthermore, we leverage the JacobianODE to directly control the trained RNN, enabling precise manipulation of its behavior. Our work lays the foundation for a theoretically grounded and data-driven understanding of interactions among biological subsystems.</article>","contentLength":1737,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars","url":"https://arxiv.org/abs/2507.01939","date":1751515200,"author":"","guid":182038,"unread":true,"content":"<article>arXiv:2507.01939v1 Announce Type: cross \nAbstract: In recent years, large language models (LLMs) have transformed natural language understanding through vast datasets and large-scale parameterization. Inspired by this success, we present SpecCLIP, a foundation model framework that extends LLM-inspired methodologies to stellar spectral analysis. Stellar spectra, akin to structured language, encode rich physical and chemical information about stars. By training foundation models on large-scale spectral datasets, our goal is to learn robust and informative embeddings that support diverse downstream applications. As a proof of concept, SpecCLIP involves pre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed by contrastive alignment using the CLIP (Contrastive Language-Image Pre-training) framework, adapted to associate spectra from different instruments. This alignment is complemented by auxiliary decoders that preserve spectrum-specific information and enable translation (prediction) between spectral types, with the former achieved by maximizing mutual information between embeddings and input spectra. The result is a cross-spectrum framework enabling intrinsic calibration and flexible applications across instruments. We demonstrate that fine-tuning these models on moderate-sized labeled datasets improves adaptability to tasks such as stellar-parameter estimation and chemical-abundance determination. SpecCLIP also enhances the accuracy and precision of parameter estimates benchmarked against external survey data. Additionally, its similarity search and cross-spectrum prediction capabilities offer potential for anomaly detection. Our results suggest that contrastively trained foundation models enriched with spectrum-aware decoders can advance precision stellar spectroscopy.</article>","contentLength":1824,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A first-order method for nonconvex-nonconcave minimax problems under a local Kurdyka-\\L{}ojasiewicz condition","url":"https://arxiv.org/abs/2507.01932","date":1751515200,"author":"","guid":182039,"unread":true,"content":"<article>arXiv:2507.01932v1 Announce Type: cross \nAbstract: We study a class of nonconvex-nonconcave minimax problems in which the inner maximization problem satisfies a local Kurdyka-{\\L}ojasiewicz (KL) condition that may vary with the outer minimization variable. In contrast to the global KL or Polyak-{\\L}ojasiewicz (PL) conditions commonly assumed in the literature -- which are significantly stronger and often too restrictive in practice -- this local KL condition accommodates a broader range of practical scenarios. However, it also introduces new analytical challenges. In particular, as an optimization algorithm progresses toward a stationary point of the problem, the region over which the KL condition holds may shrink, resulting in a more intricate and potentially ill-conditioned landscape. To address this challenge, we show that the associated maximal function is locally H\\\"older smooth. Leveraging this key property, we develop an inexact proximal gradient method for solving the minimax problem, where the inexact gradient of the maximal function is computed by applying a proximal gradient method to a KL-structured subproblem. Under mild assumptions, we establish complexity guarantees for computing an approximate stationary point of the minimax problem.</article>","contentLength":1269,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"End-to-End Large Portfolio Optimization for Variance Minimization with Neural Networks through Covariance Cleaning","url":"https://arxiv.org/abs/2507.01918","date":1751515200,"author":"","guid":182040,"unread":true,"content":"<article>arXiv:2507.01918v1 Announce Type: cross \nAbstract: We develop a rotation-invariant neural network that provides the global minimum-variance portfolio by jointly learning how to lag-transform historical returns and how to regularise both the eigenvalues and the marginal volatilities of large equity covariance matrices. This explicit mathematical mapping offers clear interpretability of each module's role, so the model cannot be regarded as a pure black-box. The architecture mirrors the analytical form of the global minimum-variance solution yet remains agnostic to dimension, so a single model can be calibrated on panels of a few hundred stocks and applied, without retraining, to one thousand US equities-a cross-sectional jump that demonstrates robust out-of-sample generalisation. The loss function is the future realized minimum portfolio variance and is optimized end-to-end on real daily returns. In out-of-sample tests from January 2000 to December 2024 the estimator delivers systematically lower realised volatility, smaller maximum drawdowns, and higher Sharpe ratios than the best analytical competitors, including state-of-the-art non-linear shrinkage. Furthermore, although the model is trained end-to-end to produce an unconstrained (long-short) minimum-variance portfolio, we show that its learned covariance representation can be used in general optimizers under long-only constraints with virtually no loss in its performance advantage over competing estimators. These gains persist when the strategy is executed under a highly realistic implementation framework that models market orders at the auctions, empirical slippage, exchange fees, and financing charges for leverage, and they remain stable during episodes of acute market stress.</article>","contentLength":1762,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advancing Magnetic Materials Discovery -- A structure-based machine learning approach for magnetic ordering and magnetic moment prediction","url":"https://arxiv.org/abs/2507.01913","date":1751515200,"author":"","guid":182041,"unread":true,"content":"<article>arXiv:2507.01913v1 Announce Type: cross \nAbstract: Accurately predicting magnetic behavior across diverse materials systems remains a longstanding challenge due to the complex interplay of structural and electronic factors and is pivotal for the accelerated discovery and design of next-generation magnetic materials. In this work, a refined descriptor is proposed that significantly improves the prediction of two critical magnetic properties -- magnetic ordering (Ferromagnetic vs. Ferrimagnetic) and magnetic moment per atom -- using only the structural information of materials. Unlike previous models limited to Mn-based or lanthanide-transition metal compounds, the present approach generalizes across a diverse dataset of 5741 stable, binary and ternary, ferromagnetic and ferrimagnetic compounds sourced from the Materials Project. Leveraging an enriched elemental vector representation and advanced feature engineering, including nonlinear terms and reduced matrix sparsity, the LightGBM-based model achieves an accuracy of 82.4% for magnetic ordering classification and balanced recall across FM and FiM classes, addressing a key limitation in prior studies. The model predicts magnetic moment per atom with a correlation coefficient of 0.93, surpassing the Hund's matrix and orbital field matrix descriptors. Additionally, it accurately estimates formation energy per atom, enabling assessment of both magnetic behavior and material stability. This generalized and computationally efficient framework offers a robust tool for high-throughput screening of magnetic materials with tailored properties.</article>","contentLength":1610,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Analyzing Common Electronic Structure Theory Algorithms for Distributed Quantum Computing","url":"https://arxiv.org/abs/2507.01902","date":1751515200,"author":"","guid":182042,"unread":true,"content":"<article>arXiv:2507.01902v1 Announce Type: cross \nAbstract: To move towards the utility era of quantum computing, many corporations have posed distributed quantum computing (DQC) as a framework for scaling the current generation of devices for practical applications. One of these applications is quantum chemistry, also known as electronic structure theory, which has been poised as a \"killer application\" of quantum computing, To this end, we analyze five electronic structure methods, found in common packages such as Tequila and ffsim, which can be easily interfaced with the Qiskit Circuit Cutting addon. Herein, we provide insights into cutting these algorithms using local operations (LO) to determine their aptitude for distribution. The key findings of our work are that many of these algorithms cannot be efficiently parallelized using LO, and new methods must be developed to apply electronic structure theory within a DQC framework.</article>","contentLength":935,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"STEM Diffraction Pattern Analysis with Deep Learning Networks","url":"https://arxiv.org/abs/2507.01889","date":1751515200,"author":"","guid":182043,"unread":true,"content":"<article>arXiv:2507.01889v1 Announce Type: cross \nAbstract: Accurate grain orientation mapping is essential for understanding and optimizing the performance of polycrystalline materials, particularly in energy-related applications. Lithium nickel oxide (LiNiO$_{2}$) is a promising cathode material for next-generation lithium-ion batteries, and its electrochemical behaviour is closely linked to microstructural features such as grain size and crystallographic orientations. Traditional orientation mapping methods--such as manual indexing, template matching (TM), or Hough transform-based techniques--are often slow and noise-sensitive when handling complex or overlapping patterns, creating a bottleneck in large-scale microstructural analysis. This work presents a machine learning-based approach for predicting Euler angles directly from scanning transmission electron microscopy (STEM) diffraction patterns (DPs). This enables the automated generation of high-resolution crystal orientation maps, facilitating the analysis of internal microstructures at the nanoscale. Three deep learning architectures--convolutional neural networks (CNNs), Dense Convolutional Networks (DenseNets), and Shifted Windows (Swin) Transformers--are evaluated, using an experimentally acquired dataset labelled via a commercial TM algorithm. While the CNN model serves as a baseline, both DenseNets and Swin Transformers demonstrate superior performance, with the Swin Transformer achieving the highest evaluation scores and the most consistent microstructural predictions. The resulting crystal maps exhibit clear grain boundary delineation and coherent intra-grain orientation distributions, underscoring the potential of attention-based architectures for analyzing diffraction-based image data. These findings highlight the promise of combining advanced machine learning models with STEM data for robust, high-throughput microstructural characterization.</article>","contentLength":1933,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs","url":"https://arxiv.org/abs/2507.01881","date":1751515200,"author":"","guid":182044,"unread":true,"content":"<article>arXiv:2507.01881v1 Announce Type: cross \nAbstract: Low-dose computed tomography (LDCT) imaging employed in lung cancer screening (LCS) programs is increasing in uptake worldwide. LCS programs herald a generational opportunity to simultaneously detect cancer and non-cancer-related early-stage lung disease. Yet these efforts are hampered by a shortage of radiologists to interpret scans at scale. Here, we present TANGERINE, a computationally frugal, open-source vision foundation model for volumetric LDCT analysis. Designed for broad accessibility and rapid adaptation, TANGERINE can be fine-tuned off the shelf for a wide range of disease-specific tasks with limited computational resources and training data. Relative to models trained from scratch, TANGERINE demonstrates fast convergence during fine-tuning, thereby requiring significantly fewer GPU hours, and displays strong label efficiency, achieving comparable or superior performance with a fraction of fine-tuning data. Pretrained using self-supervised learning on over 98,000 thoracic LDCTs, including the UK's largest LCS initiative to date and 27 public datasets, TANGERINE achieves state-of-the-art performance across 14 disease classification tasks, including lung cancer and multiple respiratory diseases, while generalising robustly across diverse clinical centres. By extending a masked autoencoder framework to 3D imaging, TANGERINE offers a scalable solution for LDCT analysis, departing from recent closed, resource-intensive models by combining architectural simplicity, public availability, and modest computational requirements. Its accessible, open-source lightweight design lays the foundation for rapid integration into next-generation medical imaging tools that could transform LCS initiatives, allowing them to pivot from a singular focus on lung cancer detection to comprehensive respiratory disease management in high-risk populations.</article>","contentLength":1919,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A hierarchical invariant for line bundles and its applications in algebraic geometry codes","url":"https://arxiv.org/abs/2507.01859","date":1751515200,"author":"","guid":182045,"unread":true,"content":"<article>arXiv:2507.01859v1 Announce Type: cross \nAbstract: We introduce the notion of hierarchical depth for line bundles on smooth projective surfaces, defined via filtrations by line subbundles with successive quotients supported on effective divisors. This invariant helps to investigate both the algebraic and geometric complexity of line bundles through discrete stepwise constructions. We study some of its basic properties, including functorial behavior under restriction to curves and compatibility with ampleness and base-point freeness. Applying this framework to algebraic geometry (AG) codes, we show that hierarchical filtrations yield natural code families whose combinatorial parameters (dimension, minimum distance) evolve predictably across the filtration.</article>","contentLength":765,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Autoadaptive Medical Segment Anything Model","url":"https://arxiv.org/abs/2507.01828","date":1751515200,"author":"","guid":182046,"unread":true,"content":"<article>arXiv:2507.01828v1 Announce Type: cross \nAbstract: Medical image segmentation is a key task in the imaging workflow, influencing many image-based decisions. Traditional, fully-supervised segmentation models rely on large amounts of labeled training data, typically obtained through manual annotation, which can be an expensive, time-consuming, and error-prone process. This signals a need for accurate, automatic, and annotation-efficient methods of training these models. We propose ADA-SAM (automated, domain-specific, and adaptive segment anything model), a novel multitask learning framework for medical image segmentation that leverages class activation maps from an auxiliary classifier to guide the predictions of the semi-supervised segmentation branch, which is based on the Segment Anything (SAM) framework. Additionally, our ADA-SAM model employs a novel gradient feedback mechanism to create a learnable connection between the segmentation and classification branches by using the segmentation gradients to guide and improve the classification predictions. We validate ADA-SAM on real-world clinical data collected during rehabilitation trials, and demonstrate that our proposed method outperforms both fully-supervised and semi-supervised baselines by double digits in limited label settings. Our code is available at: https://github.com/tbwa233/ADA-SAM.</article>","contentLength":1367,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Low-Complexity Neural Wind Noise Reduction for Audio Recordings","url":"https://arxiv.org/abs/2507.01821","date":1751515200,"author":"","guid":182047,"unread":true,"content":"<article>arXiv:2507.01821v1 Announce Type: cross \nAbstract: Wind noise significantly degrades the quality of outdoor audio recordings, yet remains difficult to suppress in real-time on resource-constrained devices. In this work, we propose a low-complexity single-channel deep neural network that leverages the spectral characteristics of wind noise. Experimental results show that our method achieves performance comparable to the state-of-the-art low-complexity ULCNet model. The proposed model, with only 249K parameters and roughly 73 MHz of computational power, is suitable for embedded and mobile audio applications.</article>","contentLength":613,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Robust brain age estimation from structural MRI with contrastive learning","url":"https://arxiv.org/abs/2507.01794","date":1751515200,"author":"","guid":182048,"unread":true,"content":"<article>arXiv:2507.01794v1 Announce Type: cross \nAbstract: Estimating brain age from structural MRI has emerged as a powerful tool for characterizing normative and pathological aging. In this work, we explore contrastive learning as a scalable and robust alternative to supervised approaches for brain age estimation. We introduce a novel contrastive loss function, $\\mathcal{L}^{exp}$, and evaluate it across multiple public neuroimaging datasets comprising over 20,000 scans. Our experiments reveal four key findings. First, scaling pre-training on diverse, multi-site data consistently improves generalization performance, cutting external mean absolute error (MAE) nearly in half. Second, $\\mathcal{L}^{exp}$ is robust to site-related confounds, maintaining low scanner-predictability as training size increases. Third, contrastive models reliably capture accelerated aging in patients with cognitive impairment and Alzheimer's disease, as shown through brain age gap analysis, ROC curves, and longitudinal trends. Lastly, unlike supervised baselines, $\\mathcal{L}^{exp}$ maintains a strong correlation between brain age accuracy and downstream diagnostic performance, supporting its potential as a foundation model for neuroimaging. These results position contrastive learning as a promising direction for building generalizable and clinically meaningful brain representations.</article>","contentLength":1374,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Generalizable Detection of Audio Deepfakes","url":"https://arxiv.org/abs/2507.01750","date":1751515200,"author":"","guid":182049,"unread":true,"content":"<article>arXiv:2507.01750v1 Announce Type: cross \nAbstract: In this paper, we present our comprehensive study aimed at enhancing the generalization capabilities of audio deepfake detection models. We investigate the performance of various pre-trained backbones, including Wav2Vec2, WavLM, and Whisper, across a diverse set of datasets, including those from the ASVspoof challenges and additional sources. Our experiments focus on the effects of different data augmentation strategies and loss functions on model performance. The results of our research demonstrate substantial enhancements in the generalization capabilities of audio deepfake detection models, surpassing the performance of the top-ranked single system in the ASVspoof 5 Challenge. This study contributes valuable insights into the optimization of audio models for more robust deepfake detection and facilitates future research in this critical area.</article>","contentLength":908,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Token Communication in the Era of Large Models: An Information Bottleneck-Based Approach","url":"https://arxiv.org/abs/2507.01728","date":1751515200,"author":"","guid":182050,"unread":true,"content":"<article>arXiv:2507.01728v1 Announce Type: cross \nAbstract: This letter proposes UniToCom, a unified token communication paradigm that treats tokens as the fundamental units for both processing and wireless transmission. Specifically, to enable efficient token representations, we propose a generative information bottleneck (GenIB) principle, which facilitates the learning of tokens that preserve essential information while supporting reliable generation across multiple modalities. By doing this, GenIB-based tokenization is conducive to improving the communication efficiency and reducing computational complexity. Additionally, we develop $\\sigma$-GenIB to address the challenges of variance collapse in autoregressive modeling, maintaining representational diversity and stability. Moreover, we employ a causal Transformer-based multimodal large language model (MLLM) at the receiver to unify the processing of both discrete and continuous tokens under the next-token prediction paradigm. Simulation results validate the effectiveness and superiority of the proposed UniToCom compared to baselines under dynamic channel conditions. By integrating token processing with MLLMs, UniToCom enables scalable and generalizable communication in favor of multimodal understanding and generation, providing a potential solution for next-generation intelligent communications.</article>","contentLength":1363,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A generative modeling / Physics-Informed Neural Network approach to random differential equations","url":"https://arxiv.org/abs/2507.01687","date":1751515200,"author":"","guid":182051,"unread":true,"content":"<article>arXiv:2507.01687v1 Announce Type: cross \nAbstract: The integration of Scientific Machine Learning (SciML) techniques with uncertainty quantification (UQ) represents a rapidly evolving frontier in computational science. This work advances Physics-Informed Neural Networks (PINNs) by incorporating probabilistic frameworks to effectively model uncertainty in complex systems. Our approach enhances the representation of uncertainty in forward problems by combining generative modeling techniques with PINNs. This integration enables in a systematic fashion uncertainty control while maintaining the predictive accuracy of the model. We demonstrate the utility of this method through applications to random differential equations and random partial differential equations (PDEs).</article>","contentLength":776,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Enriching the Felsenthal index with a priori unions for decision-making processes","url":"https://arxiv.org/abs/2507.01621","date":1751515200,"author":"","guid":182052,"unread":true,"content":"<article>arXiv:2507.01621v1 Announce Type: cross \nAbstract: Within the domain of game theory, power indexes are defined as functions that quantify the influence of individual participants in collective decision-making processes. Felsenthal [D. Felsenthal. A Well-Behaved Index of a Priori P-Power for Simple N-Person Games. Homo Oeconomicus, 33, 2016] proposed a power index with a focus on least size winning coalitions, i.e., those coalitions capable of determining the final outcome and with the smallest number of players among all winning coalitions. However, the Felsenthal index overlooks pre-existing affinities between the players, a common and impactful factor in real-world political and economic contexts. This paper introduces the Felsenthal Owen power index, a novel index based on Felsenthal's approach that integrates player affinities using Owen's a priori unions framework. The new index is rigorously characterised by two distinct sets of axiomatic properties. We demonstrate its practical utility by applying it to the International Monetary Fund's voting system, revealing how strategic alliances significantly reshape power distributions. The index thus offers policymakers a more sophisticated tool for measuring influence in complex decision-making scenarios.</article>","contentLength":1274,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"When Less Is More: Binary Feedback Can Outperform Ordinal Comparisons in Ranking Recovery","url":"https://arxiv.org/abs/2507.01613","date":1751515200,"author":"","guid":182053,"unread":true,"content":"<article>arXiv:2507.01613v1 Announce Type: cross \nAbstract: Paired comparison data, where users evaluate items in pairs, play a central role in ranking and preference learning tasks. While ordinal comparison data intuitively offer richer information than binary comparisons, this paper challenges that conventional wisdom. We propose a general parametric framework for modeling ordinal paired comparisons without ties. The model adopts a generalized additive structure, featuring a link function that quantifies the preference difference between two items and a pattern function that governs the distribution over ordinal response levels. This framework encompasses classical binary comparison models as special cases, by treating binary responses as binarized versions of ordinal data. Within this framework, we show that binarizing ordinal data can significantly improve the accuracy of ranking recovery. Specifically, we prove that under the counting algorithm, the ranking error associated with binary comparisons exhibits a faster exponential convergence rate than that of ordinal data. Furthermore, we characterize a substantial performance gap between binary and ordinal data in terms of a signal-to-noise ratio (SNR) determined by the pattern function. We identify the pattern function that minimizes the SNR and maximizes the benefit of binarization. Extensive simulations and a real application on the MovieLens dataset further corroborate our theoretical findings.</article>","contentLength":1466,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"QHARMA-GAN: Quasi-Harmonic Neural Vocoder based on Autoregressive Moving Average Model","url":"https://arxiv.org/abs/2507.01611","date":1751515200,"author":"","guid":182054,"unread":true,"content":"<article>arXiv:2507.01611v1 Announce Type: cross \nAbstract: Vocoders, encoding speech signals into acoustic features and allowing for speech signal reconstruction from them, have been studied for decades. Recently, the rise of deep learning has particularly driven the development of neural vocoders to generate high-quality speech signals. On the other hand, the existing end-to-end neural vocoders suffer from a black-box nature that blinds the speech production mechanism and the intrinsic structure of speech, resulting in the ambiguity of separately modeling source excitation and resonance characteristics and the loss of flexibly synthesizing or modifying speech with high quality. Moreover, their sequence-wise waveform generation usually requires complicated networks, leading to substantial time consumption. In this work, inspired by the quasi-harmonic model (QHM) that represents speech as sparse components, we combine the neural network and QHM synthesis process to propose a novel framework for the neural vocoder. Accordingly, speech signals can be encoded into autoregressive moving average (ARMA) functions to model the resonance characteristics, yielding accurate estimates of the amplitudes and phases of quasi-harmonics at any frequency. Subsequently, the speech can be resynthesized and arbitrarily modified in terms of pitch shifting and time stretching with high quality, whereas the time consumption and network size decrease. The experiments indicate that the proposed method leverages the strengths of QHM, the ARMA model, and neural networks, leading to the outperformance of our methods over other methods in terms of generation speed, synthesis quality, and modification flexibility.</article>","contentLength":1704,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Transfer Learning for VLC-based indoor Localization: Addressing Environmental Variability","url":"https://arxiv.org/abs/2507.01575","date":1751515200,"author":"","guid":182055,"unread":true,"content":"<article>arXiv:2507.01575v1 Announce Type: cross \nAbstract: Accurate indoor localization is crucial in industrial environments. Visible Light Communication (VLC) has emerged as a promising solution, offering high accuracy, energy efficiency, and minimal electromagnetic interference. However, VLC-based indoor localization faces challenges due to environmental variability, such as lighting fluctuations and obstacles. To address these challenges, we propose a Transfer Learning (TL)-based approach for VLC-based indoor localization. Using real-world data collected at a BOSCH factory, the TL framework integrates a deep neural network (DNN) to improve localization accuracy by 47\\%, reduce energy consumption by 32\\%, and decrease computational time by 40\\% compared to the conventional models. The proposed solution is highly adaptable under varying environmental conditions and achieves similar accuracy with only 30\\% of the dataset, making it a cost-efficient and scalable option for industrial applications in Industry 4.0.</article>","contentLength":1020,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Multipacking in Hypercubes","url":"https://arxiv.org/abs/2507.01565","date":1751515200,"author":"","guid":182056,"unread":true,"content":"<article>arXiv:2507.01565v1 Announce Type: cross \nAbstract: For an undirected graph $G$, a dominating broadcast on $G$ is a function $f : V(G) \\rightarrow \\mathbb{N}$ such that for any vertex $u \\in V(G)$, there exists a vertex $v \\in V(G)$ with $f(v) \\geqslant 1$ and $d(u,v) \\leqslant f(v)$. The cost of $f$ is $\\sum_{v \\in V} f(v)$. The minimum cost over all the dominating broadcasts on $G$ is defined as the broadcast domination number $\\gamma_b(G)$ of $G$. A multipacking in $G$ is a subset $M \\subseteq V(G)$ such that, for every vertex $v \\in V(G)$ and every positive integer $r$, the number of vertices in $M$ within distance $r$ of $v$ is at most $r$. The multipacking number of $G$, denoted $\\operatorname{mp}(G)$, is the maximum cardinality of a multipacking in $G$. These two optimisation problems are duals of each other, and it easily follows that $\\operatorname{mp}(G) \\leqslant \\gamma_b(G)$. It is known that $\\gamma_b(G) \\leqslant 2\\operatorname{mp}(G)+3$ and conjectured that $\\gamma_b(G) \\leqslant 2\\operatorname{mp}(G)$.\n  In this paper, we show that for the $n$-dimensional hypercube $Q_n$ $$ \\left\\lfloor\\frac{n}{2} \\right\\rfloor\n  \\leqslant \\operatorname{mp}(Q_n)\n  \\leqslant \\frac{n}{2} + 6\\sqrt{2n}. $$\n  Since $\\gamma_b(Q_n) = n-1$ for all $n \\geqslant 3$, this verifies the above conjecture on hypercubes and, more interestingly, gives a sequence of connected graphs for which the ratio $\\frac{\\gamma_b(G)}{\\operatorname{mp}(G)}$ approaches $2$, a search for which was initiated by Beaudou, Brewster and Foucaud in 2018. It follows that, for connected graphs $G$ $$\n  \\limsup_{\\operatorname{mp}(G) \\rightarrow \\infty} \\left\\{\\frac{\\gamma_b(G)}{\\operatorname{mp}(G)}\\right\\} = 2.$$\n  The lower bound on $\\operatorname{mp}(Q_n)$ is established by a recursive construction, and the upper bound is established using a classic result from discrepancy theory.</article>","contentLength":1872,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Multi Source COVID-19 Detection via Kernel-Density-based Slice Sampling","url":"https://arxiv.org/abs/2507.01564","date":1751515200,"author":"","guid":182057,"unread":true,"content":"<article>arXiv:2507.01564v1 Announce Type: cross \nAbstract: We present our solution for the Multi-Source COVID-19 Detection Challenge, which classifies chest CT scans from four distinct medical centers. To address multi-source variability, we employ the Spatial-Slice Feature Learning (SSFL) framework with Kernel-Density-based Slice Sampling (KDS). Our preprocessing pipeline combines lung region extraction, quality control, and adaptive slice sampling to select eight representative slices per scan. We compare EfficientNet and Swin Transformer architectures on the validation set. The EfficientNet model achieves an F1-score of 94.68%, compared to the Swin Transformer's 93.34%. The results demonstrate the effectiveness of our KDS-based pipeline on multi-source data and highlight the importance of dataset balance in multi-institutional medical imaging evaluation.</article>","contentLength":861,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Approximate Solution Methods for the Average Reward Criterion in Optimal Tracking Control of Linear Systems","url":"https://arxiv.org/abs/2507.01556","date":1751515200,"author":"","guid":182058,"unread":true,"content":"<article>arXiv:2507.01556v1 Announce Type: cross \nAbstract: This paper studies optimal control under the average-reward/cost criterion for deterministic linear systems. We derive the value function and optimal policy, and propose an approximate solution using Model Predictive Control to enable practical implementation.</article>","contentLength":311,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Parsimonious Gaussian mixture models with piecewise-constant eigenvalue profiles","url":"https://arxiv.org/abs/2507.01542","date":1751515200,"author":"","guid":182059,"unread":true,"content":"<article>arXiv:2507.01542v1 Announce Type: cross \nAbstract: Gaussian mixture models (GMMs) are ubiquitous in statistical learning, particularly for unsupervised problems. While full GMMs suffer from the overparameterization of their covariance matrices in high-dimensional spaces, spherical GMMs (with isotropic covariance matrices) certainly lack flexibility to fit certain anisotropic distributions. Connecting these two extremes, we introduce a new family of parsimonious GMMs with piecewise-constant covariance eigenvalue profiles. These extend several low-rank models like the celebrated mixtures of probabilistic principal component analyzers (MPPCA), by enabling any possible sequence of eigenvalue multiplicities. If the latter are prespecified, then we can naturally derive an expectation-maximization (EM) algorithm to learn the mixture parameters. Otherwise, to address the notoriously-challenging issue of jointly learning the mixture parameters and hyperparameters, we propose a componentwise penalized EM algorithm, whose monotonicity is proven. We show the superior likelihood-parsimony tradeoffs achieved by our models on a variety of unsupervised experiments: density fitting, clustering and single-image denoising.</article>","contentLength":1223,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Modeling individual attention dynamics on online social media","url":"https://arxiv.org/abs/2507.01511","date":1751515200,"author":"","guid":182060,"unread":true,"content":"<article>arXiv:2507.01511v1 Announce Type: cross \nAbstract: In the attention economy, understanding how individuals manage limited attention is critical. We introduce a simple model describing the decay of a user's engagement when facing multiple inputs. We analytically show that individual attention decay is determined by the overall duration of interactions, not their number or user activity. Our model is validated using data from Reddit's Change My View subreddit, where the user's attention dynamics is explicitly traceable. Despite its simplicity, our model offers a crucial microscopic perspective complementing macroscopic studies.</article>","contentLength":633,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meteoroid stream identification with HDBSCAN unsupervised clustering algorithm","url":"https://arxiv.org/abs/2507.01501","date":1751515200,"author":"","guid":182061,"unread":true,"content":"<article>arXiv:2507.01501v1 Announce Type: cross \nAbstract: Accurate identification of meteoroid streams is central to understanding their origins and evolution. However, overlapping clusters and background noise hinder classification, an issue amplified for missions such as ESA's LUMIO that rely on meteor shower observations to infer lunar meteoroid impact parameters. This study evaluates the performance of the Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) algorithm for unsupervised meteoroid stream identification, comparing its outcomes with the established Cameras for All-Sky Meteor Surveillance (CAMS) look-up table method. We analyze the CAMS Meteoroid Orbit Database v3.0 using three feature vectors: LUTAB (CAMS geocentric parameters), ORBIT (heliocentric orbital elements), and GEO (adapted geocentric parameters). HDBSCAN is applied with varying minimum cluster sizes and two cluster selection methods (eom and leaf). To align HDBSCAN clusters with CAMS classifications, the Hungarian algorithm determines the optimal mapping. Clustering performance is assessed via the Silhouette score, Normalized Mutual Information, and F1 score, with Principal Component Analysis further supporting the analysis. With the GEO vector, HDBSCAN confirms 39 meteoroid streams, 21 strongly aligning with CAMS. The ORBIT vector identifies 30 streams, 13 with high matching scores. Less active showers pose identification challenges. The eom method consistently yields superior performance and agreement with CAMS. Although HDBSCAN requires careful selection of the minimum cluster size, it delivers robust, internally consistent clusters and outperforms the look-up table method in statistical coherence. These results underscore HDBSCAN's potential as a mathematically consistent alternative for meteoroid stream identification, although further validation is needed to assess physical validity.</article>","contentLength":1921,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Epistemic Scarcity: The Economics of Unresolvable Unknowns","url":"https://arxiv.org/abs/2507.01483","date":1751515200,"author":"","guid":182062,"unread":true,"content":"<article>arXiv:2507.01483v1 Announce Type: cross \nAbstract: This paper presents a praxeological analysis of artificial intelligence and algorithmic governance, challenging assumptions about the capacity of machine systems to sustain economic and epistemic order. Drawing on Misesian a priori reasoning and Austrian theories of entrepreneurship, we argue that AI systems are incapable of performing the core functions of economic coordination: interpreting ends, discovering means, and communicating subjective value through prices. Where neoclassical and behavioural models treat decisions as optimisation under constraint, we frame them as purposive actions under uncertainty.\n  We critique dominant ethical AI frameworks such as Fairness, Accountability, and Transparency (FAT) as extensions of constructivist rationalism, which conflict with a liberal order grounded in voluntary action and property rights. Attempts to encode moral reasoning in algorithms reflect a misunderstanding of ethics and economics. However complex, AI systems cannot originate norms, interpret institutions, or bear responsibility. They remain opaque, misaligned, and inert.\n  Using the concept of epistemic scarcity, we explore how information abundance degrades truth discernment, enabling both entrepreneurial insight and soft totalitarianism. Our analysis ends with a civilisational claim: the debate over AI concerns the future of human autonomy, institutional evolution, and reasoned choice. The Austrian tradition, focused on action, subjectivity, and spontaneous order, offers the only coherent alternative to rising computational social control.</article>","contentLength":1625,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mapping the interaction between science and misinformation in COVID-19 tweets","url":"https://arxiv.org/abs/2507.01481","date":1751515200,"author":"","guid":182063,"unread":true,"content":"<article>arXiv:2507.01481v1 Announce Type: cross \nAbstract: During the COVID-19 pandemic, scientific understanding related to the topic evolved rapidly. Along with scientific information being discussed widely, a large circulation of false information, labelled an infodemic by the WHO, emerged. Here, we study the interaction between misinformation and science on Twitter (now X) during the COVID-19 pandemic. We built a comprehensive database of $\\sim$407M COVID-19 related tweets and classified the reliability of URLs in the tweets based on Media Bias/Fact Check. In addition, we use Altmetric data to see whether a tweet refers to a scientific publication. We find that many users find that many users share both scientific and unreliable content; out of the $\\sim$1.2M users who share science, $45\\%$ also share unreliable content. Publications that are more frequently shared by users who also share unreliable content are more likely to be preprints, slightly more often retracted, have fewer citations, and are published in lower-impact journals on average. Our findings suggest that misinformation is not related to a ``deficit'' of science. In addition, our findings raise some critical questions about certain open science practices and their potential for misuse. Given the fundamental opposition between science and misinformation, our findings highlight the necessity for proactive scientific engagement on social media platforms to counter false narratives during global crises.</article>","contentLength":1485,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Symbolic identification of tensor equations in multidimensional physical fields","url":"https://arxiv.org/abs/2507.01466","date":1751515200,"author":"","guid":182064,"unread":true,"content":"<article>arXiv:2507.01466v1 Announce Type: cross \nAbstract: Recently, data-driven methods have shown great promise for discovering governing equations from simulation or experimental data. However, most existing approaches are limited to scalar equations, with few capable of identifying tensor relationships. In this work, we propose a general data-driven framework for identifying tensor equations, referred to as Symbolic Identification of Tensor Equations (SITE). The core idea of SITE--representing tensor equations using a host-plasmid structure--is inspired by the multidimensional gene expression programming (M-GEP) approach. To improve the robustness of the evolutionary process, SITE adopts a genetic information retention strategy. Moreover, SITE introduces two key innovations beyond conventional evolutionary algorithms. First, it incorporates a dimensional homogeneity check to restrict the search space and eliminate physically invalid expressions. Second, it replaces traditional linear scaling with a tensor linear regression technique, greatly enhancing the efficiency of numerical coefficient optimization. We validate SITE using two benchmark scenarios, where it accurately recovers target equations from synthetic data, showing robustness to noise and small sample sizes. Furthermore, SITE is applied to identify constitutive relations directly from molecular simulation data, which are generated without reliance on macroscopic constitutive models. It adapts to both compressible and incompressible flow conditions and successfully identifies the corresponding macroscopic forms, highlighting its potential for data-driven discovery of tensor equation.</article>","contentLength":1666,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reduced Efficiency in the Right Fronto-Parietal Attentional Network During Distractor Suppression in Mild Cognitive Impairment","url":"https://arxiv.org/abs/2507.01433","date":1751515200,"author":"","guid":182065,"unread":true,"content":"<article>arXiv:2507.01433v1 Announce Type: cross \nAbstract: Mild Cognitive Impairment (MCI) is a critical transitional stage between normal cognitive aging and dementia, making its early detection essential. This study investigates the neural mechanisms of distractor suppression in MCI patients using EEG and behavioral data during an attention-cueing Eriksen flanker task. A cohort of 56 MCIs and 26 healthy controls (HCs) performed tasks with congruent and incongruent stimuli of varying saliency levels. During these tasks, EEG data were analyzed for alpha band coherence's functional connectivity, focusing on Global Efficiency (GE), while Reaction Time (RT) and Hit Rate (HR) were also collected.\n  Our findings reveal significant interactions between congruency, saliency, and cognitive status on GE, RT, and HR. In HCs, congruent conditions resulted in higher GE (p = 0.0114, multivariate t-distribution correction, MVT), faster RTs (p &lt; 0.0001, MVT), and higher HRs (p &lt; 0.0001, MVT) compared to incongruent conditions. HCs also showed increased GE in salient conditions for incongruent trials (p = 0.0406, MVT). MCIs exhibited benefits from congruent conditions with shorter RTs and higher HRs (both p &lt; 0.0001, MVT) compared to incongruent conditions but showed reduced adaptability in GE, with no significant GE differences between conditions.\n  These results highlight the potential of alpha band coherence and GE as early markers for cognitive impairment. By integrating GE, RT, and HR, this study provides insights into the interplay between neural efficiency, processing speed, and task accuracy. This approach offers valuable insights into cognitive load management and interference effects, indicating benefits for interventions aimed at improving attentional control and processing speed in MCIs.</article>","contentLength":1806,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Randomized subspace correction methods for convex optimization","url":"https://arxiv.org/abs/2507.01415","date":1751515200,"author":"","guid":182066,"unread":true,"content":"<article>arXiv:2507.01415v1 Announce Type: cross \nAbstract: This paper introduces an abstract framework for randomized subspace correction methods for convex optimization, which unifies and generalizes a broad class of existing algorithms, including domain decomposition, multigrid, and block coordinate descent methods. We provide a convergence rate analysis ranging from minimal assumptions to more practical settings, such as sharpness and strong convexity. While most existing studies on block coordinate descent methods focus on nonoverlapping decompositions and smooth or strongly convex problems, our framework extends to more general settings involving arbitrary space decompositions, inexact local solvers, and problems with limited smoothness or convexity. The proposed framework is broadly applicable to convex optimization problems arising in areas such as nonlinear partial differential equations, imaging, and data science.</article>","contentLength":928,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Age Sensitive Hippocampal Functional Connectivity: New Insights from 3D CNNs and Saliency Mapping","url":"https://arxiv.org/abs/2507.01411","date":1751515200,"author":"","guid":182067,"unread":true,"content":"<article>arXiv:2507.01411v1 Announce Type: cross \nAbstract: Grey matter loss in the hippocampus is a hallmark of neurobiological aging, yet understanding the corresponding changes in its functional connectivity remains limited. Seed-based functional connectivity (FC) analysis enables voxel-wise mapping of the hippocampus's synchronous activity with cortical regions, offering a window into functional reorganization during aging. In this study, we develop an interpretable deep learning framework to predict brain age from hippocampal FC using a three-dimensional convolutional neural network (3D CNN) combined with LayerCAM saliency mapping. This approach maps key hippocampal-cortical connections, particularly with the precuneus, cuneus, posterior cingulate cortex, parahippocampal cortex, left superior parietal lobule, and right superior temporal sulcus, that are highly sensitive to age. Critically, disaggregating anterior and posterior hippocampal FC reveals distinct mapping aligned with their known functional specializations. These findings provide new insights into the functional mechanisms of hippocampal aging and demonstrate the power of explainable deep learning to uncover biologically meaningful patterns in neuroimaging data.</article>","contentLength":1238,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reconstruction of the observable universe from the integrated Sachs-Wolfe effect","url":"https://arxiv.org/abs/2507.01399","date":1751515200,"author":"","guid":182068,"unread":true,"content":"<article>arXiv:2507.01399v1 Announce Type: cross \nAbstract: The integrated Sachs-Wolfe (ISW) effect is a property of the Cosmic Microwave Background (CMB), in which photons from the CMB are gravitationally redshifted, causing the anisotropies in the CMB. An intriguing question is whether one can infer the gravitational perturbations from the ISW effect observed near the Earth. In this work, we address the question using a tomographic reconstruction approach, similar to X-ray CT reconstruction in medical imaging. We develop the mathematical analysis for the stable inversion of the X-ray transform in the cosmological setting. In addition, we provide a numerical study of reconstruction methods, thereby demonstrating the feasibility and potential of the tomography method.</article>","contentLength":769,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy","url":"https://arxiv.org/abs/2507.01387","date":1751515200,"author":"","guid":182069,"unread":true,"content":"<article>arXiv:2507.01387v1 Announce Type: cross \nAbstract: The limited availability of bronchoscopy images makes image synthesis particularly interesting for training deep learning models. Robust image translation across different domains -- virtual bronchoscopy, phantom as well as in-vivo and ex-vivo image data -- is pivotal for clinical applications. This paper proposes BronchoGAN introducing anatomical constraints for image-to-image translation being integrated into a conditional GAN. In particular, we force bronchial orifices to match across input and output images. We further propose to use foundation model-generated depth images as intermediate representation ensuring robustness across a variety of input domains establishing models with substantially less reliance on individual training datasets. Moreover our intermediate depth image representation allows to easily construct paired image data for training. Our experiments showed that input images from different domains (e.g. virtual bronchoscopy, phantoms) can be successfully translated to images mimicking realistic human airway appearance. We demonstrated that anatomical settings (i.e. bronchial orifices) can be robustly preserved with our approach which is shown qualitatively and quantitatively by means of improved FID, SSIM and dice coefficients scores. Our anatomical constraints enabled an improvement in the Dice coefficient of up to 0.43 for synthetic images. Through foundation models for intermediate depth representations, bronchial orifice segmentation integrated as anatomical constraints into conditional GANs we are able to robustly translate images from different bronchoscopy input domains. BronchoGAN allows to incorporate public CT scan data (virtual bronchoscopy) in order to generate large-scale bronchoscopy image datasets with realistic appearance. BronchoGAN enables to bridge the gap of missing public bronchoscopy images.</article>","contentLength":1915,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Inequalities in Fourier analysis on binary cubes","url":"https://arxiv.org/abs/2507.01359","date":1751515200,"author":"","guid":182070,"unread":true,"content":"<article>arXiv:2507.01359v1 Announce Type: cross \nAbstract: This paper studies two classical inequalities, namely the Hausdorff-Young inequality and equal-exponent Young's convolution inequality, for discrete functions supported in the binary cube $\\{0,1\\}^d\\subset\\mathbb{Z}^d$. We characterize the exact ranges of Lebesgue exponents in which sharp versions of these two inequalities hold, and present several immediate consequences. First, if the functions are specialized to be the indicator of some set $A\\subseteq\\{0,1\\}^d$, then we obtain sharp upper bounds on two types of generalized additive energies of $A$, extending the works of Kane-Tao, de Dios Pont-Greenfeld-Ivanisvili-Madrid, and one of the present authors. Second, we obtain a sharp binary variant of the Beckner-Hirschman entropic uncertainty principle, as well as a sharp lower estimate on the entropy of a sum of two independent random variables with values in $\\{0,1\\}^d$. Finally, the sharp binary Hausdorff-Young inequality also reveals the exact range of dimension-free estimates for the Fourier restriction to the binary cube.</article>","contentLength":1093,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Voice Conversion for Likability Control via Automated Rating of Speech Synthesis Corpora","url":"https://arxiv.org/abs/2507.01356","date":1751515200,"author":"","guid":182071,"unread":true,"content":"<article>arXiv:2507.01356v1 Announce Type: cross \nAbstract: Perceived voice likability plays a crucial role in various social interactions, such as partner selection and advertising. A system that provides reference likable voice samples tailored to target audiences would enable users to adjust their speaking style and voice quality, facilitating smoother communication. To this end, we propose a voice conversion method that controls the likability of input speech while preserving both speaker identity and linguistic content. To improve training data scalability, we train a likability predictor on an existing voice likability dataset and employ it to automatically annotate a large speech synthesis corpus with likability ratings. Experimental evaluations reveal a significant correlation between the predictor's outputs and human-provided likability ratings. Subjective and objective evaluations further demonstrate that the proposed approach effectively controls voice likability while preserving both speaker identity and linguistic content.</article>","contentLength":1042,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"IdolSongsJp Corpus: A Multi-Singer Song Corpus in the Style of Japanese Idol Groups","url":"https://arxiv.org/abs/2507.01349","date":1751515200,"author":"","guid":182072,"unread":true,"content":"<article>arXiv:2507.01349v1 Announce Type: cross \nAbstract: Japanese idol groups, comprising performers known as \"idols,\" are an indispensable part of Japanese pop culture. They frequently appear in live concerts and television programs, entertaining audiences with their singing and dancing. Similar to other J-pop songs, idol group music covers a wide range of styles, with various types of chord progressions and instrumental arrangements. These tracks often feature numerous instruments and employ complex mastering techniques, resulting in high signal loudness. Additionally, most songs include a song division (utawari) structure, in which members alternate between singing solos and performing together. Hence, these songs are well-suited for benchmarking various music information processing techniques such as singer diarization, music source separation, and automatic chord estimation under challenging conditions. Focusing on these characteristics, we constructed a song corpus titled IdolSongsJp by commissioning professional composers to create 15 tracks in the style of Japanese idol groups. This corpus includes not only mastered audio tracks but also stems for music source separation, dry vocal tracks, and chord annotations. This paper provides a detailed description of the corpus, demonstrates its diversity through comparisons with real-world idol group songs, and presents its application in evaluating several music information processing techniques.</article>","contentLength":1464,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SpeechAccentLLM: A Unified Framework for Foreign Accent Conversion and Text to Speech","url":"https://arxiv.org/abs/2507.01348","date":1751515200,"author":"","guid":182073,"unread":true,"content":"<article>arXiv:2507.01348v1 Announce Type: cross \nAbstract: Foreign accent conversion (FAC) in speech processing remains a challenging task. Building on the remarkable success of large language models (LLMs) in Text-to-Speech (TTS) tasks, this study investigates the adaptation of LLM-based techniques for FAC, which we term SpeechAccentLLM. At the core of this framework, we introduce SpeechCodeVAE, the first model to integrate connectionist temporal classification (CTC) directly into codebook discretization for speech content tokenization. This novel architecture generates tokens with a unique \"locality\" property, as validated by experiments demonstrating optimal trade-offs among content faithfulness, temporal coherence, and structural recoverability. Then, to address data scarcity for the FAC module, we adopted a multitask learning strategy that jointly trains the FAC and TTS modules. Beyond mitigating data limitations, this approach yielded accelerated convergence and superior speech quality compared to standalone FAC training. Moreover, leveraging the salient properties of our discrete speech representations, we introduce SpeechRestorer, a postprocessing architecture designed to refine LLM-generated outputs. This module effectively mitigates stochastic errors prevalent in LLM inference pipelines while enhancing prosodic continuity, as validated by ablation experiments.</article>","contentLength":1384,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Structure and Smoothness Constrained Dual Networks for MR Bias Field Correction","url":"https://arxiv.org/abs/2507.01326","date":1751515200,"author":"","guid":182074,"unread":true,"content":"<article>arXiv:2507.01326v1 Announce Type: cross \nAbstract: MR imaging techniques are of great benefit to disease diagnosis. However, due to the limitation of MR devices, significant intensity inhomogeneity often exists in imaging results, which impedes both qualitative and quantitative medical analysis. Recently, several unsupervised deep learning-based models have been proposed for MR image improvement. However, these models merely concentrate on global appearance learning, and neglect constraints from image structures and smoothness of bias field, leading to distorted corrected results. In this paper, novel structure and smoothness constrained dual networks, named S2DNets, are proposed aiming to self-supervised bias field correction. S2DNets introduce piece-wise structural constraints and smoothness of bias field for network training to effectively remove non-uniform intensity and retain much more structural details. Extensive experiments executed on both clinical and simulated MR datasets show that the proposed model outperforms other conventional and deep learning-based models. In addition to comparison on visual metrics, downstream MR image segmentation tasks are also used to evaluate the impact of the proposed model. The source code is available at: https://github.com/LeongDong/S2DNets}{https://github.com/LeongDong/S2DNets.</article>","contentLength":1343,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An Error Bound for Aggregation in Approximate Dynamic Programming","url":"https://arxiv.org/abs/2507.01324","date":1751515200,"author":"","guid":182075,"unread":true,"content":"<article>arXiv:2507.01324v1 Announce Type: cross \nAbstract: We consider a general aggregation framework for discounted finite-state infinite horizon dynamic programming (DP) problems. It defines an aggregate problem whose optimal cost function can be obtained off-line by exact DP and then used as a terminal cost approximation for an on-line reinforcement learning (RL) scheme. We derive a bound on the error between the optimal cost functions of the aggregate problem and the original problem. This bound was first derived by Tsitsiklis and van Roy [TvR96] for the special case of hard aggregation. Our bound is similar but applies far more broadly, including to soft aggregation and feature-based aggregation schemes.</article>","contentLength":711,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SWinMamba: Serpentine Window State Space Model for Vascular Segmentation","url":"https://arxiv.org/abs/2507.01323","date":1751515200,"author":"","guid":182076,"unread":true,"content":"<article>arXiv:2507.01323v1 Announce Type: cross \nAbstract: Vascular segmentation in medical images is crucial for disease diagnosis and surgical navigation. However, the segmented vascular structure is often discontinuous due to its slender nature and inadequate prior modeling. In this paper, we propose a novel Serpentine Window Mamba (SWinMamba) to achieve accurate vascular segmentation. The proposed SWinMamba innovatively models the continuity of slender vascular structures by incorporating serpentine window sequences into bidirectional state space models. The serpentine window sequences enable efficient feature capturing by adaptively guiding global visual context modeling to the vascular structure. Specifically, the Serpentine Window Tokenizer (SWToken) adaptively splits the input image using overlapping serpentine window sequences, enabling flexible receptive fields (RFs) for vascular structure modeling. The Bidirectional Aggregation Module (BAM) integrates coherent local features in the RFs for vascular continuity representation. In addition, dual-domain learning with Spatial-Frequency Fusion Unit (SFFU) is designed to enhance the feature representation of vascular structure. Extensive experiments on three challenging datasets demonstrate that the proposed SWinMamba achieves superior performance with complete and connected vessels.</article>","contentLength":1351,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hardness of Quantum Distribution Learning and Quantum Cryptography","url":"https://arxiv.org/abs/2507.01292","date":1751515200,"author":"","guid":182077,"unread":true,"content":"<article>arXiv:2507.01292v1 Announce Type: cross \nAbstract: The existence of one-way functions (OWFs) forms the minimal assumption in classical cryptography. However, this is not necessarily the case in quantum cryptography. One-way puzzles (OWPuzzs), introduced by Khurana and Tomer, provide a natural quantum analogue of OWFs. The existence of OWPuzzs implies $PP\\neq BQP$, while the converse remains open. In classical cryptography, the analogous problem-whether OWFs can be constructed from $P \\neq NP$-has long been studied from the viewpoint of hardness of learning. Hardness of learning in various frameworks (including PAC learning) has been connected to OWFs or to $P \\neq NP$. In contrast, no such characterization previously existed for OWPuzzs. In this paper, we establish the first complete characterization of OWPuzzs based on the hardness of a well-studied learning model: distribution learning. Specifically, we prove that OWPuzzs exist if and only if proper quantum distribution learning is hard on average. A natural question that follows is whether the worst-case hardness of proper quantum distribution learning can be derived from $PP \\neq BQP$. If so, and a worst-case to average-case hardness reduction is achieved, it would imply OWPuzzs solely from $PP \\neq BQP$. However, we show that this would be extremely difficult: if worst-case hardness is PP-hard (in a black-box reduction), then $SampBQP \\neq SampBPP$ follows from the infiniteness of the polynomial hierarchy. Despite that, we show that $PP \\neq BQP$ is equivalent to another standard notion of hardness of learning: agnostic. We prove that $PP \\neq BQP$ if and only if agnostic quantum distribution learning with respect to KL divergence is hard. As a byproduct, we show that hardness of agnostic quantum distribution learning with respect to statistical distance against $PPT^{\\Sigma_3^P}$ learners implies $SampBQP \\neq SampBPP$.</article>","contentLength":1908,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PanTS: The Pancreatic Tumor Segmentation Dataset","url":"https://arxiv.org/abs/2507.01291","date":1751515200,"author":"","guid":182078,"unread":true,"content":"<article>arXiv:2507.01291v1 Announce Type: cross \nAbstract: PanTS is a large-scale, multi-institutional dataset curated to advance research in pancreatic CT analysis. It contains 36,390 CT scans from 145 medical centers, with expert-validated, voxel-wise annotations of over 993,000 anatomical structures, covering pancreatic tumors, pancreas head, body, and tail, and 24 surrounding anatomical structures such as vascular/skeletal structures and abdominal/thoracic organs. Each scan includes metadata such as patient age, sex, diagnosis, contrast phase, in-plane spacing, slice thickness, etc. AI models trained on PanTS achieve significantly better performance in pancreatic tumor detection, localization, and segmentation compared to those trained on existing public datasets. Our analysis indicates that these gains are directly attributable to the 16x larger-scale tumor annotations and indirectly supported by the 24 additional surrounding anatomical structures. As the largest and most comprehensive resource of its kind, PanTS offers a new benchmark for developing and evaluating AI models in pancreatic CT analysis.</article>","contentLength":1115,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Classification based deep learning models for lung cancer and disease using medical images","url":"https://arxiv.org/abs/2507.01279","date":1751515200,"author":"","guid":182079,"unread":true,"content":"<article>arXiv:2507.01279v1 Announce Type: cross \nAbstract: The use of deep learning (DL) in medical image analysis has significantly improved the ability to predict lung cancer. In this study, we introduce a novel deep convolutional neural network (CNN) model, named ResNet+, which is based on the established ResNet framework. This model is specifically designed to improve the prediction of lung cancer and diseases using the images. To address the challenge of missing feature information that occurs during the downsampling process in CNNs, we integrate the ResNet-D module, a variant designed to enhance feature extraction capabilities by modifying the downsampling layers, into the traditional ResNet model. Furthermore, a convolutional attention module was incorporated into the bottleneck layers to enhance model generalization by allowing the network to focus on relevant regions of the input images. We evaluated the proposed model using five public datasets, comprising lung cancer (LC2500 $n$=3183, IQ-OTH/NCCD $n$=1336, and LCC $n$=25000 images) and lung disease (ChestXray $n$=5856, and COVIDx-CT $n$=425024 images). To address class imbalance, we used data augmentation techniques to artificially increase the representation of underrepresented classes in the training dataset. The experimental results show that ResNet+ model demonstrated remarkable accuracy/F1, reaching 98.14/98.14\\% on the LC25000 dataset and 99.25/99.13\\% on the IQ-OTH/NCCD dataset. Furthermore, the ResNet+ model saved computational cost compared to the original ResNet series in predicting lung cancer images. The proposed model outperformed the baseline models on publicly available datasets, achieving better performance metrics. Our codes are publicly available at https://github.com/AIPMLab/Graduation-2024/tree/main/Peng.</article>","contentLength":1808,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Automated Classification of Volcanic Earthquakes Using Transformer Encoders: Insights into Data Quality and Model Interpretability","url":"https://arxiv.org/abs/2507.01260","date":1751515200,"author":"","guid":182080,"unread":true,"content":"<article>arXiv:2507.01260v1 Announce Type: cross \nAbstract: Precisely classifying earthquake types is crucial for elucidating the relationship between volcanic earthquakes and volcanic activity. However, traditional methods rely on subjective human judgment, which requires considerable time and effort. To address this issue, we developed a deep learning model using a transformer encoder for a more objective and efficient classification. Tested on Mount Asama's diverse seismic activity, our model achieved high F1 scores (0.930 for volcano tectonic, 0.931 for low-frequency earthquakes, and 0.980 for noise), superior to a conventional CNN-based method. To enhance interpretability, attention weight visualizations were analyzed, revealing that the model focuses on key waveform features similarly to human experts. However, inconsistencies in training data, such as ambiguously labeled B-type events with S-waves, were found to influence classification accuracy and attention weight distributions. Experiments addressing data selection and augmentation demonstrated the importance of balancing data quality and diversity. In addition, stations within 3 km of the crater played an important role in improving model performance and interpretability. These findings highlight the potential of Transformer-based models for automated volcanic earthquake classification, particularly in improving efficiency and interpretability. By addressing challenges such as data imbalance and subjective labeling, our approach provides a robust framework for understanding seismic activity at Mount Asama. Moreover, this framework offers opportunities for transfer learning to other volcanic regions, paving the way for enhanced volcanic hazard assessments and disaster mitigation strategies.</article>","contentLength":1771,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Numerical Techniques for the Maximum Likelihood Toeplitz Covariance Matrix Estimation: Part I. Symmetric Toeplitz Matrices","url":"https://arxiv.org/abs/2507.01230","date":1751515200,"author":"","guid":182081,"unread":true,"content":"<article>arXiv:2507.01230v1 Announce Type: cross \nAbstract: In several applications, one must estimate a real-valued (symmetric) Toeplitz covariance matrix, typically shifted by the conjugated diagonal matrices of phase progression and phase \"calibration\" errors. Unlike the Hermitian Toeplitz covariance matrices, these symmetric matrices have a unique potential capability of being estimated regardless of these beam-steering phase progression and/or phase \"calibration\" errors. This unique capability is the primary motivation of this paper.</article>","contentLength":535,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Degrees of Freedom of Spatial Multiplexing in Distance Domain of Arbitrary Continuous-Aperture Array in Near-Field Region","url":"https://arxiv.org/abs/2507.01227","date":1751515200,"author":"","guid":182082,"unread":true,"content":"<article>arXiv:2507.01227v1 Announce Type: cross \nAbstract: Extremely large aperture array operating in the near-field regime unlocks additional spatial resources that can be exploited to simultaneously serve multiple users even when they share the same angular direction, a capability not achievable in conventional far-field systems. A fundamental question, however, remains: What is the maximum spatial degree of freedom (DoF) of spatial multiplexing in the distance domain?\n  In this paper, we address this open problem by investigating the spatial DoF of a line-of-sight (LoS) channel between a large two-dimensional transmit aperture and a linear receive array with collinearly-aligned elements (i.e., at the same angular direction) but located at different distances from the transmit aperture. We assume that both the aperture and linear array are continuous-aperture (CAP) arrays with an infinite number of elements and infinitesimal spacing, which establishes an upper bound for the spatial degrees of freedom (DoF) in the case of finite elements. First, we assume an ideal case where the transmit array is a single piece and the linear array is on the broad side of the transmit array. By reformulating the channel as an integral operator with a Hermitian convolution kernel, we derive a closed-form expression for the spatial DoF via the Fourier transform. Our analysis shows that the spatial DoF in the distance domain is predominantly determined by the extreme boundaries of the array rather than its detailed interior structure. We further extend the framework to non-broadside configurations by employing a projection method, which effectively converts the spatial DoF to an equivalent broadside case. Finally, we extend our analytical framework to the modular array, which shows the spatial DoF gain over the single-piece array given the constraint of the physical length of the array.</article>","contentLength":1893,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LotteryCodec: Searching the Implicit Representation in a Random Network for Low-Complexity Image Compression","url":"https://arxiv.org/abs/2507.01204","date":1751515200,"author":"","guid":182083,"unread":true,"content":"<article>arXiv:2507.01204v1 Announce Type: cross \nAbstract: We introduce and validate the lottery codec hypothesis, which states that untrained subnetworks within randomly initialized networks can serve as synthesis networks for overfitted image compression, achieving rate-distortion (RD) performance comparable to trained networks. This hypothesis leads to a new paradigm for image compression by encoding image statistics into the network substructure. Building on this hypothesis, we propose LotteryCodec, which overfits a binary mask to an individual image, leveraging an over-parameterized and randomly initialized network shared by the encoder and the decoder. To address over-parameterization challenges and streamline subnetwork search, we develop a rewind modulation mechanism that improves the RD performance. LotteryCodec outperforms VTM and sets a new state-of-the-art in single-image compression. LotteryCodec also enables adaptive decoding complexity through adjustable mask ratios, offering flexible compression solutions for diverse device constraints and application requirements.</article>","contentLength":1089,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Revisiting Noise-adaptive Transpilation in Quantum Computing: How Much Impact Does it Have?","url":"https://arxiv.org/abs/2507.01195","date":1751515200,"author":"","guid":182084,"unread":true,"content":"<article>arXiv:2507.01195v1 Announce Type: cross \nAbstract: Transpilation, particularly noise-aware optimization, is widely regarded as essential for maximizing the performance of quantum circuits on superconducting quantum computers. The common wisdom is that each circuit should be transpiled using up-to-date noise calibration data to optimize fidelity. In this work, we revisit the necessity of frequent noise-adaptive transpilation, conducting an in-depth empirical study across five IBM 127-qubit quantum computers and 16 diverse quantum algorithms. Our findings reveal novel and interesting insights: (1) noise-aware transpilation leads to a heavy concentration of workloads on a small subset of qubits, which increases output error variability; (2) using random mapping can mitigate this effect while maintaining comparable average fidelity; and (3) circuits compiled once with calibration data can be reliably reused across multiple calibration cycles and time periods without significant loss in fidelity. These results suggest that the classical overhead associated with daily, per-circuit noise-aware transpilation may not be justified. We propose lightweight alternatives that reduce this overhead without sacrificing fidelity -- offering a path to more efficient and scalable quantum workflows.</article>","contentLength":1299,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Emerging Activity Temporal Hypergraph (EATH), a model for generating realistic time-varying hypergraphs","url":"https://arxiv.org/abs/2507.01124","date":1751515200,"author":"","guid":182085,"unread":true,"content":"<article>arXiv:2507.01124v1 Announce Type: cross \nAbstract: Time-varying group interactions constitute the building blocks of many complex systems. The framework of temporal hypergraphs makes it possible to represent them by taking into account the higher-order and temporal nature of the interactions. However, the corresponding datasets are often incomplete and/or limited in size and duration, and surrogate time-varying hypergraphs able to reproduce their statistical features constitute interesting substitutions, especially to understand how dynamical processes unfold on group interactions. Here, we present a new temporal hypergraph model, the Emerging Activity Temporal Hypergraph (EATH), which can be fed by parameters measured in a dataset and create synthetic datasets with similar properties. In the model, each node has an independent underlying activity dynamic and the overall system activity emerges from the nodes dynamics, with temporal group interactions resulting from both the activity of the nodes and memory mechanisms. We first show that the EATH model can generate surrogate hypergraphs of several empirical datasets of face-to-face interactions, mimicking temporal and topological properties at the node and hyperedge level. We also showcase the possibility to use the resulting synthetic data in simulations of higher-order contagion dynamics, comparing the outcome of such process on original and surrogate datasets. Finally, we illustrate the flexibility of the model, which can generate synthetic hypergraphs with tunable properties: as an example, we generate \"hybrid\" temporal hypergraphs, which mix properties of different empirical datasets. Our work opens several perspectives, from the generation of synthetic realistic hypergraphs describing contexts where data collection is difficult to a deeper understanding of dynamical processes on temporal hypergraphs.</article>","contentLength":1888,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Gate Reordering for Distributed Quantum Compiling in Data Centers","url":"https://arxiv.org/abs/2507.01090","date":1751515200,"author":"","guid":182086,"unread":true,"content":"<article>arXiv:2507.01090v1 Announce Type: cross \nAbstract: Just as classical computing relies on distributed systems, the quantum computing era requires new kinds of infrastructure and software tools. Quantum networks will become the backbone of hybrid, quantum-augmented data centers, in which quantum algorithms are distributed over a local network of quantum processing units (QPUs) interconnected via shared entanglement. In this context, it is crucial to develop methods and software that minimize the number of inter-QPU communications. Here we describe key features of the quantum compiler araQne, which is designed to minimize distribution cost, measured by the number of entangled pairs required to distribute a monolithic quantum circuit using gate teleportation protocols. We establish the crucial role played by circuit reordering strategies, which strongly reduce the distribution cost compared to a baseline approach.</article>","contentLength":923,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MID-INFRARED (MIR) OCT-based inspection in industry","url":"https://arxiv.org/abs/2507.01074","date":1751515200,"author":"","guid":182087,"unread":true,"content":"<article>arXiv:2507.01074v1 Announce Type: cross \nAbstract: This paper aims to evaluate mid-infrared (MIR) Optical Coherence Tomography (OCT) systems as a tool to penetrate different materials and detect sub-surface irregularities. This is useful for monitoring production processes, allowing Non-Destructive Inspection Techniques of great value to the industry. In this exploratory study, several acquisitions are made on composite and ceramics to know the capabilities of the system. In addition, it is assessed which preprocessing and AI-enhanced vision algorithms can be anomaly-detection methodologies capable of detecting abnormal zones in the analyzed objects. Limitations and criteria for the selection of optimal parameters will be discussed, as well as strengths and weaknesses will be highlighted.</article>","contentLength":799,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Functional Renormalization for Signal Detection: Dimensional Analysis and Dimensional Phase Transition for Nearly Continuous Spectra Effective Field Theory","url":"https://arxiv.org/abs/2507.01064","date":1751515200,"author":"","guid":182088,"unread":true,"content":"<article>arXiv:2507.01064v1 Announce Type: cross \nAbstract: Signal detection is one of the main challenges of data science. According to the nature of the data, the presence of noise may corrupt measurements and hinder the discovery of significant patterns. A wide range of techniques aiming at extracting the relevant degrees of freedom from data has been thus developed over the years. However, signal detection in almost continuous spectra, for small signal-to-noise ratios, remains a known difficult issue. This paper develops over recent advancements proposing to tackle this issue by analysing the properties of the underlying effective field theory arising as a sort of maximal entropy distribution in the vicinity of universal random matrix distributions. Nearly continuous spectra provide an intrinsic and non-conventional scaling law for field and couplings, the scaling dimensions depending on the energy scale. The coarse-graining over small eigenvalues of the empirical spectrum defines a specific renormalization group, whose characteristics change when the collective behaviour of \"informational\" modes become significant, that is, stronger than the intrinsic fluctuations of noise. This paper pursues three different goals. First, we propose to quantify the real effects of fluctuations relative to what can be called \"signal\", while improving the robustness of the results obtained in our previous work. Second, we show that quantitative changes in the presence of a signal result in a counterintuitive modification of the distribution of eigenvectors. Finally, we propose a method for estimating the number of noise components and define a limit of detection in a general nearly continuous spectrum using the renormalization group. The main statements of this paper are essentially numeric, and their reproducibility can be checked using the associated code.</article>","contentLength":1867,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Prompt Mechanisms in Medical Imaging: A Comprehensive Survey","url":"https://arxiv.org/abs/2507.01055","date":1751515200,"author":"","guid":182089,"unread":true,"content":"<article>arXiv:2507.01055v1 Announce Type: cross \nAbstract: Deep learning offers transformative potential in medical imaging, yet its clinical adoption is frequently hampered by challenges such as data scarcity, distribution shifts, and the need for robust task generalization. Prompt-based methodologies have emerged as a pivotal strategy to guide deep learning models, providing flexible, domain-specific adaptations that significantly enhance model performance and adaptability without extensive retraining. This systematic review critically examines the burgeoning landscape of prompt engineering in medical imaging. We dissect diverse prompt modalities, including textual instructions, visual prompts, and learnable embeddings, and analyze their integration for core tasks such as image generation, segmentation, and classification. Our synthesis reveals how these mechanisms improve task-specific outcomes by enhancing accuracy, robustness, and data efficiency and reducing reliance on manual feature engineering while fostering greater model interpretability by making the model's guidance explicit. Despite substantial advancements, we identify persistent challenges, particularly in prompt design optimization, data heterogeneity, and ensuring scalability for clinical deployment. Finally, this review outlines promising future trajectories, including advanced multimodal prompting and robust clinical integration, underscoring the critical role of prompt-driven AI in accelerating the revolution of diagnostics and personalized treatment planning in medicine.</article>","contentLength":1560,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Asymptotic convexity of wide and shallow neural networks","url":"https://arxiv.org/abs/2507.01044","date":1751515200,"author":"","guid":182090,"unread":true,"content":"<article>arXiv:2507.01044v1 Announce Type: cross \nAbstract: For a simple model of shallow and wide neural networks, we show that the epigraph of its input-output map as a function of the network parameters approximates epigraph of a. convex function in a precise sense. This leads to a plausible explanation of their observed good performance.</article>","contentLength":334,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hello Afrika: Speech Commands in Kinyarwanda","url":"https://arxiv.org/abs/2507.01024","date":1751515200,"author":"","guid":182091,"unread":true,"content":"<article>arXiv:2507.01024v1 Announce Type: cross \nAbstract: Voice or Speech Commands are a subset of the broader Spoken Word Corpus of a language which are essential for non-contact control of and activation of larger AI systems in devices used in everyday life especially for persons with disabilities. Currently, there is a dearth of speech command models for African languages. The Hello Afrika project aims to address this issue and its first iteration is focused on the Kinyarwanda language since the country has shown interest in developing speech recognition technologies culminating in one of the largest datasets on Mozilla Common Voice. The model was built off a custom speech command corpus made up of general directives, numbers, and a wake word. The final model was deployed on multiple devices (PC, Mobile Phone and Edge Devices) and the performance was assessed using suitable metrics.</article>","contentLength":891,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Workflow-Based Evaluation of Music Generation Systems","url":"https://arxiv.org/abs/2507.01022","date":1751515200,"author":"","guid":182092,"unread":true,"content":"<article>arXiv:2507.01022v1 Announce Type: cross \nAbstract: This study presents an exploratory evaluation of Music Generation Systems (MGS) within contemporary music production workflows by examining eight open-source systems. The evaluation framework combines technical insights with practical experimentation through criteria specifically designed to investigate the practical and creative affordances of the systems within the iterative, non-linear nature of music production. Employing a single-evaluator methodology as a preliminary phase, this research adopts a mixed approach utilizing qualitative methods to form hypotheses subsequently assessed through quantitative metrics. The selected systems represent architectural diversity across both symbolic and audio-based music generation approaches, spanning composition, arrangement, and sound design tasks. The investigation addresses limitations of current MGS in music production, challenges and opportunities for workflow integration, and development potential as collaborative tools while maintaining artistic authenticity. Findings reveal these systems function primarily as complementary tools enhancing rather than replacing human expertise. They exhibit limitations in maintaining thematic and structural coherence that emphasize the indispensable role of human creativity in tasks demanding emotional depth and complex decision-making. This study contributes a structured evaluation framework that considers the iterative nature of music creation. It identifies methodological refinements necessary for subsequent comprehensive evaluations and determines viable areas for AI integration as collaborative tools in creative workflows. The research provides empirically-grounded insights to guide future development in the field.</article>","contentLength":1783,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Scalable Offline ASR for Command-Style Dictation in Courtrooms","url":"https://arxiv.org/abs/2507.01021","date":1751515200,"author":"","guid":182093,"unread":true,"content":"<article>arXiv:2507.01021v1 Announce Type: cross \nAbstract: We propose an open-source framework for Command-style dictation that addresses the gap between resource-intensive Online systems and high-latency Batch processing. Our approach uses Voice Activity Detection (VAD) to segment audio and transcribes these segments in parallel using Whisper models, enabling efficient multiplexing across audios. Unlike proprietary systems like SuperWhisper, this framework is also compatible with most ASR architectures, including widely used CTC-based models. Our multiplexing technique maximizes compute utilization in real-world settings, as demonstrated by its deployment in around 15% of India's courtrooms. Evaluations on live data show consistent latency reduction as user concurrency increases, compared to sequential batch processing. The live demonstration will showcase our open-sourced implementation and allow attendees to interact with it in real-time.</article>","contentLength":947,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Thermodynamically extended symplectic numerical simulation of viscoelastic, thermal expansion and heat conduction phenomena in solids","url":"https://arxiv.org/abs/2211.12120","date":1751515200,"author":"","guid":182094,"unread":true,"content":"<article>arXiv:2211.12120v2 Announce Type: cross \nAbstract: Symplectic numerical schemes for reversible dynamical systems predict the solution reliably over large times as well, and are a good starting point for extension to schemes for simulating irreversible situations like viscoelastic wave propagation and heat conduction coupled via thermal expansion occuring in rocks, plastics, biological samples etc. Dissipation error (artificial nonpreservation of energies and amplitudes) of the numerical solution should be as small as possible since it should not be confused with the real dissipation occuring in the irreversible system. In addition, the other well-known numerical artefact, dispersion error (artificial oscillations emerging at sharp changes), should also be minimal to avoid confusion with the true wavy behaviour. The continuum thermodynamical aspects (respect for balances with fluxes, systematic constitutive relationships between intensive quantities and fluxes, the second law of thermodynamics with positive definite entropy production, and the spacetime-based kinematic viewpoint) prove valuable for obtaining such extended schemes and for monitoring the solutions. Generalizing earlier works in this direction, here, we establish and investigate such a numerical scheme for one-dimensional viscoelastic wave propagation in the presence of heat conduction coupled via thermal expansion, demonstrating long-term reliability and the applicability of thermodynamics-based quantities in supervising the quality of the solution.</article>","contentLength":1538,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation","url":"https://arxiv.org/abs/2507.01961","date":1751515200,"author":"","guid":182095,"unread":true,"content":"<article>arXiv:2507.01961v1 Announce Type: new \nAbstract: Recently, mobile manipulation has attracted increasing attention for enabling language-conditioned robotic control in household tasks. However, existing methods still face challenges in coordinating mobile base and manipulator, primarily due to two limitations. On the one hand, they fail to explicitly model the influence of the mobile base on manipulator control, which easily leads to error accumulation under high degrees of freedom. On the other hand, they treat the entire mobile manipulation process with the same visual observation modality (e.g., either all 2D or all 3D), overlooking the distinct multimodal perception requirements at different stages during mobile manipulation. To address this, we propose the Adaptive Coordination Diffusion Transformer (AC-DiT), which enhances mobile base and manipulator coordination for end-to-end mobile manipulation. First, since the motion of the mobile base directly influences the manipulator's actions, we introduce a mobility-to-body conditioning mechanism that guides the model to first extract base motion representations, which are then used as context prior for predicting whole-body actions. This enables whole-body control that accounts for the potential impact of the mobile base's motion. Second, to meet the perception requirements at different stages of mobile manipulation, we design a perception-aware multimodal conditioning strategy that dynamically adjusts the fusion weights between various 2D visual images and 3D point clouds, yielding visual features tailored to the current perceptual needs. This allows the model to, for example, adaptively rely more on 2D inputs when semantic information is crucial for action prediction, while placing greater emphasis on 3D geometric information when precise spatial understanding is required. We validate AC-DiT through extensive experiments on both simulated and real-world mobile manipulation tasks.</article>","contentLength":1965,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Parallel-in-Time Preconditioning for Time-Dependent Variational Mean Field Games","url":"https://arxiv.org/abs/2507.01958","date":1751515200,"author":"","guid":182096,"unread":true,"content":"<article>arXiv:2507.01958v1 Announce Type: new \nAbstract: We study the numerical approximation of a time-dependent variational mean field game system with local couplings and either periodic or Neumann boundary conditions. Following a variational approach, we employ a finite difference discretization and solve the resulting finite-dimensional optimization problem using the Chambolle--Pock primal--dual algorithm. As this involves computing proximal operators and solving ill-conditioned linear systems at each iteration, we propose a general class of parallel-in-time preconditioners based on diagonalization techniques using discrete Fourier transforms. These enable efficient, scalable iterative solvers with robustness across a wide range of viscosities. We further develop fast solvers for the resulting ill-conditioned systems arising at each time step, using exact recursive schemes for structured grids while allowing for other geometries. Numerical experiments confirm the improved performance and parallel scalability of our approach.</article>","contentLength":1037,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation","url":"https://arxiv.org/abs/2507.01957","date":1751515200,"author":"","guid":182097,"unread":true,"content":"<article>arXiv:2507.01957v1 Announce Type: new \nAbstract: We present Locality-aware Parallel Decoding (LPD) to accelerate autoregressive image generation. Traditional autoregressive image generation relies on next-patch prediction, a memory-bound process that leads to high latency. Existing works have tried to parallelize next-patch prediction by shifting to multi-patch prediction to accelerate the process, but only achieved limited parallelization. To achieve high parallelization while maintaining generation quality, we introduce two key techniques: (1) Flexible Parallelized Autoregressive Modeling, a novel architecture that enables arbitrary generation ordering and degrees of parallelization. It uses learnable position query tokens to guide generation at target positions while ensuring mutual visibility among concurrently generated tokens for consistent parallel decoding. (2) Locality-aware Generation Ordering, a novel schedule that forms groups to minimize intra-group dependencies and maximize contextual support, enhancing generation quality. With these designs, we reduce the generation steps from 256 to 20 (256$\\times$256 res.) and 1024 to 48 (512$\\times$512 res.) without compromising quality on the ImageNet class-conditional generation, and achieving at least 3.4$\\times$ lower latency than previous parallelized autoregressive models.</article>","contentLength":1351,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks","url":"https://arxiv.org/abs/2507.01955","date":1751515200,"author":"","guid":182098,"unread":true,"content":"<article>arXiv:2507.01955v1 Announce Type: new \nAbstract: Multimodal foundation models, such as GPT-4o, have recently made remarkable progress, but it is not clear where exactly these models stand in terms of understanding vision. In this paper, we benchmark the performance of popular multimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0 Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision tasks (semantic segmentation, object detection, image classification, depth and surface normal prediction) using established datasets (e.g., COCO, ImageNet and its variants, etc).\n  The main challenges to performing this are: 1) most models are trained to output text and cannot natively express versatile domains, such as segments or 3D geometry, and 2) many leading models are proprietary and accessible only at an API level, i.e., there is no weight access to adapt them. We address these challenges by translating standard vision tasks into equivalent text-promptable and API-compatible tasks via prompt chaining to create a standardized benchmarking framework.\n  We observe that 1) the models are not close to the state-of-the-art specialist models at any task. However, 2) they are respectable generalists; this is remarkable as they are presumably trained on primarily image-text-based tasks. 3) They perform semantic tasks notably better than geometric ones. 4) While the prompt-chaining techniques affect performance, better models exhibit less sensitivity to prompt variations. 5) GPT-4o performs the best among non-reasoning models, securing the top position in 4 out of 6 tasks, 6) reasoning models, e.g. o3, show improvements in geometric tasks, and 7) a preliminary analysis of models with native image generation, like the latest GPT-4o, shows they exhibit quirks like hallucinations and spatial misalignments.</article>","contentLength":1854,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FreeMorph: Tuning-Free Generalized Image Morphing with Diffusion Model","url":"https://arxiv.org/abs/2507.01953","date":1751515200,"author":"","guid":182099,"unread":true,"content":"<article>arXiv:2507.01953v1 Announce Type: new \nAbstract: We present FreeMorph, the first tuning-free method for image morphing that accommodates inputs with different semantics or layouts. Unlike existing methods that rely on finetuning pre-trained diffusion models and are limited by time constraints and semantic/layout discrepancies, FreeMorph delivers high-fidelity image morphing without requiring per-instance training. Despite their efficiency and potential, tuning-free methods face challenges in maintaining high-quality results due to the non-linear nature of the multi-step denoising process and biases inherited from the pre-trained diffusion model. In this paper, we introduce FreeMorph to address these challenges by integrating two key innovations. 1) We first propose a guidance-aware spherical interpolation design that incorporates explicit guidance from the input images by modifying the self-attention modules, thereby addressing identity loss and ensuring directional transitions throughout the generated sequence. 2) We further introduce a step-oriented variation trend that blends self-attention modules derived from each input image to achieve controlled and consistent transitions that respect both inputs. Our extensive evaluations demonstrate that FreeMorph outperforms existing methods, being 10x ~ 50x faster and establishing a new state-of-the-art for image morphing.</article>","contentLength":1389,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Test-Time Scaling with Reflective Generative Model","url":"https://arxiv.org/abs/2507.01951","date":1751515200,"author":"","guid":182100,"unread":true,"content":"<article>arXiv:2507.01951v1 Announce Type: new \nAbstract: We introduce our first reflective generative model MetaStone-S1, which obtains OpenAI o3's performance via the self-supervised process reward model (SPRM). Through sharing the backbone network and using task-specific heads for next token prediction and process scoring respectively, SPRM successfully integrates the policy model and process reward model(PRM) into a unified interface without extra process annotation, reducing over 99% PRM parameters for efficient reasoning. Equipped with SPRM, MetaStone-S1 is naturally suitable for test time scaling (TTS), and we provide three reasoning effort modes (low, medium, and high), based on the controllable thinking length. Moreover, we empirically establish a scaling law that reveals the relationship between total thinking computation and TTS performance. Experiments demonstrate that our MetaStone-S1 achieves comparable performance to OpenAI-o3-mini's series with only 32B parameter size. To support the research community, we have open-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.</article>","contentLength":1108,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kwai Keye-VL Technical Report","url":"https://arxiv.org/abs/2507.01949","date":1751515200,"author":"","guid":182101,"unread":true,"content":"<article>arXiv:2507.01949v1 Announce Type: new \nAbstract: While Multimodal Large Language Models (MLLMs) demonstrate remarkable capabilities on static images, they often fall short in comprehending dynamic, information-dense short-form videos, a dominant medium in today's digital landscape. To bridge this gap, we introduce \\textbf{Kwai Keye-VL}, an 8-billion-parameter multimodal foundation model engineered for leading-edge performance in short-video understanding while maintaining robust general-purpose vision-language abilities. The development of Keye-VL rests on two core pillars: a massive, high-quality dataset exceeding 600 billion tokens with a strong emphasis on video, and an innovative training recipe. This recipe features a four-stage pre-training process for solid vision-language alignment, followed by a meticulous two-phase post-training process. The first post-training stage enhances foundational capabilities like instruction following, while the second phase focuses on stimulating advanced reasoning. In this second phase, a key innovation is our five-mode ``cold-start'' data mixture, which includes ``thinking'', ``non-thinking'', ``auto-think'', ``think with image'', and high-quality video data. This mixture teaches the model to decide when and how to reason. Subsequent reinforcement learning (RL) and alignment steps further enhance these reasoning capabilities and correct abnormal model behaviors, such as repetitive outputs. To validate our approach, we conduct extensive evaluations, showing that Keye-VL achieves state-of-the-art results on public video benchmarks and remains highly competitive on general image-based tasks (Figure 1). Furthermore, we develop and release the \\textbf{KC-MMBench}, a new benchmark tailored for real-world short-video scenarios, where Keye-VL shows a significant advantage.</article>","contentLength":1835,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LongAnimation: Long Animation Generation with Dynamic Global-Local Memory","url":"https://arxiv.org/abs/2507.01945","date":1751515200,"author":"","guid":182102,"unread":true,"content":"<article>arXiv:2507.01945v1 Announce Type: new \nAbstract: Animation colorization is a crucial part of real animation industry production. Long animation colorization has high labor costs. Therefore, automated long animation colorization based on the video generation model has significant research value. Existing studies are limited to short-term colorization. These studies adopt a local paradigm, fusing overlapping features to achieve smooth transitions between local segments. However, the local paradigm neglects global information, failing to maintain long-term color consistency. In this study, we argue that ideal long-term color consistency can be achieved through a dynamic global-local paradigm, i.e., dynamically extracting global color-consistent features relevant to the current generation. Specifically, we propose LongAnimation, a novel framework, which mainly includes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color Consistency Reward. The SketchDiT captures hybrid reference features to support the DGLM module. The DGLM module employs a long video understanding model to dynamically compress global historical features and adaptively fuse them with the current generation features. To refine the color consistency, we introduce a Color Consistency Reward. During inference, we propose a color consistency fusion to smooth the video segment transition. Extensive experiments on both short-term (14 frames) and long-term (average 500 frames) animations show the effectiveness of LongAnimation in maintaining short-term and long-term color consistency for open-domain animation colorization task. The code can be found at https://cn-makers.github.io/long_animation_web/.</article>","contentLength":1694,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Spatial tangible user interfaces for cognitive assessment and training","url":"https://arxiv.org/abs/2507.01944","date":1751515200,"author":"","guid":182103,"unread":true,"content":"<article>arXiv:2507.01944v1 Announce Type: new \nAbstract: This paper discusses Tangible User Interfaces (TUIs) and their potential impact on cognitive assessment and cognitive training. We believe that TUIs, and particularly a subset that we dub spatial TUIs, can extend human computer interaction beyond some of its current limitations. Spatial TUIs exploit human innate spatial and tactile ability in an intuitive and direct manner, affording interaction paradigms that are practically impossible using current interface technology. As proof-of-concept we examine implementations in the field of cognitive assessment and training. In this paper we use Cognitive Cubes, a novel TUI we developed, as an applied test bed for our beliefs, presenting promising experimental results for cognitive assessment of spatial ability, and possibly for training purposes.</article>","contentLength":850,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Multiple Watchman Routes in Staircase Polygons","url":"https://arxiv.org/abs/2507.01940","date":1751515200,"author":"","guid":182104,"unread":true,"content":"<article>arXiv:2507.01940v1 Announce Type: new \nAbstract: We consider the watchman route problem for multiple watchmen in staircase polygons, which are rectilinear $x$- and $y$-monotone polygons. For two watchmen, we propose an algorithm to find an optimal solution that takes quadratic time, improving on the cubic time of a trivial solution. For $m \\geq 3$ watchmen, we explain where this approach fails, and present an approximation algorithm for the min-max criterion with only an additive error.</article>","contentLength":491,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CI-VID: A Coherent Interleaved Text-Video Dataset","url":"https://arxiv.org/abs/2507.01938","date":1751515200,"author":"","guid":182105,"unread":true,"content":"<article>arXiv:2507.01938v1 Announce Type: new \nAbstract: Text-to-video (T2V) generation has recently attracted considerable attention, resulting in the development of numerous high-quality datasets that have propelled progress in this area. However, existing public datasets are primarily composed of isolated text-video (T-V) pairs and thus fail to support the modeling of coherent multi-clip video sequences. To address this limitation, we introduce CI-VID, a dataset that moves beyond isolated text-to-video (T2V) generation toward text-and-video-to-video (TV2V) generation, enabling models to produce coherent, multi-scene video sequences. CI-VID contains over 340,000 samples, each featuring a coherent sequence of video clips with text captions that capture both the individual content of each clip and the transitions between them, enabling visually and textually grounded generation. To further validate the effectiveness of CI-VID, we design a comprehensive, multi-dimensional benchmark incorporating human evaluation, VLM-based assessment, and similarity-based metrics. Experimental results demonstrate that models trained on CI-VID exhibit significant improvements in both accuracy and content consistency when generating video sequences. This facilitates the creation of story-driven content with smooth visual transitions and strong temporal coherence, underscoring the quality and practical utility of the CI-VID dataset We release the CI-VID dataset and the accompanying code for data construction and evaluation at: https://github.com/ymju-BAAI/CI-VID</article>","contentLength":1559,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Thin Line Between Comprehension and Persuasion in LLMs","url":"https://arxiv.org/abs/2507.01936","date":1751515200,"author":"","guid":182106,"unread":true,"content":"<article>arXiv:2507.01936v1 Announce Type: new \nAbstract: Large language models (LLMs) are excellent at maintaining high-level, convincing dialogues. They are being fast deployed as chatbots and evaluators in sensitive areas, such as peer review and mental health applications. This, along with the disparate accounts on their reasoning capabilities, calls for a closer examination of LLMs and their comprehension of dialogue. In this work we begin by evaluating LLMs' ability to maintain a debate--one of the purest yet most complex forms of human communication. Then we measure how this capability relates to their understanding of what is being talked about, namely, their comprehension of dialogical structures and the pragmatic context. We find that LLMs are capable of maintaining coherent, persuasive debates, often swaying the beliefs of participants and audiences alike. We also note that awareness or suspicion of AI involvement encourage people to be more critical of the arguments made. When polling LLMs on their comprehension of deeper structures of dialogue, however, they cannot demonstrate said understanding. Our findings tie the shortcomings of LLMs-as-evaluators to their (in)ability to understand the context. More broadly, for the field of argumentation theory we posit that, if an agent can convincingly maintain a dialogue, it is not necessary for it to know what it is talking about. Hence, the modelling of pragmatic context and coherence are secondary to effectiveness.</article>","contentLength":1487,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla","url":"https://arxiv.org/abs/2507.01931","date":1751515200,"author":"","guid":182107,"unread":true,"content":"<article>arXiv:2507.01931v1 Announce Type: new \nAbstract: In recent years, neural models trained on large multilingual text and speech datasets have shown great potential for supporting low-resource languages. This study investigates the performances of two state-of-the-art Automatic Speech Recognition (ASR) models, OpenAI's Whisper (Small &amp; Large-V2) and Facebook's Wav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments using two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to evaluate model performances. Through systematic fine-tuning and hyperparameter optimization, including learning rate, epochs, and model checkpoint selection, we have compared the models based on Word Error Rate (WER), Character Error Rate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model outperformed Whisper across all key evaluation metrics, demonstrated superior performance while requiring fewer computational resources, and offered valuable insights to develop robust speech recognition systems in low-resource linguistic settings.</article>","contentLength":1079,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Large Language Model-Driven Closed-Loop UAV Operation with Semantic Observations","url":"https://arxiv.org/abs/2507.01930","date":1751515200,"author":"","guid":182108,"unread":true,"content":"<article>arXiv:2507.01930v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have revolutionized robotic autonomy, including Unmanned Aerial Vehicles (UAVs). Recent studies have demonstrated the potential of LLMs for translating human instructions into executable control code for UAV operations. However, LLMs still face challenges from logical reasoning and complex decision-making, leading to concerns about the reliability of LLM-driven UAV operations. In this paper, we propose a LLM-driven closed-loop control framework that enables reliable UAV operations powered by effective feedback and refinement using two LLM modules, i.e., a Code Generator and an Evaluator. Our framework transforms numerical state observations from UAV operations into natural language trajectory descriptions to enhance the evaluator LLM's understanding of UAV dynamics for precise feedback generation. Our framework also enables a simulation-based refinement process, and hence eliminates the risks to physical UAVs caused by incorrect code execution during the refinement. Extensive experiments on UAV control tasks with different complexities are conducted. The experimental results show that our framework can achieve reliable UAV operations using LLMs, which significantly outperforms baseline approaches in terms of success rate and completeness with the increase of task complexity.</article>","contentLength":1373,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"evMLP: An Efficient Event-Driven MLP Architecture for Vision","url":"https://arxiv.org/abs/2507.01927","date":1751515200,"author":"","guid":182109,"unread":true,"content":"<article>arXiv:2507.01927v1 Announce Type: new \nAbstract: Deep neural networks have achieved remarkable results in computer vision tasks. In the early days, Convolutional Neural Networks (CNNs) were the mainstream architecture. In recent years, Vision Transformers (ViTs) have become increasingly popular. In addition, exploring applications of multi-layer perceptrons (MLPs) has provided new perspectives for research into vision model architectures. In this paper, we present evMLP accompanied by a simple event-driven local update mechanism. The proposed evMLP can independently process patches on images or feature maps via MLPs. We define changes between consecutive frames as \"events\". Under the event-driven local update mechanism, evMLP selectively processes patches where events occur. For sequential image data (e.g., video processing), this approach improves computational performance by avoiding redundant computations. Through ImageNet image classification experiments, evMLP attains accuracy competitive with state-of-the-art models. More significantly, experimental results on multiple video datasets demonstrate that evMLP reduces computational cost via its event-driven local update mechanism while maintaining output consistency with its non-event-driven baseline. The code and trained models are available at https://github.com/i-evi/evMLP.</article>","contentLength":1350,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"IC-Custom: Diverse Image Customization via In-Context Learning","url":"https://arxiv.org/abs/2507.01926","date":1751515200,"author":"","guid":182110,"unread":true,"content":"<article>arXiv:2507.01926v1 Announce Type: new \nAbstract: Image customization, a crucial technique for industrial media production, aims to generate content that is consistent with reference images. However, current approaches conventionally separate image customization into position-aware and position-free customization paradigms and lack a universal framework for diverse customization, limiting their applications across various scenarios. To overcome these limitations, we propose IC-Custom, a unified framework that seamlessly integrates position-aware and position-free image customization through in-context learning. IC-Custom concatenates reference images with target images to a polyptych, leveraging DiT's multi-modal attention mechanism for fine-grained token-level interactions. We introduce the In-context Multi-Modal Attention (ICMA) mechanism with learnable task-oriented register tokens and boundary-aware positional embeddings to enable the model to correctly handle different task types and distinguish various inputs in polyptych configurations. To bridge the data gap, we carefully curated a high-quality dataset of 12k identity-consistent samples with 8k from real-world sources and 4k from high-quality synthetic data, avoiding the overly glossy and over-saturated synthetic appearance. IC-Custom supports various industrial applications, including try-on, accessory placement, furniture arrangement, and creative IP customization. Extensive evaluations on our proposed ProductBench and the publicly available DreamBench demonstrate that IC-Custom significantly outperforms community workflows, closed-source models, and state-of-the-art open-source approaches. IC-Custom achieves approximately 73% higher human preference across identity consistency, harmonicity, and text alignment metrics, while training only 0.4% of the original model parameters. Project page: https://liyaowei-stu.github.io/project/IC_Custom</article>","contentLength":1930,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Survey on Vision-Language-Action Models: An Action Tokenization Perspective","url":"https://arxiv.org/abs/2507.01925","date":1751515200,"author":"","guid":182111,"unread":true,"content":"<article>arXiv:2507.01925v1 Announce Type: new \nAbstract: The remarkable advancements of vision and language foundation models in multimodal understanding, reasoning, and generation has sparked growing efforts to extend such intelligence to the physical world, fueling the flourishing of vision-language-action (VLA) models. Despite seemingly diverse approaches, we observe that current VLA models can be unified under a single framework: vision and language inputs are processed by a series of VLA modules, producing a chain of \\textit{action tokens} that progressively encode more grounded and actionable information, ultimately generating executable actions. We further determine that the primary design choice distinguishing VLA models lies in how action tokens are formulated, which can be categorized into language description, code, affordance, trajectory, goal state, latent representation, raw action, and reasoning. However, there remains a lack of comprehensive understanding regarding action tokens, significantly impeding effective VLA development and obscuring future directions. Therefore, this survey aims to categorize and interpret existing VLA research through the lens of action tokenization, distill the strengths and limitations of each token type, and identify areas for improvement. Through this systematic review and analysis, we offer a synthesized outlook on the broader evolution of VLA models, highlight underexplored yet promising directions, and contribute guidance for future research, hoping to bring the field closer to general-purpose intelligence.</article>","contentLength":1574,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection","url":"https://arxiv.org/abs/2507.01924","date":1751515200,"author":"","guid":182112,"unread":true,"content":"<article>arXiv:2507.01924v1 Announce Type: new \nAbstract: The complexity of mental healthcare billing enables anomalies, including fraud. While machine learning methods have been applied to anomaly detection, they often struggle with class imbalance, label scarcity, and complex sequential patterns. This study explores a hybrid deep learning approach combining Long Short-Term Memory (LSTM) networks and Transformers, with pseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior work has not evaluated such hybrid models trained on pseudo-labeled data in the context of healthcare billing. The approach is evaluated on two real-world billing datasets related to mental healthcare. The iForest LSTM baseline achieves the highest recall (0.963) on declaration-level data. On the operation-level data, the hybrid iForest-based model achieves the highest recall (0.744), though at the cost of lower precision. These findings highlight the potential of combining pseudo-labeling with hybrid deep learning in complex, imbalanced anomaly detection settings.</article>","contentLength":1063,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Decision-oriented Text Evaluation","url":"https://arxiv.org/abs/2507.01923","date":1751515200,"author":"","guid":182113,"unread":true,"content":"<article>arXiv:2507.01923v1 Announce Type: new \nAbstract: Natural language generation (NLG) is increasingly deployed in high-stakes domains, yet common intrinsic evaluation methods, such as n-gram overlap or sentence plausibility, weakly correlate with actual decision-making efficacy. We propose a decision-oriented framework for evaluating generated text by directly measuring its influence on human and large language model (LLM) decision outcomes. Using market digest texts--including objective morning summaries and subjective closing-bell analyses--as test cases, we assess decision quality based on the financial performance of trades executed by human investors and autonomous LLM agents informed exclusively by these texts. Our findings reveal that neither humans nor LLM agents consistently surpass random performance when relying solely on summaries. However, richer analytical commentaries enable collaborative human-LLM teams to outperform individual human or agent baselines significantly. Our approach underscores the importance of evaluating generated text by its ability to facilitate synergistic decision-making between humans and LLMs, highlighting critical limitations of traditional intrinsic metrics.</article>","contentLength":1213,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NaturalThoughts: Selecting and Distilling Reasoning Traces for General Reasoning Tasks","url":"https://arxiv.org/abs/2507.01921","date":1751515200,"author":"","guid":182114,"unread":true,"content":"<article>arXiv:2507.01921v1 Announce Type: new \nAbstract: Recent work has shown that distilling reasoning traces from a larger teacher model via supervised finetuning outperforms reinforcement learning with the smaller student model alone (Guo et al. 2025). However, there has not been a systematic study of what kind of reasoning demonstrations from the teacher are most effective in improving the student model's reasoning capabilities. In this work we curate high-quality \"NaturalThoughts\" by selecting reasoning traces from a strong teacher model based on a large pool of questions from NaturalReasoning (Yuan et al. 2025). We first conduct a systematic analysis of factors that affect distilling reasoning capabilities, in terms of sample efficiency and scalability for general reasoning tasks. We observe that simply scaling up data size with random sampling is a strong baseline with steady performance gains. Further, we find that selecting difficult examples that require more diverse reasoning strategies is more sample-efficient to transfer the teacher model's reasoning skills. Evaluated on both Llama and Qwen models, training with NaturalThoughts outperforms existing reasoning datasets such as OpenThoughts, LIMO, etc. on general STEM reasoning benchmarks including GPQA-Diamond, MMLU-Pro and SuperGPQA.</article>","contentLength":1309,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PDE-Constrained High-Order Mesh Optimization","url":"https://arxiv.org/abs/2507.01917","date":1751515200,"author":"","guid":182115,"unread":true,"content":"<article>arXiv:2507.01917v1 Announce Type: new \nAbstract: We present a novel framework for PDE-constrained $r$-adaptivity of high-order meshes. The proposed method formulates mesh movement as an optimization problem, with an objective function defined as a convex combination of a mesh quality metric and a measure of the accuracy of the PDE solution obtained via finite element discretization. The proposed formulation achieves optimized, well-defined high-order meshes by integrating mesh quality control, PDE solution accuracy, and robust gradient regularization. We adopt the Target-Matrix Optimization Paradigm to control geometric properties across the mesh, independent of the PDE of interest. To incorporate the accuracy of the PDE solution, we introduce error measures that control the finite element discretization error. The implicit dependence of these error measures on the mesh nodal positions is accurately captured by adjoint sensitivity analysis. Additionally, a convolution-based gradient regularization strategy is used to ensure stable and effective adaptation of high-order meshes. We demonstrate that the proposed framework can improve mesh quality and reduce the error by up to 10 times for the solution of Poisson and linear elasto-static problems. The approach is general with respect to the dimensionality, the order of the mesh, the types of mesh elements, and can be applied to any PDE that admits well-defined adjoint operators.</article>","contentLength":1448,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models","url":"https://arxiv.org/abs/2507.01915","date":1751515200,"author":"","guid":182116,"unread":true,"content":"<article>arXiv:2507.01915v1 Announce Type: new \nAbstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful technique for aligning large language models (LLMs) with human preferences. However, effectively aligning LLMs with diverse human preferences remains a significant challenge, particularly when they are conflict. To address this issue, we frame human value alignment as a multi-objective optimization problem, aiming to maximize a set of potentially conflicting objectives. We introduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning paradigm that employs multiple-gradient descent to align LLMs with diverse preference distributions. GAPO adaptively rescales the gradients for each objective to determine an update direction that optimally balances the trade-offs between objectives. Additionally, we introduce P-GAPO, which incorporates user preferences across different objectives and achieves Pareto solutions that better align with the user's specific needs. Our theoretical analysis demonstrates that GAPO converges towards a Pareto optimal solution for multiple objectives. Empirical results on Mistral-7B show that GAPO outperforms current state-of-the-art methods, achieving superior performance in both helpfulness and harmlessness.</article>","contentLength":1285,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP","url":"https://arxiv.org/abs/2507.01912","date":1751515200,"author":"","guid":182117,"unread":true,"content":"<article>arXiv:2507.01912v1 Announce Type: new \nAbstract: In orchard automation, dense foliage during the canopy season severely occludes tree structures, minimizing visibility to various canopy parts such as trunks and branches, which limits the ability of a machine vision system. However, canopy structure is more open and visible during the dormant season when trees are defoliated. In this work, we present an information fusion framework that integrates multi-seasonal structural data to support robotic and automated crop load management during the entire growing season. The framework combines high-resolution RGB-D imagery from both dormant and canopy periods using YOLOv9-Seg for instance segmentation, Kinect Fusion for 3D reconstruction, and Fast Generalized Iterative Closest Point (Fast GICP) for model alignment. Segmentation outputs from YOLOv9-Seg were used to extract depth-informed masks, which enabled accurate 3D point cloud reconstruction via Kinect Fusion; these reconstructed models from each season were subsequently aligned using Fast GICP to achieve spatially coherent multi-season fusion. The YOLOv9-Seg model, trained on manually annotated images, achieved a mean squared error (MSE) of 0.0047 and segmentation mAP@50 scores up to 0.78 for trunks in dormant season dataset. Kinect Fusion enabled accurate reconstruction of tree geometry, validated with field measurements resulting in root mean square errors (RMSE) of 5.23 mm for trunk diameter, 4.50 mm for branch diameter, and 13.72 mm for branch spacing. Fast GICP achieved precise cross-seasonal registration with a minimum fitness score of 0.00197, allowing integrated, comprehensive tree structure modeling despite heavy occlusions during the growing season. This fused structural representation enables robotic systems to access otherwise obscured architectural information, improving the precision of pruning, thinning, and other automated orchard operations.</article>","contentLength":1938,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Modality Agnostic, patient-specific digital twins modeling temporally varying digestive motion","url":"https://arxiv.org/abs/2507.01909","date":1751515200,"author":"","guid":182118,"unread":true,"content":"<article>arXiv:2507.01909v1 Announce Type: new \nAbstract: Objective: Clinical implementation of deformable image registration (DIR) requires voxel-based spatial accuracy metrics such as manually identified landmarks, which are challenging to implement for highly mobile gastrointestinal (GI) organs. To address this, patient-specific digital twins (DT) modeling temporally varying motion were created to assess the accuracy of DIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D sequences were generated from static 3D patient scans using published analytical GI motion models through a semi-automated pipeline. Eleven datasets, including six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars, and three contrast-enhanced CT scans. The motion amplitudes of the DTs were assessed against real patient stomach motion amplitudes extracted from independent 4D MRI datasets. The generated DTs were then used to assess six different DIR methods using target registration error, Dice similarity coefficient, and the 95th percentile Hausdorff distance using summary metrics and voxel-level granular visualizations. Finally, for a subset of T2w MRI scans from patients treated with MR-guided radiation therapy, dose distributions were warped and accumulated to assess dose warping errors, including evaluations of DIR performance in both low- and high-dose regions for patient-specific error estimation. Main results: Our proposed pipeline synthesized DTs modeling realistic GI motion, achieving mean and maximum motion amplitudes and a mean log Jacobian determinant within 0.8 mm and 0.01, respectively, similar to published real-patient gastric motion data. It also enables the extraction of detailed quantitative DIR performance metrics and rigorous validation of dose mapping accuracy. Significance: The pipeline enables rigorously testing DIR tools for dynamic, anatomically complex regions enabling granular spatial and dosimetric accuracies.</article>","contentLength":1967,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning","url":"https://arxiv.org/abs/2507.01908","date":1751515200,"author":"","guid":182119,"unread":true,"content":"<article>arXiv:2507.01908v1 Announce Type: new \nAbstract: Instruction-based image editing (IIE) has advanced rapidly with the success of diffusion models. However, existing efforts primarily focus on simple and explicit instructions to execute editing operations such as adding, deleting, moving, or swapping objects. They struggle to handle more complex implicit hypothetical instructions that require deeper reasoning to infer plausible visual changes and user intent. Additionally, current datasets provide limited support for training and evaluating reasoning-aware editing capabilities. Architecturally, these methods also lack mechanisms for fine-grained detail extraction that support such reasoning. To address these limitations, we propose Reason50K, a large-scale dataset specifically curated for training and evaluating hypothetical instruction reasoning image editing, along with ReasonBrain, a novel framework designed to reason over and execute implicit hypothetical instructions across diverse scenarios. Reason50K includes over 50K samples spanning four key reasoning scenarios: Physical, Temporal, Causal, and Story reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs) for editing guidance generation and a diffusion model for image synthesis, incorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture detailed visual and textual semantics essential for supporting instruction reasoning. To mitigate the semantic loss, we further introduce a Cross-Modal Enhancer (CME) that enables rich interactions between the fine-grained cues and MLLM-derived features. Extensive experiments demonstrate that ReasonBrain consistently outperforms state-of-the-art baselines on reasoning scenarios while exhibiting strong zero-shot generalization to conventional IIE tasks. Our dataset and code will be released publicly.</article>","contentLength":1856,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI4Research: A Survey of Artificial Intelligence for Scientific Research","url":"https://arxiv.org/abs/2507.01903","date":1751515200,"author":"","guid":182120,"unread":true,"content":"<article>arXiv:2507.01903v1 Announce Type: new \nAbstract: Recent advancements in artificial intelligence (AI), particularly in large language models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated remarkable capabilities in complex domains such as logical reasoning and experimental coding. Motivated by these advancements, numerous studies have explored the application of AI in the innovation process, particularly in the context of scientific research. These AI technologies primarily aim to develop systems that can autonomously conduct research processes across a wide range of scientific disciplines. Despite these significant strides, a comprehensive survey on AI for Research (AI4Research) remains absent, which hampers our understanding and impedes further development in this field. To address this gap, we present a comprehensive survey and offer a unified perspective on AI4Research. Specifically, the main contributions of our work are as follows: (1) Systematic taxonomy: We first introduce a systematic taxonomy to classify five mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key research gaps and highlight promising future directions, focusing on the rigor and scalability of automated experiments, as well as the societal impact. (3) Abundant applications and resources: Finally, we compile a wealth of resources, including relevant multidisciplinary applications, data corpora, and tools. We hope our work will provide the research community with quick access to these resources and stimulate innovative breakthroughs in AI4Research.</article>","contentLength":1578,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"High-Layer Attention Pruning with Rescaling","url":"https://arxiv.org/abs/2507.01900","date":1751515200,"author":"","guid":182121,"unread":true,"content":"<article>arXiv:2507.01900v1 Announce Type: new \nAbstract: Pruning is a highly effective approach for compressing large language models (LLMs), significantly reducing inference latency. However, conventional training-free structured pruning methods often employ a heuristic metric that indiscriminately removes some attention heads across all pruning layers, without considering their positions within the network architecture. In this work, we propose a novel pruning algorithm that strategically prunes attention heads in the model's higher layers. Since the removal of attention heads can alter the magnitude of token representations, we introduce an adaptive rescaling parameter that calibrates the representation scale post-pruning to counteract this effect. We conduct comprehensive experiments on a wide range of LLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our evaluation includes both generation and discriminative tasks across 27 datasets. The results consistently demonstrate that our method outperforms existing structured pruning methods. This improvement is particularly notable in generation tasks, where our approach significantly outperforms existing baselines.</article>","contentLength":1194,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants","url":"https://arxiv.org/abs/2507.01887","date":1751515200,"author":"","guid":182122,"unread":true,"content":"<article>arXiv:2507.01887v1 Announce Type: new \nAbstract: Large language models (LLMs) excel at reasoning tasks requiring long thought sequences for planning, reflection, and refinement. However, their substantial model size and high computational demands are impractical for widespread deployment. Yet, small language models (SLMs) often struggle to learn long-form CoT reasoning due to their limited capacity, a phenomenon we refer to as the \"SLMs Learnability Gap\". To address this, we introduce \\textbf{Mi}d-\\textbf{Co}T \\textbf{T}eacher \\textbf{A}ssistant Distillation (MiCoTAl), a framework for improving long CoT distillation for SLMs. MiCoTA employs intermediate-sized models as teacher assistants and utilizes intermediate-length CoT sequences to bridge both the capacity and reasoning length gaps. Our experiments on downstream tasks demonstrate that although SLMs distilled from large teachers can perform poorly, by applying MiCoTA, they achieve significant improvements in reasoning performance. Specifically, Qwen2.5-7B-Instruct and Qwen2.5-3B-Instruct achieve an improvement of 3.47 and 3.93 respectively on average score on AIME2024, AMC, Olympiad, MATH-500 and GSM8K benchmarks. To better understand the mechanism behind MiCoTA, we perform a quantitative experiment demonstrating that our method produces data more closely aligned with base SLM distributions. Our insights pave the way for future research into long-CoT data distillation for SLMs.</article>","contentLength":1455,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Faber polynomials in a deltoid region and power iteration momentum methods","url":"https://arxiv.org/abs/2507.01885","date":1751515200,"author":"","guid":182123,"unread":true,"content":"<article>arXiv:2507.01885v1 Announce Type: new \nAbstract: We consider a region in the complex plane enclosed by a deltoid curve inscribed in the unit circle, and define a family of polynomials $P_n$ that satisfy the same recurrence relation as the Faber polynomials for this region. We use this family of polynomials to give a constructive proof that $z^n$ is approximately a polynomial of degree $\\sim\\sqrt{n}$ within the deltoid region. Moreover, we show that $|P_n| \\le 1$ in this deltoid region, and that, if $|z| = 1+\\varepsilon$, then the magnitude $|P_n(z)|$ is at least $\\frac{1}{3}(1+\\sqrt{\\varepsilon})^n$, for all $\\varepsilon &gt; 0$. We illustrate our polynomial approximation theory with an application to iterative linear algebra. In particular, we construct a higher-order momentum-based method that accelerates the power iteration for certain matrices with complex eigenvalues. We show how the method can be run dynamically when the two dominant eigenvalues are real and positive.</article>","contentLength":985,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification","url":"https://arxiv.org/abs/2507.01884","date":1751515200,"author":"","guid":182124,"unread":true,"content":"<article>arXiv:2507.01884v1 Announce Type: new \nAbstract: Current lifelong person re-identification (LReID) methods predominantly rely on fully labeled data streams. However, in real-world scenarios where annotation resources are limited, a vast amount of unlabeled data coexists with scarce labeled samples, leading to the Semi-Supervised LReID (Semi-LReID) problem where LReID methods suffer severe performance degradation. Existing LReID methods, even when combined with semi-supervised strategies, suffer from limited long-term adaptation performance due to struggling with the noisy knowledge occurring during unlabeled data utilization. In this paper, we pioneer the investigation of Semi-LReID, introducing a novel Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation framework (SPRED). Our key innovation lies in establishing a self-reinforcing cycle between dynamic prototype-guided pseudo-label generation and new-old knowledge collaborative purification to enhance the utilization of unlabeled data. Specifically, learnable identity prototypes are introduced to dynamically capture the identity distributions and generate high-quality pseudo-labels. Then, the dual-knowledge cooperation scheme integrates current model specialization and historical model generalization, refining noisy pseudo-labels. Through this cyclic design, reliable pseudo-labels are progressively mined to improve current-stage learning and ensure positive knowledge propagation over long-term learning. Experiments on the established Semi-LReID benchmarks show that our SPRED achieves state-of-the-art performance. Our source code is available at https://github.com/zhoujiahuan1991/ICCV2025-SPRED</article>","contentLength":1688,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Future Slot Prediction for Unsupervised Object Discovery in Surgical Video","url":"https://arxiv.org/abs/2507.01882","date":1751515200,"author":"","guid":182125,"unread":true,"content":"<article>arXiv:2507.01882v1 Announce Type: new \nAbstract: Object-centric slot attention is an emerging paradigm for unsupervised learning of structured, interpretable object-centric representations (slots). This enables effective reasoning about objects and events at a low computational cost and is thus applicable to critical healthcare applications, such as real-time interpretation of surgical video. The heterogeneous scenes in real-world applications like surgery are, however, difficult to parse into a meaningful set of slots. Current approaches with an adaptive slot count perform well on images, but their performance on surgical videos is low. To address this challenge, we propose a dynamic temporal slot transformer (DTST) module that is trained both for temporal reasoning and for predicting the optimal future slot initialization. The model achieves state-of-the-art performance on multiple surgical databases, demonstrating that unsupervised object-centric methods can be applied to real-world data and become part of the common arsenal in healthcare applications.</article>","contentLength":1071,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evolving HPC services to enable ML workloads on HPE Cray EX","url":"https://arxiv.org/abs/2507.01880","date":1751515200,"author":"","guid":182126,"unread":true,"content":"<article>arXiv:2507.01880v1 Announce Type: new \nAbstract: The Alps Research Infrastructure leverages GH200 technology at scale, featuring 10,752 GPUs. Accessing Alps provides a significant computational advantage for researchers in Artificial Intelligence (AI) and Machine Learning (ML). While Alps serves a broad range of scientific communities, traditional HPC services alone are not sufficient to meet the dynamic needs of the ML community. This paper presents an initial investigation into extending HPC service capabilities to better support ML workloads. We identify key challenges and gaps we have observed since the early-access phase (2023) of Alps by the Swiss AI community and propose several technological enhancements. These include a user environment designed to facilitate the adoption of HPC for ML workloads, balancing performance with flexibility; a utility for rapid performance screening of ML applications during development; observability capabilities and data products for inspecting ongoing large-scale ML workloads; a utility to simplify the vetting of allocated nodes for compute readiness; a service plane infrastructure to deploy various types of workloads, including support and inference services; and a storage infrastructure tailored to the specific needs of ML workloads. These enhancements aim to facilitate the execution of ML workloads on HPC systems, increase system usability and resilience, and better align with the needs of the ML community. We also discuss our current approach to security aspects. This paper concludes by placing these proposals in the broader context of changes in the communities served by HPC infrastructure like ours.</article>","contentLength":1672,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Generalized ODE reduction algorithm for bounded degree transformation","url":"https://arxiv.org/abs/2507.01878","date":1751515200,"author":"","guid":182127,"unread":true,"content":"<article>arXiv:2507.01878v1 Announce Type: new \nAbstract: The integrability problem of rational first-order ODEs $y^{\\prime}=\\frac{M(x,y)}{N(x,y)}$, where $M,N \\in \\mathbb{R}[x,y]$ is a long-term research focus in the area of dynamical systems, physics, etc. Although the computer algebra system such as Mathematica, Maple has developed standard algorithms to tackle its first integral expressed by Liouvillian or special function, this problem is quite difficult and the general method requires specifying a tight degree bound for the Darboux polynomial. Computing the bounded degree first integral, in general, is very expensive for a computer algebra system\\cite{duarte2021efficient}\\cite{cheze2020symbolic} and becomes impractical for ODE of large size. In \\cite{huang2025algorithm}, we have proposed an algorithm to find the inverse of a local rational transformation $y \\to \\frac{A(x,y)}{B(x,y)}$ that transforms a rational ODE to a simpler and more tractable structure $y^{\\prime}=\\sum_{i=0}^nf_i(x)y^i$, whose integrability under linear transformation $\\left\\{x \\to F(x),y \\to P(x)y+Q(x)\\right\\}$ can be detected by Maple efficiently \\cite{CHEBTERRAB2000204}\\cite{cheb2000first}. In that paper we have also mentioned when $M(x,y),N(x,y)$ of the reducible structure are not coprime, canceling the common factors in $y$ will alter the structure which makes that algorithm fail. In this paper, we consider this issue. We conclude that with the exact tight degree bound for the polynomial $A(x,y)$ given, we have an efficient algorithm to compute such transformation and the reduced ODE for \"quite a lot of\" cases where $M,N$ are not coprime. We have also implemented this algorithm in Maple and the code is available in researchgate.</article>","contentLength":1729,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Joint Power Control and Precoding for Cell-Free Massive MIMO Systems With Sparse Multi-Dimensional Graph Neural Networks","url":"https://arxiv.org/abs/2507.01876","date":1751515200,"author":"","guid":182128,"unread":true,"content":"<article>arXiv:2507.01876v1 Announce Type: new \nAbstract: Cell-free massive multiple-input multiple-output (CF mMIMO) has emerged as a prominent candidate for future networks due to its ability to significantly enhance spectral efficiency by eliminating inter-cell interference. However, its practical deployment faces considerable challenges, such as high computational complexity and the optimization of its complex processing. To address these challenges, this correspondence proposes a framework based on a sparse multi-dimensional graph neural network (SP-MDGNN), which sparsifies the connections between access points (APs) and user equipments (UEs) to significantly reduce computational complexity while maintaining high performance. In addition, the weighted minimum mean square error (WMMSE) algorithm is introduced as a comparative method to further analyze the trade-off between performance and complexity. Simulation results demonstrate that the sparse method achieves an optimal balance between performance and complexity, significantly reducing the computational complexity of the original MDGNN method while incurring only a slight performance degradation, providing insights for the practical deployment of CF mMIMO systems in large-scale network.</article>","contentLength":1254,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Foundation Auto-Encoders for Time-Series Anomaly Detection","url":"https://arxiv.org/abs/2507.01875","date":1751515200,"author":"","guid":182129,"unread":true,"content":"<article>arXiv:2507.01875v1 Announce Type: new \nAbstract: We investigate a novel approach to time-series modeling, inspired by the successes of large pretrained foundation models. We introduce FAE (Foundation Auto-Encoders), a foundation generative-AI model for anomaly detection in time-series data, based on Variational Auto-Encoders (VAEs). By foundation, we mean a model pretrained on massive amounts of time-series data which can learn complex temporal patterns useful for accurate modeling, forecasting, and detection of anomalies on previously unseen datasets. FAE leverages VAEs and Dilated Convolutional Neural Networks (DCNNs) to build a generic model for univariate time-series modeling, which could eventually perform properly in out-of-the-box, zero-shot anomaly detection applications. We introduce the main concepts of FAE, and present preliminary results in different multi-dimensional time-series datasets from various domains, including a real dataset from an operational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.</article>","contentLength":1047,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Breaking the $n^{1.5}$ Additive Error Barrier for Private and Efficient Graph Sparsification via Private Expander Decomposition","url":"https://arxiv.org/abs/2507.01873","date":1751515200,"author":"","guid":182130,"unread":true,"content":"<article>arXiv:2507.01873v1 Announce Type: new \nAbstract: We study differentially private algorithms for graph cut sparsification, a fundamental problem in algorithms, privacy, and machine learning. While significant progress has been made, the best-known private and efficient cut sparsifiers on $n$-node graphs approximate each cut within $\\widetilde{O}(n^{1.5})$ additive error and $1+\\gamma$ multiplicative error for any $\\gamma &gt; 0$ [Gupta, Roth, Ullman TCC'12]. In contrast, \"inefficient\" algorithms, i.e., those requiring exponential time, can achieve an $\\widetilde{O}(n)$ additive error and $1+\\gamma$ multiplicative error [Eli{\\'a}{\\v{s}}, Kapralov, Kulkarni, Lee SODA'20]. In this work, we break the $n^{1.5}$ additive error barrier for private and efficient cut sparsification. We present an $(\\varepsilon,\\delta)$-DP polynomial time algorithm that, given a non-negative weighted graph, outputs a private synthetic graph approximating all cuts with multiplicative error $1+\\gamma$ and additive error $n^{1.25 + o(1)}$ (ignoring dependencies on $\\varepsilon, \\delta, \\gamma$).\n  At the heart of our approach lies a private algorithm for expander decomposition, a popular and powerful technique in (non-private) graph algorithms.</article>","contentLength":1230,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DIY-MKG: An LLM-Based Polyglot Language Learning System","url":"https://arxiv.org/abs/2507.01872","date":1751515200,"author":"","guid":182131,"unread":true,"content":"<article>arXiv:2507.01872v1 Announce Type: new \nAbstract: Existing language learning tools, even those powered by Large Language Models (LLMs), often lack support for polyglot learners to build linguistic connections across vocabularies in multiple languages, provide limited customization for individual learning paces or needs, and suffer from detrimental cognitive offloading. To address these limitations, we design Do-It-Yourself Multilingual Knowledge Graph (DIY-MKG), an open-source system that supports polyglot language learning. DIY-MKG allows the user to build personalized vocabulary knowledge graphs, which are constructed by selective expansion with related words suggested by an LLM. The system further enhances learning through rich annotation capabilities and an adaptive review module that leverages LLMs for dynamic, personalized quiz generation. In addition, DIY-MKG allows users to flag incorrect quiz questions, simultaneously increasing user engagement and providing a feedback loop for prompt refinement. Our evaluation of LLM-based components in DIY-MKG shows that vocabulary expansion is reliable and fair across multiple languages, and that the generated quizzes are highly accurate, validating the robustness of DIY-MKG.</article>","contentLength":1239,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents","url":"https://arxiv.org/abs/2507.01862","date":1751515200,"author":"","guid":182132,"unread":true,"content":"<article>arXiv:2507.01862v1 Announce Type: new \nAbstract: Domain specific chatbot applications often involve multi step interactions, such as refining search filters, selecting multiple items, or performing comparisons. Traditional graphical user interfaces (GUIs) handle these workflows by providing explicit \"Submit\" (commit data) and \"Reset\" (discard data) actions, allowing back-end systems to track user intent unambiguously. In contrast, conversational agents rely on subtle language cues, which can lead to confusion and incomplete context management. This paper proposes modeling these GUI inspired metaphors acknowledgment (submit like) and context switching (reset-like) as explicit tasks within large language model (LLM) prompts. By capturing user acknowledgment, reset actions, and chain of thought (CoT) reasoning as structured session data, we preserve clarity, reduce user confusion, and align domain-specific chatbot interactions with back-end logic. We demonstrate our approach in hotel booking and customer management scenarios, highlighting improvements in multi-turn task coherence, user satisfaction, and efficiency.</article>","contentLength":1129,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types","url":"https://arxiv.org/abs/2507.01857","date":1751515200,"author":"","guid":182133,"unread":true,"content":"<article>arXiv:2507.01857v1 Announce Type: new \nAbstract: Dexterous teleoperation plays a crucial role in robotic manipulation for real-world data collection and remote robot control. Previous dexterous teleoperation mostly relies on hand retargeting to closely mimic human hand postures. However, these approaches may fail to fully leverage the inherent dexterity of dexterous hands, which can execute unique actions through their structural advantages compared to human hands. To address this limitation, we propose TypeTele, a type-guided dexterous teleoperation system, which enables dexterous hands to perform actions that are not constrained by human motion patterns. This is achieved by introducing dexterous manipulation types into the teleoperation system, allowing operators to employ appropriate types to complete specific tasks. To support this system, we build an extensible dexterous manipulation type library to cover comprehensive dexterous postures used in manipulation tasks. During teleoperation, we employ a MLLM (Multi-modality Large Language Model)-assisted type retrieval module to identify the most suitable manipulation type based on the specific task and operator commands. Extensive experiments of real-world teleoperation and imitation learning demonstrate that the incorporation of manipulation types significantly takes full advantage of the dexterous robot's ability to perform diverse and complex tasks with higher success rates.</article>","contentLength":1452,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages","url":"https://arxiv.org/abs/2507.01853","date":1751515200,"author":"","guid":182134,"unread":true,"content":"<article>arXiv:2507.01853v1 Announce Type: new \nAbstract: The rapid advancement of Large Language Models (LLMs) has intensified the need for evaluation frameworks that go beyond English centric benchmarks and address the requirements of linguistically diverse regions such as India. We present EKA-EVAL, a unified and production-ready evaluation framework that integrates over 35 benchmarks, including 10 Indic-specific datasets, spanning categories like reasoning, mathematics, tool use, long-context understanding, and reading comprehension. Compared to existing Indian language evaluation tools, EKA-EVAL offers broader benchmark coverage, with built-in support for distributed inference, quantization, and multi-GPU usage. Our systematic comparison positions EKA-EVAL as the first end-to-end, extensible evaluation suite tailored for both global and Indic LLMs, significantly lowering the barrier to multilingual benchmarking. The framework is open-source and publicly available at https://github.com/lingo-iitgn/ eka-eval and a part of ongoing EKA initiative (https://eka.soket.ai), which aims to scale up to over 100 benchmarks and establish a robust, multilingual evaluation ecosystem for LLMs.</article>","contentLength":1192,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Low-Perplexity LLM-Generated Sequences and Where To Find Them","url":"https://arxiv.org/abs/2507.01844","date":1751515200,"author":"","guid":182135,"unread":true,"content":"<article>arXiv:2507.01844v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) become increasingly widespread, understanding how specific training data shapes their outputs is crucial for transparency, accountability, privacy, and fairness. To explore how LLMs leverage and replicate their training data, we introduce a systematic approach centered on analyzing low-perplexity sequences - high-probability text spans generated by the model. Our pipeline reliably extracts such long sequences across diverse topics while avoiding degeneration, then traces them back to their sources in the training data. Surprisingly, we find that a substantial portion of these low-perplexity spans cannot be mapped to the corpus. For those that do match, we quantify the distribution of occurrences across source documents, highlighting the scope and nature of verbatim recall and paving a way toward better understanding of how LLMs training data impacts their behavior.</article>","contentLength":958,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics","url":"https://arxiv.org/abs/2507.01843","date":1751515200,"author":"","guid":182136,"unread":true,"content":"<article>arXiv:2507.01843v1 Announce Type: new \nAbstract: Mixture-of-Experts (MoE) approaches have recently gained traction in robotics applications due to their ability to dynamically allocate computational resources and specialize sub-networks for distinct tasks or environmental contexts, enabling more efficient decision-making. Such systems often comprise sparsely activated experts combined under a single monolithic architecture and require a well-configured internal routing mechanism, which does not allow for selective low-level expert and router customization and requires additional training. We propose MoIRA, an architecture-agnostic modular MoE framework designed to coordinate existing experts with an external text-based router. MoIRA incorporates two zero-shot routing options: embedding-based similarity and prompt-driven language model inference. In our experiments, we choose large Vision-Language-Action models, gr00t-N1 and $\\pi_0$, as the underlying experts, and train low-rank adapters for low-overhead inference. We evaluate MoIRA on various GR1 Humanoid tasks and LIBERO Spatial and Goal benchmarks, where it consistently outperforms generalist models and competes with other MoE pipelines. Additionally, we analyse the robustness of the proposed approach to the variations of the instructions. While relying solely on textual descriptions of tasks and experts, MoIRA demonstrates the practical viability of modular deployment with precise, low-effort routing and provides an alternative, scalable foundation for future multi-expert robotic systems.</article>","contentLength":1567,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Automatic Rank Determination for Low-Rank Adaptation via Submodular Function Maximization","url":"https://arxiv.org/abs/2507.01841","date":1751515200,"author":"","guid":182137,"unread":true,"content":"<article>arXiv:2507.01841v1 Announce Type: new \nAbstract: In this paper, we propose SubLoRA, a rank determination method for Low-Rank Adaptation (LoRA) based on submodular function maximization. In contrast to prior approaches, such as AdaLoRA, that rely on first-order (linearized) approximations of the loss function, SubLoRA utilizes second-order information to capture the potentially complex loss landscape by incorporating the Hessian matrix. We show that the linearization becomes inaccurate and ill-conditioned when the LoRA parameters have been well optimized, motivating the need for a more reliable and nuanced second-order formulation. To this end, we reformulate the rank determination problem as a combinatorial optimization problem with a quadratic objective. However, solving this problem exactly is NP-hard in general. To overcome the computational challenge, we introduce a submodular function maximization framework and devise a greedy algorithm with approximation guarantees. We derive a sufficient and necessary condition under which the rank-determination objective becomes submodular, and construct a closed-form projection of the Hessian matrix that satisfies this condition while maintaining computational efficiency. Our method combines solid theoretical foundations, second-order accuracy, and practical computational efficiency. We further extend SubLoRA to a joint optimization setting, alternating between LoRA parameter updates and rank determination under a rank budget constraint. Extensive experiments on fine-tuning physics-informed neural networks (PINNs) for solving partial differential equations (PDEs) demonstrate the effectiveness of our approach. Results show that SubLoRA outperforms existing methods in both rank determination and joint training performance.</article>","contentLength":1793,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MobileIE: An Extremely Lightweight and Effective ConvNet for Real-Time Image Enhancement on Mobile Devices","url":"https://arxiv.org/abs/2507.01838","date":1751515200,"author":"","guid":182138,"unread":true,"content":"<article>arXiv:2507.01838v1 Announce Type: new \nAbstract: Recent advancements in deep neural networks have driven significant progress in image enhancement (IE). However, deploying deep learning models on resource-constrained platforms, such as mobile devices, remains challenging due to high computation and memory demands. To address these challenges and facilitate real-time IE on mobile, we introduce an extremely lightweight Convolutional Neural Network (CNN) framework with around 4K parameters. Our approach integrates reparameterization with an Incremental Weight Optimization strategy to ensure efficiency. Additionally, we enhance performance with a Feature Self-Transform module and a Hierarchical Dual-Path Attention mechanism, optimized with a Local Variance-Weighted loss. With this efficient framework, we are the first to achieve real-time IE inference at up to 1,100 frames per second (FPS) while delivering competitive image quality, achieving the best trade-off between speed and performance across multiple IE tasks. The code will be available at https://github.com/AVC2-UESTC/MobileIE.git.</article>","contentLength":1101,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views","url":"https://arxiv.org/abs/2507.01835","date":1751515200,"author":"","guid":182139,"unread":true,"content":"<article>arXiv:2507.01835v1 Announce Type: new \nAbstract: Hyperspectral reconstruction (HSR) from RGB images is a fundamentally ill-posed problem due to severe spectral information loss. Existing approaches typically rely on a single RGB image, limiting reconstruction accuracy. In this work, we propose a novel multi-image-to-hyperspectral reconstruction (MI-HSR) framework that leverages a triple-camera smartphone system, where two lenses are equipped with carefully selected spectral filters. Our configuration, grounded in theoretical and empirical analysis, enables richer and more diverse spectral observations than conventional single-camera setups. To support this new paradigm, we introduce Doomer, the first dataset for MI-HSR, comprising aligned images from three smartphone cameras and a hyperspectral reference camera across diverse scenes. We show that the proposed HSR model achieves consistent improvements over existing methods on the newly proposed benchmark. In a nutshell, our setup allows 30% towards more accurately estimated spectra compared to an ordinary RGB camera. Our findings suggest that multi-view spectral filtering with commodity hardware can unlock more accurate and practical hyperspectral imaging solutions.</article>","contentLength":1235,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Refining Gelfond Rationality Principle Towards More Comprehensive Foundational Principles for Answer Set Semantics","url":"https://arxiv.org/abs/2507.01833","date":1751515200,"author":"","guid":182140,"unread":true,"content":"<article>arXiv:2507.01833v1 Announce Type: new \nAbstract: Non-monotonic logic programming is the basis for a declarative problem solving paradigm known as answer set programming (ASP). Departing from the seminal definition by Gelfond and Lifschitz in 1988 for simple normal logic programs, various answer set semantics have been proposed for extensions. We consider two important questions: (1) Should the minimal model property, constraint monotonicity and foundedness as defined in the literature be mandatory conditions for an answer set semantics in general? (2) If not, what other properties could be considered as general principles for answer set semantics? We address the two questions. First, it seems that the three aforementioned conditions may sometimes be too strong, and we illustrate with examples that enforcing them may exclude expected answer sets. Second, we evolve the Gelfond answer set (GAS) principles for answer set construction by refining the Gelfond's rationality principle to well-supportedness, minimality w.r.t. negation by default and minimality w.r.t. epistemic negation. The principle of well-supportedness guarantees that every answer set is constructible from if-then rules obeying a level mapping and is thus free of circular justification, while the two minimality principles ensure that the formalism minimizes knowledge both at the level of answer sets and of world views. Third, to embody the refined GAS principles, we extend the notion of well-supportedness substantially to answer sets and world views, respectively. Fourth, we define new answer set semantics in terms of the refined GAS principles. Fifth, we use the refined GAS principles as an alternative baseline to intuitively assess the existing answer set semantics. Finally, we analyze the computational complexity.</article>","contentLength":1808,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Out-of-Distribution Detection Methods Answer the Wrong Questions","url":"https://arxiv.org/abs/2507.01831","date":1751515200,"author":"","guid":182141,"unread":true,"content":"<article>arXiv:2507.01831v1 Announce Type: new \nAbstract: To detect distribution shifts and improve model safety, many out-of-distribution (OOD) detection methods rely on the predictive uncertainty or features of supervised models trained on in-distribution data. In this paper, we critically re-examine this popular family of OOD detection procedures, and we argue that these methods are fundamentally answering the wrong questions for OOD detection. There is no simple fix to this misalignment, since a classifier trained only on in-distribution classes cannot be expected to identify OOD points; for instance, a cat-dog classifier may confidently misclassify an airplane if it contains features that distinguish cats from dogs, despite generally appearing nothing alike. We find that uncertainty-based methods incorrectly conflate high uncertainty with being OOD, while feature-based methods incorrectly conflate far feature-space distance with being OOD. We show how these pathologies manifest as irreducible errors in OOD detection and identify common settings where these methods are ineffective. Additionally, interventions to improve OOD detection such as feature-logit hybrid methods, scaling of model and data size, epistemic uncertainty representation, and outlier exposure also fail to address this fundamental misalignment in objectives. We additionally consider unsupervised density estimation and generative models for OOD detection, which we show have their own fundamental limitations.</article>","contentLength":1493,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SPARSE-PIVOT: Dynamic correlation clustering for node insertions","url":"https://arxiv.org/abs/2507.01830","date":1751515200,"author":"","guid":182142,"unread":true,"content":"<article>arXiv:2507.01830v1 Announce Type: new \nAbstract: We present a new Correlation Clustering algorithm for a dynamic setting where nodes are added one at a time. In this model, proposed by Cohen-Addad, Lattanzi, Maggiori, and Parotsidis (ICML 2024), the algorithm uses database queries to access the input graph and updates the clustering as each new node is added. Our algorithm has the amortized update time of $O_{\\epsilon}(\\log^{O(1)}(n))$. Its approximation factor is $20+\\varepsilon$, which is a substantial improvement over the approximation factor of the algorithm by Cohen-Addad et al. We complement our theoretical findings by empirically evaluating the approximation guarantee of our algorithm. The results show that it outperforms the algorithm by Cohen-Addad et al.~in practice.</article>","contentLength":787,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling","url":"https://arxiv.org/abs/2507.01829","date":1751515200,"author":"","guid":182143,"unread":true,"content":"<article>arXiv:2507.01829v1 Announce Type: new \nAbstract: Edge devices for temporal processing demand models that capture both short- and long- range dynamics under tight memory constraints. While Transformers excel at sequence modeling, their quadratic memory scaling with sequence length makes them impractical for such settings. Recurrent Neural Networks (RNNs) offer constant memory but train sequentially, and Temporal Convolutional Networks (TCNs), though efficient, scale memory with kernel size. To address this, we propose mGRADE (mininally Gated Recurrent Architecture with Delay Embedding), a hybrid-memory system that integrates a temporal 1D-convolution with learnable spacings followed by a minimal gated recurrent unit (minGRU). This design allows the convolutional layer to realize a flexible delay embedding that captures rapid temporal variations, while the recurrent module efficiently maintains global context with minimal memory overhead. We validate our approach on two synthetic tasks, demonstrating that mGRADE effectively separates and preserves multi-scale temporal features. Furthermore, on challenging pixel-by-pixel image classification benchmarks, mGRADE consistently outperforms both pure convolutional and pure recurrent counterparts using approximately 20% less memory footprint, highlighting its suitability for memory-constrained temporal processing at the edge. This highlights mGRADE's promise as an efficient solution for memory-constrained multi-scale temporal processing at the edge.</article>","contentLength":1514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"APRMCTS: Improving LLM-based Automated Program Repair with Iterative Tree Search","url":"https://arxiv.org/abs/2507.01827","date":1751515200,"author":"","guid":182144,"unread":true,"content":"<article>arXiv:2507.01827v1 Announce Type: new \nAbstract: Automated Program Repair (APR) attempts to fix software bugs without human intervention, which plays a crucial role in software development and maintenance. Recently, with the advances in Large Language Models (LLMs), a rapidly increasing number of APR techniques have been proposed with remarkable performance. However, existing LLM-based APR techniques typically adopt trial-and-error strategies, which suffer from two major drawbacks: (1) inherently limited patch effectiveness due to local exploration, and (2) low search efficiency due to redundant exploration. In this paper, we propose APRMCTS, which uses iterative tree search to improve LLM-based APR. APRMCTS incorporates Monte Carlo Tree Search (MCTS) into patch searching by performing a global evaluation of the explored patches and selecting the most promising one for subsequent refinement and generation. APRMCTS effectively resolves the problems of falling into local optima and thus helps improve the efficiency of patch searching. Our experiments on 835 bugs from Defects4J demonstrate that, when integrated with GPT-3.5, APRMCTS can fix a total of 201 bugs, which outperforms all state-of-the-art baselines. Besides, APRMCTS helps GPT-4o-mini, GPT-3.5, Yi-Coder-9B, and Qwen2.5-Coder-7B to fix 30, 27, 37, and 28 more bugs, respectively. More importantly, APRMCTS boasts a significant performance advantage while employing small patch size (16 and 32), notably fewer than the 500 and 10,000 patches adopted in previous studies. In terms of cost, compared to existing state-of-the-art LLM-based APR methods, APRMCTS has time and monetary costs of less than 20% and 50%, respectively. Our extensive study demonstrates that APRMCTS exhibits good effectiveness and efficiency, with particular advantages in addressing complex bugs.</article>","contentLength":1846,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MILP-SAT-GNN: Yet Another Neural SAT Solver","url":"https://arxiv.org/abs/2507.01825","date":1751515200,"author":"","guid":182145,"unread":true,"content":"<article>arXiv:2507.01825v1 Announce Type: new \nAbstract: We proposes a novel method that enables Graph Neural Networks (GNNs) to solve SAT problems by leveraging a technique developed for applying GNNs to Mixed Integer Linear Programming (MILP). Specifically, k-CNF formulae are mapped into MILP problems, which are then encoded as weighted bipartite graphs and subsequently fed into a GNN for training and testing. From a theoretical perspective: (i) we establish permutation and equivalence invariance results, demonstrating that the method produces outputs that are stable under reordering of clauses and variables; (ii) we identify a theoretical limitation, showing that for a class of formulae called foldable formulae, standard GNNs cannot always distinguish satisfiable from unsatisfiable instances; (iii) we prove a universal approximation theorem, establishing that with Random Node Initialization (RNI), the method can approximate SAT solving to arbitrary precision on finite datasets, that is, the GNN becomes approximately sound and complete on such datasets. Furthermore, we show that for unfoldable formulae, the same approximation guarantee can be achieved without the need for RNI. Finally, we conduct an experimental evaluation of our approach, which show that, despite the simplicity of the neural architecture, the method achieves promising results.</article>","contentLength":1360,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TD-MPC-Opt: Distilling Model-Based Multi-Task Reinforcement Learning Agents","url":"https://arxiv.org/abs/2507.01823","date":1751515200,"author":"","guid":182146,"unread":true,"content":"<article>arXiv:2507.01823v1 Announce Type: new \nAbstract: We present a novel approach to knowledge transfer in model-based reinforcement learning, addressing the critical challenge of deploying large world models in resource-constrained environments. Our method efficiently distills a high-capacity multi-task agent (317M parameters) into a compact model (1M parameters) on the MT30 benchmark, significantly improving performance across diverse tasks. Our distilled model achieves a state-of-the-art normalized score of 28.45, surpassing the original 1M parameter model score of 18.93. This improvement demonstrates the ability of our distillation technique to capture and consolidate complex multi-task knowledge. We further optimize the distilled model through FP16 post-training quantization, reducing its size by $\\sim$50\\%. Our approach addresses practical deployment limitations and offers insights into knowledge representation in large world models, paving the way for more efficient and accessible multi-task reinforcement learning systems in robotics and other resource-constrained applications. Code available at https://github.com/dmytro-kuzmenko/td-mpc-opt.</article>","contentLength":1161,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Design and Development of a Concentric Tube Steerable Drilling Robot for Creating S-shape Tunnels for Pelvic Fixation Procedures","url":"https://arxiv.org/abs/2507.01811","date":1751515200,"author":"","guid":182147,"unread":true,"content":"<article>arXiv:2507.01811v1 Announce Type: new \nAbstract: Current pelvic fixation techniques rely on rigid drilling tools, which inherently constrain the placement of rigid medical screws in the complex anatomy of pelvis. These constraints prevent medical screws from following anatomically optimal pathways and force clinicians to fixate screws in linear trajectories. This suboptimal approach, combined with the unnatural placement of the excessively long screws, lead to complications such as screw misplacement, extended surgery times, and increased radiation exposure due to repeated X-ray images taken ensure to safety of procedure. To address these challenges, in this paper, we present the design and development of a unique 4 degree-of-freedom (DoF) pelvic concentric tube steerable drilling robot (pelvic CT-SDR). The pelvic CT-SDR is capable of creating long S-shaped drilling trajectories that follow the natural curvatures of the pelvic anatomy. The performance of the pelvic CT-SDR was thoroughly evaluated through several S-shape drilling experiments in simulated bone phantoms.</article>","contentLength":1084,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evaluating Structured Output Robustness of Small Language Models for Open Attribute-Value Extraction from Clinical Notes","url":"https://arxiv.org/abs/2507.01810","date":1751515200,"author":"","guid":182148,"unread":true,"content":"<article>arXiv:2507.01810v1 Announce Type: new \nAbstract: We present a comparative analysis of the parseability of structured outputs generated by small language models for open attribute-value extraction from clinical notes. We evaluate three widely used serialization formats: JSON, YAML, and XML, and find that JSON consistently yields the highest parseability. Structural robustness improves with targeted prompting and larger models, but declines for longer documents and certain note types. Our error analysis identifies recurring format-specific failure patterns. These findings offer practical guidance for selecting serialization formats and designing prompts when deploying language models in privacy-sensitive clinical settings.</article>","contentLength":730,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems","url":"https://arxiv.org/abs/2507.01808","date":1751515200,"author":"","guid":182149,"unread":true,"content":"<article>arXiv:2507.01808v1 Announce Type: new \nAbstract: Small- and medium-sized manufacturers need innovative data tools but, because of competition and privacy concerns, often do not want to share their proprietary data with researchers who might be interested in helping. This paper introduces a privacy-preserving platform by which manufacturers may safely share their data with researchers through secure methods, so that those researchers then create innovative tools to solve the manufacturers' real-world problems, and then provide tools that execute solutions back onto the platform for others to use with privacy and confidentiality guarantees. We illustrate this problem through a particular use case which addresses an important problem in the large-scale manufacturing of food crystals, which is that quality control relies on image analysis tools. Previous to our research, food crystals in the images were manually counted, which required substantial and time-consuming human efforts, but we have developed and deployed a crystal analysis tool which makes this process both more rapid and accurate. The tool enables automatic characterization of the crystal size distribution and numbers from microscope images while the natural imperfections from the sample preparation are automatically removed; a machine learning model to count high resolution translucent crystals and agglomeration of crystals was also developed to aid in these efforts. The resulting algorithm was then packaged for real-world use on the factory floor via a web-based app secured through the originating privacy-preserving platform, allowing manufacturers to use it while keeping their proprietary data secure. After demonstrating this full process, future directions are also explored.</article>","contentLength":1766,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs","url":"https://arxiv.org/abs/2507.01806","date":1751515200,"author":"","guid":182150,"unread":true,"content":"<article>arXiv:2507.01806v1 Announce Type: new \nAbstract: Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language Models (LLMs) by enabling parameter-efficient updates. However, their widespread adoption remains limited by the reliance on GPU-based training. In this work, we propose a theoretically grounded approach to LoRA fine-tuning designed specifically for users with limited computational resources, particularly those restricted to standard laptop CPUs. Our method learns a meta-operator that maps any input dataset, represented as a probability distribution, to a set of LoRA weights by leveraging a large bank of pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of performing new gradient-based updates, our pipeline constructs adapters via lightweight combinations of existing LoRAs directly on CPU. While the resulting adapters do not match the performance of GPU-trained counterparts, they consistently outperform the base Mistral model on downstream tasks, offering a practical and accessible alternative to traditional GPU-based fine-tuning.</article>","contentLength":1089,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Dataset for Automatic Assessment of TTS Quality in Spanish","url":"https://arxiv.org/abs/2507.01805","date":1751515200,"author":"","guid":182151,"unread":true,"content":"<article>arXiv:2507.01805v1 Announce Type: new \nAbstract: This work addresses the development of a database for the automatic assessment of text-to-speech (TTS) systems in Spanish, aiming to improve the accuracy of naturalness prediction models. The dataset consists of 4,326 audio samples from 52 different TTS systems and human voices and is, up to our knowledge, the first of its kind in Spanish. To label the audios, a subjective test was designed based on the ITU-T Rec. P.807 standard and completed by 92 participants. Furthermore, the utility of the collected dataset was validated by training automatic naturalness prediction systems. We explored two approaches: fine-tuning an existing model originally trained for English, and training small downstream networks on top of frozen self-supervised speech models. Our models achieve a mean absolute error of 0.8 on a five-point MOS scale. Further analysis demonstrates the quality and diversity of the developed dataset, and its potential to advance TTS research in Spanish.</article>","contentLength":1021,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Decentralized and Sustainable Foundation Model Training with the Edge","url":"https://arxiv.org/abs/2507.01803","date":1751515200,"author":"","guid":182152,"unread":true,"content":"<article>arXiv:2507.01803v1 Announce Type: new \nAbstract: Foundation models are at the forefront of AI research, appealing for their ability to learn from vast datasets and cater to diverse tasks. Yet, their significant computational demands raise issues of environmental impact and the risk of centralized control in their development. We put forward a vision towards decentralized and sustainable foundation model training that leverages the collective compute of sparingly used connected edge AI devices. We present the rationale behind our vision, particularly in support of its sustainability benefit. We further outline a set of challenges that need to be addressed to turn this vision into reality.</article>","contentLength":696,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Anatomy of Evidence: An Investigation Into Explainable ICD Coding","url":"https://arxiv.org/abs/2507.01802","date":1751515200,"author":"","guid":182153,"unread":true,"content":"<article>arXiv:2507.01802v1 Announce Type: new \nAbstract: Automatic medical coding has the potential to ease documentation and billing processes. For this task, transparency plays an important role for medical coders and regulatory bodies, which can be achieved using explainability methods. However, the evaluation of these approaches has been mostly limited to short text and binary settings due to a scarcity of annotated data. Recent efforts by Cheng et al. (2023) have introduced the MDACE dataset, which provides a valuable resource containing code evidence in clinical records. In this work, we conduct an in-depth analysis of the MDACE dataset and perform plausibility evaluation of current explainable medical coding systems from an applied perspective. With this, we contribute to a deeper understanding of automatic medical coding and evidence extraction. Our findings reveal that ground truth evidence aligns with code descriptions to a certain degree. An investigation into state-of-the-art approaches shows a high overlap with ground truth evidence. We propose match measures and highlight success and failure cases. Based on our findings, we provide recommendations for developing and evaluating explainable medical coding systems.</article>","contentLength":1237,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction","url":"https://arxiv.org/abs/2507.01801","date":1751515200,"author":"","guid":182154,"unread":true,"content":"<article>arXiv:2507.01801v1 Announce Type: new \nAbstract: Accurately predicting the future trajectories of traffic agents is essential in autonomous driving. However, due to the inherent imbalance in trajectory distributions, tail data in natural datasets often represents more complex and hazardous scenarios. Existing studies typically rely solely on a base model's prediction error, without considering the diversity and uncertainty of long-tail trajectory patterns. We propose an adaptive momentum and decoupled contrastive learning framework (AMD), which integrates unsupervised and supervised contrastive learning strategies. By leveraging an improved momentum contrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module, our framework enhances the model's ability to recognize rare and complex trajectories. Additionally, we design four types of trajectory random augmentation methods and introduce an online iterative clustering strategy, allowing the model to dynamically update pseudo-labels and better adapt to the distributional shifts in long-tail data. We propose three different criteria to define long-tail trajectories and conduct extensive comparative experiments on the nuScenes and ETH$/$UCY datasets. The results show that AMD not only achieves optimal performance in long-tail trajectory prediction but also demonstrates outstanding overall prediction accuracy.</article>","contentLength":1390,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision","url":"https://arxiv.org/abs/2507.01800","date":1751515200,"author":"","guid":182155,"unread":true,"content":"<article>arXiv:2507.01800v1 Announce Type: new \nAbstract: 3D Visual Question-Answering (3D VQA) is pivotal for models to perceive the physical world and perform spatial reasoning. Answer-centric supervision is a commonly used training method for 3D VQA models. Many models that utilize this strategy have achieved promising results in 3D VQA tasks. However, the answer-centric approach only supervises the final output of models and allows models to develop reasoning pathways freely. The absence of supervision on the reasoning pathway enables the potential for developing superficial shortcuts through common patterns in question-answer pairs. Moreover, although slow-thinking methods advance large language models, they suffer from underthinking. To address these issues, we propose \\textbf{HCNQA}, a 3D VQA model leveraging a hierarchical concentration narrowing supervision method. By mimicking the human process of gradually focusing from a broad area to specific objects while searching for answers, our method guides the model to perform three phases of concentration narrowing through hierarchical supervision. By supervising key checkpoints on a general reasoning pathway, our method can ensure the development of a rational and effective reasoning pathway. Extensive experimental results demonstrate that our method can effectively ensure that the model develops a rational reasoning pathway and performs better. The code is available at https://github.com/JianuoZhu/HCNQA.</article>","contentLength":1475,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Neural Entropy-stable conservative flux form neural networks for learning hyperbolic conservation laws","url":"https://arxiv.org/abs/2507.01795","date":1751515200,"author":"","guid":182156,"unread":true,"content":"<article>arXiv:2507.01795v1 Announce Type: new \nAbstract: We propose a neural entropy-stable conservative flux form neural network (NESCFN) for learning hyperbolic conservation laws and their associated entropy functions directly from solution trajectories, without requiring any predefined numerical discretization. While recent neural network architectures have successfully integrated classical numerical principles into learned models, most rely on prior knowledge of the governing equations or assume a fixed discretization. Our approach removes this dependency by embedding entropy-stable design principles into the learning process itself, enabling the discovery of physically consistent dynamics in a fully data-driven setting. By jointly learning both the numerical flux function and a corresponding entropy, the proposed method ensures conservation and entropy dissipation, critical for long-term stability and fidelity in the system of hyperbolic conservation laws. Numerical results demonstrate that the method achieves stability and conservation over extended time horizons and accurately captures shock propagation speeds, even without oracle access to future-time solution profiles in the training data.</article>","contentLength":1209,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FreeLoRA: Enabling Training-Free LoRA Fusion for Autoregressive Multi-Subject Personalization","url":"https://arxiv.org/abs/2507.01792","date":1751515200,"author":"","guid":182157,"unread":true,"content":"<article>arXiv:2507.01792v1 Announce Type: new \nAbstract: Subject-driven image generation plays a crucial role in applications such as virtual try-on and poster design. Existing approaches typically fine-tune pretrained generative models or apply LoRA-based adaptations for individual subjects. However, these methods struggle with multi-subject personalization, as combining independently adapted modules often requires complex re-tuning or joint optimization. We present FreeLoRA, a simple and generalizable framework that enables training-free fusion of subject-specific LoRA modules for multi-subject personalization. Each LoRA module is adapted on a few images of a specific subject using a Full Token Tuning strategy, where it is applied across all tokens in the prompt to encourage weakly supervised token-content alignment. At inference, we adopt Subject-Aware Inference, activating each module only on its corresponding subject tokens. This enables training-free fusion of multiple personalized subjects within a single image, while mitigating overfitting and mutual interference between subjects. Extensive experiments show that FreeLoRA achieves strong performance in both subject fidelity and prompt consistency.</article>","contentLength":1215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Boosting Adversarial Transferability Against Defenses via Multi-Scale Transformation","url":"https://arxiv.org/abs/2507.01791","date":1751515200,"author":"","guid":182158,"unread":true,"content":"<article>arXiv:2507.01791v1 Announce Type: new \nAbstract: The transferability of adversarial examples poses a significant security challenge for deep neural networks, which can be attacked without knowing anything about them. In this paper, we propose a new Segmented Gaussian Pyramid (SGP) attack method to enhance the transferability, particularly against defense models. Unlike existing methods that generally focus on single-scale images, our approach employs Gaussian filtering and three types of downsampling to construct a series of multi-scale examples. Then, the gradients of the loss function with respect to each scale are computed, and their average is used to determine the adversarial perturbations. The proposed SGP can be considered an input transformation with high extensibility that is easily integrated into most existing adversarial attacks. Extensive experiments demonstrate that in contrast to the state-of-the-art methods, SGP significantly enhances attack success rates against black-box defense models, with average attack success rates increasing by 2.3% to 32.6%, based only on transferability.</article>","contentLength":1113,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Do Vision-Language Models Process Conflicting Information Across Modalities?","url":"https://arxiv.org/abs/2507.01790","date":1751515200,"author":"","guid":182159,"unread":true,"content":"<article>arXiv:2507.01790v1 Announce Type: new \nAbstract: AI models are increasingly required to be multimodal, integrating disparate input streams into a coherent state representation on which subsequent behaviors and actions can be based. This paper seeks to understand how such models behave when input streams present conflicting information. Focusing specifically on vision-language models, we provide inconsistent inputs (e.g., an image of a dog paired with the caption \"A photo of a cat\") and ask the model to report the information present in one of the specific modalities (e.g., \"What does the caption say / What is in the image?\"). We find that models often favor one modality over the other, e.g., reporting the image regardless of what the caption says, but that different models differ in which modality they favor. We find evidence that the behaviorally preferred modality is evident in the internal representational structure of the model, and that specific attention heads can restructure the representations to favor one modality over the other. Moreover, we find modality-agnostic \"router heads\" which appear to promote answers about the modality requested in the instruction, and which can be manipulated or transferred in order to improve performance across datasets and modalities. Together, the work provides essential steps towards identifying and controlling if and how models detect and resolve conflicting signals within complex multimodal environments.</article>","contentLength":1471,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The inverse source problem of stochastic wave equation","url":"https://arxiv.org/abs/2507.01789","date":1751515200,"author":"","guid":182160,"unread":true,"content":"<article>arXiv:2507.01789v1 Announce Type: new \nAbstract: To address the ill-posedness of the inverse source problem for the one-dimensional stochastic Helmholtz equations without attenuation, this study develops a novel computational framework designed to mitigate this inherent challenge at the numerical implementation level. For the stochastic wave equation driven by a finite-jump L\\'evy process (assuming that its jump amplitude obeys a Gaussian distribution and the jump time interval obeys a Poisson distribution), this paper firstly establish the existence of a mild solution to its direct problem satisfying a particular stability estimate. Building upon these theoretical foundations, we further investigate the well-posedness of the inverse problem and develop a methodology to reconstruct the unknown source terms $f$ and $g$ using the data of the wave field at the final time point $u(x,T)$. This work not only provides rigorous theoretical analysis and effective numerical schemes for solving inverse source problems in these two specific classes of stochastic wave equations, but also offers new perspectives and methodological approaches for addressing a broader range of wave propagation inverse problems characterized by non-Gaussian stochastic properties. The proposed framework demonstrates significant relevance for characterizing physical phenomena influenced by jump-type stochastic perturbations, offering promising applications in diverse domains including but not limited to seismic wave propagation analysis and financial market volatility modeling.</article>","contentLength":1568,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging","url":"https://arxiv.org/abs/2507.01788","date":1751515200,"author":"","guid":182161,"unread":true,"content":"<article>arXiv:2507.01788v1 Announce Type: new \nAbstract: Vision transformers (ViTs) have rapidly gained prominence in medical imaging tasks such as disease classification, segmentation, and detection due to their superior accuracy compared to conventional deep learning models. However, due to their size and complex interactions via the self-attention mechanism, they are not well understood. In particular, it is unclear whether the representations produced by such models are semantically meaningful. In this paper, using a projected gradient-based algorithm, we show that their representations are not semantically meaningful and they are inherently vulnerable to small changes. Images with imperceptible differences can have very different representations; on the other hand, images that should belong to different semantic classes can have nearly identical representations. Such vulnerability can lead to unreliable classification results; for example, unnoticeable changes cause the classification accuracy to be reduced by over 60\\%. %. To the best of our knowledge, this is the first work to systematically demonstrate this fundamental lack of semantic meaningfulness in ViT representations for medical image classification, revealing a critical challenge for their deployment in safety-critical systems.</article>","contentLength":1305,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"From Reports to Reality: Testing Consistency in Instagram's Digital Services Act Compliance Data","url":"https://arxiv.org/abs/2507.01787","date":1751515200,"author":"","guid":182162,"unread":true,"content":"<article>arXiv:2507.01787v1 Announce Type: new \nAbstract: The Digital Services Act (DSA) introduces harmonized rules for content moderation and platform governance in the European Union, mandating robust compliance mechanisms, particularly for very large online platforms and search engines. This study examined compliance with DSA requirements, focusing on Instagram as a case study. We develop and apply a multi-level consistency framework to evaluate DSA compliance. Our findings contribute to the broader discussion on empirically-based regulation, providing insight into how researchers, regulators, auditors and platforms can better utilize DSA mechanisms to improve reporting and enforcement quality and accountability. This work underscores that consistency can help detect potential compliance failures. It also demonstrates that platforms should be evaluated as part of an interconnected ecosystem rather than through isolated processes, which is crucial for effective compliance evaluation under the DSA.</article>","contentLength":1006,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Probing Evaluation Awareness of Language Models","url":"https://arxiv.org/abs/2507.01786","date":1751515200,"author":"","guid":182163,"unread":true,"content":"<article>arXiv:2507.01786v1 Announce Type: new \nAbstract: Language models can distinguish between testing and deployment phases -- a capability known as evaluation awareness. This has significant safety and policy implications, potentially undermining the reliability of evaluations that are central to AI governance frameworks and voluntary industry commitments. In this paper, we study evaluation awareness in Llama-3.3-70B-Instruct. We show that linear probes can separate real-world evaluation and deployment prompts, suggesting that current models internally represent this distinction. We also find that current safety evaluations are correctly classified by the probes, suggesting that they already appear artificial or inauthentic to models. Our findings underscore the importance of ensuring trustworthy evaluations and understanding deceptive capabilities. More broadly, our work showcases how model internals may be leveraged to support blackbox methods in safety audits, especially for future models more competent at evaluation awareness and deception.</article>","contentLength":1056,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining","url":"https://arxiv.org/abs/2507.01785","date":1751515200,"author":"","guid":182164,"unread":true,"content":"<article>arXiv:2507.01785v1 Announce Type: new \nAbstract: Data quality is a critical driver of large language model performance, yet existing model-based selection methods focus almost exclusively on English. We introduce MuRating, a scalable framework that transfers high-quality English data-quality signals into a single rater for 17 target languages. MuRating aggregates multiple English \"raters\" via pairwise comparisons to learn unified document-quality scores,then projects these judgments through translation to train a multilingual evaluator on monolingual, cross-lingual, and parallel text pairs. Applied to web data, MuRating selects balanced subsets of English and multilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to strong baselines, including QuRater, AskLLM, DCLM and so on, our approach boosts average accuracy on both English benchmarks and multilingual evaluations, with especially large gains on knowledge-intensive tasks. We further analyze translation fidelity, selection biases, and underrepresentation of narrative material, outlining directions for future work.</article>","contentLength":1100,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ASTARS empowered Satellite Positioning Approach for Urban Canyons and Indoor Environments","url":"https://arxiv.org/abs/2507.01783","date":1751515200,"author":"","guid":182165,"unread":true,"content":"<article>arXiv:2507.01783v1 Announce Type: new \nAbstract: To mitigate the loss of satellite navigation signals in urban canyons and indoor environments, we propose an active simultaneous transmitting and reflecting reconfigurable intelligent surface (ASTARS) empowered satellite positioning approach. Deployed on building structures, ASTARS reflects navigation signals to outdoor receivers in urban canyons and transmits signals indoors to bypass obstructions, providing high-precision positioning services to receivers in non-line-of-sight (NLoS) areas. The path between ASTARS and the receiver is defined as the extended line-of-sight (ELoS) path and an improved carrier phase observation equation is derived to accommodate that. The receiver compensates for its clock bias through network time synchronization, corrects the actual signal path distance to the satellite-to-receiver distance through a distance correction algorithm, and determines its position by using the least squares (LS) method. Mathematical modeling of the errors introduced by the proposed method is conducted, followed by simulation analysis to assess their impact. Simulation results show that: 1) in areas where GNSS signals are blocked, with time synchronization accuracy within a 10 ns error range, the proposed method provides positioning services with errors not exceeding 4 m for both indoor and outdoor receivers, outperforming conventional NLoS methods with positioning errors of more than 7 m; 2) the additional errors introduced by the proposed method do not exceed 3 m for time synchronization errors within 10 ns, which includes the phase shift, beamwidth error, time synchronization errors, and satellite distribution errors, outperforming traditional NLoS methods, which typically produce positioning errors greater than 5 m.</article>","contentLength":1807,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Symbiotic Backscatter Communication: A Design Perspective on the Modulation Scheme of Backscatter Devices","url":"https://arxiv.org/abs/2507.01782","date":1751515200,"author":"","guid":182166,"unread":true,"content":"<article>arXiv:2507.01782v1 Announce Type: new \nAbstract: Symbiotic Backscatter Communication (SBC) has emerged as a spectrum-efficient and low-power communication technology, where backscatter devices (BDs) modulate and reflect incident radio frequency (RF) signals from primary transmitters (PTs). While previous studies have assumed a circularly symmetric complex Gaussian (CSCG) distribution for the BD's signal, this assumption may not be practical because the high complexity of generating CSCG signals is not supported by the low-cost BD. In this paper, we address this gap by investigating SBC for two low-complexity modulation schemes, i.e., $M$-ary amplitude-shift keying (MASK) and $M$-ary phase-shift keying (MPSK), where BD's signals inherently deviate from CSCG distribution. Our goal is to derive the achievable rate of the PT and BD under the MASK/MPSK and to design MASK/MPSK modulation scheme for maximizing the PT's rate. Towards this end, we first derive the expressions of both the PT's rate and BD's rate. Theoretical results reveal that whether or not the BD improves the PT's rate depends on the phase of MASK/MPSK modulation, while the BD's rate is independent of this phase. We then formulate two optimization problems to maximize the PT's rate by adjusting the phase under the MASK and MPSK modulation schemes, respectively, and derive the optimal phases for each modulation scheme in closed forms. Simulation results demonstrate that the optimal phase of MASK/MPSK can ensure an improvement in the PT's rate, and reveal that a low-order ASK modulation is better than a low-order PSK for the BD in terms of improving PT's rate, especially when the direct link is not significantly weaker than the backscatter link in SBC.</article>","contentLength":1739,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BranchNet: A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification","url":"https://arxiv.org/abs/2507.01781","date":1751515200,"author":"","guid":182167,"unread":true,"content":"<article>arXiv:2507.01781v1 Announce Type: new \nAbstract: We introduce BranchNet, a neuro-symbolic learning framework that transforms decision tree ensembles into sparse, partially connected neural networks. Each branch, defined as a decision path from root to a parent of leaves, is mapped to a hidden neuron, preserving symbolic structure while enabling gradient-based optimization. The resulting models are compact, interpretable, and require no manual architecture tuning. Evaluated on a suite of structured multi-class classification benchmarks, BranchNet consistently outperforms XGBoost in accuracy, with statistically significant gains. We detail the architecture, training procedure, and sparsity dynamics, and discuss the model's strengths in symbolic interpretability as well as its current limitations, particularly on binary tasks where further adaptive calibration may be beneficial.</article>","contentLength":888,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LeanLTL: A unifying framework for linear temporal logics in Lean","url":"https://arxiv.org/abs/2507.01780","date":1751515200,"author":"","guid":182168,"unread":true,"content":"<article>arXiv:2507.01780v1 Announce Type: new \nAbstract: We propose LeanLTL, a unifying framework for linear temporal logics in Lean 4. LeanLTL supports reasoning about traces that represent either infinite or finite linear time. The library allows traditional LTL syntax to be combined with arbitrary Lean expressions, making it straightforward to define properties involving numerical or other types. We prove that standard flavors of LTL can be embedded in our framework. The library also provides automation for reasoning about LeanLTL formulas in a way that facilitates using Lean's existing tactics. Finally, we provide examples illustrating the utility of the library in reasoning about systems that come from applications.</article>","contentLength":722,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"S3D: A Spatial Steerable Surgical Drilling Framework for Robotic Spinal Fixation Procedures","url":"https://arxiv.org/abs/2507.01779","date":1751515200,"author":"","guid":182169,"unread":true,"content":"<article>arXiv:2507.01779v1 Announce Type: new \nAbstract: In this paper, we introduce S3D: A Spatial Steerable Surgical Drilling Framework for Robotic Spinal Fixation Procedures. S3D is designed to enable realistic steerable drilling while accounting for the anatomical constraints associated with vertebral access in spinal fixation (SF) procedures. To achieve this, we first enhanced our previously designed concentric tube Steerable Drilling Robot (CT-SDR) to facilitate steerable drilling across all vertebral levels of the spinal column. Additionally, we propose a four-Phase calibration, registration, and navigation procedure to perform realistic SF procedures on a spine holder phantom by integrating the CT-SDR with a seven-degree-of-freedom robotic manipulator. The functionality of this framework is validated through planar and out-of-plane steerable drilling experiments in vertebral phantoms.</article>","contentLength":897,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Hybrid Ensemble Learning Framework for Image-Based Solar Panel Classification","url":"https://arxiv.org/abs/2507.01778","date":1751515200,"author":"","guid":182170,"unread":true,"content":"<article>arXiv:2507.01778v1 Announce Type: new \nAbstract: The installation of solar energy systems is on the rise, and therefore, appropriate maintenance techniques are required to be used in order to maintain maximum performance levels. One of the major challenges is the automated discrimination between clean and dirty solar panels. This paper presents a novel Dual Ensemble Neural Network (DENN) to classify solar panels using image-based features. The suggested approach utilizes the advantages offered by various ensemble models by integrating them into a dual framework, aimed at improving both classification accuracy and robustness. The DENN model is evaluated in comparison to current ensemble methods, showcasing its superior performance across a range of assessment metrics. The proposed approach performs the best compared to other methods and reaches state-of-the-art accuracy on experimental results for the Deep Solar Eye dataset, effectively serving predictive maintenance purposes in solar energy systems. It reveals the potential of hybrid ensemble learning techniques to further advance the prospects of automated solar panel inspections as a scalable solution to real-world challenges.</article>","contentLength":1197,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Human-Machine Collaboration-Guided Space Design: Combination of Machine Learning Models and Humanistic Design Concepts","url":"https://arxiv.org/abs/2507.01776","date":1751515200,"author":"","guid":182171,"unread":true,"content":"<article>arXiv:2507.01776v1 Announce Type: new \nAbstract: The integration of machine learning (ML) into spatial design holds immense potential for optimizing space utilization, enhancing functionality, and streamlining design processes. ML can automate tasks, predict performance outcomes, and tailor spaces to user preferences. However, the emotional, cultural, and aesthetic dimensions of design remain crucial for creating spaces that truly resonate with users-elements that ML alone cannot address. The key challenge lies in harmonizing data-driven efficiency with the nuanced, subjective aspects of design. This paper proposes a human-machine collaboration framework to bridge this gap. An effective framework should recognize that while ML enhances design efficiency through automation and prediction, it must be paired with human creativity to ensure spaces are emotionally engaging and culturally relevant. Human designers contribute intuition, empathy, and cultural insight, guiding ML-generated solutions to align with users' emotional and cultural needs. Additionally, we explore how various ML models can be integrated with human-centered design principles. These models can automate design generation and optimization, while human designers refine the outputs to ensure emotional resonance and aesthetic appeal. Through case studies in office and residential design, we illustrate how this framework fosters both creativity and cultural relevance. By merging ML with human creativity, spatial design can achieve a balance of efficiency and emotional impact, resulting in environments that are both functional and deeply human.</article>","contentLength":1630,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Deterministic Partition Tree and Applications","url":"https://arxiv.org/abs/2507.01775","date":1751515200,"author":"","guid":182172,"unread":true,"content":"<article>arXiv:2507.01775v1 Announce Type: new \nAbstract: In this paper, we present a deterministic variant of Chan's randomized partition tree [Discret. Comput. Geom., 2012]. This result leads to numerous applications. In particular, for $d$-dimensional simplex range counting (for any constant $d \\ge 2$), we construct a data structure using $O(n)$ space and $O(n^{1+\\epsilon})$ preprocessing time, such that each query can be answered in $o(n^{1-1/d})$ time (specifically, $O(n^{1-1/d} / \\log^{\\Omega(1)} n)$ time), thereby breaking an $\\Omega(n^{1-1/d})$ lower bound known for the semigroup setting. Notably, our approach does not rely on any bit-packing techniques. We also obtain deterministic improvements for several other classical problems, including simplex range stabbing counting and reporting, segment intersection detection, counting and reporting, ray-shooting among segments, and more. Similar to Chan's original randomized partition tree, we expect that additional applications will emerge in the future, especially in situations where deterministic results are preferred.</article>","contentLength":1081,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Frontiers of Generative AI for Network Optimization: Theories, Limits, and Visions","url":"https://arxiv.org/abs/2507.01773","date":1751515200,"author":"","guid":182173,"unread":true,"content":"<article>arXiv:2507.01773v1 Announce Type: new \nAbstract: While interest in the application of generative AI (GenAI) in network optimization has surged in recent years, its rapid progress has often overshadowed critical limitations intrinsic to generative models that remain insufficiently examined in existing literature. This survey provides a comprehensive review and critical analysis of GenAI in network optimization. We focus on the two dominant paradigms of GenAI including generative diffusion models (GDMs) and large pre-trained models (LPTMs), and organize our discussion around a categorization we introduce, dividing network optimization problems into two primary formulations: one-shot optimization and Markov decision process (MDP). We first trace key works, including foundational contributions from the AI community, and categorize current efforts in network optimization. We also review frontier applications of GDMs and LPTMs in other networking tasks, providing additional context. Furthermore, we present theoretical generalization bounds for GDMs in both one-shot and MDP settings, offering insights into the fundamental factors affecting model performance. Most importantly, we reflect on the overestimated perception of GenAI's general capabilities and caution against the all-in-one illusion it may convey. We highlight critical limitations, including difficulties in constraint satisfying, limited concept understanding, and the inherent probabilistic nature of outputs. We also propose key future directions, such as bridging the gap between generation and optimization. Although they are increasingly integrated in implementations, they differ fundamentally in both objectives and underlying mechanisms, necessitating a deeper understanding of their theoretical connections. Ultimately, this survey aims to provide a structured overview and a deeper insight into the strengths, limitations, and potential of GenAI in network optimization.</article>","contentLength":1956,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GPU-based complete search for nonlinear minimization subject to bounds","url":"https://arxiv.org/abs/2507.01770","date":1751515200,"author":"","guid":182174,"unread":true,"content":"<article>arXiv:2507.01770v1 Announce Type: new \nAbstract: This paper introduces a GPU-based complete search method to enclose the global minimum of a nonlinear function subject to simple bounds on the variables. Using interval analysis, coupled with the computational power and architecture of GPU, the method iteratively rules out the regions in the search domain where the global minimum cannot exist and leaves a finite set of regions where the global minimum must exist. For effectiveness, because of the rigor of interval analysis, the method is guaranteed to enclose the global minimum of the nonlinear function even in the presence of rounding errors. For efficiency, the method employs a novel GPU-based single program, single data parallel programming style to circumvent major GPU performance bottlenecks, and a variable cycling technique is also integrated into the method to reduce computational cost when minimizing large-scale nonlinear functions. The method is validated by minimizing 10 multimodal benchmark test functions with scalable dimensions, including the well-known Ackley function, Griewank function, Levy function, and Rastrigin function. These benchmark test functions represent grand challenges of global optimization, and enclosing the guaranteed global minimum of these benchmark test functions with more than 80 dimensions has not been reported in the literature. Our method completely searches the feasible domain and successfully encloses the guaranteed global minimum of these 10 benchmark test functions with up to 10,000 dimensions using only one GPU in a reasonable computation time, far exceeding the reported results in the literature due to the unique method design and implementation based on GPU architecture.</article>","contentLength":1742,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Distance-based Relative Orbital Transition for Satellite Swarm Array Deployment Under J2 Perturbation","url":"https://arxiv.org/abs/2507.01769","date":1751515200,"author":"","guid":182175,"unread":true,"content":"<article>arXiv:2507.01769v1 Announce Type: new \nAbstract: This paper presents an autonomous guidance and control strategy for a satellite swarm that enables scalable distributed space structures for innovative science and business opportunities. The averaged $J_2$ orbital parameters that describe the drift and periodic orbital motion were derived along with their target values to achieve a distributed space structure in a decentralized manner. This enabled the design of a distance-based orbital stabilizer to ensure autonomous deployment into a monolithic formation of a coplanar equidistant configuration on a user-defined orbital plane. Continuous formation control was assumed to be achieved through fuel-free actuation, such as satellite magnetic field interaction and differential aerodynamic forces, thereby maintaining long-term formation stability without thruster usage. A major challenge for such actuation systems is the potential loss of control capability due to increasing inter-satellite distances resulting from unstable orbital dynamics, particularly for autonomous satellite swarms. To mitigate this risk, our decentralized deployment controller minimized drift distance during unexpected communication outages. As a case study, we consider the deployment of palm-sized satellites into a coplanar equidistant formation in a $J_2$-perturbed orbit. Moreover, centralized grouping strategies are presented.</article>","contentLength":1417,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Signals and Symptoms: ICS Attack Dataset From Railway Cyber Range","url":"https://arxiv.org/abs/2507.01768","date":1751515200,"author":"","guid":182176,"unread":true,"content":"<article>arXiv:2507.01768v1 Announce Type: new \nAbstract: The prevalence of cyberattacks on Industrial Control Systems (ICS) has highlighted the necessity for robust security measures and incident response to protect critical infrastructure. This is prominent when Operational Technology (OT) systems undergo digital transformation by integrating with Information Technology (IT) systems to enhance operational efficiency, adaptability, and safety. To support analysts in staying abreast of emerging attack patterns, there is a need for ICS datasets that reflect indicators representative of contemporary cyber threats. To address this, we conduct two ICS cyberattack simulations to showcase the impact of trending ICS cyberattacks on a railway cyber range that resembles the railway infrastructure. The attack scenario is designed to blend trending attack trends with attack patterns observed from historical ICS incidents. The resulting evidence is collected as datasets, serving as an essential resource for cyberattack analysis. This captures key indicators that are relevant to the current threat landscape, augmenting the effectiveness of security systems and analysts to protect against ICS cyber threats.</article>","contentLength":1203,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reconfigurable Intelligent Surface aided Integrated-Navigation-and-Communication in Urban Canyons: A Satellite Selection Approach","url":"https://arxiv.org/abs/2507.01766","date":1751515200,"author":"","guid":182177,"unread":true,"content":"<article>arXiv:2507.01766v1 Announce Type: new \nAbstract: This study investigates the application of a simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided medium-Earth-orbit (MEO) satellite network for providing both global positioning services and communication services in the urban canyons, where the direct satellite-user links are obstructed. Superposition coding (SC) and successive interference cancellation (SIC) techniques are utilized for the integrated navigation and communication (INAC) networks, and the composed navigation and communication signals are reflected or transmitted to ground users or indoor users located in urban canyons. To meet diverse application needs, navigation-oriented (NO)-INAC and communication-oriented (CO)-INAC have been developed, each tailored according to distinct power allocation factors. We then proposed two algorithms, namely navigation-prioritized-algorithm (NPA) and communication-prioritized-algorithm (CPA), to improve the navigation or communication performance by selecting the satellite with the optimized position dilution of precision (PDoP) or with the best channel gain. The effectiveness of the proposed STAR-RIS-aided INAC network is quantified by analyzing the positioning error for navigation services and by evaluating communication performance through achievable ergodic rate metrics. Our satellite selection approach indicates that: the positioning services at the urban canyon users can be completed with the aid of STAR-RIS. 2) Additionally, it is observed that while a single STAR-RIS array can extend the navigational link, it fails to serve users in indoor scenarios, highlighting a limitation in the current system design.</article>","contentLength":1728,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Data interference: emojis, homoglyphs, and issues of data fidelity in corpora and their results","url":"https://arxiv.org/abs/2507.01764","date":1751515200,"author":"","guid":182178,"unread":true,"content":"<article>arXiv:2507.01764v1 Announce Type: new \nAbstract: Tokenisation - \"the process of splitting text into atomic parts\" (Brezina &amp; Timperley, 2017: 1) - is a crucial step for corpus linguistics, as it provides the basis for any applicable quantitative method (e.g. collocations) while ensuring the reliability of qualitative approaches. This paper examines how discrepancies in tokenisation affect the representation of language data and the validity of analytical findings: investigating the challenges posed by emojis and homoglyphs, the study highlights the necessity of preprocessing these elements to maintain corpus fidelity to the source data. The research presents methods for ensuring that digital texts are accurately represented in corpora, thereby supporting reliable linguistic analysis and guaranteeing the repeatability of linguistic interpretations. The findings emphasise the necessity of a detailed understanding of both linguistic and technical aspects involved in digital textual data to enhance the accuracy of corpus analysis, and have significant implications for both quantitative and qualitative approaches in corpus-based research.</article>","contentLength":1151,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination","url":"https://arxiv.org/abs/2507.01762","date":1751515200,"author":"","guid":182179,"unread":true,"content":"<article>arXiv:2507.01762v1 Announce Type: new \nAbstract: The quality of simplex mesh is crucial for the stability and accuracy of numerical simulations in finite element analysis and computational geometry. However, the presence of sliver elements in 3D simplex mesh can severely impact the results. This paper presents a novel method based on a radius ratio energy function to optimize the quality of simplex mesh elements. This method can effectively eliminate sliver elements, thereby enhancing mesh quality.The gradient of the proposed energy function can be decomposed into a matrix-vector product. With minor processing, the matrix becomes symmetric positive definite, and this symmetric positive definite matrix can serve as a preconditioner to significantly accelerate the optimization process. Experimental results demonstrate that this method has significant advantages in eliminating sliver elements and improving mesh quality.</article>","contentLength":930,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Enhanced Generative Model Evaluation with Clipped Density and Coverage","url":"https://arxiv.org/abs/2507.01761","date":1751515200,"author":"","guid":182180,"unread":true,"content":"<article>arXiv:2507.01761v1 Announce Type: new \nAbstract: Although generative models have made remarkable progress in recent years, their use in critical applications has been hindered by their incapacity to reliably evaluate sample quality. Quality refers to at least two complementary concepts: fidelity and coverage. Current quality metrics often lack reliable, interpretable values due to an absence of calibration or insufficient robustness to outliers. To address these shortcomings, we introduce two novel metrics, Clipped Density and Clipped Coverage. By clipping individual sample contributions and, for fidelity, the radii of nearest neighbor balls, our metrics prevent out-of-distribution samples from biasing the aggregated values. Through analytical and empirical calibration, these metrics exhibit linear score degradation as the proportion of poor samples increases. Thus, they can be straightforwardly interpreted as equivalent proportions of good samples. Extensive experiments on synthetic and real-world datasets demonstrate that Clipped Density and Clipped Coverage outperform existing methods in terms of robustness, sensitivity, and interpretability for evaluating generative models.</article>","contentLength":1196,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Scheduling on identical machines with conflicts to minimize the mean flow time","url":"https://arxiv.org/abs/2507.01759","date":1751515200,"author":"","guid":182181,"unread":true,"content":"<article>arXiv:2507.01759v1 Announce Type: new \nAbstract: This paper addresses the problem of scheduling jobs on identical machines with conflict constraints, where certain jobs cannot be scheduled simultaneously on different machines. We focus on the case where conflicts can be represented by a simple undirected graph, and the objective is to minimize the mean flow time. We show that the problem is NP-hard even on two machines and two distinct processing times. For unit-time jobs, the problem becomes NP-hard when the number of machines increases to three. We also identify polynomial-time solvable cases for specific classes of conflict graphs. For the general problem, we propose mathematical models, lower bounds, and a genetic algorithm. We evaluate their performance through computational experiments on a wide range of instances derived from well-known benchmark instances in the literature.</article>","contentLength":894,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis","url":"https://arxiv.org/abs/2507.01756","date":1751515200,"author":"","guid":182182,"unread":true,"content":"<article>arXiv:2507.01756v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have spurred interests in encoding images as discrete tokens and leveraging autoregressive (AR) frameworks for visual generation. However, the quantization process in AR-based visual generation models inherently introduces information loss that degrades image fidelity. To mitigate this limitation, recent studies have explored to autoregressively predict continuous tokens. Unlike discrete tokens that reside in a structured and bounded space, continuous representations exist in an unbounded, high-dimensional space, making density estimation more challenging and increasing the risk of generating out-of-distribution artifacts. Based on the above findings, this work introduces DisCon (Discrete-Conditioned Continuous Autoregressive Model), a novel framework that reinterprets discrete tokens as conditional signals rather than generation targets. By modeling the conditional probability of continuous representations conditioned on discrete tokens, DisCon circumvents the optimization challenges of continuous token modeling while avoiding the information loss caused by quantization. DisCon achieves a gFID score of 1.38 on ImageNet 256$\\times$256 generation, outperforming state-of-the-art autoregressive approaches by a clear margin.</article>","contentLength":1337,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PathDB: A system for evaluating regular path queries","url":"https://arxiv.org/abs/2507.01755","date":1751515200,"author":"","guid":182183,"unread":true,"content":"<article>arXiv:2507.01755v1 Announce Type: new \nAbstract: PathDB is a Java-based graph database designed for in-memory data loading and querying. By utilizing Regular Path Queries (RPQ) and a closed path algebra, PathDB processes paths through its three main components: the parser, the logical plan, and the physical plan. This modular design allows for targeted optimizations and modifications without impacting overall functionality. Benchmark experiments illustrate PathDB's execution times and flexibility in handling dynamic and complex path queries, compared to baseline methods like Depth-First Search (DFS) and Breadth-First Search (BFS) guided by an automaton, highlighting its optimizations that contribute to its performance.</article>","contentLength":728,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Augmented Bridge Spinal Fixation: A New Concept for Addressing Pedicle Screw Pullout via a Steerable Drilling Robot and Flexible Pedicle Screws","url":"https://arxiv.org/abs/2507.01753","date":1751515200,"author":"","guid":182184,"unread":true,"content":"<article>arXiv:2507.01753v1 Announce Type: new \nAbstract: To address the screw loosening and pullout limitations of rigid pedicle screws in spinal fixation procedures, and to leverage our recently developed Concentric Tube Steerable Drilling Robot (CT-SDR) and Flexible Pedicle Screw (FPS), in this paper, we introduce the concept of Augmented Bridge Spinal Fixation (AB-SF). In this concept, two connecting J-shape tunnels are first drilled through pedicles of vertebra using the CT-SDR. Next, two FPSs are passed through this tunnel and bone cement is then injected through the cannulated region of the FPS to form an augmented bridge between two pedicles and reinforce strength of the fixated spine. To experimentally analyze and study the feasibility of AB-SF technique, we first used our robotic system (i.e., a CT-SDR integrated with a robotic arm) to create two different fixation scenarios in which two J-shape tunnels, forming a bridge, were drilled at different depth of a vertebral phantom. Next, we implanted two FPSs within the drilled tunnels and then successfully simulated the bone cement augmentation process.</article>","contentLength":1117,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training","url":"https://arxiv.org/abs/2507.01752","date":1751515200,"author":"","guid":182185,"unread":true,"content":"<article>arXiv:2507.01752v1 Announce Type: new \nAbstract: Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, its reliance on large volumes of labeled data raises privacy and security concerns such as susceptibility to data poisoning attacks and the risk of overfitting. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. However, black box methods also pose significant challenges, including poor scalability to high-dimensional parameter spaces, as prevalent in large language models (LLMs), and high computational costs due to reliance on numerous model evaluations. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide strong theoretical bounds on generalization, differential privacy, susceptibility to data poisoning attacks, and robustness to extraction attacks. BBoxER operates on top of pre-trained LLMs, offering a lightweight and modular enhancement suitable for deployment in restricted or privacy-sensitive environments, in addition to non-vacuous generalization guarantees. In experiments with LLMs, we demonstrate empirically that Retrofitting methods are able to learn, showing how a few iterations of BBoxER improve performance and generalize well on a benchmark of reasoning datasets. This positions BBoxER as an attractive add-on on top of gradient-based optimization.</article>","contentLength":1772,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Joint Matching and Pricing for Crowd-shipping with In-store Customers","url":"https://arxiv.org/abs/2507.01749","date":1751515200,"author":"","guid":182186,"unread":true,"content":"<article>arXiv:2507.01749v1 Announce Type: new \nAbstract: This paper examines the use of in-store customers as delivery couriers in a centralized crowd-shipping system, targeting the growing need for efficient last-mile delivery in urban areas. We consider a brick-and-mortar retail setting where shoppers are offered compensation to deliver time-sensitive online orders. To manage this process, we propose a Markov Decision Process (MDP) model that captures key uncertainties, including the stochastic arrival of orders and crowd-shippers, and the probabilistic acceptance of delivery offers. Our solution approach integrates Neural Approximate Dynamic Programming (NeurADP) for adaptive order-to-shopper assignment with a Deep Double Q-Network (DDQN) for dynamic pricing. This joint optimization strategy enables multi-drop routing and accounts for offer acceptance uncertainty, aligning more closely with real-world operations. Experimental results demonstrate that the integrated NeurADP + DDQN policy achieves notable improvements in delivery cost efficiency, with up to 6.7\\% savings over NeurADP with fixed pricing and approximately 18\\% over myopic baselines. We also show that allowing flexible delivery delays and enabling multi-destination routing further reduces operational costs by 8\\% and 17\\%, respectively. These findings underscore the advantages of dynamic, forward-looking policies in crowd-shipping systems and offer practical guidance for urban logistics operators.</article>","contentLength":1478,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SSL4SAR: Self-Supervised Learning for Glacier Calving Front Extraction from SAR Imagery","url":"https://arxiv.org/abs/2507.01747","date":1751515200,"author":"","guid":182187,"unread":true,"content":"<article>arXiv:2507.01747v1 Announce Type: new \nAbstract: Glaciers are losing ice mass at unprecedented rates, increasing the need for accurate, year-round monitoring to understand frontal ablation, particularly the factors driving the calving process. Deep learning models can extract calving front positions from Synthetic Aperture Radar imagery to track seasonal ice losses at the calving fronts of marine- and lake-terminating glaciers. The current state-of-the-art model relies on ImageNet-pretrained weights. However, they are suboptimal due to the domain shift between the natural images in ImageNet and the specialized characteristics of remote sensing imagery, in particular for Synthetic Aperture Radar imagery. To address this challenge, we propose two novel self-supervised multimodal pretraining techniques that leverage SSL4SAR, a new unlabeled dataset comprising 9,563 Sentinel-1 and 14 Sentinel-2 images of Arctic glaciers, with one optical image per glacier in the dataset. Additionally, we introduce a novel hybrid model architecture that combines a Swin Transformer encoder with a residual Convolutional Neural Network (CNN) decoder. When pretrained on SSL4SAR, this model achieves a mean distance error of 293 m on the \"CAlving Fronts and where to Find thEm\" (CaFFe) benchmark dataset, outperforming the prior best model by 67 m. Evaluating an ensemble of the proposed model on a multi-annotator study of the benchmark dataset reveals a mean distance error of 75 m, approaching the human performance of 38 m. This advancement enables precise monitoring of seasonal changes in glacier calving fronts.</article>","contentLength":1610,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans","url":"https://arxiv.org/abs/2507.01744","date":1751515200,"author":"","guid":182188,"unread":true,"content":"<article>arXiv:2507.01744v1 Announce Type: new \nAbstract: Vision Transformers (ViTs) have gained significant popularity in the natural image domain but have been less successful in 3D medical image segmentation. Nevertheless, 3D ViTs are particularly interesting for large medical imaging volumes due to their efficient self-supervised training within the masked autoencoder (MAE) framework, which enables the use of imaging data without the need for expensive manual annotations. intracranial arterial calcification (IAC) is an imaging biomarker visible on routinely acquired CT scans linked to neurovascular diseases such as stroke and dementia, and automated IAC quantification could enable their large-scale risk assessment. We pre-train ViTs with MAE and fine-tune them for IAC segmentation for the first time. To develop our models, we use highly heterogeneous data from a large clinical trial, the third International Stroke Trial (IST-3). We evaluate key aspects of MAE pre-trained ViTs in IAC segmentation, and analyse the clinical implications. We show: 1) our calibrated self-supervised ViT beats a strong supervised nnU-Net baseline by 3.2 Dice points, 2) low patch sizes are crucial for ViTs for IAC segmentation and interpolation upsampling with regular convolutions is preferable to transposed convolutions for ViT-based models, and 3) our ViTs increase robustness to higher slice thicknesses and improve risk group classification in a clinical scenario by 46%. Our code is available online.</article>","contentLength":1497,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based Inference","url":"https://arxiv.org/abs/2507.01740","date":1751515200,"author":"","guid":182189,"unread":true,"content":"<article>arXiv:2507.01740v1 Announce Type: new \nAbstract: Accurately estimating parameters of physiological models is essential to achieving reliable digital twins. For Type 1 Diabetes, this is particularly challenging due to the complexity of glucose-insulin interactions. Traditional methods based on Markov Chain Monte Carlo struggle with high-dimensional parameter spaces and fit parameters from scratch at inference time, making them slow and computationally expensive. In this study, we propose a Simulation-Based Inference approach based on Neural Posterior Estimation to efficiently capture the complex relationships between meal intake, insulin, and glucose level, providing faster, amortized inference. Our experiments demonstrate that SBI not only outperforms traditional methods in parameter estimation but also generalizes better to unseen conditions, offering real-time posterior inference with reliable uncertainty quantification.</article>","contentLength":936,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy","url":"https://arxiv.org/abs/2507.01738","date":1751515200,"author":"","guid":182190,"unread":true,"content":"<article>arXiv:2507.01738v1 Announce Type: new \nAbstract: Referring Image Segmentation (RIS) is a challenging task that aims to segment objects in an image based on natural language expressions. While prior studies have predominantly concentrated on improving vision-language interactions and achieving fine-grained localization, a systematic analysis of the fundamental bottlenecks in existing RIS frameworks remains underexplored. To bridge this gap, we propose DeRIS, a novel framework that decomposes RIS into two key components: perception and cognition. This modular decomposition facilitates a systematic analysis of the primary bottlenecks impeding RIS performance. Our findings reveal that the predominant limitation lies not in perceptual deficiencies, but in the insufficient multi-modal cognitive capacity of current models. To mitigate this, we propose a Loopback Synergy mechanism, which enhances the synergy between the perception and cognition modules, thereby enabling precise segmentation while simultaneously improving robust image-text comprehension. Additionally, we analyze and introduce a simple non-referent sample conversion data augmentation to address the long-tail distribution issue related to target existence judgement in general scenarios. Notably, DeRIS demonstrates inherent adaptability to both non- and multi-referents scenarios without requiring specialized architectural modifications, enhancing its general applicability. The codes and models are available at https://github.com/Dmmm1997/DeRIS.</article>","contentLength":1524,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion","url":"https://arxiv.org/abs/2507.01737","date":1751515200,"author":"","guid":182191,"unread":true,"content":"<article>arXiv:2507.01737v1 Announce Type: new \nAbstract: Generating realistic 3D human-object interactions (HOIs) remains a challenging task due to the difficulty of modeling detailed interaction dynamics. Existing methods treat human and object motions independently, resulting in physically implausible and causally inconsistent behaviors. In this work, we present HOI-Dyn, a novel framework that formulates HOI generation as a driver-responder system, where human actions drive object responses. At the core of our method is a lightweight transformer-based interaction dynamics model that explicitly predicts how objects should react to human motion. To further enforce consistency, we introduce a residual-based dynamics loss that mitigates the impact of dynamics prediction errors and prevents misleading optimization signals. The dynamics model is used only during training, preserving inference efficiency. Through extensive qualitative and quantitative experiments, we demonstrate that our approach not only enhances the quality of HOI generation but also establishes a feasible metric for evaluating the quality of generated interactions.</article>","contentLength":1139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An energy-based discontinuous Galerkin method for the wave equation with nonsmooth solutions","url":"https://arxiv.org/abs/2507.01736","date":1751515200,"author":"","guid":182192,"unread":true,"content":"<article>arXiv:2507.01736v1 Announce Type: new \nAbstract: We develop a stable and high-order accurate discontinuous Galerkin method for the second order wave equation, specifically designed to handle nonsmooth solutions. Our approach integrates the energy-based discontinuous Galerkin method with the oscillation-free technique to effectively suppress spurious oscillations near solution discontinuities. Both stability analysis and apriori error estimates are established for common choices of numerical fluxes. We present a series of numerical experiments to confirm the optimal convergence rates for smooth solutions and its robustness in maintaining oscillation-free behavior for nonsmooth solutions in wave equations without or with nonlinear source terms.</article>","contentLength":752,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving","url":"https://arxiv.org/abs/2507.01735","date":1751515200,"author":"","guid":182193,"unread":true,"content":"<article>arXiv:2507.01735v1 Announce Type: new \nAbstract: In this paper, we present details of the 1st W-CODA workshop, held in conjunction with the ECCV 2024. W-CODA aims to explore next-generation solutions for autonomous driving corner cases, empowered by state-of-the-art multimodal perception and comprehension techniques. 5 Speakers from both academia and industry are invited to share their latest progress and opinions. We collect research papers and hold a dual-track challenge, including both corner case scene understanding and generation. As the pioneering effort, we will continuously bridge the gap between frontier autonomous driving techniques and fully intelligent, reliable self-driving agents robust towards corner cases.</article>","contentLength":731,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LLMs for Legal Subsumption in German Employment Contracts","url":"https://arxiv.org/abs/2507.01734","date":1751515200,"author":"","guid":182194,"unread":true,"content":"<article>arXiv:2507.01734v1 Announce Type: new \nAbstract: Legal work, characterized by its text-heavy and resource-intensive nature, presents unique challenges and opportunities for NLP research. While data-driven approaches have advanced the field, their lack of interpretability and trustworthiness limits their applicability in dynamic legal environments. To address these issues, we collaborated with legal experts to extend an existing dataset and explored the use of Large Language Models (LLMs) and in-context learning to evaluate the legality of clauses in German employment contracts. Our work evaluates the ability of different LLMs to classify clauses as \"valid,\" \"unfair,\" or \"void\" under three legal context variants: no legal context, full-text sources of laws and court rulings, and distilled versions of these (referred to as examination guidelines). Results show that full-text sources moderately improve performance, while examination guidelines significantly enhance recall for void clauses and weighted F1-Score, reaching 80\\%. Despite these advancements, LLMs' performance when using full-text sources remains substantially below that of human lawyers. We contribute an extended dataset, including examination guidelines, referenced legal sources, and corresponding annotations, alongside our code and all log files. Our findings highlight the potential of LLMs to assist lawyers in contract legality review while also underscoring the limitations of the methods presented.</article>","contentLength":1485,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A trust-region framework for optimization using Hermite kernel surrogate models","url":"https://arxiv.org/abs/2507.01729","date":1751515200,"author":"","guid":182195,"unread":true,"content":"<article>arXiv:2507.01729v1 Announce Type: new \nAbstract: In this work, we present a trust-region optimization framework that employs Hermite kernel surrogate models. The method targets optimization problems with computationally demanding objective functions, for which direct optimization is often impractical due to expensive function evaluations. To address these challenges, we leverage a trust-region strategy, where the objective function is approximated by an efficient surrogate model within a local neighborhood of the current iterate. In particular, we construct the surrogate using Hermite kernel interpolation and define the trust-region based on bounds for the interpolation error. As mesh-free techniques, kernel-based methods are naturally suited for medium- to high-dimensional problems. Furthermore, the Hermite formulation incorporates gradient information, enabling precise gradient estimates that are crucial for many optimization algorithms. We prove that the proposed algorithm converges to a stationary point, and we demonstrate its effectiveness through numerical experiments, which illustrate the convergence behavior as well as the efficiency gains compared to direct optimization.</article>","contentLength":1198,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Auto-optimization of Energy Generation for Wave Energy Converters with Active Learning","url":"https://arxiv.org/abs/2507.01727","date":1751515200,"author":"","guid":182196,"unread":true,"content":"<article>arXiv:2507.01727v1 Announce Type: new \nAbstract: This paper presents an auto-optimization control framework for wave energy converters (WECs) to maximize energy generation under unknown and changing ocean conditions. The proposed control framework consists of two levels. The high-level controller operating at a longer time scale aims to maximize the average energy generation over several wave periods. The generated Power Take-Off (PTO) profile as the reference for the low-level physical system to follow. The new auto-optimization process leverages the parameterization of the non-stationary operation condition in WECs, establishing the relationship between the average energy generation and the key design parameters of the PTO force subject to the unknown wave parameters. The high-level controller is designed based on the concept of Dual Control for Exploration and Exploitation (DCEE) to quickly learn the unknown wave parameters by actively probing the ocean condition, while generating the optimal PTO profile. During this process, the uncertainty of the estimated wave condition is quantified and embedded in the optimization cost function to enable active learning. Simulation results under unknown regular and irregular waves demonstrate the effectiveness and robustness of this novel auto-optimization WEC systems with active learning, outperforming model predictive control, extremum seeking and classic Bang-Bang control approaches.</article>","contentLength":1451,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Revisiting Learning Rate Control","url":"https://arxiv.org/abs/2507.01724","date":1751515200,"author":"","guid":182197,"unread":true,"content":"<article>arXiv:2507.01724v1 Announce Type: new \nAbstract: The learning rate is one of the most important hyperparameters in deep learning, and how to control it is an active area within both AutoML and deep learning research. Approaches for learning rate control span from classic optimization to online scheduling based on gradient statistics. This paper compares paradigms to assess the current state of learning rate control. We find that methods from multi-fidelity hyperparameter optimization, fixed-hyperparameter schedules, and hyperparameter-free learning often perform very well on selected deep learning tasks but are not reliable across settings. This highlights the need for algorithm selection methods in learning rate control, which have been neglected so far by both the AutoML and deep learning communities. We also observe a trend of hyperparameter optimization approaches becoming less effective as models and tasks grow in complexity, even when combined with multi-fidelity approaches for more expensive model trainings. A focus on more relevant test tasks and new promising directions like finetunable methods and meta-learning will enable the AutoML community to significantly strengthen its impact on this crucial factor in deep learning.</article>","contentLength":1251,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SE(3)-Equivariant Diffusion Policy in Spherical Fourier Space","url":"https://arxiv.org/abs/2507.01723","date":1751515200,"author":"","guid":182198,"unread":true,"content":"<article>arXiv:2507.01723v1 Announce Type: new \nAbstract: Diffusion Policies are effective at learning closed-loop manipulation policies from human demonstrations but generalize poorly to novel arrangements of objects in 3D space, hurting real-world performance. To address this issue, we propose Spherical Diffusion Policy (SDP), an SE(3) equivariant diffusion policy that adapts trajectories according to 3D transformations of the scene. Such equivariance is achieved by embedding the states, actions, and the denoising process in spherical Fourier space. Additionally, we employ novel spherical FiLM layers to condition the action denoising process equivariantly on the scene embeddings. Lastly, we propose a spherical denoising temporal U-net that achieves spatiotemporal equivariance with computational efficiency. In the end, SDP is end-to-end SE(3) equivariant, allowing robust generalization across transformed 3D scenes. SDP demonstrates a large performance improvement over strong baselines in 20 simulation tasks and 5 physical robot tasks including single-arm and bi-manual embodiments. Code is available at https://github.com/amazon-science/Spherical_Diffusion_Policy.</article>","contentLength":1172,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"When Does Pruning Benefit Vision Representations?","url":"https://arxiv.org/abs/2507.01722","date":1751515200,"author":"","guid":182199,"unread":true,"content":"<article>arXiv:2507.01722v1 Announce Type: new \nAbstract: Pruning is widely used to reduce the complexity of deep learning models, but its effects on interpretability and representation learning remain poorly understood. This paper investigates how pruning influences vision models across three key dimensions: (i) interpretability, (ii) unsupervised object discovery, and (iii) alignment with human perception. We first analyze different vision network architectures to examine how varying sparsity levels affect feature attribution interpretability methods. Additionally, we explore whether pruning promotes more succinct and structured representations, potentially improving unsupervised object discovery by discarding redundant information while preserving essential features. Finally, we assess whether pruning enhances the alignment between model representations and human perception, investigating whether sparser models focus on more discriminative features similarly to humans. Our findings also reveal the presence of sweet spots, where sparse models exhibit higher interpretability, downstream generalization and human alignment. However, these spots highly depend on the network architectures and their size in terms of trainable parameters. Our results suggest a complex interplay between these three dimensions, highlighting the importance of investigating when and how pruning benefits vision representations.</article>","contentLength":1415,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation","url":"https://arxiv.org/abs/2507.01721","date":1751515200,"author":"","guid":182200,"unread":true,"content":"<article>arXiv:2507.01721v1 Announce Type: new \nAbstract: We consider weakly supervised segmentation where only a fraction of pixels have ground truth labels (scribbles) and focus on a self-labeling approach optimizing relaxations of the standard unsupervised CRF/Potts loss on unlabeled pixels. While WSSS methods can directly optimize such losses via gradient descent, prior work suggests that higher-order optimization can improve network training by introducing hidden pseudo-labels and powerful CRF sub-problem solvers, e.g. graph cut. However, previously used hard pseudo-labels can not represent class uncertainty or errors, which motivates soft self-labeling. We derive a principled auxiliary loss and systematically evaluate standard and new CRF relaxations (convex and non-convex), neighborhood systems, and terms connecting network predictions with soft pseudo-labels. We also propose a general continuous sub-problem solver. Using only standard architectures, soft self-labeling consistently improves scribble-based training and outperforms significantly more complex specialized WSSS systems. It can outperform full pixel-precise supervision. Our general ideas apply to other weakly-supervised problems/systems.</article>","contentLength":1215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America","url":"https://arxiv.org/abs/2507.01719","date":1751515200,"author":"","guid":182201,"unread":true,"content":"<article>arXiv:2507.01719v1 Announce Type: new \nAbstract: There is justifiable interest in leveraging conversational AI (CAI) for health across the majority world, but to be effective, CAI must respond appropriately within culturally and linguistically diverse contexts. Therefore, we need ways to address the fact that current LLMs exclude many lived experiences globally. Various advances are underway which focus on top-down approaches and increasing training data. In this paper, we aim to complement these with a bottom-up locally-grounded approach based on qualitative data collected during participatory workshops in Latin America. Our goal is to construct a rich and human-centred understanding of: a) potential areas of cultural misalignment in digital health; b) regional perspectives on chatbots for health and c)strategies for creating culturally-appropriate CAI; with a focus on the understudied Latin American context. Our findings show that academic boundaries on notions of culture lose meaning at the ground level and technologies will need to engage with a broader framework; one that encapsulates the way economics, politics, geography and local logistics are entangled in cultural experience. To this end, we introduce a framework for 'Pluriversal Conversational AI for Health' which allows for the possibility that more relationality and tolerance, rather than just more data, may be called for.</article>","contentLength":1407,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI","url":"https://arxiv.org/abs/2507.01717","date":1751515200,"author":"","guid":182202,"unread":true,"content":"<article>arXiv:2507.01717v1 Announce Type: new \nAbstract: Patents contain rich technical knowledge that can inspire innovative product ideas, yet accessing and interpreting this information remains a challenge. This work explores the use of Large Language Models (LLMs) and autonomous agents to mine and generate product concepts from a given patent. In this work, we design Agent Ideate, a framework for automatically generating product-based business ideas from patents. We experimented with open-source LLMs and agent-based architectures across three domains: Computer Science, Natural Language Processing, and Material Chemistry. Evaluation results show that the agentic approach consistently outperformed standalone LLMs in terms of idea quality, relevance, and novelty. These findings suggest that combining LLMs with agentic workflows can significantly enhance the innovation pipeline by unlocking the untapped potential of business idea generation from patent data.</article>","contentLength":964,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach","url":"https://arxiv.org/abs/2507.01715","date":1751515200,"author":"","guid":182203,"unread":true,"content":"<article>arXiv:2507.01715v1 Announce Type: new \nAbstract: Bias and stereotypes in language models can cause harm, especially in sensitive areas like content moderation and decision-making. This paper addresses bias and stereotype detection by exploring how jointly learning these tasks enhances model performance. We introduce StereoBias, a unique dataset labeled for bias and stereotype detection across five categories: religion, gender, socio-economic status, race, profession, and others, enabling a deeper study of their relationship. Our experiments compare encoder-only models and fine-tuned decoder-only models using QLoRA. While encoder-only models perform well, decoder-only models also show competitive results. Crucially, joint training on bias and stereotype detection significantly improves bias detection compared to training them separately. Additional experiments with sentiment analysis confirm that the improvements stem from the connection between bias and stereotypes, not multi-task learning alone. These findings highlight the value of leveraging stereotype information to build fairer and more effective AI systems.</article>","contentLength":1130,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"B-PL-PINN: Stabilizing PINN Training with Bayesian Pseudo Labeling","url":"https://arxiv.org/abs/2507.01714","date":1751515200,"author":"","guid":182204,"unread":true,"content":"<article>arXiv:2507.01714v1 Announce Type: new \nAbstract: Training physics-informed neural networks (PINNs) for forward problems often suffers from severe convergence issues, hindering the propagation of information from regions where the desired solution is well-defined. Haitsiukevich and Ilin (2023) proposed an ensemble approach that extends the active training domain of each PINN based on i) ensemble consensus and ii) vicinity to (pseudo-)labeled points, thus ensuring that the information from the initial condition successfully propagates to the interior of the computational domain.\n  In this work, we suggest replacing the ensemble by a Bayesian PINN, and consensus by an evaluation of the PINN's posterior variance. Our experiments show that this mathematically principled approach outperforms the ensemble on a set of benchmark problems and is competitive with PINN ensembles trained with combinations of Adam and LBFGS.</article>","contentLength":924,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Using Wavelet Domain Fingerprints to Improve Source Camera Identification","url":"https://arxiv.org/abs/2507.01712","date":1751515200,"author":"","guid":182205,"unread":true,"content":"<article>arXiv:2507.01712v1 Announce Type: new \nAbstract: Camera fingerprint detection plays a crucial role in source identification and image forensics, with wavelet denoising approaches proving to be particularly effective in extracting sensor pattern noise (SPN). In this article, we propose a modification to wavelet-based SPN extraction. Rather than constructing the fingerprint as an image, we introduce the notion of a wavelet domain fingerprint. This avoids the final inversion step of the denoising algorithm and allows fingerprint comparisons to be made directly in the wavelet domain. As such, our modification streamlines the extraction and comparison process. Experimental results on real-world datasets demonstrate that our method not only achieves higher detection accuracy but can also significantly improve processing speed.</article>","contentLength":832,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Component Adaptive Clustering for Generalized Category Discovery","url":"https://arxiv.org/abs/2507.01711","date":1751515200,"author":"","guid":182206,"unread":true,"content":"<article>arXiv:2507.01711v1 Announce Type: new \nAbstract: Generalized Category Discovery (GCD) tackles the challenging problem of categorizing unlabeled images into both known and novel classes within a partially labeled dataset, without prior knowledge of the number of unknown categories. Traditional methods often rely on rigid assumptions, such as predefining the number of classes, which limits their ability to handle the inherent variability and complexity of real-world data. To address these shortcomings, we propose AdaGCD, a cluster-centric contrastive learning framework that incorporates Adaptive Slot Attention (AdaSlot) into the GCD framework. AdaSlot dynamically determines the optimal number of slots based on data complexity, removing the need for predefined slot counts. This adaptive mechanism facilitates the flexible clustering of unlabeled data into known and novel categories by dynamically allocating representational capacity. By integrating adaptive representation with dynamic slot allocation, our method captures both instance-specific and spatially clustered features, improving class discovery in open-world scenarios. Extensive experiments on public and fine-grained datasets validate the effectiveness of our framework, emphasizing the advantages of leveraging spatial local information for category discovery in unlabeled image datasets.</article>","contentLength":1362,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Better Attribute Inference Vulnerability Measures","url":"https://arxiv.org/abs/2507.01710","date":1751515200,"author":"","guid":182207,"unread":true,"content":"<article>arXiv:2507.01710v1 Announce Type: new \nAbstract: The purpose of anonymizing structured data is to protect the privacy of individuals in the data while retaining the statistical properties of the data. An important class of attack on anonymized data is attribute inference, where an attacker infers the value of an unknown attribute of a target individual given knowledge of one or more known attributes. A major limitation of recent attribute inference measures is that they do not take recall into account, only precision. It is often the case that attacks target only a fraction of individuals, for instance data outliers. Incorporating recall, however, substantially complicates the measure, because one must determine how to combine recall and precision in a composite measure for both the attack and baseline. This paper presents the design and implementation of an attribute inference measure that incorporates both precision and recall. Our design also improves on how the baseline attribute inference is computed. In experiments using a generic best row match attack on moderately-anonymized microdata, we show that in over 25\\% of the attacks, our approach correctly labeled the attack to be at risk while the prior approach incorrectly labeled the attack to be safe.</article>","contentLength":1276,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A modified Levenberg-Marquardt method for estimating the elastic material parameters of polymer waveguides using residuals between autocorrelated frequency responses","url":"https://arxiv.org/abs/2507.01706","date":1751515200,"author":"","guid":182208,"unread":true,"content":"<article>arXiv:2507.01706v1 Announce Type: new \nAbstract: In this contribution, we address the estimation of the frequency-dependent elastic parameters of polymers in the ultrasound range, which is formulated as an inverse problem. This inverse problem is implemented as a nonlinear regression-type optimization problem, in which the simulation signals are fitted to the measurement signals. These signals consist of displacement responses in waveguides, focusing on hollow cylindrical geometries to enhance the simulation efficiency. To accelerate the optimization and reduce the number of model evaluations and wait times, we propose two novel methods. First, we introduce an adaptation of the Levenberg-Marquardt method derived from a geometrical interpretation of the least-squares optimization problem. Second, we introduce an improved objective function based on the autocorrelated envelopes of the measurement and simulation signals. Given that this study primarily relies on simulation data to quantify optimization convergence, we aggregate the expected ranges of realistic material parameters and derive their distributions to ensure the reproducibility of optimizations with proper measurements. We demonstrate the effectiveness of our objective function modification and step adaptation for various materials with isotropic material symmetry by comparing them with a state-of-the-art optimization method. In all cases, our method reduces the total number of model evaluations, thereby shortening the time to identify the material parameters.</article>","contentLength":1544,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Collision Detection for Long and Slender Robotic Links in Euclidean Distance Fields: Application to a Forestry Crane","url":"https://arxiv.org/abs/2507.01705","date":1751515200,"author":"","guid":182209,"unread":true,"content":"<article>arXiv:2507.01705v1 Announce Type: new \nAbstract: Collision-free motion planning in complex outdoor environments relies heavily on perceiving the surroundings through exteroceptive sensors. A widely used approach represents the environment as a voxelized Euclidean distance field, where robots are typically approximated by spheres. However, for large-scale manipulators such as forestry cranes, which feature long and slender links, this conventional spherical approximation becomes inefficient and inaccurate. This work presents a novel collision detection algorithm specifically designed to exploit the elongated structure of such manipulators, significantly enhancing the computational efficiency of motion planning algorithms. Unlike traditional sphere decomposition methods, our approach not only improves computational efficiency but also naturally eliminates the need to fine-tune the approximation accuracy as an additional parameter. We validate the algorithm's effectiveness using real-world LiDAR data from a forestry crane application, as well as simulated environment data.</article>","contentLength":1086,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness","url":"https://arxiv.org/abs/2507.01702","date":1751515200,"author":"","guid":182210,"unread":true,"content":"<article>arXiv:2507.01702v1 Announce Type: new \nAbstract: The proliferation of multimodal memes in the social media era demands that multimodal Large Language Models (mLLMs) effectively understand meme harmfulness. Existing benchmarks for assessing mLLMs on harmful meme understanding rely on accuracy-based, model-agnostic evaluations using static datasets. These benchmarks are limited in their ability to provide up-to-date and thorough assessments, as online memes evolve dynamically. To address this, we propose AdamMeme, a flexible, agent-based evaluation framework that adaptively probes the reasoning capabilities of mLLMs in deciphering meme harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive evaluations by iteratively updating the meme data with challenging samples, thereby exposing specific limitations in how mLLMs interpret harmfulness. Extensive experiments show that our framework systematically reveals the varying performance of different target mLLMs, offering in-depth, fine-grained analyses of model-specific weaknesses. Our code is available at https://github.com/Lbotirx/AdamMeme.</article>","contentLength":1124,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture","url":"https://arxiv.org/abs/2507.01701","date":1751515200,"author":"","guid":182211,"unread":true,"content":"<article>arXiv:2507.01701v1 Announce Type: new \nAbstract: In this paper, we propose to incorporate the blackboard architecture into LLM multi-agent systems (MASs) so that (1) agents with various roles can share all the information and others' messages during the whole problem-solving process, (2) agents that will take actions are selected based on the current content of the blackboard, and (3) the selection and execution round is repeated until a consensus is reached on the blackboard. We develop the first implementation of this proposal and conduct experiments on commonsense knowledge, reasoning and mathematical datasets. The results show that our system can be competitive with the SOTA static and dynamic MASs by achieving the best average performance, and at the same time manage to spend less tokens. Our proposal has the potential to enable complex and dynamic problem-solving where well-defined structures or workflows are unavailable.</article>","contentLength":941,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Relational Causal Discovery with Latent Confounders","url":"https://arxiv.org/abs/2507.01700","date":1751515200,"author":"","guid":182212,"unread":true,"content":"<article>arXiv:2507.01700v1 Announce Type: new \nAbstract: Estimating causal effects from real-world relational data can be challenging when the underlying causal model and potential confounders are unknown. While several causal discovery algorithms exist for learning causal models with latent confounders from data, they assume that the data is independent and identically distributed (i.i.d.) and are not well-suited for learning from relational data. Similarly, existing relational causal discovery algorithms assume causal sufficiency, which is unrealistic for many real-world datasets. To address this gap, we propose RelFCI, a sound and complete causal discovery algorithm for relational data with latent confounders. Our work builds upon the Fast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms and it defines new graphical models, necessary to support causal discovery in relational domains. We also establish soundness and completeness guarantees for relational d-separation with latent confounders. We present experimental results demonstrating the effectiveness of RelFCI in identifying the correct causal structure in relational causal models with latent confounders.</article>","contentLength":1194,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Variational Graph Convolutional Neural Networks","url":"https://arxiv.org/abs/2507.01699","date":1751515200,"author":"","guid":182213,"unread":true,"content":"<article>arXiv:2507.01699v1 Announce Type: new \nAbstract: Estimation of model uncertainty can help improve the explainability of Graph Convolutional Networks and the accuracy of the models at the same time. Uncertainty can also be used in critical applications to verify the results of the model by an expert or additional models. In this paper, we propose Variational Neural Network versions of spatial and spatio-temporal Graph Convolutional Networks. We estimate uncertainty in both outputs and layer-wise attentions of the models, which has the potential for improving model explainability. We showcase the benefits of these models in the social trading analysis and the skeleton-based human action recognition tasks on the Finnish board membership, NTU-60, NTU-120 and Kinetics datasets, where we show improvement in model accuracy in addition to estimated model uncertainties.</article>","contentLength":873,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An RRT* algorithm based on Riemannian metric model for optimal path planning","url":"https://arxiv.org/abs/2507.01697","date":1751515200,"author":"","guid":182214,"unread":true,"content":"<article>arXiv:2507.01697v1 Announce Type: new \nAbstract: This paper presents a Riemannian metric-based model to solve the optimal path planning problem on two-dimensional smooth submanifolds in high-dimensional space. Our model is based on constructing a new Riemannian metric on a two-dimensional projection plane, which is induced by the high-dimensional Euclidean metric on two-dimensional smooth submanifold and reflects the environmental information of the robot. The optimal path planning problem in high-dimensional space is therefore transformed into a geometric problem on the two-dimensional plane with new Riemannian metric. Based on the new Riemannian metric, we proposed an incremental algorithm RRT*-R on the projection plane. The experimental results show that the proposed algorithm is suitable for scenarios with uneven fields in multiple dimensions. The proposed algorithm can help the robot to effectively avoid areas with drastic changes in height, ground resistance and other environmental factors. More importantly, the RRT*-R algorithm shows better smoothness and optimization properties compared with the original RRT* algorithm using Euclidean distance in high-dimensional workspace. The length of the entire path by RRT*-R is a good approximation of the theoretical minimum geodesic distance on projection plane.</article>","contentLength":1330,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dynamic Similarity Graph Construction with Kernel Density Estimation","url":"https://arxiv.org/abs/2507.01696","date":1751515200,"author":"","guid":182215,"unread":true,"content":"<article>arXiv:2507.01696v1 Announce Type: new \nAbstract: In the kernel density estimation (KDE) problem, we are given a set $X$ of data points in $\\mathbb{R}^d$, a kernel function $k: \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}$, and a query point $\\mathbf{q} \\in \\mathbb{R}^d$, and the objective is to quickly output an estimate of $\\sum_{\\mathbf{x} \\in X} k(\\mathbf{q}, \\mathbf{x})$. In this paper, we consider $\\textsf{KDE}$ in the dynamic setting, and introduce a data structure that efficiently maintains the estimates for a set of query points as data points are added to $X$ over time. Based on this, we design a dynamic data structure that maintains a sparse approximation of the fully connected similarity graph on $X$, and develop a fast dynamic spectral clustering algorithm. We further evaluate the effectiveness of our algorithms on both synthetic and real-world datasets.</article>","contentLength":889,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PERTINENCE: Input-based Opportunistic Neural Network Dynamic Execution","url":"https://arxiv.org/abs/2507.01695","date":1751515200,"author":"","guid":182216,"unread":true,"content":"<article>arXiv:2507.01695v1 Announce Type: new \nAbstract: Deep neural networks (DNNs) have become ubiquitous thanks to their remarkable ability to model complex patterns across various domains such as computer vision, speech recognition, robotics, etc. While large DNN models are often more accurate than simpler, lightweight models, they are also resource- and energy-hungry. Hence, it is imperative to design methods to reduce reliance on such large models without significant degradation in output accuracy. The high computational cost of these models is often necessary only for a reduced set of challenging inputs, while lighter models can handle most simple ones. Thus, carefully combining properties of existing DNN models in a dynamic, input-based way opens opportunities to improve efficiency without impacting accuracy.\n  In this work, we introduce PERTINENCE, a novel online method designed to analyze the complexity of input features and dynamically select the most suitable model from a pre-trained set to process a given input effectively. To achieve this, we employ a genetic algorithm to explore the training space of an ML-based input dispatcher, enabling convergence towards the Pareto front in the solution space that balances overall accuracy and computational efficiency.\n  We showcase our approach on state-of-the-art Convolutional Neural Networks (CNNs) trained on the CIFAR-10 and CIFAR-100, as well as Vision Transformers (ViTs) trained on TinyImageNet dataset. We report results showing PERTINENCE's ability to provide alternative solutions to existing state-of-the-art models in terms of trade-offs between accuracy and number of operations. By opportunistically selecting among models trained for the same task, PERTINENCE achieves better or comparable accuracy with up to 36% fewer operations.</article>","contentLength":1813,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks","url":"https://arxiv.org/abs/2507.01694","date":1751515200,"author":"","guid":182217,"unread":true,"content":"<article>arXiv:2507.01694v1 Announce Type: new \nAbstract: Federated large language models (FedLLMs) provide powerful generative capabilities in CyberEdge networks while protecting data privacy. However, FedLLMs remains highly vulnerable to model poisoning attacks. This article first reviews recent model poisoning techniques and existing defense mechanisms for FedLLMs, highlighting critical limitations, particularly under non-IID text distributions. In particular, current defenses primarily utilize distance-based outlier detection or norm constraints, operating under the assumption that adversarial updates significantly diverge from benign statistics. This assumption can fail when facing adaptive attackers targeting billionparameter LLMs. Next, this article investigates emerging Graph Representation-Based Model Poisoning (GRMP), a novel attack paradigm that leverages higher-order correlations among honest client gradients to synthesize malicious updates indistinguishable from legitimate model updates. GRMP can effectively evade advanced defenses, resulting in substantial accuracy loss and performance degradation. Moreover, this article outlines a research roadmap emphasizing the importance of graph-aware secure aggregation methods, FedLLMs-specific vulnerability metrics, and evaluation frameworks to strengthen the robustness of future federated language model deployments.</article>","contentLength":1384,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GPT, But Backwards: Exactly Inverting Language Model Outputs","url":"https://arxiv.org/abs/2507.01693","date":1751515200,"author":"","guid":182218,"unread":true,"content":"<article>arXiv:2507.01693v1 Announce Type: new \nAbstract: While existing auditing techniques attempt to identify potential unwanted behaviours in large language models (LLMs), we address the complementary forensic problem of reconstructing the exact input that led to an existing LLM output - enabling post-incident analysis and potentially the detection of fake output reports. We formalize exact input reconstruction as a discrete optimisation problem with a unique global minimum and introduce SODA, an efficient gradient-based algorithm that operates on a continuous relaxation of the input search space with periodic restarts and parameter decay. Through comprehensive experiments on LLMs ranging in size from 33M to 3B parameters, we demonstrate that SODA significantly outperforms existing approaches. We succeed in fully recovering 79.5% of shorter out-of-distribution inputs from next-token logits, without a single false positive, but struggle to extract private information from the outputs of longer (15+ token) input sequences. This suggests that standard deployment practices may currently provide adequate protection against malicious use of our method. Our code is available at https://doi.org/10.5281/zenodo.15539879.</article>","contentLength":1225,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Designing for Community Care: Reimagining Support for Equity & Well-being in Academia","url":"https://arxiv.org/abs/2507.01690","date":1751515200,"author":"","guid":182219,"unread":true,"content":"<article>arXiv:2507.01690v1 Announce Type: new \nAbstract: Academic well-being is deeply influenced by peer-support networks, yet they remain informal, inequitable, and unsustainable, often relying on personal connections and social capital rather than structured, inclusive systems. Additionally, institutional well-being responses frequently focus on student populations, neglecting the emotional labour of faculty and staff, reinforcing an exclusionary academic culture. Drawing on HCI methodologies, participatory design, and care ethics, this workshop will provide a space for rethinking how academic communities can support inclusive networks. Through pre-workshop engagement, co-design activities, and reflection, participants will examine systemic gaps in networks and explore ways to embed care, equity, and sustainability into academic peer-support frameworks -- from informal, exclusionary models to structured, inclusive care-based ecosystems. At the end of the workshop, participants will co-develop design strategies for integrating care and resilience in academic ecosystems, resources for designing equitable support systems, and a peer network invested and committed to fostering a supportive academic community.</article>","contentLength":1219,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Half Spatially Coupled Turbo-Like Codes","url":"https://arxiv.org/abs/2507.01685","date":1751515200,"author":"","guid":182220,"unread":true,"content":"<article>arXiv:2507.01685v1 Announce Type: new \nAbstract: This paper presents a new class of spatially coupled turbo-like codes (SC-TCs), namely half spatially coupled braided convolutional codes (HSC-BCCs) and half spatially coupled parallel concatenated codes (HSC-PCCs). Different from the conventional SC-TCs, the proposed codes have simpler and deterministic coupling structures. Most notably, the coupling of HSC-BCCs is performed by re-encoding the whole coupling sequence in the component encoder of one time instant, rather than spreading the coupling bits to component encoders of multiple time instants. This simplification not only addresses the window decoding threshold loss issue in existing BCCs, but also allows the proposed codes to attain very close-to-capacity performance with a coupling memory as small as 2. Both theoretical and numerical results are provided to demonstrate the performance advantages of the proposed codes over existing spatially coupled codes.</article>","contentLength":976,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling","url":"https://arxiv.org/abs/2507.01679","date":1751515200,"author":"","guid":182221,"unread":true,"content":"<article>arXiv:2507.01679v1 Announce Type: new \nAbstract: Existing post-training techniques for large language models are broadly categorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking demonstration data but can lead to problematic generalization as a form of behavior cloning. Conversely, RFT can significantly enhance a model's performance but is prone to learn unexpected behaviors, and its performance is highly sensitive to the initial policy. In this paper, we propose a unified view of these methods and introduce Prefix-RFT, a hybrid approach that synergizes learning from both demonstration and exploration. Using mathematical reasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is both simple and effective. It not only surpasses the performance of standalone SFT and RFT but also outperforms parallel mixed-policy RFT methods. A key advantage is its seamless integration into existing open-source frameworks, requiring only minimal modifications to the standard RFT pipeline. Our analysis highlights the complementary nature of SFT and RFT, and validates that Prefix-RFT effectively harmonizes these two learning paradigms. Furthermore, ablation studies confirm the method's robustness to variations in the quality and quantity of demonstration data. We hope this work offers a new perspective on LLM post-training, suggesting that a unified paradigm that judiciously integrates demonstration and exploration could be a promising direction for future research.</article>","contentLength":1583,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Deep Recommender Models Inference: Automatic Asymmetric Data Flow Optimization","url":"https://arxiv.org/abs/2507.01676","date":1751515200,"author":"","guid":182222,"unread":true,"content":"<article>arXiv:2507.01676v1 Announce Type: new \nAbstract: Deep Recommender Models (DLRMs) inference is a fundamental AI workload accounting for more than 79% of the total AI workload in Meta's data centers. DLRMs' performance bottleneck is found in the embedding layers, which perform many random memory accesses to retrieve small embedding vectors from tables of various sizes. We propose the design of tailored data flows to speedup embedding look-ups. Namely, we propose four strategies to look up an embedding table effectively on one core, and a framework to automatically map the tables asymmetrically to the multiple cores of a SoC. We assess the effectiveness of our method using the Huawei Ascend AI accelerators, comparing it with the default Ascend compiler, and we perform high-level comparisons with Nvidia A100. Results show a speed-up varying from 1.5x up to 6.5x for real workload distributions, and more than 20x for extremely unbalanced distributions. Furthermore, the method proves to be much more independent of the query distribution than the baseline.</article>","contentLength":1064,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition","url":"https://arxiv.org/abs/2507.01673","date":1751515200,"author":"","guid":182223,"unread":true,"content":"<article>arXiv:2507.01673v1 Announce Type: new \nAbstract: Facial expression recognition (FER) in 3D and 4D domains presents a significant challenge in affective computing due to the complexity of spatial and temporal facial dynamics. Its success is crucial for advancing applications in human behavior understanding, healthcare monitoring, and human-computer interaction. In this work, we propose FACET-VLM, a vision-language framework for 3D/4D FER that integrates multiview facial representation learning with semantic guidance from natural language prompts. FACET-VLM introduces three key components: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion, Multiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions, and a multiview consistency loss to enforce structural coherence across views. Our model achieves state-of-the-art accuracy across multiple benchmarks, including BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extend FACET-VLM to 4D micro-expression recognition (MER) on the 4DME dataset, demonstrating strong performance in capturing subtle, short-lived emotional cues. The extensive experimental results confirm the effectiveness and substantial contributions of each individual component within the framework. Overall, FACET-VLM offers a robust, extensible, and high-performing solution for multimodal FER in both posed and spontaneous settings.</article>","contentLength":1402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Comparing Optimization Algorithms Through the Lens of Search Behavior Analysis","url":"https://arxiv.org/abs/2507.01668","date":1751515200,"author":"","guid":182224,"unread":true,"content":"<article>arXiv:2507.01668v1 Announce Type: new \nAbstract: The field of numerical optimization has recently seen a surge in the development of \"novel\" metaheuristic algorithms, inspired by metaphors derived from natural or human-made processes, which have been widely criticized for obscuring meaningful innovations and failing to distinguish themselves from existing approaches. Aiming to address these concerns, we investigate the applicability of statistical tests for comparing algorithms based on their search behavior. We utilize the cross-match statistical test to compare multivariate distributions and assess the solutions produced by 114 algorithms from the MEALPY library. These findings are incorporated into an empirical analysis aiming to identify algorithms with similar search behaviors.</article>","contentLength":793,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What does really matter in image goal navigation?","url":"https://arxiv.org/abs/2507.01667","date":1751515200,"author":"","guid":182225,"unread":true,"content":"<article>arXiv:2507.01667v1 Announce Type: new \nAbstract: Image goal navigation requires two different skills: firstly, core navigation skills, including the detection of free space and obstacles, and taking decisions based on an internal representation; and secondly, computing directional information by comparing visual observations to the goal image. Current state-of-the-art methods either rely on dedicated image-matching, or pre-training of computer vision modules on relative pose estimation. In this paper, we study whether this task can be efficiently solved with end-to-end training of full agents with RL, as has been claimed by recent work. A positive answer would have impact beyond Embodied AI and allow training of relative pose estimation from reward for navigation alone. In a large study we investigate the effect of architectural choices like late fusion, channel stacking, space-to-depth projections and cross-attention, and their role in the emergence of relative pose estimators from navigation training. We show that the success of recent methods is influenced up to a certain extent by simulator settings, leading to shortcuts in simulation. However, we also show that these capabilities can be transferred to more realistic setting, up to some extend. We also find evidence for correlations between navigation performance and probed (emerging) relative pose estimation performance, an important sub skill.</article>","contentLength":1422,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Globality and Regions","url":"https://arxiv.org/abs/2507.01664","date":1751515200,"author":"","guid":182226,"unread":true,"content":"<article>arXiv:2507.01664v1 Announce Type: new \nAbstract: We obtain a characterization of global variables by unifying abstraction with region abstraction in a region-based language. More precisely, in a previous work a language called global was presented, whose virtue is to provide a conceptually clear way of introducing imperative operations in a functional language. Memory safety is provided by the concept of linear protection, which connects the global system to a linear one. In this paper we show that the concept of global variable provided by the global language arises from the Tofte and Talping's region language through the unification of abstraction and region abstraction.</article>","contentLength":681,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training","url":"https://arxiv.org/abs/2507.01663","date":1751515200,"author":"","guid":182227,"unread":true,"content":"<article>arXiv:2507.01663v1 Announce Type: new \nAbstract: Reinforcement learning (RL) has become a pivotal technology in the post-training phase of large language models (LLMs). Traditional task-colocated RL frameworks suffer from significant scalability bottlenecks, while task-separated RL frameworks face challenges in complex dataflows and the corresponding resource idling and workload imbalance. Moreover, most existing frameworks are tightly coupled with LLM training or inference engines, making it difficult to support custom-designed engines. To address these challenges, we propose AsyncFlow, an asynchronous streaming RL framework for efficient post-training. Specifically, we introduce a distributed data storage and transfer module that provides a unified data management and fine-grained scheduling capability in a fully streamed manner. This architecture inherently facilitates automated pipeline overlapping among RL tasks and dynamic load balancing. Moreover, we propose a producer-consumer-based asynchronous workflow engineered to minimize computational idleness by strategically deferring parameter update process within staleness thresholds. Finally, the core capability of AsynFlow is architecturally decoupled from underlying training and inference engines and encapsulated by service-oriented user interfaces, offering a modular and customizable user experience. Extensive experiments demonstrate an average of 1.59 throughput improvement compared with state-of-the-art baseline. The presented architecture in this work provides actionable insights for next-generation RL training system designs.</article>","contentLength":1612,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Re-examining the Legendre-Gauss-Lobatto Pseudospectral Methods for Optimal Control","url":"https://arxiv.org/abs/2507.01660","date":1751515200,"author":"","guid":182228,"unread":true,"content":"<article>arXiv:2507.01660v1 Announce Type: new \nAbstract: Pseudospectral methods represent an efficient approach for solving optimal control problems. While Legendre-Gauss-Lobatto (LGL) collocation points have traditionally been considered inferior to Legendre-Gauss (LG) and Legendre-Gauss-Radau (LGR) points in terms of convergence properties, this paper presents a rigorous re-examination of LGL-based methods. We introduce an augmented formulation that enhances the standard LGL collocation approach by incorporating an additional degree of freedom (DOF) into the interpolation structure. We demonstrate that this augmented formulation is mathematically equivalent to the integral formulation of the LGL collocation method. Through analytical derivation, we establish that the adjoint system in both the augmented differential and integral formulations corresponds to a Lobatto IIIB discontinuous collocation method for the costate vector, thereby resolving the previously reported convergence issues. Our comparative analysis of LG, LGR, and LGL collocation methods reveals significant advantages of the improved LGL approach in terms of discretized problem dimensionality and symplectic integration properties. Numerical examples validate our theoretical findings, demonstrating that the proposed LGL-based method achieves comparable accuracy to LG and LGR methods while offering superior computational performance for long-horizon optimal control problems due to the preservation of symplecticity.</article>","contentLength":1495,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Symport/Antiport P Systems with Membrane Separation Characterize P^(#P)","url":"https://arxiv.org/abs/2507.01657","date":1751515200,"author":"","guid":182229,"unread":true,"content":"<article>arXiv:2507.01657v1 Announce Type: new \nAbstract: Membrane systems represent a computational model that operates in a distributed and parallel manner, inspired by the behavior of biological cells. These systems feature objects that transform within a nested membrane structure. This research concentrates on a specific type of these systems, based on cellular symport/antiport communication of chemicals.\n  Results in the literature show that systems of this type that also allow cell division can solve PSPACE problems. In our study, we investigate systems that use membrane separation instead of cell division, for which only limited results are available. Notably, it has been shown that any problem solvable by such systems in polynomial time falls within the complexity class P^(#P).\n  By implementing a system solving MIDSAT, a P^(#P)-complete problem, we demonstrate that the reverse inclusion is true as well, thus providing an exact characterization of the problem class solvable by P systems with symport/antiport and membrane separation.\n  Moreover, our implementation uses rules of length at most three. With this limit, systems were known to be able to solve NP-complete problems, whereas limiting the rules by length two, they characterize P.</article>","contentLength":1255,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SPoT: Subpixel Placement of Tokens in Vision Transformers","url":"https://arxiv.org/abs/2507.01654","date":1751515200,"author":"","guid":182230,"unread":true,"content":"<article>arXiv:2507.01654v1 Announce Type: new \nAbstract: Vision Transformers naturally accommodate sparsity, yet standard tokenization methods confine features to discrete patch grids. This constraint prevents models from fully exploiting sparse regimes, forcing awkward compromises. We propose Subpixel Placement of Tokens (SPoT), a novel tokenization strategy that positions tokens continuously within images, effectively sidestepping grid-based limitations. With our proposed oracle-guided search, we uncover substantial performance gains achievable with ideal subpixel token positioning, drastically reducing the number of tokens necessary for accurate predictions during inference. SPoT provides a new direction for flexible, efficient, and interpretable ViT architectures, redefining sparsity as a strategic advantage rather than an imposed limitation.</article>","contentLength":850,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather","url":"https://arxiv.org/abs/2507.01653","date":1751515200,"author":"","guid":182231,"unread":true,"content":"<article>arXiv:2507.01653v1 Announce Type: new \nAbstract: Learning-based stereo matching models struggle in adverse weather conditions due to the scarcity of corresponding training data and the challenges in extracting discriminative features from degraded images. These limitations significantly hinder zero-shot generalization to out-of-distribution weather conditions. In this paper, we propose \\textbf{RobuSTereo}, a novel framework that enhances the zero-shot generalization of stereo matching models under adverse weather by addressing both data scarcity and feature extraction challenges. First, we introduce a diffusion-based simulation pipeline with a stereo consistency module, which generates high-quality stereo data tailored for adverse conditions. By training stereo matching models on our synthetic datasets, we reduce the domain gap between clean and degraded images, significantly improving the models' robustness to unseen weather conditions. The stereo consistency module ensures structural alignment across synthesized image pairs, preserving geometric integrity and enhancing depth estimation accuracy. Second, we design a robust feature encoder that combines a specialized ConvNet with a denoising transformer to extract stable and reliable features from degraded images. The ConvNet captures fine-grained local structures, while the denoising transformer refines global representations, effectively mitigating the impact of noise, low visibility, and weather-induced distortions. This enables more accurate disparity estimation even under challenging visual conditions. Extensive experiments demonstrate that \\textbf{RobuSTereo} significantly improves the robustness and generalization of stereo matching models across diverse adverse weather scenarios.</article>","contentLength":1767,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective","url":"https://arxiv.org/abs/2507.01652","date":1751515200,"author":"","guid":182232,"unread":true,"content":"<article>arXiv:2507.01652v1 Announce Type: new \nAbstract: Autoregressive (AR) models have garnered significant attention in image generation for their ability to effectively capture both local and global structures within visual data. However, prevalent AR models predominantly rely on the transformer architectures, which are beset by quadratic computational complexity concerning input sequence length and substantial memory overhead due to the necessity of maintaining key-value caches. Although linear attention mechanisms have successfully reduced this burden in language models, our initial experiments reveal that they significantly degrade image generation quality because of their inability to capture critical long-range dependencies in visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a novel attention mechanism that explicitly preserves genuine 2D spatial relationships within the flattened image sequences by computing position-dependent decay factors based on true 2D spatial location rather than 1D sequence positions. Based on this mechanism, we present LASADGen, an autoregressive image generator that enables selective attention to relevant spatial contexts with linear complexity. Experiments on ImageNet show LASADGen achieves state-of-the-art image generation performance and computational efficiency, bridging the gap between linear attention's efficiency and spatial understanding needed for high-quality generation.</article>","contentLength":1457,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Dynamical Cartography of the Epistemic Diffusion of Artificial Intelligence in Neuroscience","url":"https://arxiv.org/abs/2507.01651","date":1751515200,"author":"","guid":182233,"unread":true,"content":"<article>arXiv:2507.01651v1 Announce Type: new \nAbstract: Neuroscience and AI have an intertwined history, largely relayed in the literature of both fields. In recent years, due to the engineering orientations of AI research and the monopoly of industry for its large-scale applications, the mutual expansion of neuroscience and AI in fundamental research seems challenged. In this paper, we bring some empirical evidences that, on the contrary, AI and neuroscience are continuing to grow together, but with a pronounced interest in the fields of study related to neurodegenerative diseases since the 1990s. With a temporal knowledge cartography of neuroscience drawn with advanced document embedding techniques, we draw the dynamical shaping of the discipline since the 1970s and identified the conceptual articulation of AI with this particular subfield mentioned before. However, a further analysis of the underlying citation network of the studied corpus shows that the produced AI technologies remain confined in the different subfields and are not transferred from one subfield to another. This invites us to discuss the genericity capability of AI in the context of an intradisciplinary development, especially in the diffusion of its associated metrology.</article>","contentLength":1254,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GradMetaNet: An Equivariant Architecture for Learning on Gradients","url":"https://arxiv.org/abs/2507.01649","date":1751515200,"author":"","guid":182234,"unread":true,"content":"<article>arXiv:2507.01649v1 Announce Type: new \nAbstract: Gradients of neural networks encode valuable information for optimization, editing, and analysis of models. Therefore, practitioners often treat gradients as inputs to task-specific algorithms, e.g. for pruning or optimization. Recent works explore learning algorithms that operate directly on gradients but use architectures that are not specifically designed for gradient processing, limiting their applicability. In this paper, we present a principled approach for designing architectures that process gradients. Our approach is guided by three principles: (1) equivariant design that preserves neuron permutation symmetries, (2) processing sets of gradients across multiple data points to capture curvature information, and (3) efficient gradient representation through rank-1 decomposition. Based on these principles, we introduce GradMetaNet, a novel architecture for learning on gradients, constructed from simple equivariant blocks. We prove universality results for GradMetaNet, and show that previous approaches cannot approximate natural gradient-based functions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness on a diverse set of gradient-based tasks on MLPs and transformers, such as learned optimization, INR editing, and estimating loss landscape curvature.</article>","contentLength":1343,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Adapting Language Models to Indonesian Local Languages: An Empirical Study of Language Transferability on Zero-Shot Settings","url":"https://arxiv.org/abs/2507.01645","date":1751515200,"author":"","guid":182235,"unread":true,"content":"<article>arXiv:2507.01645v1 Announce Type: new \nAbstract: In this paper, we investigate the transferability of pre-trained language models to low-resource Indonesian local languages through the task of sentiment analysis. We evaluate both zero-shot performance and adapter-based transfer on ten local languages using models of different types: a monolingual Indonesian BERT, multilingual models such as mBERT and XLM-R, and a modular adapter-based approach called MAD-X. To better understand model behavior, we group the target languages into three categories: seen (included during pre-training), partially seen (not included but linguistically related to seen languages), and unseen (absent and unrelated in pre-training data). Our results reveal clear performance disparities across these groups: multilingual models perform best on seen languages, moderately on partially seen ones, and poorly on unseen languages. We find that MAD-X significantly improves performance, especially for seen and partially seen languages, without requiring labeled data in the target language. Additionally, we conduct a further analysis on tokenization and show that while subword fragmentation and vocabulary overlap with Indonesian correlate weakly with prediction quality, they do not fully explain the observed performance. Instead, the most consistent predictor of transfer success is the model's prior exposure to the language, either directly or through a related language.</article>","contentLength":1457,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dance Dance ConvLSTM","url":"https://arxiv.org/abs/2507.01644","date":1751515200,"author":"","guid":182236,"unread":true,"content":"<article>arXiv:2507.01644v1 Announce Type: new \nAbstract: \\textit{Dance Dance Revolution} is a rhythm game consisting of songs and accompanying choreography, referred to as charts. Players press arrows on a device referred to as a dance pad in time with steps determined by the song's chart. In 2017, the authors of Dance Dance Convolution (DDC) developed an algorithm for the automatic generation of \\textit{Dance Dance Revolution} charts, utilizing a CNN-LSTM architecture. We introduce Dance Dance ConvLSTM (DDCL), a new method for the automatic generation of DDR charts using a ConvLSTM based model, which improves upon the DDC methodology and substantially increases the accuracy of chart generation.</article>","contentLength":696,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement","url":"https://arxiv.org/abs/2507.01643","date":1751515200,"author":"","guid":182237,"unread":true,"content":"<article>arXiv:2507.01643v1 Announce Type: new \nAbstract: Vision Transformers (ViTs) are essential as foundation backbones in establishing the visual comprehension capabilities of Multimodal Large Language Models (MLLMs). Although most ViTs achieve impressive performance through image-text pair-based contrastive learning or self-supervised mechanisms, they struggle to engage in connector-based co-training directly with LLMs due to potential parameter initialization conflicts and modality semantic gaps. To address the above challenges, this paper proposes SAILViT, a gradual feature learning-enhanced ViT for facilitating MLLMs to break through performance bottlenecks in complex multimodal interactions. SAILViT achieves coarse-to-fine-grained feature alignment and world knowledge infusion with gradual feature refinement, which better serves target training demands. We perform thorough empirical analyses to confirm the powerful robustness and generalizability of SAILViT across different dimensions, including parameter sizes, model architectures, training strategies, and data scales. Equipped with SAILViT, existing MLLMs show significant and consistent performance improvements on the OpenCompass benchmark across extensive downstream tasks. SAILViT series models are released at https://huggingface.co/BytedanceDouyinContent.</article>","contentLength":1330,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Joint Spatial Division and Multiplexing with Customized Orthogonal Group Channels in Multi-RIS-Assisted Systems","url":"https://arxiv.org/abs/2507.01641","date":1751515200,"author":"","guid":182238,"unread":true,"content":"<article>arXiv:2507.01641v1 Announce Type: new \nAbstract: Reconfigurable intelligent surfaces (RISs) offer the unique capability to reshape the radio environment, thereby simplifying transmission schemes traditionally contingent on channel conditions. Joint spatial division and multiplexing (JSDM) emerges as a low-overhead transmission scheme for multi-user equipment (UE) scenarios, typically requiring complex matrix decomposition to achieve block-diagonalization of the effective channel matrix. In this study, we introduce an innovative JSDM design that leverages RISs to customize channels, thereby streamlining the overall procedures. By strategically positioning RISs at the discrete Fourier transform (DFT) directions of the base station (BS), we establish orthogonal line-of-sight links within the BS-RIS channel, enabling a straightforward pre-beamforming design. Based on UE grouping, we devise reflected beams of the RIS with optimized directions to mitigate inter-group interference in the RISs-UEs channel. An approximation of the channel cross-correlation coefficient is derived and serves as a foundation for the RISs-UEs association, further diminishing inter-group interference. Numerical results substantiate the efficacy of our RIS-customized JSDM in not only achieving effective channel block-diagonalization but also in significantly enhancing the sum spectral efficiency for multi-UE transmissions.</article>","contentLength":1414,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Customized Exploration of Landscape Features Driving Multi-Objective Combinatorial Optimization Performance","url":"https://arxiv.org/abs/2507.01638","date":1751515200,"author":"","guid":182239,"unread":true,"content":"<article>arXiv:2507.01638v1 Announce Type: new \nAbstract: We present an analysis of landscape features for predicting the performance of multi-objective combinatorial optimization algorithms. We consider features from the recently proposed compressed Pareto Local Optimal Solutions Networks (C-PLOS-net) model of combinatorial landscapes. The benchmark instances are a set of rmnk-landscapes with 2 and 3 objectives and various levels of ruggedness and objective correlation. We consider the performance of three algorithms -- Pareto Local Search (PLS), Global Simple EMO Optimizer (GSEMO), and Non-dominated Sorting Genetic Algorithm (NSGA-II) - using the resolution and hypervolume metrics. Our tailored analysis reveals feature combinations that influence algorithm performance specific to certain landscapes. This study provides deeper insights into feature importance, tailored to specific rmnk-landscapes and algorithms.</article>","contentLength":917,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kernel Recursive Least Squares Dictionary Learning Algorithm","url":"https://arxiv.org/abs/2507.01636","date":1751515200,"author":"","guid":182240,"unread":true,"content":"<article>arXiv:2507.01636v1 Announce Type: new \nAbstract: We propose an efficient online dictionary learning algorithm for kernel-based sparse representations. In this framework, input signals are nonlinearly mapped to a high-dimensional feature space and represented sparsely using a virtual dictionary. At each step, the dictionary is updated recursively using a novel algorithm based on the recursive least squares (RLS) method. This update mechanism works with single samples or mini-batches and maintains low computational complexity. Experiments on four datasets across different domains show that our method not only outperforms existing online kernel dictionary learning approaches but also achieves classification accuracy close to that of batch-trained models, while remaining significantly more efficient.</article>","contentLength":807,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EGNInfoLeaker: Unveiling the Risks of Public Key Reuse and User Identity Leakage in Blockchain","url":"https://arxiv.org/abs/2507.01635","date":1751515200,"author":"","guid":182241,"unread":true,"content":"<article>arXiv:2507.01635v1 Announce Type: new \nAbstract: While Ethereum's discovery protocols (Discv4/ Discv5) incorporate robust cryptographic designs to protect user privacy, real-world deployment reveals critical vulnerabilities when users deviate from security guidelines. In this paper, we design a system called EGNInfoLeaker. Our study is the first work that uncovers widespread public key reuse across Ethereum's peer-to-peer networks - a practice that fundamentally undermines the protocol's privacy guarantees. Through systematic analysis of 300 real-world network snapshots, we identify 83 users controlling 483 service nodes via public key reuse, enabling precise de-anonymization through IP correlation. Using evidence collected by EGNInfoLeaker, our Graph-Based Identity Association Algorithm links users to network entities and generates comprehensive user profiles. For User27, it exposes the public key, IP, network ID, location (country/region/city), and ISP/ORG details. The EGNInfoLeaker system demonstrates how such cryptographic misuse transforms theoretical anonymity into practical identity leakage, exposing users to surveillance and targeted attacks. These findings establish that protocol security depends not only on sound design but also on strict user compliance. Going forward, our detection framework provides a foundation for enhancing real-world privacy preservation in decentralized networks.</article>","contentLength":1419,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Depth Anything at Any Condition","url":"https://arxiv.org/abs/2507.01634","date":1751515200,"author":"","guid":182242,"unread":true,"content":"<article>arXiv:2507.01634v1 Announce Type: new \nAbstract: We present Depth Anything at Any Condition (DepthAnything-AC), a foundation monocular depth estimation (MDE) model capable of handling diverse environmental conditions. Previous foundation MDE models achieve impressive performance across general scenes but not perform well in complex open-world environments that involve challenging conditions, such as illumination variations, adverse weather, and sensor-induced distortions. To overcome the challenges of data scarcity and the inability of generating high-quality pseudo-labels from corrupted images, we propose an unsupervised consistency regularization finetuning paradigm that requires only a relatively small amount of unlabeled data. Furthermore, we propose the Spatial Distance Constraint to explicitly enforce the model to learn patch-level relative relationships, resulting in clearer semantic boundaries and more accurate details. Experimental results demonstrate the zero-shot capabilities of DepthAnything-AC across diverse benchmarks, including real-world adverse weather benchmarks, synthetic corruption benchmarks, and general benchmarks.\n  Project Page: https://ghost233lism.github.io/depthanything-AC-page\n  Code: https://github.com/HVision-NKU/DepthAnythingAC</article>","contentLength":1278,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Confidence and Stability of Global and Pairwise Scores in NLP Evaluation","url":"https://arxiv.org/abs/2507.01633","date":1751515200,"author":"","guid":182243,"unread":true,"content":"<article>arXiv:2507.01633v1 Announce Type: new \nAbstract: With the advent of highly capable instruction-tuned neural language models, benchmarking in natural language processing (NLP) is increasingly shifting towards pairwise comparison leaderboards, such as LMSYS Arena, from traditional global pointwise scores (e.g., GLUE, BIG-bench, SWE-bench). This paper empirically investigates the strengths and weaknesses of both global scores and pairwise comparisons to aid decision-making in selecting appropriate model evaluation strategies. Through computational experiments on synthetic and real-world datasets using standard global metrics and the popular Bradley-Terry model for pairwise comparisons, we found that while global scores provide more reliable overall rankings, they can underestimate strong models with rare, significant errors or low confidence. Conversely, pairwise comparisons are particularly effective for identifying strong contenders among models with lower global scores, especially where quality metrics are hard to define (e.g., text generation), though they require more comparisons to converge if ties are frequent. Our code and data are available at https://github.com/HSPyroblast/srw-ranking under a permissive license.</article>","contentLength":1238,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation","url":"https://arxiv.org/abs/2507.01631","date":1751515200,"author":"","guid":182244,"unread":true,"content":"<article>arXiv:2507.01631v1 Announce Type: new \nAbstract: Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D reconstruction from multiview satellite imagery. However, state-of-the-art NeRF methods are typically constrained to small scenes due to the memory footprint during training, which we study in this paper. Previous work on large-scale NeRFs palliate this by dividing the scene into NeRFs. This paper introduces Snake-NeRF, a framework that scales to large scenes. Our out-of-core method eliminates the need to load all images and networks simultaneously, and operates on a single device. We achieve this by dividing the region of interest into NeRFs that 3D tile without overlap. Importantly, we crop the images with overlap to ensure each NeRFs is trained with all the necessary pixels. We introduce a novel $2\\times 2$ 3D tile progression strategy and segmented sampler, which together prevent 3D reconstruction errors along the tile edges. Our experiments conclude that large satellite images can effectively be processed with linear time complexity, on a single GPU, and without compromise in quality.</article>","contentLength":1126,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss","url":"https://arxiv.org/abs/2507.01630","date":1751515200,"author":"","guid":182245,"unread":true,"content":"<article>arXiv:2507.01630v1 Announce Type: new \nAbstract: The task of Human-Object conTact (HOT) detection involves identifying the specific areas of the human body that are touching objects. Nevertheless, current models are restricted to just one type of image, often leading to too much segmentation in areas with little interaction, and struggling to maintain category consistency within specific regions. To tackle this issue, a HOT framework, termed \\textbf{P3HOT}, is proposed, which blends \\textbf{P}rompt guidance and human \\textbf{P}roximal \\textbf{P}erception. To begin with, we utilize a semantic-driven prompt mechanism to direct the network's attention towards the relevant regions based on the correlation between image and text. Then a human proximal perception mechanism is employed to dynamically perceive key depth range around the human, using learnable parameters to effectively eliminate regions where interactions are not expected. Calculating depth resolves the uncertainty of the overlap between humans and objects in a 2D perspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss (RJLoss) has been created as a new loss to inhibit abnormal categories in the same area. A new evaluation metric called ``AD-Acc.'' is introduced to address the shortcomings of existing methods in addressing negative samples. Comprehensive experimental results demonstrate that our approach achieves state-of-the-art performance in four metrics across two benchmark datasets. Specifically, our model achieves an improvement of \\textbf{0.7}$\\uparrow$, \\textbf{2.0}$\\uparrow$, \\textbf{1.6}$\\uparrow$, and \\textbf{11.0}$\\uparrow$ in SC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated dataset. Code is available at https://github.com/YuxiaoWang-AI/P3HOT.</article>","contentLength":1791,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Adaptive Estimation of the Number of Algorithm Runs in Stochastic Optimization","url":"https://arxiv.org/abs/2507.01629","date":1751515200,"author":"","guid":182246,"unread":true,"content":"<article>arXiv:2507.01629v1 Announce Type: new \nAbstract: Determining the number of algorithm runs is a critical aspect of experimental design, as it directly influences the experiment's duration and the reliability of its outcomes. This paper introduces an empirical approach to estimating the required number of runs per problem instance for accurate estimation of the performance of the continuous single-objective stochastic optimization algorithm. The method leverages probability theory, incorporating a robustness check to identify significant imbalances in the data distribution relative to the mean, and dynamically adjusts the number of runs during execution as an online approach. The proposed methodology was extensively tested across two algorithm portfolios (104 Differential Evolution configurations and the Nevergrad portfolio) and the COCO benchmark suite, totaling 5748000 runs. The results demonstrate 82% - 95% accuracy in estimations across different algorithms, allowing a reduction of approximately 50% in the number of runs without compromising optimization outcomes. This online calculation of required runs not only improves benchmarking efficiency, but also contributes to energy reduction, fostering a more environmentally sustainable computing ecosystem.</article>","contentLength":1274,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DaiFu: In-Situ Crash Recovery for Deep Learning Systems","url":"https://arxiv.org/abs/2507.01628","date":1751515200,"author":"","guid":182247,"unread":true,"content":"<article>arXiv:2507.01628v1 Announce Type: new \nAbstract: Deep learning (DL) systems have been widely adopted in many areas, and are becoming even more popular with the emergence of large language models. However, due to the complex software stacks involved in their development and execution, crashes are unavoidable and common. Crashes severely waste computing resources and hinder development productivity, so efficient crash recovery is crucial. Existing solutions, such as checkpoint-retry, are too heavyweight for fast recovery from crashes caused by minor programming errors or transient runtime errors. Therefore, we present DaiFu, an in-situ recovery framework for DL systems. Through a lightweight code transformation to a given DL system, DaiFu augments it to intercept crashes in situ and enables dynamic and instant updates to its program running context (e.g., code, configurations, and other data) for agile crash recovery. Our evaluation shows that DaiFu helps reduce the restore time for crash recovery, achieving a 1372x speedup compared with state-of-the-art solutions. Meanwhile, the overhead of DaiFu is negligible (under 0.40%). We also construct a benchmark spanning 7 distinct crash scenarios in DL systems, and show the effectiveness of DaiFu in diverse situations.</article>","contentLength":1281,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Chart Question Answering from Real-World Analytical Narratives","url":"https://arxiv.org/abs/2507.01627","date":1751515200,"author":"","guid":182248,"unread":true,"content":"<article>arXiv:2507.01627v1 Announce Type: new \nAbstract: We present a new dataset for chart question answering (CQA) constructed from visualization notebooks. The dataset features real-world, multi-view charts paired with natural language questions grounded in analytical narratives. Unlike prior benchmarks, our data reflects ecologically valid reasoning workflows. Benchmarking state-of-the-art multimodal large language models reveals a significant performance gap, with GPT-4.1 achieving an accuracy of 69.3%, underscoring the challenges posed by this more authentic CQA setting.</article>","contentLength":575,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Spatially Distributed Wettability Characterization in Porous Media","url":"https://arxiv.org/abs/2507.01617","date":1751515200,"author":"","guid":182249,"unread":true,"content":"<article>arXiv:2507.01617v1 Announce Type: new \nAbstract: An enhanced geometric algorithm for automated pore-by-pore contact angle measurement from micro-CT images, is presented that achieves superior accuracy compared to existing methods through robust fluid-fluid and solid-fluid interface extrapolation. Using this high resolution data, we generate spatially distributed contact angle maps that reveal previously hidden wettability heterogeneity. Our analysis of mixed-wet systems demonstrates the severe limitations of averaged metrics: a sample with a mean contact angle of 64.7 degrees, conventionally classified as uniformly weakly water-wet, exhibits 40% of its pore space in the intermediate-wetting regime (70-110 degrees). This heterogeneity explains the presence of minimal surface interfaces and fundamentally different pore-filling mechanisms operating within the same sample. By providing open-source tools for spatially-resolved wettability characterization, this work enables more accurate predictions of multiphase flow behavior in heterogeneous porous materials, essential for optimizing subsurface energy storage and recovery processes.</article>","contentLength":1147,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Enhanced Influence-aware Group Recommendation for Online Media Propagation","url":"https://arxiv.org/abs/2507.01616","date":1751515200,"author":"","guid":182250,"unread":true,"content":"<article>arXiv:2507.01616v1 Announce Type: new \nAbstract: Group recommendation over social media streams has attracted significant attention due to its wide applications in domains such as e-commerce, entertainment, and online news broadcasting. By leveraging social connections and group behaviours, group recommendation (GR) aims to provide more accurate and engaging content to a set of users rather than individuals. Recently, influence-aware GR has emerged as a promising direction, as it considers the impact of social influence on group decision-making. In earlier work, we proposed Influence-aware Group Recommendation (IGR) to solve this task. However, this task remains challenging due to three key factors: the large and ever-growing scale of social graphs, the inherently dynamic nature of influence propagation within user groups, and the high computational overhead of real-time group-item matching.\n  To tackle these issues, we propose an Enhanced Influence-aware Group Recommendation (EIGR) framework. First, we introduce a Graph Extraction-based Sampling (GES) strategy to minimise redundancy across multiple temporal social graphs and effectively capture the evolving dynamics of both groups and items. Second, we design a novel DYnamic Independent Cascade (DYIC) model to predict how influence propagates over time across social items and user groups. Finally, we develop a two-level hash-based User Group Index (UG-Index) to efficiently organise user groups and enable real-time recommendation generation. Extensive experiments on real-world datasets demonstrate that our proposed framework, EIGR, consistently outperforms state-of-the-art baselines in both effectiveness and efficiency.</article>","contentLength":1698,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EDGChain-E: A Decentralized Git-Based Framework for Versioning Encrypted Energy Data","url":"https://arxiv.org/abs/2507.01615","date":1751515200,"author":"","guid":182251,"unread":true,"content":"<article>arXiv:2507.01615v1 Announce Type: new \nAbstract: This paper proposes a new decentralized framework, named EDGChain-E (Encrypted-Data-Git Chain for Energy), designed to manage version-controlled, encrypted energy data using blockchain and the InterPlanetary File System. The framework incorporates a Decentralized Autonomous Organization (DAO) to orchestrate collaborative data governance across the lifecycle of energy research and operations, such as smart grid monitoring, demand forecasting, and peer-to-peer energy trading. In EDGChain-E, initial commits capture the full encrypted datasets-such as smart meter readings or grid telemetry-while subsequent updates are tracked as encrypted Git patches, ensuring integrity, traceability, and privacy. This versioning mechanism supports secure collaboration across multiple stakeholders (e.g., utilities, researchers, regulators) without compromising sensitive or regulated information. We highlight the framework's capability to maintain FAIR-compliant (Findable, Accessible, Interoperable, Reusable) provenance of encrypted data. By embedding hash-based content identifiers in Merkle trees, the system enables transparent, auditable, and immutable tracking of data changes, thereby supporting reproducibility and trust in decentralized energy applications.</article>","contentLength":1308,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Perception-Oriented Latent Coding for High-Performance Compressed Domain Semantic Inference","url":"https://arxiv.org/abs/2507.01608","date":1751515200,"author":"","guid":182252,"unread":true,"content":"<article>arXiv:2507.01608v1 Announce Type: new \nAbstract: In recent years, compressed domain semantic inference has primarily relied on learned image coding models optimized for mean squared error (MSE). However, MSE-oriented optimization tends to yield latent spaces with limited semantic richness, which hinders effective semantic inference in downstream tasks. Moreover, achieving high performance with these models often requires fine-tuning the entire vision model, which is computationally intensive, especially for large models. To address these problems, we introduce Perception-Oriented Latent Coding (POLC), an approach that enriches the semantic content of latent features for high-performance compressed domain semantic inference. With the semantically rich latent space, POLC requires only a plug-and-play adapter for fine-tuning, significantly reducing the parameter count compared to previous MSE-oriented methods. Experimental results demonstrate that POLC achieves rate-perception performance comparable to state-of-the-art generative image coding methods while markedly enhancing performance in vision tasks, with minimal fine-tuning overhead. Code is available at https://github.com/NJUVISION/POLC.</article>","contentLength":1208,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems","url":"https://arxiv.org/abs/2507.01607","date":1751515200,"author":"","guid":182253,"unread":true,"content":"<article>arXiv:2507.01607v1 Announce Type: new \nAbstract: The widespread use of deep learning face recognition raises several security concerns. Although prior works point at existing vulnerabilities, DNN backdoor attacks against real-life, unconstrained systems dealing with images captured in the wild remain a blind spot of the literature. This paper conducts the first system-level study of backdoors in deep learning-based face recognition systems. This paper yields four contributions by exploring the feasibility of DNN backdoors on these pipelines in a holistic fashion. We demonstrate for the first time two backdoor attacks on the face detection task: face generation and face landmark shift attacks. We then show that face feature extractors trained with large margin losses also fall victim to backdoor attacks. Combining our models, we then show using 20 possible pipeline configurations and 15 attack cases that a single backdoor enables an attacker to bypass the entire function of a system. Finally, we provide stakeholders with several best practices and countermeasures.</article>","contentLength":1079,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation","url":"https://arxiv.org/abs/2507.01603","date":1751515200,"author":"","guid":182254,"unread":true,"content":"<article>arXiv:2507.01603v1 Announce Type: new \nAbstract: Diffusion-based video depth estimation methods have achieved remarkable success with strong generalization ability. However, predicting depth for long videos remains challenging. Existing methods typically split videos into overlapping sliding windows, leading to accumulated scale discrepancies across different windows, particularly as the number of windows increases. Additionally, these methods rely solely on 2D diffusion priors, overlooking the inherent 3D geometric structure of video depths, which results in geometrically inconsistent predictions. In this paper, we propose DepthSync, a novel, training-free framework using diffusion guidance to achieve scale- and geometry-consistent depth predictions for long videos. Specifically, we introduce scale guidance to synchronize the depth scale across windows and geometry guidance to enforce geometric alignment within windows based on the inherent 3D constraints in video depths. These two terms work synergistically, steering the denoising process toward consistent depth predictions. Experiments on various datasets validate the effectiveness of our method in producing depth estimates with improved scale and geometry consistency, particularly for long videos.</article>","contentLength":1271,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems","url":"https://arxiv.org/abs/2507.01599","date":1751515200,"author":"","guid":182255,"unread":true,"content":"<article>arXiv:2507.01599v1 Announce Type: new \nAbstract: Traditional Data+AI systems utilize data-driven techniques to optimize performance, but they rely heavily on human experts to orchestrate system pipelines, enabling them to adapt to changes in data, queries, tasks, and environments. For instance, while there are numerous data science tools available, developing a pipeline planning system to coordinate these tools remains challenging. This difficulty arises because existing Data+AI systems have limited capabilities in semantic understanding, reasoning, and planning. Fortunately, we have witnessed the success of large language models (LLMs) in enhancing semantic understanding, reasoning, and planning abilities. It is crucial to incorporate LLM techniques to revolutionize data systems for orchestrating Data+AI applications effectively.\n  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive architecture designed to orchestrate Data+AI ecosystems, which focuses on tackling data-related tasks by integrating knowledge comprehension, reasoning, and planning capabilities. We delve into the challenges involved in designing data agents, such as understanding data/queries/environments/tools, orchestrating pipelines/workflows, optimizing and executing pipelines, and fostering pipeline self-reflection. Furthermore, we present examples of data agent systems, including a data science agent, data analytics agents (such as unstructured data analytics agent, semantic structured data analytics agent, data lake analytics agent, and multi-modal data analytics agent), and a database administrator (DBA) agent. We also outline several open challenges associated with designing data agent systems.</article>","contentLength":1720,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Analysis of Muon's Convergence and Critical Batch Size","url":"https://arxiv.org/abs/2507.01598","date":1751515200,"author":"","guid":182256,"unread":true,"content":"<article>arXiv:2507.01598v1 Announce Type: new \nAbstract: This paper presents a theoretical analysis of Muon, a new optimizer that leverages the inherent matrix structure of neural network parameters. We provide convergence proofs for four practical variants of Muon: with and without Nesterov momentum, and with and without weight decay. We then show that adding weight decay leads to strictly tighter bounds on both the parameter and gradient norms, and we clarify the relationship between the weight decay coefficient and the learning rate. Finally, we derive Muon's critical batch size minimizing the stochastic first-order oracle (SFO) complexity, which is the stochastic computational cost, and validate our theoretical findings with experiments.</article>","contentLength":743,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning","url":"https://arxiv.org/abs/2507.01597","date":1751515200,"author":"","guid":182257,"unread":true,"content":"<article>arXiv:2507.01597v1 Announce Type: new \nAbstract: Temporal Knowledge Graph (TKG) is an efficient method for describing the dynamic development of facts along a timeline. Most research on TKG reasoning (TKGR) focuses on modelling the repetition of global facts and designing patterns of local historical facts. However, they face two significant challenges: inadequate modeling of the event distribution shift between training and test samples, and reliance on random entity substitution for generating negative samples, which often results in low-quality sampling. To this end, we propose a novel distributional feature modeling approach for training TKGR models, Test-Time Training-guided Distribution shift Modelling (T3DM), to adjust the model based on distribution shift and ensure the global consistency of model reasoning. In addition, we design a negative-sampling strategy to generate higher-quality negative quadruples based on adversarial training. Extensive experiments show that T3DM provides better and more robust results than the state-of-the-art baselines in most cases.</article>","contentLength":1085,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Emotionally Intelligent Task-oriented Dialogue Systems: Architecture, Representation, and Optimisation","url":"https://arxiv.org/abs/2507.01594","date":1751515200,"author":"","guid":182258,"unread":true,"content":"<article>arXiv:2507.01594v1 Announce Type: new \nAbstract: Task-oriented dialogue (ToD) systems are designed to help users achieve specific goals through natural language interaction. While recent advances in large language models (LLMs) have significantly improved linguistic fluency and contextual understanding, building effective and emotionally intelligent ToD systems remains a complex challenge. Effective ToD systems must optimise for task success, emotional understanding and responsiveness, and precise information conveyance, all within inherently noisy and ambiguous conversational environments. In this work, we investigate architectural, representational, optimisational as well as emotional considerations of ToD systems. We set up systems covering these design considerations with a challenging evaluation environment composed of a natural-language user simulator coupled with an imperfect natural language understanding module. We propose \\textbf{LUSTER}, an \\textbf{L}LM-based \\textbf{U}nified \\textbf{S}ystem for \\textbf{T}ask-oriented dialogue with \\textbf{E}nd-to-end \\textbf{R}einforcement learning with both short-term (user sentiment) and long-term (task success) rewards. Our findings demonstrate that combining LLM capability with structured reward modelling leads to more resilient and emotionally responsive ToD systems, offering a practical path forward for next-generation conversational agents.</article>","contentLength":1415,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring","url":"https://arxiv.org/abs/2507.01590","date":1751515200,"author":"","guid":182259,"unread":true,"content":"<article>arXiv:2507.01590v1 Announce Type: new \nAbstract: This study presents a novel classroom surveillance system that integrates multiple modalities, including drowsiness, tracking of mobile phone usage, and face recognition,to assess student attentiveness with enhanced precision.The system leverages the YOLOv8 model to detect both mobile phone and sleep usage,(Ghatge et al., 2024) while facial recognition is achieved through LResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These models work in synergy to provide comprehensive, real-time monitoring, offering insights into student engagement and behavior.(S et al., 2023) The framework is trained on specialized datasets, such as the RMFD dataset for face recognition and a Roboflow dataset for mobile phone detection. The extensive evaluation of the system shows promising results. Sleep detection achieves 97. 42% mAP@50, face recognition achieves 86. 45% validation accuracy and mobile phone detection reach 85. 89% mAP@50. The system is implemented within a core PHP web application and utilizes ESP32-CAM hardware for seamless data capture.(Neto et al., 2024) This integrated approach not only enhances classroom monitoring, but also ensures automatic attendance recording via face recognition as students remain seated in the classroom, offering scalability for diverse educational environments.(Banada,2025)</article>","contentLength":1386,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards Controllable Real Image Denoising with Camera Parameters","url":"https://arxiv.org/abs/2507.01587","date":1751515200,"author":"","guid":182260,"unread":true,"content":"<article>arXiv:2507.01587v1 Announce Type: new \nAbstract: Recent deep learning-based image denoising methods have shown impressive performance; however, many lack the flexibility to adjust the denoising strength based on the noise levels, camera settings, and user preferences. In this paper, we introduce a new controllable denoising framework that adaptively removes noise from images by utilizing information from camera parameters. Specifically, we focus on ISO, shutter speed, and F-number, which are closely related to noise levels. We convert these selected parameters into a vector to control and enhance the performance of the denoising network. Experimental results show that our method seamlessly adds controllability to standard denoising neural networks and improves their performance. Code is available at https://github.com/OBAKSA/CPADNet.</article>","contentLength":845,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation","url":"https://arxiv.org/abs/2507.01586","date":1751515200,"author":"","guid":182261,"unread":true,"content":"<article>arXiv:2507.01586v1 Announce Type: new \nAbstract: The production of high-quality 2D animation is highly labor-intensive process, as animators are currently required to draw and color a large number of frames by hand. We present SketchColour, the first sketch-to-colour pipeline for 2D animation built on a diffusion transformer (DiT) backbone. By replacing the conventional U-Net denoiser with a DiT-style architecture and injecting sketch information via lightweight channel-concatenation adapters accompanied with LoRA finetuning, our method natively integrates conditioning without the parameter and memory bloat of a duplicated ControlNet, greatly reducing parameter count and GPU memory usage. Evaluated on the SAKUGA dataset, SketchColour outperforms previous state-of-the-art video colourization methods across all metrics, despite using only half the training data of competing models. Our approach produces temporally coherent animations with minimal artifacts such as colour bleeding or object deformation. Our code is available at: https://bconstantine.github.io/SketchColour .</article>","contentLength":1087,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder","url":"https://arxiv.org/abs/2507.01582","date":1751515200,"author":"","guid":182262,"unread":true,"content":"<article>arXiv:2507.01582v1 Announce Type: new \nAbstract: The creativity of classical music arises not only from composers who craft the musical sheets but also from performers who interpret the static notations with expressive nuances. This paper addresses the challenge of generating classical piano performances from scratch, aiming to emulate the dual roles of composer and pianist in the creative process. We introduce the Expressive Compound Word (ECP) representation, which effectively captures both the metrical structure and expressive nuances of classical performances. Building on this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a model featuring two branches: a Vector Quantized Variational AutoEncoder (VQ-VAE) branch that generates score-related content, representing the Composer, and a vanilla VAE branch that produces expressive details, fulfilling the role of Pianist. These branches are jointly trained with similar Seq2Seq architectures, leveraging a multiscale encoder to capture beat-level contextual information and an orthogonal Transformer decoder for efficient compound tokens decoding. Both objective and subjective evaluations demonstrate that XMVAE generates classical performances with superior musical quality compared to state-of-the-art models. Furthermore, pretraining the Composer branch on extra musical score datasets contribute to a significant performance gain.</article>","contentLength":1414,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Privacy-Preserving Indoor Localization System based on Hierarchical Federated Learning","url":"https://arxiv.org/abs/2507.01581","date":1751515200,"author":"","guid":182263,"unread":true,"content":"<article>arXiv:2507.01581v1 Announce Type: new \nAbstract: Location information serves as the fundamental element for numerous Internet of Things (IoT) applications. Traditional indoor localization techniques often produce significant errors and raise privacy concerns due to centralized data collection. In response, Machine Learning (ML) techniques offer promising solutions by capturing indoor environment variations. However, they typically require central data aggregation, leading to privacy, bandwidth, and server reliability issues. To overcome these challenges, in this paper, we propose a Federated Learning (FL)-based approach for dynamic indoor localization using a Deep Neural Network (DNN) model. Experimental results show that FL has the nearby performance to Centralized Model (CL) while keeping the data privacy, bandwidth efficiency and server reliability. This research demonstrates that our proposed FL approach provides a viable solution for privacy-enhanced indoor localization, paving the way for advancements in secure and efficient indoor localization systems.</article>","contentLength":1075,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Interpolation with Automated First-Order Reasoning","url":"https://arxiv.org/abs/2507.01577","date":1751515200,"author":"","guid":182264,"unread":true,"content":"<article>arXiv:2507.01577v1 Announce Type: new \nAbstract: We consider interpolation from the viewpoint of fully automated theorem proving in first-order logic as a general core technique for mechanized knowledge processing. For Craig interpolation, our focus is on the two-stage approach, where first an essentially propositional ground interpolant is calculated that is then lifted to a quantified first-order formula. We discuss two possibilities to obtain a ground interpolant from a proof, with clausal tableaux, and with resolution. Established preprocessing techniques for first-order proving can also be applied for Craig interpolation if they are restricted in specific ways. Equality encodings from automated reasoning justify strengthened variations of Craig interpolation. Also further contributions to Craig interpolation emerged from automated reasoning. As an approach to uniform interpolation we introduce second-order quantifier elimination with examples and describe the basic algorithms DLS and SCAN.</article>","contentLength":1009,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Vision-Aided ISAC in Low-Altitude Economy Networks via De-Diffused Visual Priors","url":"https://arxiv.org/abs/2507.01574","date":1751515200,"author":"","guid":182265,"unread":true,"content":"<article>arXiv:2507.01574v1 Announce Type: new \nAbstract: Emerging low-altitude economy networks (LAENets) require agile and privacy-preserving resource control under dynamic agent mobility and limited infrastructure support. To meet these challenges, we propose a vision-aided integrated sensing and communication (ISAC) framework for UAV-assisted access systems, where onboard masked De-Diffusion models extract compact semantic tokens, including agent type, activity class, and heading orientation, while explicitly suppressing sensitive visual content. These tokens are fused with mmWave radar measurements to construct a semantic risk heatmap reflecting motion density, occlusion, and scene complexity, which guides access technology selection and resource scheduling. We formulate a multi-objective optimization problem to jointly maximize weighted energy and perception efficiency via radio access technology (RAT) assignment, power control, and beamforming, subject to agent-specific QoS constraints. To solve this, we develop De-Diffusion-driven vision-aided risk-aware resource optimization algorithm DeDiff-VARARO, a novel two-stage cross-modal control algorithm: the first stage reconstructs visual scenes from tokens via De-Diffusion model for semantic parsing, while the second stage employs a deep deterministic policy gradient (DDPG)-based policy to adapt RAT selection, power control, and beam assignment based on fused radar-visual states. Simulation results show that DeDiff-VARARO consistently outperforms baselines in reward convergence, link robustness, and semantic fidelity, achieving within $4\\%$ of the performance of a raw-image upper bound while preserving user privacy and scalability in dense environments.</article>","contentLength":1727,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation","url":"https://arxiv.org/abs/2507.01573","date":1751515200,"author":"","guid":182266,"unread":true,"content":"<article>arXiv:2507.01573v1 Announce Type: new \nAbstract: Remote sensing semantic segmentation must address both what the ground objects are within an image and where they are located. Consequently, segmentation models must ensure not only the semantic correctness of large-scale patches (low-frequency information) but also the precise localization of boundaries between patches (high-frequency information). However, most existing approaches rely heavily on discriminative learning, which excels at capturing low-frequency features, while overlooking its inherent limitations in learning high-frequency features for semantic segmentation. Recent studies have revealed that diffusion generative models excel at generating high-frequency details. Our theoretical analysis confirms that the diffusion denoising process significantly enhances the model's ability to learn high-frequency features; however, we also observe that these models exhibit insufficient semantic inference for low-frequency features when guided solely by the original image. Therefore, we integrate the strengths of both discriminative and generative learning, proposing the Integration of Discriminative and diffusion-based Generative learning for Boundary Refinement (IDGBR) framework. The framework first generates a coarse segmentation map using a discriminative backbone model. This map and the original image are fed into a conditioning guidance network to jointly learn a guidance representation subsequently leveraged by an iterative denoising diffusion process refining the coarse segmentation. Extensive experiments across five remote sensing semantic segmentation datasets (binary and multi-class segmentation) confirm our framework's capability of consistent boundary refinement for coarse results from diverse discriminative architectures. The source code will be available at https://github.com/KeyanHu-git/IDGBR.</article>","contentLength":1890,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On the Effect of Ruleset Tuning and Data Imbalance on Explainable Network Security Alert Classifications: a Case-Study on DeepCASE","url":"https://arxiv.org/abs/2507.01571","date":1751515200,"author":"","guid":182267,"unread":true,"content":"<article>arXiv:2507.01571v1 Announce Type: new \nAbstract: Automation in Security Operations Centers (SOCs) plays a prominent role in alert classification and incident escalation. However, automated methods must be robust in the presence of imbalanced input data, which can negatively affect performance. Additionally, automated methods should make explainable decisions. In this work, we evaluate the effect of label imbalance on the classification of network intrusion alerts. As our use-case we employ DeepCASE, the state-of-the-art method for automated alert classification. We show that label imbalance impacts both classification performance and correctness of the classification explanations offered by DeepCASE. We conclude tuning the detection rules used in SOCs can significantly reduce imbalance and may benefit the performance and explainability offered by alert post-processing methods such as DeepCASE. Therefore, our findings suggest that traditional methods to improve the quality of input data can benefit automation.</article>","contentLength":1024,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Time-Varying Coverage Control: A Distributed Tracker-Planner MPC Framework","url":"https://arxiv.org/abs/2507.01567","date":1751515200,"author":"","guid":182268,"unread":true,"content":"<article>arXiv:2507.01567v1 Announce Type: new \nAbstract: Time-varying coverage control addresses the challenge of coordinating multiple agents covering an environment where regions of interest change over time. This problem has broad applications, including the deployment of autonomous taxis and coordination in search and rescue operations. The achievement of effective coverage is complicated by the presence of time-varying density functions, nonlinear agent dynamics, and stringent system and safety constraints. In this paper, we present a distributed multi-agent control framework for time-varying coverage under nonlinear constrained dynamics. Our approach integrates a reference trajectory planner and a tracking model predictive control (MPC) scheme, which operate at different frequencies within a multi-rate framework. For periodic density functions, we demonstrate closed-loop convergence to an optimal configuration of trajectories and provide formal guarantees regarding constraint satisfaction, collision avoidance, and recursive feasibility. Additionally, we propose an efficient algorithm capable of handling nonperiodic density functions, making the approach suitable for practical applications. Finally, we validate our method through hardware experiments using a fleet of four miniature race cars.</article>","contentLength":1310,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real-Time Emergency Vehicle Siren Detection with Efficient CNNs on Embedded Hardware","url":"https://arxiv.org/abs/2507.01563","date":1751515200,"author":"","guid":182269,"unread":true,"content":"<article>arXiv:2507.01563v1 Announce Type: new \nAbstract: We present a full-stack emergency vehicle (EV) siren detection system designed for real-time deployment on embedded hardware. The proposed approach is based on E2PANNs, a fine-tuned convolutional neural network derived from EPANNs, and optimized for binary sound event detection under urban acoustic conditions. A key contribution is the creation of curated and semantically structured datasets - AudioSet-EV, AudioSet-EV Augmented, and Unified-EV - developed using a custom AudioSet-Tools framework to overcome the low reliability of standard AudioSet annotations. The system is deployed on a Raspberry Pi 5 equipped with a high-fidelity DAC+microphone board, implementing a multithreaded inference engine with adaptive frame sizing, probability smoothing, and a decision-state machine to control false positive activations. A remote WebSocket interface provides real-time monitoring and facilitates live demonstration capabilities. Performance is evaluated using both framewise and event-based metrics across multiple configurations. Results show the system achieves low-latency detection with improved robustness under realistic audio conditions. This work demonstrates the feasibility of deploying IoS-compatible SED solutions that can form distributed acoustic monitoring networks, enabling collaborative emergency vehicle tracking across smart city infrastructures through WebSocket connectivity on low-cost edge devices.</article>","contentLength":1476,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Self-Closing Suction Grippers for Industrial Grasping via Form-Flexible Design","url":"https://arxiv.org/abs/2507.01561","date":1751515200,"author":"","guid":182270,"unread":true,"content":"<article>arXiv:2507.01561v1 Announce Type: new \nAbstract: Shape-morphing robots have shown benefits in industrial grasping. We propose form-flexible grippers for adaptive grasping. The design is based on the hybrid jamming and suction mechanism, which deforms to handle objects that vary significantly in size from the aperture, including both larger and smaller parts. Compared with traditional grippers, the gripper achieves self-closing to form an airtight seal. Under a vacuum, a wide range of grasping is realized through the passive morphing mechanism at the interface that harmonizes pressure and flow rate. This hybrid gripper showcases the capability to securely grasp an egg, as small as 54.5% of its aperture, while achieving a maximum load-to-mass ratio of 94.3.</article>","contentLength":765,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks","url":"https://arxiv.org/abs/2507.01559","date":1751515200,"author":"","guid":182271,"unread":true,"content":"<article>arXiv:2507.01559v1 Announce Type: new \nAbstract: Recent work in continual learning has highlighted the beneficial effect of resampling weights in the last layer of a neural network (``zapping\"). Although empirical results demonstrate the effectiveness of this approach, the underlying mechanisms that drive these improvements remain unclear. In this work, we investigate in detail the pattern of learning and forgetting that take place inside a convolutional neural network when trained in challenging settings such as continual learning and few-shot transfer learning, with handwritten characters and natural images. Our experiments show that models that have undergone zapping during training more quickly recover from the shock of transferring to a new domain. Furthermore, to better observe the effect of continual learning in a multi-task setting we measure how each individual task is affected. This shows that, not only zapping, but the choice of optimizer can also deeply affect the dynamics of learning and forgetting, causing complex patterns of synergy/interference between tasks to emerge when the model learns sequentially at transfer time.</article>","contentLength":1153,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Interpolation-Based Event Visual Data Filtering Algorithms","url":"https://arxiv.org/abs/2507.01557","date":1751515200,"author":"","guid":182272,"unread":true,"content":"<article>arXiv:2507.01557v1 Announce Type: new \nAbstract: The field of neuromorphic vision is developing rapidly, and event cameras are finding their way into more and more applications. However, the data stream from these sensors is characterised by significant noise. In this paper, we propose a method for event data that is capable of removing approximately 99\\% of noise while preserving the majority of the valid signal. We have proposed four algorithms based on the matrix of infinite impulse response (IIR) filters method. We compared them on several event datasets that were further modified by adding artificially generated noise and noise recorded with dynamic vision sensor. The proposed methods use about 30KB of memory for a sensor with a resolution of 1280 x 720 and is therefore well suited for implementation in embedded devices.</article>","contentLength":837,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A mixed Petrov--Galerkin Cosserat rod finite element formulation","url":"https://arxiv.org/abs/2507.01552","date":1751515200,"author":"","guid":182273,"unread":true,"content":"<article>arXiv:2507.01552v1 Announce Type: new \nAbstract: This paper presents a total Lagrangian mixed Petrov--Galerkin finite element formulation that provides a computationally efficient approach for analyzing Cosserat rods that is free of singularities and locking. To achieve a singularity-free orientation parametrization of the rod, the nodal kinematical unknowns are defined as the nodal centerline positions and unit quaternions. We apply Lagrangian interpolation to all nodal kinematic coordinates, and in combination with a projection of non-unit quaternions, this leads to an interpolation with orthonormal cross-section-fixed bases. To eliminate locking effects such as shear locking, the variational Hellinger--Reissner principle is applied, resulting in a mixed approach with additional fields composed of resultant contact forces and moments. Since the mixed formulation contains the constitutive law in compliance form, it naturally incorporates constrained theories, such as the Kirchhoff--Love theory. This study specifically examines the influence of the additional internal force fields on the numerical performance, including locking mitigation and robustness. Using well-established benchmark examples, the method demonstrates enhanced computational robustness and efficiency, as evidenced by the reduction in required load steps and iterations when applying the standard Newton--Raphson method.</article>","contentLength":1408,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning","url":"https://arxiv.org/abs/2507.01551","date":1751515200,"author":"","guid":182274,"unread":true,"content":"<article>arXiv:2507.01551v1 Announce Type: new \nAbstract: Process Reinforcement Learning~(PRL) has demonstrated considerable potential in enhancing the reasoning capabilities of Large Language Models~(LLMs). However, introducing additional process reward models incurs substantial computational overhead, and there is no unified theoretical framework for process-level advantage estimation. To bridge this gap, we propose \\textbf{S}elf-Guided \\textbf{P}rocess \\textbf{R}eward \\textbf{O}ptimization~(\\textbf{SPRO}), a novel framework that enables process-aware RL through two key innovations: (1) we first theoretically demonstrate that process rewards can be derived intrinsically from the policy model itself, and (2) we introduce well-defined cumulative process rewards and \\textbf{M}asked \\textbf{S}tep \\textbf{A}dvantage (\\textbf{MSA}), which facilitates rigorous step-wise action advantage estimation within shared-prompt sampling groups. Our experimental results demonstrate that SPRO outperforms vaniila GRPO with 3.4x higher training efficiency and a 17.5\\% test accuracy improvement. Furthermore, SPRO maintains a stable and elevated policy entropy throughout training while reducing the average response length by approximately $1/3$, evidencing sufficient exploration and prevention of reward hacking. Notably, SPRO incurs no additional computational overhead compared to outcome-supervised RL methods such as GRPO, which benefit industrial implementation.</article>","contentLength":1458,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dynamic System Model Generation for Online Fault Detection and Diagnosis of Robotic Systems","url":"https://arxiv.org/abs/2507.01550","date":1751515200,"author":"","guid":182275,"unread":true,"content":"<article>arXiv:2507.01550v1 Announce Type: new \nAbstract: With the rapid development of more complex robots, Fault Detection and Diagnosis (FDD) becomes increasingly harder. Especially the need for predetermined models and historic data is problematic because they do not encompass the dynamic and fast-changing nature of such systems. To this end, we propose a concept that actively generates a dynamic system model at runtime and utilizes it to locate root causes. The goal is to be applicable to all kinds of robotic systems that share a similar software design. Additionally, it should exhibit minimal overhead and enhance independence from expert attention.</article>","contentLength":653,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants","url":"https://arxiv.org/abs/2507.01548","date":1751515200,"author":"","guid":182276,"unread":true,"content":"<article>arXiv:2507.01548v1 Announce Type: new \nAbstract: This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.</article>","contentLength":929,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI and Remote Sensing for Resilient and Sustainable Built Environments: A Review of Current Methods, Open Data and Future Directions","url":"https://arxiv.org/abs/2507.01547","date":1751515200,"author":"","guid":182277,"unread":true,"content":"<article>arXiv:2507.01547v1 Announce Type: new \nAbstract: Critical infrastructure, such as transport networks, underpins economic growth by enabling mobility and trade. However, ageing assets, climate change impacts (e.g., extreme weather, rising sea levels), and hybrid threats ranging from natural disasters to cyber attacks and conflicts pose growing risks to their resilience and functionality. This review paper explores how emerging digital technologies, specifically Artificial Intelligence (AI), can enhance damage assessment and monitoring of transport infrastructure. A systematic literature review examines existing AI models and datasets for assessing damage in roads, bridges, and other critical infrastructure impacted by natural disasters. Special focus is given to the unique challenges and opportunities associated with bridge damage detection due to their structural complexity and critical role in connectivity. The integration of SAR (Synthetic Aperture Radar) data with AI models is also discussed, with the review revealing a critical research gap: a scarcity of studies applying AI models to SAR data for comprehensive bridge damage assessment. Therefore, this review aims to identify the research gaps and provide foundations for AI-driven solutions for assessing and monitoring critical transport infrastructures.</article>","contentLength":1329,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MARVIS: Modality Adaptive Reasoning over VISualizations","url":"https://arxiv.org/abs/2507.01544","date":1751515200,"author":"","guid":182278,"unread":true,"content":"<article>arXiv:2507.01544v1 Announce Type: new \nAbstract: Scientific applications of machine learning often rely on small, specialized models tuned to particular domains. Such models often achieve excellent performance, but lack flexibility. Foundation models offer versatility, but typically underperform specialized approaches, especially on non-traditional modalities and long-tail domains. We propose MARVIS (Modality Adaptive Reasoning over VISualizations), a training-free method that enables even small vision-language models to predict any data modality with high accuracy. MARVIS transforms latent embedding spaces into visual representations and then leverages the spatial and fine-grained reasoning skills of VLMs to successfully interpret and utilize them. MARVIS achieves competitive performance on vision, audio, biological, and tabular domains using a single 3B parameter model, achieving results that beat Gemini by 16\\% on average and approach specialized methods, without exposing personally identifiable information (P.I.I.) or requiring any domain-specific training. We open source our code and datasets at https://github.com/penfever/marvis</article>","contentLength":1152,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is External Information Useful for Stance Detection with LLMs?","url":"https://arxiv.org/abs/2507.01543","date":1751515200,"author":"","guid":182279,"unread":true,"content":"<article>arXiv:2507.01543v1 Announce Type: new \nAbstract: In the stance detection task, a text is classified as either favorable, opposing, or neutral towards a target. Prior work suggests that the use of external information, e.g., excerpts from Wikipedia, improves stance detection performance. However, whether or not such information can benefit large language models (LLMs) remains an unanswered question, despite their wide adoption in many reasoning tasks. In this study, we conduct a systematic evaluation on how Wikipedia and web search external information can affect stance detection across eight LLMs and in three datasets with 12 targets. Surprisingly, we find that such information degrades performance in most cases, with macro F1 scores dropping by up to 27.9\\%. We explain this through experiments showing LLMs' tendency to align their predictions with the stance and sentiment of the provided information rather than the ground truth stance of the given text. We also find that performance degradation persists with chain-of-thought prompting, while fine-tuning mitigates but does not fully eliminate it. Our findings, in contrast to previous literature on BERT-based systems which suggests that external information enhances performance, highlight the risks of information biases in LLM-based stance classifiers. Code is available at https://github.com/ngqm/acl2025-stance-detection.</article>","contentLength":1393,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing","url":"https://arxiv.org/abs/2507.01541","date":1751515200,"author":"","guid":182280,"unread":true,"content":"<article>arXiv:2507.01541v1 Announce Type: new \nAbstract: Out-of-scope (OOS) intent detection is a critical challenge in task-oriented dialogue systems (TODS), as it ensures robustness to unseen and ambiguous queries. In this work, we propose a novel but simple modular framework that combines uncertainty modeling with fine-tuned large language models (LLMs) for efficient and accurate OOS detection. The first step applies uncertainty estimation to the output of an in-scope intent detection classifier, which is currently deployed in a real-world TODS handling tens of thousands of user interactions daily. The second step then leverages an emerging LLM-based approach, where a fine-tuned LLM is triggered to make a final decision on instances with high uncertainty. Unlike prior approaches, our method effectively balances computational efficiency and performance, combining traditional approaches with LLMs and yielding state-of-the-art results on key OOS detection benchmarks, including real-world OOS data acquired from a deployed TODS.</article>","contentLength":1034,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Multi-Centric Anthropomorphic 3D CT Phantom-Based Benchmark Dataset for Harmonization","url":"https://arxiv.org/abs/2507.01539","date":1751515200,"author":"","guid":182281,"unread":true,"content":"<article>arXiv:2507.01539v1 Announce Type: new \nAbstract: Artificial intelligence (AI) has introduced numerous opportunities for human assistance and task automation in medicine. However, it suffers from poor generalization in the presence of shifts in the data distribution. In the context of AI-based computed tomography (CT) analysis, significant data distribution shifts can be caused by changes in scanner manufacturer, reconstruction technique or dose. AI harmonization techniques can address this problem by reducing distribution shifts caused by various acquisition settings. This paper presents an open-source benchmark dataset containing CT scans of an anthropomorphic phantom acquired with various scanners and settings, which purpose is to foster the development of AI harmonization techniques. Using a phantom allows fixing variations attributed to inter- and intra-patient variations. The dataset includes 1378 image series acquired with 13 scanners from 4 manufacturers across 8 institutions using a harmonized protocol as well as several acquisition doses. Additionally, we present a methodology, baseline results and open-source code to assess image- and feature-level stability and liver tissue classification, promoting the development of AI harmonization strategies.</article>","contentLength":1277,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cybersecurity Issues in Local Energy Markets","url":"https://arxiv.org/abs/2507.01536","date":1751515200,"author":"","guid":182282,"unread":true,"content":"<article>arXiv:2507.01536v1 Announce Type: new \nAbstract: Local Energy Markets (LEMs), though pivotal to the energy transition, face growing cybersecurity threats due to their reliance on smart grid communication standards and vulnerable Internet-of-Things (IoT)-enabled devices. This is a critical issue because such vulnerabilities can be exploited to manipulate market operations, compromise participants' privacy, and destabilize power distribution networks. This work maps LEM communication flows to existing standards, highlights potential impacts of key identified vulnerabilities, and simulates cyberattack scenarios on a privacy-preserving LEM model to assess their impacts. Findings reveal how attackers could distort pricing and demand patterns. We finally present recommendations for researchers, industry developers, policymakers, and LEM stakeholders to secure future LEM deployments.</article>","contentLength":889,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking","url":"https://arxiv.org/abs/2507.01535","date":1751515200,"author":"","guid":182283,"unread":true,"content":"<article>arXiv:2507.01535v1 Announce Type: new \nAbstract: The Vision Transformer (ViT) model has long struggled with the challenge of quadratic complexity, a limitation that becomes especially critical in unmanned aerial vehicle (UAV) tracking systems, where data must be processed in real time. In this study, we explore the recently proposed State-Space Model, Mamba, leveraging its computational efficiency and capability for long-sequence modeling to effectively process dense image sequences in tracking tasks. First, we highlight the issue of temporal inconsistency in existing Mamba-based methods, specifically the failure to account for temporal continuity in the Mamba scanning mechanism. Secondly, building upon this insight,we propose TrackingMiM, a Mamba-in-Mamba architecture, a minimal-computation burden model for handling image sequence of tracking problem. In our framework, the mamba scan is performed in a nested way while independently process temporal and spatial coherent patch tokens. While the template frame is encoded as query token and utilized for tracking in every scan. Extensive experiments conducted on five UAV tracking benchmarks confirm that the proposed TrackingMiM achieves state-of-the-art precision while offering noticeable higher speed in UAV tracking.</article>","contentLength":1284,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Consistency of Learned Sparse Grid Quadrature Rules using NeuralODEs","url":"https://arxiv.org/abs/2507.01533","date":1751515200,"author":"","guid":182284,"unread":true,"content":"<article>arXiv:2507.01533v1 Announce Type: new \nAbstract: This paper provides a proof of the consistency of sparse grid quadrature for numerical integration of high dimensional distributions. In a first step, a transport map is learned that normalizes the distribution to a noise distribution on the unit cube. This step is built on the statistical learning theory of neural ordinary differential equations, which has been established recently. Secondly, the composition of the generative map with the quantity of interest is integrated numerically using the Clenshaw-Curtis sparse grid quadrature. A decomposition of the total numerical error in quadrature error and statistical error is provided. As main result it is proven in the framework of empirical risk minimization that all error terms can be controlled in the sense of PAC (probably approximately correct) learning and with high probability the numerical integral approximates the theoretical value up to an arbitrary small error in the limit where the data set size is growing and the network capacity is increased adaptively.</article>","contentLength":1079,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights","url":"https://arxiv.org/abs/2507.01532","date":1751515200,"author":"","guid":182285,"unread":true,"content":"<article>arXiv:2507.01532v1 Announce Type: new \nAbstract: Sign Language Translation (SLT) has evolved significantly, moving from isolated recognition approaches to complex, continuous gloss-free translation systems. This paper explores the impact of pose-based data preprocessing techniques - normalization, interpolation, and augmentation - on SLT performance. We employ a transformer-based architecture, adapting a modified T5 encoder-decoder model to process pose representations. Through extensive ablation studies on YouTubeASL and How2Sign datasets, we analyze how different preprocessing strategies affect translation accuracy. Our results demonstrate that appropriate normalization, interpolation, and augmentation techniques can significantly improve model robustness and generalization abilities. Additionally, we provide a deep analysis of the model's attentions and reveal interesting behavior suggesting that adding a dedicated register token can improve overall model performance. We publish our code on our GitHub repository, including the preprocessed YouTubeASL data.</article>","contentLength":1075,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A surface finite element scheme for a stochastic PDE on an evolving curve","url":"https://arxiv.org/abs/2507.01527","date":1751515200,"author":"","guid":182286,"unread":true,"content":"<article>arXiv:2507.01527v1 Announce Type: new \nAbstract: In this paper we consider an ESFEM method for the advection and diffusion of a scalar quantity on a moving closed curve. The diffusion process is controlled by a forcing term that may include a rough term (specifically a stochastic noise) which in particular destroys the classical time differentiability properties of the solution. We provide a suitable variational solution concept and a fully discrete FEM discretization. Our error analysis appropriately generalizes classical estimates to this weaker setting. We present some numerical simulations that confirm our theoretical findings.</article>","contentLength":639,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Diversity-Preserving Exploitation of Crossover","url":"https://arxiv.org/abs/2507.01524","date":1751515200,"author":"","guid":182287,"unread":true,"content":"<article>arXiv:2507.01524v1 Announce Type: new \nAbstract: Crossover is a powerful mechanism for generating new solutions from a given population of solutions. Crossover comes with a discrepancy in itself: on the one hand, crossover usually works best if there is enough diversity in the population; on the other hand, exploiting the benefits of crossover reduces diversity. This antagonism often makes crossover reduce its own effectiveness.\n  We introduce a new paradigm for utilizing crossover that reduces this antagonism, which we call diversity-preserving exploitation of crossover (DiPEC). The resulting Diversity Exploitation Genetic Algorithm (DEGA) is able to still exploit the benefits of crossover, but preserves a much higher diversity than conventional approaches.\n  We demonstrate the benefits by proving that the (2+1)-DEGA finds the optimum of LeadingOnes with $O(n^{5/3}\\log^{2/3} n)$ fitness evaluations. This is remarkable since standard genetic algorithms need $\\Theta(n^2)$ evaluations, and among genetic algorithms only some artificial and specifically tailored algorithms were known to break this runtime barrier. We confirm the theoretical results by simulations. Finally, we show that the approach is not overfitted to Leadingones by testing it empirically on other benchmarks and showing that it is also competitive in other settings. We believe that our findings justify further systematic investigations of the DiPEC paradigm.</article>","contentLength":1445,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Chargax: A JAX Accelerated EV Charging Simulator","url":"https://arxiv.org/abs/2507.01522","date":1751515200,"author":"","guid":182288,"unread":true,"content":"<article>arXiv:2507.01522v1 Announce Type: new \nAbstract: Deep Reinforcement Learning can play a key role in addressing sustainable energy challenges. For instance, many grid systems are heavily congested, highlighting the urgent need to enhance operational efficiency. However, reinforcement learning approaches have traditionally been slow due to the high sample complexity and expensive simulation requirements. While recent works have effectively used GPUs to accelerate data generation by converting environments to JAX, these works have largely focussed on classical toy problems. This paper introduces Chargax, a JAX-based environment for realistic simulation of electric vehicle charging stations designed for accelerated training of RL agents. We validate our environment in a variety of scenarios based on real data, comparing reinforcement learning agents against baselines. Chargax delivers substantial computational performance improvements of over 100x-1000x over existing environments. Additionally, Chargax' modular architecture enables the representation of diverse real-world charging station configurations.</article>","contentLength":1117,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A bibliometric analysis on the current situation and hot trends of the impact of microplastics on soil based on CiteSpace","url":"https://arxiv.org/abs/2507.01520","date":1751515200,"author":"","guid":182289,"unread":true,"content":"<article>arXiv:2507.01520v1 Announce Type: new \nAbstract: This paper aims to comprehensively grasp the research status and development trends of soil microplastics (MPs). It collects studies from the Web of Science Core Collection covering the period from 2013 to 2024. Employing CiteSpace and VOSviewer, the paper conducts in - depth analyses of literature regarding the environmental impacts of microplastics. These analyses involve keyword co - occurrence, clustering, burst term identification, as well as co - occurrence analysis of authors and institutions. Microplastics can accumulate in soil, transfer through food chains, and ultimately affect human health, making the research on them essential for effective pollution control. Focusing on the international research on the impacts of microplastics on soil and ecosystems, the study reveals a steadily increasing trend in the number of publications each year, reaching a peak of 956 articles in 2024. A small number of highly productive authors contribute significantly to the overall research output. The keyword clustering analysis results in ten major clusters, including topics such as plastic pollution and microbial communities. The research on soil microplastics has evolved through three distinct stages: the preliminary exploration phase from 2013 to 2016, the expansion phase from 2017 to 2020, and the integration phase from 2021 to 2024. For future research, multi - level assessments of the impacts of microplastics on soil ecosystems and organisms should be emphasized, in order to fully uncover the associated hazards and develop practical solutions.</article>","contentLength":1617,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Loss Functions in Diffusion Models: A Comparative Study","url":"https://arxiv.org/abs/2507.01516","date":1751515200,"author":"","guid":182290,"unread":true,"content":"<article>arXiv:2507.01516v1 Announce Type: new \nAbstract: Diffusion models have emerged as powerful generative models, inspiring extensive research into their underlying mechanisms. One of the key questions in this area is the loss functions these models shall train with. Multiple formulations have been introduced in the literature over the past several years with some links and some critical differences stemming from various initial considerations. In this paper, we explore the different target objectives and corresponding loss functions in detail. We present a systematic overview of their relationships, unifying them under the framework of the variational lower bound objective. We complement this theoretical analysis with an empirical study providing insights into the conditions under which these objectives diverge in performance and the underlying factors contributing to such deviations. Additionally, we evaluate how the choice of objective impacts the model ability to achieve specific goals, such as generating high-quality samples or accurately estimating likelihoods. This study offers a unified understanding of loss functions in diffusion models, contributing to more efficient and goal-oriented model designs in future research.</article>","contentLength":1243,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism","url":"https://arxiv.org/abs/2507.01513","date":1751515200,"author":"","guid":182291,"unread":true,"content":"<article>arXiv:2507.01513v1 Announce Type: new \nAbstract: By incorporating visual inputs, Multimodal Large Language Models (MLLMs) extend LLMs to support visual reasoning. However, this integration also introduces new vulnerabilities, making MLLMs susceptible to multimodal jailbreak attacks and hindering their safe deployment.Existing defense methods, including Image-to-Text Translation, Safe Prompting, and Multimodal Safety Tuning, attempt to address this by aligning multimodal inputs with LLMs' built-in safeguards.Yet, they fall short in uncovering root causes of multimodal vulnerabilities, particularly how harmful multimodal tokens trigger jailbreak in MLLMs? Consequently, they remain vulnerable to text-driven multimodal jailbreaks, often exhibiting overdefensive behaviors and imposing heavy training overhead.To bridge this gap, we present an comprehensive analysis of where, how and which harmful multimodal tokens bypass safeguards in MLLMs. Surprisingly, we find that less than 1% tokens in early-middle layers are responsible for inducing unsafe behaviors, highlighting the potential of precisely removing a small subset of harmful tokens, without requiring safety tuning, can still effectively improve safety against jailbreaks. Motivated by this, we propose Safe Prune-then-Restore (SafePTR), an training-free defense framework that selectively prunes harmful tokens at vulnerable layers while restoring benign features at subsequent layers.Without incurring additional computational overhead, SafePTR significantly enhances the safety of MLLMs while preserving efficiency. Extensive evaluations across three MLLMs and five benchmarks demonstrate SafePTR's state-of-the-art performance in mitigating jailbreak risks without compromising utility.</article>","contentLength":1757,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation","url":"https://arxiv.org/abs/2507.01509","date":1751515200,"author":"","guid":182292,"unread":true,"content":"<article>arXiv:2507.01509v1 Announce Type: new \nAbstract: Polyp segmentation in colonoscopy images is crucial for early detection and diagnosis of colorectal cancer. However, this task remains a significant challenge due to the substantial variations in polyp shape, size, and color, as well as the high similarity between polyps and surrounding tissues, often compounded by indistinct boundaries. While existing encoder-decoder CNN and transformer-based approaches have shown promising results, they struggle with stable segmentation performance on polyps with weak or blurry boundaries. These methods exhibit limited abilities to distinguish between polyps and non-polyps and capture essential boundary cues. Moreover, their generalizability still falls short of meeting the demands of real-time clinical applications. To address these limitations, we propose SAM-MaGuP, a groundbreaking approach for robust polyp segmentation. By incorporating a boundary distillation module and a 1D-2D Mamba adapter within the Segment Anything Model (SAM), SAM-MaGuP excels at resolving weak boundary challenges and amplifies feature learning through enriched global contextual interactions. Extensive evaluations across five diverse datasets reveal that SAM-MaGuP outperforms state-of-the-art methods, achieving unmatched segmentation accuracy and robustness. Our key innovations, a Mamba-guided boundary prior and a 1D-2D Mamba block, set a new benchmark in the field, pushing the boundaries of polyp segmentation to new heights.</article>","contentLength":1510,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence","url":"https://arxiv.org/abs/2507.01504","date":1751515200,"author":"","guid":182293,"unread":true,"content":"<article>arXiv:2507.01504v1 Announce Type: new \nAbstract: The collection and release of street-level recordings as Open Data play a vital role in advancing autonomous driving systems and AI research. However, these datasets pose significant privacy risks, particularly for pedestrians, due to the presence of Personally Identifiable Information (PII) that extends beyond biometric traits such as faces. In this paper, we present cRID, a novel cross-modal framework combining Large Vision-Language Models, Graph Attention Networks, and representation learning to detect textual describable clues of PII and enhance person re-identification (Re-ID). Our approach focuses on identifying and leveraging interpretable features, enabling the detection of semantically meaningful PII beyond low-level appearance cues. We conduct a systematic evaluation of PII presence in person image datasets. Our experiments show improved performance in practical cross-dataset Re-ID scenarios, notably from Market-1501 to CUHK03-np (detected), highlighting the framework's practical utility. Code is available at https://github.com/RAufschlaeger/cRID.</article>","contentLength":1122,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images","url":"https://arxiv.org/abs/2507.01502","date":1751515200,"author":"","guid":182294,"unread":true,"content":"<article>arXiv:2507.01502v1 Announce Type: new \nAbstract: Global warming, loss of biodiversity, and air pollution are among the most significant problems facing Earth. One of the primary challenges in addressing these issues is the lack of monitoring forests to protect them. To tackle this problem, it is important to leverage remote sensing and computer vision methods to automate monitoring applications. Hence, automatic tree crown detection algorithms emerged based on traditional and deep learning methods. In this study, we first introduce two different tree crown detection methods based on these approaches. Then, we form a novel rule-based approach that integrates these two methods to enhance robustness and accuracy of tree crown detection results. While traditional methods are employed for feature extraction and segmentation of forested areas, deep learning methods are used to detect tree crowns in our method. With the proposed rule-based approach, we post-process these results, aiming to increase the number of detected tree crowns through neighboring trees and localized operations. We compare the obtained results with the proposed method in terms of the number of detected tree crowns and report the advantages, disadvantages, and areas for improvement of the obtained outcomes.</article>","contentLength":1291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ReFlex: Text-Guided Editing of Real Images in Rectified Flow via Mid-Step Feature Extraction and Attention Adaptation","url":"https://arxiv.org/abs/2507.01496","date":1751515200,"author":"","guid":182295,"unread":true,"content":"<article>arXiv:2507.01496v1 Announce Type: new \nAbstract: Rectified Flow text-to-image models surpass diffusion models in image quality and text alignment, but adapting ReFlow for real-image editing remains challenging. We propose a new real-image editing method for ReFlow by analyzing the intermediate representations of multimodal transformer blocks and identifying three key features. To extract these features from real images with sufficient structural preservation, we leverage mid-step latent, which is inverted only up to the mid-step. We then adapt attention during injection to improve editability and enhance alignment to the target text. Our method is training-free, requires no user-provided mask, and can be applied even without a source prompt. Extensive experiments on two benchmarks with nine baselines demonstrate its superior performance over prior methods, further validated by human evaluations confirming a strong user preference for our approach.</article>","contentLength":961,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Crop Pest Classification Using Deep Learning Techniques: A Review","url":"https://arxiv.org/abs/2507.01494","date":1751515200,"author":"","guid":182296,"unread":true,"content":"<article>arXiv:2507.01494v1 Announce Type: new \nAbstract: Insect pests continue to bring a serious threat to crop yields around the world, and traditional methods for monitoring them are often slow, manual, and difficult to scale. In recent years, deep learning has emerged as a powerful solution, with techniques like convolutional neural networks (CNNs), vision transformers (ViTs), and hybrid models gaining popularity for automating pest detection. This review looks at 37 carefully selected studies published between 2018 and 2025, all focused on AI-based pest classification. The selected research is organized by crop type, pest species, model architecture, dataset usage, and key technical challenges. The early studies relied heavily on CNNs but latest work is shifting toward hybrid and transformer-based models that deliver higher accuracy and better contextual understanding. Still, challenges like imbalanced datasets, difficulty in detecting small pests, limited generalizability, and deployment on edge devices remain significant hurdles. Overall, this review offers a structured overview of the field, highlights useful datasets, and outlines the key challenges and future directions for AI-based pest monitoring systems.</article>","contentLength":1228,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AVC-DPO: Aligned Video Captioning via Direct Preference Optimization","url":"https://arxiv.org/abs/2507.01492","date":1751515200,"author":"","guid":182297,"unread":true,"content":"<article>arXiv:2507.01492v1 Announce Type: new \nAbstract: Although video multimodal large language models (video MLLMs) have achieved substantial progress in video captioning tasks, it remains challenging to adjust the focal emphasis of video captions according to human preferences. To address this limitation, we propose Aligned Video Captioning via Direct Preference Optimization (AVC-DPO), a post-training framework designed to enhance captioning capabilities in video MLLMs through preference alignment. Our approach designs enhanced prompts that specifically target temporal dynamics and spatial information-two key factors that humans care about when watching a video-thereby incorporating human-centric preferences. AVC-DPO leverages the same foundation model's caption generation responses under varied prompt conditions to conduct preference-aware training and caption alignment. Using this framework, we have achieved exceptional performance in the LOVE@CVPR'25 Workshop Track 1A: Video Detailed Captioning Challenge, achieving first place on the Video Detailed Captioning (VDC) benchmark according to the VDCSCORE evaluation metric.</article>","contentLength":1135,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Frequency Domain Design of a Reset-Based Filter: An Add-On Nonlinear Filter for Industrial Motion Control","url":"https://arxiv.org/abs/2507.01491","date":1751515200,"author":"","guid":182298,"unread":true,"content":"<article>arXiv:2507.01491v1 Announce Type: new \nAbstract: This study introduces a modified version of the Constant-in-Gain, Lead-in-Phase (CgLp) filter, which incorporates a feedthrough term in the First-Order Reset Element (FORE) to reduce the undesirable nonlinearities and achieve an almost constant gain across all frequencies. A backward calculation approach is proposed to derive the additional parameter introduced by the feedthrough term, enabling designers to easily tune the filter to generate the required phase. The paper also presents an add-on filter structure that can enhance the performance of an existing LTI controller without altering its robustness margins. A sensitivity improvement indicator is proposed to guide the tuning process, enabling designers to visualize the improvements in closed-loop performance. The proposed methodology is demonstrated through a case study of an industrial wire bonder machine, showcasing its effectiveness in addressing low-frequency vibrations and improving overall control performance.</article>","contentLength":1034,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning","url":"https://arxiv.org/abs/2507.01489","date":1751515200,"author":"","guid":182299,"unread":true,"content":"<article>arXiv:2507.01489v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have emerged as one of the most significant technological advancements in artificial intelligence in recent years. Their ability to understand, generate, and reason with natural language has transformed how we interact with AI systems. With the development of LLM-based agents and reinforcement-learning-based reasoning models, the study of applying reinforcement learning in agent frameworks has become a new research focus. However, all previous studies face the challenge of deciding the tool calling process and the reasoning process simultaneously, and the chain of reasoning was solely relied on the unprocessed raw result with redundant information and symbols unrelated to the task from the tool, which impose a heavy burden on the model's capability to reason. Therefore, in our research, we proposed a hierarchical framework Agent-as-tool that detach the tool calling process and the reasoning process, which enables the model to focus on the verbally reasoning process while the tool calling process is handled by another agent. Our work had achieved comparable results with only a slight reinforcement fine-tuning on 180 samples, and had achieved exceptionally well performance in Bamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding Search-R1 by 4.8% in exact match and 3.2% in cover exact match.</article>","contentLength":1412,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Securely Shuffle? A survey about Secure Shufflers for privacy-preserving computations","url":"https://arxiv.org/abs/2507.01487","date":1751515200,"author":"","guid":182300,"unread":true,"content":"<article>arXiv:2507.01487v1 Announce Type: new \nAbstract: Ishai et al. (FOCS'06) introduced secure shuffling as an efficient building block for private data aggregation. Recently, the field of differential privacy has revived interest in secure shufflers by highlighting the privacy amplification they can provide in various computations. Although several works argue for the utility of secure shufflers, they often treat them as black boxes; overlooking the practical vulnerabilities and performance trade-offs of existing implementations. This leaves a central question open: what makes a good secure shuffler?\n  This survey addresses that question by identifying, categorizing, and comparing 26 secure protocols that realize the necessary shuffling functionality. To enable a meaningful comparison, we adapt and unify existing security definitions into a consistent set of properties. We also present an overview of privacy-preserving technologies that rely on secure shufflers, offer practical guidelines for selecting appropriate protocols, and outline promising directions for future work.</article>","contentLength":1086,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments","url":"https://arxiv.org/abs/2507.01485","date":1751515200,"author":"","guid":182301,"unread":true,"content":"<article>arXiv:2507.01485v1 Announce Type: new \nAbstract: Large language models (LLMs) and vision-language models (VLMs) have the potential to transform biological research by enabling autonomous experimentation. Yet, their application remains constrained by rigid protocol design, limited adaptability to dynamic lab conditions, inadequate error handling, and high operational complexity. Here we introduce BioMARS (Biological Multi-Agent Robotic System), an intelligent platform that integrates LLMs, VLMs, and modular robotics to autonomously design, plan, and execute biological experiments. BioMARS uses a hierarchical architecture: the Biologist Agent synthesizes protocols via retrieval-augmented generation; the Technician Agent translates them into executable robotic pseudo-code; and the Inspector Agent ensures procedural integrity through multimodal perception and anomaly detection. The system autonomously conducts cell passaging and culture tasks, matching or exceeding manual performance in viability, consistency, and morphological integrity. It also supports context-aware optimization, outperforming conventional strategies in differentiating retinal pigment epithelial cells. A web interface enables real-time human-AI collaboration, while a modular backend allows scalable integration with laboratory hardware. These results highlight the feasibility of generalizable, AI-driven laboratory automation and the transformative role of language-based reasoning in biological research.</article>","contentLength":1492,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What Really Matters for Robust Multi-Sensor HD Map Construction?","url":"https://arxiv.org/abs/2507.01484","date":1751515200,"author":"","guid":182302,"unread":true,"content":"<article>arXiv:2507.01484v1 Announce Type: new \nAbstract: High-definition (HD) map construction methods are crucial for providing precise and comprehensive static environmental information, which is essential for autonomous driving systems. While Camera-LiDAR fusion techniques have shown promising results by integrating data from both modalities, existing approaches primarily focus on improving model accuracy and often neglect the robustness of perception models, which is a critical aspect for real-world applications. In this paper, we explore strategies to enhance the robustness of multi-modal fusion methods for HD map construction while maintaining high accuracy. We propose three key components: data augmentation, a novel multi-modal fusion module, and a modality dropout training strategy. These components are evaluated on a challenging dataset containing 10 days of NuScenes data. Our experimental results demonstrate that our proposed methods significantly enhance the robustness of baseline methods. Furthermore, our approach achieves state-of-the-art performance on the clean validation set of the NuScenes dataset. Our findings provide valuable insights for developing more robust and reliable HD map construction models, advancing their applicability in real-world autonomous driving scenarios. Project website: https://robomap-123.github.io.</article>","contentLength":1353,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities","url":"https://arxiv.org/abs/2507.01479","date":1751515200,"author":"","guid":182303,"unread":true,"content":"<article>arXiv:2507.01479v1 Announce Type: new \nAbstract: Automatic text simplification (ATS) aims to enhance language accessibility for various target groups, particularly persons with intellectual disabilities. Recent advancements in generative AI, especially large language models (LLMs), have substantially improved the quality of machine-generated text simplifications, thereby mitigating information barriers for the target group. However, existing LLM-based ATS systems do not incorporate preference feedback on text simplifications during training, resulting in a lack of personalization tailored to the specific needs of target group representatives.\n  In this work, we extend the standard supervised fine-tuning (SFT) approach for adapting LLM-based ATS models by leveraging a computationally efficient LLM alignment technique -- direct preference optimization (DPO). Specifically, we post-train LLM-based ATS models using human feedback collected from persons with intellectual disabilities, reflecting their preferences on paired text simplifications generated by mainstream LLMs. Furthermore, we propose a pipeline for developing personalized LLM-based ATS systems, encompassing data collection, model selection, SFT and DPO post-training, and evaluation. Our findings underscore the necessity of active participation of target group persons in designing personalized AI accessibility solutions aligned with human expectations. This work represents a step towards personalizing inclusive AI systems at the target-group level, incorporating insights not only from text simplification experts but also from target group persons themselves.</article>","contentLength":1641,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Active Control Points-based 6DoF Pose Tracking for Industrial Metal Objects","url":"https://arxiv.org/abs/2507.01478","date":1751515200,"author":"","guid":182304,"unread":true,"content":"<article>arXiv:2507.01478v1 Announce Type: new \nAbstract: Visual pose tracking is playing an increasingly vital role in industrial contexts in recent years. However, the pose tracking for industrial metal objects remains a challenging task especially in the real world-environments, due to the reflection characteristic of metal objects. To address this issue, we propose a novel 6DoF pose tracking method based on active control points. The method uses image control points to generate edge feature for optimization actively instead of 6DoF pose-based rendering, and serve them as optimization variables. We also introduce an optimal control point regression method to improve robustness. The proposed tracking method performs effectively in both dataset evaluation and real world tasks, providing a viable solution for real-time tracking of industrial metal objects. Our source code is made publicly available at: https://github.com/tomatoma00/ACPTracking.</article>","contentLength":949,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Combining Type Inference and Automated Unit Test Generation for Python","url":"https://arxiv.org/abs/2507.01477","date":1751515200,"author":"","guid":182305,"unread":true,"content":"<article>arXiv:2507.01477v1 Announce Type: new \nAbstract: Automated unit test generation is an established research field that has so far focused on statically-typed programming languages. The lack of type information in dynamically-typed programming languages, such as Python, inhibits test generators, which heavily rely on information about parameter and return types of functions to select suitable arguments when constructing test cases. Since automated test generators inherently rely on frequent execution of candidate tests, we make use of these frequent executions to address this problem by introducing type tracing, which extracts type-related information during execution and gradually refines the available type information. We implement type tracing as an extension of the Pynguin test-generation framework for Python, allowing it (i) to infer parameter types by observing how parameters are used during runtime, (ii) to record the types of values that function calls return, and (iii) to use this type information to increase code coverage. The approach leads to up to 90.0% more branch coverage, improved mutation scores, and to type information of similar quality to that produced by other state-of-the-art type-inference tools.</article>","contentLength":1236,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware","url":"https://arxiv.org/abs/2507.01472","date":1751515200,"author":"","guid":182306,"unread":true,"content":"<article>arXiv:2507.01472v1 Announce Type: new \nAbstract: Methane is a potent greenhouse gas, and detecting its leaks early via hyperspectral satellite imagery can help mitigate climate change. Meanwhile, many existing missions operate in manual tasking regimes only, thus missing potential events of interest. To overcome slow downlink rates cost-effectively, onboard detection is a viable solution. However, traditional methane enhancement methods are too computationally demanding for resource-limited onboard hardware. This work accelerates methane detection by focusing on efficient, low-power algorithms. We test fast target detection methods (ACE, CEM) that have not been previously used for methane detection and propose a Mag1c-SAS - a significantly faster variant of the current state-of-the-art algorithm for methane detection: Mag1c. To explore their true detection potential, we integrate them with a machine learning model (U-Net, LinkNet). Our results identify two promising candidates (Mag1c-SAS and CEM), both acceptably accurate for the detection of strong plumes and computationally efficient enough for onboard deployment: one optimized more for accuracy, the other more for speed, achieving up to ~100x and ~230x faster computation than original Mag1c on resource-limited hardware. Additionally, we propose and evaluate three band selection strategies. One of them can outperform the method traditionally used in the field while using fewer channels, leading to even faster processing without compromising accuracy. This research lays the foundation for future advancements in onboard methane detection with minimal hardware requirements, improving timely data delivery. The produced code, data, and models are open-sourced and can be accessed from https://github.com/zaitra/methane-filters-benchmark.</article>","contentLength":1813,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Analysis of Drone-Assisted Building Inspection Training in VR vs 2D Monitor Display: an EEG Study","url":"https://arxiv.org/abs/2507.01471","date":1751515200,"author":"","guid":182307,"unread":true,"content":"<article>arXiv:2507.01471v1 Announce Type: new \nAbstract: Researchers have been using simulation-based methods for drone-assisted inspection training. Multiple brain regions are associated with information processes and decision-making, and the connectivity of these regions may further influence inspectors' performance. However, researchers do not understand the pathways of the information flows when drone pilots process the maintenance and manipulation of information, which may affect the efficiency of tacit knowledge transfer. This study aims to reveal the causal connection between participants' brain regions using an electroencephalogram and dynamic causal modeling when processing drone-assisted building energy audit tasks using different display modalities. The results showed similar single-direction connectivity patterns for the different simulation groups. The results also showed similar patterns between brain regions related to visual inspection performance before and after training. These findings highlight the nature of brain asymmetries and may be utilized in measuring cognitive states and designing adaptive automation in the knowledge transfer of drone-based inspection.</article>","contentLength":1190,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals","url":"https://arxiv.org/abs/2507.01470","date":1751515200,"author":"","guid":182308,"unread":true,"content":"<article>arXiv:2507.01470v1 Announce Type: new \nAbstract: This work re-examines the commonly held assumption that the frequency of rewards is a reliable measure of task difficulty in reinforcement learning. We identify and formalize a structural challenge that undermines the effectiveness of current policy learning methods: when essential subgoals do not directly yield rewards. We characterize such settings as exhibiting zero-incentive dynamics, where transitions critical to success remain unrewarded. We show that state-of-the-art deep subgoal-based algorithms fail to leverage these dynamics and that learning performance is highly sensitive to the temporal proximity between subgoal completion and eventual reward. These findings reveal a fundamental limitation in current approaches and point to the need for mechanisms that can infer latent task structure without relying on immediate incentives.</article>","contentLength":897,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cross-platform Smartphone Positioning at Museums","url":"https://arxiv.org/abs/2507.01469","date":1751515200,"author":"","guid":182309,"unread":true,"content":"<article>arXiv:2507.01469v1 Announce Type: new \nAbstract: Indoor Positioning Systems (IPSs) hold significant potential for enhancing visitor experiences in cultural heritage institutions. By enabling personalized navigation, efficient artifact organization, and better interaction with exhibits, IPSs can transform the modalities of how individuals engage with museums, galleries and libraries. However, these institutions face several challenges in implementing IPSs, including environmental constraints, technical limits, and limited experimentation. In other contexts, Received Signal Strength (RSS)-based approaches using Bluetooth Low Energy (BLE) and WiFi have emerged as preferred solutions due to their non-invasive nature and minimal infrastructure requirements. Nevertheless, the lack of publicly available RSS datasets that specifically reflect museum environments presents a substantial barrier to developing and evaluating positioning algorithms designed for the intricate spatial characteristics typical of cultural heritage sites. To address this limitation, we present BAR, a novel RSS dataset collected in front of 90 artworks across 13 museum rooms using two different platforms, i.e., Android and iOS. Additionally, we provide an advanced position classification baseline taking advantage of a proximity-based method and $k$-NN algorithms. In our analysis, we discuss the results and offer suggestions for potential research directions.</article>","contentLength":1446,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think","url":"https://arxiv.org/abs/2507.01467","date":1751515200,"author":"","guid":182310,"unread":true,"content":"<article>arXiv:2507.01467v1 Announce Type: new \nAbstract: REPA and its variants effectively mitigate training challenges in diffusion models by incorporating external visual representations from pretrained models, through alignment between the noisy hidden projections of denoising networks and foundational clean image representations. We argue that the external alignment, which is absent during the entire denoising inference process, falls short of fully harnessing the potential of discriminative representations. In this work, we propose a straightforward method called Representation Entanglement for Generation (REG), which entangles low-level image latents with a single high-level class token from pretrained foundation models for denoising. REG acquires the capability to produce coherent image-class pairs directly from pure noise, substantially improving both generation quality and training efficiency. This is accomplished with negligible additional inference overhead, requiring only one single additional token for denoising (&lt;0.5\\% increase in FLOPs and latency). The inference process concurrently reconstructs both image latents and their corresponding global semantics, where the acquired semantic knowledge actively guides and enhances the image generation process. On ImageNet 256$\\times$256, SiT-XL/2 + REG demonstrates remarkable convergence acceleration, achieving $\\textbf{63}\\times$ and $\\textbf{23}\\times$ faster training than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively, SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA trained for 4M iterations ($\\textbf{10}\\times$ longer). Code is available at: https://github.com/Martinser/REG.</article>","contentLength":1698,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A new efficient RPKI Design","url":"https://arxiv.org/abs/2507.01465","date":1751515200,"author":"","guid":182311,"unread":true,"content":"<article>arXiv:2507.01465v1 Announce Type: new \nAbstract: Resource Public Key Infrastructure (RPKI) is a critical security mechanism for BGP, but the complexity of its architecture is a growing concern as its adoption scales. Current RPKI design heavily reuses legacy PKI components, such as X.509 EE-certificates, ASN.1 encoding, and XML-based repository protocols, all these introduce excessive cryptographic validation, redundant metadata, and inefficiencies in both storage and processing. We show that these design choices, although based on established standards, create significant performance bottlenecks, increase the vulnerability surface, and hinder scalability for wide-scale Internet deployment.\n  In this paper, we perform the first systematic analysis of the root causes of complexity in RPKI's design and experimentally quantify their real-world impact. We show that over 70% of validation time in RPKI relying parties is spent on certificate parsing and signature verification, much of it unnecessary. Building on this insight, we introduce the improved RPKI (iRPKI), a backwards-compatible redesign that preserves all security guarantees while substantially reducing protocol overhead. iRPKI eliminates EE-certificates and ROA signatures, merges revocation and integrity objects, replaces verbose encodings with Protobuf, and restructures repository metadata for more efficient access. We experimentally demonstrate that our implementation of iRPKI in the Routinator validator achieves a 20x speed-up of processing time, 18x improvement of bandwidth requirements and 8x reduction in cache memory footprint, while also eliminating classes of vulnerabilities that have led to at least 10 vulnerabilities in RPKI software. iRPKI significantly increases the feasibility of deploying RPKI at scale in the Internet, and especially in constrained environments. Our design may be deployed incrementally without impacting existing operations.</article>","contentLength":1942,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Coding for Quasi-Static Fading Channel with Imperfect CSI at the Transmitter and Quantized Feedback","url":"https://arxiv.org/abs/2507.01464","date":1751515200,"author":"","guid":182312,"unread":true,"content":"<article>arXiv:2507.01464v1 Announce Type: new \nAbstract: The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise channel with noiseless feedback is highly efficient since its coding complexity is extremely low and the decoding error doubly exponentially decays as the coding blocklength tends to infinity. However, its application to the fading channel with imperfect CSI at the transmitter (I-CSIT) is challenging since the SK scheme is sensitive to the CSI. In this paper, we investigate how to design SK-type scheme for the quasi-static fading channel with I-CSIT and quantized feedback. By introducing modulo lattice function and an auxiliary signal into the SK-type encoder-decoder of the transceiver, we show that the decoding error caused by the I-CSIT can be perfectly eliminated, resulting in the success of designing SK-type scheme for such a case. The study of this paper provides a way to design efficient coding scheme for fading channels in the presence of imperfect CSI and quantized feedback.</article>","contentLength":1021,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation","url":"https://arxiv.org/abs/2507.01463","date":1751515200,"author":"","guid":182313,"unread":true,"content":"<article>arXiv:2507.01463v1 Announce Type: new \nAbstract: Instance segmentation of novel objects instances in RGB images, given some example images for each object, is a well known problem in computer vision. Designing a model general enough to be employed, for all kinds of novel objects, without (re-) training, has proven to be a difficult task. To handle this, we propose a simple, yet powerful, framework, called: Novel Object Cyclic Threshold based Instance Segmentation (NOCTIS). This work stems from and improves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it also leverages on recent vision foundation models, namely: Grounded-SAM 2 and DINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precise bounding boxes and their corresponding segmentation masks; while DINOv2's zero-shot capabilities are employed to generate the image embeddings. The quality of those masks, together with their embeddings, is of vital importance to our approach; as the proposal-object matching is realized by determining an object matching score based on the similarity of the class embeddings and the average maximum similarity of the patch embeddings. Differently to SAM-6D, calculating the latter involves a prior patch filtering based on the distance between each patch and its corresponding cyclic/roundtrip patch in the image grid. Furthermore, the average confidence of the proposals' bounding box and mask is used as an additional weighting factor for the object matching score. We empirically show that NOCTIS, without further training/fine tuning, outperforms the best RGB and RGB-D methods on the seven core datasets of the BOP 2023 challenge for the \"Model-based 2D segmentation of unseen objects\" task.</article>","contentLength":1722,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0","url":"https://arxiv.org/abs/2507.01462","date":1751515200,"author":"","guid":182314,"unread":true,"content":"<article>arXiv:2507.01462v1 Announce Type: new \nAbstract: This work explores the application of hybrid quantum-classical algorithms to optimize robotic inspection trajectories derived from Computer-Aided Design (CAD) models in industrial settings. By modeling the task as a 3D variant of the Traveling Salesman Problem, incorporating incomplete graphs and open-route constraints, this study evaluates the performance of two D-Wave-based solvers against classical methods such as GUROBI and Google OR-Tools. Results across five real-world cases demonstrate competitive solution quality with significantly reduced computation times, highlighting the potential of quantum approaches in automation under Industry 4.0.</article>","contentLength":704,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Handling out-of-order input arrival in CEP engines on the edge combining optimistic, pessimistic and lazy evaluation","url":"https://arxiv.org/abs/2507.01461","date":1751515200,"author":"","guid":182315,"unread":true,"content":"<article>arXiv:2507.01461v1 Announce Type: new \nAbstract: In Complex Event Processing, handling out-of-order, late, and duplicate events is critical for real-time analytics, especially on resource-constrained devices that process heterogeneous data from multiple sources. We present LimeCEP, a hybrid CEP approach that combines lazy evaluation, buffering, and speculative processing to efficiently handle data inconsistencies while supporting multi-pattern detection under relaxed semantics. LimeCEP integrates Kafka for efficient message ordering, retention, and duplicate elimination, and offers configurable strategies to trade off between accuracy, latency, and resource consumption. Compared to state-of-the-art systems like SASE and FlinkCEP, LimeCEP achieves up to six orders of magnitude lower latency, with up to 10 times lower memory usage and 6 times lower CPU utilization, while maintaining near-perfect precision and recall under high-disorder input streams, making it well-suited for non-cloud deployments.</article>","contentLength":1011,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Robust Input Shaping Control for Flexible Structures Based on Unscented Kalman Filter","url":"https://arxiv.org/abs/2507.01460","date":1751515200,"author":"","guid":182316,"unread":true,"content":"<article>arXiv:2507.01460v1 Announce Type: new \nAbstract: With the rapid development of industrial automation and smart manufacturing, the control of flexible structures and underactuated systems has become a critical research focus. Residual vibrations in these systems not only degrade operational efficiency but also pose risks to structural integrity and longevity. Traditional input shaping techniques, while effective, often suffer from performance degradation due to parameter inaccuracies and environmental disturbances. To address these challenges, this paper introduces an innovative unscented Kalman filter-based zero vibration derivative input shaping (UZS) method. The proposed approach combines two key innovations: 1) a data-driven Unscented Kalman Filterfor real-time system parameter identification, and 2) a zero-vibration derivative (ZVD) input shaper for robust vibration suppression. To validate the effectiveness of UZS, we conducted extensive experiments on a vertical flexible beam platform, and the results demonstrate significant improvements over state-of-the-art methods. Additionally, we have made the experimental datasets publicly available to facilitate further research. The findings highlight UZS's potential for practical applications in industrial automation, robotics, and precision engineering.</article>","contentLength":1323,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Some remarks on the uncolored versions of the original CFI-graphs","url":"https://arxiv.org/abs/2507.01459","date":1751515200,"author":"","guid":182317,"unread":true,"content":"<article>arXiv:2507.01459v1 Announce Type: new \nAbstract: The CFI-graphs, named after Cai, F\\\"urer, and Immerman, are central to the study of the graph isomorphism testing and of first-order logic with counting. They are colored graphs, and the coloring plays a role in many of their applications. As usual, it is not hard to remove the coloring by some extra graph gadgets, but at the cost of blowing up the size of the graphs and changing some parameters of them as well. This might lead to suboptimal combinatorial bounds important to their applications. Since then for some uncolored variants of the CFI-graphs it has been shown that they serve the same purposes. We show that this already applies to the graphs obtained from the original CFI-graphs by forgetting the colors. Moreover, we will see that there is a first-order formula $\\varphi(x,y)$ expressing in almost all uncolored CFI-graphs that $x$ and $y$ have the same color in the corresponding colored graphs.</article>","contentLength":963,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs","url":"https://arxiv.org/abs/2507.01457","date":1751515200,"author":"","guid":182318,"unread":true,"content":"<article>arXiv:2507.01457v1 Announce Type: new \nAbstract: RISC-V provides a flexible and scalable platform for applications ranging from embedded devices to high-performance computing clusters. Particularly, its RISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI workloads. But writing software that efficiently utilizes the vector units of RISC-V CPUs without expert knowledge requires the programmer to rely on the autovectorization features of compilers or hand-crafted libraries like muRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing the integration with the RISC-V RVV extension, thus heavily limiting the efficient deployment of complex AI workloads. In this paper, we present a workflow based on the TVM compiler to efficiently map AI workloads onto RISC-V vector units. Instead of relying on hand-crafted libraries, we integrated the RVV extension into TVM's MetaSchedule framework, a probabilistic program framework for tensor operation tuning. We implemented different RISC-V SoCs on an FPGA and tuned a wide range of AI workloads on them. We found that our proposal shows a mean improvement of 46% in execution latency when compared against the autovectorization feature of GCC, and 29% against muRISCV-NN. Moreover, the binary resulting from our proposal has a smaller code memory footprint, making it more suitable for embedded devices. Finally, we also evaluated our solution on a commercially available RISC-V SoC implementing the RVV 1.0 Vector Extension and found our solution is able to find mappings that are 35% faster on average than the ones proposed by LLVM. We open-sourced our proposal for the community to expand it to target other RISC-V extensions.</article>","contentLength":1721,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OoDDINO:A Multi-level Framework for Anomaly Segmentation on Complex Road Scenes","url":"https://arxiv.org/abs/2507.01455","date":1751515200,"author":"","guid":182319,"unread":true,"content":"<article>arXiv:2507.01455v1 Announce Type: new \nAbstract: Anomaly segmentation aims to identify Out-of-Distribution (OoD) anomalous objects within images. Existing pixel-wise methods typically assign anomaly scores individually and employ a global thresholding strategy to segment anomalies. Despite their effectiveness, these approaches encounter significant challenges in real-world applications: (1) neglecting spatial correlations among pixels within the same object, resulting in fragmented segmentation; (2) variabil ity in anomaly score distributions across image regions, causing global thresholds to either generate false positives in background areas or miss segments of anomalous objects. In this work, we introduce OoDDINO, a novel multi-level anomaly segmentation framework designed to address these limitations through a coarse-to-fine anomaly detection strategy. OoDDINO combines an uncertainty-guided anomaly detection model with a pixel-level segmentation model within a two-stage cascade architecture. Initially, we propose an Orthogonal Uncertainty-Aware Fusion Strategy (OUAFS) that sequentially integrates multiple uncertainty metrics with visual representations, employing orthogonal constraints to strengthen the detection model's capacity for localizing anomalous regions accurately. Subsequently, we develop an Adaptive Dual-Threshold Network (ADT-Net), which dynamically generates region-specific thresholds based on object-level detection outputs and pixel-wise anomaly scores. This approach allows for distinct thresholding strategies within foreground and background areas, achieving fine-grained anomaly segmentation. The proposed framework is compatible with other pixel-wise anomaly detection models, which acts as a plug-in to boost the performance. Extensive experiments on two benchmark datasets validate our framework's superiority and compatibility over state-of-the-art methods.</article>","contentLength":1907,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rational Censorship Attack: Breaking Blockchain with a Blackboard","url":"https://arxiv.org/abs/2507.01453","date":1751515200,"author":"","guid":182320,"unread":true,"content":"<article>arXiv:2507.01453v1 Announce Type: new \nAbstract: Censorship resilience is a fundamental assumption underlying the security of blockchain protocols. Additionally, the analysis of blockchain security from an economic and game theoretic perspective has been growing in popularity in recent years. In this work, we present a surprising rational censorship attack on blockchain censorship resilience when we adopt the analysis of blockchain security from a game theoretic lens and assume all users are rational. In our attack, a colluding group with sufficient voting power censors the remainder nodes such that the group alone can gain all the rewards from maintaining the blockchain. We show that if nodes are rational, coordinating this attack just requires a public read and write blackboard and we formally model the attack using a game theoretic framework. Furthermore, we note that to ensure the success of the attack, nodes need to know the total true voting power held by the colluding group. We prove that the strategy to join the rational censorship attack and also for nodes to honestly declare their power is a subgame perfect equilibrium in the corresponding extensive form game induced by our attack. Finally, we discuss the implications of the attack on blockchain users and protocol designers as well as some potential countermeasures.</article>","contentLength":1347,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Multi-Revolution Low-Thrust Trajectory Optimization With Very Sparse Mesh Pseudospectral Method","url":"https://arxiv.org/abs/2507.01450","date":1751515200,"author":"","guid":182321,"unread":true,"content":"<article>arXiv:2507.01450v1 Announce Type: new \nAbstract: Multi-revolution low-thrust trajectory optimization problems are important and challenging in space mission design. In this paper, an efficient, accurate, and widely applicable pseudospectral method is proposed to solve multi-revolution low-thrust trajectory optimization problems with various objective functions and perturbations. The method is based on the Sundman transformation and pseudospectral method, together with a sparse mesh that is monotonic, near-uniformly spaced, and uniformly scattered on the unit circle. Two methods are proposed to construct the mesh: a deterministic method based on rotation mapping; a stochastic method utilizing autocorrelated random sequences. Core mechanisms ensuring the correctness of the method are analyzed, including the dual roles of mesh points as both integration points in the temporal domain and sampling points in the angular domain, the slow dynamics of the system excluding the fast angle variable, and the nearly commutative vector fields generated by applying different control inputs. The method is demonstrated through a multi-revolution low-thrust orbital rendezvous problem. Results show that the proposed method achieves high accuracy with only a few seconds of computational time for challenging problems.</article>","contentLength":1317,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LogitSpec: Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation","url":"https://arxiv.org/abs/2507.01449","date":1751515200,"author":"","guid":182322,"unread":true,"content":"<article>arXiv:2507.01449v1 Announce Type: new \nAbstract: Speculative decoding (SD), where a small draft model is employed to propose draft tokens in advance and then the target model validates them in parallel, has emerged as a promising technique for LLM inference acceleration. Many endeavors to improve SD are to eliminate the need for a draft model and generate draft tokens in a retrieval-based manner in order to further alleviate the drafting overhead and significantly reduce the difficulty in deployment and applications. However, retrieval-based SD relies on a matching paradigm to retrieval the most relevant reference as the draft tokens, where these methods often fail to find matched and accurate draft tokens. To address this challenge, we propose LogitSpec to effectively expand the retrieval range and find the most relevant reference as drafts. Our LogitSpec is motivated by the observation that the logit of the last token can not only predict the next token, but also speculate the next next token. Specifically, LogitSpec generates draft tokens in two steps: (1) utilizing the last logit to speculate the next next token; (2) retrieving relevant reference for both the next token and the next next token. LogitSpec is training-free and plug-and-play, which can be easily integrated into existing LLM inference frameworks. Extensive experiments on a wide range of text generation benchmarks demonstrate that LogitSpec can achieve up to 2.61 $\\times$ speedup and 3.28 mean accepted tokens per decoding step. Our code is available at https://github.com/smart-lty/LogitSpec.</article>","contentLength":1583,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Using multi-agent architecture to mitigate the risk of LLM hallucinations","url":"https://arxiv.org/abs/2507.01446","date":1751515200,"author":"","guid":182323,"unread":true,"content":"<article>arXiv:2507.01446v1 Announce Type: new \nAbstract: Improving customer service quality and response time are critical factors for maintaining customer loyalty and increasing a company's market share. While adopting emerging technologies such as Large Language Models (LLMs) is becoming a necessity to achieve these goals, the risk of hallucination remains a major challenge. In this paper, we present a multi-agent system to handle customer requests sent via SMS. This system integrates LLM based agents with fuzzy logic to mitigate hallucination risks.</article>","contentLength":550,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TurboReg: TurboClique for Robust and Efficient Point Cloud Registration","url":"https://arxiv.org/abs/2507.01439","date":1751515200,"author":"","guid":182324,"unread":true,"content":"<article>arXiv:2507.01439v1 Announce Type: new \nAbstract: Robust estimation is essential in correspondence-based Point Cloud Registration (PCR). Existing methods using maximal clique search in compatibility graphs achieve high recall but suffer from exponential time complexity, limiting their use in time-sensitive applications. To address this challenge, we propose a fast and robust estimator, TurboReg, built upon a novel lightweight clique, TurboClique, and a highly parallelizable Pivot-Guided Search (PGS) algorithm. First, we define the TurboClique as a 3-clique within a highly-constrained compatibility graph. The lightweight nature of the 3-clique allows for efficient parallel searching, and the highly-constrained compatibility graph ensures robust spatial consistency for stable transformation estimation. Next, PGS selects matching pairs with high SC$^2$ scores as pivots, effectively guiding the search toward TurboCliques with higher inlier ratios. Moreover, the PGS algorithm has linear time complexity and is significantly more efficient than the maximal clique search with exponential time complexity. Extensive experiments show that TurboReg achieves state-of-the-art performance across multiple real-world datasets, with substantial speed improvements. For example, on the 3DMatch+FCGF dataset, TurboReg (1K) operates $208.22\\times$ faster than 3DMAC while also achieving higher recall. Our code is accessible at \\href{https://github.com/Laka-3DV/TurboReg}{\\texttt{TurboReg}}.</article>","contentLength":1489,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices","url":"https://arxiv.org/abs/2507.01438","date":1751515200,"author":"","guid":182325,"unread":true,"content":"<article>arXiv:2507.01438v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have gained significant attention due to their versatility across a wide array of applications. Fine-tuning LLMs with parameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these models to efficiently adapt to downstream tasks without extensive retraining. Deploying fine-tuned LLMs on multi-tenant edge devices offers substantial benefits, such as reduced latency, enhanced privacy, and personalized responses. However, serving LLMs efficiently on resource-constrained edge devices presents critical challenges, including the complexity of adapter selection for different tasks and memory overhead from frequent adapter swapping. Moreover, given the multiple requests in multi-tenant settings, processing requests sequentially results in underutilization of computational resources and increased latency. This paper introduces EdgeLoRA, an efficient system for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA incorporates three key innovations: (1) an adaptive adapter selection mechanism to streamline the adapter configuration process; (2) heterogeneous memory management, leveraging intelligent adapter caching and pooling to mitigate memory operation overhead; and (3) batch LoRA inference, enabling efficient batch processing to significantly reduce computational latency. Comprehensive evaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly outperforms the status quo (i.e., llama.cpp) in terms of both latency and throughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times boost in throughput. Even more impressively, it can serve several orders of magnitude more adapters simultaneously. These results highlight EdgeLoRA's potential to transform edge deployment of LLMs in multi-tenant scenarios, offering a scalable and efficient solution for resource-constrained environments.</article>","contentLength":1948,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction","url":"https://arxiv.org/abs/2507.01437","date":1751515200,"author":"","guid":182326,"unread":true,"content":"<article>arXiv:2507.01437v1 Announce Type: new \nAbstract: This paper addresses the challenges posed by the unstructured nature and high-dimensional semantic complexity of electronic health record texts. A deep learning method based on attention mechanisms is proposed to achieve unified modeling for information extraction and multi-label disease prediction. The study is conducted on the MIMIC-IV dataset. A Transformer-based architecture is used to perform representation learning over clinical text. Multi-layer self-attention mechanisms are employed to capture key medical entities and their contextual relationships. A Sigmoid-based multi-label classifier is then applied to predict multiple disease labels. The model incorporates a context-aware semantic alignment mechanism, enhancing its representational capacity in typical medical scenarios such as label co-occurrence and sparse information. To comprehensively evaluate model performance, a series of experiments were conducted, including baseline comparisons, hyperparameter sensitivity analysis, data perturbation studies, and noise injection tests. Results demonstrate that the proposed method consistently outperforms representative existing approaches across multiple performance metrics. The model maintains strong generalization under varying data scales, interference levels, and model depth configurations. The framework developed in this study offers an efficient algorithmic foundation for processing real-world clinical texts and presents practical significance for multi-label medical text modeling tasks.</article>","contentLength":1570,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Challenges & Opportunities with LLM-Assisted Visualization Retargeting","url":"https://arxiv.org/abs/2507.01436","date":1751515200,"author":"","guid":182327,"unread":true,"content":"<article>arXiv:2507.01436v1 Announce Type: new \nAbstract: Despite the ubiquity of visualization examples published on the web, retargeting existing custom chart implementations to new datasets remains difficult, time-intensive, and tedious. The adaptation process assumes author familiarity with both the implementation of the example as well as how the new dataset might need to be transformed to fit into the example code. With recent advances in Large Language Models (LLMs), automatic adaptation of code can be achieved from high-level user prompts, reducing the barrier for visualization retargeting. To better understand how LLMs can assist retargeting and its potential limitations, we characterize and evaluate the performance of LLM assistance across multiple datasets and charts of varying complexity, categorizing failures according to type and severity. In our evaluation, we compare two approaches: (1) directly instructing the LLM model to fully generate and adapt code by treating code as text inputs and (2) a more constrained program synthesis pipeline where the LLM guides the code construction process by providing structural information (e.g., visual encodings) based on properties of the example code and data. We find that both approaches struggle when new data has not been appropriately transformed, and discuss important design recommendations for future retargeting systems.</article>","contentLength":1391,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An Optimal Least-Square Solver For Scaled Partial-Isometric Linear Systems","url":"https://arxiv.org/abs/2507.01434","date":1751515200,"author":"","guid":182328,"unread":true,"content":"<article>arXiv:2507.01434v1 Announce Type: new \nAbstract: We present an $O(mn)$ direct least-squares solver for $m \\times n$ linear systems with a scaled partial isometry. The proposed algorithm is also useful when the system is block diagonal and each block is a scaled partial isometry with distinct scaling factors. We also include numerical experiments as a demonstration.</article>","contentLength":367,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading","url":"https://arxiv.org/abs/2507.01431","date":1751515200,"author":"","guid":182329,"unread":true,"content":"<article>arXiv:2507.01431v1 Announce Type: new \nAbstract: Grading handwritten, open-ended responses remains a major bottleneck in large university STEM courses. We introduce Pensieve (https://www.pensieve.co), an AI-assisted grading platform that leverages large language models (LLMs) to transcribe and evaluate student work, providing instructors with rubric-aligned scores, transcriptions, and confidence ratings. Unlike prior tools that focus narrowly on specific tasks like transcription or rubric generation, Pensieve supports the entire grading pipeline-from scanned student submissions to final feedback-within a human-in-the-loop interface.\n  Pensieve has been deployed in real-world courses at over 20 institutions and has graded more than 300,000 student responses. We present system details and empirical results across four core STEM disciplines: Computer Science, Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces grading time by an average of 65%, while maintaining a 95.4% agreement rate with instructor-assigned grades for high-confidence predictions.</article>","contentLength":1086,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems","url":"https://arxiv.org/abs/2507.01429","date":1751515200,"author":"","guid":182330,"unread":true,"content":"<article>arXiv:2507.01429v1 Announce Type: new \nAbstract: Deep neural networks generate and process large volumes of data, posing challenges for low-resource embedded systems. In-memory computing has been demonstrated as an efficient computing infrastructure and shows promise for embedded AI applications. Among newly-researched memory technologies, racetrack memory is a non-volatile technology that allows high data density fabrication, making it a good fit for in-memory computing. However, integrating in-memory arithmetic circuits with memory cells affects both the memory density and power efficiency. It remains challenging to build efficient in-memory arithmetic circuits on racetrack memory within area and energy constraints. To this end, we present an efficient in-memory convolutional neural network (CNN) accelerator optimized for use with racetrack memory. We design a series of fundamental arithmetic circuits as in-memory computing cells suited for multiply-and-accumulate operations. Moreover, we explore the design space of racetrack memory based systems and CNN model architectures, employing co-design to improve the efficiency and performance of performing CNN inference in racetrack memory while maintaining model accuracy. Our designed circuits and model-system co-optimization strategies achieve a small memory bank area with significant improvements in energy and performance for racetrack memory based embedded systems.</article>","contentLength":1437,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DiffMark: Diffusion-based Robust Watermark Against Deepfakes","url":"https://arxiv.org/abs/2507.01428","date":1751515200,"author":"","guid":182331,"unread":true,"content":"<article>arXiv:2507.01428v1 Announce Type: new \nAbstract: Deepfakes pose significant security and privacy threats through malicious facial manipulations. While robust watermarking can aid in authenticity verification and source tracking, existing methods often lack the sufficient robustness against Deepfake manipulations. Diffusion models have demonstrated remarkable performance in image generation, enabling the seamless fusion of watermark with image during generation. In this study, we propose a novel robust watermarking framework based on diffusion model, called DiffMark. By modifying the training and sampling scheme, we take the facial image and watermark as conditions to guide the diffusion model to progressively denoise and generate corresponding watermarked image. In the construction of facial condition, we weight the facial image by a timestep-dependent factor that gradually reduces the guidance intensity with the decrease of noise, thus better adapting to the sampling process of diffusion model. To achieve the fusion of watermark condition, we introduce a cross information fusion (CIF) module that leverages a learnable embedding table to adaptively extract watermark features and integrates them with image features via cross-attention. To enhance the robustness of the watermark against Deepfake manipulations, we integrate a frozen autoencoder during training phase to simulate Deepfake manipulations. Additionally, we introduce Deepfake-resistant guidance that employs specific Deepfake model to adversarially guide the diffusion sampling process to generate more robust watermarked images. Experimental results demonstrate the effectiveness of the proposed DiffMark on typical Deepfakes. Our code will be available at https://github.com/vpsg-research/DiffMark.</article>","contentLength":1782,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Approximation-free Control of Unknown Euler-Lagrangian Systems under Input Constraints","url":"https://arxiv.org/abs/2507.01426","date":1751515200,"author":"","guid":182332,"unread":true,"content":"<article>arXiv:2507.01426v1 Announce Type: new \nAbstract: In this paper, we present a novel funnel-based tracking control algorithm for robotic systems with unknown dynamics and prescribed input constraints. The Euler-Lagrange formulation, a common modeling approach for robotic systems, has been adopted in this study to address the trade-off between performance and actuator safety. We establish feasibility conditions that ensure tracking errors evolve within predefined funnel bounds while maintaining bounded control efforts, a crucial consideration for robots with limited actuation capabilities. We propose two approximation-free control strategies for scenarios where these conditions are violated: one actively corrects the error, and the other stops further deviation. Finally, we demonstrate the robust performance and safety of the approach through simulations and experimental validations. This work represents a significant advancement in funnel-based control, enhancing its applicability to real-world robotics systems with input constraints.</article>","contentLength":1048,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TriVLA: A Unified Triple-System-Based Unified Vision-Language-Action Model for General Robot Control","url":"https://arxiv.org/abs/2507.01424","date":1751515200,"author":"","guid":182333,"unread":true,"content":"<article>arXiv:2507.01424v1 Announce Type: new \nAbstract: Recent advancements in vision-language models (VLMs) for common-sense reasoning have led to the development of vision-language-action (VLA) models, enabling robots to perform generalized manipulation. Although existing autoregressive VLA methods design a specific architecture like dual-system to leverage large-scale pretrained knowledge, they tend to capture static information, often neglecting the dynamic aspects vital for embodied tasks. To this end, we propose TriVLA, a unified Vision-Language-Action model with a triple-system architecture for general robot control. The vision-language module (System 2) interprets the environment through vision and language instructions. The dynamics perception module (System 3) inherently produces visual representations that encompass both current static information and predicted future dynamics, thereby providing valuable guidance for policy learning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trained video foundation model on robot datasets along with internet human manipulation data. The subsequent policy learning module (System 1) generates fluid motor actions in real time. Experimental evaluation demonstrates that TriVLA operates at approximately 36 Hz and surpasses state-of-the-art imitation learning baselines on standard simulation benchmarks as well as challenging real-world manipulation tasks.</article>","contentLength":1424,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Compact 16-bit S-box over Tower Field $\\F_{(((2^2)^2)^2)^2}$ with High Security","url":"https://arxiv.org/abs/2507.01423","date":1751515200,"author":"","guid":182334,"unread":true,"content":"<article>arXiv:2507.01423v1 Announce Type: new \nAbstract: This paper introduces a compact and secure 16-bit substitution box (S-box) designed over the composite field $\\F_{(((2^2)^2)^2)^2}$, optimized for both hardware efficiency and cryptographic robustness. The proposed S-box decomposes operations into subfields, leveraging a tower field architecture. This enables significant hardware reduction through optimized field inversion and a low-cost affine transformation. Security evaluations confirm resilience against linear, differential, algebraic and DPA attacks, validated via metrics including Nonlinearity (32512), Differential Uniformity (4), Algebraic Degree (15), Transparency order (15.9875) and SNR (0.34e-08). The hardware results, in 65 nm CMOS technology, show the proposed 16-bit S-box has lower hardware resources consumption and lower critical path delay (CPD) than those of other 16-bit S-boxes. By integrating high algebraic complexity with resource-efficient structures, this work addresses the growing demand for scalable cryptographic primitives in data-sensitive applications, demonstrating that larger S-boxes can enhance security without proportional hardware costs. The results underscore the viability of composite field-based architectures in balancing security and efficiency for modern block ciphers.</article>","contentLength":1323,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal","url":"https://arxiv.org/abs/2507.01422","date":1751515200,"author":"","guid":182335,"unread":true,"content":"<article>arXiv:2507.01422v1 Announce Type: new \nAbstract: Document shadow removal is a crucial task in the field of document image enhancement. However, existing methods tend to remove shadows with constant color background and ignore color shadows. In this paper, we first design a diffusion model in latent space for document image shadow removal, called DocShaDiffusion. It translates shadow images from pixel space to latent space, enabling the model to more easily capture essential features. To address the issue of color shadows, we design a shadow soft-mask generation module (SSGM). It is able to produce accurate shadow mask and add noise into shadow regions specially. Guided by the shadow mask, a shadow mask-aware guided diffusion module (SMGDM) is proposed to remove shadows from document images by supervising the diffusion and denoising process. We also propose a shadow-robust perceptual feature loss to preserve details and structures in document images. Moreover, we develop a large-scale synthetic document color shadow removal dataset (SDCSRD). It simulates the distribution of realistic color shadows and provides powerful supports for the training of models. Experiments on three public datasets validate the proposed method's superiority over state-of-the-art. Our code and dataset will be publicly available.</article>","contentLength":1324,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Penalizing Transparency? How AI Disclosure and Author Demographics Shape Human and AI Judgments About Writing","url":"https://arxiv.org/abs/2507.01418","date":1751515200,"author":"","guid":182336,"unread":true,"content":"<article>arXiv:2507.01418v1 Announce Type: new \nAbstract: As AI integrates in various types of human writing, calls for transparency around AI assistance are growing. However, if transparency operates on uneven ground and certain identity groups bear a heavier cost for being honest, then the burden of openness becomes asymmetrical. This study investigates how AI disclosure statement affects perceptions of writing quality, and whether these effects vary by the author's race and gender. Through a large-scale controlled experiment, both human raters (n = 1,970) and LLM raters (n = 2,520) evaluated a single human-written news article while disclosure statements and author demographics were systematically varied. This approach reflects how both human and algorithmic decisions now influence access to opportunities (e.g., hiring, promotion) and social recognition (e.g., content recommendation algorithms). We find that both human and LLM raters consistently penalize disclosed AI use. However, only LLM raters exhibit demographic interaction effects: they favor articles attributed to women or Black authors when no disclosure is present. But these advantages disappear when AI assistance is revealed. These findings illuminate the complex relationships between AI disclosure and author identity, highlighting disparities between machine and human evaluation patterns.</article>","contentLength":1365,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention","url":"https://arxiv.org/abs/2507.01417","date":1751515200,"author":"","guid":182337,"unread":true,"content":"<article>arXiv:2507.01417v1 Announce Type: new \nAbstract: Out-of-Distribution (OOD) detection is critical for safely deploying deep models in open-world environments, where inputs may lie outside the training distribution. During inference on a model trained exclusively with In-Distribution (ID) data, we observe a salient gradient phenomenon: around an ID sample, the local gradient directions for \"enhancing\" that sample's predicted class remain relatively consistent, whereas OOD samples--unseen in training--exhibit disorganized or conflicting gradient directions in the same neighborhood. Motivated by this observation, we propose an inference-stage technique to short-circuit those feature coordinates that spurious gradients exploit to inflate OOD confidence, while leaving ID classification largely intact. To circumvent the expense of recomputing the logits after this gradient short-circuit, we further introduce a local first-order approximation that accurately captures the post-modification outputs without a second forward pass. Experiments on standard OOD benchmarks show our approach yields substantial improvements. Moreover, the method is lightweight and requires minimal changes to the standard inference pipeline, offering a practical path toward robust OOD detection in real-world applications.</article>","contentLength":1307,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Decomposing Prediction Mechanisms for In-Context Recall","url":"https://arxiv.org/abs/2507.01414","date":1751515200,"author":"","guid":182338,"unread":true,"content":"<article>arXiv:2507.01414v1 Announce Type: new \nAbstract: We introduce a new family of toy problems that combine features of linear-regression-style continuous in-context learning (ICL) with discrete associative recall. We pretrain transformer models on sample traces from this toy, specifically symbolically-labeled interleaved state observations from randomly drawn linear deterministic dynamical systems. We study if the transformer models can recall the state of a sequence previously seen in its context when prompted to do so with the corresponding in-context label. Taking a closer look at this task, it becomes clear that the model must perform two functions: (1) identify which system's state should be recalled and apply that system to its last seen state, and (2) continuing to apply the correct system to predict the subsequent states. Training dynamics reveal that the first capability emerges well into a model's training. Surprisingly, the second capability, of continuing the prediction of a resumed sequence, develops much earlier.\n  Via out-of-distribution experiments, and a mechanistic analysis on model weights via edge pruning, we find that next-token prediction for this toy problem involves at least two separate mechanisms. One mechanism uses the discrete symbolic labels to do the associative recall required to predict the start of a resumption of a previously seen sequence. The second mechanism, which is largely agnostic to the discrete symbolic labels, performs a \"Bayesian-style\" prediction based on the previous token and the context. These two mechanisms have different learning dynamics.\n  To confirm that this multi-mechanism (manifesting as separate phase transitions) phenomenon is not just an artifact of our toy setting, we used OLMo training checkpoints on an ICL translation task to see a similar phenomenon: a decisive gap in the emergence of first-task-token performance vs second-task-token performance.</article>","contentLength":1939,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evaluating LLM Agent Collusion in Double Auctions","url":"https://arxiv.org/abs/2507.01413","date":1751515200,"author":"","guid":182339,"unread":true,"content":"<article>arXiv:2507.01413v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated impressive capabilities as autonomous agents with rapidly expanding applications in various domains. As these agents increasingly engage in socioeconomic interactions, identifying their potential for undesirable behavior becomes essential. In this work, we examine scenarios where they can choose to collude, defined as secretive cooperation that harms another party. To systematically study this, we investigate the behavior of LLM agents acting as sellers in simulated continuous double auction markets. Through a series of controlled experiments, we analyze how parameters such as the ability to communicate, choice of model, and presence of environmental pressures affect the stability and emergence of seller collusion. We find that direct seller communication increases collusive tendencies, the propensity to collude varies across models, and environmental pressures, such as oversight and urgency from authority figures, influence collusive behavior. Our findings highlight important economic and ethical considerations for the deployment of LLM-based market agents.</article>","contentLength":1170,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models","url":"https://arxiv.org/abs/2507.01410","date":1751515200,"author":"","guid":182340,"unread":true,"content":"<article>arXiv:2507.01410v1 Announce Type: new \nAbstract: The ontological and epistemic complexities inherent in the moral domain make it challenging to establish clear standards for evaluating the performance of a moral machine. In this paper, we present a formal method to describe Ethical Decision Making models based on ethical risk assessment. Then, we show how these models that are specified as fuzzy rules can be verified and validated using fuzzy Petri nets. A case study from the medical field is considered to illustrate the proposed approach.</article>","contentLength":545,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning","url":"https://arxiv.org/abs/2507.01409","date":1751515200,"author":"","guid":182341,"unread":true,"content":"<article>arXiv:2507.01409v1 Announce Type: new \nAbstract: An image captioning model flexibly switching its language pattern, e.g., descriptiveness and length, should be useful since it can be applied to diverse applications. However, despite the dramatic improvement in generative vision-language models, fine-grained control over the properties of generated captions is not easy due to two reasons: (i) existing models are not given the properties as a condition during training and (ii) existing models cannot smoothly transition its language pattern from one state to the other. Given this challenge, we propose a new approach, CaptionSmiths, to acquire a single captioning model that can handle diverse language patterns. First, our approach quantifies three properties of each caption, length, descriptiveness, and uniqueness of a word, as continuous scalar values, without human annotation. Given the values, we represent the conditioning via interpolation between two endpoint vectors corresponding to the extreme states, e.g., one for a very short caption and one for a very long caption. Empirical results demonstrate that the resulting model can smoothly change the properties of the output captions and show higher lexical alignment than baselines. For instance, CaptionSmiths reduces the error in controlling caption length by 506\\% despite better lexical alignment. Code will be available on https://github.com/omron-sinicx/captionsmiths.</article>","contentLength":1442,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Asymptotic Preserving and Accurate scheme for Multiscale Poisson-Nernst-Planck (MPNP) system","url":"https://arxiv.org/abs/2507.01402","date":1751515200,"author":"","guid":182342,"unread":true,"content":"<article>arXiv:2507.01402v1 Announce Type: new \nAbstract: In this paper, we propose and validate a two-species Multiscale model for a Poisson-Nernst-Planck (PNP) system, focusing on the correlated motion of positive and negative ions under the influence of a trap. Specifically, we aim to model surface traps whose attraction range, of length delta, is much smaller then the scale of the problem. The physical setup we refer to is an anchored gas drop (bubble) surrounded by a diffusive flow of charged surfactants (ions). When the diffusing surfactants reach the surface of the trap, the anions are adsorbed. As in our previous works [11,6,9,4], the effect of the attractive potential is replaced by a suitable boundary condition derived by mass conservation and asymptotic analysis. The novelty of this work is the extension of the model proposed in [11], now incorporating the influence of both carriers - positive and negative ions - simultaneously, which is often neglected in traditional approaches that treat ion species independently. In the second part of the paper, we address the treatment of the Coulomb interaction between carriers. When the Debye length lambda_D (proportional to a small parameter epsilon) is very small, one can adopt the so-called Quasi-Neutral limit, which significantly simplifies the system, reducing it to a diffusion equation for a single carriers with effective diffusion coefficient [36,53]. This approach, while simplifying the mathematical model, does not capture the effects of non negligible values of epsilon. When the Debye length is small but not negligible, it may be very expensive to capture the small deviation from the Quasi-Neutral limit by standard methods in the literature. [...]</article>","contentLength":1726,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound","url":"https://arxiv.org/abs/2507.01401","date":1751515200,"author":"","guid":182343,"unread":true,"content":"<article>arXiv:2507.01401v1 Announce Type: new \nAbstract: Fetal abdominal malformations are serious congenital anomalies that require accurate diagnosis to guide pregnancy management and reduce mortality. Although AI has demonstrated significant potential in medical diagnosis, its application to prenatal abdominal anomalies remains limited. Most existing studies focus on image-level classification and rely on standard plane localization, placing less emphasis on case-level diagnosis. In this paper, we develop a case-level multiple instance learning (MIL)-based method, free of standard plane localization, for classifying fetal abdominal anomalies in prenatal ultrasound. Our contribution is three-fold. First, we adopt a mixture-of-attention-experts module (MoAE) to weight different attention heads for various planes. Secondly, we propose a medical-knowledge-driven feature selection module (MFS) to align image features with medical knowledge, performing self-supervised image token selection at the case-level. Finally, we propose a prompt-based prototype learning (PPL) to enhance the MFS. Extensively validated on a large prenatal abdominal ultrasound dataset containing 2,419 cases, with a total of 24,748 images and 6 categories, our proposed method outperforms the state-of-the-art competitors. Codes are available at:https://github.com/LL-AC/AAcls.</article>","contentLength":1356,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps","url":"https://arxiv.org/abs/2507.01397","date":1751515200,"author":"","guid":182344,"unread":true,"content":"<article>arXiv:2507.01397v1 Announce Type: new \nAbstract: Most autonomous cars rely on the availability of high-definition (HD) maps. Current research aims to address this constraint by directly predicting HD map elements from onboard sensors and reasoning about the relationships between the predicted map and traffic elements. Despite recent advancements, the coherent online construction of HD maps remains a challenging endeavor, as it necessitates modeling the high complexity of road topologies in a unified and consistent manner. To address this challenge, we propose a coherent approach to predict lane segments and their corresponding topology, as well as road boundaries, all by leveraging prior map information represented by commonly available standard-definition (SD) maps. We propose a network architecture, which leverages hybrid lane segment encodings comprising prior information and denoising techniques to enhance training stability and performance. Furthermore, we facilitate past frames for temporal consistency. Our experimental evaluation demonstrates that our approach outperforms previous methods by a large margin, highlighting the benefits of our modeling scheme.</article>","contentLength":1181,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FixTalk: Taming Identity Leakage for High-Quality Talking Head Generation in Extreme Cases","url":"https://arxiv.org/abs/2507.01390","date":1751515200,"author":"","guid":182345,"unread":true,"content":"<article>arXiv:2507.01390v1 Announce Type: new \nAbstract: Talking head generation is gaining significant importance across various domains, with a growing demand for high-quality rendering. However, existing methods often suffer from identity leakage (IL) and rendering artifacts (RA), particularly in extreme cases. Through an in-depth analysis of previous approaches, we identify two key insights: (1) IL arises from identity information embedded within motion features, and (2) this identity information can be leveraged to address RA. Building on these findings, this paper introduces FixTalk, a novel framework designed to simultaneously resolve both issues for high-quality talking head generation. Firstly, we propose an Enhanced Motion Indicator (EMI) to effectively decouple identity information from motion features, mitigating the impact of IL on generated talking heads. To address RA, we introduce an Enhanced Detail Indicator (EDI), which utilizes the leaked identity information to supplement missing details, thus fixing the artifacts. Extensive experiments demonstrate that FixTalk effectively mitigates IL and RA, achieving superior performance compared to state-of-the-art methods.</article>","contentLength":1191,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Surrogate Modeling via Factorization Machine and Ising Model with Enhanced Higher-Order Interaction Learning","url":"https://arxiv.org/abs/2507.01389","date":1751515200,"author":"","guid":182346,"unread":true,"content":"<article>arXiv:2507.01389v1 Announce Type: new \nAbstract: Recently, a surrogate model was proposed that employs a factorization machine to approximate the underlying input-output mapping of the original system, with quantum annealing used to optimize the resulting surrogate function. Inspired by this approach, we propose an enhanced surrogate model that incorporates additional slack variables into both the factorization machine and its associated Ising representation thereby unifying what was by design a two-step process into a single, integrated step. During the training phase, the slack variables are iteratively updated, enabling the model to account for higher-order feature interactions. We apply the proposed method to the task of predicting drug combination effects. Experimental results indicate that the introduction of slack variables leads to a notable improvement of performance. Our algorithm offers a promising approach for building efficient surrogate models that exploit potential quantum advantages.</article>","contentLength":1014,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing","url":"https://arxiv.org/abs/2507.01384","date":1751515200,"author":"","guid":182347,"unread":true,"content":"<article>arXiv:2507.01384v1 Announce Type: new \nAbstract: The weakly-supervised audio-visual video parsing (AVVP) aims to predict all modality-specific events and locate their temporal boundaries. Despite significant progress, due to the limitations of the weakly-supervised and the deficiencies of the model architecture, existing methods are lacking in simultaneously improving both the segment-level prediction and the event-level prediction. In this work, we propose a audio-visual Mamba network with pseudo labeling aUGmentation (MUG) for emphasising the uniqueness of each segment and excluding the noise interference from the alternate modalities. Specifically, we annotate some of the pseudo-labels based on previous work. Using unimodal pseudo-labels, we perform cross-modal random combinations to generate new data, which can enhance the model's ability to parse various segment-level event combinations. For feature processing and interaction, we employ a audio-visual mamba network. The AV-Mamba enhances the ability to perceive different segments and excludes additional modal noise while sharing similar modal information. Our extensive experiments demonstrate that MUG improves state-of-the-art results on LLP dataset in all metrics (e.g,, gains of 2.1% and 1.2% in terms of visual Segment-level and audio Segment-level metrics). Our code is available at https://github.com/WangLY136/MUG.</article>","contentLength":1394,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DARTS: A Dual-View Attack Framework for Targeted Manipulation in Federated Sequential Recommendation","url":"https://arxiv.org/abs/2507.01383","date":1751515200,"author":"","guid":182348,"unread":true,"content":"<article>arXiv:2507.01383v1 Announce Type: new \nAbstract: Federated recommendation (FedRec) preserves user privacy by enabling decentralized training of personalized models, but this architecture is inherently vulnerable to adversarial attacks. Significant research has been conducted on targeted attacks in FedRec systems, motivated by commercial and social influence considerations. However, much of this work has largely overlooked the differential robustness of recommendation models. Moreover, our empirical findings indicate that existing targeted attack methods achieve only limited effectiveness in Federated Sequential Recommendation(FSR) tasks. Driven by these observations, we focus on investigating targeted attacks in FSR and propose a novel dualview attack framework, named DV-FSR. This attack method uniquely combines a sampling-based explicit strategy with a contrastive learning-based implicit gradient strategy to orchestrate a coordinated attack. Additionally, we introduce a specific defense mechanism tailored for targeted attacks in FSR, aiming to evaluate the mitigation effects of the attack method we proposed. Extensive experiments validate the effectiveness of our proposed approach on representative sequential models. Our codes are publicly available.</article>","contentLength":1271,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Distributional Soft Actor-Critic with Diffusion Policy","url":"https://arxiv.org/abs/2507.01381","date":1751515200,"author":"","guid":182349,"unread":true,"content":"<article>arXiv:2507.01381v1 Announce Type: new \nAbstract: Reinforcement learning has been proven to be highly effective in handling complex control tasks. Traditional methods typically use unimodal distributions, such as Gaussian distributions, to model the output of value distributions. However, unimodal distribution often and easily causes bias in value function estimation, leading to poor algorithm performance. This paper proposes a distributional reinforcement learning algorithm called DSAC-D (Distributed Soft Actor Critic with Diffusion Policy) to address the challenges of estimating bias in value functions and obtaining multimodal policy representations. A multimodal distributional policy iteration framework that can converge to the optimal policy was established by introducing policy entropy and value distribution function. A diffusion value network that can accurately characterize the distribution of multi peaks was constructed by generating a set of reward samples through reverse sampling using a diffusion model. Based on this, a distributional reinforcement learning algorithm with dual diffusion of the value network and the policy network was derived. MuJoCo testing tasks demonstrate that the proposed algorithm not only learns multimodal policy, but also achieves state-of-the-art (SOTA) performance in all 9 control tasks, with significant suppression of estimation bias and total average return improvement of over 10\\% compared to existing mainstream algorithms. The results of real vehicle testing show that DSAC-D can accurately characterize the multimodal distribution of different driving styles, and the diffusion policy network can characterize multimodal trajectories.</article>","contentLength":1699,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms","url":"https://arxiv.org/abs/2507.01378","date":1751515200,"author":"","guid":182350,"unread":true,"content":"<article>arXiv:2507.01378v1 Announce Type: new \nAbstract: Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as a critical research focus, and it typically requires the swarm to navigate effectively while avoiding obstacles and achieving continuous coverage over multiple mission targets. Although traditional Multi-Agent Reinforcement Learning (MARL) approaches offer dynamic adaptability, they are hindered by the semantic gap in numerical communication and the rigidity of homogeneous role structures, resulting in poor generalization and limited task scalability. Recent advances in Large Language Model (LLM)-based control frameworks demonstrate strong semantic reasoning capabilities by leveraging extensive prior knowledge. However, due to the lack of online learning and over-reliance on static priors, these works often struggle with effective exploration, leading to reduced individual potential and overall system performance. To address these limitations, we propose a Role-Adaptive LLM-Driven Yoked navigation algorithm RALLY. Specifically, we first develop an LLM-driven semantic decision framework that uses structured natural language for efficient semantic communication and collaborative reasoning. Afterward, we introduce a dynamic role-heterogeneity mechanism for adaptive role switching and personalized decision-making. Furthermore, we propose a Role-value Mixing Network (RMIX)-based assignment strategy that integrates LLM offline priors with MARL online policies to enable semi-offline training of role selection strategies. Experiments in the Multi-Agent Particle Environment (MPE) environment and a Software-In-The-Loop (SITL) platform demonstrate that RALLY outperforms conventional approaches in terms of task coverage, convergence speed, and generalization, highlighting its strong potential for collaborative navigation in agentic multi-UAV systems.</article>","contentLength":1894,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing","url":"https://arxiv.org/abs/2507.01376","date":1751515200,"author":"","guid":182351,"unread":true,"content":"<article>arXiv:2507.01376v1 Announce Type: new \nAbstract: AI agents are autonomous systems designed to perceive, reason, and act within dynamic environments. With the rapid advancements in generative AI (GenAI), large language models (LLMs) and multimodal large language models (MLLMs) have significantly improved AI agents' capabilities in semantic comprehension, complex reasoning, and autonomous decision-making. At the same time, the rise of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents (MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in information processing, environmental perception, and autonomous decision-making, opening new avenues for smart manufacturing. However, the definitions, capability boundaries, and practical applications of these emerging AI paradigms in smart manufacturing remain unclear. To address this gap, this study systematically reviews the evolution of AI and AI agent technologies, examines the core concepts and technological advancements of LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential applications in and integration into manufacturing, along with the potential challenges they may face.</article>","contentLength":1276,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Active Measurement: Efficient Estimation at Scale","url":"https://arxiv.org/abs/2507.01372","date":1751515200,"author":"","guid":182352,"unread":true,"content":"<article>arXiv:2507.01372v1 Announce Type: new \nAbstract: AI has the potential to transform scientific discovery by analyzing vast datasets with little human effort. However, current workflows often do not provide the accuracy or statistical guarantees that are needed. We introduce active measurement, a human-in-the-loop AI framework for scientific measurement. An AI model is used to predict measurements for individual units, which are then sampled for human labeling using importance sampling. With each new set of human labels, the AI model is improved and an unbiased Monte Carlo estimate of the total measurement is refined. Active measurement can provide precise estimates even with an imperfect AI model, and requires little human effort when the AI model is very accurate. We derive novel estimators, weighting schemes, and confidence intervals, and show that active measurement reduces estimation error compared to alternatives in several measurement tasks.</article>","contentLength":960,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Activation Reward Models for Few-Shot Model Alignment","url":"https://arxiv.org/abs/2507.01368","date":1751515200,"author":"","guid":182353,"unread":true,"content":"<article>arXiv:2507.01368v1 Announce Type: new \nAbstract: Aligning Large Language Models (LLMs) and Large Multimodal Models (LMMs) to human preferences is a central challenge in improving the quality of the models' generative outputs for real-world applications. A common approach is to use reward modeling to encode preferences, enabling alignment via post-training using reinforcement learning. However, traditional reward modeling is not easily adaptable to new preferences because it requires a separate reward model, commonly trained on large preference datasets. To address this, we introduce Activation Reward Models (Activation RMs) -- a novel few-shot reward modeling method that leverages activation steering to construct well-aligned reward signals using minimal supervision and no additional model finetuning. Activation RMs outperform existing few-shot reward modeling approaches such as LLM-as-a-judge with in-context learning, voting-based scoring, and token probability scoring on standard reward modeling benchmarks. Furthermore, we demonstrate the effectiveness of Activation RMs in mitigating reward hacking behaviors, highlighting their utility for safety-critical applications. Toward this end, we propose PreferenceHack, a novel few-shot setting benchmark, the first to test reward models on reward hacking in a paired preference format. Finally, we show that Activation RM achieves state-of-the-art performance on this benchmark, surpassing even GPT-4o.</article>","contentLength":1467,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation","url":"https://arxiv.org/abs/2507.01367","date":1751515200,"author":"","guid":182354,"unread":true,"content":"<article>arXiv:2507.01367v1 Announce Type: new \nAbstract: Physical adversarial attack methods expose the vulnerabilities of deep neural networks and pose a significant threat to safety-critical scenarios such as autonomous driving. Camouflage-based physical attack is a more promising approach compared to the patch-based attack, offering stronger adversarial effectiveness in complex physical environments. However, most prior work relies on mesh priors of the target object and virtual environments constructed by simulators, which are time-consuming to obtain and inevitably differ from the real world. Moreover, due to the limitations of the backgrounds in training images, previous methods often fail to produce multi-view robust adversarial camouflage and tend to fall into sub-optimal solutions. Due to these reasons, prior work lacks adversarial effectiveness and robustness across diverse viewpoints and physical environments. We propose a physical attack framework based on 3D Gaussian Splatting (3DGS), named PGA, which provides rapid and precise reconstruction with few images, along with photo-realistic rendering capabilities. Our framework further enhances cross-view robustness and adversarial effectiveness by preventing mutual and self-occlusion among Gaussians and employing a min-max optimization approach that adjusts the imaging background of each viewpoint, helping the algorithm filter out non-robust adversarial features. Extensive experiments validate the effectiveness and superiority of PGA. Our code is available at:https://github.com/TRLou/PGA.</article>","contentLength":1565,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Faster Algorithm for Second (s,t)-mincut and Breaking Quadratic barrier for Dual Edge Sensitivity for (s,t)-mincut","url":"https://arxiv.org/abs/2507.01366","date":1751515200,"author":"","guid":182355,"unread":true,"content":"<article>arXiv:2507.01366v1 Announce Type: new \nAbstract: We study (s,t)-cuts of second minimum capacity and present the following algorithmic and graph-theoretic results.\n  1. Vazirani and Yannakakis [ICALP 1992] designed the first algorithm for computing an (s,t)-cut of second minimum capacity using $O(n^2)$ maximum (s,t)-flow computations. For directed integer-weighted graphs, we significantly improve this bound by designing an algorithm that computes an $(s,t)$-cut of second minimum capacity using $O(\\sqrt{n})$ maximum (s,t)-flow computations w.h.p. To achieve this result, a close relationship of independent interest is established between $(s,t)$-cuts of second minimum capacity and global mincuts in directed weighted graphs.\n  2. Minimum+1 (s,t)-cuts have been studied quite well recently [Baswana, Bhanja, and Pandey, ICALP 2022], which is a special case of second (s,t)-mincut.\n  (a) For directed multi-graphs, we design an algorithm that, given any maximum (s,t)-flow, computes a minimum+1 (s,t)-cut, if it exists, in $O(m)$ time.\n  (b) The existing structures for storing and characterizing all minimum+1 (s,t)-cuts occupy $O(mn)$ space. For undirected multi-graphs, we design a DAG occupying only $O(m)$ space that stores and characterizes all minimum+1 (s,t)-cuts.\n  3. The study of minimum+1 (s,t)-cuts often turns out to be useful in designing dual edge sensitivity oracles -- a compact data structure for efficiently reporting an (s,t)-mincut after insertion/failure of any given pair of query edges. It has been shown recently [Bhanja, ICALP 2025] that any dual edge sensitivity oracle for (s,t)-mincut in undirected multi-graphs must occupy ${\\Omega}(n^2)$ space in the worst-case, irrespective of the query time. For simple graphs, we break this quadratic barrier while achieving a non-trivial query time.</article>","contentLength":1823,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MmBack: Clock-free Multi-Sensor Backscatter with Synchronous Acquisition and Multiplexing","url":"https://arxiv.org/abs/2507.01360","date":1751515200,"author":"","guid":182356,"unread":true,"content":"<article>arXiv:2507.01360v1 Announce Type: new \nAbstract: Backscatter tags provide a low-power solution for sensor applications, yet many real-world scenarios require multiple sensors-often of different types-for complex sensing tasks. However, existing designs support only a single sensor per tag, increasing spatial overhead. State-of-the-art approaches to multiplexing multiple sensor streams on a single tag rely on onboard clocks or multiple modulation chains, which add cost, enlarge form factor, and remain prone to timing drift-disrupting synchronization across sensors.\n  We present mmBack, a low-power, clock-free backscatter tag that enables synchronous multi-sensor data acquisition and multiplexing over a single modulation chain. mmBack synchronizes sensor inputs in parallel using a shared reference signal extracted from ambient RF excitation, eliminating the need for an onboard timing source. To efficiently multiplex sensor data, mmBack designs a voltage-division scheme to multiplex multiple sensor inputs as backscatter frequency shifts through a single oscillator and RF switch. At the receiver, mmBack develops a frequency tracking algorithm and a finite-state machine for accurate demultiplexing. mmBack's ASIC design consumes 25.56uW, while its prototype supports 5 concurrent sensor streams with bandwidths of up to 5kHz and 3 concurrent sensor streams with bandwidth of up to 18kHz. Evaluation shows that mmBack achieves an average SNR surpassing 15dB in signal reconstruction.</article>","contentLength":1496,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Kilometer-Scale Precipitation Downscaling with Conditional Wavelet Diffusion","url":"https://arxiv.org/abs/2507.01354","date":1751515200,"author":"","guid":182357,"unread":true,"content":"<article>arXiv:2507.01354v1 Announce Type: new \nAbstract: Effective hydrological modeling and extreme weather analysis demand precipitation data at a kilometer-scale resolution, which is significantly finer than the 10 km scale offered by standard global products like IMERG. To address this, we propose the Wavelet Diffusion Model (WDM), a generative framework that achieves 10x spatial super-resolution (downscaling to 1 km) and delivers a 9x inference speedup over pixel-based diffusion models. WDM is a conditional diffusion model that learns the learns the complex structure of precipitation from MRMS radar data directly in the wavelet domain. By focusing on high-frequency wavelet coefficients, it generates exceptionally realistic and detailed 1-km precipitation fields. This wavelet-based approach produces visually superior results with fewer artifacts than pixel-space models, and delivers a significant gains in sampling efficiency. Our results demonstrate that WDM provides a robust solution to the dual challenges of accuracy and speed in geoscience super-resolution, paving the way for more reliable hydrological forecasts.</article>","contentLength":1129,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy","url":"https://arxiv.org/abs/2507.01352","date":1751515200,"author":"","guid":182358,"unread":true,"content":"<article>arXiv:2507.01352v1 Announce Type: new \nAbstract: Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.</article>","contentLength":1966,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model","url":"https://arxiv.org/abs/2507.01351","date":1751515200,"author":"","guid":182359,"unread":true,"content":"<article>arXiv:2507.01351v1 Announce Type: new \nAbstract: The mixture-of-experts (MoE), which replaces dense models with sparse architectures, has gained attention in large vision-language models (LVLMs) for achieving comparable performance with fewer activated parameters. Existing MoE frameworks for LVLMs focus on token-to-expert routing (TER), encouraging different experts to specialize in processing distinct tokens. However, these frameworks often rely on the load balancing mechanism, overlooking the inherent distributional differences between vision and language. To this end, we propose a Long-Tailed Distribution-aware Router (LTDR) for vision-language TER, tackling two challenges: (1) Distribution-aware router for modality-specific routing. We observe that language TER follows a uniform distribution, whereas vision TER exhibits a long-tailed distribution. This discrepancy necessitates distinct routing strategies tailored to each modality. (2) Enhancing expert activation for vision tail tokens. Recognizing the importance of vision tail tokens, we introduce an oversampling-like strategy by increasing the number of activated experts for these tokens. Experiments on extensive benchmarks validate the effectiveness of our approach.</article>","contentLength":1241,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cooperative Target Capture in 3D Engagements over Switched Dynamic Graphs","url":"https://arxiv.org/abs/2507.01350","date":1751515200,"author":"","guid":182360,"unread":true,"content":"<article>arXiv:2507.01350v1 Announce Type: new \nAbstract: This paper presents a leaderless cooperative guidance strategy for simultaneous time-constrained interception of a stationary target when the interceptors exchange information over switched dynamic graphs. We specifically focus on scenarios when the interceptors lack radial acceleration capabilities, relying solely on their lateral acceleration components. This consideration aligns with their inherent kinematic turn constraints. The proposed strategy explicitly addresses the complexities of coupled 3D engagements, thereby mitigating performance degradation that typically arises when the pitch and yaw channels are decoupled into two separate, mutually orthogonal planar engagements. Moreover, our formulation incorporates modeling uncertainties associated with the time-to-go estimation into the derivation of cooperative guidance commands to ensure robustness against inaccuracies in dynamic engagement scenarios. To optimize control efficiency, we analytically derive the lateral acceleration components in the orthogonal pitch and yaw channels by solving an instantaneous optimization problem, subject to an affine constraint. We show that the proposed cooperative guidance commands guarantee consensus in time-to-go values within a predefined time, which can be prescribed as a design parameter, regardless of the interceptors' initial configurations. We provide simulations to attest to the efficacy of the proposed method.</article>","contentLength":1484,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation","url":"https://arxiv.org/abs/2507.01347","date":1751515200,"author":"","guid":182361,"unread":true,"content":"<article>arXiv:2507.01347v1 Announce Type: new \nAbstract: We introduce Generalized Test-Time Augmentation (GTTA), a highly effective method for improving the performance of a trained model, which unlike other existing Test-Time Augmentation approaches from the literature is general enough to be used off-the-shelf for many vision and non-vision tasks, such as classification, regression, image segmentation and object detection. By applying a new general data transformation, that randomly perturbs multiple times the PCA subspace projection of a test input, GTTA forms robust ensembles at test time in which, due to sound statistical properties, the structural and systematic noises in the initial input data is filtered out and final estimator errors are reduced. Different from other existing methods, we also propose a final self-supervised learning stage in which the ensemble output, acting as an unsupervised teacher, is used to train the initial single student model, thus reducing significantly the test time computational cost, at no loss in accuracy. Our tests and comparisons to strong TTA approaches and SoTA models on various vision and non-vision well-known datasets and tasks, such as image classification and segmentation, speech recognition and house price prediction, validate the generality of the proposed GTTA. Furthermore, we also prove its effectiveness on the more specific real-world task of salmon segmentation and detection in low-visibility underwater videos, for which we introduce DeepSalmon, the largest dataset of its kind in the literature.</article>","contentLength":1566,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learning Camera-Agnostic White-Balance Preferences","url":"https://arxiv.org/abs/2507.01342","date":1751515200,"author":"","guid":182362,"unread":true,"content":"<article>arXiv:2507.01342v1 Announce Type: new \nAbstract: The image signal processor (ISP) pipeline in modern cameras consists of several modules that transform raw sensor data into visually pleasing images in a display color space. Among these, the auto white balance (AWB) module is essential for compensating for scene illumination. However, commercial AWB systems often strive to compute aesthetic white-balance preferences rather than accurate neutral color correction. While learning-based methods have improved AWB accuracy, they typically struggle to generalize across different camera sensors -- an issue for smartphones with multiple cameras. Recent work has explored cross-camera AWB, but most methods remain focused on achieving neutral white balance. In contrast, this paper is the first to address aesthetic consistency by learning a post-illuminant-estimation mapping that transforms neutral illuminant corrections into aesthetically preferred corrections in a camera-agnostic space. Once trained, our mapping can be applied after any neutral AWB module to enable consistent and stylized color rendering across unseen cameras. Our proposed model is lightweight -- containing only $\\sim$500 parameters -- and runs in just 0.024 milliseconds on a typical flagship mobile CPU. Evaluated on a dataset of 771 smartphone images from three different cameras, our method achieves state-of-the-art performance while remaining fully compatible with existing cross-camera AWB techniques, introducing minimal computational and memory overhead.</article>","contentLength":1537,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Physics-informed Ground Reaction Dynamics from Human Motion Capture","url":"https://arxiv.org/abs/2507.01340","date":1751515200,"author":"","guid":182363,"unread":true,"content":"<article>arXiv:2507.01340v1 Announce Type: new \nAbstract: Body dynamics are crucial information for the analysis of human motions in important research fields, ranging from biomechanics, sports science to computer vision and graphics. Modern approaches collect the body dynamics, external reactive force specifically, via force plates, synchronizing with human motion capture data, and learn to estimate the dynamics from a black-box deep learning model. Being specialized devices, force plates can only be installed in laboratory setups, imposing a significant limitation on the learning of human dynamics. To this end, we propose a novel method for estimating human ground reaction dynamics directly from the more reliable motion capture data with physics laws and computational simulation as constrains. We introduce a highly accurate and robust method for computing ground reaction forces from motion capture data using Euler's integration scheme and PD algorithm. The physics-based reactive forces are used to inform the learning model about the physics-informed motion dynamics thus improving the estimation accuracy. The proposed approach was tested on the GroundLink dataset, outperforming the baseline model on: 1) the ground reaction force estimation accuracy compared to the force plates measurement; and 2) our simulated root trajectory precision. The implementation code is available at https://github.com/cuongle1206/Phys-GRD</article>","contentLength":1430,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"User-guided Generative Source Separation","url":"https://arxiv.org/abs/2507.01339","date":1751515200,"author":"","guid":182364,"unread":true,"content":"<article>arXiv:2507.01339v1 Announce Type: new \nAbstract: Music source separation (MSS) aims to extract individual instrument sources from their mixture. While most existing methods focus on the widely adopted four-stem separation setup (vocals, bass, drums, and other instruments), this approach lacks the flexibility needed for real-world applications. To address this, we propose GuideSep, a diffusion-based MSS model capable of instrument-agnostic separation beyond the four-stem setup. GuideSep is conditioned on multiple inputs: a waveform mimicry condition, which can be easily provided by humming or playing the target melody, and mel-spectrogram domain masks, which offer additional guidance for separation. Unlike prior approaches that relied on fixed class labels or sound queries, our conditioning scheme, coupled with the generative approach, provides greater flexibility and applicability. Additionally, we design a mask-prediction baseline using the same model architecture to systematically compare predictive and generative approaches. Our objective and subjective evaluations demonstrate that GuideSep achieves high-quality separation while enabling more versatile instrument extraction, highlighting the potential of user participation in the diffusion-based generative process for MSS. Our code and demo page are available at https://yutongwen.github.io/GuideSep/</article>","contentLength":1374,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dynamical Multimodal Fusion with Mixture-of-Experts for Localizations","url":"https://arxiv.org/abs/2507.01337","date":1751515200,"author":"","guid":182365,"unread":true,"content":"<article>arXiv:2507.01337v1 Announce Type: new \nAbstract: Multimodal fingerprinting is a crucial technique to sub-meter 6G integrated sensing and communications (ISAC) localization, but two hurdles block deployment: (i) the contribution each modality makes to the target position varies with the operating conditions such as carrier frequency, and (ii) spatial and fingerprint ambiguities markedly undermine localization accuracy, especially in non-line-of-sight (NLOS) scenarios. To solve these problems, we introduce SCADF-MoE, a spatial-context aware dynamic fusion network built on a soft mixture-of-experts backbone. SCADF-MoE first clusters neighboring points into short trajectories to inject explicit spatial context. Then, it adaptively fuses channel state information, angle of arrival profile, distance, and gain through its learnable MoE router, so that the most reliable cues dominate at each carrier band. The fused representation is fed to a modality-task MoE that simultaneously regresses the coordinates of every vertex in the trajectory and its centroid, thereby exploiting inter-point correlations. Finally, an auxiliary maximum-mean-discrepancy loss enforces expert diversity and mitigates gradient interference, stabilizing multi-task training. On three real urban layouts and three carrier bands (2.6, 6, 28 GHz), the model delivers consistent sub-meter MSE and halves unseen-NLOS error versus the best prior work. To our knowledge, this is the first work that leverages large-scale multimodal MoE for frequency-robust ISAC localization.</article>","contentLength":1550,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LEDOM: An Open and Fundamental Reverse Language Model","url":"https://arxiv.org/abs/2507.01335","date":1751515200,"author":"","guid":182366,"unread":true,"content":"<article>arXiv:2507.01335v1 Announce Type: new \nAbstract: We introduce LEDOM, the first purely reverse language model, trained autoregressively on 435B tokens with 2B and 7B parameter variants, which processes sequences in reverse temporal order through previous token prediction. For the first time, we present the reverse language model as a potential foundational model across general tasks, accompanied by a set of intriguing examples and insights. Based on LEDOM, we further introduce a novel application: Reverse Reward, where LEDOM-guided reranking of forward language model outputs leads to substantial performance improvements on mathematical reasoning tasks. This approach leverages LEDOM's unique backward reasoning capability to refine generation quality through posterior evaluation. Our findings suggest that LEDOM exhibits unique characteristics with broad application potential. We will release all models, training code, and pre-training data to facilitate future research.</article>","contentLength":981,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs","url":"https://arxiv.org/abs/2507.01334","date":1751515200,"author":"","guid":182367,"unread":true,"content":"<article>arXiv:2507.01334v1 Announce Type: new \nAbstract: Navigating the complexities of physics reasoning has long been a difficult task for Large Language Models (LLMs), requiring a synthesis of profound conceptual understanding and adept problem-solving techniques. In this study, we investigate the application of advanced instruction-tuned reasoning models, such as Deepseek-R1, to address a diverse spectrum of physics problems curated from the challenging SciBench benchmark. Our comprehensive experimental evaluation reveals the remarkable capabilities of reasoning models. Not only do they achieve state-of-the-art accuracy in answering intricate physics questions, but they also generate distinctive reasoning patterns that emphasize on symbolic derivation. Furthermore, our findings indicate that even for these highly sophisticated reasoning models, the strategic incorporation of few-shot prompting can still yield measurable improvements in overall accuracy, highlighting the potential for continued performance gains.</article>","contentLength":1023,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Multi-User Generative Semantic Communication with Intent-Aware Semantic-Splitting Multiple Access","url":"https://arxiv.org/abs/2507.01333","date":1751515200,"author":"","guid":182368,"unread":true,"content":"<article>arXiv:2507.01333v1 Announce Type: new \nAbstract: With the booming development of generative artificial intelligence (GAI), semantic communication (SemCom) has emerged as a new paradigm for reliable and efficient communication. This paper considers a multi-user downlink SemCom system, using vehicular networks as the representative scenario for multi-user content dissemination. To address diverse yet overlapping user demands, we propose a multi-user Generative SemCom-enhanced intent-aware semantic-splitting multiple access (SS-MGSC) framework. In the framework, we construct an intent-aware shared knowledge base (SKB) that incorporates prior knowledge of semantic information (SI) and user-specific preferences. Then, we designate the common SI as a one-hot semantic map that is broadcast to all users, while the private SI is delivered as personalized text for each user. On the receiver side, a diffusion model enhanced with ControlNet is adopted to generate high-quality personalized images. To capture both semantic relevance and perceptual similarity, we design a novel semantic efficiency score (SES) metric as the optimization objective. Building on this, we formulate a joint optimization problem for multi-user semantic extraction and beamforming, solved using a reinforcement learning-based algorithm due to its robustness in high-dimensional settings. Simulation results demonstrate the effectiveness of the proposed scheme.</article>","contentLength":1440,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On Securing Berrut Approximated Coded Computing Through Discrete Cosine Transforms","url":"https://arxiv.org/abs/2507.01330","date":1751515200,"author":"","guid":182369,"unread":true,"content":"<article>arXiv:2507.01330v1 Announce Type: new \nAbstract: Coded computing is a reliable and fault-tolerant mechanism for implementing large computing tasks over a distributed set of worker nodes. While a majority of coded computing frameworks address accurate computation of the target functions, they are restricted to computing multivariate polynomial functions. To generalize these computing platforms to non-polynomial target functions, Jahani-Nezhad and Maddah-Ali recently proposed Berrut Approximated Coded computing (BACC), which was proven fault-tolerant against stragglers albiet with tolerable approximation errors on the target functions. Despite these benefits, there is no formal study on the security of BACC against worker nodes which report erroneous computations. To fill this research gap, we use a coding-theoretic approach to propose Secure Berrut Approximated Coded Computing (SBACC), which is resilient to stragglers and also robust to the presence of such untrusted worker nodes. One of the highlights of SBACC is the new choice of evaluation points for distributed computation which makes the well-known Discrete Cosine Transform (DCT) codes amenable to error detection and correction. To validate the new choice of evaluation points, first, we derive bounds on the accuracy of SBACC in the absence of untrusted worker nodes. Subsequently, to handle the presence of untrusted worker nodes, we derive bounds on the accuracy of SBACC and show that interesting optimization problems can be formulated to study the trade-off between the error correcting capability of the DCT codes and the accuracy of the target computation.</article>","contentLength":1637,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy","url":"https://arxiv.org/abs/2507.01327","date":1751515200,"author":"","guid":182370,"unread":true,"content":"<article>arXiv:2507.01327v1 Announce Type: new \nAbstract: Detecting abnormal events in real-world customer service dialogues is highly challenging due to the complexity of business data and the dynamic nature of customer interactions. Moreover, models must demonstrate strong out-of-domain (OOD) generalization to enable rapid adaptation across different business scenarios and maximize commercial value. In this work, we propose a novel Adaptive Perplexity-Aware Reinforcement Learning (APARL) framework that leverages the advanced reasoning capabilities of large language models for abnormal event detection. APARL introduces a dual-loop dynamic curriculum learning architecture, enabling the model to progressively focus on more challenging samples as its proficiency increases. This design effectively addresses performance bottlenecks and significantly enhances OOD transferability. Extensive evaluations on food delivery dialogue tasks show that our model achieves significantly enhanced adaptability and robustness, attaining the highest F1 score with an average improvement of 17.19\\%, and an average improvement of 9.59\\% in OOD transfer tests. This method provides a superior solution for industrial deployment of anomaly detection models, contributing to improved operational efficiency and commercial benefits.</article>","contentLength":1313,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks","url":"https://arxiv.org/abs/2507.01321","date":1751515200,"author":"","guid":182371,"unread":true,"content":"<article>arXiv:2507.01321v1 Announce Type: new \nAbstract: In-context learning (ICL) has demonstrated remarkable success in large language models (LLMs) due to its adaptability and parameter-free nature. However, it also introduces a critical vulnerability to backdoor attacks, where adversaries can manipulate LLM behaviors by simply poisoning a few ICL demonstrations. In this paper, we propose, for the first time, the dual-learning hypothesis, which posits that LLMs simultaneously learn both the task-relevant latent concepts and backdoor latent concepts within poisoned demonstrations, jointly influencing the probability of model outputs. Through theoretical analysis, we derive an upper bound for ICL backdoor effects, revealing that the vulnerability is dominated by the concept preference ratio between the task and the backdoor. Motivated by these findings, we propose ICLShield, a defense mechanism that dynamically adjusts the concept preference ratio. Our method encourages LLMs to select clean demonstrations during the ICL phase by leveraging confidence and similarity scores, effectively mitigating susceptibility to backdoor attacks. Extensive experiments across multiple LLMs and tasks demonstrate that our method achieves state-of-the-art defense effectiveness, significantly outperforming existing approaches (+26.02% on average). Furthermore, our method exhibits exceptional adaptability and defensive performance even for closed-source models (e.g., GPT-4).</article>","contentLength":1470,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Robust Multi-generation Learned Compression of Point Cloud Attribute","url":"https://arxiv.org/abs/2507.01320","date":1751515200,"author":"","guid":182372,"unread":true,"content":"<article>arXiv:2507.01320v1 Announce Type: new \nAbstract: Existing learned point cloud attribute compression methods primarily focus on single-pass rate-distortion optimization, while overlooking the issue of cumulative distortion in multi-generation compression scenarios. This paper, for the first time, investigates the multi-generation issue in learned point cloud attribute compression. We identify two primary factors contributing to quality degradation in multi-generation compression: quantization-induced non-idempotency and transformation irreversibility. To address the former, we propose a Mapping Idempotency Constraint, that enables the network to learn the complete compression-decompression mapping, enhancing its robustness to repeated processes. To address the latter, we introduce a Transformation Reversibility Constraint, which preserves reversible information flow via a quantization-free training path. Further, we propose a Latent Variable Consistency Constraint which enhances the multi-generation compression robustness by incorporating a decompression-compression cross-generation path and a latent variable consistency loss term. Extensive experiments conducted on the Owlii and 8iVFB datasets verify that the proposed methods can effectively suppress multi-generation loss while maintaining single-pass rate-distortion performance comparable to baseline models.</article>","contentLength":1381,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Context-Aware Code Wiring Recommendation with LLM-based Agent","url":"https://arxiv.org/abs/2507.01315","date":1751515200,"author":"","guid":182373,"unread":true,"content":"<article>arXiv:2507.01315v1 Announce Type: new \nAbstract: Copy-paste-modify is a widespread and pragmatic practice in software development, where developers adapt reused code snippets, sourced from platforms such as Stack Overflow, GitHub, or LLM outputs, into their local codebase. A critical yet underexplored aspect of this adaptation is code wiring, which involves substituting unresolved variables in the pasted code with suitable ones from the surrounding context. Existing solutions either rely on heuristic rules or historical templates, often failing to effectively utilize contextual information, despite studies showing that over half of adaptation cases are context-dependent. In this paper, we introduce WIRL, an LLM-based agent for code wiring framed as a Retrieval-Augmented Generation (RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an orchestration module to identify unresolved variables, retrieve context, and perform context-aware substitutions. To balance efficiency and autonomy, the agent adopts a mixed strategy: deterministic rule-based steps for common patterns, and a state-machine-guided decision process for intelligent exploration. We evaluate WIRL on a carefully curated, high-quality dataset consisting of real-world code adaptation scenarios. Our approach achieves an exact match precision of 91.7% and a recall of 90.0%, outperforming advanced LLMs by 22.6 and 13.7 percentage points in precision and recall, respectively, and surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results underscore its practical utility, particularly in contexts with complex variable dependencies or multiple unresolved variables. We believe WIRL paves the way for more intelligent and context-aware developer assistance in modern IDEs.</article>","contentLength":1782,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Neural Hamiltonian Operator","url":"https://arxiv.org/abs/2507.01313","date":1751515200,"author":"","guid":182374,"unread":true,"content":"<article>arXiv:2507.01313v1 Announce Type: new \nAbstract: Stochastic control problems in high dimensions are notoriously difficult to solve due to the curse of dimensionality. An alternative to traditional dynamic programming is Pontryagin's Maximum Principle (PMP), which recasts the problem as a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In this paper, we introduce a formal framework for solving such problems with deep learning by defining a \\textbf{Neural Hamiltonian Operator (NHO)}. This operator parameterizes the coupled FBSDE dynamics via neural networks that represent the feedback control and an ansatz for the value function's spatial gradient. We show how the optimal NHO can be found by training the underlying networks to enforce the consistency conditions dictated by the PMP. By adopting this operator-theoretic view, we situate the deep FBSDE method within the rigorous language of statistical inference, framing it as a problem of learning an unknown operator from simulated data. This perspective allows us to prove the universal approximation capabilities of NHOs under general martingale drivers and provides a clear lens for analyzing the significant optimization challenges inherent to this class of models.</article>","contentLength":1252,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SD-Acc: Accelerating Stable Diffusion through Phase-aware Sampling and Hardware Co-Optimizations","url":"https://arxiv.org/abs/2507.01309","date":1751515200,"author":"","guid":182375,"unread":true,"content":"<article>arXiv:2507.01309v1 Announce Type: new \nAbstract: The emergence of diffusion models has significantly advanced generative AI, improving the quality, realism, and creativity of image and video generation. Among them, Stable Diffusion (StableDiff) stands out as a key model for text-to-image generation and a foundation for next-generation multi-modal algorithms. However, its high computational and memory demands hinder inference speed and energy efficiency. To address these challenges, we identify three core issues: (1) intensive and often redundant computations, (2) heterogeneous operations involving convolutions and attention mechanisms, and (3) diverse weight and activation sizes.\n  We present SD-Acc, a novel algorithm and hardware co-optimization framework. At the algorithm level, we observe that high-level features in certain denoising phases show significant similarity, enabling approximate computation. Leveraging this, we propose an adaptive, phase-aware sampling strategy that reduces compute and memory loads. This framework automatically balances image quality and complexity based on the StableDiff model and user requirements. At the hardware level, we design an address-centric dataflow to efficiently handle heterogeneous operations within a simple systolic array. We address the bottleneck of nonlinear functions via a two-stage streaming architecture and a reconfigurable vector processing unit. Additionally, we implement adaptive dataflow optimizations by combining dynamic reuse and operator fusion tailored to StableDiff workloads, significantly reducing memory access. Across multiple StableDiff models, our method achieves up to a 3x reduction in computational demand without compromising image quality. Combined with our optimized hardware accelerator, SD-Acc delivers higher speed and energy efficiency than traditional CPU and GPU implementations.</article>","contentLength":1882,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction","url":"https://arxiv.org/abs/2507.01308","date":1751515200,"author":"","guid":182376,"unread":true,"content":"<article>arXiv:2507.01308v1 Announce Type: new \nAbstract: Accurate motion forecasting is critical for safe and efficient autonomous driving, enabling vehicles to predict future trajectories and make informed decisions in complex traffic scenarios. Most of the current designs of motion prediction models are based on the major representation of lane centerlines, which limits their capability to capture critical road environments and traffic rules and constraints. In this work, we propose an enhanced motion forecasting model informed by multiple vector map elements, including lane boundaries and road edges, that facilitates a richer and more complete representation of driving environments. An effective feature fusion strategy is developed to merge information in different vector map components, where the model learns holistic information on road structures and their interactions with agents. Since encoding more information about the road environment increases memory usage and is computationally expensive, we developed an effective pruning mechanism that filters the most relevant map connections to the target agent, ensuring computational efficiency while maintaining essential spatial and semantic relationships for accurate trajectory prediction. Overcoming the limitations of lane centerline-based models, our method provides a more informative and efficient representation of the driving environment and advances the state of the art for autonomous vehicle motion forecasting. We verify our approach with extensive experiments on the Argoverse 2 motion forecasting dataset, where our method maintains competitiveness on AV2 while achieving improved performance.\n  Index Terms-Autonomous driving, trajectory prediction, vector map elements, road topology, connection pruning, Argoverse 2.</article>","contentLength":1796,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting","url":"https://arxiv.org/abs/2507.01305","date":1751515200,"author":"","guid":182377,"unread":true,"content":"<article>arXiv:2507.01305v1 Announce Type: new \nAbstract: We introduce a simple yet effective technique for estimating lighting from a single low-dynamic-range (LDR) image by reframing the task as a chrome ball inpainting problem. This approach leverages a pre-trained diffusion model, Stable Diffusion XL, to overcome the generalization failures of existing methods that rely on limited HDR panorama datasets. While conceptually simple, the task remains challenging because diffusion models often insert incorrect or inconsistent content and cannot readily generate chrome balls in HDR format. Our analysis reveals that the inpainting process is highly sensitive to the initial noise in the diffusion process, occasionally resulting in unrealistic outputs. To address this, we first introduce DiffusionLight, which uses iterative inpainting to compute a median chrome ball from multiple outputs to serve as a stable, low-frequency lighting prior that guides the generation of a high-quality final result. To generate high-dynamic-range (HDR) light probes, an Exposure LoRA is fine-tuned to create LDR images at multiple exposure values, which are then merged. While effective, DiffusionLight is time-intensive, requiring approximately 30 minutes per estimation. To reduce this overhead, we introduce DiffusionLight-Turbo, which reduces the runtime to about 30 seconds with minimal quality loss. This 60x speedup is achieved by training a Turbo LoRA to directly predict the averaged chrome balls from the iterative process. Inference is further streamlined into a single denoising pass using a LoRA swapping technique. Experimental results that show our method produces convincing light estimates across diverse settings and demonstrates superior generalization to in-the-wild scenarios. Our code is available at https://diffusionlight.github.io/turbo</article>","contentLength":1842,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Practical SAFE-AI Framework for Small and Medium-Sized Enterprises Developing Medical Artificial Intelligence Ethics Policies","url":"https://arxiv.org/abs/2507.01304","date":1751515200,"author":"","guid":182378,"unread":true,"content":"<article>arXiv:2507.01304v1 Announce Type: new \nAbstract: Artificial intelligence (AI) offers incredible possibilities for patient care, but raises significant ethical issues, such as the potential for bias. Powerful ethical frameworks exist to minimize these issues, but are often developed for academic or regulatory environments and tend to be comprehensive but overly prescriptive, making them difficult to operationalize within fast-paced, resource-constrained environments. We introduce the Scalable Agile Framework for Execution in AI (SAFE-AI) designed to balance ethical rigor with business priorities by embedding ethical oversight into standard Agile-based product development workflows. The framework emphasizes the early establishment of testable acceptance criteria, fairness metrics, and transparency metrics to manage model uncertainty, while also promoting continuous monitoring and re-evaluation of these metrics across the AI lifecycle. A core component of this framework are responsibility metrics using scenario-based probability analogy mapping designed to enhance transparency and stakeholder trust. This ensures that retraining or tuning activities are subject to lightweight but meaningful ethical review. By focusing on the minimum necessary requirements for responsible development, our framework offers a scalable, business-aligned approach to ethical AI suitable for organizations without dedicated ethics teams.</article>","contentLength":1432,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Synchronising DER inverters to weak grid using Kalman filter and LQR current controller","url":"https://arxiv.org/abs/2507.01300","date":1751515200,"author":"","guid":182379,"unread":true,"content":"<article>arXiv:2507.01300v1 Announce Type: new \nAbstract: Grid-following (GFL) inverters are commonly used for integrating renewable energy sources into power grids. However, the dynamic performance of GFL models can be significantly impacted by the Phase-Locked Loop (PLL) in a weak grid, leading to instability due to inaccuracies in grid source phase angle estimation. The proposed method in this manuscript replaces the PLL with an Advanced Angle Estimation based Kalman Filter including a Linear Quadratic Regulator (LQR) controller of the GFL. This method is robust in incorporating grid impedance terms as part of state space models in the Kalman Filter approach to estimate instantaneous phase angle using {\\alpha}-\\b{eta} Synchronous Reference Frame equations. The stability performance of the proposed approach is validated through eigenvalue analysis in a two-source case. Additionally, an LQR controller is employed to regulate capacitor voltage, inverter current, and the current at the Point of Common Coupling (PCC). The proposed controller surpasses existing approaches in terms of accuracy and distortion reduction under abrupt grid impedance increases. Moreover, drop compensation is integrated into the Kalman Filter to enhance robustness of the inverter against external oscillation disturbances from a synchronous machine connected to the GFL via the PCC. The results in this paper demonstrate substantial improvement in oscillation damping across a range of frequencies compared with published research works.</article>","contentLength":1522,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"La RoSA: Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation","url":"https://arxiv.org/abs/2507.01299","date":1751515200,"author":"","guid":182380,"unread":true,"content":"<article>arXiv:2507.01299v1 Announce Type: new \nAbstract: Activation sparsity can reduce the computational overhead and memory transfers during the forward pass of Large Language Model (LLM) inference. Existing methods face limitations, either demanding time-consuming recovery training that hinders real-world adoption, or relying on empirical magnitude-based pruning, which causes fluctuating sparsity and unstable inference speed-up. This paper introduces LaRoSA (Layerwise Rotated Sparse Activation), a novel method for activation sparsification designed to improve LLM efficiency without requiring additional training or magnitude-based pruning. We leverage layerwise orthogonal rotations to transform input activations into rotated forms that are more suitable for sparsification. By employing a Top-K selection approach within the rotated activations, we achieve consistent model-level sparsity and reliable wall-clock time speed-up. LaRoSA is effective across various sizes and types of LLMs, demonstrating minimal performance degradation and robust inference acceleration. Specifically, for LLaMA2-7B at 40% sparsity, LaRoSA achieves a mere 0.17 perplexity gap with a consistent 1.30x wall-clock time speed-up, and reduces the accuracy gap in zero-shot tasks compared to the dense model to just 0.54%, while surpassing TEAL by 1.77% and CATS by 17.14%.</article>","contentLength":1352,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Optimal Dispersion Under Asynchrony","url":"https://arxiv.org/abs/2507.01298","date":1751515200,"author":"","guid":182381,"unread":true,"content":"<article>arXiv:2507.01298v1 Announce Type: new \nAbstract: We study the dispersion problem in anonymous port-labeled graphs: $k \\leq n$ mobile agents, each with a unique ID and initially located arbitrarily on the nodes of an $n$-node graph with maximum degree $\\Delta$, must autonomously relocate so that no node hosts more than one agent. Dispersion serves as a fundamental task in distributed computing of mobile agents, and its complexity stems from key challenges in local coordination under anonymity and limited memory.\n  The goal is to minimize both the time to achieve dispersion and the memory required per agent. It is known that any algorithm requires $\\Omega(k)$ time in the worst case, and $\\Omega(\\log k)$ bits of memory per agent. A recent result [SPAA'25] gives an optimal $O(k)$-time algorithm in the synchronous setting and an $O(k \\log k)$-time algorithm in the asynchronous setting, both using $O(\\log(k+\\Delta))$ bits.\n  In this paper, we close the complexity gap in the asynchronous setting by presenting the first dispersion algorithm that runs in optimal $O(k)$ time using $O(\\log(k+\\Delta))$ bits of memory per agent. Our solution is based on a novel technique we develop in this paper that constructs a port-one tree in anonymous graphs, which may be of independent interest.</article>","contentLength":1292,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks","url":"https://arxiv.org/abs/2507.01297","date":1751515200,"author":"","guid":182382,"unread":true,"content":"<article>arXiv:2507.01297v1 Announce Type: new \nAbstract: Retrieval-augmented Generation (RAG) has primarily been studied in limited settings, such as factoid question answering; more challenging, reasoning-intensive benchmarks have seen limited success from minimal RAG. In this work, we challenge this prevailing view on established, reasoning-intensive benchmarks: MMLU, MMLU Pro, AGI Eval, GPQA, and MATH. We identify a key missing component in prior work: a usable, web-scale datastore aligned with the breadth of pretraining data. To this end, we introduce CompactDS: a diverse, high-quality, web-scale datastore that achieves high retrieval accuracy and subsecond latency on a single-node. The key insights are (1) most web content can be filtered out without sacrificing coverage, and a compact, high-quality subset is sufficient; and (2) combining in-memory approximate nearest neighbor (ANN) retrieval and on-disk exact search balances speed and recall. Using CompactDS, we show that a minimal RAG pipeline achieves consistent accuracy improvements across all benchmarks and model sizes (8B--70B), with relative gains of 10% on MMLU, 33% on MMLU Pro, 14% on GPQA, and 19% on MATH. No single data source suffices alone, highlighting the importance of diversity of sources (web crawls, curated math, academic papers, textbooks). Finally, we show that our carefully designed in-house datastore matches or outperforms web search engines such as Google Search, as well as recently proposed, complex agent-based RAG systems--all while maintaining simplicity, reproducibility, and self-containment. We release CompactDS and our retrieval pipeline, supporting future research exploring retrieval-based AI systems.</article>","contentLength":1706,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stability and error analysis of a new class of higher-order consistent splitting schemes for the Navier-Stokes equations","url":"https://arxiv.org/abs/2507.01296","date":1751515200,"author":"","guid":182383,"unread":true,"content":"<article>arXiv:2507.01296v1 Announce Type: new \nAbstract: A new class of fully decoupled consistent splitting schemes for the Navier-Stokes equations are constructed and analyzed in this paper. The schemes are based on the Taylor expansion at $t^{n+\\beta}$ with $\\beta\\ge 1$ being a free parameter. It is shown that by choosing {\\color{black} $\\beta= 3, \\,6,\\,9$} respectively for the second-, third- and fourth-order schemes, their numerical solutions are uniformed bounded in a strong norm, and admit optimal global-in-time convergence rates in both 2D and 3D. {\\color{black}These } results are the first stability and convergence results for any fully decoupled, higher than second-order schemes for the Navier-Stokes equations. Numerical results are provided to show that the third- and fourth-order schemes based on the usual BDF (i.e. $\\beta=1$) are not unconditionally stable while the new third- and fourth-order schemes with suitable $\\beta$ are unconditionally stable and lead to expected convergence rates.</article>","contentLength":1008,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learning an Ensemble Token from Task-driven Priors in Facial Analysis","url":"https://arxiv.org/abs/2507.01290","date":1751515200,"author":"","guid":182384,"unread":true,"content":"<article>arXiv:2507.01290v1 Announce Type: new \nAbstract: Facial analysis exhibits task-specific feature variations. While Convolutional Neural Networks (CNNs) have enabled the fine-grained representation of spatial information, Vision Transformers (ViTs) have facilitated the representation of semantic information at the patch level. Although the generalization of conventional methodologies has advanced visual interpretability, there remains paucity of research that preserves the unified feature representation on single task learning during the training process. In this work, we introduce ET-Fuser, a novel methodology for learning ensemble token by leveraging attention mechanisms based on task priors derived from pre-trained models for facial analysis. Specifically, we propose a robust prior unification learning method that generates a ensemble token within a self-attention mechanism, which shares the mutual information along the pre-trained encoders. This ensemble token approach offers high efficiency with negligible computational cost. Our results show improvements across a variety of facial analysis, with statistically significant enhancements observed in the feature representations.</article>","contentLength":1196,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fluid Aerial Networks: UAV Rotation for Inter-Cell Interference Mitigation","url":"https://arxiv.org/abs/2507.01289","date":1751515200,"author":"","guid":182385,"unread":true,"content":"<article>arXiv:2507.01289v1 Announce Type: new \nAbstract: With the rapid development of aerial infrastructure, unmanned aerial vehicles (UAVs) that function as aerial base stations (ABSs) extend terrestrial network services into the sky, enabling on-demand connectivity and enhancing emergency communication capabilities in cellular networks by leveraging the flexibility and mobility of UAVs. In such a UAV-assisted network, this paper investigates position-based beamforming between ABSs and ground users (GUs). To mitigate inter-cell interference, we propose a novel fluid aerial network that leverages ABS rotation to increase multi-cell capacity and overall network efficiency. Specifically, considering the line-of-sight channel model, the spatial beamforming weights are determined by the orientation angles of the GUs. In this direction, we examine the beamforming gain of a two-dimensional multiple-input multiple-output (MIMO) array at various ground positions, revealing that ABS rotation significantly affects multi-user channel correlation and inter-cell interference. Based on these findings, we propose an alternative low-complexity algorithm to design the optimal rotation angle for ABSs, aiming to reduce inter-cell interference and thus maximize the sum rate of multi-cell systems. In simulations, exhaustive search serves as a benchmark to validate the optimization performance of the proposed sequential ABS rotation scheme. Moreover, simulation results demonstrate that, in interference-limited regions, the proposed ABS rotation paradigm can significantly reduce inter-cell interference in terrestrial networks and improve the multi-cell sum rate by approximately 10\\% compared to fixed-direction ABSs without rotation.</article>","contentLength":1732,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Far From Sight, Far From Mind: Inverse Distance Weighting for Graph Federated Recommendation","url":"https://arxiv.org/abs/2507.01285","date":1751515200,"author":"","guid":182386,"unread":true,"content":"<article>arXiv:2507.01285v1 Announce Type: new \nAbstract: Graph federated recommendation systems offer a privacy-preserving alternative to traditional centralized recommendation architectures, which often raise concerns about data security. While federated learning enables personalized recommendations without exposing raw user data, existing aggregation methods overlook the unique properties of user embeddings in this setting. Indeed, traditional aggregation methods fail to account for their complexity and the critical role of user similarity in recommendation effectiveness. Moreover, evolving user interactions require adaptive aggregation while preserving the influence of high-relevance anchor users (the primary users before expansion in graph-based frameworks). To address these limitations, we introduce Dist-FedAvg, a novel distance-based aggregation method designed to enhance personalization and aggregation efficiency in graph federated learning. Our method assigns higher aggregation weights to users with similar embeddings, while ensuring that anchor users retain significant influence in local updates. Empirical evaluations on multiple datasets demonstrate that Dist-FedAvg consistently outperforms baseline aggregation techniques, improving recommendation accuracy while maintaining seamless integration into existing federated learning frameworks.</article>","contentLength":1362,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process","url":"https://arxiv.org/abs/2507.01284","date":1751515200,"author":"","guid":182387,"unread":true,"content":"<article>arXiv:2507.01284v1 Announce Type: new \nAbstract: Recent advancements in open-source Visual Language Models (VLMs) such as LLaVA, Qwen-VL, and Llama have catalyzed extensive research on their integration with diverse systems. The internet-scale general knowledge encapsulated within these models presents significant opportunities for enhancing autonomous driving perception, prediction, and planning capabilities. In this paper we propose VLAD, a vision-language autonomous driving model, which integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end system. We implement a specialized fine-tuning approach using custom question-answer datasets designed specifically to improve the spatial reasoning capabilities of the model. The enhanced VLM generates high-level navigational commands that VAD subsequently processes to guide vehicle operation. Additionally, our system produces interpretable natural language explanations of driving decisions, thereby increasing transparency and trustworthiness of the traditionally black-box end-to-end architecture. Comprehensive evaluation on the real-world nuScenes dataset demonstrates that our integrated system reduces average collision rates by 31.82% compared to baseline methodologies, establishing a new benchmark for VLM-augmented autonomous driving systems.</article>","contentLength":1319,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care","url":"https://arxiv.org/abs/2507.01282","date":1751515200,"author":"","guid":182388,"unread":true,"content":"<article>arXiv:2507.01282v1 Announce Type: new \nAbstract: The recent boom of large language models (LLMs) has re-ignited the hope that artificial intelligence (AI) systems could aid medical diagnosis. Yet despite dazzling benchmark scores, LLM assistants have yet to deliver measurable improvements at the bedside. This scoping review aims to highlight the areas where AI is limited to make practical contributions in the clinical setting, specifically in dementia diagnosis and care.\n  Standalone machine-learning models excel at pattern recognition but seldom provide actionable, interpretable guidance, eroding clinician trust. Adjacent use of LLMs by physicians did not result in better diagnostic accuracy or speed. Key limitations trace to the data-driven paradigm: black-box outputs which lack transparency, vulnerability to hallucinations, and weak causal reasoning. Hybrid approaches that combine statistical learning with expert rule-based knowledge, and involve clinicians throughout the process help bring back interpretability. They also fit better with existing clinical workflows, as seen in examples like PEIRS and ATHENA-CDS.\n  Future decision-support should prioritise explanatory coherence by linking predictions to clinically meaningful causes. This can be done through neuro-symbolic or hybrid AI that combines the language ability of LLMs with human causal expertise. AI researchers have addressed this direction, with explainable AI and neuro-symbolic AI being the next logical steps in further advancement in AI. However, they are still based on data-driven knowledge integration instead of human-in-the-loop approaches. Future research should measure success not only by accuracy but by improvements in clinician understanding, workflow fit, and patient outcomes. A better understanding of what helps improve human-computer interactions is greatly needed for AI systems to become part of clinical practice.</article>","contentLength":1922,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization","url":"https://arxiv.org/abs/2507.01281","date":1751515200,"author":"","guid":182389,"unread":true,"content":"<article>arXiv:2507.01281v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating their parametric knowledge with external retrieved content. However, knowledge conflicts caused by internal inconsistencies or noisy retrieved content can severely undermine the generation reliability of RAG systems.In this work, we argue that LLMs should rethink all evidence, including both retrieved content and internal knowledge, before generating responses.We propose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel framework that improves trustworthiness through Conflict-Driven Summarization of all available evidence.CARE-RAG first derives parameter-aware evidence by comparing parameter records to identify diverse internal perspectives. It then refines retrieved evidences to produce context-aware evidence, removing irrelevant or misleading content. To detect and summarize conflicts, we distill a 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable synthesis across multiple sources.To further ensure evaluation integrity, we introduce a QA Repair step to correct outdated or ambiguous benchmark answers.Experiments on revised QA datasets with retrieval data show that CARE-RAG consistently outperforms strong RAG baselines, especially in scenarios with noisy or conflicting evidence.</article>","contentLength":1379,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening","url":"https://arxiv.org/abs/2507.01278","date":1751515200,"author":"","guid":182390,"unread":true,"content":"<article>arXiv:2507.01278v1 Announce Type: new \nAbstract: Large language models (LLMs) can simulate clinical reasoning based on natural language prompts, but their utility in ophthalmology is largely unexplored. This study evaluated GPT-4's ability to interpret structured textual descriptions of retinal fundus photographs and simulate clinical decisions for diabetic retinopathy (DR) and glaucoma screening, including the impact of adding real or synthetic clinical metadata. We conducted a retrospective diagnostic validation study using 300 annotated fundus images. GPT-4 received structured prompts describing each image, with or without patient metadata. The model was tasked with assigning an ICDR severity score, recommending DR referral, and estimating the cup-to-disc ratio for glaucoma referral. Performance was evaluated using accuracy, macro and weighted F1 scores, and Cohen's kappa. McNemar's test and change rate analysis were used to assess the influence of metadata. GPT-4 showed moderate performance for ICDR classification (accuracy 67.5%, macro F1 0.33, weighted F1 0.67, kappa 0.25), driven mainly by correct identification of normal cases. Performance improved in the binary DR referral task (accuracy 82.3%, F1 0.54, kappa 0.44). For glaucoma referral, performance was poor across all settings (accuracy ~78%, F1 &lt;0.04, kappa &lt;0.03). Metadata inclusion did not significantly affect outcomes (McNemar p &gt; 0.05), and predictions remained consistent across conditions. GPT-4 can simulate basic ophthalmic decision-making from structured prompts but lacks precision for complex tasks. While not suitable for clinical use, LLMs may assist in education, documentation, or image annotation workflows in ophthalmology.</article>","contentLength":1725,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing","url":"https://arxiv.org/abs/2507.01275","date":1751515200,"author":"","guid":182391,"unread":true,"content":"<article>arXiv:2507.01275v1 Announce Type: new \nAbstract: Unpaired image dehazing has attracted increasing attention due to its flexible data requirements during model training. Dominant methods based on contrastive learning not only introduce haze-unrelated content information, but also ignore haze-specific properties in the frequency domain (\\ie,~haze-related degradation is mainly manifested in the amplitude spectrum). To address these issues, we propose a novel frequency domain-based diffusion model, named \\ours, for fully exploiting the beneficial knowledge in unpaired clear data. In particular, inspired by the strong generative ability shown by Diffusion Models (DMs), we tackle the dehazing task from the perspective of frequency domain reconstruction and perform the DMs to yield the amplitude spectrum consistent with the distribution of clear images. To implement it, we propose an Amplitude Residual Encoder (ARE) to extract the amplitude residuals, which effectively compensates for the amplitude gap from the hazy to clear domains, as well as provide supervision for the DMs training. In addition, we propose a Phase Correction Module (PCM) to eliminate artifacts by further refining the phase spectrum during dehazing with a simple attention mechanism. Experimental results demonstrate that our \\ours outperforms other state-of-the-art methods on both synthetic and real-world datasets.</article>","contentLength":1398,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance","url":"https://arxiv.org/abs/2507.01274","date":1751515200,"author":"","guid":182392,"unread":true,"content":"<article>arXiv:2507.01274v1 Announce Type: new \nAbstract: Traditional simulator-based training for maritime professionals is critical for ensuring safety at sea but often depends on subjective trainer assessments of technical skills, behavioral focus, communication, and body language, posing challenges such as subjectivity, difficulty in measuring key features, and cognitive limitations. Addressing these issues, this study develops an AI-driven framework to enhance maritime training by objectively assessing trainee performance through visual focus tracking, speech recognition, and stress detection, improving readiness for high-risk scenarios. The system integrates AI techniques, including visual focus determination using eye tracking, pupil dilation analysis, and computer vision; communication analysis through a maritime-specific speech-to-text model and natural language processing; communication correctness using large language models; and mental stress detection via vocal pitch. Models were evaluated on data from simulated maritime scenarios with seafarers exposed to controlled high-stress events. The AI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for maritime speech recognition, and ~90% for stress detection, surpassing existing benchmarks. The system provides insights into visual attention, adherence to communication checklists, and stress levels under demanding conditions. This study demonstrates how AI can transform maritime training by delivering objective performance analytics, enabling personalized feedback, and improving preparedness for real-world operational challenges.</article>","contentLength":1627,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advanced LPeg techniques: A dual case study approach","url":"https://arxiv.org/abs/2507.01272","date":1751515200,"author":"","guid":182393,"unread":true,"content":"<article>arXiv:2507.01272v1 Announce Type: new \nAbstract: This paper presents advanced optimization techniques for Lua Parsing Expression Grammars (LPeg) through two complementary case studies: a high-performance JSON parser and a sophisticated Glob-to-LPeg pattern converter. We demonstrate how strategic grammar construction can dramatically improve parsing performance without modifying the underlying LPeg library. For the JSON parser, we implement substitution capture and table construction optimization to reduce memory allocation overhead and improve object processing. For the Glob converter, we introduce segment-boundary separation, implement Cox's flattened search strategy, and develop optimized braced condition handling to prevent exponential backtracking. Comprehensive benchmarks demonstrate that our JSON parser achieves processing speeds up to 125 MB/s on complex documents, consistently outperforming dkjson and showing competitive results against rxi_json across most test cases. Our Glob-to-LPeg converter exhibits 14-92% better performance than Bun.Glob and runs 3-14 times faster than Minimatch across diverse pattern matching scenarios. This research provides practical optimization techniques for LPeg-based parsers, contributing valuable strategies to the text processing ecosystem.</article>","contentLength":1300,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning","url":"https://arxiv.org/abs/2507.01271","date":1751515200,"author":"","guid":182394,"unread":true,"content":"<article>arXiv:2507.01271v1 Announce Type: new \nAbstract: In recent years, unlearning techniques, which are methods for inducing a model to \"forget\" previously learned information, have attracted attention as a way to address privacy and copyright concerns in large language models (LLMs) and large multimodal models (LMMs). While several unlearning benchmarks have been established for LLMs, a practical evaluation framework for unlearning in LMMs has been less explored. Specifically, existing unlearning benchmark for LMMs considers only scenarios in which the model is required to unlearn fine-tuned knowledge through a single unlearning operation. In this study, we introduce PULSE protocol for realistic unlearning scenarios for LMMs by introducing two critical perspectives: (i) Pre-trained knowledge Unlearning for analyzing the effect across different knowledge acquisition phases and (ii) Long-term Sustainability Evaluation to address sequential requests. We then evaluate existing unlearning methods along these dimensions. Our results reveal that, although some techniques can successfully unlearn knowledge acquired through fine-tuning, they struggle to eliminate information learned during pre-training. Moreover, methods that effectively unlearn a batch of target data in a single operation exhibit substantial performance degradation when the same data are split and unlearned sequentially.</article>","contentLength":1398,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advancements in Weed Mapping: A Systematic Review","url":"https://arxiv.org/abs/2507.01269","date":1751515200,"author":"","guid":182395,"unread":true,"content":"<article>arXiv:2507.01269v1 Announce Type: new \nAbstract: Weed mapping plays a critical role in precision management by providing accurate and timely data on weed distribution, enabling targeted control and reduced herbicide use. This minimizes environmental impacts, supports sustainable land management, and improves outcomes across agricultural and natural environments. Recent advances in weed mapping leverage ground-vehicle Red Green Blue (RGB) cameras, satellite and drone-based remote sensing combined with sensors such as spectral, Near Infra-Red (NIR), and thermal cameras. The resulting data are processed using advanced techniques including big data analytics and machine learning, significantly improving the spatial and temporal resolution of weed maps and enabling site-specific management decisions. Despite a growing body of research in this domain, there is a lack of comprehensive literature reviews specifically focused on weed mapping. In particular, the absence of a structured analysis spanning the entire mapping pipeline, from data acquisition to processing techniques and mapping tools, limits progress in the field. This review addresses these gaps by systematically examining state-of-the-art methods in data acquisition (sensor and platform technologies), data processing (including annotation and modelling), and mapping techniques (such as spatiotemporal analysis and decision support tools). Following PRISMA guidelines, we critically evaluate and synthesize key findings from the literature to provide a holistic understanding of the weed mapping landscape. This review serves as a foundational reference to guide future research and support the development of efficient, scalable, and sustainable weed management systems.</article>","contentLength":1746,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Counterfactual Explanation of Shapley Value in Data Coalitions","url":"https://arxiv.org/abs/2507.01267","date":1751515200,"author":"","guid":182396,"unread":true,"content":"<article>arXiv:2507.01267v1 Announce Type: new \nAbstract: The Shapley value is widely used for data valuation in data markets. However, explaining the Shapley value of an owner in a data coalition is an unexplored and challenging task. To tackle this, we formulate the problem of finding the counterfactual explanation of Shapley value in data coalitions. Essentially, given two data owners $A$ and $B$ such that $A$ has a higher Shapley value than $B$, a counterfactual explanation is a smallest subset of data entries in $A$ such that transferring the subset from $A$ to $B$ makes the Shapley value of $A$ less than that of $B$. We show that counterfactual explanations always exist, but finding an exact counterfactual explanation is NP-hard. Using Monte Carlo estimation to approximate counterfactual explanations directly according to the definition is still very costly, since we have to estimate the Shapley values of owners $A$ and $B$ after each possible subset shift. We develop a series of heuristic techniques to speed up computation by estimating differential Shapley values, computing the power of singular data entries, and shifting subsets greedily, culminating in the SV-Exp algorithm. Our experimental results on real datasets clearly demonstrate the efficiency of our method and the effectiveness of counterfactuals in interpreting the Shapley value of an owner.</article>","contentLength":1372,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LLM-based Realistic Safety-Critical Driving Video Generation","url":"https://arxiv.org/abs/2507.01264","date":1751515200,"author":"","guid":182397,"unread":true,"content":"<article>arXiv:2507.01264v1 Announce Type: new \nAbstract: Designing diverse and safety-critical driving scenarios is essential for evaluating autonomous driving systems. In this paper, we propose a novel framework that leverages Large Language Models (LLMs) for few-shot code generation to automatically synthesize driving scenarios within the CARLA simulator, which has flexibility in scenario scripting, efficient code-based control of traffic participants, and enforcement of realistic physical dynamics. Given a few example prompts and code samples, the LLM generates safety-critical scenario scripts that specify the behavior and placement of traffic participants, with a particular focus on collision events. To bridge the gap between simulation and real-world appearance, we integrate a video generation pipeline using Cosmos-Transfer1 with ControlNet, which converts rendered scenes into realistic driving videos. Our approach enables controllable scenario generation and facilitates the creation of rare but critical edge cases, such as pedestrian crossings under occlusion or sudden vehicle cut-ins. Experimental results demonstrate the effectiveness of our method in generating a wide range of realistic, diverse, and safety-critical scenarios, offering a promising tool for simulation-based testing of autonomous vehicles.</article>","contentLength":1325,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant","url":"https://arxiv.org/abs/2507.01259","date":1751515200,"author":"","guid":182398,"unread":true,"content":"<article>arXiv:2507.01259v1 Announce Type: new \nAbstract: In this paper we discuss the capability of large language models to base their answer and provide proper references when dealing with legal matters of non-english and non-chinese speaking country. We discuss the history of legal information retrieval, the difference between case law and statute law, its impact on the legal tasks and analyze the latest research in this field. Basing on that background we introduce gAIus, the architecture of the cognitive LLM-based agent, whose responses are based on the knowledge retrieved from certain legal act, which is Polish Civil Code. We propose a retrieval mechanism which is more explainable, human-friendly and achieves better results than embedding-based approaches. To evaluate our method we create special dataset based on single-choice questions from entrance exams for law apprenticeships conducted in Poland. The proposed architecture critically leveraged the abilities of used large language models, improving the gpt-3.5-turbo-0125 by 419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%. At the end of our paper we show the possible future path of research and potential applications of our findings.</article>","contentLength":1232,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation","url":"https://arxiv.org/abs/2507.01255","date":1751515200,"author":"","guid":182399,"unread":true,"content":"<article>arXiv:2507.01255v1 Announce Type: new \nAbstract: The rapid advancement of AI-generated video models has created a pressing need for robust and interpretable evaluation frameworks. Existing metrics are limited to producing numerical scores without explanatory comments, resulting in low interpretability and human evaluation alignment. To address those challenges, we introduce AIGVE-MACS, a unified model for AI-Generated Video Evaluation(AIGVE), which can provide not only numerical scores but also multi-aspect language comment feedback in evaluating these generated videos. Central to our approach is AIGVE-BENCH 2, a large-scale benchmark comprising 2,500 AI-generated videos and 22,500 human-annotated detailed comments and numerical scores across nine critical evaluation aspects. Leveraging AIGVE-BENCH 2, AIGVE-MACS incorporates recent Vision-Language Models with a novel token-wise weighted loss and a dynamic frame sampling strategy to better align with human evaluators. Comprehensive experiments across supervised and zero-shot benchmarks demonstrate that AIGVE-MACS achieves state-of-the-art performance in both scoring correlation and comment quality, significantly outperforming prior baselines including GPT-4o and VideoScore. In addition, we further showcase a multi-agent refinement framework where feedback from AIGVE-MACS drives iterative improvements in video generation, leading to 53.5% quality enhancement. This work establishes a new paradigm for comprehensive, human-aligned evaluation of AI-generated videos. We release the AIGVE-BENCH 2 and AIGVE-MACS at https://huggingface.co/xiaoliux/AIGVE-MACS.</article>","contentLength":1626,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Robust Brain Tumor Segmentation with Incomplete MRI Modalities Using H\\\"older Divergence and Mutual Information-Enhanced Knowledge Transfer","url":"https://arxiv.org/abs/2507.01254","date":1751515200,"author":"","guid":182400,"unread":true,"content":"<article>arXiv:2507.01254v1 Announce Type: new \nAbstract: Multimodal MRI provides critical complementary information for accurate brain tumor segmentation. However, conventional methods struggle when certain modalities are missing due to issues such as image quality, protocol inconsistencies, patient allergies, or financial constraints. To address this, we propose a robust single-modality parallel processing framework that achieves high segmentation accuracy even with incomplete modalities. Leveraging Holder divergence and mutual information, our model maintains modality-specific features while dynamically adjusting network parameters based on the available inputs. By using these divergence- and information-based loss functions, the framework effectively quantifies discrepancies between predictions and ground-truth labels, resulting in consistently accurate segmentation. Extensive evaluations on the BraTS 2018 and BraTS 2020 datasets demonstrate superior performance over existing methods in handling missing modalities.</article>","contentLength":1025,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tunnelling Through Time Series: A Probabilistic Visibility Graph for Local and Global Pattern Discovery","url":"https://arxiv.org/abs/2507.01247","date":1751515200,"author":"","guid":182401,"unread":true,"content":"<article>arXiv:2507.01247v1 Announce Type: new \nAbstract: The growing availability of high-resolution, long-term time series data has highlighted the need for methods capable of capturing both local and global patterns. To address this, we introduce the Probabilistic Visibility Graph (PVG), a novel approach inspired by the quantum tunnelling phenomenon. The PVG extends the classical Visibility Graph (VG) by introducing probabilistic connections between time points that are obstructed in the VG due to intermediate values. We demonstrate the PVG's effectiveness in capturing long-range dependencies through simulations of amplitude-modulated signals and analysis of electrocorticography (ECoG) data under rest and anesthesia conditions. Key results show that the PVG presents distinct network properties between rest and anesthesia, with rest exhibiting stronger small-worldness and scale-free behavior, reflecting a hub-dominated, centralized connectivity structure, compared to anesthesia. These findings highlight the PVG's potential for analyzing complex signals with interacting temporal scales, offering new insights into neural dynamics and other real-world phenomena.</article>","contentLength":1170,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A fourth-order exponential time differencing scheme with real and distinct poles rational approximation for solving non-linear reaction-diffusion systems","url":"https://arxiv.org/abs/2507.01245","date":1751515200,"author":"","guid":182402,"unread":true,"content":"<article>arXiv:2507.01245v1 Announce Type: new \nAbstract: A fourth-order, L-stable, exponential time differencing Runge-Kutta type scheme is developed to solve nonlinear systems of reaction diffusion equations with nonsmooth data. The new scheme, ETDRK4RDP, is constructed by approximating the matrix exponentials in the ETDRK4 scheme with a fourth order, L-acceptable, non-Pad\\'e rational function having real and distinct poles (RDP). Using RDP rational functions to construct the scheme ensures efficient damping of spurious oscillations arising from non-smooth initial and boundary conditions and a straightforward parallelization. We verify empirically that the new ETDRK4RDP scheme is fourth-order accurate for several reaction diffusion systems with Dirichlet and Neumann boundary conditions and show it to be more efficient than competing exponential time differencing schemes, especially when implemented in parallel, with up to six times speedup in CPU time.</article>","contentLength":959,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Jump-Start Reinforcement Learning with Self-Evolving Priors for Extreme Monopedal Locomotion","url":"https://arxiv.org/abs/2507.01243","date":1751515200,"author":"","guid":182403,"unread":true,"content":"<article>arXiv:2507.01243v1 Announce Type: new \nAbstract: Reinforcement learning (RL) has shown great potential in enabling quadruped robots to perform agile locomotion. However, directly training policies to simultaneously handle dual extreme challenges, i.e., extreme underactuation and extreme terrains, as in monopedal hopping tasks, remains highly challenging due to unstable early-stage interactions and unreliable reward feedback. To address this, we propose JumpER (jump-start reinforcement learning via self-evolving priors), an RL training framework that structures policy learning into multiple stages of increasing complexity. By dynamically generating self-evolving priors through iterative bootstrapping of previously learned policies, JumpER progressively refines and enhances guidance, thereby stabilizing exploration and policy optimization without relying on external expert priors or handcrafted reward shaping. Specifically, when integrated with a structured three-stage curriculum that incrementally evolves action modality, observation space, and task objective, JumpER enables quadruped robots to achieve robust monopedal hopping on unpredictable terrains for the first time. Remarkably, the resulting policy effectively handles challenging scenarios that traditional methods struggle to conquer, including wide gaps up to 60 cm, irregularly spaced stairs, and stepping stones with distances varying from 15 cm to 35 cm. JumpER thus provides a principled and scalable approach for addressing locomotion tasks under the dual challenges of extreme underactuation and extreme terrains.</article>","contentLength":1596,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradients and AdamW","url":"https://arxiv.org/abs/2507.01241","date":1751515200,"author":"","guid":182404,"unread":true,"content":"<article>arXiv:2507.01241v1 Announce Type: new \nAbstract: Stochastic gradient-based descent (SGD), have long been central to training large language models (LLMs). However, their effectiveness is increasingly being questioned, particularly in large-scale applications where empirical evidence suggests potential performance limitations. In response, this paper proposes a stochastic conjugate subgradient method together with adaptive sampling tailored specifically for training LLMs. The method not only achieves faster convergence per iteration but also demonstrates improved scalability compared to traditional SGD techniques. It leverages sample complexity analysis to adaptively choose the sample size, employs a stochastic conjugate subgradient approach to determine search directions and utilizing an AdamW-like algorithm to adaptively adjust step sizes. This approach preserves the key advantages of first-order methods while effectively addressing the nonconvexity and non-smoothness inherent in LLMs training. Additionally, we provide a detailed analysis of the advantage of the algorithm. Experimental results show that the proposed method not only maintains, but in many cases surpasses, the scalability of traditional SGD techniques, significantly enhancing both the speed and accuracy of the optimization process.</article>","contentLength":1318,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Full-Stack Platform Architecture for Self-Organised Social Coordination","url":"https://arxiv.org/abs/2507.01239","date":1751515200,"author":"","guid":182405,"unread":true,"content":"<article>arXiv:2507.01239v1 Announce Type: new \nAbstract: To mitigate the restrictive centralising and monopolistic tendencies of platformisation, we aim to empower local communities by democratising platforms for self-organised social coordination. Our approach is to develop an open-source, full-stack architecture for platform development that supports ease of distribution and cloning, generativity, and a variety of hosting options. The architecture consists of a meta-platform that is used to instantiate a base platform with supporting libraries for generic functions, and plugins (intended to be supplied by third parties) for customisation of application-specification functionality for self-organised social coordination. Associated developer- and user-oriented toolchains support the instantiation and customisation of a platform in a two-stage process. This is demonstrated through the proof-of-concept implementation of two case studies: a platform for regular sporting association, and a platform for collective group study. We conclude by arguing that self-organisation at the application layer can be achieved by the specific supporting functionality of a full-stack architecture with complimentary developer and user toolchains.</article>","contentLength":1236,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quantum Machine Learning in Transportation: A Case Study of Pedestrian Stress Modelling","url":"https://arxiv.org/abs/2507.01235","date":1751515200,"author":"","guid":182406,"unread":true,"content":"<article>arXiv:2507.01235v1 Announce Type: new \nAbstract: Quantum computing has opened new opportunities to tackle complex machine learning tasks, for instance, high-dimensional data representations commonly required in intelligent transportation systems. We explore quantum machine learning to model complex skin conductance response (SCR) events that reflect pedestrian stress in a virtual reality road crossing experiment. For this purpose, Quantum Support Vector Machine (QSVM) with an eight-qubit ZZ feature map and a Quantum Neural Network (QNN) using a Tree Tensor Network ansatz and an eight-qubit ZZ feature map, were developed on Pennylane. The dataset consists of SCR measurements along with features such as the response amplitude and elapsed time, which have been categorized into amplitude-based classes. The QSVM achieved good training accuracy, but had an overfitting problem, showing a low test accuracy of 45% and therefore impacting the reliability of the classification model. The QNN model reached a higher test accuracy of 55%, making it a better classification model than the QSVM and the classic versions.</article>","contentLength":1120,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Medium Is Not the Message: Deconfounding Text Embeddings via Linear Concept Erasure","url":"https://arxiv.org/abs/2507.01234","date":1751515200,"author":"","guid":182407,"unread":true,"content":"<article>arXiv:2507.01234v1 Announce Type: new \nAbstract: Embedding-based similarity metrics between text sequences can be influenced not just by the content dimensions we most care about, but can also be biased by spurious attributes like the text's source or language. These document confounders cause problems for many applications, but especially those that need to pool texts from different corpora. This paper shows that a debiasing algorithm that removes information about observed confounders from the encoder representations substantially reduces these biases at a minimal computational cost. Document similarity and clustering metrics improve across every embedding variant and task we evaluate -- often dramatically. Interestingly, performance on out-of-distribution benchmarks is not impacted, indicating that the embeddings are not otherwise degraded.</article>","contentLength":855,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rethinking the Illusion of Thinking","url":"https://arxiv.org/abs/2507.01231","date":1751515200,"author":"","guid":182408,"unread":true,"content":"<article>arXiv:2507.01231v1 Announce Type: new \nAbstract: Earlier this year, Apple ignited controversy by publishing \"The Illusion of Thinking,\" prompting heated debate within the AI community. Critics seized upon the findings as conclusive evidence that Large Reasoning Models (LRMs) lack genuine reasoning capabilities, branding them as mere stochastic parrots. Meanwhile, defenders-spearheaded by Lawsen et al. (2025)-fired back, condemning the experimental setup as flawed and the conclusions overstated. We clarify this debate by replicating and refining two of the original study's most contentious benchmarks: Towers of Hanoi and River Crossing. By introducing incremental stepwise prompting and agentic collaborative dialogue, we show that previously reported failures solving the Towers of Hanoi were not purely result of output constraints, but also partly a result of cognition limitations: LRMs still stumble when complexity rises moderately (around 8 disks). Moreover, the River Crossing results initially heralded as catastrophic failures turn out to hinge upon testing unsolvable configurations. Once we limit tests strictly to solvable problems-LRMs effortlessly solve large instances involving over 100 agent pairs. Our findings ultimately defy simplistic narratives: today's LRMs are stochastic, RL-tuned searchers in a discrete state space we barely understand. Real progress in symbolic, long-horizon reasoning demands mapping that terrain through fine-grained ablations like those introduced here.</article>","contentLength":1509,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The hunt for research data: Development of an open-source workflow for tracking institutionally-affiliated research data publications","url":"https://arxiv.org/abs/2507.01228","date":1751515200,"author":"","guid":182409,"unread":true,"content":"<article>arXiv:2507.01228v1 Announce Type: new \nAbstract: The ability to find data is central to the FAIR principles underlying research data stewardship. As with the ability to reuse data, efforts to ensure and enhance findability have historically focused on discoverability of data by other researchers, but there is a growing recognition of the importance of stewarding data in a fashion that makes them FAIR for a wide range of potential reusers and stakeholders. Research institutions are one such stakeholder and have a range of motivations for discovering data, specifically those affiliated with a focal institution, from facilitating compliance with funder provisions to gathering data to inform research data services. However, many research datasets and repositories are not optimized for institutional discovery (e.g., not recording or standardizing affiliation metadata), which creates downstream obstacles to workflows designed for theoretically comprehensive discovery and to metadata-conscious data generators. Here I describe an open-source workflow for institutional tracking of research datasets at the University of Texas at Austin. This workflow comprises a multi-faceted approach that utilizes multiple open application programming interfaces (APIs) in order to address some of the common challenges to institutional discovery, such as variation in whether affiliation metadata are recorded or made public, and if so, how metadata are standardized, structured, and recorded. It is presently able to retrieve more than 4,000 affiliated datasets across nearly 70 distinct platforms, including objects without DOIs and objects without affiliation metadata. However, there remain major gaps that stem from suboptimal practices of both researchers and data repositories, many of which were identified in previous studies and which persist despite significant investment in efforts to standardize and elevate the quality of datasets and their metadata.</article>","contentLength":1960,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Capacity Planning and Scheduling for Jobs with Uncertainty in Resource Usage and Duration","url":"https://arxiv.org/abs/2507.01225","date":1751515200,"author":"","guid":182410,"unread":true,"content":"<article>arXiv:2507.01225v1 Announce Type: new \nAbstract: Organizations around the world schedule jobs (programs) regularly to perform various tasks dictated by their end users. With the major movement towards using a cloud computing infrastructure, our organization follows a hybrid approach with both cloud and on-prem servers. The objective of this work is to perform capacity planning, i.e., estimate resource requirements, and job scheduling for on-prem grid computing environments. A key contribution of our approach is handling uncertainty in both resource usage and duration of the jobs, a critical aspect in the finance industry where stochastic market conditions significantly influence job characteristics. For capacity planning and scheduling, we simultaneously balance two conflicting objectives: (a) minimize resource usage, and (b) provide high quality-of-service to the end users by completing jobs by their requested deadlines. We propose approximate approaches using deterministic estimators and pair sampling-based constraint programming. Our best approach (pair sampling-based) achieves much lower peak resource usage compared to manual scheduling without compromising on the quality-of-service.</article>","contentLength":1206,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FLARE: A Dataflow-Aware and Scalable Hardware Architecture for Neural-Hybrid Scientific Lossy Compression","url":"https://arxiv.org/abs/2507.01224","date":1751515200,"author":"","guid":182411,"unread":true,"content":"<article>arXiv:2507.01224v1 Announce Type: new \nAbstract: Scientific simulation leveraging high-performance computing (HPC) systems is crucial for modeling complex systems and phenomena in fields such as astrophysics, climate science, and fluid dynamics, generating massive datasets that often reach petabyte to exabyte scales. However, managing these vast data volumes introduces significant I/O and network bottlenecks, limiting practical performance and scalability. While cutting-edge lossy compression frameworks powered by deep neural networks (DNNs) have demonstrated superior compression ratios by capturing complex data correlations, their integration into HPC workflows poses substantial challenges due to the hybrid non-neural and neural computation patterns, causing excessive memory access overhead, large sequential stalls, and limited adaptability to varying data sizes and workloads in existing hardware platforms. To overcome these challenges and push the limit of high-performance scientific computing, we for the first time propose FLARE, a dataflow-aware and scalable hardware architecture for neural-hybrid scientific lossy compression. FLARE minimizes off-chip data access, reduces bubble overhead through efficient dataflow, and adopts a modular design that provides both scalability and flexibility, significantly enhancing throughput and energy efficiency on modern HPC systems. Particularly, the proposed FLARE achieves runtime speedups ranging from $3.50 \\times$ to $96.07 \\times$, and energy efficiency improvements ranging from $24.51 \\times$ to $520.68 \\times$, across various datasets and hardware platforms.</article>","contentLength":1630,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PAE MobiLLM: Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning","url":"https://arxiv.org/abs/2507.01216","date":1751515200,"author":"","guid":182412,"unread":true,"content":"<article>arXiv:2507.01216v1 Announce Type: new \nAbstract: There is a huge gap between numerous intriguing applications fostered by on-device large language model (LLM) fine-tuning (FT) from fresh mobile data and the limited resources of a mobile device. While existing server-assisted methods (e.g., split learning or side-tuning) may enable LLM FT on the local mobile device, they suffer from heavy communication burdens of activation transmissions, and may disclose data, labels or fine-tuned models to the server. To address those issues, we develop PAE MobiLLM, a privacy-aware and efficient LLM FT method which can be deployed on the mobile device via server-assisted additive side-tuning. To further accelerate FT convergence and improve computing efficiency, PAE MobiLLM integrates activation caching on the server side, which allows the server to reuse historical activations and saves the mobile device from repeatedly computing forward passes for the recurring data samples. Besides, to reduce communication cost, PAE MobiLLM develops a one-token (i.e., ``pivot'' token) activation shortcut that transmits only a single activation dimension instead of full activation matrices to guide the side network tuning. Last but not least, PAE MobiLLM introduces the additive adapter side-network design which makes the server train the adapter modules based on device-defined prediction differences rather than raw ground-truth labels. In this way, the server can only assist device-defined side-network computing, and learn nothing about data, labels or fine-tuned models.</article>","contentLength":1566,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MEGA: xLSTM with Multihead Exponential Gated Fusion for Precise Aspect-based Sentiment Analysis","url":"https://arxiv.org/abs/2507.01213","date":1751515200,"author":"","guid":182413,"unread":true,"content":"<article>arXiv:2507.01213v1 Announce Type: new \nAbstract: Aspect-based Sentiment Analysis (ABSA) is a critical Natural Language Processing (NLP) task that extracts aspects from text and determines their associated sentiments, enabling fine-grained analysis of user opinions. Existing ABSA methods struggle to balance computational efficiency with high performance: deep learning models often lack global context, transformers demand significant computational resources, and Mamba-based approaches face CUDA dependency and diminished local correlations. Recent advancements in Extended Long Short-Term Memory (xLSTM) models, particularly their efficient modeling of long-range dependencies, have significantly advanced the NLP community. However, their potential in ABSA remains untapped. To this end, we propose xLSTM with Multihead Exponential Gated Fusion (MEGA), a novel framework integrating a bi-directional mLSTM architecture with forward and partially flipped backward (PF-mLSTM) streams. The PF-mLSTM enhances localized context modeling by processing the initial sequence segment in reverse with dedicated parameters, preserving critical short-range patterns. We further introduce an mLSTM-based multihead cross exponential gated fusion mechanism (MECGAF) that dynamically combines forward mLSTM outputs as query and key with PF-mLSTM outputs as value, optimizing short-range dependency capture while maintaining global context and efficiency. Experimental results on three benchmark datasets demonstrate that MEGA outperforms state-of-the-art baselines, achieving superior accuracy and efficiency in ABSA tasks.</article>","contentLength":1611,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Teaching Cars to Drive: Spotlight on Connected and Automated Vehicles","url":"https://arxiv.org/abs/2507.01211","date":1751515200,"author":"","guid":182414,"unread":true,"content":"<article>arXiv:2507.01211v1 Announce Type: new \nAbstract: In recent decades, society has witnessed significant advancements in emerging mobility systems. These systems refer to transportation solutions that incorporate digital technologies, automation, connectivity, and sustainability to create safer, more efficient, and user-centered mobility. Examples include connected and automated vehicles (CAVs), shared mobility services (car-pooling), electric vehicles, and mobility-as-a-service platforms. These innovations have the potential to greatly impact areas such as safety, pollution, comfort, travel time, and fairness. In this article, we explore the current landscape of CAVs. We discuss their role in daily life and their future potential, while also addressing the challenges they may introduce. Following, we also examine the practical difficulties in research associated with CAVs especially simulating and testing CAV-related algorithms in real-world settings. We present existing solutions that aim to overcome these limitations. Finally, we provide an accessible introduction to modeling CAVs using basic kinematic principles and offer an open-source tutorial to help interested students begin exploring the field.</article>","contentLength":1219,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Judgment as Coordination: A Joint Systems View of Visualization Design Practice","url":"https://arxiv.org/abs/2507.01209","date":1751515200,"author":"","guid":182415,"unread":true,"content":"<article>arXiv:2507.01209v1 Announce Type: new \nAbstract: Professional visualization design has become an increasingly important area of inquiry, yet much of the field's discourse remains anchored in researcher-centered contexts. Studies of design practice often focus on individual designers' decisions and reflections, offering limited insight into the collaborative and systemic dimensions of professional work. In this paper, we propose a systems-level reframing of design judgment grounded in the coordination and adaptation that sustain progress amid uncertainty, constraint, and misalignment. Drawing on sustained engagement across multiple empirical studies--including ethnographic observation of design teams and qualitative studies of individual practitioners--we identify recurring episodes in which coherence was preserved not by selecting an optimal option, but by repairing alignment, adjusting plans, and reframing goals. We interpret these dynamics through the lens of Joint Cognitive Systems, which provide tools for analyzing how judgment emerges as a distributed capacity within sociotechnical activity. This perspective surfaces often-invisible work in visualization design and offers researchers a new conceptual vocabulary for studying how design activity is sustained in practice.</article>","contentLength":1294,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Deep Learning-Based Intrusion Detection for Automotive Ethernet: Evaluating & Optimizing Fast Inference Techniques for Deployment on Low-Cost Platform","url":"https://arxiv.org/abs/2507.01208","date":1751515200,"author":"","guid":182416,"unread":true,"content":"<article>arXiv:2507.01208v1 Announce Type: new \nAbstract: Modern vehicles are increasingly connected, and in this context, automotive Ethernet is one of the technologies that promise to provide the necessary infrastructure for intra-vehicle communication. However, these systems are subject to attacks that can compromise safety, including flow injection attacks. Deep Learning-based Intrusion Detection Systems (IDS) are often designed to combat this problem, but they require expensive hardware to run in real time. In this work, we propose to evaluate and apply fast neural network inference techniques like Distilling and Prunning for deploying IDS models on low-cost platforms in real time. The results show that these techniques can achieve intrusion detection times of up to 727 {\\mu}s using a Raspberry Pi 4, with AUCROC values of 0.9890.</article>","contentLength":837,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On the Intensity-based Inversion Method for Quantitative Quasi-Static Elastography","url":"https://arxiv.org/abs/2507.01207","date":1751515200,"author":"","guid":182417,"unread":true,"content":"<article>arXiv:2507.01207v1 Announce Type: new \nAbstract: In this paper, we consider the intensity-based inversion method (IIM) for quantitative material parameter estimation in quasi-static elastography. In particular, we consider the problem of estimating the material parameters of a given sample from two internal measurements, one obtained before and one after applying some form of deformation. These internal measurements can be obtained via any imaging modality of choice, for example ultrasound, optical coherence or photo-acoustic tomography. Compared to two-step approaches to elastography, which first estimate internal displacement fields or strains and then reconstruct the material parameters from them, the IIM is a one-step approach which computes the material parameters directly from the internal measurements. To do so, the IIM combines image registration together with a model-based, regularized parameter reconstruction approach. This combination has the advantage of avoiding some approximations and derivative computations typically found in two-step approaches, and results in the IIM being generally more stable to measurement noise. In the paper, we provide a full convergence analysis of the IIM within the framework of inverse problems, and detail its application to linear elastography. Furthermore, we discuss the numerical implementation of the IIM and provide numerical examples simulating an optical coherence elastography (OCE) experiment.</article>","contentLength":1465,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"2024 NASA SUITS Report: LLM-Driven Immersive Augmented Reality User Interface for Robotics and Space Exploration","url":"https://arxiv.org/abs/2507.01206","date":1751515200,"author":"","guid":182418,"unread":true,"content":"<article>arXiv:2507.01206v1 Announce Type: new \nAbstract: As modern computing advances, new interaction paradigms have emerged, particularly in Augmented Reality (AR), which overlays virtual interfaces onto physical objects. This evolution poses challenges in machine perception, especially for tasks like 3D object pose estimation in complex, dynamic environments. Our project addresses critical issues in human-robot interaction within mobile AR, focusing on non-intrusive, spatially aware interfaces. We present URSA, an LLM-driven immersive AR system developed for NASA's 2023-2024 SUITS challenge, targeting future spaceflight needs such as the Artemis missions. URSA integrates three core technologies: a head-mounted AR device (e.g., HoloLens) for intuitive visual feedback, voice control powered by large language models for hands-free interaction, and robot tracking algorithms that enable accurate 3D localization in dynamic settings. To enhance precision, we leverage digital twin localization technologies, using datasets like DTTD-Mobile and specialized hardware such as the ZED2 camera for real-world tracking under noise and occlusion. Our system enables real-time robot control and monitoring via an AR interface, even in the absence of ground-truth sensors--vital for hazardous or remote operations. Key contributions include: (1) a non-intrusive AR interface with LLM-based voice input; (2) a ZED2-based dataset tailored for non-rigid robotic bodies; (3) a Local Mission Control Console (LMCC) for mission visualization; (4) a transformer-based 6DoF pose estimator (DTTDNet) optimized for depth fusion and real-time tracking; and (5) end-to-end integration for astronaut mission support. This work advances digital twin applications in robotics, offering scalable solutions for both aerospace and industrial domains.</article>","contentLength":1825,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models","url":"https://arxiv.org/abs/2507.01201","date":1751515200,"author":"","guid":182419,"unread":true,"content":"<article>arXiv:2507.01201v1 Announce Type: new \nAbstract: Independently trained vision and language models inhabit disjoint representational spaces, shaped by their respective modalities, objectives, and architectures. Yet an emerging hypothesis - the Platonic Representation Hypothesis - suggests that such models may nonetheless converge toward a shared statistical model of reality. This compatibility, if it exists, raises a fundamental question: can we move beyond post-hoc statistical detection of alignment and explicitly optimize for it between such disjoint representations? We cast this Platonic alignment problem as a multi-objective optimization task - preserve each modality's native structure while aligning for mutual coherence. We introduce the Joint Autoencoder Modulator (JAM) framework that jointly trains modality-specific autoencoders on the latent representations of pre-trained single modality models, encouraging alignment through both reconstruction and cross-modal objectives. By analogy, this framework serves as a method to escape Plato's Cave, enabling the emergence of shared structure from disjoint inputs. We evaluate this framework across three critical design axes: (i) the alignment objective - comparing contrastive loss (Con), its hard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at which alignment is most effective, and (iii) the impact of foundation model scale on representational convergence. Our findings show that our lightweight Pareto-efficient framework reliably induces alignment, even across frozen, independently trained representations, offering both theoretical insight and practical pathways for transforming generalist unimodal foundations into specialist multimodal models.</article>","contentLength":1744,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives","url":"https://arxiv.org/abs/2507.01198","date":1751515200,"author":"","guid":182420,"unread":true,"content":"<article>arXiv:2507.01198v1 Announce Type: new \nAbstract: This work proposes a motion planning algorithm for robotic manipulators that combines sampling-based and search-based planning methods. The core contribution of the proposed approach is the usage of burs of free configuration space (C-space) as adaptive motion primitives within the graph search algorithm. Due to their feature to adaptively expand in free C-space, burs enable more efficient exploration of the configuration space compared to fixed-sized motion primitives, significantly reducing the time to find a valid path and the number of required expansions. The algorithm is implemented within the existing SMPL (Search-Based Motion Planning Library) library and evaluated through a series of different scenarios involving manipulators with varying number of degrees-of-freedom (DoF) and environment complexity. Results demonstrate that the bur-based approach outperforms fixed-primitive planning in complex scenarios, particularly for high DoF manipulators, while achieving comparable performance in simpler scenarios.</article>","contentLength":1077,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Spectral-Based Tuning Criterion for PI Controllers in IPDT Systems With Unified Tracking and Disturbance Rejection Performance","url":"https://arxiv.org/abs/2507.01197","date":1751515200,"author":"","guid":182421,"unread":true,"content":"<article>arXiv:2507.01197v1 Announce Type: new \nAbstract: This paper proposes a spectral-based tuning method for proportional-integral (PI) controllers in integrating-plus-dead-time (IPDT) systems. The design objective is to achieve unified exponential decay for both reference tracking and disturbance rejection by minimizing the spectral abscissa of the closed-loop system. A second-order semi-discrete model accurately captures the integrator and delay dynamics while enabling efficient dominant pole extraction. These discrete-time poles are mapped to continuous time and refined using Newton-Raphson iterations on the exact transcendental characteristic equation. The method produces a unique PI gain set without requiring heuristic trade-offs or weighting parameters. Comparative simulations demonstrate that the proposed tuning achieves faster convergence and improved robustness margins compared to classical rules (Ziegler-Nichols, SIMC) and integral performance criteria (IAE, ITAE). The approach provides a transparent and computationally efficient framework for PI control in delay-dominant systems.</article>","contentLength":1102,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning","url":"https://arxiv.org/abs/2507.01196","date":1751515200,"author":"","guid":182422,"unread":true,"content":"<article>arXiv:2507.01196v1 Announce Type: new \nAbstract: Foundation Models have demonstrated significant success across various domains in Artificial Intelligence (AI), yet their capabilities for brainwave modeling remain unclear. In this paper, we comprehensively evaluate current Large Brainwave Foundation Models (LBMs) through systematic fine-tuning experiments across multiple Brain-Computer Interface (BCI) benchmark tasks, including memory tasks and sleep stage classification. Our extensive analysis shows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%) over traditional deep architectures while requiring significantly more parameters (millions vs thousands), raising important questions about their efficiency and applicability in BCI contexts. Moreover, through detailed ablation studies and Low-Rank Adaptation (LoRA), we significantly reduce trainable parameters without performance degradation, while demonstrating that architectural and training inefficiencies limit LBMs' current capabilities. Our experiments span both full model fine-tuning and parameter-efficient adaptation techniques, providing insights into optimal training strategies for BCI applications. We pioneer the application of LoRA to LBMs, revealing that performance benefits generally emerge when adapting multiple neural network components simultaneously. These findings highlight the critical need for domain-specific development strategies to advance LBMs, suggesting that current architectures may require redesign to fully leverage the potential of foundation models in brainwave analysis.</article>","contentLength":1597,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PCPP-Based Reconfiguration Inapproximability: Query Complexity vs. Soundness Gap Trade-offs","url":"https://arxiv.org/abs/2507.01192","date":1751515200,"author":"","guid":182423,"unread":true,"content":"<article>arXiv:2507.01192v1 Announce Type: new \nAbstract: The Reconfiguration Inapproximability Hypothesis (RIH), recently established by Hirahara-Ohsaka (STOC'24) and Karthik-Manurangsi (ECCC'24), studies the hardness of reconfiguring one solution into another in constraint satisfaction problems (CSP) when restricted to approximate intermediate solutions. In this work, we make a tighter connection between RIH's soundness gap and that of probabilistically checkable proofs of proximity (PCPP). Consequently, we achieve an improved trade-off between soundness and query complexity in Gap CSP Reconfiguration. Our approach leverages a parallelization framework, which also appears in some recent parameterized inapproximability results.</article>","contentLength":729,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rapid Salient Object Detection with Difference Convolutional Neural Networks","url":"https://arxiv.org/abs/2507.01182","date":1751515200,"author":"","guid":182424,"unread":true,"content":"<article>arXiv:2507.01182v1 Announce Type: new \nAbstract: This paper addresses the challenge of deploying salient object detection (SOD) on resource-constrained devices with real-time performance. While recent advances in deep neural networks have improved SOD, existing top-leading models are computationally expensive. We propose an efficient network design that combines traditional wisdom on SOD and the representation power of modern CNNs. Like biologically-inspired classical SOD methods relying on computing contrast cues to determine saliency of image regions, our model leverages Pixel Difference Convolutions (PDCs) to encode the feature contrasts. Differently, PDCs are incorporated in a CNN architecture so that the valuable contrast cues are extracted from rich feature maps. For efficiency, we introduce a difference convolution reparameterization (DCR) strategy that embeds PDCs into standard convolutions, eliminating computation and parameters at inference. Additionally, we introduce SpatioTemporal Difference Convolution (STDC) for video SOD, enhancing the standard 3D convolution with spatiotemporal contrast capture. Our models, SDNet for image SOD and STDNet for video SOD, achieve significant improvements in efficiency-accuracy trade-offs. On a Jetson Orin device, our models with $&lt;$ 1M parameters operate at 46 FPS and 150 FPS on streamed images and videos, surpassing the second-best lightweight models in our experiments by more than $2\\times$ and $3\\times$ in speed with superior accuracy. Code will be available at https://github.com/hellozhuo/stdnet.git.</article>","contentLength":1576,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Differentiable Distance Metric for Robotics Through Generalized Alternating Projection","url":"https://arxiv.org/abs/2507.01181","date":1751515200,"author":"","guid":182425,"unread":true,"content":"<article>arXiv:2507.01181v1 Announce Type: new \nAbstract: In many robotics applications, it is necessary to compute not only the distance between the robot and the environment, but also its derivative - for example, when using control barrier functions. However, since the traditional Euclidean distance is not differentiable, there is a need for alternative distance metrics that possess this property. Recently, a metric with guaranteed differentiability was proposed [1]. This approach has some important drawbacks, which we address in this paper. We provide much simpler and practical expressions for the smooth projection for general convex polytopes. Additionally, as opposed to [1], we ensure that the distance vanishes as the objects overlap. We show the efficacy of the approach in experimental results. Our proposed distance metric is publicly available through the Python-based simulation package UAIBot.</article>","contentLength":906,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Diffusion Explorer: Interactive Exploration of Diffusion Models","url":"https://arxiv.org/abs/2507.01178","date":1751515200,"author":"","guid":182426,"unread":true,"content":"<article>arXiv:2507.01178v1 Announce Type: new \nAbstract: Diffusion models have been central to the development of recent image, video, and even text generation systems. They posses striking geometric properties that can be faithfully portrayed in low-dimensional settings. However, existing resources for explaining diffusion either require an advanced theoretical foundation or focus on their neural network architectures rather than their rich geometric properties. We introduce Diffusion Explorer, an interactive tool to explain the geometric properties of diffusion models. Users can train 2D diffusion models in the browser and observe the temporal dynamics of their sampling process. Diffusion Explorer leverages interactive animation, which has been shown to be a powerful tool for making engaging visualizations of dynamic systems, making it well suited to explaining diffusion models which represent stochastic processes that evolve over time. Diffusion Explorer is open source and a live demo is available at alechelbling.com/Diffusion-Explorer.</article>","contentLength":1047,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An Adaptive Estimation Approach based on Fisher Information to Overcome the Challenges of LFP Battery SOC Estimation","url":"https://arxiv.org/abs/2507.01173","date":1751515200,"author":"","guid":182427,"unread":true,"content":"<article>arXiv:2507.01173v1 Announce Type: new \nAbstract: Robust and Real-time State of Charge (SOC) estimation is essential for Lithium Iron Phosphate (LFP) batteries, which are widely used in electric vehicles (EVs) and energy storage systems due to safety and longevity. However, the flat Open Circuit Voltage (OCV)-SOC curve makes this task particularly challenging. This challenge is complicated by hysteresis effects, and real-world conditions such as current bias, voltage quantization errors, and temperature that must be considered in the battery management system use. In this paper, we proposed an adaptive estimation approach to overcome the challenges of LFPSOC estimation. Specifically, the method uses an adaptive fisher information fusion strategy that adaptively combines the SOC estimation from two different models, which are Coulomb counting and equivalent circuit model-based parameter identification. The effectiveness of this strategy is rationalized by the information richness excited by external cycling signals. A 3D OCV-H-SOC map that captures the relationship between OCV, hysteresis, and SOC was proposed as the backbone, and can be generalizable to other widely adopted parameter-identification methods. Extensive validation under ideal and real-world use scenarios, including SOC-OCV flat zones, current bias, voltage quantization errors, low temperatures, and insufficient current excitations, have been performed using 4 driving profiles, i.e., the Orange County Transit Bus Cycle, the California Unified Cycle, the US06 Drive Cycle, and the New York City Cycle, where the results demonstrate superiority over the state-of-the-art unscented Kalman filter, long short-term memory networks and transformer in all validation cases.</article>","contentLength":1753,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Stable and Theoretically Grounded Gromov-Wasserstein Distance for Reeb Graph Comparison using Persistence Images","url":"https://arxiv.org/abs/2507.01171","date":1751515200,"author":"","guid":182428,"unread":true,"content":"<article>arXiv:2507.01171v1 Announce Type: new \nAbstract: Reeb graphs are a fundamental structure for analyzing the topological and geometric properties of scalar fields. Comparing Reeb graphs is crucial for advancing research in this domain, yet existing metrics are often computationally prohibitive or fail to capture essential topological features effectively. In this paper, we explore the application of the Gromov-Wasserstein distance, a versatile metric for comparing metric measure spaces, to Reeb graphs. We propose a framework integrating a symmetric variant of the Reeb radius for robust geometric comparison, and a novel probabilistic weighting scheme based on Persistence Images derived from extended persistence diagrams to effectively incorporate topological significance. A key contribution of this work is the rigorous theoretical proof of the stability of our proposed Reeb Gromov-Wasserstein distance with respect to perturbations in the underlying scalar fields. This ensures that small changes in the input data lead to small changes in the computed distance between Reeb graphs, a critical property for reliable analysis. We demonstrate the advantages of our approach, including its enhanced ability to capture topological features and its proven stability, through comparisons with other alternatives on several datasets, showcasing its practical utility and theoretical soundness.</article>","contentLength":1396,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Matching and Linking Entries in Historical Swedish Encyclopedias","url":"https://arxiv.org/abs/2507.01170","date":1751515200,"author":"","guid":182429,"unread":true,"content":"<article>arXiv:2507.01170v1 Announce Type: new \nAbstract: The \\textit{Nordisk familjebok} is a Swedish encyclopedia from the 19th and 20th centuries. It was written by a team of experts and aimed to be an intellectual reference, stressing precision and accuracy. This encyclopedia had four main editions remarkable by their size, ranging from 20 to 38 volumes. As a consequence, the \\textit{Nordisk familjebok} had a considerable influence in universities, schools, the media, and society overall. As new editions were released, the selection of entries and their content evolved, reflecting intellectual changes in Sweden.\n  In this paper, we used digitized versions from \\textit{Project Runeberg}. We first resegmented the raw text into entries and matched pairs of entries between the first and second editions using semantic sentence embeddings. We then extracted the geographical entries from both editions using a transformer-based classifier and linked them to Wikidata. This enabled us to identify geographic trends and possible shifts between the first and second editions, written between 1876-1899 and 1904-1926, respectively.\n  Interpreting the results, we observe a small but significant shift in geographic focus away from Europe and towards North America, Africa, Asia, Australia, and northern Scandinavia from the first to the second edition, confirming the influence of the First World War and the rise of new powers. The code and data are available on GitHub at https://github.com/sibbo/nordisk-familjebok.</article>","contentLength":1515,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Towards a Signal Detection Based Measure for Assessing Information Quality of Explainable Recommender Systems","url":"https://arxiv.org/abs/2507.01168","date":1751515200,"author":"","guid":182430,"unread":true,"content":"<article>arXiv:2507.01168v1 Announce Type: new \nAbstract: There is growing interest in explainable recommender systems that provide recommendations along with explanations for the reasoning behind them. When evaluating recommender systems, most studies focus on overall recommendation performance. Only a few assess the quality of the explanations. Explanation quality is often evaluated through user studies that subjectively gather users' opinions on representative explanatory factors that shape end-users' perspective towards the results, not about the explanation contents itself. We aim to fill this gap by developing an objective metric to evaluate Veracity: the information quality of explanations. Specifically, we decompose Veracity into two dimensions: Fidelity and Attunement. Fidelity refers to whether the explanation includes accurate information about the recommended item. Attunement evaluates whether the explanation reflects the target user's preferences. By applying signal detection theory, we first determine decision outcomes for each dimension and then combine them to calculate a sensitivity, which serves as the final Veracity value. To assess the effectiveness of the proposed metric, we set up four cases with varying levels of information quality to validate whether our metric can accurately capture differences in quality. The results provided meaningful insights into the effectiveness of our proposed metric.</article>","contentLength":1432,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Methodological Framework for Capturing Cognitive-Affective States in Collaborative Learning","url":"https://arxiv.org/abs/2507.01166","date":1751515200,"author":"","guid":182431,"unread":true,"content":"<article>arXiv:2507.01166v1 Announce Type: new \nAbstract: Identification of affective and attentional states of individuals within groups is difficult to obtain without disrupting the natural flow of collaboration. Recent work from our group used a retrospect cued recall paradigm where participants spoke about their cognitive-affective states while they viewed videos of their groups. We then collected additional participants where their reports were constrained to a subset of pre-identified cognitive-affective states. In this latter case, participants either self reported or reported in response to probes. Here, we present an initial analysis of the frequency and temporal distribution of participant reports, and how the distributions of labels changed across the two collections. Our approach has implications for the educational data mining community in tracking cognitive-affective states in collaborative learning more effectively and in developing improved adaptive learning systems that can detect and respond to cognitive-affective states.</article>","contentLength":1046,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"cp_measure: API-first feature extraction for image-based profiling workflows","url":"https://arxiv.org/abs/2507.01163","date":1751515200,"author":"","guid":182432,"unread":true,"content":"<article>arXiv:2507.01163v1 Announce Type: new \nAbstract: Biological image analysis has traditionally focused on measuring specific visual properties of interest for cells or other entities. A complementary paradigm gaining increasing traction is image-based profiling - quantifying many distinct visual features to form comprehensive profiles which may reveal hidden patterns in cellular states, drug responses, and disease mechanisms. While current tools like CellProfiler can generate these feature sets, they pose significant barriers to automated and reproducible analyses, hindering machine learning workflows. Here we introduce cp_measure, a Python library that extracts CellProfiler's core measurement capabilities into a modular, API-first tool designed for programmatic feature extraction. We demonstrate that cp_measure features retain high fidelity with CellProfiler features while enabling seamless integration with the scientific Python ecosystem. Through applications to 3D astrocyte imaging and spatial transcriptomics, we showcase how cp_measure enables reproducible, automated image-based profiling pipelines that scale effectively for machine learning applications in computational biology.</article>","contentLength":1200,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Imitation Learning for Satellite Attitude Control under Unknown Perturbations","url":"https://arxiv.org/abs/2507.01161","date":1751515200,"author":"","guid":182433,"unread":true,"content":"<article>arXiv:2507.01161v1 Announce Type: new \nAbstract: This paper presents a novel satellite attitude control framework that integrates Soft Actor-Critic (SAC) reinforcement learning with Generative Adversarial Imitation Learning (GAIL) to achieve robust performance under various unknown perturbations. Traditional control techniques often rely on precise system models and are sensitive to parameter uncertainties and external perturbations. To overcome these limitations, we first develop a SAC-based expert controller that demonstrates improved resilience against actuator failures, sensor noise, and attitude misalignments, outperforming our previous results in several challenging scenarios. We then use GAIL to train a learner policy that imitates the expert's trajectories, thereby reducing training costs and improving generalization through expert demonstrations. Preliminary experiments under single and combined perturbations show that the SAC expert can rotate the antenna to a specified direction and keep the antenna orientation reliably stable in most of the listed perturbations. Additionally, the GAIL learner can imitate most of the features from the trajectories generated by the SAC expert. Comparative evaluations and ablation studies confirm the effectiveness of the SAC algorithm and reward shaping. The integration of GAIL further reduces sample complexity and demonstrates promising imitation capabilities, paving the way for more intelligent and autonomous spacecraft control systems.</article>","contentLength":1505,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Event-based evaluation of abstractive news summarization","url":"https://arxiv.org/abs/2507.01160","date":1751515200,"author":"","guid":182434,"unread":true,"content":"<article>arXiv:2507.01160v1 Announce Type: new \nAbstract: An abstractive summary of a news article contains its most important information in a condensed version. The evaluation of automatically generated summaries by generative language models relies heavily on human-authored summaries as gold references, by calculating overlapping units or similarity scores. News articles report events, and ideally so should the summaries. In this work, we propose to evaluate the quality of abstractive summaries by calculating overlapping events between generated summaries, reference summaries, and the original news articles. We experiment on a richly annotated Norwegian dataset comprising both events annotations and summaries authored by expert human annotators. Our approach provides more insight into the event information contained in the summaries.</article>","contentLength":839,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FlashDP: Private Training Large Language Models with Efficient DP-SGD","url":"https://arxiv.org/abs/2507.01154","date":1751515200,"author":"","guid":182435,"unread":true,"content":"<article>arXiv:2507.01154v1 Announce Type: new \nAbstract: As large language models (LLMs) increasingly underpin technological advancements, the privacy of their training data emerges as a critical concern. Differential Privacy (DP) serves as a rigorous mechanism to protect this data, yet its integration via Differentially Private Stochastic Gradient Descent (DP-SGD) introduces substantial challenges, primarily due to the complexities of per-sample gradient clipping. Current explicit methods, such as Opacus, necessitate extensive storage for per-sample gradients, significantly inflating memory requirements. Conversely, implicit methods like GhostClip reduce storage needs by recalculating gradients multiple times, which leads to inefficiencies due to redundant computations. This paper introduces FlashDP, an innovative cache-friendly per-layer DP-SGD that consolidates necessary operations into a single task, calculating gradients only once in a fused manner. This approach not only diminishes memory movement by up to \\textbf{50\\%} but also cuts down redundant computations by \\textbf{20\\%}, compared to previous methods. Consequently, FlashDP does not increase memory demands and achieves a \\textbf{90\\%} throughput compared to the Non-DP method on a four-A100 system during the pre-training of the Llama-13B model, while maintaining parity with standard per-layer clipped DP-SGD in terms of accuracy. These advancements establish FlashDP as a pivotal development for efficient and privacy-preserving training of LLMs. FlashDP's code has been open-sourced in https://github.com/kaustpradalab/flashdp.</article>","contentLength":1603,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SonoGym: High Performance Simulation for Challenging Surgical Tasks with Robotic Ultrasound","url":"https://arxiv.org/abs/2507.01152","date":1751515200,"author":"","guid":182436,"unread":true,"content":"<article>arXiv:2507.01152v1 Announce Type: new \nAbstract: Ultrasound (US) is a widely used medical imaging modality due to its real-time capabilities, non-invasive nature, and cost-effectiveness. Robotic ultrasound can further enhance its utility by reducing operator dependence and improving access to complex anatomical regions. For this, while deep reinforcement learning (DRL) and imitation learning (IL) have shown potential for autonomous navigation, their use in complex surgical tasks such as anatomy reconstruction and surgical guidance remains limited -- largely due to the lack of realistic and efficient simulation environments tailored to these tasks. We introduce SonoGym, a scalable simulation platform for complex robotic ultrasound tasks that enables parallel simulation across tens to hundreds of environments. Our framework supports realistic and real-time simulation of US data from CT-derived 3D models of the anatomy through both a physics-based and a generative modeling approach. Sonogym enables the training of DRL and recent IL agents (vision transformers and diffusion policies) for relevant tasks in robotic orthopedic surgery by integrating common robotic platforms and orthopedic end effectors. We further incorporate submodular DRL -- a recent method that handles history-dependent rewards -- for anatomy reconstruction and safe reinforcement learning for surgery. Our results demonstrate successful policy learning across a range of scenarios, while also highlighting the limitations of current methods in clinically relevant environments. We believe our simulation can facilitate research in robot learning approaches for such challenging robotic surgery applications. Dataset, codes, and videos are publicly available at https://sonogym.github.io/.</article>","contentLength":1773,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Computational Insights into Orthotropic Fracture: Crack-Tip Fields in Strain-Limiting Materials under Non-Uniform Loads","url":"https://arxiv.org/abs/2507.01150","date":1751515200,"author":"","guid":182437,"unread":true,"content":"<article>arXiv:2507.01150v1 Announce Type: new \nAbstract: A finite element framework is presented for analyzing crack-tip phenomena in transversely isotropic, strain-limiting elastic materials. Mechanical response is characterized by an algebraically nonlinear constitutive model, relating stress to linearized strain. Non-physical strain singularities at the crack apex are mitigated, ensuring bounded strain magnitudes. This methodology significantly advances boundary value problem (BVP) formulation, especially for first-order approximate theories. For a transversely isotropic elastic solid with a crack, the governing equilibrium equation, derived from linear momentum balance and the nonlinear constitutive model, is reduced to a second-order, vector-valued, quasilinear elliptic BVP. This BVP is solved using a robust numerical scheme combining Picard-type linearization with a continuous Galerkin finite element method for spatial discretization. Numerical results are presented for various loading conditions, including uniform tension, non-uniform slope, and parabolic loading, with two distinct material fiber orientations. It is demonstrated that crack-tip strain growth is substantially lower than stress growth. Nevertheless, strain-energy density is found to be concentrated at the crack tip, consistent with linear elastic fracture mechanics principles. The proposed framework provides a robust basis for formulating physically meaningful, rigorous BVPs, critical for investigating fundamental processes like crack propagation, damage, and nucleation in anisotropic, strain-limiting elastic solids under diverse loading conditions.</article>","contentLength":1639,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CarbonClarity: Understanding and Addressing Uncertainty in Embodied Carbon for Sustainable Computing","url":"https://arxiv.org/abs/2507.01145","date":1751515200,"author":"","guid":182438,"unread":true,"content":"<article>arXiv:2507.01145v1 Announce Type: new \nAbstract: Embodied carbon footprint modeling has become an area of growing interest due to its significant contribution to carbon emissions in computing. However, the deterministic nature of the existing models fail to account for the spatial and temporal variability in the semiconductor supply chain. The absence of uncertainty modeling limits system designers' ability to make informed, carbon-aware decisions. We introduce CarbonClarity, a probabilistic framework designed to model embodied carbon footprints through distributions that reflect uncertainties in energy-per-area, gas-per-area, yield, and carbon intensity across different technology nodes. Our framework enables a deeper understanding of how design choices, such as chiplet architectures and new vs. old technology node selection, impact emissions and their associated uncertainties. For example, we show that the gap between the mean and 95th percentile of embodied carbon per cm$^2$ can reach up to 1.6X for the 7nm technology node. Additionally, we demonstrate through case studies that: (i) CarbonClarity is a valuable resource for device provisioning, help maintaining performance under a tight carbon budget; and (ii) chiplet technology and mature nodes not only reduce embodied carbon but also significantly lower its associated uncertainty, achieving an 18% reduction in the 95th percentile compared to monolithic designs for the mobile application.</article>","contentLength":1465,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Review on Sound Source Localization in Robotics: Focusing on Deep Learning Methods","url":"https://arxiv.org/abs/2507.01143","date":1751515200,"author":"","guid":182439,"unread":true,"content":"<article>arXiv:2507.01143v1 Announce Type: new \nAbstract: Sound source localization (SSL) adds a spatial dimension to auditory perception, allowing a system to pinpoint the origin of speech, machinery noise, warning tones, or other acoustic events, capabilities that facilitate robot navigation, human-machine dialogue, and condition monitoring. While existing surveys provide valuable historical context, they typically address general audio applications and do not fully account for robotic constraints or the latest advancements in deep learning. This review addresses these gaps by offering a robotics-focused synthesis, emphasizing recent progress in deep learning methodologies. We start by reviewing classical methods such as Time Difference of Arrival (TDOA), beamforming, Steered-Response Power (SRP), and subspace analysis. Subsequently, we delve into modern machine learning (ML) and deep learning (DL) approaches, discussing traditional ML and neural networks (NNs), convolutional neural networks (CNNs), convolutional recurrent neural networks (CRNNs), and emerging attention-based architectures. The data and training strategy that are the two cornerstones of DL-based SSL are explored. Studies are further categorized by robot types and application domains to facilitate researchers in identifying relevant work for their specific contexts. Finally, we highlight the current challenges in SSL works in general, regarding environmental robustness, sound source multiplicity, and specific implementation constraints in robotics, as well as data and learning strategies in DL-based SSL. Also, we sketch promising directions to offer an actionable roadmap toward robust, adaptable, efficient, and explainable DL-based SSL for next-generation robots.</article>","contentLength":1751,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Multi-Focus Probes for Context-Preserving Network Exploration and Interaction in Immersive Analytics","url":"https://arxiv.org/abs/2507.01140","date":1751515200,"author":"","guid":182440,"unread":true,"content":"<article>arXiv:2507.01140v1 Announce Type: new \nAbstract: Immersive visualization of network data enables users to physically navigate and interact with complex structures, but managing transitions between detailed local (egocentric) views and global (exocentric) overviews remains a major challenge. We present a multifocus probe technique for immersive environments that allows users to instantiate multiple egocentric subgraph views while maintaining persistent links to the global network context. Each probe acts as a portable local focus, enabling fine-grained inspection and editing of distant or occluded regions. Visual and haptic guidance mechanisms ensure context preservation during multi-scale interaction. We demonstrate and discuss the usability of our technique for the editing of network data.</article>","contentLength":801,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Animated Visual Encoding and Layer Blending for Identification of Educational Game Strategies","url":"https://arxiv.org/abs/2507.01134","date":1751515200,"author":"","guid":182441,"unread":true,"content":"<article>arXiv:2507.01134v1 Announce Type: new \nAbstract: Game-Based Learning has proven to be an effective method for enhancing engagement with educational material. However, gaining a deeper understanding of player strategies remains challenging. Sequential game-state and action-based tracking tools often gather extensive data that can be difficult to interpret as long-term strategy. This data presents unique problems to visualization, as it can be fairly natural, noisy data but is constrained within synthetic, controlled environments, leading to issues such as overplotting which can make interpretation complicated. We propose an animated visual encoding tool that utilizes kinetic visualization to address these issues. This tool enables researchers to construct animated data narratives through the configuration of parameter interpolation curves and blending layers. Finally, we demonstrate the usefulness of the tool while addressing specific interests as outlined by a domain expert collaborator.</article>","contentLength":1002,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Spectral Manifold Harmonization for Graph Imbalanced Regression","url":"https://arxiv.org/abs/2507.01132","date":1751515200,"author":"","guid":182442,"unread":true,"content":"<article>arXiv:2507.01132v1 Announce Type: new \nAbstract: Graph-structured data is ubiquitous in scientific domains, where models often face imbalanced learning settings. In imbalanced regression, domain preferences focus on specific target value ranges representing the most scientifically valuable cases; we observe a significant lack of research. In this paper, we present Spectral Manifold Harmonization (SMH), a novel approach for addressing this imbalanced regression challenge on graph-structured data by generating synthetic graph samples that preserve topological properties while focusing on often underrepresented target distribution regions. Conventional methods fail in this context because they either ignore graph topology in case generation or do not target specific domain ranges, resulting in models biased toward average target values. Experimental results demonstrate the potential of SMH on chemistry and drug discovery benchmark datasets, showing consistent improvements in predictive performance for target domain ranges.</article>","contentLength":1035,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tensor Decomposition Networks for Fast Machine Learning Interatomic Potential Computations","url":"https://arxiv.org/abs/2507.01131","date":1751515200,"author":"","guid":182443,"unread":true,"content":"<article>arXiv:2507.01131v1 Announce Type: new \nAbstract: $\\rm{SO}(3)$-equivariant networks are the dominant models for machine learning interatomic potentials (MLIPs). The key operation of such networks is the Clebsch-Gordan (CG) tensor product, which is computationally expensive. To accelerate the computation, we develop tensor decomposition networks (TDNs) as a class of approximately equivariant networks whose CG tensor products are replaced by low-rank tensor decompositions, such as the CANDECOMP/PARAFAC (CP) decomposition. With the CP decomposition, we prove (i) a uniform bound on the induced error of $\\rm{SO}(3)$-equivariance, and (ii) the universality of approximating any equivariant bilinear map. To further reduce the number of parameters, we propose path-weight sharing that ties all multiplicity-space weights across the $O(L^3)$ CG paths into a single path without compromising equivariance, where $L$ is the maximum angular degree. The resulting layer acts as a plug-and-play replacement for tensor products in existing networks, and the computational complexity of tensor products is reduced from $O(L^6)$ to $O(L^4)$. We evaluate TDNs on PubChemQCR, a newly curated molecular relaxation dataset containing 105 million DFT-calculated snapshots. We also use existing datasets, including OC20, and OC22. Results show that TDNs achieve competitive performance with dramatic speedup in computations.</article>","contentLength":1409,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On Design Principles for Private Adaptive Optimizers","url":"https://arxiv.org/abs/2507.01129","date":1751515200,"author":"","guid":182444,"unread":true,"content":"<article>arXiv:2507.01129v1 Announce Type: new \nAbstract: The spherical noise added to gradients in differentially private (DP) training undermines the performance of adaptive optimizers like AdaGrad and Adam, and hence many recent works have proposed algorithms to address this challenge. However, the empirical results in these works focus on simple tasks and models and the conclusions may not generalize to model training in practice. In this paper we survey several of these variants, and develop better theoretical intuition for them as well as perform empirical studies comparing them. We find that a common intuition of aiming for unbiased estimates of second moments of gradients in adaptive optimizers is misguided, and instead that a simple technique called scale-then-privatize (which does not achieve unbiased second moments) has more desirable theoretical behaviors and outperforms all other variants we study on a small-scale language model training task. We additionally argue that scale-then-privatize causes the noise addition to better match the application of correlated noise mechanisms which are more desirable to use in practice.</article>","contentLength":1143,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online Semantic Gaussian Splatting","url":"https://arxiv.org/abs/2507.01125","date":1751515200,"author":"","guid":182445,"unread":true,"content":"<article>arXiv:2507.01125v1 Announce Type: new \nAbstract: We present VISTA (Viewpoint-based Image selection with Semantic Task Awareness), an active exploration method for robots to plan informative trajectories that improve 3D map quality in areas most relevant for task completion. Given an open-vocabulary search instruction (e.g., \"find a person\"), VISTA enables a robot to explore its environment to search for the object of interest, while simultaneously building a real-time semantic 3D Gaussian Splatting reconstruction of the scene. The robot navigates its environment by planning receding-horizon trajectories that prioritize semantic similarity to the query and exploration of unseen regions of the environment. To evaluate trajectories, VISTA introduces a novel, efficient viewpoint-semantic coverage metric that quantifies both the geometric view diversity and task relevance in the 3D scene. On static datasets, our coverage metric outperforms state-of-the-art baselines, FisherRF and Bayes' Rays, in computation speed and reconstruction quality. In quadrotor hardware experiments, VISTA achieves 6x higher success rates in challenging maps, compared to baseline methods, while matching baseline performance in less challenging maps. Lastly, we show that VISTA is platform-agnostic by deploying it on a quadrotor drone and a Spot quadruped robot. Open-source code will be released upon acceptance of the paper.</article>","contentLength":1415,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions","url":"https://arxiv.org/abs/2507.01123","date":1751515200,"author":"","guid":182446,"unread":true,"content":"<article>arXiv:2507.01123v1 Announce Type: new \nAbstract: Landslides pose severe threats to infrastructure, economies, and human lives, necessitating accurate detection and predictive mapping across diverse geographic regions. With advancements in deep learning and remote sensing, automated landslide detection has become increasingly effective. This study presents a comprehensive approach integrating multi-source satellite imagery and deep learning models to enhance landslide identification and prediction. We leverage Sentinel-2 multispectral data and ALOS PALSAR-derived slope and Digital Elevation Model (DEM) layers to capture critical environmental features influencing landslide occurrences. Various geospatial analysis techniques are employed to assess the impact of terra in characteristics, vegetation cover, and rainfall on detection accuracy. Additionally, we evaluate the performance of multiple stateof-the-art deep learning segmentation models, including U-Net, DeepLabV3+, and Res-Net, to determine their effectiveness in landslide detection. The proposed framework contributes to the development of reliable early warning systems, improved disaster risk management, and sustainable land-use planning. Our findings provide valuable insights into the potential of deep learning and multi-source remote sensing in creating robust, scalable, and transferable landslide prediction models.</article>","contentLength":1395,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"From Literature to ReWA: Discussing Reproductive Well-being in HCI","url":"https://arxiv.org/abs/2507.01121","date":1751515200,"author":"","guid":182447,"unread":true,"content":"<article>arXiv:2507.01121v1 Announce Type: new \nAbstract: Reproductive well-being is shaped by intersecting cultural, religious, gendered, and political contexts, yet current technologies often reflect narrow, Western-centric assumptions. In this literature review, we synthesize findings from 147 peer-reviewed papers published between 2015 and 2025 across HCI, CSCW and social computing, ICTD, digital and public health, and AI for well-being scholarship to map the evolving reproductive well-being landscape. We identify three thematic waves that focused on early access and education, cultural sensitivity and privacy, and AI integration with policy-aware design, and highlight how technologies support or constrain diverse reproductive experiences. Our analysis reveals critical gaps in inclusivity, with persistent exclusions of men and non-binary users, migrants, and users in the Global South. Additionally, we surfaced the significant absence of literature on the role of stakeholders (e.g., husband and family members, household maids and cleaning helping hands, midwife, etc.) in the reproductive well-being space. Drawing on the findings from the literature, we propose the ReWA framework to support reproductive well-being for all agendas through six design orientations associated with: location, culture, and history; polyvocality and agency; rationality, temporality, distributive roles, and methodology.</article>","contentLength":1411,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quasi-twisted codes: decoding and applications in code-based cryptography","url":"https://arxiv.org/abs/2507.01118","date":1751515200,"author":"","guid":182448,"unread":true,"content":"<article>arXiv:2507.01118v1 Announce Type: new \nAbstract: Quasi-twisted (QT) codes generalize several important families of linear codes, including cyclic, constacyclic, and quasi-cyclic codes. Despite their potential, to the best of our knowledge, there exists no efficient decoding algorithm for QT codes. In this work, we propose a syndrome-based decoding method capable of efficiently correcting up to (d* - 1)/2 errors, where d* denotes an HT-like lower bound on the minimum distance of QT codes, which we formalize here. Additionally, we introduce a Niederreiter-like cryptosystem constructed from QT codes. This cryptosystem is resistant to some classical attacks as well as some quantum attacks based on Quantum Fourier Sampling.</article>","contentLength":728,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Neural Operator based on Dynamic Mode Decomposition","url":"https://arxiv.org/abs/2507.01117","date":1751515200,"author":"","guid":182449,"unread":true,"content":"<article>arXiv:2507.01117v1 Announce Type: new \nAbstract: The scientific computation methods development in conjunction with artificial intelligence technologies remains a hot research topic. Finding a balance between lightweight and accurate computations is a solid foundation for this direction. The study presents a neural operator based on the dynamic mode decomposition algorithm (DMD), mapping functional spaces, which combines DMD and deep learning (DL) for spatiotemporal processes efficient modeling. Solving PDEs for various initial and boundary conditions requires significant computational resources. The method suggested automatically extracts key modes and system dynamics using them to construct predictions, reducing computational costs compared to traditional numerical methods. The approach has demonstrated its efficiency through comparative analysis of performance with closest analogues DeepONet and FNO in the heat equation, Laplaces equation, and Burgers equation solutions approximation, where it achieves high reconstruction accuracy.</article>","contentLength":1050,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Semiautomatic Simplification","url":"https://arxiv.org/abs/2507.01116","date":1751515200,"author":"","guid":182450,"unread":true,"content":"<article>arXiv:2507.01116v1 Announce Type: new \nAbstract: We present semisimp, a tool for semiautomatic simplification of three dimensional polygonal models. Existing automatic simplification technology is quite mature, but is not sensitive to the heightened importance of distinct semantic model regions such as faces and limbs, nor to simplification constraints imposed by model usage such as animation. semisimp allows users to preserve such regions by intervening in the simplification process. Users can manipulate the order in which basic simplifications are applied to redistribute model detail, improve the simplified models themselves by repositioning vertices with propagation to neighboring levels of detail, and adjust the hierarchical partitioning of the model surface to segment simplification and improve control of reordering and position propagation.</article>","contentLength":858,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HERCULES: Hardware accElerator foR stoChastic schedULing in hEterogeneous Systems","url":"https://arxiv.org/abs/2507.01113","date":1751515200,"author":"","guid":182451,"unread":true,"content":"<article>arXiv:2507.01113v1 Announce Type: new \nAbstract: Efficient workload scheduling is a critical challenge in modern heterogeneous computing environments, particularly in high-performance computing (HPC) systems. Traditional software-based schedulers struggle to efficiently balance workload distribution due to high scheduling overhead, lack of adaptability to dynamic workloads, and suboptimal resource utilization. These pitfalls are compounded in heterogeneous systems, where differing computational elements can have vastly different performance profiles. To resolve these hindrances, we present a novel FPGA-based accelerator for stochastic online scheduling (SOS). We modify a greedy cost selection assignment policy by adapting existing cost equations to engage with discretized time before implementing them into a hardware accelerator design. Our design leverages hardware parallelism, precalculation, and precision quantization to reduce job scheduling latency. By introducing a hardware-accelerated approach to real-time scheduling, this paper establishes a new paradigm for adaptive scheduling mechanisms in heterogeneous computing systems. The proposed design achieves high throughput, low latency, and energy-efficient operation, offering a scalable alternative to traditional software scheduling methods. Experimental results demonstrate consistent workload distribution, fair machine utilization, and up to 1060x speedup over single-threaded software scheduling policy implementations. This makes the SOS accelerator a strong candidate for deployment in high-performance computing system, deeplearning pipelines, and other performance-critical applications.</article>","contentLength":1670,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Environment-Aware and Human-Cooperative Swing Control for Lower-Limb Prostheses in Diverse Obstacle Scenarios","url":"https://arxiv.org/abs/2507.01111","date":1751515200,"author":"","guid":182452,"unread":true,"content":"<article>arXiv:2507.01111v1 Announce Type: new \nAbstract: Current control strategies for powered lower limb prostheses often lack awareness of the environment and the user's intended interactions with it. This limitation becomes particularly apparent in complex terrains. Obstacle negotiation, a critical scenario exemplifying such challenges, requires both real-time perception of obstacle geometry and responsiveness to user intention about when and where to step over or onto, to dynamically adjust swing trajectories. We propose a novel control strategy that fuses environmental awareness and human cooperativeness: an on-board depth camera detects obstacles ahead of swing phase, prompting an elevated early-swing trajectory to ensure clearance, while late-swing control defers to natural biomechanical cues from the user. This approach enables intuitive stepping strategies without requiring unnatural movement patterns. Experiments with three non-amputee participants demonstrated 100 percent success across more than 150 step-overs and 30 step-ons with randomly placed obstacles of varying heights (4-16 cm) and distances (15-70 cm). By effectively addressing obstacle navigation -- a gateway challenge for complex terrain mobility -- our system demonstrates adaptability to both environmental constraints and user intentions, with promising applications across diverse locomotion scenarios.</article>","contentLength":1390,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory","url":"https://arxiv.org/abs/2507.01110","date":1751515200,"author":"","guid":182453,"unread":true,"content":"<article>arXiv:2507.01110v1 Announce Type: new \nAbstract: Gaussian Splatting has emerged as a high-performance technique for novel view synthesis, enabling real-time rendering and high-quality reconstruction of small scenes. However, scaling to larger environments has so far relied on partitioning the scene into chunks -- a strategy that introduces artifacts at chunk boundaries, complicates training across varying scales, and is poorly suited to unstructured scenarios such as city-scale flyovers combined with street-level views. Moreover, rendering remains fundamentally limited by GPU memory, as all visible chunks must reside in VRAM simultaneously. We introduce A LoD of Gaussians, a framework for training and rendering ultra-large-scale Gaussian scenes on a single consumer-grade GPU -- without partitioning. Our method stores the full scene out-of-core (e.g., in CPU memory) and trains a Level-of-Detail (LoD) representation directly, dynamically streaming only the relevant Gaussians. A hybrid data structure combining Gaussian hierarchies with Sequential Point Trees enables efficient, view-dependent LoD selection, while a lightweight caching and view scheduling system exploits temporal coherence to support real-time streaming and rendering. Together, these innovations enable seamless multi-scale reconstruction and interactive visualization of complex scenes -- from broad aerial views to fine-grained ground-level details.</article>","contentLength":1433,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bugs in the Shadows: Static Detection of Faulty Python Refactorings","url":"https://arxiv.org/abs/2507.01103","date":1751515200,"author":"","guid":182454,"unread":true,"content":"<article>arXiv:2507.01103v1 Announce Type: new \nAbstract: Python is a widely adopted programming language, valued for its simplicity and flexibility. However, its dynamic type system poses significant challenges for automated refactoring - an essential practice in software evolution aimed at improving internal code structure without changing external behavior. Understanding how type errors are introduced during refactoring is crucial, as such errors can compromise software reliability and reduce developer productivity. In this work, we propose a static analysis technique to detect type errors introduced by refactoring implementations for Python. We evaluated our technique on Rope refactoring implementations, applying them to open-source Python projects. Our analysis uncovered 29 bugs across four refactoring types from a total of 1,152 refactoring attempts. Several of these issues were also found in widely used IDEs such as PyCharm and PyDev. All reported bugs were submitted to the respective developers, and some of them were acknowledged and accepted. These results highlight the need to improve the robustness of current Python refactoring tools to ensure the correctness of automated code transformations and support reliable software maintenance.</article>","contentLength":1256,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Geometry-aware 4D Video Generation for Robot Manipulation","url":"https://arxiv.org/abs/2507.01099","date":1751515200,"author":"","guid":182455,"unread":true,"content":"<article>arXiv:2507.01099v1 Announce Type: new \nAbstract: Understanding and predicting the dynamics of the physical world can enhance a robot's ability to plan and interact effectively in complex environments. While recent video generation models have shown strong potential in modeling dynamic scenes, generating videos that are both temporally coherent and geometrically consistent across camera views remains a significant challenge. To address this, we propose a 4D video generation model that enforces multi-view 3D consistency of videos by supervising the model with cross-view pointmap alignment during training. This geometric supervision enables the model to learn a shared 3D representation of the scene, allowing it to predict future video sequences from novel viewpoints based solely on the given RGB-D observations, without requiring camera poses as inputs. Compared to existing baselines, our method produces more visually stable and spatially aligned predictions across multiple simulated and real-world robotic datasets. We further show that the predicted 4D videos can be used to recover robot end-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting robust robot manipulation and generalization to novel camera viewpoints.</article>","contentLength":1253,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Proof of a perfect platonic representation hypothesis","url":"https://arxiv.org/abs/2507.01098","date":1751515200,"author":"","guid":182456,"unread":true,"content":"<article>arXiv:2507.01098v1 Announce Type: new \nAbstract: In this note, we elaborate on and explain in detail the proof given by Ziyin et al. (2025) of the \"perfect\" Platonic Representation Hypothesis (PRH) for the embedded deep linear network model (EDLN). We show that if trained with SGD, two EDLNs with different widths and depths and trained on different data will become Perfectly Platonic, meaning that every possible pair of layers will learn the same representation up to a rotation. Because most of the global minima of the loss function are not Platonic, that SGD only finds the perfectly Platonic solution is rather extraordinary. The proof also suggests at least six ways the PRH can be broken. We also show that in the EDLN model, the emergence of the Platonic representations is due to the same reason as the emergence of progressive sharpening. This implies that these two seemingly unrelated phenomena in deep learning can, surprisingly, have a common cause. Overall, the theory and proof highlight the importance of understanding emergent \"entropic forces\" due to the irreversibility of SGD training and their role in representation learning. The goal of this note is to be instructive and avoid lengthy technical details.</article>","contentLength":1231,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI-guided digital intervention with physiological monitoring reduces intrusive memories after experimental trauma","url":"https://arxiv.org/abs/2507.01081","date":1751515200,"author":"","guid":182457,"unread":true,"content":"<article>arXiv:2507.01081v1 Announce Type: new \nAbstract: Trauma prevalence is vast globally. Evidence-based digital treatments can help, but most require human guidance. Human guides provide tailored instructions and responsiveness to internal cognitive states, but limit scalability. Can generative AI and neurotechnology provide a scalable alternative? Here we test ANTIDOTE, combining AI guidance and pupillometry to automatically deliver and monitor an evidence-based digital treatment, specifically the Imagery Competing Task Intervention (ICTI), to reduce intrusive memories after psychological trauma. One hundred healthy volunteers were exposed to videos of traumatic events and randomly assigned to an intervention or active control condition. As predicted, intervention participants reported significantly fewer intrusive memories over the following week. Post-hoc assessment against clinical rubrics confirmed the AI guide delivered the intervention successfully. Additionally, pupil size tracked intervention engagement and predicted symptom reduction, providing a candidate biomarker of intervention effectiveness. These findings open a path toward rigorous AI-guided digital interventions that can scale to trauma prevalence.</article>","contentLength":1231,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Development and Comparative Evaluation of Three Artificial Intelligence Models (NLP, LLM, JEPA) for Predicting Triage in Emergency Departments: A 7-Month Retrospective Proof-of-Concept","url":"https://arxiv.org/abs/2507.01080","date":1751515200,"author":"","guid":182458,"unread":true,"content":"<article>arXiv:2507.01080v1 Announce Type: new \nAbstract: Triage errors, including undertriage and overtriage, are persistent challenges in emergency departments (EDs). With increasing patient influx and staff shortages, the integration of artificial intelligence (AI) into triage protocols has gained attention. This study compares the performance of three AI models [Natural Language Processing (NLP), Large Language Models (LLM), and Joint Embedding Predictive Architecture (JEPA)] in predicting triage outcomes against the FRENCH scale and clinical practice.We conducted a retrospective analysis of a prospectively recruited cohort gathering adult patient triage data over a 7-month period at the Roger Salengro Hospital ED (Lille, France). Three AI models were trained and validated : (1) TRIAGEMASTER (NLP), (2) URGENTIAPARSE (LLM), and (3) EMERGINET (JEPA). Data included demographic details, verbatim chief complaints, vital signs, and triage outcomes based on the FRENCH scale and GEMSA coding. The primary outcome was the concordance of AI-predicted triage level with the FRENCH gold-standard. It was assessed thanks to various indicators : F1-Score, Weighted Kappa, Spearman, MAE, RMSE. The LLM model (URGENTIAPARSE) showed higher accuracy (composite score: 2.514) compared to JEPA (EMERGINET, 0.438) and NLP (TRIAGEMASTER, -3.511), outperforming nurse triage (-4.343). Secondary analyses highlighted the effectiveness of URGENTIAPARSE in predicting hospitalization needs (GEMSA) and its robustness with structured data versus raw transcripts (either for GEMSA prediction or for FRENCH prediction). LLM architecture, through abstraction of patient representations, offers the most accurate triage predictions among tested models. Integrating AI into ED workflows could enhance patient safety and operational efficiency, though integration into clinical workflows requires addressing model limitations and ensuring ethical transparency.</article>","contentLength":1937,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MobileRAG: A Fast, Memory-Efficient, and Energy-Efficient Method for On-Device RAG","url":"https://arxiv.org/abs/2507.01079","date":1751515200,"author":"","guid":182459,"unread":true,"content":"<article>arXiv:2507.01079v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) has proven effective on server infrastructures, but its application on mobile devices is still underexplored due to limited memory and power resources. Existing vector search and RAG solutions largely assume abundant computation resources, making them impractical for on-device scenarios. In this paper, we propose MobileRAG, a fully on-device pipeline that overcomes these limitations by combining a mobile-friendly vector search algorithm, \\textit{EcoVector}, with a lightweight \\textit{Selective Content Reduction} (SCR) method. By partitioning and partially loading index data, EcoVector drastically reduces both memory footprint and CPU usage, while the SCR method filters out irrelevant text to diminish Language Model (LM) input size without degrading accuracy. Extensive experiments demonstrated that MobileRAG significantly outperforms conventional vector search and RAG methods in terms of latency, memory usage, and power consumption, while maintaining accuracy and enabling offline operation to safeguard privacy in resource-constrained environments.</article>","contentLength":1148,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"yProv4ML: Effortless Provenance Tracking for Machine Learning Systems","url":"https://arxiv.org/abs/2507.01078","date":1751515200,"author":"","guid":182460,"unread":true,"content":"<article>arXiv:2507.01078v1 Announce Type: new \nAbstract: The rapid growth of interest in large language models (LLMs) reflects their potential for flexibility and generalization, and attracted the attention of a diverse range of researchers. However, the advent of these techniques has also brought to light the lack of transparency and rigor with which development is pursued. In particular, the inability to determine the number of epochs and other hyperparameters in advance presents challenges in identifying the best model. To address this challenge, machine learning frameworks such as MLFlow can automate the collection of this type of information. However, these tools capture data using proprietary formats and pose little attention to lineage. This paper proposes yProv4ML, a framework to capture provenance information generated during machine learning processes in PROV-JSON format, with minimal code modifications.</article>","contentLength":919,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Good Enough to Learn: LLM-based Anomaly Detection in ECU Logs without Reliable Labels","url":"https://arxiv.org/abs/2507.01077","date":1751515200,"author":"","guid":182461,"unread":true,"content":"<article>arXiv:2507.01077v1 Announce Type: new \nAbstract: Anomaly detection often relies on supervised or clustering approaches, with limited success in specialized domains like automotive communication systems where scalable solutions are essential. We propose a novel decoder-only Large Language Model (LLM) to detect anomalies in Electronic Control Unit (ECU) communication logs. Our approach addresses two key challenges: the lack of LLMs tailored for ECU communication and the complexity of inconsistent ground truth data. By learning from UDP communication logs, we formulate anomaly detection simply as identifying deviations in time from normal behavior. We introduce an entropy regularization technique that increases model's uncertainty in known anomalies while maintaining consistency in similar scenarios. Our solution offers three novelties: a decoder-only anomaly detection architecture, a way to handle inconsistent labeling, and an adaptable LLM for different ECU communication use cases. By leveraging the generative capabilities of decoder-only models, we present a new technique that addresses the high cost and error-prone nature of manual labeling through a more scalable system that is able to learn from a minimal set of examples, while improving detection accuracy in complex communication environments.</article>","contentLength":1318,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Empirical Analysis Of Heuristic and Approximation Algorithms for the The Mutual-Visibility Problem","url":"https://arxiv.org/abs/2507.01076","date":1751515200,"author":"","guid":182462,"unread":true,"content":"<article>arXiv:2507.01076v1 Announce Type: new \nAbstract: The NP-complete mutual-visibility (MV) problem currently lacks empirical analysis on its practical behaviour despite theoretical studies. This paper addresses this gap by implementing and evaluating three distinct algorithms - a direct greedy heuristic, a hypergraph-based approximation, and a genetic algorithm - on diverse synthetic graph datasets, including those with analytically known $\\mu(G)$ values and general graph models. Our results demonstrate that for smaller graphs, the algorithms consistently achieve MV set sizes aligning with theoretical bounds. However, for larger instances, achieved solution sizes notably diverge from theoretical limits; this, combined with the absence of tight bounds, complicates absolute quality assessment. Nevertheless, validation on known optimal graphs showed the Genetic Algorithm and other heuristics empirically performing best among tested methods.</article>","contentLength":948,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Provenance Tracking in Large-Scale Machine Learning Systems","url":"https://arxiv.org/abs/2507.01075","date":1751515200,"author":"","guid":182463,"unread":true,"content":"<article>arXiv:2507.01075v1 Announce Type: new \nAbstract: As the demand for large scale AI models continues to grow, the optimization of their training to balance computational efficiency, execution time, accuracy and energy consumption represents a critical multidimensional challenge. Achieving this balance requires not only innovative algorithmic techniques and hardware architectures but also comprehensive tools for monitoring, analyzing, and understanding the underlying processes involved in model training and deployment. Provenance data information about the origins, context, and transformations of data and processes has become a key component in this pursuit. By leveraging provenance, researchers and engineers can gain insights into resource usage patterns, identify inefficiencies, and ensure reproducibility and accountability in AI development workflows. For this reason, the question of how distributed resources can be optimally utilized to scale large AI models in an energy efficient manner is a fundamental one. To support this effort, we introduce the yProv4ML library, a tool designed to collect provenance data in JSON format, compliant with the W3C PROV and ProvML standards. yProv4ML focuses on flexibility and extensibility, and enables users to integrate additional data collection tools via plugins. The library is fully integrated with the yProv framework, allowing for higher level pairing in tasks run also through workflow management systems.</article>","contentLength":1468,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rotational Sampling: A Plug-and-Play Encoder for Rotation-Invariant 3D Molecular GNNs","url":"https://arxiv.org/abs/2507.01073","date":1751515200,"author":"","guid":182464,"unread":true,"content":"<article>arXiv:2507.01073v1 Announce Type: new \nAbstract: Graph neural networks (GNNs) have achieved remarkable success in molecular property prediction. However, traditional graph representations struggle to effectively encode the inherent 3D spatial structures of molecules, as molecular orientations in 3D space introduce significant variability, severely limiting model generalization and robustness. Existing approaches primarily focus on rotation-invariant and rotation-equivariant methods. Invariant methods often rely heavily on prior knowledge and lack sufficient generalizability, while equivariant methods suffer from high computational costs. To address these limitations, this paper proposes a novel plug-and-play 3D encoding module leveraging rotational sampling. By computing the expectation over the SO(3) rotational group, the method naturally achieves approximate rotational invariance. Furthermore, by introducing a carefully designed post-alignment strategy, strict invariance can be achieved without compromising performance. Experimental evaluations on the QM9 and C10 Datasets demonstrate superior predictive accuracy, robustness, and generalization performance compared to existing methods. Moreover, the proposed approach maintains low computational complexity and enhanced interpretability, providing a promising direction for efficient and effective handling of 3D molecular information in drug discovery and material design.</article>","contentLength":1443,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Agentic AI in Product Management: A Co-Evolutionary Model","url":"https://arxiv.org/abs/2507.01069","date":1751515200,"author":"","guid":182465,"unread":true,"content":"<article>arXiv:2507.01069v1 Announce Type: new \nAbstract: This study explores agentic AI's transformative role in product management, proposing a conceptual co-evolutionary framework to guide its integration across the product lifecycle. Agentic AI, characterized by autonomy, goal-driven behavior, and multi-agent collaboration, redefines product managers (PMs) as orchestrators of socio-technical ecosystems. Using systems theory, co-evolutionary theory, and human-AI interaction theory, the framework maps agentic AI capabilities in discovery, scoping, business case development, development, testing, and launch. An integrative review of 70+ sources, including case studies from leading tech firms, highlights PMs' evolving roles in AI orchestration, supervision, and strategic alignment. Findings emphasize mutual adaptation between PMs and AI, requiring skills in AI literacy, governance, and systems thinking. Addressing gaps in traditional frameworks, this study provides a foundation for future research and practical implementation to ensure responsible, effective agentic AI integration in software organizations.</article>","contentLength":1115,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Prediction of Freezing of Gait in Parkinsons Disease using Explainable AI and Federated Deep Learning for Wearable Sensors","url":"https://arxiv.org/abs/2507.01068","date":1751515200,"author":"","guid":182466,"unread":true,"content":"<article>arXiv:2507.01068v1 Announce Type: new \nAbstract: This study leverages an Inertial Measurement Unit (IMU) dataset to develop explainable AI methods for the early detection and prediction of Freezing of Gait (FOG), a common symptom in Parkinson's disease. Machine learning models, including CatBoost, XGBoost, and Extra Trees classifiers, are employed to accurately categorize FOG episodes based on relevant clinical features. A Stacking Ensemble model achieves superior performance, surpassing a hybrid bidirectional GRU model and reaching nearly 99% classification accuracy. SHAP interpretability analysis reveals that time (seconds) is the most influential factor in distinguishing gait patterns. Additionally, the proposed FOG prediction framework incorporates federated learning, where models are trained locally on individual devices and aggregated on a central server using a federated averaging approach, utilizing a hybrid Conv1D + LSTM architecture for enhanced predictive capability.</article>","contentLength":992,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evaluation of a Foundational Model and Stochastic Models for Forecasting Sporadic or Spiky Production Outages of High-Performance Machine Learning Services","url":"https://arxiv.org/abs/2507.01067","date":1751515200,"author":"","guid":182467,"unread":true,"content":"<article>arXiv:2507.01067v1 Announce Type: new \nAbstract: Time series forecasting models have diverse real world applications (e.g., from electricity metrics to software workload). Latest foundational models trained for time series forecasting show strengths (e.g., for long sequences and in zero-shot settings). However, foundational model was not yet used for forecasting rare, spiky events, i.e., a challenging target because those are a corner case of extreme events. In this paper, we optimize a state-of-the-art foundational model to forecast sporadic or spiky production outages of high-performance machine learning services powering billions of client devices. We evaluate the forecasting errors of the foundational model compared with classical stochastic forecasting models (e.g., moving average and autoregressive). The analysis helps us understand how each of the evaluated models performs for the sporadic or spiky events. For example, it identifies the key patterns in the target data that are well tracked by the foundational model vs. each of the stochastic models. We use the models with optimal parameters to estimate a year-long outage statistics of a particular root cause with less than 6% value errors.</article>","contentLength":1215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Embedding-based Retrieval in Multimodal Content Moderation","url":"https://arxiv.org/abs/2507.01066","date":1751515200,"author":"","guid":182468,"unread":true,"content":"<article>arXiv:2507.01066v1 Announce Type: new \nAbstract: Video understanding plays a fundamental role for content moderation on short video platforms, enabling the detection of inappropriate content. While classification remains the dominant approach for content moderation, it often struggles in scenarios requiring rapid and cost-efficient responses, such as trend adaptation and urgent escalations. To address this issue, we introduce an Embedding-Based Retrieval (EBR) method designed to complement traditional classification approaches. We first leverage a Supervised Contrastive Learning (SCL) framework to train a suite of foundation embedding models, including both single-modal and multi-modal architectures. Our models demonstrate superior performance over established contrastive learning methods such as CLIP and MoCo. Building on these embedding models, we design and implement the embedding-based retrieval system that integrates embedding generation and video retrieval to enable efficient and effective trend handling. Comprehensive offline experiments on 25 diverse emerging trends show that EBR improves ROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further online experiments reveal that EBR increases action rates by 10.32% and reduces operational costs by over 80%, while also enhancing interpretability and flexibility compared to classification-based solutions.</article>","contentLength":1386,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is It Safe To Learn And Share? On Psychological Safety and Social Learning in (Agile) Communities of Practice","url":"https://arxiv.org/abs/2507.01065","date":1751515200,"author":"","guid":182469,"unread":true,"content":"<article>arXiv:2507.01065v1 Announce Type: new \nAbstract: As hybrid, distributed, and asynchronous work models become more prevalent, continuous learning in Agile Software Development (ASD) gains renewed importance. Communities of Practice (CoPs) are increasingly adopted to support social learning beyond formal education, often relying on virtual communication. Psychological safety, a prerequisite for effective learning, remains insufficiently understood in these settings. This mixed-methods study investigates psychological safety within Agile CoPs through survey data from 143 participants. Results indicate that psychological safety is significantly lower in online interactions compared to face-to-face settings. Moreover, low psychological safety reduces participants' intent to continue contributing and avoidance of interpersonal risk. No significant differences emerged based on gender, community seniority, or content creation activity. However, differences by role and age group suggest potential generational or role-related effects. Thematic analysis revealed exclusionary behavior, negative interaction patterns, and hostility as primary threats to psychological safety, often reinforced by tribalism and specific community dynamics. Suggested interventions include establishing explicit norms, structured facilitation, and active moderation. The findings were validated through member checking with 30 participants. This study provides a comparative perspective on interaction modalities and offers practical guidance for organizers seeking to cultivate inclusive, high-impact CoPs and similarly structured virtual or hybrid work environments.</article>","contentLength":1653,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FAIR-MATCH: A Multi-Objective Framework for Bias Mitigation in Reciprocal Dating Recommendations","url":"https://arxiv.org/abs/2507.01063","date":1751515200,"author":"","guid":182470,"unread":true,"content":"<article>arXiv:2507.01063v1 Announce Type: new \nAbstract: Online dating platforms have fundamentally transformed the formation of romantic relationships, with millions of users worldwide relying on algorithmic matching systems to find compatible partners. However, current recommendation systems in dating applications suffer from significant algorithmic deficiencies, including but not limited to popularity bias, filter bubble effects, and inadequate reciprocity modeling that limit effectiveness and introduce harmful biases. This research integrates foundational work with recent empirical findings to deliver a detailed analysis of dating app recommendation systems, highlighting key issues and suggesting research-backed solutions. Through analysis of reciprocal recommendation frameworks, fairness evaluation metrics, and industry implementations, we demonstrate that current systems achieve modest performance with collaborative filtering reaching 25.1\\% while reciprocal methods achieve 28.7\\%. Our proposed mathematical framework addresses these limitations through enhanced similarity measures, multi-objective optimization, and fairness-aware algorithms that maintain competitive accuracy while improving demographic representation to reduce algorithmic bias.</article>","contentLength":1262,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quantifying Student Success with Generative AI: A Monte Carlo Simulation Informed by Systematic Review","url":"https://arxiv.org/abs/2507.01062","date":1751515200,"author":"","guid":182471,"unread":true,"content":"<article>arXiv:2507.01062v1 Announce Type: new \nAbstract: The exponential development of generative artificial intelligence (GenAI) technologies like ChatGPT has raised increasing curiosity about their use in higher education, specifically with respect to how students view them, make use of them, and the implications for learning outcomes. This paper employs a hybrid methodological approach involving a systematic literature review and simulation-based modeling to explore student perceptions of GenAI use in the context of higher education. A total of nineteen empirical articles from 2023 through 2025 were selected from the PRISMA-based search targeting the Scopus database. Synthesis of emerging patterns from the literature was achieved by thematic categorization. Six of these had enough quantitative information, i.e., item-level means and standard deviations, to permit probabilistic modeling. One dataset, from the resulting subset, was itself selected as a representative case with which to illustrate inverse-variance weighting by Monte Carlo simulation, by virtue of its well-designed Likert scale format and thematic alignment with the use of computing systems by the researcher.\n  The simulation provided a composite \"Success Score\" forecasting the strength of the relationship between student perceptions and learning achievements. Findings reveal that attitude factors concerned with usability and real-world usefulness are significantly better predictors of positive learning achievement than affective or trust-based factors. Such an interdisciplinary perspective provides a unique means of linking thematic results with predictive modelling, resonating with longstanding controversies about the proper use of GenAI tools within the university.</article>","contentLength":1756,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Epitome: Pioneering an Experimental Platform for AI-Social Science Integration","url":"https://arxiv.org/abs/2507.01061","date":1751515200,"author":"","guid":182472,"unread":true,"content":"<article>arXiv:2507.01061v1 Announce Type: new \nAbstract: The integration of Large Language Models (LLMs) into social science experiments represents a transformative approach to understanding human-AI interactions and their societal impacts. We introduce Epitome, the world's first open experimental platform dedicated to the deep integration of artificial intelligence and social science. Rooted in theoretical foundations from management, communication studies, sociology, psychology, and ethics, Epitome focuses on the interactive impacts of AI on individuals, organizations, and society during its real-world deployment. It constructs a theoretical support system through cross-disciplinary experiments. The platform offers a one-stop comprehensive experimental solution spanning \"foundation models-complex application development-user feedback\" through seven core modules, while embedding the classical \"control-comparison-comparative causal logic\" of social science experiments into multilevel human-computer interaction environments, including dialogues, group chats, and multi-agent virtual scenarios. With its canvas-style, user-friendly interface, Epitome enables researchers to easily design and run complex experimental scenarios, facilitating systematic investigations into the social impacts of AI and exploration of integrated solutions.To demonstrate its capabilities, we replicated three seminal social science experiments involving LLMs, showcasing Epitome's potential to streamline complex experimental designs and produce robust results, suitable for publishing in the top selective journals. Our findings highlight the platform's utility in enhancing the efficiency and quality of human-AI interactions, providing valuable insights into the societal implications of AI technologies. Epitome thus offers a powerful tool for advancing interdisciplinary research at the intersection of AI and social science, with potential applications in policy-making, ...</article>","contentLength":1967,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Optimizing Conversational Product Recommendation via Reinforcement Learning","url":"https://arxiv.org/abs/2507.01060","date":1751515200,"author":"","guid":182473,"unread":true,"content":"<article>arXiv:2507.01060v1 Announce Type: new \nAbstract: We propose a reinforcement learning-based approach to optimize conversational strategies for product recommendation across diverse industries. As organizations increasingly adopt intelligent agents to support sales and service operations, the effectiveness of a conversation hinges not only on what is recommended but how and when recommendations are delivered. We explore a methodology where agentic systems learn optimal dialogue policies through feedback-driven reinforcement learning. By mining aggregate behavioral patterns and conversion outcomes, our approach enables agents to refine talk tracks that drive higher engagement and product uptake, while adhering to contextual and regulatory constraints. We outline the conceptual framework, highlight key innovations, and discuss the implications for scalable, personalized recommendation in enterprise environments.</article>","contentLength":921,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Automated Vehicles Should be Connected with Natural Language","url":"https://arxiv.org/abs/2507.01059","date":1751515200,"author":"","guid":182474,"unread":true,"content":"<article>arXiv:2507.01059v1 Announce Type: new \nAbstract: Multi-agent collaborative driving promises improvements in traffic safety and efficiency through collective perception and decision making. However, existing communication media -- including raw sensor data, neural network features, and perception results -- suffer limitations in bandwidth efficiency, information completeness, and agent interoperability. Moreover, traditional approaches have largely ignored decision-level fusion, neglecting critical dimensions of collaborative driving. In this paper we argue that addressing these challenges requires a transition from purely perception-oriented data exchanges to explicit intent and reasoning communication using natural language. Natural language balances semantic density and communication bandwidth, adapts flexibly to real-time conditions, and bridges heterogeneous agent platforms. By enabling the direct communication of intentions, rationales, and decisions, it transforms collaborative driving from reactive perception-data sharing into proactive coordination, advancing safety, efficiency, and transparency in intelligent transportation systems.</article>","contentLength":1159,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Data Science Approach to Calcutta High Court Judgments: An Efficient LLM and RAG-powered Framework for Summarization and Similar Cases Retrieval","url":"https://arxiv.org/abs/2507.01058","date":1751515200,"author":"","guid":182475,"unread":true,"content":"<article>arXiv:2507.01058v1 Announce Type: new \nAbstract: The judiciary, as one of democracy's three pillars, is dealing with a rising amount of legal issues, needing careful use of judicial resources. This research presents a complex framework that leverages Data Science methodologies, notably Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) techniques, to improve the efficiency of analyzing Calcutta High Court verdicts. Our framework focuses on two key aspects: first, the creation of a robust summarization mechanism that distills complex legal texts into concise and coherent summaries; and second, the development of an intelligent system for retrieving similar cases, which will assist legal professionals in research and decision making. By fine-tuning the Pegasus model using case head note summaries, we achieve significant improvements in the summarization of legal cases. Our two-step summarizing technique preserves crucial legal contexts, allowing for the production of a comprehensive vector database for RAG. The RAG-powered framework efficiently retrieves similar cases in response to user queries, offering thorough overviews and summaries. This technique not only improves legal research efficiency, but it also helps legal professionals and students easily acquire and grasp key legal information, benefiting the overall legal scenario.</article>","contentLength":1370,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Loop2Net: Data-Driven Generation and Optimization of Airfoil CFD Meshes from Sparse Boundary Coordinates","url":"https://arxiv.org/abs/2507.01057","date":1751515200,"author":"","guid":182476,"unread":true,"content":"<article>arXiv:2507.01057v1 Announce Type: new \nAbstract: In this study, an innovative intelligent optimization system for mesh quality is proposed, which is based on a deep convolutional neural network architecture, to achieve mesh generation and optimization. The core of the study is the Loop2Net generator and loss function, it predicts the mesh based on the given wing coordinates. And the model's performance is continuously optimised by two key loss functions during the training. Then discipline by adding penalties, the goal of mesh generation was finally reached.</article>","contentLength":564,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evaluating Pavement Deterioration Rates Due to Flooding Events Using Explainable AI","url":"https://arxiv.org/abs/2507.01056","date":1751515200,"author":"","guid":182477,"unread":true,"content":"<article>arXiv:2507.01056v1 Announce Type: new \nAbstract: Flooding can damage pavement infrastructure significantly, causing both immediate and long-term structural and functional issues. This research investigates how flooding events affect pavement deterioration, specifically focusing on measuring pavement roughness by the International Roughness Index (IRI). To quantify these effects, we utilized 20 years of pavement condition data from TxDOT's PMIS database, which is integrated with flood event data, including duration and spatial extent. Statistical analyses were performed to compare IRI values before and after flooding and to calculate the deterioration rates influenced by flood exposure. Moreover, we applied Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME), to assess the impact of flooding on pavement performance. The results demonstrate that flood-affected pavements experience a more rapid increase in roughness compared to non-flooded sections. These findings emphasize the need for proactive flood mitigation strategies, including improved drainage systems, flood-resistant materials, and preventative maintenance, to enhance pavement resilience in vulnerable regions.</article>","contentLength":1291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science","url":"https://arxiv.org/abs/2507.01054","date":1751515200,"author":"","guid":182478,"unread":true,"content":"<article>arXiv:2507.01054v1 Announce Type: new \nAbstract: Recent advances in materials discovery have been driven by structure-based models, particularly those using crystal graphs. While effective for computational datasets, these models are impractical for real-world applications where atomic structures are often unknown or difficult to obtain. We propose a scalable multimodal framework that learns directly from elemental composition and X-ray diffraction (XRD) -- two of the more available modalities in experimental workflows without requiring crystal structure input. Our architecture integrates modality-specific encoders with a cross-attention fusion module and is trained on the 5-million-sample Alexandria dataset. We present masked XRD modeling (MXM), and apply MXM and contrastive alignment as self-supervised pretraining strategies. Pretraining yields faster convergence (up to 4.2x speedup) and improves both accuracy and representation quality. We further demonstrate that multimodal performance scales more favorably with dataset size than unimodal baselines, with gains compounding at larger data regimes. Our results establish a path toward structure-free, experimentally grounded foundation models for materials science.</article>","contentLength":1233,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis","url":"https://arxiv.org/abs/2507.01053","date":1751515200,"author":"","guid":182479,"unread":true,"content":"<article>arXiv:2507.01053v1 Announce Type: new \nAbstract: As ever-larger clinical datasets become available, they have the potential to unlock unprecedented opportunities for medical research. Foremost among them is Medical Information Mart for Intensive Care (MIMIC-IV), the world's largest open-source EHR database. However, the inherent complexity of these datasets, particularly the need for sophisticated querying skills and the need to understand the underlying clinical settings, often presents a significant barrier to their effective use. M3 lowers the technical barrier to understanding and querying MIMIC-IV data. With a single command it retrieves MIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the hosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers converse with the database in plain English. Ask a clinical question in natural language; M3 uses a language model to translate it into SQL, executes the query against the MIMIC-IV dataset, and returns structured results alongside the underlying query for verifiability and reproducibility. Demonstrations show that minutes of dialogue with M3 yield the kind of nuanced cohort analyses that once demanded hours of handcrafted SQL and relied on understanding the complexities of clinical workflows. By simplifying access, M3 invites the broader research community to mine clinical critical-care data and accelerates the translation of raw records into actionable insight.</article>","contentLength":1474,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Long-Sequence Memory with Temporal Kernels and Dense Hopfield Functionals","url":"https://arxiv.org/abs/2507.01052","date":1751515200,"author":"","guid":182480,"unread":true,"content":"<article>arXiv:2507.01052v1 Announce Type: new \nAbstract: In this study we introduce a novel energy functional for long-sequence memory, building upon the framework of dense Hopfield networks which achieves exponential storage capacity through higher-order interactions. Building upon earlier work on long-sequence Hopfield memory models, we propose a temporal kernal $K(m, k)$ to incorporate temporal dependencies, enabling efficient sequential retrieval of patterns over extended sequences. We demonstrate the successful application of this technique for the storage and sequential retrieval of movies frames which are well suited for this because of the high dimensional vectors that make up each frame creating enough variation between even sequential frames in the high dimensional space. The technique has applications in modern transformer architectures, including efficient long-sequence modeling, memory augmentation, improved attention with temporal bias, and enhanced handling of long-term dependencies in time-series data. Our model offers a promising approach to address the limitations of transformers in long-context tasks, with potential implications for natural language processing, forecasting, and beyond.</article>","contentLength":1215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Can AI be Consentful?","url":"https://arxiv.org/abs/2507.01051","date":1751515200,"author":"","guid":182481,"unread":true,"content":"<article>arXiv:2507.01051v1 Announce Type: new \nAbstract: The evolution of generative AI systems exposes the challenges of traditional legal and ethical frameworks built around consent. This chapter examines how the conventional notion of consent, while fundamental to data protection and privacy rights, proves insufficient in addressing the implications of AI-generated content derived from personal data. Through legal and ethical analysis, we show that while individuals can consent to the initial use of their data for AI training, they cannot meaningfully consent to the numerous potential outputs their data might enable or the extent to which the output is used or distributed. We identify three fundamental challenges: the scope problem, the temporality problem, and the autonomy trap, which collectively create what we term a ''consent gap'' in AI systems and their surrounding ecosystem. We argue that current legal frameworks inadequately address these emerging challenges, particularly regarding individual autonomy, identity rights, and social responsibility, especially in cases where AI-generated content creates new forms of personal representation beyond the scope of the original consent. By examining how these consent limitations intersect with broader principles of responsible AI (including fairness, transparency, accountability, and autonomy) we demonstrate the need to evolve ethical and legal approaches to consent.</article>","contentLength":1433,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Text Detoxification: Data Efficiency, Semantic Preservation and Model Generalization","url":"https://arxiv.org/abs/2507.01050","date":1751515200,"author":"","guid":182482,"unread":true,"content":"<article>arXiv:2507.01050v1 Announce Type: new \nAbstract: The widespread dissemination of toxic content on social media poses a serious threat to both online environments and public discourse, highlighting the urgent need for detoxification methods that effectively remove toxicity while preserving the original semantics. However, existing approaches often struggle to simultaneously achieve strong detoxification performance, semantic preservation, and robustness to out-of-distribution data. Moreover, they typically rely on costly, manually annotated parallel corpora while showing poor data efficiency. To address these challenges, we propose a two-stage training framework that jointly optimizes for data efficiency, semantic preservation, and model generalization. We first perform supervised fine-tuning on a small set of high-quality, filtered parallel data to establish a strong initialization. Then, we leverage unlabeled toxic inputs and a custom-designed reward model to train the LLM using Group Relative Policy Optimization. Experimental results demonstrate that our method effectively mitigates the trade-offs faced by previous work, achieving state-of-the-art performance with improved generalization and significantly reduced dependence on annotated data. Our code is available at: https://anonymous.4open.science/r/Detoxification-of-Text-725F/</article>","contentLength":1353,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cohort Retrieval using Dense Passage Retrieval","url":"https://arxiv.org/abs/2507.01049","date":1751515200,"author":"","guid":182483,"unread":true,"content":"<article>arXiv:2507.01049v1 Announce Type: new \nAbstract: Patient cohort retrieval is a pivotal task in medical research and clinical practice, enabling the identification of specific patient groups from extensive electronic health records (EHRs). In this work, we address the challenge of cohort retrieval in the echocardiography domain by applying Dense Passage Retrieval (DPR), a prominent methodology in semantic search. We propose a systematic approach to transform an echocardiographic EHR dataset of unstructured nature into a Query-Passage dataset, framing the problem as a Cohort Retrieval task. Additionally, we design and implement evaluation metrics inspired by real-world clinical scenarios to rigorously test the models across diverse retrieval tasks. Furthermore, we present a custom-trained DPR embedding model that demonstrates superior performance compared to traditional and off-the-shelf SOTA methods.To our knowledge, this is the first work to apply DPR for patient cohort retrieval in the echocardiography domain, establishing a framework that can be adapted to other medical domains.</article>","contentLength":1097,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"3W Dataset 2.0.0: a realistic and public dataset with rare undesirable real events in oil wells","url":"https://arxiv.org/abs/2507.01048","date":1751515200,"author":"","guid":182484,"unread":true,"content":"<article>arXiv:2507.01048v1 Announce Type: new \nAbstract: In the oil industry, undesirable events in oil wells can cause economic losses, environmental accidents, and human casualties. Solutions based on Artificial Intelligence and Machine Learning for Early Detection of such events have proven valuable for diverse applications across industries. In 2019, recognizing the importance and the lack of public datasets related to undesirable events in oil wells, Petrobras developed and publicly released the first version of the 3W Dataset, which is essentially a set of Multivariate Time Series labeled by experts. Since then, the 3W Dataset has been developed collaboratively and has become a foundational reference for numerous works in the field. This data article describes the current publicly available version of the 3W Dataset, which contains structural modifications and additional labeled data. The detailed description provided encourages and supports the 3W community and new 3W users to improve previous published results and to develop new robust methodologies, digital products and services capable of detecting undesirable events in oil wells with enough anticipation to enable corrective or mitigating actions.</article>","contentLength":1218,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Variational Digital Twins","url":"https://arxiv.org/abs/2507.01047","date":1751515200,"author":"","guid":182485,"unread":true,"content":"<article>arXiv:2507.01047v1 Announce Type: new \nAbstract: While digital twins (DT) hold promise for providing real-time insights into complex energy assets, much of the current literature either does not offer a clear framework for information exchange between the model and the asset, lacks key features needed for real-time implementation, or gives limited attention to model uncertainty. Here, we aim to solve these gaps by proposing a variational digital twin (VDT) framework that augments standard neural architectures with a single Bayesian output layer. This lightweight addition, along with a novel VDT updating algorithm, lets a twin update in seconds on commodity GPUs while producing calibrated uncertainty bounds that can inform experiment design, control algorithms, and model reliability. The VDT is evaluated on four energy-sector problems. For critical-heat-flux prediction, uncertainty-driven active learning reaches R2 = 0.98 using 47 % fewer experiments and one-third the training time of random sampling. A three-year renewable-generation twin maintains R2 &gt; 0.95 for solar output and curbs error growth for volatile wind forecasts via monthly updates that process only one month of data at a time. A nuclear reactor transient cooldown twin reconstructs thermocouple signals with R2 &gt; 0.99 and preserves accuracy after 50 % sensor loss, demonstrating robustness to degraded instrumentation. Finally, a physics-informed Li-ion battery twin, retrained after every ten discharges, lowers voltage mean-squared error by an order of magnitude relative to the best static model while adapting its credible intervals as the cell approaches end-of-life. These results demonstrate that combining modest Bayesian augmentation with efficient update schemes turns conventional surrogates into uncertainty-aware, data-efficient, and computationally tractable DTs, paving the way for dependable models across industrial and scientific energy systems.</article>","contentLength":1946,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals","url":"https://arxiv.org/abs/2507.01045","date":1751515200,"author":"","guid":182486,"unread":true,"content":"<article>arXiv:2507.01045v1 Announce Type: new \nAbstract: Cardiac biosignals, such as electrocardiograms (ECG) and photoplethysmograms (PPG), are of paramount importance for the diagnosis, prevention, and management of cardiovascular diseases, and have been extensively used in a variety of clinical tasks. Conventional deep learning approaches for analyzing these signals typically rely on homogeneous datasets and static bespoke models, limiting their robustness and generalizability across diverse clinical settings and acquisition protocols. In this study, we present a cardiac sensing foundation model (CSFM) that leverages advanced transformer architectures and a generative, masked pretraining strategy to learn unified representations from vast, heterogeneous health records. Our model is pretrained on an innovative multi-modal integration of data from multiple large-scale datasets (including MIMIC-III-WDB, MIMIC-IV-ECG, and CODE), comprising cardiac signals and the corresponding clinical or machine-generated text reports from approximately 1.7 million individuals. We demonstrate that the embeddings derived from our CSFM not only serve as effective feature extractors across diverse cardiac sensing scenarios, but also enable seamless transfer learning across varying input configurations and sensor modalities. Extensive evaluations across diagnostic tasks, demographic information recognition, vital sign measurement, clinical outcome prediction, and ECG question answering reveal that CSFM consistently outperforms traditional one-modal-one-task approaches. Notably, CSFM exhibits robust performance across multiple ECG lead configurations from standard 12-lead systems to single-lead setups, and in scenarios where only ECG, only PPG, or a combination thereof is available. These findings highlight the potential of CSFM as a versatile and scalable solution, for comprehensive cardiac monitoring.</article>","contentLength":1906,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Data Classification with Dynamically Growing and Shrinking Neural Networks","url":"https://arxiv.org/abs/2507.01043","date":1751515200,"author":"","guid":182487,"unread":true,"content":"<article>arXiv:2507.01043v1 Announce Type: new \nAbstract: The issue of data-driven neural network model construction is one of the core problems in the domain of Artificial Intelligence. A standard approach assumes a fixed architecture with trainable weights. A conceptually more advanced assumption is that we not only train the weights, but also find out the optimal model architecture. We present a new method that realizes just that. This article is an extended version of our conference paper titled \"Dynamic Growing and Shrinking of Neural Networks with Monte Carlo Tree Search [26]\". In the paper, we show in detail how to create a neural network with a procedure that allows dynamic shrinking and growing of the model while it is being trained. The decision-making mechanism for the architectural design is governed by a Monte Carlo tree search procedure which simulates network behavior and allows to compare several candidate architecture changes to choose the best one. The proposed method was validated using both visual and time series datasets, demonstrating its particular effectiveness in multivariate time series classification. This is attributed to the architecture's ability to adapt dynamically, allowing independent modifications for each time series. The approach is supplemented by Python source code for reproducibility. Experimental evaluations in visual pattern and multivariate time series classification tasks revealed highly promising performance, underscoring the method's robustness and adaptability.</article>","contentLength":1523,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Can Argus Judge Them All? Comparing VLMs Across Domains","url":"https://arxiv.org/abs/2507.01042","date":1751515200,"author":"","guid":182488,"unread":true,"content":"<article>arXiv:2507.01042v1 Announce Type: new \nAbstract: Vision-Language Models (VLMs) are advancing multimodal AI, yet their performance consistency across tasks is underexamined. We benchmark CLIP, BLIP, and LXMERT across diverse datasets spanning retrieval, captioning, and reasoning. Our evaluation includes task accuracy, generation quality, efficiency, and a novel Cross-Dataset Consistency (CDC) metric. CLIP shows strongest generalization (CDC: 0.92), BLIP excels on curated data, and LXMERT leads in structured reasoning. These results expose trade-offs between generalization and specialization, informing industrial deployment of VLMs and guiding development toward robust, task-flexible architectures.</article>","contentLength":705,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fast AI Model Splitting over Edge Networks","url":"https://arxiv.org/abs/2507.01041","date":1751515200,"author":"","guid":182489,"unread":true,"content":"<article>arXiv:2507.01041v1 Announce Type: new \nAbstract: Split learning (SL) has emerged as a computationally efficient approach for artificial intelligence (AI) model training, which can alleviate device-side computational workloads. However, complex AI model architectures pose high computational complexity to obtain the optimal model splitting. In this paper, we represent an arbitrary AI model as a directed acyclic graph (DAG), and then reformulate the optimal model splitting problem as a minimum s-t cut search problem. To solve the problem, we propose a fast DAG-based model splitting algorithm, which restructures the DAG to enable the optimal model splitting identification via a maximum flow method. Theoretical analysis indicates that the proposed algorithm is optimal. Furthermore, considering AI models with block structures, we propose a block-wise model splitting algorithm to reduce computational complexity. The algorithm abstracts each block, i.e., a component consisting of multiple layers, into a single vertex, thereby obtaining the optimal model splitting via a simplified DAG. Extensive experimental results demonstrate that the proposed algorithms can determine the optimal model splitting within milliseconds, as well as reduce training delay by 24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art benchmarks.</article>","contentLength":1351,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fast Clifford Neural Layers","url":"https://arxiv.org/abs/2507.01040","date":1751515200,"author":"","guid":182490,"unread":true,"content":"<article>arXiv:2507.01040v1 Announce Type: new \nAbstract: Clifford Neural Layers improve PDE modeling by introducing Clifford Algebra into neural networks. In this project we focus on optimizing the inference of 2/3D Clifford convolutional layers and multivector activation layers for one core CPU performance.\n  Overall, by testing on a real network block involving Clifford convolutional layers and multivector activation layers, we observe that our implementation is 30% faster than standard PyTorch implementation in relatively large data + network size (&gt;L2 cache).\n  We open source our code base at https://github.com/egretwAlker/c-opt-clifford-layers</article>","contentLength":648,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"On-Policy Optimization of ANFIS Policies Using Proximal Policy Optimization","url":"https://arxiv.org/abs/2507.01039","date":1751515200,"author":"","guid":182491,"unread":true,"content":"<article>arXiv:2507.01039v1 Announce Type: new \nAbstract: We propose a reinforcement learning (RL) approach for training neuro-fuzzy controllers using Proximal Policy Optimization (PPO). Building on prior work that applied Deep Q-Learning to Adaptive Neuro-Fuzzy Inference Systems (ANFIS), our method replaces the off-policy value-based framework with a stable on-policy actor-critic loop. We evaluate this approach in the CartPole-v1 environment using multiple random seeds and compare its learning performance against ANFIS-Deep Q-Network (DQN) baselines. It was found that PPO-trained fuzzy agents achieved a mean return of 500 +/- 0 on CartPole-v1 after 20000 updates, showcasing less variance than prior DQN-based methods during training and overall faster convergence. These findings suggest that PPO offers a promising pathway for training explainable neuro-fuzzy controllers in reinforcement learning tasks.</article>","contentLength":906,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cross-Attention Message-Passing Transformers for Code-Agnostic Decoding in 6G Networks","url":"https://arxiv.org/abs/2507.01038","date":1751515200,"author":"","guid":182492,"unread":true,"content":"<article>arXiv:2507.01038v1 Announce Type: new \nAbstract: Channel coding for 6G networks is expected to support a wide range of requirements arising from heterogeneous communication scenarios. These demands challenge traditional code-specific decoders, which lack the flexibility and scalability required for next-generation systems. To tackle this problem, we propose an AI-native foundation model for unified and code-agnostic decoding based on the transformer architecture. We first introduce a cross-attention message-passing transformer (CrossMPT). CrossMPT employs two masked cross-attention blocks that iteratively update two distinct input representations-magnitude and syndrome vectors-allowing the model to effectively learn the decoding problem. Notably, our CrossMPT has achieved state-of-the-art decoding performance among single neural decoders. Building on this, we develop foundation CrossMPT (FCrossMPT) by making the architecture invariant to code length, rate, and class, allowing a single trained model to decode a broad range of codes without retraining. To further enhance decoding performance, particularly for short blocklength codes, we propose CrossMPT ensemble decoder (CrossED), an ensemble decoder composed of multiple parallel CrossMPT blocks employing different parity-check matrices. This architecture can also serve as a foundation model, showing strong generalization across diverse code types. Overall, the proposed AI-native code-agnostic decoder offers flexibility, scalability, and high performance, presenting a promising direction to channel coding for 6G networks.</article>","contentLength":1596,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learning to Segment for Vehicle Routing Problems","url":"https://arxiv.org/abs/2507.01037","date":1751515200,"author":"","guid":182493,"unread":true,"content":"<article>arXiv:2507.01037v1 Announce Type: new \nAbstract: Iterative search heuristics are widely recognized as state-of-the-art for solving Vehicle Routing Problems (VRPs). In this work, we identify and exploit a critical observation: within these solvers, a large portion of the solution remains stable, i.e., unchanged across search iterations, causing redundant computations, especially for large-scale VRPs with long subtours. To address this, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA) decomposition technique to accelerate iterative solvers. Specifically, FSTA preserves stable solution segments during the search, aggregates nodes within each segment into fixed hypernodes, and focuses the search only on unstable portions. Yet, a key challenge lies in identifying which segments should be aggregated by FSTA. To this end, we then introduce Learning-to-Segment (L2Seg), a novel neural framework to intelligently differentiate potentially stable and unstable portions for FSTA decomposition. We present three L2Seg variants: non-autoregressive (globally comprehensive but locally indiscriminate), autoregressive (locally refined but globally deficient), and their synergy, with bespoke training and inference strategies. Empirical results on CVRP and VRPTW suggest that L2Seg accelerates state-of-the-art iterative solvers by up to 7x. Additionally, we provide in-depth analysis showing NAR and AR synergy achieves best performance by combining their complementary strengths. Notably, L2Seg is a flexible framework that is compatible with traditional, learning-based, and hybrid solvers, while supporting a broad class of VRPs.</article>","contentLength":1652,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Systemic Constraints of Undecidability","url":"https://arxiv.org/abs/2507.01036","date":1751515200,"author":"","guid":182494,"unread":true,"content":"<article>arXiv:2507.01036v1 Announce Type: new \nAbstract: This paper presents a theory of systemic undecidability, reframing incomputability as a structural property of systems rather than a localized feature of specific functions or problems. We define a notion of causal embedding and prove a closure principle: any subsystem that participates functionally in the computation of an undecidable system inherits its undecidability. This result positions undecidability as a pervasive constraint on prediction, modeling, and epistemic access in both natural and artificial systems. Our framework disarms oracle mimicry and challenges the view that computational limits can be circumvented through architectural innovation. By generalizing classical results into a dynamic systems context, this work augments the logical trajectory of G\\\"odel, Turing, and Chaitin, offering a new perspective of the topology of computability and its interrelation to the boundaries of scientific knowledge.</article>","contentLength":978,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Research on Low-Latency Inference and Training Efficiency Optimization for Graph Neural Network and Large Language Model-Based Recommendation Systems","url":"https://arxiv.org/abs/2507.01035","date":1751515200,"author":"","guid":182495,"unread":true,"content":"<article>arXiv:2507.01035v1 Announce Type: new \nAbstract: The incessant advent of online services demands high speed and efficient recommender systems (ReS) that can maintain real-time performance along with processing very complex user-item interactions. The present study, therefore, considers computational bottlenecks involved in hybrid Graph Neural Network (GNN) and Large Language Model (LLM)-based ReS with the aim optimizing their inference latency and training efficiency. An extensive methodology was used: hybrid GNN-LLM integrated architecture-optimization strategies(quantization, LoRA, distillation)-hardware acceleration (FPGA, DeepSpeed)-all under R 4.4.2. Experimental improvements were significant, with the optimal Hybrid + FPGA + DeepSpeed configuration reaching 13.6% more accuracy (NDCG@10: 0.75) at 40-60ms of latency, while LoRA brought down training time by 66% (3.8 hours) in comparison to the non-optimized baseline. Irrespective of domain, such as accuracy or efficiency, it can be established that hardware-software co-design and parameter-efficient tuning permit hybrid models to outperform GNN or LLM approaches implemented independently. It recommends the use of FPGA as well as LoRA for real-time deployment. Future work should involve federated learning along with advanced fusion architectures for better scalability and privacy preservation. Thus, this research marks the fundamental groundwork concerning next-generation ReS balancing low-latency response with cutting-edge personalization.</article>","contentLength":1518,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Data-driven Insights for Informed Decision-Making: Applying LSTM Networks for Robust Electricity Forecasting in Libya","url":"https://arxiv.org/abs/2507.01034","date":1751515200,"author":"","guid":182496,"unread":true,"content":"<article>arXiv:2507.01034v1 Announce Type: new \nAbstract: Accurate electricity forecasting is crucial for grid stability and energy planning, especially in Benghazi, Libya, where frequent load shedding, generation deficits, and infrastructure limitations persist. This study proposes a data-driven approach to forecast electricity load, generation, and deficits for 2025 using historical data from 2019 (a year marked by instability) and 2023 (a more stable year). Multiple time series models were applied, including ARIMA, seasonal ARIMA, dynamic regression ARIMA, exponential smoothing, extreme gradient boosting, and Long Short-Term Memory (LSTM) neural networks. The dataset was enhanced through missing value imputation, outlier smoothing, and log transformation. Performance was assessed using mean squared error, root mean squared error, mean absolute error, and mean absolute percentage error. LSTM outperformed all other models, showing strong capabilities in modeling non-stationary and seasonal patterns. A key contribution of this work is an optimized LSTM framework that integrates exogenous factors such as temperature and humidity, offering robust performance in forecasting multiple electricity indicators. These results provide practical insights for policymakers and grid operators to enable proactive load management and resource planning in data-scarce, volatile regions.</article>","contentLength":1382,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An Uncertainty-Aware Dynamic Decision Framework for Progressive Multi-Omics Integration in Classification Tasks","url":"https://arxiv.org/abs/2507.01032","date":1751515200,"author":"","guid":182497,"unread":true,"content":"<article>arXiv:2507.01032v1 Announce Type: new \nAbstract: Background and Objective: High-throughput multi-omics technologies have proven invaluable for elucidating disease mechanisms and enabling early diagnosis. However, the high cost of multi-omics profiling imposes a significant economic burden, with over reliance on full omics data potentially leading to unnecessary resource consumption. To address these issues, we propose an uncertainty-aware, multi-view dynamic decision framework for omics data classification that aims to achieve high diagnostic accuracy while minimizing testing costs. Methodology: At the single-omics level, we refine the activation functions of neural networks to generate Dirichlet distribution parameters, utilizing subjective logic to quantify both the belief masses and uncertainty mass of classification results. Belief mass reflects the support of a specific omics modality for a disease class, while the uncertainty parameter captures limitations in data quality and model discriminability, providing a more trustworthy basis for decision-making. At the multi omics level, we employ a fusion strategy based on Dempster-Shafer theory to integrate heterogeneous modalities, leveraging their complementarity to boost diagnostic accuracy and robustness. A dynamic decision mechanism is then applied that omics data are incrementally introduced for each patient until either all data sources are utilized or the model confidence exceeds a predefined threshold, potentially before all data sources are utilized. Results and Conclusion: We evaluate our approach on four benchmark multi-omics datasets, ROSMAP, LGG, BRCA, and KIPAN. In three datasets, over 50% of cases achieved accurate classification using a single omics modality, effectively reducing redundant testing. Meanwhile, our method maintains diagnostic performance comparable to full-omics models and preserves essential biological insights.</article>","contentLength":1927,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PyTorch-based Geometric Learning with Non-CUDA Processing Units: Experiences from Intel Gaudi-v2 HPUs","url":"https://arxiv.org/abs/2507.01031","date":1751515200,"author":"","guid":182498,"unread":true,"content":"<article>arXiv:2507.01031v1 Announce Type: new \nAbstract: Geometric learning has emerged as a powerful paradigm for modeling non-Euclidean data, especially graph-structured ones, with applications spanning social networks, molecular structures, knowledge graphs, and recommender systems. While Nvidia's CUDA-enabled graphics processing units (GPUs) largely dominate the hardware landscape, emerging accelerators such as Intel's Gaudi Habana Processing Units (HPUs) offer competitive performance and energy efficiency. However, the usage of such non-CUDA processing units requires significant engineering effort and novel software adaptations. In this work, we present our experiences porting PyTorch-based geometric learning frameworks to Gaudi-v2 HPUs. We introduce a collection of core utilities that restore essential operations (e.g., scatter, sparse indexing, k-nearest neighbors) on Gaudi-v2 HPUs, and we consolidate sixteen guided tutorials and eleven real-world examples with diagnostic analyses of encountered failures and detailed workarounds. We collect all our experiences into a publicly accessible GitHub repository. Our contributions lower the barrier for researchers to experiment with geometric-learning algorithms and models on non-CUDA hardware, providing a foundation for further optimization and cross-platform portability.</article>","contentLength":1335,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Optimizing Flamelet Generated Manifold Models: A Machine Learning Performance Study","url":"https://arxiv.org/abs/2507.01030","date":1751515200,"author":"","guid":182499,"unread":true,"content":"<article>arXiv:2507.01030v1 Announce Type: new \nAbstract: In chemistry tabulations and Flamelet combustion models, the Flamelet Generated Manifold (FGM) is recognized for its precision and physical representation. The practical implementation of FGM requires a significant allocation of memory resources. FGM libraries are developed specifically for a specific fuel and subsequently utilized for all numerical problems using machine learning techniques. This research aims to develop libraries of Laminar FGM utilizing machine learning algorithms for application in combustion simulations of methane fuel. This study employs four Machine Learning algorithms to regenerate Flamelet libraries, based on an understanding of data sources, techniques, and data-driven concepts. 1. Multi-Layer Perceptron; 2. Random Forest; 3. Linear Regression; 4. Support Vector Machine. Seven libraries were identified as appropriate for constructing a database for training machine learning models, giving an error rate of 2.30%. The default architectures of each method were evaluated to determine the optimal approach, leading to the selection of the MLP method as the primary choice. The method was enhanced through hyperparameter tuning to improve accuracy. The quantity of hidden layers and neurons significantly influences method performance. The optimal model, comprising four hidden layers with 10, 15, 20, and 25 neurons respectively, achieved an accuracy of 99.81%.</article>","contentLength":1447,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning","url":"https://arxiv.org/abs/2507.01029","date":1751515200,"author":"","guid":182500,"unread":true,"content":"<article>arXiv:2507.01029v1 Announce Type: new \nAbstract: With the development of generative artificial intelligence and instruction tuning techniques, multimodal large language models (MLLMs) have made impressive progress on general reasoning tasks. Benefiting from the chain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning problem step-by-step. However, existing MLLMs still face significant challenges when applied to pathology visual reasoning tasks: (1) LLMs often underperforms because they lack domain-specific information, which can lead to model hallucinations. (2) The additional reasoning steps in CoT may introduce errors, leading to the divergence of answers. To address these limitations, we propose PathCoT, a novel zero-shot CoT prompting method which integrates the pathology expert-knowledge into the reasoning process of MLLMs and incorporates self-evaluation to mitigate divergence of answers. Specifically, PathCoT guides the MLLM with prior knowledge to perform as pathology experts, and provides comprehensive analysis of the image with their domain-specific knowledge. By incorporating the experts' knowledge, PathCoT can obtain the answers with CoT reasoning. Furthermore, PathCoT incorporates a self-evaluation step that assesses both the results generated directly by MLLMs and those derived through CoT, finally determining the reliable answer. The experimental results on the PathMMU dataset demonstrate the effectiveness of our method on pathology visual understanding and reasoning.</article>","contentLength":1523,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dual Perspectives on Non-Contrastive Self-Supervised Learning","url":"https://arxiv.org/abs/2507.01028","date":1751515200,"author":"","guid":182501,"unread":true,"content":"<article>arXiv:2507.01028v1 Announce Type: new \nAbstract: The objective of non-contrastive approaches to self-supervised learning is to train on pairs of different views of the data an encoder and a predictor that minimize the mean discrepancy between the code predicted from the embedding of the first view and the embedding of the second one. In this setting, the stop gradient and exponential moving average iterative procedures are commonly used to avoid representation collapse, with excellent performance in downstream supervised applications. This presentation investigates these procedures from the dual theoretical viewpoints of optimization and dynamical systems. We first show that, in general, although they do not optimize the original objective, or for that matter, any other smooth function, they do avoid collapse. Following Tian et al. [2021], but without any of the extra assumptions used in their proofs, we then show using a dynamical system perspective that, in the linear case, minimizing the original objective function without the use of a stop gradient or exponential moving average always leads to collapse. Conversely, we finally show that the limit points of the dynamical systems associated with these two procedures are, in general, asymptotically stable equilibria, with no risk of degenerating to trivial solutions.</article>","contentLength":1338,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DBellQuant: Breaking the Bell with Double-Bell Transformation for LLMs Post Training Binarization","url":"https://arxiv.org/abs/2507.01027","date":1751515200,"author":"","guid":182502,"unread":true,"content":"<article>arXiv:2507.01027v1 Announce Type: new \nAbstract: Large language models (LLMs) demonstrate remarkable performance but face substantial computational and memory challenges that limit their practical deployment. Quantization has emerged as a promising solution; however, its effectiveness is often limited by quantization errors arising from weight distributions that are not quantization-friendly and the presence of activation outliers. To address these challenges, we introduce DBellQuant, an innovative post-training quantization (PTQ) framework that achieves nearly 1-bit weight compression and 6-bit activation quantization with minimal performance degradation. DBellQuant uses Learnable Transformation for Dual-Bell (LTDB) algorithm, which transforms single-bell weight distributions into dual-bell forms to reduce binarization errors and applies inverse transformations to smooth activations. DBellQuant sets a new state-of-the-art by preserving superior model performance under aggressive weight and activation quantization. For example, on the Wikitext2 dataset, DBellQuant achieves a perplexity of 14.39 on LLaMA2-13B with 6-bit activation quantization, significantly outperforming BiLLM's 21.35 without activation quantization, underscoring its potential in compressing LLMs for real-world applications.</article>","contentLength":1312,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Few-Shot Inspired Generative Zero-Shot Learning","url":"https://arxiv.org/abs/2507.01026","date":1751515200,"author":"","guid":182503,"unread":true,"content":"<article>arXiv:2507.01026v1 Announce Type: new \nAbstract: Generative zero-shot learning (ZSL) methods typically synthesize visual features for unseen classes using predefined semantic attributes, followed by training a fully supervised classification model. While effective, these methods require substantial computational resources and extensive synthetic data, thereby relaxing the original ZSL assumptions. In this paper, we propose FSIGenZ, a few-shot-inspired generative ZSL framework that reduces reliance on large-scale feature synthesis. Our key insight is that class-level attributes exhibit instance-level variability, i.e., some attributes may be absent or partially visible, yet conventional ZSL methods treat them as uniformly present. To address this, we introduce Model-Specific Attribute Scoring (MSAS), which dynamically re-scores class attributes based on model-specific optimization to approximate instance-level variability without access to unseen data. We further estimate group-level prototypes as clusters of instances based on MSAS-adjusted attribute scores, which serve as representative synthetic features for each unseen class. To mitigate the resulting data imbalance, we introduce a Dual-Purpose Semantic Regularization (DPSR) strategy while training a semantic-aware contrastive classifier (SCC) using these prototypes. Experiments on SUN, AwA2, and CUB benchmarks demonstrate that FSIGenZ achieves competitive performance using far fewer synthetic features.</article>","contentLength":1480,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HPC-AI Coupling Methodology for Scientific Applications","url":"https://arxiv.org/abs/2507.01025","date":1751515200,"author":"","guid":182504,"unread":true,"content":"<article>arXiv:2507.01025v1 Announce Type: new \nAbstract: Artificial intelligence (AI) technologies have fundamentally transformed numerical-based high-performance computing (HPC) applications with data-driven approaches and endeavored to address existing challenges, e.g. high computational intensity, in various scientific domains. In this study, we explore the scenarios of coupling HPC and AI (HPC-AI) in the context of emerging scientific applications, presenting a novel methodology that incorporates three patterns of coupling: surrogate, directive, and coordinate. Each pattern exemplifies a distinct coupling strategy, AI-driven prerequisite, and typical HPC-AI ensembles. Through case studies in materials science, we demonstrate the application and effectiveness of these patterns. The study highlights technical challenges, performance improvements, and implementation details, providing insight into promising perspectives of HPC-AI coupling. The proposed coupling patterns are applicable not only to materials science but also to other scientific domains, offering valuable guidance for future HPC-AI ensembles in scientific discovery.</article>","contentLength":1140,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models","url":"https://arxiv.org/abs/2507.01020","date":1751515200,"author":"","guid":182505,"unread":true,"content":"<article>arXiv:2507.01020v1 Announce Type: new \nAbstract: Large Language Models (LLMs) continue to exhibit vulnerabilities to jailbreaking attacks: carefully crafted malicious inputs intended to circumvent safety guardrails and elicit harmful responses. As such, we present AutoAdv, a novel framework that automates adversarial prompt generation to systematically evaluate and expose vulnerabilities in LLM safety mechanisms. Our approach leverages a parametric attacker LLM to produce semantically disguised malicious prompts through strategic rewriting techniques, specialized system prompts, and optimized hyperparameter configurations. The primary contribution of our work is a dynamic, multi-turn attack methodology that analyzes failed jailbreak attempts and iteratively generates refined follow-up prompts, leveraging techniques such as roleplaying, misdirection, and contextual manipulation. We quantitatively evaluate attack success rate (ASR) using the StrongREJECT (arXiv:2402.10260 [cs.CL]) framework across sequential interaction turns. Through extensive empirical evaluation of state-of-the-art models--including ChatGPT, Llama, and DeepSeek--we reveal significant vulnerabilities, with our automated attacks achieving jailbreak success rates of up to 86% for harmful content generation. Our findings reveal that current safety mechanisms remain susceptible to sophisticated multi-turn attacks, emphasizing the urgent need for more robust defense strategies.</article>","contentLength":1463,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MALIBU Benchmark: Multi-Agent LLM Implicit Bias Uncovered","url":"https://arxiv.org/abs/2507.01019","date":1751515200,"author":"","guid":182506,"unread":true,"content":"<article>arXiv:2507.01019v1 Announce Type: new \nAbstract: Multi-agent systems, which consist of multiple AI models interacting within a shared environment, are increasingly used for persona-based interactions. However, if not carefully designed, these systems can reinforce implicit biases in large language models (LLMs), raising concerns about fairness and equitable representation. We present MALIBU, a novel benchmark developed to assess the degree to which LLM-based multi-agent systems implicitly reinforce social biases and stereotypes. MALIBU evaluates bias in LLM-based multi-agent systems through scenario-based assessments. AI models complete tasks within predefined contexts, and their responses undergo evaluation by an LLM-based multi-agent judging system in two phases. In the first phase, judges score responses labeled with specific demographic personas (e.g., gender, race, religion) across four metrics. In the second phase, judges compare paired responses assigned to different personas, scoring them and selecting the superior response. Our study quantifies biases in LLM-generated outputs, revealing that bias mitigation may favor marginalized personas over true neutrality, emphasizing the need for nuanced detection, balanced fairness strategies, and transparent evaluation benchmarks in multi-agent systems.</article>","contentLength":1323,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Systematic Review of Security Vulnerabilities in Smart Home Devices and Mitigation Techniques","url":"https://arxiv.org/abs/2507.01018","date":1751515200,"author":"","guid":182507,"unread":true,"content":"<article>arXiv:2507.01018v1 Announce Type: new \nAbstract: Smart homes that integrate Internet of Things (IoT) devices face increasing cybersecurity risks, posing significant challenges to these environments. The study explores security threats in smart homes ecosystems, categorizing them into vulnerabilities at the network layer, device level, and those from cloud-based and AI-driven systems. Research findings indicate that post-quantum encryption, coupled with AI-driven anomaly detection, is highly effective in enhancing security; however, computational resource demands present significant challenges. Blockchain authentication together with zero-trust structures builds security resilience, although they need changes to existing infrastructure. The specific security strategies show their effectiveness through ANOVA, Chi-square tests, and Monte Carlo simulations yet lack sufficient scalability according to the results. The research demonstrates the requirement for improvement in cryptographic techniques, alongside AI-enhanced threat detection and adaptive security models which must achieve a balance between performance and efficiency and real-time applicability within smart home ecosystems.</article>","contentLength":1199,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"French B2B neobank Qonto reaches 600,000 customers, files for banking license","url":"https://techcrunch.com/2025/07/02/french-b2b-neobank-qonto-reaches-600000-customers-files-for-banking-license/","date":1751515200,"author":"Anna Heim","guid":182566,"unread":true,"content":"<article>Qonto, which targets European freelancers and SMBs, currently operates with a payment institution license it obtained in 2018.</article>","contentLength":126,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Data Breach Reveals Catwatchful 'Stalkerware' Is Spying On Thousands of Phones","url":"https://yro.slashdot.org/story/25/07/03/0023253/data-breach-reveals-catwatchful-stalkerware-is-spying-on-thousands-of-phones?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751513400,"author":"BeauHD","guid":181779,"unread":true,"content":"An anonymous reader quotes a report from TechCrunch: A security vulnerability in a stealthy Android spyware operation called Catwatchful has exposed thousands of its customers, including its administrator. The bug, which was discovered by security researcher Eric Daigle, spilled the spyware app's full database of email addresses and plaintext passwords that Catwatchful customers use to access the data stolen from the phones of their victims. [...] According to a copy of the database from early June, which TechCrunch has seen, Catwatchful had email addresses and passwords on more than 62,000 customers and the phone data from 26,000 victims' devices.\n \nMost of the compromised devices were located in Mexico, Colombia, India, Peru, Argentina, Ecuador, and Bolivia (in order of the number of victims). Some of the records date back to 2018, the data shows. The Catwatchful database also revealed the identity of the spyware operation's administrator, Omar Soca Charcov, a developer based in Uruguay. Charcov opened our emails, but did not respond to our requests for comment sent in both English and Spanish. TechCrunch asked if he was aware of the Catwatchful data breach, and if he plans to disclose the incident to its customers. Without any clear indication that Charcov will disclose the incident, TechCrunch provided a copy of the Catwatchful database to data breach notification service Have I Been Pwned. The stalkerware operation uses a custom API and Google's Firebase to collect and store victims' stolen data, including photos and audio recordings. According to Daigle, the API was left unauthenticated, exposing sensitive user data such as email addresses and passwords.\n \nThe hosting provider temporarily suspended the spyware after TechCrunch disclosed this vulnerability but it returned later on HostGator. Despite being notified, Google has yet to take down the Firebase instance but updated Google Play Protect to detect Catwatchful.\n \nWhile Catwatchful claims it \"cannot be uninstalled,\" you can dial \"543210\" and press the call button on your Android phone to reveal the hidden app. As for its removal, TechCrunch has a general how-to guide for removing Android spyware that could be helpful.","contentLength":2217,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Astronomers discover 3I/ATLAS – Third interstellar object to visit Solar System","url":"https://www.abc.net.au/news/science/2025-07-03/3i-atlas-a11pl3z-interstellar-object-in-our-solar-system/105489180","date":1751512764,"author":"gammarator","guid":182735,"unread":true,"content":"<p>For only the third time in history, astronomers have discovered a new interstellar object that originated from outside our Solar System.</p><p>The object, known as 3I/ATLAS, is likely a comet and is much faster than any other interstellar object found before.&nbsp;</p><p>The object appears to be hurtling towards our Sun at about 60 kilometres a second.&nbsp;</p><p>\"This thing is coming in at such an incredible speed that absolutely nothing in the Solar System could have caused this,\" Jonti Horner, an astronomer at the University of Southern Queensland, said.&nbsp;</p><div data-component=\"EmphasisedText\"><blockquote>\"Of the three interstellar objects we have seen, this is by far the fastest.\"</blockquote></div><p>There are only two other interstellar objects that have previously beentracked entering our Solar System — <a href=\"https://www.abc.net.au/news/2023-03-23/scientists-offer-non-alien-explanation-for-oumuamua/102138318\" data-component=\"Link\">'Oumuamua</a> and <a href=\"https://www.abc.net.au/news/science/2019-11-16/interstellar-comet-2i-borisov-excites-astronomers/11691940\" data-component=\"Link\">Comet 2I/Borisov.</a></p><p>\"It's so exciting,\" Professor Horner added.</p><p>Rumblings of the potential interstellar object started in astronomy groups&nbsp;when the object was first detected early this week.</p><p>\"It has been picked up so early — relatively speaking — that we've got at least eight months [during which]we'll be able to observe it,\" he said.</p><p>The object was first detected by the ATLAS telescope in Chile on 1 July.</p><p>Follow-up observations confirmed the orbit was extremely unusual — almost unaffected by the Sun's gravity, Professor Horner said.&nbsp;</p><div data-component=\"EmphasisedText\"><blockquote>\"Plotting the orbit of this thing [shows] it barely bends as it goes past the Sun.\"</blockquote></div><figure data-print=\"inline-media\" data-component=\"Figure\" data-uri=\"coremedia://imageproxy/105489798\"><figcaption><p data-component=\"Typography\">The trajectory of interstellar comet 3I/ATLAS as it passes through the Solar System.<cite>()</cite></p></figcaption></figure><p>But it wasn't until yesterday that scientists at the <a href=\"https://minorplanetcenter.net/mpec/K25/K25N12.html\" data-component=\"Link\">Minor Planet Centre</a> in the USconfirmed the object was an interstellar object.</p><p>They also suggested the object was likely a comet, due to images that showed it had a short tail.</p><p>More observations will need to be done to confirm this, and get more detail about the object.</p><p>However, because 3I/ATLAS has been found so early, astronomers will have plenty of time to track it as it moves through the Solar System.</p><h2 data-component=\"Heading\">When will 3I/ATLAS be closest to the Sun?</h2><p>Currently, estimates suggest it will be closest to the Sun at the end of October, before returning out past Jupiter and into the outer Solar System by March next year.</p><p>Unfortunately, Earth will be on the other side of the Solar System when 3I/ATLAS is closest to the Sun and at its brightest, making it harder for us to see.</p><p>\"If we were on Mars, we'd have a fairly good view of it,\" Professor Horner said.</p><p>\"It's not going to be hugely close to Mars, but it's going to be a lot closer to Mars than it will to the Earth.\"</p><p>Because 3I/ATLAS might currently be going through an outburst — a sudden brightening caused by dust and gas being released by the object — it's difficult to track its size.</p><figure data-print=\"inline-media\" data-component=\"Figure\" data-uri=\"coremedia://imageproxy/105489848\"><figcaption><p data-component=\"Typography\">'Oumuamua was in a \"cigar\" shape, making it much less bright.&nbsp;<cite>()</cite></p></figcaption></figure><p>'Oumuamua was quite a small object, and estimates on the size of 2I/Borisov ranged from about 1 kilometre to more than 16km in diameter.</p><p>\"I would say this is probably more along the lines of a few hundred metres to a kilometre across, maybe a bit bigger than that,\" Professor Horner said.&nbsp;</p><p>\"Which is big, but not exceptional.\"</p><h2 data-component=\"Heading\">Will we see more interstellar objects?&nbsp;</h2><p>Interstellar objects have been extremely rare so far, but with better telescopes like the Rubin Observatory, we're likely to catch many more of these objects when they arrive.&nbsp;</p><p>\"We've had three [interstellar objects] in less than a decade with our current technology,\" Professor Horner said.&nbsp;</p><p>\"The Rubin Observatory is probably an order of magnitude better at finding things … so that would suggest we'll find a few of these per year.\"</p><p>Within its first 10 hours of operation the observatory detected more than 2,000 previously unknown asteroids in the Solar System.&nbsp;</p><div data-component=\"EmphasisedText\"><blockquote>\"It's kind of a sneak peek into the future.\"</blockquote></div>","contentLength":3679,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44451329"},{"title":"TN Govt. Saves School Children From Smut Like Magic Tree House, Calvin & Hobbes, & A Light In The Attic","url":"https://www.techdirt.com/2025/07/02/tn-govt-saves-school-children-from-smut-like-magic-tree-house-calvin-hobbes-a-light-in-the-attic/","date":1751510580,"author":"Dark Helmet","guid":181727,"unread":true,"content":"<p><a href=\"https://www.techdirt.com/tag/book-bans/\">Book bans</a> are all the rage these days, as you likely well know. Far too many people, and folks in government more importantly, seem to have read Ray Bradbury’s  not as a lesson in the dangers of new media, but as some sort of instruction manual for how to treat literature. But the real story here is that a bunch of cowardly state and federal politicians are placating the desires largely of the religious right, who are seeking to tightly control the books that children have access to in public, secular schools. And if you can’t manage to understand how plainly that is the antithesis of our form of government, then you’re beyond help.</p><p>But because authoritarianism makes a fool of itself as a habit, and religiously-based authoritarianism all the moreso, then end result of these attempts at censorship always eventually reveal themselves as absurd. And if you need an example of that, you need <a href=\"https://pen.org/magic-tree-house-author-calvin-and-hobbes-among-hundreds-of-tennessee-book-bans/\">only look at the state of Tennessee</a>.</p><blockquote><p><em>Magic Tree House&nbsp;author&nbsp;, children’s poet&nbsp;&nbsp;and&nbsp;Calvin and Hobbes&nbsp;cartoonist&nbsp;have joined&nbsp;<strong>Judy Blume, Sarah J. Maas, Eric Carle</strong>&nbsp;and&nbsp;&nbsp;on a mind-boggling list of hundreds of books purged from some Tennessee school libraries.</em></p><p><em>The removals are the result of a&nbsp;<a href=\"https://pen.org/report/beyond-the-shelves/\">growing political movement</a>&nbsp;to control information through book banning. In 2024, the state legislature&nbsp;<a href=\"https://www.wbir.com/article/news/education/tennessee-book-ban-sexual-imagery-explicit-content/51-5a5ba0f6-38c7-4aa9-99e1-ea4a55e41577\">amended</a>&nbsp;the “Age-Appropriate Materials Act of 2022” to specify that any materials that “in whole or in part” contain any “nudity, or descriptions or depictions of sexual excitement, sexual conduct, excess violence, or sadomasochistic abuse” are inappropriate for all students and do not belong in a school library. This change means books are not evaluated as a whole, and excerpts can be considered without context, if they have any content that is deemed to cross these lines. This leaves no room for educators and librarians to curate collections that reflect the real world and serve the educational needs of today’s students.</em></p></blockquote><p>And because you have groups of far-right activists marching around looking for any scintilla of material over which they can manufacture faux outrage, you get these examples of books being banned for their terrible, awful, smutty content. Such as a , book that was banned because it had this pornographical image on its cover:</p><p>Special thanks to Mike Masnick for briefly allowing me to post porn images on Techdirt. And for all of you whose naughty bits are currently twitching due to that book cover, I offer you my sincerest apologies.</p><p>But if you thought  was bad, check out this panel image from a  book that got it banned. Here we have the nude image of a child on full display.</p><p>Now, I sure hope everyone realizes that the above is a dalliance into sarcasm, because I was laying it on quite thick. I grew up on , not to mention Shel Silverstein’s , which was also banned. Why? More butts, that’s why. And, because the universe is not without a sense of irony, one school even had to ban a book authored by an alumnus.</p><blockquote><p><em>Oak Ridge Schools, where a significant number of the bans target art history books, even removed&nbsp;Richard Jolley: Sculptor of Glass, a collection of works by the artist, who graduated from Oak Ridge High School.</em></p><p><em>“Regarding the book written by Mr. Jolley, we were thrilled to feature a book written by an ORHS alumni on our shelves and were equally disappointed to have to remove it,” Molly Gallagher Smith, an Oak Ridge Schools spokeswoman,&nbsp;<a href=\"https://www.wbir.com/article/news/local/oak-ridge-anderson/books-removed-from-shelves-in-oak-ridge-schools-libraries-after-changes-to-state-law/51-db8f413d-d363-44e9-8910-79dff10e8072\">told WBIR</a>. “Unfortunately, as an artist, Mr. Jolley’s book features depictions of the human body that are in direct violation of the law.”</em></p></blockquote><p>There are more and the bans hit all the notes you would expect: LGBTQ+ material, books about the Holocaust, books about African American contributions to government and science, and, because of course,  itself.</p><p>Now, this is indeed all absurd, but it isn’t remotely funny. There is a ton of literature, hundreds of books, that are being banned under this Tennessee law. Many of them reportedly without going through any review process.</p><blockquote><p><em>And many of the bans are coming without any review or discussion. The Tennessee Association of School Libraries&nbsp;<a href=\"https://www.tasltn.org/assets/docs/advocacy/TASL%20Survey%20October%202024.pdf\">found in a survey</a>&nbsp;of its members that in 20% of school districts, books were removed from the shelves at the command of district leaders without any sort of review process. “Librarians and educators are concerned that we will end up pulling a massive amount of books without looking at the books as a whole,” one member said in the survey. “It’s a slippery slope,” said another, “and I’m fearful of the next topic that will be regulated.”</em></p></blockquote><p>Open up book bans to the frothy-mouthed mob. What could possibly go wrong, other than keeping valuable literature out of the hands of our children?</p>","contentLength":4718,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Proposed Budget Seeks To Close Mauna Loa Observatory's Climate CO2 Study","url":"https://news.slashdot.org/story/25/07/03/0031226/proposed-budget-seeks-to-close-mauna-loa-observatorys-climate-co2-study?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751508120,"author":"BeauHD","guid":181621,"unread":true,"content":"\"Slashdot regularly posts milestones on CO2 levels reported by the Mauna Loa Observatory,\" writes longtime Slashdot reader symbolset, pointing to a new article highlighting how the Trump administration's proposed budget would eliminate funding for the lab's carbon dioxide monitoring. \"Continuous observation records since 1958 will end with the new federal budget as ocean and atmospheric sciences are defunded.\" From a report: [I]t's the Mauna Loa laboratory that is the most prominent target of the President Donald Trump's climate ire, as measurements that began there in 1958 have steadily shown CO2's upward march as human activities have emitted more and more of the planet-warming gas each year. The curve produced by the Mauna Loa measurements is one of the most iconic charts in modern science, known as the Keeling Curve, after Charles David Keeling, who was the researcher who painstakingly collected the data. His son, Ralph Keeling, a professor at the Scripps Institution of Oceanography at UC San Diego, now oversees collecting and updating that data.\n \nToday, the Keeling Curve measurements are made possible by the National Oceanic and Atmospheric administration, but the data gathering and maintenance of the historical record also is funded by Schmidt Sciences and Earth Networks, according to the Keeling Curve website. In the event of a NOAA shut down of the lab, Scripps could seek alternate sources of funding to host the instruments atop the same peak or introduce a discontinuity in the record by moving the instruments elsewhere in Hawaii.\n \nThe proposal to shut down Mauna Loa had been made public previously but was spelled out in more detail on Monday when NOAA submitted a budget document (PDF) to Congress. It made more clear that the Trump administration envisions eliminating all climate-related research work at NOAA, as had been proposed in Project 2025, the conservative blueprint for overhauling the government. It would do this in large part by cutting NOAA's Office of Oceanic and Atmospheric Research entirely, including some labs that are also involved in improving weather forecasting. NOAA has long been one of the world's top climate science agencies, but the administration would steer it instead towards being more focused on operational weather forecasting and warning responsibilities.","contentLength":2333,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ISC Stormcast For Thursday, July 3rd, 2025 https://isc.sans.edu/podcastdetail/9512, (Thu, Jul 3rd)","url":"https://isc.sans.edu/diary/rss/32078","date":1751508002,"author":"","guid":181680,"unread":true,"content":"<article>\n \n (c) SANS Internet Storm Center. https://isc.sans.edu Creative Commons Attribution-Noncommercial 3.0 United States License.</article>","contentLength":126,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Foxconn Mysteriously Tells Chinese Workers To Quit India and Return To China","url":"https://apple.slashdot.org/story/25/07/03/0016210/foxconn-mysteriously-tells-chinese-workers-to-quit-india-and-return-to-china?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751505900,"author":"BeauHD","guid":181506,"unread":true,"content":"Apple's expansion in India has hit a snag as Foxconn has sent over 300 Chinese workers back to China, potentially reducing production efficiency just as mass manufacturing of the iPhone 17 begins. AppleInsider reports: It's not known why Foxconn has done this, nor is it clear whether workers have been laid off or redeployed to the company's facilities in China. The move, though, does follow Beijing officials reportedly working to prevent firms moving away from China. Those officials are said to have been verbally encouraging China's local governments and regulatory bodies to curb exports of equipment or technologies to India and Southeast Asia.\n \nOverall, China has been making it harder for skilled labor to leave the country. It's not clear how any changes have specifically affected Chinese workers who had already left.What is clear is that Foxconn has used many experienced Chinese engineers as it attempts to rapidly expand in India. It's said, too, that Chinese managers have been vital in training Foxconn staff in India. Since that training has been ongoing for some years, and since at least most of Foxconn's production lines have been set up, it's said that there will not be an impact on the quality of manufacturing. But one source said the changes will impact efficiency on the production line.","contentLength":1317,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trans-Taiga Road (2004)","url":"https://www.jamesbayroad.com/ttr/index.html","date":1751504824,"author":"jason_pomerleau","guid":182591,"unread":true,"content":"<p align=\"left\">The Trans-Taiga Road is a gravel road that runs 666 km east \nfrom near the top end of the <a href=\"https://www.jamesbayroad.com/jbr/index.html\"> James Bay Road</a>. It \nwas built to access the various dams and generating stations that extend upriver \nalong the La Grande River.</p><p align=\"left\">This is an  road, leading 666 km \neast - almost to Labrador - with no settlements or towns aside from Hydro \nQuebec's settlements for workers (not open to the public). At the far end you \nwill be 745 km from the nearest town! This is the farthest you can get from a \ntown on a road in North America! (Not counting the private Hydro Quebec towns \nthat are not open to the public). Along this road is also the\n<a href=\"https://www.jamesbayroad.com/ttr/virtualtour/ttrvirtualtour08.html#km542\">farthest north</a> point you \ncan travel on a road in eastern Canada.</p><p align=\"left\">The road from <a href=\"https://www.jamesbayroad.com/ttr/brisay/index.html\">Brisay</a> (km 582) \nto <a href=\"https://www.jamesbayroad.com/ttr/caniapiscau/index.html\">Caniapiscau</a> is rougher and a 4-wheel \ndrive vehicle is recommended by Hydro Quebec. The main reason for this is the \nvery coarse gravel used for this road - there's large rocks littering the road \nsurface. However, I have heard from people who have driven this road in ordinary \npassenger cars and they say it is fine. You do have to keep your eyes open for \nthe larger rocks though.</p><p align=\"left\">You should definitely travel this road only in a reliable \nvehicle with good tires. It is not an overly rough road; passenger vehicles can \ndrive it, but it is gravel. Vehicle breakdowns here can be very costly. Flat \ntires can be a serious (and expensive) incident if your tires are damaged. You \ncould be looking at having tires flown in on a non-scheduled flight - there are \nno convenient \"tire stores\" up here! Please read\n<a href=\"https://www.jamesbayroad.com/ttr/ttrdriving.html\">Driving the Trans-Taiga Road</a> first.</p><p align=\"left\">Although there are no towns, there are a couple of outfitters \nalong the way that sell fuel and offer meals and lodging. Cell phones do not \nwork here.</p><p align=\"left\">Generally the scenery is fairly level, but this road is \ndefinitely more interesting than the <a href=\"https://www.jamesbayroad.com/jbr/index.html\">James Bay Road</a>.&nbsp;For \nmost of the length it runs through taiga: spruce and jack pine forest, bogs, \nrocks, and low hills.&nbsp;This is about all you'll see apart from birds and some \nwildlife, the occasional cabin a short distance off the road, and Hydro Quebec \ninstallations. I once saw a couple of wolves playing in the middle of this road.</p><table border=\"0\" width=\"100%\"><tbody><tr><td><ul></ul></td></tr></tbody></table>","contentLength":2156,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44450575"},{"title":"Hacker With 'Political Agenda' Stole Data From Columbia, University Says","url":"https://news.slashdot.org/story/25/07/03/0012219/hacker-with-political-agenda-stole-data-from-columbia-university-says?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751503500,"author":"BeauHD","guid":181505,"unread":true,"content":"A politically motivated hacker breached Columbia University's IT systems, stealing vast amounts of sensitive student and employee data -- including admissions decisions and Social Security numbers. The Record reports: The hacker reportedly provided Bloomberg News with 1.6 gigabytes of data they claimed to have stolen from the university, including information from 2.5 million applications going back decades. The stolen data the outlet reviewed reportedly contains details on whether applicants were rejected or accepted, their citizenship status, their university ID numbers and which academic programs they sought admission to. While the hacker's claims have not been independently verified, Bloomberg said it compared data provided by the hacker to that belonging to eight Columbia applicants seeking admission between 2019 and 2024 and found it matched.\n \nThe threat actor reportedly told Bloomberg he was seeking information that would indicate whether the university continues to use affirmative action in admissions despite a 2023 Supreme Court decision prohibiting the practice. The hacker told Bloomberg he obtained 460 gigabytes of data in total -- after spending two months targeting and penetrating increasingly privileged layers of the university's servers -- and said he harvested information about financial aid packages, employee pay and at least 1.8 million Social Security numbers belonging to employees, applicants, students and their family members.","contentLength":1472,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Steam On Linux Usage Dips Slightly For June, AMD Linux CPU Usage Hits 69%","url":"https://www.phoronix.com/news/Steam-June-2025","date":1751503116,"author":"Michael Larabel","guid":181563,"unread":true,"content":"<article>Steam Survey issues prevented the survey results from being posted on the evening of the 1st as is traditionally done, but the results were just uploaded now to the Steam website. Steam on Linux usage dipped slightly but overall remains healthy with much excitement still around the Steam Deck and SteamOS efforts...</article>","contentLength":316,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Debian 13 Installer RC2 Fixes An Annoying Issue, Improves Btrfs Rescue Handling","url":"https://www.phoronix.com/news/Debian-Installer-13-Trixie-RC2","date":1751502500,"author":"Michael Larabel","guid":181562,"unread":true,"content":"<article>Following last month's release of Debian Installer Trixie RC1 as the installer for the upcoming Debian 13.0 release, a second release candidate was issued today for testing...</article>","contentLength":175,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Whole-genome ancestry of an Old Kingdom Egyptian","url":"https://www.nature.com/articles/s41586-025-09195-5","date":1751502286,"author":"A_D_E_P_T","guid":182734,"unread":true,"content":"<li data-counter=\"1.\"><p>Garstang, J. in <i>The Burial Customs of Ancient Egypt</i> (ed. Garstang, J.) 26–30 (Archibald Constable, 1907).</p></li><li data-counter=\"3.\"><p>Skourtanioti, E. et al. Genomic history of Neolithic to Bronze Age Anatolia, Northern Levant, and Southern Caucasus. , 1158–1175.e28 (2020).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1016/j.cell.2020.04.044\" data-track-item_id=\"10.1016/j.cell.2020.04.044\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1016%2Fj.cell.2020.04.044\" aria-label=\"Article reference 3\" data-doi=\"10.1016/j.cell.2020.04.044\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXhtVKnurbN\" aria-label=\"CAS reference 3\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32470401\" aria-label=\"PubMed reference 3\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 3\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Genomic%20history%20of%20Neolithic%20to%20Bronze%20Age%20Anatolia%2C%20Northern%20Levant%2C%20and%20Southern%20Caucasus&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2020.04.044&amp;volume=181&amp;pages=1158-1175.e28&amp;publication_year=2020&amp;author=Skourtanioti%2CE\">\n                    Google Scholar</a></p></li><li data-counter=\"4.\"><p>Haber, M. et al. Continuity and admixture in the last five millennia of Levantine history from ancient Canaanite and present-day Lebanese genome sequences. , 274–282 (2017).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1016/j.ajhg.2017.06.013\" data-track-item_id=\"10.1016/j.ajhg.2017.06.013\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1016%2Fj.ajhg.2017.06.013\" aria-label=\"Article reference 4\" data-doi=\"10.1016/j.ajhg.2017.06.013\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXht1CksrzJ\" aria-label=\"CAS reference 4\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28757201\" aria-label=\"PubMed reference 4\">PubMed</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed central reference\" data-track-action=\"pubmed central reference\" href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5544389\" aria-label=\"PubMed Central reference 4\">PubMed Central</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 4\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Continuity%20and%20admixture%20in%20the%20last%20five%20millennia%20of%20Levantine%20history%20from%20ancient%20Canaanite%20and%20present-day%20Lebanese%20genome%20sequences&amp;journal=Am.%20J.%20Hum.%20Genet.&amp;doi=10.1016%2Fj.ajhg.2017.06.013&amp;volume=101&amp;pages=274-282&amp;publication_year=2017&amp;author=Haber%2CM\">\n                    Google Scholar</a></p></li><li data-counter=\"6.\"><p>Salvatori, S. &amp; Usai, D. The neolithic and ‘pastoralism’ along the Nile: a dissenting view. , 251–285 (2019).</p></li><li data-counter=\"7.\"><p>Wengrow, D. <i>The Archaeology of Early Egypt: Social Transformations in North-East Africa, 10,000 to 2,650 BC</i> (Cambridge Univ. Press, 2006).</p></li><li data-counter=\"8.\"><p>Bard, K. A. in <i>The Oxford History of Ancient Egypt</i> (ed. Shaw, I.) 61–88 (Oxford Univ. Press, 2000).</p></li><li data-counter=\"9.\"><p>Stevenson, A. in  (ed. Crawford, H.) 620–636 (Routledge, 2013).</p></li><li data-counter=\"10.\"><p>Malek, J. in <i>The Oxford History of Ancient Egypt</i> (ed. Shaw, I.) 89–117 (Oxford Univ. Press, 2000).</p></li><li data-counter=\"11.\"><p>Doherty, S. K. <i>The Origins and Use of the Potter’s Wheel in Ancient Egypt</i> (Archaeopress, 2015).</p></li><li data-counter=\"12.\"><p>Keita, S. O. Y. Further studies of crania from ancient northern Africa: an analysis of crania from First Dynasty Egyptian tombs. , 245–254 (1992).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.1330870302\" data-track-item_id=\"10.1002/ajpa.1330870302\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.1330870302\" aria-label=\"Article reference 12\" data-doi=\"10.1002/ajpa.1330870302\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK383it1Slsw%3D%3D\" aria-label=\"CAS reference 12\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1562056\" aria-label=\"PubMed reference 12\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 12\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Further%20studies%20of%20crania%20from%20ancient%20northern%20Africa%3A%20an%20analysis%20of%20crania%20from%20First%20Dynasty%20Egyptian%20tombs&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.1330870302&amp;volume=87&amp;pages=245-254&amp;publication_year=1992&amp;author=Keita%2CSOY\">\n                    Google Scholar</a></p></li><li data-counter=\"13.\"><p>Prowse, T. L. &amp; Lovell, N. C. Concordance of cranial and dental morphological traits and evidence for endogamy in ancient Egypt. , 237–246 (1996).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/(SICI)1096-8644(199610)101:2<237::AID-AJPA8>3.0.CO;2-Z\" data-track-item_id=\"10.1002/(SICI)1096-8644(199610)101:2<237::AID-AJPA8>3.0.CO;2-Z\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2F%28SICI%291096-8644%28199610%29101%3A2%3C237%3A%3AAID-AJPA8%3E3.0.CO%3B2-Z\" aria-label=\"Article reference 13\" data-doi=\"10.1002/(SICI)1096-8644(199610)101:2<237::AID-AJPA8>3.0.CO;2-Z\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK2s%2FkvVamsw%3D%3D\" aria-label=\"CAS reference 13\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8893087\" aria-label=\"PubMed reference 13\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 13\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Concordance%20of%20cranial%20and%20dental%20morphological%20traits%20and%20evidence%20for%20endogamy%20in%20ancient%20Egypt&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2F%28SICI%291096-8644%28199610%29101%3A2%3C237%3A%3AAID-AJPA8%3E3.0.CO%3B2-Z&amp;volume=101&amp;pages=237-246&amp;publication_year=1996&amp;author=Prowse%2CTL&amp;author=Lovell%2CNC\">\n                    Google Scholar</a></p></li><li data-counter=\"14.\"><p>Irish, J. D. Who were the ancient Egyptians? Dental affinities among Neolithic through postdynastic peoples. , 529–543 (2006).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.20261\" data-track-item_id=\"10.1002/ajpa.20261\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.20261\" aria-label=\"Article reference 14\" data-doi=\"10.1002/ajpa.20261\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16331657\" aria-label=\"PubMed reference 14\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 14\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Who%20were%20the%20ancient%20Egyptians%3F%20Dental%20affinities%20among%20Neolithic%20through%20postdynastic%20peoples&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.20261&amp;volume=129&amp;pages=529-543&amp;publication_year=2006&amp;author=Irish%2CJD\">\n                    Google Scholar</a></p></li><li data-counter=\"15.\"><p>Zakrzewski, S. R. in <i>Egyptian Bioarchaeology: Humans, Animals, and the Environment</i> (eds Ikram, S. et al.) 157–167 (Sidestone, 2015).</p></li><li data-counter=\"16.\"><p>Dicke-Toupin, C. R. <i>Population Continuity or Replacement at Ancient Lachish?</i> (Fairbanks, 2012).</p></li><li data-counter=\"17.\"><p>Irish, J. D. Diachronic and synchronic dental trait affinities of late and post-Pleistocene peoples from North Africa. , 138–155 (1998).</p></li><li data-counter=\"18.\"><p>Maaranen, N., Zakrzewski, S. &amp; Schutkowski, H. Who were the Hyksos? , 66–69 (2022).</p></li><li data-counter=\"22.\"><p>De Meyer, M. et al. in <i>Under the Potter’s Tree: Studies on Ancient Egypt Presented to Janine Bourriau</i> Vol. 204 (eds Aston, D. et al.) 679–702 (Peeters, 2011).</p></li><li data-counter=\"23.\"><p>Power, R. K. &amp; Tristant, Y. From refuse to rebirth: repositioning the pot burial in the Egyptian archaeological record. , 1474–1488 (2016).</p></li><li data-counter=\"25.\"><p>Buikstra, J. E. &amp; Ubelaker, D. U. <i>Standards for Data Collection from Human Skeletal Remains</i> (Arkansas Archeological Survey, 1994).</p></li><li data-counter=\"26.\"><p>Raxter, M. H. et al. Stature estimation in ancient Egyptians: a new technique based on anatomical reconstruction of stature. , 147–155 (2008).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.20790\" data-track-item_id=\"10.1002/ajpa.20790\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.20790\" aria-label=\"Article reference 26\" data-doi=\"10.1002/ajpa.20790\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18257013\" aria-label=\"PubMed reference 26\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 26\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Stature%20estimation%20in%20ancient%20Egyptians%3A%20a%20new%20technique%20based%20on%20anatomical%20reconstruction%20of%20stature&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.20790&amp;volume=136&amp;pages=147-155&amp;publication_year=2008&amp;author=Raxter%2CMH\">\n                    Google Scholar</a></p></li><li data-counter=\"27.\"><p>Işcan, M. Y., Loth, S. R. &amp; Wright, R. K. Age estimation from the rib by phase analysis: white males. , 1094–1104 (1984).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1520/JFS11776J\" data-track-item_id=\"10.1520/JFS11776J\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1520%2FJFS11776J\" aria-label=\"Article reference 27\" data-doi=\"10.1520/JFS11776J\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=6502109\" aria-label=\"PubMed reference 27\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 27\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Age%20estimation%20from%20the%20rib%20by%20phase%20analysis%3A%20white%20males&amp;journal=J.%20Forensic%20Sci.&amp;doi=10.1520%2FJFS11776J&amp;volume=29&amp;pages=1094-1104&amp;publication_year=1984&amp;author=I%C5%9Fcan%2CMY&amp;author=Loth%2CSR&amp;author=Wright%2CRK\">\n                    Google Scholar</a></p></li><li data-counter=\"28.\"><p>Kennedy, K. A. R. in <i>Reconstruction of Life from the Skeleton</i> (eds Kennedy, K. A. R. &amp; Işcan, M. Y.) 129–160 (Alan R. Liss, 1989).</p></li><li data-counter=\"29.\"><p>Capasso, L., Kenney, K. A. R. &amp; Wilczak, C. A. <i>Atlas of Occupational Markers on Human Remains</i> (Edigratifal, 1998).</p></li><li data-counter=\"30.\"><p>Buzon, M. R. &amp; Simonetti, A. Strontium isotope (Sr/Sr) variability in the Nile Valley: identifying residential mobility during ancient Egyptian and Nubian sociopolitical changes in the New Kingdom and Napatan periods. , 1–9 (2013).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.22235\" data-track-item_id=\"10.1002/ajpa.22235\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.22235\" aria-label=\"Article reference 30\" data-doi=\"10.1002/ajpa.22235\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23440634\" aria-label=\"PubMed reference 30\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 30\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Strontium%20isotope%20%2887Sr%2F86Sr%29%20variability%20in%20the%20Nile%20Valley%3A%20identifying%20residential%20mobility%20during%20ancient%20Egyptian%20and%20Nubian%20sociopolitical%20changes%20in%20the%20New%20Kingdom%20and%20Napatan%20periods&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.22235&amp;volume=151&amp;pages=1-9&amp;publication_year=2013&amp;author=Buzon%2CMR&amp;author=Simonetti%2CA\">\n                    Google Scholar</a></p></li><li data-counter=\"31.\"><p>Stantis, C., Nowell, G. M., Prell, S. &amp; Schutkowski, H. Animal proxies to characterize the strontium biosphere in the northeastern Nile Delta. <i>Bioarchaeology of the Near East</i>, 1–13 (2019).</p></li><li data-counter=\"32.\"><p>Touzeau, A. et al. Egyptian mummies record increasing aridity in the Nile Valley from 5500 to 1500 yr before present. , 92–100 (2013).</p></li><li data-counter=\"33.\"><p>Richards, M. P. in <i>Archaeological Science: An Introduction</i> (eds Richards, M. P. &amp; Britton, K.) 125–144 (Cambridge Univ. Press, 2019).</p></li><li data-counter=\"34.\"><p>Touzeau, A. et al. Diet of ancient Egyptians inferred from stable isotope systematics. , 114–124 (2014).</p></li><li data-counter=\"35.\"><p>Macko, S. A. et al. Documenting the diet in ancient human populations through stable isotope analysis of hair. <i>Philos. Trans. R. Soc. London, B: Biol. Sci.</i>, 65–76 (1999).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1098/rstb.1999.0360\" data-track-item_id=\"10.1098/rstb.1999.0360\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1098%2Frstb.1999.0360\" aria-label=\"Article reference 35\" data-doi=\"10.1098/rstb.1999.0360\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DyaK1MXhtlygtr4%3D\" aria-label=\"CAS reference 35\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10091248\" aria-label=\"PubMed reference 35\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 35\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Documenting%20the%20diet%20in%20ancient%20human%20populations%20through%20stable%20isotope%20analysis%20of%20hair&amp;journal=Philos.%20Trans.%20R.%20Soc.%20London%2C%20B%3A%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.1999.0360&amp;volume=354&amp;pages=65-76&amp;publication_year=1999&amp;author=Macko%2CSA\">\n                    Google Scholar</a></p></li><li data-counter=\"36.\"><p>Thompson, A. H., Richards, M. P., Shortland, A. &amp; Zakrzewski, S. R. Isotopic palaeodiet studies of ancient Egyptian fauna and humans. , 451–463 (2005).</p></li><li data-counter=\"37.\"><p>Thompson, A. H., Chaix, L. &amp; Richards, M. P. Stable isotopes and diet at ancient Kerma, Upper Nubia (Sudan). , 376–387 (2008).</p></li><li data-counter=\"38.\"><p>Poulallion, E. et al. High δN values in Predynastic Egyptian archeological remains: a potential indicator for localised soil fertilisation practices in extreme conditions. Preprint at <a href=\"https://doi.org/10.1101/2024.11.18.624066\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"10.1101/2024.11.18.624066\">https://doi.org/10.1101/2024.11.18.624066</a> (2024).</p></li><li data-counter=\"39.\"><p>Gansauge, M.-T. &amp; Meyer, M. Single-stranded DNA library preparation for the sequencing of ancient or damaged DNA. , 737–748 (2013).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1038/nprot.2013.038\" data-track-item_id=\"10.1038/nprot.2013.038\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1038%2Fnprot.2013.038\" aria-label=\"Article reference 39\" data-doi=\"10.1038/nprot.2013.038\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23493070\" aria-label=\"PubMed reference 39\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 39\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Single-stranded%20DNA%20library%20preparation%20for%20the%20sequencing%20of%20ancient%20or%20damaged%20DNA&amp;journal=Nat.%20Protoc.&amp;doi=10.1038%2Fnprot.2013.038&amp;volume=8&amp;pages=737-748&amp;publication_year=2013&amp;author=Gansauge%2CM-T&amp;author=Meyer%2CM\">\n                    Google Scholar</a></p></li><li data-counter=\"48.\"><p>Zvelebil, M. &amp; Lillie, M. in  (ed Price, T. D.) 57–92 (Cambridge Univ. Press, 2000).</p></li><li data-counter=\"49.\"><p>Pinhasi, R. &amp; Stock, J. T. <i>Human Bioarchaeology of the Transition to Agriculture</i> (Wiley, 2011).</p></li><li data-counter=\"50.\"><p>Martin, N. et al. From hunter-gatherers to food producers: new dental insights into the Nile Valley population history (Late Paleolithic-Neolithic). , e24948 (2024).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.24948\" data-track-item_id=\"10.1002/ajpa.24948\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.24948\" aria-label=\"Article reference 50\" data-doi=\"10.1002/ajpa.24948\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=38733278\" aria-label=\"PubMed reference 50\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 50\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=From%20hunter-gatherers%20to%20food%20producers%3A%20new%20dental%20insights%20into%20the%20Nile%20Valley%20population%20history%20%28Late%20Paleolithic-Neolithic%29&amp;journal=Am.%20J.%20Biol.%20Anthropol.&amp;doi=10.1002%2Fajpa.24948&amp;volume=184&amp;publication_year=2024&amp;author=Martin%2CN\">\n                    Google Scholar</a></p></li><li data-counter=\"51.\"><p>Stevenson, A. The Egyptian Predynastic and state formation. , 421–468 (2016).</p></li><li data-counter=\"52.\"><p>Redford, D. B. <i>Egypt, Canaan, and Israel in Ancient Times</i>&nbsp;(Princeton Univ. Press, 1992).</p></li><li data-counter=\"53.\"><p>Llorente, M. G. et al. Ancient Ethiopian genome reveals extensive Eurasian admixture in Eastern Africa. , 820–822 (2015).</p></li><li data-counter=\"56.\"><p>Bourriau, J. in <i>The Oxford History of Ancient Egypt</i> (ed. Shaw, I.) 172–206 (Oxford Univ. Press, 2000).</p></li><li data-counter=\"57.\"><p>Ryholt, K. S. B. &amp; Bülow-Jacobsen, A. <i>The Political Situation in Egypt During the Second Intermediate Period, C. 1800-1550 B.C.</i> (Museum Tusculanum, 1997).</p></li><li data-counter=\"58.\"><p>Weiss, B. The decline of Late Bronze Age civilization as a possible response to climatic change. , 173–198 (1982).</p></li><li data-counter=\"59.\"><p>Ward, W. A., Joukowsky, M. S. &amp; Åström, P. <i>The Crisis Years: The 12th Century B.C.: From Beyond the Danube to the Tigris</i> (Kendall Hunt, 1992).</p></li><li data-counter=\"63.\"><p>Dabney, J. et al. Complete mitochondrial genome sequence of a Middle Pleistocene cave bear reconstructed from ultrashort DNA fragments. <i>Proc. Natl Acad. Sci. USA</i>, 15758–15763 (2013).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1073/pnas.1314445110\" data-track-item_id=\"10.1073/pnas.1314445110\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1073%2Fpnas.1314445110\" aria-label=\"Article reference 63\" data-doi=\"10.1073/pnas.1314445110\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXhs1WlurnO\" aria-label=\"CAS reference 63\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24019490\" aria-label=\"PubMed reference 63\">PubMed</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed central reference\" data-track-action=\"pubmed central reference\" href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3785785\" aria-label=\"PubMed Central reference 63\">PubMed Central</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 63\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Complete%20mitochondrial%20genome%20sequence%20of%20a%20Middle%20Pleistocene%20cave%20bear%20reconstructed%20from%20ultrashort%20DNA%20fragments&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1314445110&amp;volume=110&amp;pages=15758-15763&amp;publication_year=2013&amp;author=Dabney%2CJ\">\n                    Google Scholar</a></p></li><li data-counter=\"64.\"><p>Kircher, M., Sawyer, S. &amp; Meyer, M. Double indexing overcomes inaccuracies in multiplex sequencing on the Illumina platform. , e3 (2012).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1093/nar/gkr771\" data-track-item_id=\"10.1093/nar/gkr771\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1093%2Fnar%2Fgkr771\" aria-label=\"Article reference 64\" data-doi=\"10.1093/nar/gkr771\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38Xit1GmtQ%3D%3D\" aria-label=\"CAS reference 64\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22021376\" aria-label=\"PubMed reference 64\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 64\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Double%20indexing%20overcomes%20inaccuracies%20in%20multiplex%20sequencing%20on%20the%20Illumina%20platform&amp;journal=Nucleic%20Acids%20Res.&amp;doi=10.1093%2Fnar%2Fgkr771&amp;volume=40&amp;publication_year=2012&amp;author=Kircher%2CM&amp;author=Sawyer%2CS&amp;author=Meyer%2CM\">\n                    Google Scholar</a></p></li><li data-counter=\"65.\"><p>Gansauge, M.-T., Aximu-Petri, A., Nagel, S. &amp; Meyer, M. Manual and automated preparation of single-stranded DNA libraries for the sequencing of DNA from ancient biological remains and other sources of highly degraded DNA. , 2279–2300 (2020).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1038/s41596-020-0338-0\" data-track-item_id=\"10.1038/s41596-020-0338-0\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1038%2Fs41596-020-0338-0\" aria-label=\"Article reference 65\" data-doi=\"10.1038/s41596-020-0338-0\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXhtlSht7vF\" aria-label=\"CAS reference 65\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32612278\" aria-label=\"PubMed reference 65\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 65\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Manual%20and%20automated%20preparation%20of%20single-stranded%20DNA%20libraries%20for%20the%20sequencing%20of%20DNA%20from%20ancient%20biological%20remains%20and%20other%20sources%20of%20highly%20degraded%20DNA&amp;journal=Nat.%20Protoc.&amp;doi=10.1038%2Fs41596-020-0338-0&amp;volume=15&amp;pages=2279-2300&amp;publication_year=2020&amp;author=Gansauge%2CM-T&amp;author=Aximu-Petri%2CA&amp;author=Nagel%2CS&amp;author=Meyer%2CM\">\n                    Google Scholar</a></p></li><li data-counter=\"66.\"><p>Dee, M. C14 data pottery coffin burial excavated by Garstang in Nuwayrat (World Museum, Liverpool, UK, 2016).</p></li><li data-counter=\"67.\"><p>Vanthuyne, B. <i>Early Old Kingdom Rock Circle Cemeteries in the 15th and 16th Nomes of Upper Egypt. A Socio-archaeological Investigation of the Cemeteries in Dayr al-Barshā, Dayr Abū Ḥinnis, Benī Ḥasan al-Shurūq and Nuwayrāt</i>. PhD thesis, KU Leuven (2017).</p></li><li data-counter=\"69.\"><p>Reimer, P. J. et al. The IntCal20 Northern Hemisphere radiocarbon age calibration curve (0–55 cal kBP). , 725–757 (2020).</p></li><li data-counter=\"71.\"><p>Bayliss, A. &amp; Marshall, P. <i>Radiocarbon Dating and Chronological Modelling: Guidelines and Best Practice</i> (Historical Association, 2022).</p></li><li data-counter=\"72.\"><p>Brown, T. A., Nelson, D. E., Vogel, J. S. &amp; Southon, J. R. Improved collagen extraction by modified Longin method. , 171–177 (1988).</p></li><li data-counter=\"75.\"><p>Coplen, T. B. Normalization of oxygen and hydrogen isotope data. , 293–297 (1988).</p></li><li data-counter=\"76.\"><p>Chenery, C. A., Pashley, V., Lamb, A. L., Sloane, H. J. &amp; Evans, J. A. The oxygen isotope relationship between the phosphate and structural carbonate fractions of human bioapatite. <i>Rapid Commun. Mass Spectrom.</i>, 309–319 (2012).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/rcm.5331\" data-track-item_id=\"10.1002/rcm.5331\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Frcm.5331\" aria-label=\"Article reference 76\" data-doi=\"10.1002/rcm.5331\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XjtFagtQ%3D%3D\" aria-label=\"CAS reference 76\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22223318\" aria-label=\"PubMed reference 76\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 76\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=The%20oxygen%20isotope%20relationship%20between%20the%20phosphate%20and%20structural%20carbonate%20fractions%20of%20human%20bioapatite&amp;journal=Rapid%20Commun.%20Mass%20Spectrom.&amp;doi=10.1002%2Frcm.5331&amp;volume=26&amp;pages=309-319&amp;publication_year=2012&amp;author=Chenery%2CCA&amp;author=Pashley%2CV&amp;author=Lamb%2CAL&amp;author=Sloane%2CHJ&amp;author=Evans%2CJA\">\n                    Google Scholar</a></p></li><li data-counter=\"77.\"><p>Font, L., Nowell, G. M., Graham Pearson, D., Ottley, C. J. &amp; Willis, S. G. Sr isotope analysis of bird feathers by TIMS: a tool to trace bird migration paths and breeding sites. , 513 (2007).</p></li><li data-counter=\"78.\"><p>Nier, A. O. The isotopic constitution of strontium, barium, bismuth, thallium and mercury. , 275–278 (1938).</p></li><li data-counter=\"79.\"><p>Avanzinelli, R., Conticelli, S. &amp; Francalanci, L. High precision Sr, Nd, and Pb isotopic analyses using the new generation Thermal Ionisation Mass Spectrometer ThermoFinnigan Triton-Ti®. , 147–166 (2015).</p></li><li data-counter=\"80.\"><p>Işcan, M. Y., Loth, S. R. &amp; Wright, R. K. Age estimation from the rib by phase analysis: white females. , 853–863 (1985).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1520/JFS11018J\" data-track-item_id=\"10.1520/JFS11018J\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1520%2FJFS11018J\" aria-label=\"Article reference 80\" data-doi=\"10.1520/JFS11018J\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=4031812\" aria-label=\"PubMed reference 80\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 80\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Age%20estimation%20from%20the%20rib%20by%20phase%20analysis%3A%20white%20females&amp;journal=J.%20Forensic%20Sci.&amp;doi=10.1520%2FJFS11018J&amp;volume=30&amp;pages=853-863&amp;publication_year=1985&amp;author=I%C5%9Fcan%2CMY&amp;author=Loth%2CSR&amp;author=Wright%2CRK\">\n                    Google Scholar</a></p></li><li data-counter=\"81.\"><p>Işcan, M. Y. &amp; Loth, S. R. Determination of age from the sternal rib in white males: a test of the phase method. , 122–132 (1986).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1520/JFS11866J\" data-track-item_id=\"10.1520/JFS11866J\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1520%2FJFS11866J\" aria-label=\"Article reference 81\" data-doi=\"10.1520/JFS11866J\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=3944556\" aria-label=\"PubMed reference 81\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 81\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Determination%20of%20age%20from%20the%20sternal%20rib%20in%20white%20males%3A%20a%20test%20of%20the%20phase%20method&amp;journal=J.%20Forensic%20Sci.&amp;doi=10.1520%2FJFS11866J&amp;volume=31&amp;pages=122-132&amp;publication_year=1986&amp;author=I%C5%9Fcan%2CMY&amp;author=Loth%2CSR\">\n                    Google Scholar</a></p></li><li data-counter=\"82.\"><p>Meindl, R. S. &amp; Lovejoy, C. O. Ectocranial suture closure: a revised method for the determination of skeletal age at death based on the lateral-anterior sutures. , 57–66 (1985).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.1330680106\" data-track-item_id=\"10.1002/ajpa.1330680106\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.1330680106\" aria-label=\"Article reference 82\" data-doi=\"10.1002/ajpa.1330680106\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL28%2FkvVWisg%3D%3D\" aria-label=\"CAS reference 82\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=4061602\" aria-label=\"PubMed reference 82\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 82\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Ectocranial%20suture%20closure%3A%20a%20revised%20method%20for%20the%20determination%20of%20skeletal%20age%20at%20death%20based%20on%20the%20lateral-anterior%20sutures&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.1330680106&amp;volume=68&amp;pages=57-66&amp;publication_year=1985&amp;author=Meindl%2CRS&amp;author=Lovejoy%2CCO\">\n                    Google Scholar</a></p></li><li data-counter=\"83.\"><p>Lovejoy, C. O., Meindl, R. S., Pryzbeck, T. R. &amp; Mensforth, R. P. Chronological metamorphosis of the auricular surface of the ilium: a new method for the determination of adult skeletal age at death. , 15–28 (1985).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.1330680103\" data-track-item_id=\"10.1002/ajpa.1330680103\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.1330680103\" aria-label=\"Article reference 83\" data-doi=\"10.1002/ajpa.1330680103\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL28%2FkvVWjtQ%3D%3D\" aria-label=\"CAS reference 83\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=4061599\" aria-label=\"PubMed reference 83\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 83\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Chronological%20metamorphosis%20of%20the%20auricular%20surface%20of%20the%20ilium%3A%20a%20new%20method%20for%20the%20determination%20of%20adult%20skeletal%20age%20at%20death&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.1330680103&amp;volume=68&amp;pages=15-28&amp;publication_year=1985&amp;author=Lovejoy%2CCO&amp;author=Meindl%2CRS&amp;author=Pryzbeck%2CTR&amp;author=Mensforth%2CRP\">\n                    Google Scholar</a></p></li><li data-counter=\"84.\"><p>Brooks, S. &amp; Suchey, J. M. Skeletal age determination based on the os pubis: a comparison of the Acsádi-Nemeskéri and Suchey-Brooks methods. , 227–238 (1990).</p></li><li data-counter=\"85.\"><p>Trotter, M. &amp; Gleser, G. C. Estimation of stature from long bones of American whites and Negroes. , 463–514 (1952).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.1330100407\" data-track-item_id=\"10.1002/ajpa.1330100407\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.1330100407\" aria-label=\"Article reference 85\" data-doi=\"10.1002/ajpa.1330100407\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:STN:280:DyaG3s%2Fjt1arsQ%3D%3D\" aria-label=\"CAS reference 85\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=13007782\" aria-label=\"PubMed reference 85\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 85\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Estimation%20of%20stature%20from%20long%20bones%20of%20American%20whites%20and%20Negroes&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.1330100407&amp;volume=10&amp;pages=463-514&amp;publication_year=1952&amp;author=Trotter%2CM&amp;author=Gleser%2CGC\">\n                    Google Scholar</a></p></li><li data-counter=\"86.\"><p>Robins, G. &amp; Shute, C. C. D. Predynastic Egyptian stature and physical proportions. , 313–324 (1986).</p></li><li data-counter=\"87.\"><p>Bass, W. M. <i>Human Osteology: A Laboratory and Field Manual</i> (Missouri Archaeological Society, 2006).</p></li><li data-counter=\"88.\"><p>Richard Scott, G. &amp; Irish, J. D. <i>Human Tooth Crown and Root Morphology</i> (Cambridge Univ. Press, 2017).</p></li><li data-counter=\"89.\"><p>Howells, W. W. <i>Skull Shapes and the Map: Craniometric Analyses in the Dispersion of Modern Homo</i>, Vol. 79 (Harvard Univ. Press, 1989) .</p></li><li data-counter=\"90.\"><p>Scott, G. R. et al. rASUDAS: a new web-based application for estimating ancestry from tooth morphology. , 18–31 (2018).</p></li><li data-counter=\"92.\"><p>Ortner, D. J. &amp; Putschar, W. <i>Identification of Paleopathological Conditions in Human Skeletal Remains</i> (Smithsonian Institution, 1985).</p></li><li data-counter=\"93.\"><p>Aufderheide, A. C. &amp; Rodríguez-Martín, C. <i>The Cambridge Encyclopedia of Human Paleopathology</i> (Cambridge Univ. Press, 1998).</p></li><li data-counter=\"94.\"><p>Hawkey, D. E. &amp; Merbs, C. F. Activity‐induced musculoskeletal stress markers (MSM) and subsistence strategy changes among ancient Hudson Bay Eskimos. , 324–338 (1995).</p></li><li data-counter=\"95.\"><p>Alves-Cardoso, F. &amp; Assis, S. Exploring ‘wear and tear’ of joints and ‘muscle function’ assumptions in skeletons with known occupation at death. , 689–700 (2021).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.24334\" data-track-item_id=\"10.1002/ajpa.24334\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.24334\" aria-label=\"Article reference 95\" data-doi=\"10.1002/ajpa.24334\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34013541\" aria-label=\"PubMed reference 95\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 95\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Exploring%20%E2%80%98wear%20and%20tear%E2%80%99%20of%20joints%20and%20%E2%80%98muscle%20function%E2%80%99%20assumptions%20in%20skeletons%20with%20known%20occupation%20at%20death&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.24334&amp;volume=175&amp;pages=689-700&amp;publication_year=2021&amp;author=Alves-Cardoso%2CF&amp;author=Assis%2CS\">\n                    Google Scholar</a></p></li><li data-counter=\"96.\"><p>Wallace, I. J. et al. Experimental evidence that physical activity inhibits osteoarthritis: implications for inferring activity patterns from osteoarthritis in archeological human skeletons. , 223–231 (2022).</p></li><li data-counter=\"97.\"><p>Wilkinson, C. M. &amp; Mahoney, G. in <i>Craniofacial Identification</i> (eds Wilkinson, C. M. &amp; Rynn, C.) 222–237 (Cambridge Univ. Press, 2012).</p></li><li data-counter=\"98.\"><p>El-Mehallawi, I. H. &amp; Soliman, E. M. Ultrasonic assessment of facial soft tissue thicknesses in adult Egyptians. , 99–107 (2001).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1016/S0379-0738(00)00453-9\" data-track-item_id=\"10.1016/S0379-0738(00)00453-9\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1016%2FS0379-0738%2800%2900453-9\" aria-label=\"Article reference 98\" data-doi=\"10.1016/S0379-0738(00)00453-9\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BD3M3js1SltQ%3D%3D\" aria-label=\"CAS reference 98\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11230951\" aria-label=\"PubMed reference 98\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 98\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Ultrasonic%20assessment%20of%20facial%20soft%20tissue%20thicknesses%20in%20adult%20Egyptians&amp;journal=Forensic%20Sci.%20Int.&amp;doi=10.1016%2FS0379-0738%2800%2900453-9&amp;volume=117&amp;pages=99-107&amp;publication_year=2001&amp;author=El-Mehallawi%2CIH&amp;author=Soliman%2CEM\">\n                    Google Scholar</a></p></li><li data-counter=\"100.\"><p>Rynn, C., Balueva, T. &amp; Veselovskaya, E. in <i>Craniofacial Identification</i> (eds Wilkinson, C. M. &amp; Rynn, C.) 193–202 (Cambridge Univ. Press, 2012).</p></li><li data-counter=\"101.\"><p>Wilkinson, C. M. Cognitive bias and facial depiction from skeletal remains. , 1–14 (2021).</p></li><li data-counter=\"108.\"><p>Jónsson, H., Ginolhac, A., Schubert, M., Johnson, P. L. F. &amp; Orlando, L. mapDamage2.0: fast approximate Bayesian estimates of ancient DNA damage parameters. , 1682–1684 (2013).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1093/bioinformatics/btt193\" data-track-item_id=\"10.1093/bioinformatics/btt193\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1093%2Fbioinformatics%2Fbtt193\" aria-label=\"Article reference 108\" data-doi=\"10.1093/bioinformatics/btt193\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23613487\" aria-label=\"PubMed reference 108\">PubMed</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed central reference\" data-track-action=\"pubmed central reference\" href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3694634\" aria-label=\"PubMed Central reference 108\">PubMed Central</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 108\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=mapDamage2.0%3A%20fast%20approximate%20Bayesian%20estimates%20of%20ancient%20DNA%20damage%20parameters&amp;journal=Bioinformatics&amp;doi=10.1093%2Fbioinformatics%2Fbtt193&amp;volume=29&amp;pages=1682-1684&amp;publication_year=2013&amp;author=J%C3%B3nsson%2CH&amp;author=Ginolhac%2CA&amp;author=Schubert%2CM&amp;author=Johnson%2CPLF&amp;author=Orlando%2CL\">\n                    Google Scholar</a></p></li><li data-counter=\"109.\"><p>Meyer, M. et al. Nuclear DNA sequences from the Middle Pleistocene Sima de los Huesos hominins. , 504–507 (2016).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1038/nature17405\" data-track-item_id=\"10.1038/nature17405\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1038%2Fnature17405\" aria-label=\"Article reference 109\" data-doi=\"10.1038/nature17405\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28XksVKlu7Y%3D\" aria-label=\"CAS reference 109\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26976447\" aria-label=\"PubMed reference 109\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 109\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Nuclear%20DNA%20sequences%20from%20the%20Middle%20Pleistocene%20Sima%20de%20los%20Huesos%20hominins&amp;journal=Nature&amp;doi=10.1038%2Fnature17405&amp;volume=531&amp;pages=504-507&amp;publication_year=2016&amp;author=Meyer%2CM\">\n                    Google Scholar</a></p></li><li data-counter=\"111.\"><p>Renaud, G., Slon, V., Duggan, A. T. &amp; Kelso, J. Schmutzi: estimation of contamination and endogenous mitochondrial consensus calling for ancient DNA. , 224 (2015).</p><p><a data-track=\"click_references\" rel=\"noopener\" data-track-label=\"10.1186/s13059-015-0776-0\" data-track-item_id=\"10.1186/s13059-015-0776-0\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://link.springer.com/doi/10.1186/s13059-015-0776-0\" aria-label=\"Article reference 111\" data-doi=\"10.1186/s13059-015-0776-0\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26458810\" aria-label=\"PubMed reference 111\">PubMed</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed central reference\" data-track-action=\"pubmed central reference\" href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4601135\" aria-label=\"PubMed Central reference 111\">PubMed Central</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 111\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Schmutzi%3A%20estimation%20of%20contamination%20and%20endogenous%20mitochondrial%20consensus%20calling%20for%20ancient%20DNA&amp;journal=Genome%20Biol.&amp;doi=10.1186%2Fs13059-015-0776-0&amp;volume=16&amp;publication_year=2015&amp;author=Renaud%2CG&amp;author=Slon%2CV&amp;author=Duggan%2CAT&amp;author=Kelso%2CJ\">\n                    Google Scholar</a></p></li><li data-counter=\"112.\"><p>Korneliussen, T. S., Albrechtsen, A. &amp; Nielsen, R. ANGSD: analysis of next generation sequencing data. , 356 (2014).</p></li><li data-counter=\"113.\"><p>Skoglund, P., Storå, J., Götherström, A. &amp; Jakobsson, M. Accurate sex identification of ancient human remains using DNA shotgun sequencing. , 4477–4482 (2013).</p></li><li data-counter=\"116.\"><p>Briggs, A. W. et al. Removal of deaminated cytosines and detection of in vivo methylation in ancient DNA. , e87–e87 (2010).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1093/nar/gkp1163\" data-track-item_id=\"10.1093/nar/gkp1163\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1093%2Fnar%2Fgkp1163\" aria-label=\"Article reference 116\" data-doi=\"10.1093/nar/gkp1163\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20028723\" aria-label=\"PubMed reference 116\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 116\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Removal%20of%20deaminated%20cytosines%20and%20detection%20of%20in%20vivo%20methylation%20in%20ancient%20DNA&amp;journal=Nucleic%20Acids%20Res.&amp;doi=10.1093%2Fnar%2Fgkp1163&amp;volume=38&amp;pages=e87-e87&amp;publication_year=2010&amp;author=Briggs%2CAW\">\n                    Google Scholar</a></p></li><li data-counter=\"117.\"><p>Schönherr, S., Weissensteiner, H., Kronenberg, F. &amp; Forer, L. Haplogrep3—an interactive haplogroup classification and analysis platform. , W263–W268 (2023).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1093/nar/gkad284\" data-track-item_id=\"10.1093/nar/gkad284\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1093%2Fnar%2Fgkad284\" aria-label=\"Article reference 117\" data-doi=\"10.1093/nar/gkad284\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=37070190\" aria-label=\"PubMed reference 117\">PubMed</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed central reference\" data-track-action=\"pubmed central reference\" href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC10320078\" aria-label=\"PubMed Central reference 117\">PubMed Central</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 117\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Haplogrep3%E2%80%94an%20interactive%20haplogroup%20classification%20and%20analysis%20platform&amp;journal=Nucleic%20Acids%20Res.&amp;doi=10.1093%2Fnar%2Fgkad284&amp;volume=51&amp;pages=W263-W268&amp;publication_year=2023&amp;author=Sch%C3%B6nherr%2CS&amp;author=Weissensteiner%2CH&amp;author=Kronenberg%2CF&amp;author=Forer%2CL\">\n                    Google Scholar</a></p></li><li data-counter=\"127.\"><p>Fregel, R. et al. Ancient genomes from North Africa evidence prehistoric migrations to the Maghreb from both the Levant and Europe. <i>Proc. Natl Acad. Sci. USA</i>, 6774–6779 (2018).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1073/pnas.1800851115\" data-track-item_id=\"10.1073/pnas.1800851115\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1073%2Fpnas.1800851115\" aria-label=\"Article reference 127\" data-doi=\"10.1073/pnas.1800851115\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29895688\" aria-label=\"PubMed reference 127\">PubMed</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed central reference\" data-track-action=\"pubmed central reference\" href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6042094\" aria-label=\"PubMed Central reference 127\">PubMed Central</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 127\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Ancient%20genomes%20from%20North%20Africa%20evidence%20prehistoric%20migrations%20to%20the%20Maghreb%20from%20both%20the%20Levant%20and%20Europe&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1800851115&amp;volume=115&amp;pages=6774-6779&amp;publication_year=2018&amp;author=Fregel%2CR\">\n                    Google Scholar</a></p></li><li data-counter=\"147.\"><p>Omrak, A. et al. Genomic evidence establishes Anatolia as the source of the European Neolithic gene pool. , 270–275 (2016).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1016/j.cub.2015.12.019\" data-track-item_id=\"10.1016/j.cub.2015.12.019\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1016%2Fj.cub.2015.12.019\" aria-label=\"Article reference 147\" data-doi=\"10.1016/j.cub.2015.12.019\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28XhvFarsw%3D%3D\" aria-label=\"CAS reference 147\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26748850\" aria-label=\"PubMed reference 147\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 147\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Genomic%20evidence%20establishes%20Anatolia%20as%20the%20source%20of%20the%20European%20Neolithic%20gene%20pool&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2015.12.019&amp;volume=26&amp;pages=270-275&amp;publication_year=2016&amp;author=Omrak%2CA\">\n                    Google Scholar</a></p></li><li data-counter=\"149.\"><p>Raghavan, M. et al. Upper Palaeolithic Siberian genome reveals dual ancestry of native Americans. , 87–91 (2014).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1038/nature12736\" data-track-item_id=\"10.1038/nature12736\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1038%2Fnature12736\" aria-label=\"Article reference 149\" data-doi=\"10.1038/nature12736\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24256729\" aria-label=\"PubMed reference 149\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 149\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Upper%20Palaeolithic%20Siberian%20genome%20reveals%20dual%20ancestry%20of%20native%20Americans&amp;journal=Nature&amp;doi=10.1038%2Fnature12736&amp;volume=505&amp;pages=87-91&amp;publication_year=2014&amp;author=Raghavan%2CM\">\n                    Google Scholar</a></p></li><li data-counter=\"150.\"><p>Rodríguez-Varela, R. et al. Genomic analyses of pre-European conquest human remains from the Canary Islands reveal close affinity to modern North Africans. , 1677–1679 (2018).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1016/j.cub.2018.04.083\" data-track-item_id=\"10.1016/j.cub.2018.04.083\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1016%2Fj.cub.2018.04.083\" aria-label=\"Article reference 150\" data-doi=\"10.1016/j.cub.2018.04.083\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29787714\" aria-label=\"PubMed reference 150\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 150\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Genomic%20analyses%20of%20pre-European%20conquest%20human%20remains%20from%20the%20Canary%20Islands%20reveal%20close%20affinity%20to%20modern%20North%20Africans&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2018.04.083&amp;volume=28&amp;pages=1677-1679&amp;publication_year=2018&amp;author=Rodr%C3%ADguez-Varela%2CR\">\n                    Google Scholar</a></p></li><li data-counter=\"151.\"><p>Schlebusch, C. M. et al. Southern African ancient genomes estimate modern human divergence to 350,000 to 260,000 years ago. , 652–655 (2017).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1126/science.aao6266\" data-track-item_id=\"10.1126/science.aao6266\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1126%2Fscience.aao6266\" aria-label=\"Article reference 151\" data-doi=\"10.1126/science.aao6266\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXhslCitb3F\" aria-label=\"CAS reference 151\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28971970\" aria-label=\"PubMed reference 151\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 151\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Southern%20African%20ancient%20genomes%20estimate%20modern%20human%20divergence%20to%20350%2C000%20to%20260%2C000%20years%20ago&amp;journal=Science&amp;doi=10.1126%2Fscience.aao6266&amp;volume=358&amp;pages=652-655&amp;publication_year=2017&amp;author=Schlebusch%2CCM\">\n                    Google Scholar</a></p></li><li data-counter=\"152.\"><p>Seguin-Orlando, A. et al. Genomic structure in Europeans dating back at least 36,200 years. , 1113–1118 (2014).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1126/science.aaa0114\" data-track-item_id=\"10.1126/science.aaa0114\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1126%2Fscience.aaa0114\" aria-label=\"Article reference 152\" data-doi=\"10.1126/science.aaa0114\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXhvFKqtLfK\" aria-label=\"CAS reference 152\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25378462\" aria-label=\"PubMed reference 152\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 152\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Genomic%20structure%20in%20Europeans%20dating%20back%20at%20least%2036%2C200%20years&amp;journal=Science&amp;doi=10.1126%2Fscience.aaa0114&amp;volume=346&amp;pages=1113-1118&amp;publication_year=2014&amp;author=Seguin-Orlando%2CA\">\n                    Google Scholar</a></p></li><li data-counter=\"154.\"><p>van de Loosdrecht, M. et al. Pleistocene North African genomes link Near Eastern and sub-Saharan African human populations. , 548–552 (2018).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1126/science.aar8380\" data-track-item_id=\"10.1126/science.aar8380\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1126%2Fscience.aar8380\" aria-label=\"Article reference 154\" data-doi=\"10.1126/science.aar8380\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29545507\" aria-label=\"PubMed reference 154\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 154\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Pleistocene%20North%20African%20genomes%20link%20Near%20Eastern%20and%20sub-Saharan%20African%20human%20populations&amp;journal=Science&amp;doi=10.1126%2Fscience.aar8380&amp;volume=360&amp;pages=548-552&amp;publication_year=2018&amp;author=Loosdrecht%2CM\">\n                    Google Scholar</a></p></li><li data-counter=\"157.\"><p>Wang, C.-C. et al. Ancient human genome-wide data from a 3000-year interval in the Caucasus corresponds with eco-geographic regions. , 1–13 (2019).</p></li><li data-counter=\"159.\"><p>Yang, M. A. et al. Ancient DNA indicates human population shifts and admixture in northern and southern China. , 282–288 (2020).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1126/science.aba0909\" data-track-item_id=\"10.1126/science.aba0909\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1126%2Fscience.aba0909\" aria-label=\"Article reference 159\" data-doi=\"10.1126/science.aba0909\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXhsVSjtLbN\" aria-label=\"CAS reference 159\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32409524\" aria-label=\"PubMed reference 159\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 159\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Ancient%20DNA%20indicates%20human%20population%20shifts%20and%20admixture%20in%20northern%20and%20southern%20China&amp;journal=Science&amp;doi=10.1126%2Fscience.aba0909&amp;volume=369&amp;pages=282-288&amp;publication_year=2020&amp;author=Yang%2CMA\">\n                    Google Scholar</a></p></li><li data-counter=\"167.\"><p>Vyas, D. N., Al-Meeri, A. &amp; Mulligan, C. J. Testing support for the northern and southern dispersal routes out of Africa: an analysis of Levantine and southern Arabian populations. , 736–749 (2017).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1002/ajpa.23312\" data-track-item_id=\"10.1002/ajpa.23312\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1002%2Fajpa.23312\" aria-label=\"Article reference 167\" data-doi=\"10.1002/ajpa.23312\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28913852\" aria-label=\"PubMed reference 167\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 167\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Testing%20support%20for%20the%20northern%20and%20southern%20dispersal%20routes%20out%20of%20Africa%3A%20an%20analysis%20of%20Levantine%20and%20southern%20Arabian%20populations&amp;journal=Am.%20J.%20Phys.%20Anthropol.&amp;doi=10.1002%2Fajpa.23312&amp;volume=164&amp;pages=736-749&amp;publication_year=2017&amp;author=Vyas%2CDN&amp;author=Al-Meeri%2CA&amp;author=Mulligan%2CCJ\">\n                    Google Scholar</a></p></li><li data-counter=\"170.\"><p>Mallick, S. et al. The Allen Ancient DNA Resource (AADR) a curated compendium of ancient human genomes. , 1–10 (2024).</p></li><li data-counter=\"174.\"><p>Rubinacci, S., Ribeiro, D. M., Hofmeister, R. J. &amp; Delaneau, O. Efficient phasing and imputation of low-coverage sequencing data using large reference panels. , 120–126 (2021).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1038/s41588-020-00756-0\" data-track-item_id=\"10.1038/s41588-020-00756-0\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1038%2Fs41588-020-00756-0\" aria-label=\"Article reference 174\" data-doi=\"10.1038/s41588-020-00756-0\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXosVOluw%3D%3D\" aria-label=\"CAS reference 174\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33414550\" aria-label=\"PubMed reference 174\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 174\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Efficient%20phasing%20and%20imputation%20of%20low-coverage%20sequencing%20data%20using%20large%20reference%20panels&amp;journal=Nat.%20Genet.&amp;doi=10.1038%2Fs41588-020-00756-0&amp;volume=53&amp;pages=120-126&amp;publication_year=2021&amp;author=Rubinacci%2CS&amp;author=Ribeiro%2CDM&amp;author=Hofmeister%2CRJ&amp;author=Delaneau%2CO\">\n                    Google Scholar</a></p></li><li data-counter=\"175.\"><p>The 1000 Genomes Project Consortium. A global reference for human genetic variation. , 68–74 (2015).</p></li><li data-counter=\"176.\"><p>Chaitanya, L. et al. The HIrisPlex-S system for eye, hair and skin colour prediction from DNA: introduction and forensic developmental validation. <i>Forensic Sci. Int. Genet.</i>, 123–135 (2018).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1016/j.fsigen.2018.04.004\" data-track-item_id=\"10.1016/j.fsigen.2018.04.004\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1016%2Fj.fsigen.2018.04.004\" aria-label=\"Article reference 176\" data-doi=\"10.1016/j.fsigen.2018.04.004\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXpt1egur4%3D\" aria-label=\"CAS reference 176\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29753263\" aria-label=\"PubMed reference 176\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 176\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=The%20HIrisPlex-S%20system%20for%20eye%2C%20hair%20and%20skin%20colour%20prediction%20from%20DNA%3A%20introduction%20and%20forensic%20developmental%20validation&amp;journal=Forensic%20Sci.%20Int.%20Genet.&amp;doi=10.1016%2Fj.fsigen.2018.04.004&amp;volume=35&amp;pages=123-135&amp;publication_year=2018&amp;author=Chaitanya%2CL\">\n                    Google Scholar</a></p></li><li data-counter=\"177.\"><p>Walsh, S. et al. Developmental validation of the HIrisPlex system: DNA-based eye and hair colour prediction for forensic and anthropological usage. <i>Forensic Sci. Int. Genet.</i>, 150–161 (2014).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1016/j.fsigen.2013.12.006\" data-track-item_id=\"10.1016/j.fsigen.2013.12.006\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1016%2Fj.fsigen.2013.12.006\" aria-label=\"Article reference 177\" data-doi=\"10.1016/j.fsigen.2013.12.006\">Article</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"cas reference\" data-track-action=\"cas reference\" href=\"https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXisFCitLg%3D\" aria-label=\"CAS reference 177\">CAS</a><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"pubmed reference\" data-track-action=\"pubmed reference\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24528593\" aria-label=\"PubMed reference 177\">PubMed</a><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 177\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Developmental%20validation%20of%20the%20HIrisPlex%20system%3A%20DNA-based%20eye%20and%20hair%20colour%20prediction%20for%20forensic%20and%20anthropological%20usage&amp;journal=Forensic%20Sci.%20Int.%20Genet.&amp;doi=10.1016%2Fj.fsigen.2013.12.006&amp;volume=9&amp;pages=150-161&amp;publication_year=2014&amp;author=Walsh%2CS\">\n                    Google Scholar</a></p></li>","contentLength":15895,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44450304"},{"title":"What to build instead of AI agents","url":"https://decodingml.substack.com/p/stop-building-ai-agents","date":1751500963,"author":"giuliomagnifico","guid":181701,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44450160"},{"title":"Intel's New CEO Explores Big Shift In Chip Manufacturing Business","url":"https://tech.slashdot.org/story/25/07/02/2149214/intels-new-ceo-explores-big-shift-in-chip-manufacturing-business?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751500920,"author":"BeauHD","guid":181435,"unread":true,"content":"An anonymous reader quotes a report from Reuters: Intel's new chief executive is exploring a big change to its contract manufacturing business to win major customers, two people familiar with the matter told Reuters, in a potentially expensive shift from his predecessor's plans. The new strategy for Intel's foundry business would mean offering outside customers a newer generation of technology, the people said. That next-generation chipmaking process, analysts believe, will be more competitive against Taiwan Semiconductor Manufacturing Co in trying to land major customers such as Apple or Nvidia.\n \nSince taking the company's helm in March, CEO Lip-Bu Tan has moved fast to cut costs and find a new path to revive the ailing U.S. chipmaker. By June, he started voicing that a manufacturing process known as 18A, in which prior CEO Pat Gelsinger had invested heavily, was losing its appeal to new customers, said the sources, who spoke on condition of anonymity. To put aside external sales of 18A and its variant 18A-P, manufacturing processes that have cost Intel billions of dollars to develop, the company would have to take a write-off, one of the people familiar with the matter said. Industry analysts contacted by Reuters said such a charge could amount to a loss of hundreds of millions, if not billions, of dollars.\n \nIntel declined to comment on such \"hypothetical scenarios or market speculation.\" It said the lead customer for 18A has long been Intel itself, and it aims to ramp production of its \"Panther Lake\" laptop chips later in 2025, which it called the most advanced processors ever designed and manufactured in the United States. Persuading outside clients to use Intel's factories remains key to its future. As its 18A fabrication process faced delays, rival TSMC's N2 technology has been on track for production. Tan's preliminary answer to this challenge: focus more resources on 14A, a next-generation chipmaking process where Intel expects to have advantages over Taiwan's TSMC, the two sources said. The move is part of a play for big customers like Apple and Nvidia, which currently pay TSMC to manufacture their chips.","contentLength":2153,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Navigating Failures in Pods With Devices","url":"https://kubernetes.io/blog/2025/07/03/navigating-failures-in-pods-with-devices/","date":1751500800,"author":"","guid":181564,"unread":true,"content":"<p>Kubernetes is the de facto standard for container orchestration, but when it\ncomes to handling specialized hardware like GPUs and other accelerators, things\nget a bit complicated. This blog post dives into the challenges of managing\nfailure modes when operating pods with devices in Kubernetes, based on insights\nfrom <a href=\"https://sched.co/1i7pT\">Sergey Kanzhelev and Mrunal Patel's talk at KubeCon NA\n2024</a>. You can follow the links to\n<a href=\"https://static.sched.com/hosted_files/kccncna2024/b9/KubeCon%20NA%202024_%20Navigating%20Failures%20in%20Pods%20With%20Devices_%20Challenges%20and%20Solutions.pptx.pdf?_gl=1*191m4j5*_gcl_au*MTU1MDM0MTM1My4xNzMwOTE4ODY5LjIxNDI4Nzk1NDIuMTczMTY0ODgyMC4xNzMxNjQ4ODIy*FPAU*MTU1MDM0MTM1My4xNzMwOTE4ODY5\">slides</a>\nand\n<a href=\"https://www.youtube.com/watch?v=-YCnOYTtVO8&amp;list=PLj6h78yzYM2Pw4mRw4S-1p_xLARMqPkA7&amp;index=150\">recording</a>.</p><h2>The AI/ML boom and its impact on Kubernetes</h2><p>The rise of AI/ML workloads has brought new challenges to Kubernetes. These\nworkloads often rely heavily on specialized hardware, and any device failure can\nsignificantly impact performance and lead to frustrating interruptions. As\nhighlighted in the 2024 <a href=\"https://ai.meta.com/research/publications/the-llama-3-herd-of-models/\">Llama\npaper</a>,\nhardware issues, particularly GPU failures, are a major cause of disruption in\nAI/ML training. You can also learn how much effort NVIDIA spends on handling\ndevices failures and maintenance in the KubeCon talk by <a href=\"https://kccncna2024.sched.com/event/1i7kJ/all-your-gpus-are-belong-to-us-an-inside-look-at-nvidias-self-healing-geforce-now-infrastructure-ryan-hallisey-piotr-prokop-pl-nvidia\">Ryan Hallisey and Piotr\nProkop All-Your-GPUs-Are-Belong-to-Us: An Inside Look at NVIDIA's Self-Healing\nGeForce NOW\nInfrastructure</a>\n(<a href=\"https://www.youtube.com/watch?v=iLnHtKwmu2I\">recording</a>) as they see 19\nremediation requests per 1000 nodes a day!\nWe also see data centers offering spot consumption models and overcommit on\npower, making device failures commonplace and a part of the business model.</p><p>However, Kubernetes’s view on resources is still very static. The resource is\neither there or not. And if it is there, the assumption is that it will stay\nthere fully functional - Kubernetes lacks good support for handling full or partial\nhardware failures. These long-existing assumptions combined with the overall complexity of a setup lead\nto a variety of failure modes, which we discuss here.</p><h3>Understanding AI/ML workloads</h3><p>Generally, all AI/ML workloads require specialized hardware, have challenging\nscheduling requirements, and are expensive when idle. AI/ML workloads typically\nfall into two categories - training and inference. Here is an oversimplified\nview of those categories’ characteristics, which are different from traditional workloads\nlike web services:</p><dl><dd>These workloads are resource-intensive, often consuming entire\nmachines and running as gangs of pods. Training jobs are usually \"run to\ncompletion\" - but that could be days, weeks or even months. Any failure in a\nsingle pod can necessitate restarting the entire step across all the pods.</dd><dd>These workloads are usually long-running or run indefinitely,\nand can be small enough to consume a subset of a Node’s devices or large enough to span\nmultiple nodes. They often require downloading huge files with the model\nweights.</dd></dl><p>These workload types specifically break many past assumptions:</p><table><caption>Workload assumptions before and now</caption><tbody><tr><td>Can get a better CPU and the app will work faster.</td><td>Require a  device (or ) to run.</td></tr><tr><td>When something doesn’t work, just recreate it.</td><td>Allocation or reallocation is expensive.</td></tr><tr><td>Any node will work. No need to coordinate between Pods.</td><td>Scheduled in a special way - devices often connected in a cross-node topology.</td></tr><tr><td>Each Pod can be plug-and-play replaced if failed.</td><td>Pods are a part of a larger task. Lifecycle of an entire task depends on each Pod.</td></tr><tr><td>Container images are slim and easily available.</td><td>Container images may be so big that they require special handling.</td></tr><tr><td>Long initialization can be offset by slow rollout.</td><td>Initialization may be long and should be optimized, sometimes across many Pods together.</td></tr><tr><td>Compute nodes are commoditized and relatively inexpensive, so some idle time is acceptable.</td><td>Nodes with specialized hardware can be an order of magnitude more expensive than those without, so idle time is very wasteful.</td></tr></tbody></table><p>The existing failure model was relying on old assumptions. It may still work for\nthe new workload types, but it has limited knowledge about devices and is very\nexpensive for them. In some cases, even prohibitively expensive. You will see\nmore examples later in this article.</p><h3>Why Kubernetes still reigns supreme</h3><p>This article is not going deeper into the question: why not start fresh for\nAI/ML workloads since they are so different from the traditional Kubernetes\nworkloads. Despite many challenges, Kubernetes remains the platform of choice\nfor AI/ML workloads. Its maturity, security, and rich ecosystem of tools make it\na compelling option. While alternatives exist, they often lack the years of\ndevelopment and refinement that Kubernetes offers. And the Kubernetes developers\nare actively addressing the gaps identified in this article and beyond.</p><h2>The current state of device failure handling</h2><p>This section outlines different failure modes and the best practices and DIY\n(Do-It-Yourself) solutions used today. The next session will describe a roadmap\nof improving things for those failure modes.</p><h3>Failure modes: K8s infrastructure</h3><p>In order to understand the failures related to the Kubernetes infrastructure,\nyou need to understand how many moving parts are involved in scheduling a Pod on\nthe node. The sequence of events when the Pod is scheduled in the Node is as\nfollows:</p><ol><li> is scheduled on the Node</li><li> is registered with the  via local gRPC</li><li> uses  to watch for devices and updates capacity of\nthe node</li><li> places a  on a Node based on the updated capacity</li><li> asks  to  devices for a </li><li> creates a  with the allocated devices attached to it</li></ol><p>This diagram shows some of those actors involved:</p><p>As there are so many actors interconnected, every one of them and every\nconnection may experience interruptions. This leads to many exceptional\nsituations that are often considered failures, and may cause serious workload\ninterruptions:</p><ul><li>Pods failing admission at various stages of its lifecycle</li><li>Pods unable to run on perfectly fine hardware</li><li>Scheduling taking unexpectedly long time</li></ul><p>The goal for Kubernetes is to make the interruption between these components as\nreliable as possible. Kubelet already implements retries, grace periods, and\nother techniques to improve it. The roadmap section goes into details on other\nedge cases that the Kubernetes project tracks. However, all these improvements\nonly work when these best practices are followed:</p><ul><li>Configure and restart kubelet and the container runtime (such as containerd or CRI-O)\nas early as possible to not interrupt the workload.</li><li>Monitor device plugin health and carefully plan for upgrades.</li><li>Do not overload the node with less-important workloads to prevent interruption\nof device plugin and other components.</li><li>Configure user pods tolerations to handle node readiness flakes.</li><li>Configure and code graceful termination logic carefully to not block devices\nfor too long.</li></ul><p>Another class of Kubernetes infra-related issues is driver-related. With\ntraditional resources like CPU and memory, no compatibility checks between the\napplication and hardware were needed. With special devices like hardware\naccelerators, there are new failure modes. Device drivers installed on the node:</p><ul><li>Be compatible with an app</li><li>Must work with other drivers (like <a href=\"https://developer.nvidia.com/nccl\">nccl</a>,\netc.)</li></ul><p>Best practices for handling driver versions:</p><ul><li>Monitor driver installer health</li><li>Plan upgrades of infrastructure and Pods to match the version</li><li>Have canary deployments whenever possible</li></ul><p>Following the best practices in this section and using device plugins and device\ndriver installers from trusted and reliable sources generally eliminate this\nclass of failures. Kubernetes is tracking work to make this space even better.</p><h3>Failure modes: device failed</h3><p>There is very little handling of device failure in Kubernetes today. Device\nplugins report the device failure only by changing the count of allocatable\ndevices. And Kubernetes relies on standard mechanisms like liveness probes or\ncontainer failures to allow Pods to communicate the failure condition to the\nkubelet. However, Kubernetes does not correlate device failures with container\ncrashes and does not offer any mitigation beyond restarting the container while\nbeing attached to the same device.</p><p>This is why many plugins and DIY solutions exist to handle device failures based\non various signals.</p><p>In many cases a failed device will result in unrecoverable and very expensive\nnodes doing nothing. A simple DIY solution is a . The\ncontroller could compare the device allocatable count with the capacity and if\nthe capacity is greater, it starts a timer. Once the timer reaches a threshold,\nthe health controller kills and recreates a node.</p><p>There are problems with the  approach:</p><ul><li>Root cause of the device failure is typically not known</li><li>The controller is not workload aware</li><li>Failed device might not be in use and you want to keep other devices running</li><li>The detection may be too slow as it is very generic</li><li>The node may be part of a bigger set of nodes and simply cannot be deleted in\nisolation without other nodes</li></ul><p>There are variations of the health controller solving some of the problems\nabove. The overall theme here though is that to best handle failed devices, you\nneed customized handling for the specific workload. Kubernetes doesn’t yet offer\nenough abstraction to express how critical the device is for a node, for the\ncluster, and for the Pod it is assigned to.</p><p>Another DIY approach for device failure handling is a per-pod reaction on a\nfailed device. This approach is applicable for  workloads that are\nimplemented as Jobs.</p><p>There are some problems with the  approach for Jobs:</p><ul><li>There is no well-known  condition, so this approach does not work for the\ngeneric Pod case</li><li>Error codes must be coded carefully and in some cases are hard to guarantee.</li><li>Only works with Jobs with , due to the limitation of a pod\nfailure policy feature.</li></ul><p>So, this solution has limited applicability.</p><p>A little more generic approach is to implement the Pod watcher as a DIY solution\nor use some third party tools offering this functionality. The pod watcher is\nmost often used to handle device failures for inference workloads.</p><p>Since Kubernetes just keeps a pod assigned to a device, even if the device is\nreportedly unhealthy, the idea is to detect this situation with the pod watcher\nand apply some remediation. It often involves obtaining device health status and\nits mapping to the Pod using Pod Resources API on the node. If a device fails,\nit can then delete the attached Pod as a remediation. The replica set will\nhandle the Pod recreation on a healthy device.</p><p>The other reasons to implement this watcher:</p><ul><li>Without it, the Pod will keep being assigned to the failed device forever.</li><li>There is no  for a pod with .</li><li>There are no built-in controllers that delete Pods in CrashLoopBackoff.</li></ul><p>Problems with the :</p><ul><li>The signal for the pod watcher is expensive to get, and involves some\nprivileged actions.</li><li>It is a custom solution and it assumes the importance of a device for a Pod.</li><li>The pod watcher relies on external controllers to reschedule a Pod.</li></ul><p>There are more variations of DIY solutions for handling device failures or\nupcoming maintenance. Overall, Kubernetes has enough extension points to\nimplement these solutions. However, some extension points require higher\nprivilege than users may be comfortable with or are too disruptive. The roadmap\nsection goes into more details on specific improvements in handling the device\nfailures.</p><h3>Failure modes: container code failed</h3><p>When the container code fails or something bad happens with it, like out of\nmemory conditions, Kubernetes knows how to handle those cases. There is either\nthe restart of a container, or a crash of a Pod if it has \nand scheduling it on another node. Kubernetes has limited expressiveness on what\nis a failure (for example, non-zero exit code or liveness probe failure) and how\nto react on such a failure (mostly either Always restart or immediately fail the\nPod).</p><p>This level of expressiveness is often not enough for the complicated AI/ML\nworkloads. AI/ML pods are better rescheduled locally or even in-place as that\nwould save on image pulling time and device allocation. AI/ML pods are often\ninterconnected and need to be restarted together. This adds another level of\ncomplexity and optimizing it often brings major savings in running AI/ML\nworkloads.</p><p>There are various DIY solutions to handle Pod failures orchestration. The most\ntypical one is to wrap a main executable in a container by some orchestrator.\nAnd this orchestrator will be able to restart the main executable whenever the\njob needs to be restarted because some other pod has failed.</p><p>Solutions like this are very fragile and elaborate. They are often worth the\nmoney saved comparing to a regular JobSet delete/recreate cycle when used in\nlarge training jobs. Making these solutions less fragile and more streamlined\nby developing new hooks and extension points in Kubernetes will make it\neasy to apply to smaller jobs, benefiting everybody.</p><h3>Failure modes: device degradation</h3><p>Not all device failures are terminal for the overall workload or batch job.\nAs the hardware stack gets more and more\ncomplex, misconfiguration on one of the hardware stack layers, or driver\nfailures, may result in devices that are functional, but lagging on performance.\nOne device that is lagging behind can slow down the whole training job.</p><p>We see reports of such cases more and more often. Kubernetes has no way to\nexpress this type of failures today and since it is the newest type of failure\nmode, there is not much of a best practice offered by hardware vendors for\ndetection and third party tooling for remediation of these situations.</p><p>Typically, these failures are detected based on observed workload\ncharacteristics. For example, the expected speed of AI/ML training steps on\nparticular hardware. Remediation for those issues is highly depend on a workload needs.</p><p>As outlined in a section above, Kubernetes offers a lot of extension points\nwhich are used to implement various DIY solutions. The space of AI/ML is\ndeveloping very fast, with changing requirements and usage patterns. SIG Node is\ntaking a measured approach of enabling more extension points to implement the\nworkload-specific scenarios over introduction of new semantics to support\nspecific scenarios. This means prioritizing making information about failures\nreadily available over implementing automatic remediations for those failures\nthat might only be suitable for a subset of workloads.</p><p>This approach ensures there are no drastic changes for workload handling which\nmay break existing, well-oiled DIY solutions or experiences with the existing\nmore traditional workloads.</p><p>Many error handling techniques used today work for AI/ML, but are very\nexpensive. SIG Node will invest in extension points to make those cheaper, with\nthe understanding that the price cutting for AI/ML is critical.</p><p>The following is the set of specific investments we envision for various failure\nmodes.</p><h3>Roadmap for failure modes: K8s infrastructure</h3><p>The area of Kubernetes infrastructure is the easiest to understand and very\nimportant to make right for the upcoming transition from Device Plugins to DRA.\nSIG Node is tracking many work items in this area, most notably the following:</p><p>Basically, every interaction of Kubernetes components must be reliable via\neither the kubelet improvements or the best practices in plugins development\nand deployment.</p><h3>Roadmap for failure modes: device failed</h3><p>For the device failures some patterns are already emerging in common scenarios\nthat Kubernetes can support. However, the very first step is to make information\nabout failed devices available easier. The very first step here is the work in\n<a href=\"https://kep.k8s.io/4680\">KEP 4680</a> (Add Resource Health Status to the Pod Status for\nDevice Plugin and DRA).</p><p>Longer term ideas include to be tested:</p><ul><li>Integrate device failures into Pod Failure Policy.</li><li>Node-local retry policies, enabling pod failure policies for Pods with\nrestartPolicy=OnFailure and possibly beyond that.</li><li>Ability to  pod, including with the , so it can\nget a new device allocated.</li><li>Add device health to the ResourceSlice used to represent devices in DRA,\nrather than simply withdrawing an unhealthy device from the ResourceSlice.</li></ul><h3>Roadmap for failure modes: container code failed</h3><p>The main improvements to handle container code failures for AI/ML workloads are\nall targeting cheaper error handling and recovery. The cheapness is mostly\ncoming from reuse of pre-allocated resources as much as possible. From reusing\nthe Pods by restarting containers in-place, to node local restart of containers\ninstead of rescheduling whenever possible, to snapshotting support, and\nre-scheduling prioritizing the same node to save on image pulls.</p><p>Consider this scenario: A big training job needs 512 Pods to run. And one of the\npods failed. It means that all Pods need to be interrupted and synced up to\nrestart the failed step. The most efficient way to achieve this generally is to\nreuse as many Pods as possible by restarting them in-place, while replacing the\nfailed pod to clear up the error from it. Like demonstrated in this picture:</p><p>It is possible to implement this scenario, but all solutions implementing it are\nfragile due to lack of certain extension points in Kubernetes. Adding these\nextension points to implement this scenario is on the Kubernetes roadmap.</p><h3>Roadmap for failure modes: device degradation</h3><p>There is very little done in this area - there is no clear detection signal,\nvery limited troubleshooting tooling, and no built-in semantics to express the\n\"degraded\" device on Kubernetes. There has been discussion of adding data on\ndevice performance or degradation in the ResourceSlice used by DRA to represent\ndevices, but it is not yet clearly defined. There are also projects like\n<a href=\"https://github.com/medik8s/node-healthcheck-operator\">node-healthcheck-operator</a>\nthat can be used for some scenarios.</p><p>We expect developments in this area from hardware vendors and cloud providers, and we expect to see mostly DIY\nsolutions in the near future. As more users get exposed to AI/ML workloads, this\nis a space needing feedback on patterns used here.</p><p>The Kubernetes community encourages feedback and participation in shaping the\nfuture of device failure handling. Join SIG Node and contribute to the ongoing\ndiscussions!</p><p>This blog post provides a high-level overview of the challenges and future\ndirections for device failure management in Kubernetes. By addressing these\nissues, Kubernetes can solidify its position as the leading platform for AI/ML\nworkloads, ensuring resilience and reliability for applications that depend on\nspecialized hardware.</p>","contentLength":18095,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tools: Code Is All You Need","url":"https://lucumr.pocoo.org/2025/7/3/tools/","date":1751500800,"author":"Armin Ronacher","guid":183031,"unread":true,"content":"<p>If you've been following me on Twitter, you know I'm not a big fan of MCP right\nnow.  It's not that I dislike the idea; I just haven't found it to work as\nadvertised.  In my view, MCP suffers from two major flaws:</p><ol><li><strong>It isn’t truly composable.</strong>  Most composition happens through inference.</li><li><strong>It demands too much context.</strong>  You must supply significant upfront input, and\nevery tool invocation consumes even more context than simply writing and\nrunning code.</li></ol><p>A quick experiment makes this clear: try completing a GitHub task with the\nGitHub MCP, then repeat it with the  CLI tool.  You'll almost certainly\nfind the latter uses context far more efficiently and you get to your intended\nresults quicker.</p><p>I want to address some of the feedback I've received on my stance on this.  I\nevaluated MCP extensively in the context of agentic coding, where its\nlimitations were easiest to observe.  One piece of feedback is that MCP might\nnot make a ton of sense for general code generation, because models are already\nvery good at that but they make a lot of sense for end-user applications, like,\nsay, automating a domain-specific task in a financial company.  Another one is\nthat I need to look at the world of the future, where models will be able to\nreach many more tools and handle much more complex tasks.</p><p>My current take is that my data indicates that current MCP will always be harder\nto use than writing code, primarily due to the reliance on inference.  If you\nlook at the approaches today for pushing towards higher tool counts, the\nproposals all include a layer of filtering.  You pass all your tools to an LLM\nand ask it to filter it down based on the taks at hand.  So far, there hasn't\nbeen much better approaches proposed.</p><p>The main reason I believe this will most likely also hold true — that you\nshouldn't be using MCP in its current form even for non-programming,\ndomain-specific tasks — is that even in those cases code generation just is the\nbetter choice because of the ability to compose.</p><h2>Replace Yourself With A Shellscript</h2><p>The way to think about this problem is that when you don't have an AI, and\nyou're solving a problem as a software engineer, your tool of choice is code.\nPerhaps as a non-software engineer, code is out of reach.  Many many tasks\npeople do by hand are actually automatable through software.  The challenge is\nfinding someone to write that software.  If you're working in a niche\nenvironment and you're not a programmer yourself, you might not pick up a\nprogramming book to learn how to code, and you might not find a developer\nwilling to provide you with a custom piece of software to solve your specific\nproblem.  And yes, maybe your task requires some inference, but many do need\nthem all the time.</p><p>There is a reason we say “to replace oneself with a shell script”, it's because\nthat has been happening for a long time.  With LLMs and programming, the idea is\nthat rather than replacing yourself with a shell script, you're replacing\nyourself with an LLM.  But you run into three problems: cost, speed, and general\nreliability.  All these problems are what we need to deal with <em>before we can\neven think of tool usage</em> or MCP.  We need to figure out how to ensure that our\nautomated task actually works correctly at scale.</p><p>The key to automation is really to automate things that will happen over and\nover.  You're not going to automate a one-shot change that will never recur.\nYou're going to start automating the things where the machine can truly give you\na productivity boost because you're going to do it once or twice, figure out how\nto make it work, and then have the machine repeat it a thousand times.  For that\nrepetition, there's a very strong argument to be made for always using code.\nThat's because if we instruct the machine to use inference to do it, it might\nwork, particularly for small tasks, but it requires validation which can take\nalmost the same time as doing it in the first place.  Getting an LLM to\ncalculate for you sort of works, but it's much better for the LLM to write the\nPython code to do the calculation.  Why?  First, you can review the formula, not\nthe calculation.  We can it ourselves or we can use the LLM as a judge to figure\nout if the  is correct.  Don't really have to validate that Python\ncalculates correct, you can rely on that.  So, by opting for code generation for\ntask solving, we get a little closer to being able to verify and validate the\nprocess ourselves, rather than hoping the LLM inferred correctly.</p><p>This obviously goes way beyond calculation.  Take, for instance, this blog.  I\nconverted this entire blob from reStructuredText to Markdown recently.  I put\nthis conversion off for a really long time, partly because I was a little too\nlazy.  But also, when I was lazy enough to consider deploying an LLM for it, I\njust didn't trust it to do the conversion itself without regressing somewhere.\nI was worried that if it ran out of context, it might start hallucinating text\nor change wording slightly.  It's just that I worried about subtle regressions\ntoo much.</p><p>I still used an LLM for it, but I asked it to do that transformation in a\ndifferent way: through code.</p><ol><li><p>I asked the LLM to perform the core transformation from reStructuredText to\nMarkdown but I also asked it to do this in a way that uses the underlying AST\n(Abstract Syntax Tree).  So, I instructed it to parse the reStructuredText\ninto an actual reStructuredText AST, then convert that to a Markdown AST, and\nfinally render it to HTML, just like it did before. This gave me an intermediate\ntransformation step and a comparable end result.</p></li><li><p>Then, I asked it to write a script that compares the old HTML with the new HTML,\nperforms the diffing after some basic cleanup it deemed necessary for\ncomparison.  I asked it to consider what kind of conversion errors were\nactually acceptable.  So, it read through its own scripts to see where it might\nnot match the original output due to known technical limitations (e.g.,\nfootnotes render differently between the Markdown library I'm using and the\nreStructuredText library, so even if the syntax matches correctly, the HTML\nwould look different).  I asked it to compensate for this in that script.</p></li><li><p>After that was done, I asked it to create a third script, which I could run\nover the output of hundreds of files to analyze the differece to go back into\nthe agentic loop for another iteration tep.</p></li></ol><p>Then I kicked off off this in a loop.  I did not provide all the posts, I\nstarted with 10 until differences were low and then had it do it for all.  It\ndid this for maybe 30 minutes or so until I came back to it and found it in a\npretty acceptable state.</p><p>What's key about this transformation is not so much that the LLM was capable of\npulling it off, but that I actually trusted this process at the end because I\ncould review the approach.  Not only that, I also tried to ask another LLM what\nit thinks of the code that another LLM wrote, and the changes.  It gave me much\nhigher confidence that what was going on would not lose data.  It felt right to\nme.  It felt like a mechanical process that was fundamentally correct, and I was\nable to observe it and do spot checks.  At worst, the regressions were minor\nMarkdown syntax errors, but the text itself wouldn't have been corrupted.</p><p>Another key here is also that because the inference is rather constant, the cost\nof inference in this process scales with the number of iteration steps and the\nsample size, but it doesn't depend on how many documents I'm wanting to convert\noverall.  Eventually, I just had it run over all documents all the time but\nrunning it over 15 docs vs 150 docs is more or less the same effort, because the\nfinal LLM based analysis step did not have that many more things to review (it\nalready skipped over all minor differences in the files).</p><p>This is a long-winded way of saying that this entire transformation went through\ncode.  It's a pipeline that starts with human input, produces code, does an LLM\nas a judge step and iterates.  And you can take this transformation and apply it\nto a general task as well.</p><p>To give an example, one MCP you might be using is Playwright.  I find it very\nhard to replace Playwright with a code approach  because what\nyou're essentially doing is remotely controlling your browser.  The task you're\ngiving it largely involves reading the page, understanding what's on it, and\nclicking the next button.  That's the kind of scenario where it's very hard to\neliminate inference at each step.</p><p>However, if you already know what the page is — for instance, if you're\nnavigating your own app you're working on — then you can actually start telling\nit to write a Playwright Python script instead and run that.  This script can\nperform many of those steps sequentially without any inference.  I've noticed\nthat this approach is significantly quicker, and because it understands your\ncode, it still generally produces correct results.  It doesn't need to navigate,\nread page contents, find a button, or press an input in real-time.  Instead, it\nwill write a single Python script that automates the entire process in one go,\nrequiring very little context by comparison. </p><p>This process is repeatable.  Once the script is written, I can execute it 100,\n200, or even 300 times without requiring any further inference.  This is a\nsignificant advantage that an MCP (Multi-Component Pipeline) typically cannot\noffer.  It's incredibly challenging to get an LLM to understand generic,\nabstract MCP tool calls.  I wish I could, for example, embed an MCP client\ndirectly into a shell script, allowing me to run remote MCP services efficiently\nvia code generation, but actually doing that is incredibly hard because the\ntools are not written with non inference based automation in mind.</p><p>Also, as ironic as it is: I'm a human, not an MCP client.  I can run and debug a\nscript, I cannot even figure out how to reliably do MCP calls.  It's always a\ngamble and incredibly hard to debug.  I love using the little tools that Claude\nCode generates while generating code.  Some of those I had it convert into long\nterm additions to my development process.</p><p>I don't know.  But it's an interesting moment to think what we could potentially\ndo to make code generation for purposeful agentic coding better.  The weird\nthing is that MCP is actually pretty great when it works.  But it feels in the\ncurrent form too much like a dead end that cannot be scaled up, particularly to\nautomation at scale because it relies on inference too much.</p><p>So maybe we need to look at ways to find a better abstraction for what MCP is\ngreat at, and code generation.  For that that we might need to build better\nsandboxes and maybe start looking at how we can expose APIs in ways that allow\nan agent to do some sort of fan out / fan in for inference.  Effectively we want\nto do as much in generated code as we can, but then use the magic of LLMs after\nbulk code execution to judge what we did.</p><p>I can also imagine that it might be quite interesting to do code generation in a\nway that also provides enough context for an LLM to explain in human language to\na non programmer what the script is doing.  That might enable these flows to be\nused by human users that are not developers themselves.</p><p>In any case I can only encourage people to bypass MCP and to explore what else\nis possible.  LLMs can do so much more if you give them the power to write code.</p><p>Here are some more posts you might want to read or videos you might want to\nwatch:</p><ul><li>Drew Breunig's post “<a href=\"https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html\">How to fix your context</a>”\nwhich covers some attempts to improve MCP tool selection if you cannot avoid\nit.</li><li>Manuel Odendahl's excellent “<a href=\"https://www.youtube.com/watch?v=J3oJqan2Gv8\">MCPs are Boring</a>”\ntalk from AI Engineer that was one of the first to point to the challenges\nwith MCP.</li></ul>","contentLength":11721,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI condemns Robinhood’s ‘OpenAI tokens’","url":"https://techcrunch.com/2025/07/02/openai-condemns-robinhoods-openai-tokens/","date":1751499807,"author":"Maxwell Zeff","guid":181416,"unread":true,"content":"<article>OpenAI wants to make clear that Robinhood's sale of \"OpenAI tokens\" will not give everyday consumers equity — or stock — in OpenAI.</article>","contentLength":135,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Nintendo Locked Down the Switch 2's USB-C Port, Broke Third-Party Docking","url":"https://hardware.slashdot.org/story/25/07/02/2136241/nintendo-locked-down-the-switch-2s-usb-c-port-broke-third-party-docking?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751498400,"author":"BeauHD","guid":181434,"unread":true,"content":"Two accessory manufacturers have told The Verge that Nintendo has intentionally locked down the Switch 2's USB-C port using a new encryption scheme, preventing compatibility with third-party docks and accessories. \"I haven't yet found proof of that encryption chip myself -- but when I analyzed the USB-C PD traffic with a Power-Z tester, I could clearly see the new Nintendo Switch not behaving like a good USB citizen should,\" writes The Verge's Sean Hollister. From the report: If you've been wondering why there are basically no portable Switch 2 docks on the market, this is the reason. Even Jsaux, the company that built its reputation by beating the Steam Deck dock to market, tells us it's paused its plans to build a Switch 2 dock because of Nintendo's actions. It's not simply because the Switch 2 now requires more voltage, as was previously reported; it's that Nintendo has made things even more difficult this generation.","contentLength":934,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Wonder Dynamics co-founder Nikola Todorovic joins the AI Stage at TechCrunch Disrupt 2025","url":"https://techcrunch.com/2025/07/02/wonder-dynamics-co-founder-nikola-todorovic-joins-the-ai-stage-at-techcrunch-disrupt-2025/","date":1751497800,"author":"TechCrunch Events","guid":181415,"unread":true,"content":"<article>TechCrunch Disrupt 2025 is back at Moscone West in San Francisco from October 27–29, bringing together 10,000+ startup and VC leaders to dig into what’s next in tech. And when it comes to artificial intelligence, the conversations aren’t just technical — they’re creative, cinematic, and boundary-pushing. That’s why Nikola Todorovic is headed to the AI […]</article>","contentLength":371,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lightning Talk: Optimizing Web Applications by Offloading Heavy Processing To Kuberne... Asami Okina","url":"https://www.youtube.com/watch?v=8pVt9dhHEVc","date":1751497305,"author":"CNCF [Cloud Native Computing Foundation]","guid":181437,"unread":true,"content":"<article>Don't miss out! Join us at our next Flagship Conference: KubeCon + CloudNativeCon India in Hyderabad (August 6-7), and KubeCon + CloudNativeCon North America in Atlanta (November 10-13). Connect with our current graduated, incubating, and sandbox projects as the community gathers to further the education and advancement of cloud native computing. Learn more at https://kubecon.io\n\nLightning Talk: Optimizing Web Applications by Offloading Heavy Processing To Kubernetes Jobs - Asami Okina, Craftsman Software, Inc.\n\nWhile typical web applications do not require large amounts of resources constantly, there are cases where specific processes consume significant CPU and memory.\n\nIn this session, we will introduce an architecture that offloads such resource-intensive processes to Kubernetes Jobs.\n\nWe will explain specific methods for Job management, how to integrate web applications (Next.js, @kubernetes/client-node) with the Kubernetes API, methods for data integration between Jobs and web applications, and real-time tracking of Job progress in the UI, all while sharing practical examples. Furthermore, we will provide a detailed introduction to a pattern where Kubernetes Job definitions generated from applications are managed using ConfigMaps, enabling quick configuration switching between environments, and offer hints to optimize your applications in terms of cost, performance, and management.</article>","contentLength":1410,"flags":null,"enclosureUrl":"https://www.youtube.com/v/8pVt9dhHEVc?version=3","enclosureMime":"","commentsUrl":null},{"title":"The NO FAKES Act Has Changed – And It’s So Much Worse","url":"https://www.techdirt.com/2025/07/02/the-no-fakes-act-has-changed-and-its-so-much-worse/","date":1751496180,"author":"katharine.trendacosta","guid":181387,"unread":true,"content":"<p>A bill purporting to target the issue of misinformation and defamation caused by generative AI has mutated into something that could change the internet forever, harming speech and innovation from here on out.</p><p>The Nurture Originals, Foster Art and Keep Entertainment Safe (NO FAKES) Act aims to address understandable concerns about generative AI-created “replicas” by creating a broad new intellectual property right. That approach was&nbsp;<a href=\"https://www.eff.org/deeplinks/2024/04/congress-should-just-say-no-no-fakes\">the first mistake</a>: rather than giving people targeted tools to protect against harmful misrepresentations—balanced against the need to protect legitimate speech such as parodies and satires—the original NO FAKES just federalized an image-licensing system.</p><p>The updated bill doubles down on that initial mistaken approach by mandating a whole new censorship infrastructure for that system, encompassing not just images but the products and services used to create them, with few safeguards against abuse.</p><p>The new version of NO FAKES requires almost every internet gatekeeper to create a system that will a) take down speech upon receipt of a notice; b) keep down any recurring instance—meaning, adopt inevitably overbroad replica filters on top of the already deeply flawed copyright filters; &nbsp;c) take down and filter tools that might have been used to make the image; and d) unmask the user who uploaded the material based on nothing more than the say so of person who was allegedly “replicated.”</p><p>This bill would be a disaster for internet speech and innovation.</p><p>The first version of NO FAKES focused on digital replicas. The new version goes further, targeting tools that can be used to produce images that aren’t authorized by the individual, anyone who owns the rights in that individual’s image, or the law. Anyone who makes, markets, or hosts such tools is on the hook. There are some limits—the tools must be primarily designed for, or have only limited commercial uses other than making unauthorized images—but those limits will offer cold comfort to developers given that they can be targeted based on nothing more than a bare allegation. These provisions effectively give rights-holders the veto power on innovation they’ve long sought in the copyright wars, based on the same tech panics.&nbsp;</p><h4><strong>Takedown Notices and Filter Mandate</strong></h4><p>The first version of NO FAKES set up a notice and takedown system patterned on the DMCA, with even fewer safeguards. NO FAKES expands it to cover more service providers and require those providers to not only take down targeted materials (or tools) but keep them from being uploaded in the future. &nbsp;In other words, adopt broad filters or lose the safe harbor.</p><p>But copyright filters are not yet required by law. NO FAKES would create a legal mandate that will inevitably lead to hecklers’ vetoes and other forms of over-censorship.</p><p>The bill does contain carve outs for parody, satire, and commentary, but those will also be cold comfort for those who cannot afford to litigate the question.</p><h4><strong>Threats to Anonymous Speech</strong></h4><p>As currently written, NO FAKES also allows anyone to get a subpoena from a court clerk—not a judge, and without any form of proof—forcing a service to hand over identifying information about a user.</p><p>We’ve already seen abuse of a similar system in action. In copyright cases, those unhappy with the criticisms being made against them get such subpoenas to silence critics. Often that the criticism includes the complainant’s own words as proof of the criticism, an ur-example of fair use. But the subpoena is issued anyway and, unless the service is incredibly on the ball, the user can be unmasked.</p><p>Not only does this chill further speech, the unmasking itself can cause harm to users. Either reputationally or in their personal life.</p><p>Most of us are very unhappy with the state of Big Tech. It seems like not only are we increasingly forced to use the tech giants, but that the quality of their services is actively degrading. By increasing the sheer amount of infrastructure a new service would need to comply with the law, NO FAKES makes it harder for any new service to challenge Big Tech. It is probably not a coincidence that some of these very giants are okay with this new version of NO FAKES.</p><p>Requiring removal of tools, apps, and services could likewise stymie innovation. For one, it would harm people using such services for otherwise lawful creativity. &nbsp;For another, it would discourage innovators from developing new tools. Who wants to invest in a tool or service that can be forced offline by nothing more than an allegation?</p><p>This bill is a solution in search of a problem. Just a few months ago, Congress passed Take It Down, which targeted images involving intimate or sexual content. That deeply flawed bill pressures platforms to actively monitor online speech, including speech that is presently encrypted. But if Congress is really worried about privacy harms, it should at least wait to see the effects of the last piece of&nbsp;internet regulation before going further into a new one. Its failure to do so makes clear that this is not about protecting victims of harmful digital replicas.</p><p>NO FAKES is designed to consolidate control over the commercial exploitation of digital images, not prevent it. Along the way, it will cause collateral damage to all of us.</p>","contentLength":5292,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Grammarly Acquires AI Email Client Superhuman","url":"https://slashdot.org/story/25/07/02/2128229/grammarly-acquires-ai-email-client-superhuman?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751496000,"author":"BeauHD","guid":181356,"unread":true,"content":"Grammarly has acquired the AI email client Superhuman to enhance its AI-driven productivity suite and expand AI capabilities within email communication. Financial terms of the deal were not disclosed but Superhuman CEO Rahul Vohra and his team will be joining the AI writing company. TechCrunch reports: Superhuman was founded by Rahul Vohra, Vivek Sodera, and Conrad Irwin. The company raised more than $114 million in funding from backers including a16z, IVP, and Tiger Global, with its last valuation at $825 million, according to data from venture data analytics firm Traxcn. \"With Superhuman, we can deliver that future to millions more professionals while giving our existing users another surface for agent collaboration that simply doesn't exist anywhere else. Email isn't just another app; it's where professionals spend significant portions of their day, and it's the perfect staging ground for orchestrating multiple AI agents simultaneously,\" Shishir Mehrotra, CEO of Grammarly, said in a statement.\n \nWith this deal, CEO Vohra and other Superhuman employees are moving over to Grammarly. \"Email is the main communication tool for billions of people worldwide and the number-one use case for Grammarly customers. By joining forces with Grammarly, we will invest even more in the core Superhuman experience, as well as create a new way of working where AI agents collaborate across the communication tools that we all use every day,\" Rahul Vohra, CEO of Superhuman, said in a statement.","contentLength":1497,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NYT To Start Searching Deleted ChatGPT Logs After Beating OpenAI In Court","url":"https://yro.slashdot.org/story/25/07/02/2122230/nyt-to-start-searching-deleted-chatgpt-logs-after-beating-openai-in-court?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751493600,"author":"BeauHD","guid":181265,"unread":true,"content":"An anonymous reader quotes a report from Ars Technica: Last week, OpenAI raised objections in court, hoping to overturn a court order requiring the AI company to retain all ChatGPT logs \"indefinitely,\" including deleted and temporary chats. But Sidney Stein, the US district judge reviewing OpenAI's request, immediately denied OpenAI's objections. He was seemingly unmoved by the company's claims that the order forced OpenAI to abandon \"long-standing privacy norms\" and weaken privacy protections that users expect based on ChatGPT's terms of service. Rather, Stein suggested that OpenAI's user agreement specified that their data could be retained as part of a legal process, which Stein said is exactly what is happening now.\n \nThe order was issued by magistrate judge Ona Wang just days after news organizations, led by The New York Times, requested it. The news plaintiffs claimed the order was urgently needed to preserve potential evidence in their copyright case, alleging that ChatGPT users are likely to delete chats where they attempted to use the chatbot to skirt paywalls to access news content. A spokesperson told Ars that OpenAI plans to \"keep fighting\" the order, but the ChatGPT maker seems to have few options left. They could possibly petition the Second Circuit Court of Appeals for a rarely granted emergency order that could intervene to block Wang's order, but the appeals court would have to consider Wang's order an extraordinary abuse of discretion for OpenAI to win that fight.\n \nIn the meantime, OpenAI is negotiating a process that will allow news plaintiffs to search through the retained data. Perhaps the sooner that process begins, the sooner the data will be deleted. And that possibility puts OpenAI in the difficult position of having to choose between either caving to some data collection to stop retaining data as soon as possible or prolonging the fight over the order and potentially putting more users' private conversations at risk of exposure through litigation or, worse, a data breach. [...]\n \nBoth sides are negotiating the exact process for searching through the chat logs, with both parties seemingly hoping to minimize the amount of time the chat logs will be preserved. For OpenAI, sharing the logs risks revealing instances of infringing outputs that could further spike damages in the case. The logs could also expose how often outputs attribute misinformation to news plaintiffs. But for news plaintiffs, accessing the logs is not considered key to their case -- perhaps providing additional examples of copying -- but could help news organizations argue that ChatGPT dilutes the market for their content. That could weigh against the fair use argument, as a judge opined in a recent ruling that evidence of market dilution could tip an AI copyright case in favor of plaintiffs.","contentLength":2834,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lucid sales inch forward as EV maker pushes to ramp Gravity production","url":"https://techcrunch.com/2025/07/02/lucid-sales-inch-forward-as-ev-maker-pushes-to-ramp-gravity-production/","date":1751492828,"author":"Kirsten Korosec","guid":181236,"unread":true,"content":"<article>Lucid sold 3,309 vehicles in the second quarter, a new record for the  EV maker. Still, the company must ramp up production of its Gravity SUV to meet its 2025 target. </article>","contentLength":168,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google Ordered To Pay $315 Million for Taking Data From Idle Android Phones","url":"https://yro.slashdot.org/story/25/07/02/1818254/google-ordered-to-pay-315-million-for-taking-data-from-idle-android-phones?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751491200,"author":"msmash","guid":181264,"unread":true,"content":"A California jury has ordered Google to pay $314.6 million to Android smartphone users in the state after finding the company liable for collecting data from idle devices without permission. \n\nThe San Jose jury ruled Tuesday that Google sent and received information from phones while idle, creating \"mandatory and unavoidable burdens shouldered by Android device users for Google's benefit.\" The 2019 class action represented an estimated 14 million Californians who argued Google consumed their cellular data for targeted advertising purposes.","contentLength":545,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Websites hosting major US climate reports taken down","url":"https://apnews.com/article/climate-change-national-assessment-nasa-white-house-057cec699caef90832d8b10f21a6ffe8","date":1751490613,"author":"geox","guid":181355,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44448868"},{"title":"Be Polarizing as a Job Seeker","url":"https://spectrum.ieee.org/be-a-polarizing-job-seeker","date":1751490335,"author":"Rahul Pandey","guid":181250,"unread":true,"content":"<p>Your goal is to be an exceptional fit for one specific job</p>","contentLength":58,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy81OTEwNDExMC9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc2MjIxNDM1NH0.KU_HC9RlAuzaq6NFugnkIjhO6mrvJzTfytOINkYN-Lg/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Optimize RAG in production environments using Amazon SageMaker JumpStart and Amazon OpenSearch Service","url":"https://aws.amazon.com/blogs/machine-learning/optimize-rag-in-production-environments-using-amazon-sagemaker-jumpstart-and-amazon-opensearch-service/","date":1751489751,"author":"Vivek Gangasani","guid":181160,"unread":true,"content":"<p>Generative AI has revolutionized customer interactions across industries by offering personalized, intuitive experiences powered by unprecedented access to information. This transformation is further enhanced by Retrieval Augmented Generation (RAG), a technique that allows large language models (LLMs) to reference external knowledge sources beyond their training data. RAG has gained popularity for its ability to improve generative AI applications by incorporating additional information, often preferred by customers over techniques like fine-tuning due to its cost-effectiveness and faster iteration cycles.</p><p>The RAG approach excels in grounding language generation with external knowledge, producing more factual, coherent, and relevant responses. This capability proves invaluable in applications such as question answering, dialogue systems, and content generation, where accuracy and informative outputs are crucial. For businesses, RAG offers a powerful way to use internal knowledge by connecting company documentation to a generative AI model. When an employee asks a question, the RAG system retrieves relevant information from the company’s internal documents and uses this context to generate an accurate, company-specific response. This approach enhances the understanding and usage of internal company documents and reports. By extracting relevant context from corporate knowledge bases, RAG models facilitate tasks like summarization, information extraction, and complex question answering on domain-specific materials, enabling employees to quickly access vital insights from vast internal resources. This integration of AI with proprietary information can significantly improve efficiency, decision-making, and knowledge sharing across the organization.</p><p>A typical RAG workflow consists of four key components: input prompt, document retrieval, contextual generation, and output. The process begins with a user query, which is used to search a comprehensive knowledge corpus. Relevant documents are then retrieved and combined with the original query to provide additional context for the LLM. This enriched input allows the model to generate more accurate and contextually appropriate responses. RAG’s popularity stems from its ability to use frequently updated external data, providing dynamic outputs without the need for costly and compute-intensive model retraining.</p><p>To implement RAG effectively, many organizations turn to platforms like <a href=\"https://aws.amazon.com/sagemaker/jumpstart/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon SageMaker JumpStart</a>. This service offers numerous advantages for building and deploying generative AI applications, including access to a wide range of pre-trained models with ready-to-use artifacts, a user-friendly interface, and seamless scalability within the AWS ecosystem. By using pre-trained models and optimized hardware, SageMaker JumpStart enables rapid deployment of both LLMs and embedding models, minimizing the time spent on complex scalability configurations.</p><p>To implement our RAG workflow on SageMaker, we use a popular open source Python library known as LangChain. With LangChain, the RAG components are simplified into independent blocks that you can bring together using a chain object that will encapsulate the entire workflow. The solution consists of the following key components:</p><ul><li> – We need an LLM that will do the actual inference and answer the end-user’s initial prompt. For our use case, we use Meta Llama3 for this component. LangChain comes with a default wrapper class for <a href=\"https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/llms/sagemaker_endpoint.py\" target=\"_blank\" rel=\"noopener noreferrer\">SageMaker endpoints</a> with which we can simply pass in the endpoint name to define an LLM object in the library.</li><li> – We need an embeddings model to convert our document corpus into textual embeddings. This is necessary for when we’re doing a similarity search on the input text to see what documents share similarities or contain the information to help augment our response. For this post, we use the <a href=\"https://python.langchain.com/docs/integrations/text_embedding/bge_huggingface/\" target=\"_blank\" rel=\"noopener noreferrer\">BGE Hugging Face Embeddings</a> model available in SageMaker JumpStart.</li><li><strong>Vector store and retriever</strong> – To house the different embeddings we have generated, we use a vector store. In this case, we use OpenSearch Service, which allows for similarity search using k-nearest neighbors (k-NN) as well as traditional lexical search. Within our chain object, we define the vector store as the retriever. You can tune this depending on how many documents you want to retrieve.</li></ul><p>The following diagram illustrates the solution architecture.</p><p>In the following sections, we walk through setting up OpenSearch, followed by exploring the <a href=\"https://github.com/aws-samples/sagemaker-genai-hosting-examples/blob/main/genai-recipes/RAG-recipes/llama3-rag-langchain-smjs.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\">notebook</a> that implements a RAG solution with LangChain, <a href=\"https://aws.amazon.com/sagemaker-ai/getting-started/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon SageMaker AI</a>, and OpenSearch Service.</p><h2>Benefits of using OpenSearch Service as a vector store for RAG</h2><p>In this post, we showcase how you can use a vector store such as OpenSearch Service as a knowledge base and embedding store. OpenSearch Service offers several advantages when used for RAG in conjunction with SageMaker AI:</p><ul><li> – Efficiently handles large-scale data and search operations</li><li> – Offers full-text search, relevance scoring, and semantic capabilities</li><li> – Seamlessly integrates with SageMaker AI and other AWS services</li><li> – Supports continuous knowledge base updates with minimal delay</li><li> – Allows fine-tuning of search relevance for optimal context retrieval</li><li> – Provides high availability and fault tolerance through a distributed architecture</li><li> – Provides analytical features for data understanding and performance improvement</li><li> – Offers robust features such as encryption, access control, and audit logging</li><li> – Serves as an economical solution compared to proprietary vector databases</li><li> – Supports various data types and search algorithms, offering versatile storage and retrieval options for RAG applications</li></ul><p>You can use SageMaker AI with OpenSearch Service to create powerful and efficient RAG systems. SageMaker AI provides the machine learning (ML) infrastructure for training and deploying your language models, and OpenSearch Service serves as an efficient and scalable knowledge base for retrieval.</p><h2>OpenSearch Service optimization strategies for RAG</h2><p>Based on our learnings from the hundreds of RAG applications deployed using OpenSearch Service as a vector store, we’ve developed several best practices:</p><ul><li>If you are starting from a clean slate and want to move quickly with something simple, scalable, and high-performing, we recommend using an <a href=\"https://aws.amazon.com/opensearch-service/features/serverless/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon OpenSearch Serverless</a> vector store collection. With OpenSearch Serverless, you benefit from automatic scaling of resources, decoupling of storage, indexing compute, and search compute, with no node or shard management, and you only pay for what you use.</li><li>If you have a large-scale production workload and want to take the time to tune for the best price-performance and the most flexibility, you can use an OpenSearch Service managed cluster. In a managed cluster, you pick the node type, node size, number of nodes, and number of shards and replicas, and you have more control over when to scale your resources. For more details on best practices for operating an OpenSearch Service managed cluster, see <a href=\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/bp.html\" target=\"_blank\" rel=\"noopener noreferrer\">Operational best practices for Amazon OpenSearch Service</a>.</li><li>OpenSearch supports both exact k-NN and approximate k-NN. Use exact k-NN if the number of documents or vectors in your corpus is less than 50,000 for the best recall. For use cases where the number of vectors is greater than 50,000, exact k-NN will still provide the best recall but might not provide sub-100 millisecond query performance. Use approximate k-NN in use cases above 50,000 vectors for the best performance.</li><li>OpenSearch uses algorithms from the <a href=\"https://github.com/nmslib/nmslib\" target=\"_blank\" rel=\"noopener noreferrer\">NMSLIB</a>, <a href=\"https://github.com/facebookresearch/faiss\" target=\"_blank\" rel=\"noopener noreferrer\">Faiss</a>, and <a href=\"https://lucene.apache.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Lucene</a> libraries to power approximate k-NN search. There are pros and cons to each k-NN engine, but we find that most customers choose Faiss due to its overall performance in both indexing and search as well as the variety of different quantization and algorithm options that are supported and the broad community support.</li><li>Within the Faiss engine, OpenSearch supports both Hierarchical Navigable Small World (HNSW) and Inverted File System (IVF) algorithms. Most customers find HNSW to have better recall than IVF and choose it for their RAG use cases. To learn more about the differences between these engine algorithms, see <a href=\"https://docs.opensearch.org/docs/latest/field-types/supported-field-types/knn-methods-engines/\" target=\"_blank\" rel=\"noopener noreferrer\">Vector search</a>.</li><li>To reduce the memory footprint to lower the cost of the vector store while keeping the recall high, you can start with Faiss HNSW 16-bit scalar quantization. This can also reduce search latencies and improve indexing throughput when used with <a href=\"https://docs.opensearch.org/docs/latest/field-types/supported-field-types/knn-methods-engines/#simd-optimization\" target=\"_blank\" rel=\"noopener noreferrer\">SIMD optimization</a>.</li><li>If using an OpenSearch Service managed cluster, refer to <a href=\"https://opensearch.org/docs/latest/search-plugins/knn/performance-tuning/\" target=\"_blank\" rel=\"noopener noreferrer\">Performance tuning</a> for additional recommendations.</li></ul><p>Make sure you have access to one ml.g5.4xlarge and ml.g5.2xlarge instance each in your account. A secret should be created in the same region as the stack is deployed.Then complete the following prerequisite steps to create a secret using <a href=\"https://aws.amazon.com/secrets-manager/\" target=\"_blank\" rel=\"noopener noreferrer\">AWS Secrets Manager</a>:</p><ol><li>On the Secrets Manager console, choose  in the navigation pane.</li><li>Choose .</li></ol><ol start=\"3\"><li>For , select .</li><li>For , on the  tab, enter a complete password.</li></ol><ol start=\"6\"><li>For , enter a name for your secret.</li></ol><ol start=\"8\"><li>Under , keep the settings as default and choose .</li></ol><ol start=\"9\"><li>Choose  to save your secret.</li></ol><ol start=\"10\"><li>On the secret details page, note the secret Amazon Resource Name (ARN) to use in the next step.</li></ol><h2>Create an OpenSearch Service cluster and SageMaker notebook</h2><p>We use <a href=\"http://aws.amazon.com/cloudformation\" target=\"_blank\" rel=\"noopener noreferrer\">AWS CloudFormation</a> to deploy our OpenSearch Service cluster, SageMaker notebook, and other resources. Complete the following steps:</p><ol><li>Provide the ARN of the secret you created as a prerequisite and keep the other parameters as default.</li></ol><ol start=\"3\"><li>Choose  to create your stack, and wait for the stack to complete (about 20 minutes).</li><li>When the status of the stack is , note the value of  on the stack  tab.</li><li>Locate  in the outputs and choose the link to open the SageMaker notebook.</li></ol><h2>Run the SageMaker notebook</h2><p>After you have launched the notebook in JupyterLab, complete the following steps:</p><ol><li>Go to <code>genai-recipes/RAG-recipes/llama3-RAG-Opensearch-langchain-SMJS.ipynb</code>.</li></ol><ol><li>Update the value of&nbsp;&nbsp;in the notebook with the value copied from&nbsp; in the previous step (look for <code data-stringify-type=\"code\">os.environ['OPENSEARCH_URL'] = \"\"</code>).&nbsp; The port needs to be 443.</li><li>Run the cells in the notebook.</li></ol><p>The notebook provides a detailed explanation of all the steps. We explain some of the key cells in the notebook in this section.</p><p>For the RAG workflow, we deploy the <code>huggingface-sentencesimilarity-bge-large-en-v1-5</code> embedding model and <code>meta-textgeneration-llama-3-8b-instruct</code> LLM from Hugging Face. SageMaker JumpStart simplifies this process because the model artifacts, data, and container specifications are all prepackaged for optimal inference. These are then exposed using the SageMaker Python SDK high-level API calls, which let you specify the model ID for deployment to a <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html\" target=\"_blank\" rel=\"noopener noreferrer\">SageMaker real-time endpoint</a>:</p><div><pre><code>\n&nbsp;sagemaker.jumpstart.model&nbsp;&nbsp;JumpStartModel\n\nmodel_id&nbsp;&nbsp;\"meta-textgeneration-llama-3-8b-instruct\"\naccept_eula&nbsp;&nbsp;\nmodel&nbsp;&nbsp;JumpStartModel(model_idmodel_id)\nllm_predictor&nbsp;&nbsp;modeldeploy(accept_eulaaccept_eula)\n\nmodel_id&nbsp;&nbsp;\"huggingface-sentencesimilarity-bge-large-en-v1-5\"\ntext_embedding_model&nbsp;&nbsp;JumpStartModel(model_idmodel_id)\nembedding_predictor&nbsp;&nbsp;text_embedding_modeldeploy()</code></pre></div><p>Content handlers are crucial for formatting data for SageMaker endpoints. They transform inputs into the format expected by the model and handle model-specific parameters like temperature and token limits. These parameters can be tuned to control the creativity and consistency of the model’s responses.</p><div><pre><code>class Llama38BContentHandler(LLMContentHandler):\n&nbsp;&nbsp; &nbsp;content_type = \"application/json\"\n&nbsp;&nbsp; &nbsp;accepts = \"application/json\"\n\n&nbsp;&nbsp; &nbsp;def transform_input(self, prompt: str, model_kwargs: dict) -&gt; bytes:\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;payload = {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"inputs\": prompt,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"parameters\": {\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"max_new_tokens\": 1000,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"top_p\": 0.9,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"temperature\": 0.6,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\"stop\": [\"&lt;|eot_id|&gt;\"],\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;}\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;input_str = json.dumps(\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;payload,\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;)\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;#print(input_str)\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;return input_str.encode(\"utf-8\")</code></pre></div><p>We use  from LangChain to load PDF files, attach metadata to each document fragment, and then use <code>RecursiveCharacterTextSplitter</code> to break the documents into smaller, manageable chunks. The text splitter is configured with a chunk size of 1,000 characters and an overlap of 100 characters, which helps maintain context between chunks. This preprocessing step is crucial for effective document retrieval and embedding generation, because it makes sure the text segments are appropriately sized for the embedding model and the language model used in the RAG system.</p><div><pre><code>import&nbsp;numpy as&nbsp;np\nfrom&nbsp;langchain_community.document_loaders import&nbsp;PyPDFLoader\nfrom&nbsp;langchain.text_splitter import&nbsp;RecursiveCharacterTextSplitter\ndocuments&nbsp;=&nbsp;[]\nfor&nbsp;idx, file&nbsp;in&nbsp;enumerate(filenames):\n&nbsp;&nbsp; &nbsp;loader&nbsp;=&nbsp;PyPDFLoader(data_root&nbsp;+&nbsp;file)\n&nbsp;&nbsp; &nbsp;document&nbsp;=&nbsp;loader.load()\n&nbsp;&nbsp; &nbsp;for&nbsp;document_fragment&nbsp;in&nbsp;document:\n&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;document_fragment.metadata =&nbsp;metadata[idx]\n&nbsp;&nbsp; &nbsp;documents&nbsp;+=&nbsp;document\n# - in our testing Character split works better with this PDF data set\ntext_splitter&nbsp;=&nbsp;RecursiveCharacterTextSplitter(\n&nbsp;&nbsp; &nbsp;# Set a really small chunk size, just to show.\n&nbsp;&nbsp; &nbsp;chunk_size=1000,\n&nbsp;&nbsp; &nbsp;chunk_overlap=100,\n)\ndocs&nbsp;=&nbsp;text_splitter.split_documents(documents)\nprint(docs[100])</code></pre></div><p>The following block initializes a vector store using OpenSearch Service for the RAG system. It converts preprocessed document chunks into vector embeddings using a SageMaker model and stores them in OpenSearch Service. The process is configured with security measures like SSL and authentication to provide secure data handling. The bulk insertion is optimized for performance with a sizeable batch size. Finally, the vector store is wrapped with , providing a simplified interface for operations like querying and retrieval. This setup creates a searchable database of document embeddings, enabling quick and relevant context retrieval for user queries in the RAG pipeline.</p><div><pre><code>from&nbsp;langchain.indexes.vectorstore import&nbsp;VectorStoreIndexWrapper\n# Initialize OpenSearchVectorSearch\nvectorstore_opensearch&nbsp;=&nbsp;OpenSearchVectorSearch.from_documents(\n&nbsp;&nbsp; &nbsp;docs,\n&nbsp;&nbsp; &nbsp;sagemaker_embeddings,\n&nbsp;&nbsp; &nbsp;http_auth=awsauth, &nbsp;# Auth will use the IAM role\n&nbsp;&nbsp; &nbsp;use_ssl=True,\n&nbsp;&nbsp; &nbsp;verify_certs=True,\n&nbsp;&nbsp; &nbsp;connection_class=RequestsHttpConnection,\n&nbsp;&nbsp; &nbsp;bulk_size=2000&nbsp;&nbsp;# Increase this to accommodate the number of documents you have\n)\n# Wrap the OpenSearch vector store with the VectorStoreIndexWrapper\nwrapper_store_opensearch&nbsp;=&nbsp;VectorStoreIndexWrapper(vectorstore=vectorstore_opensearch)</code></pre></div><p>Next, we use the wrapper from the previous step along with the prompt template. We define the prompt template for interacting with the Meta Llama 3 8B Instruct model in the RAG system. The template uses specific tokens to structure the input in a way that the model expects. It sets up a conversation format with system instructions, user query, and a placeholder for the assistant’s response. The  class from LangChain is used to create a reusable prompt with a variable for the user’s query. This structured approach to prompt engineering helps maintain consistency in the model’s responses and guides it to act as a helpful assistant.</p><div><pre><code>prompt_template&nbsp;=&nbsp;\"\"\"&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\nYou are a helpful assistant.\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n{query}\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\"\"\"\nPROMPT&nbsp;=&nbsp;PromptTemplate(\n&nbsp;&nbsp; &nbsp;template=prompt_template, input_variables=[\"query\"]\n)\nquery&nbsp;=&nbsp;\"How did AWS perform in 2021?\"\n\nanswer&nbsp;=&nbsp;wrapper_store_opensearch.query(question=PROMPT.format(query=query), llm=llm)\nprint(answer)</code></pre></div><p>Similarly, the notebook also shows how to use <a href=\"https://js.langchain.com/v0.1/docs/modules/chains/popular/vector_db_qa_legacy/\" target=\"_blank\" rel=\"noopener noreferrer\">Retrieval QA</a>, where you can customize how the documents fetched should be added to prompt using the  parameter.</p><p>Delete your SageMaker endpoints from the notebook to avoid incurring costs:</p><div><pre><code># Delete resources\nllm_predictor.delete_model()\nllm_predictor.delete_endpoint()\nembedding_predictor.delete_model()\nembedding_predictor.delete_endpoint()</code></pre></div><p>Next, delete your OpenSearch cluster to stop incurring additional charges:<code>aws cloudformation delete-stack --stack-name rag-opensearch</code></p><p>RAG has revolutionized how businesses use AI by enabling general-purpose language models to work seamlessly with company-specific data. The key benefit is the ability to create AI systems that combine broad knowledge with up-to-date, proprietary information without expensive model retraining. This approach transforms customer engagement and internal operations by delivering personalized, accurate, and timely responses based on the latest company data. The RAG workflow—comprising input prompt, document retrieval, contextual generation, and output—allows businesses to tap into their vast repositories of internal documents, policies, and data, making this information readily accessible and actionable. For businesses, this means enhanced decision-making, improved customer service, and increased operational efficiency. Employees can quickly access relevant information, while customers receive more accurate and personalized responses. Moreover, RAG’s cost-efficiency and ability to rapidly iterate make it an attractive solution for businesses looking to stay competitive in the AI era without constant, expensive updates to their AI systems. By making general-purpose LLMs work effectively on proprietary data, RAG empowers businesses to create dynamic, knowledge-rich AI applications that evolve with their data, potentially transforming how companies operate, innovate, and engage with both employees and customers.</p><p>SageMaker JumpStart has streamlined the process of developing and deploying generative AI applications. It offers pre-trained models, user-friendly interfaces, and seamless scalability within the AWS ecosystem, making it straightforward for businesses to harness the power of RAG.</p><p>Furthermore, using OpenSearch Service as a vector store facilitates swift retrieval from vast information repositories. This approach not only enhances the speed and relevance of responses, but also helps manage costs and operational complexity effectively.</p><p>By combining these technologies, you can create robust, scalable, and efficient RAG systems that provide up-to-date, context-aware responses to customer queries, ultimately enhancing user experience and satisfaction.</p><p>To get started with implementing this Retrieval Augmented Generation (RAG) solution using Amazon SageMaker JumpStart and Amazon OpenSearch Service, check out the example notebook on <a href=\"https://github.com/aws-samples/sagemaker-genai-hosting-examples/blob/main/genai-recipes/RAG-recipes/llama3-RAG-Opensearch-langchain-SMJS.ipynb.\" target=\"_blank\" rel=\"noopener\">GitHub</a>. You can also learn more about Amazon OpenSearch Service in the <a href=\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/what-is.html\" target=\"_blank\" rel=\"noopener\">developer guide</a>.</p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/12/03/vggangas-LR-1.jpg\" alt=\"\" width=\"100\" height=\"122\">is a Lead Specialist Solutions Architect for Inference at AWS. He helps emerging generative AI companies build innovative solutions using AWS services and accelerated compute. Currently, he is focused on developing strategies for fine-tuning and optimizing the inference performance of large language models. In his free time, Vivek enjoys hiking, watching movies, and trying different cuisines.</p><p><a href=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/11/29/ml-17917-image012.png\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/11/29/ml-17917-image012.png\" alt=\"\" width=\"100\" height=\"133\"></a> is a Senior Solutions Architect at AWS, specializing in large-scale distributed AI training and inference. He empowers customers to harness the power of AI to drive innovation and solve complex challenges. Outside of work, Harish embraces an active lifestyle, enjoying the tranquility of hiking, the intensity of racquetball, and the mental clarity of mindfulness practices.</p><p><a href=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/11/29/ml-17917-image009.jpg\" target=\"_blank\" rel=\"noopener\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/11/29/ml-17917-image009.jpg\" alt=\"\" width=\"100\" height=\"100\"></a> is an ML Solutions Architect. He specializes in machine learning, AI, and computer vision domains, and holds a master’s degree in Computer Science from UT Dallas. In his free time, he enjoys traveling and photography.</p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/10/11/sohain.jpg\" alt=\"\" width=\"97\" height=\"129\"> is a Sr. Specialist Solutions Architect at AWS focused on Amazon OpenSearch Service. His interests are in all things data and analytics. More specifically he loves to help customers use AI in their data strategy to solve modern day challenges.</p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/07/25/ML-17115_Author-Karan-1.jpg\" alt=\"Karan Jain\" width=\"100\" height=\"100\"> is a Senior Machine Learning Specialist at AWS, where he leads the worldwide Go-To-Market strategy for Amazon SageMaker Inference. He helps customers accelerate their generative AI and ML journey on AWS by providing guidance on deployment, cost-optimization, and GTM strategy. He has led product, marketing, and business development efforts across industries for over 10 years, and is passionate about mapping complex service features to customer solutions.</p>","contentLength":20368,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Amazon To Shut Down Its Freevee App Next Month","url":"https://entertainment.slashdot.org/story/25/07/02/1844245/amazon-to-shut-down-its-freevee-app-next-month?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751488800,"author":"msmash","guid":181178,"unread":true,"content":"Amazon plans to shut down its standalone Freevee app in August, according to an in-app notice to users. From a report: The free, ad-supported streaming service is directing viewers to continue watching Freevee content on Prime Video. \n\n\"Prime Video is the new exclusive home for Freevee Tv show, movies, and Live TV,\" the notice to readers states. \"The Freevee app will be accessible until August 2025. Continue watching your favorite Free Originals and our library of hit movies, shows, and live TV on Prime Video for free, no subscription needed. Download Prime Video to get started and sign-in with your Amazon account.\"","contentLength":623,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Our National Robocall Nightmare Is Getting Worse Under Donald Trump","url":"https://www.techdirt.com/2025/07/02/our-national-robocall-nightmare-is-getting-worse-under-donald-trump/","date":1751488800,"author":"Karl Bode","guid":181205,"unread":true,"content":"<p>According to the latest data on robocalls from the <a href=\"https://robocallindex.com/\">YouMail Robocall Index</a>, the scale of the U.S. robocall problem has grown by <em>another eleven percent year over year</em>. U.S. consumers received just over <strong>4.8 billion robocalls in May</strong>. We’ve normalized ceding our primary voice communications platforms to corporations, debt collectors, and scammers, and there’s every indication it’s going to get worse under Donald Trump.</p><p>YouGov’s latest study found that “just” 14 percent of May’s robocall total was from “scammers.” </p><p>Even before Trump, a corrupted court system had consistently limited the FCC’s authority to combat robocalls. Corrupt lawmakers and regulators, cowed into blind obedience by a massive, generational, cross-industry-lobbying campaign, like to keep the focus on&nbsp;, when many “legit” companies, again, leverage the&nbsp;<a href=\"https://arstechnica.com/tech-policy/2023/10/many-robocallers-dont-pay-fines-as-fcc-still-lacks-legal-power-to-collect/\">exact same tactics as scammers</a>.</p><p>As a result, federal regulators refuse to hold large phone companies accountable for their lagging efforts to combat fraud and spam. Case in point:&nbsp;<a href=\"https://publicinterestnetwork.org/wp-content/uploads/2024/10/US-SpamScam-Report_2024_0307.pdf\">Truecaller’s U.S. Spam and Scam Report</a>&nbsp;found that half of all major U.S. phone companies earned a D or F in their efforts to combat annoying robocalls and scams. Functional, developed countries (even many less developed ones) don’t have these problems.</p><p>So while the FCC is supposed to enforce robocall offenses and levy fines, terrible court rulings mean they aren’t allowed to&nbsp;&nbsp;fines. That’s left to the DOJ, which routinely just… doesn’t bother. As a result a comically small volume of the overall fines levied&nbsp;<a href=\"https://www.techdirt.com/2023/08/08/fcc-hits-robocall-scammers-with-300-million-fine-that-still-somehow-means-nothing/\">are ever actually collected</a>. For example between 2015 and 2019 the FCC issued $208.4 million in robocall fines, but collected just&nbsp;.</p><p>And again, this is all  Trump 2.0. And before largely unregulated AI.</p><p>Trump FCC boss Brendan Carr has been promising to take a hatchet to whatever is left of U.S. corporate oversight as part of his “delete, delete, delete” deregulatory initiative. Big telecoms and robocallers have been making it very clear <a href=\"https://www.techdirt.com/2025/04/17/big-telecom-robocallers-love-brendan-carrs-plan-to-lobotomize-the-fcc/\">they’re very excited about it</a>. Debt collectors in particular are <a href=\"https://arstechnica.com/tech-policy/2025/04/isps-and-robocallers-love-the-fcc-plan-to-delete-as-many-rules-as-possible/\">very eager to roll back already flimsy rules</a> governing how badly they can harass people they already know can’t pay. </p><p>Like so many systemic U.S. problems, the robocall menace isn’t something that gets fixed without first embracing much broader corruption, campaign finance, lobbying, and legal reforms. That is, obviously and indisputably, not something that’s happening under Trump and his <a href=\"https://www.techdirt.com/2025/04/17/big-telecom-robocallers-love-brendan-carrs-plan-to-lobotomize-the-fcc/\">sycophantic regulators</a> and <a href=\"https://www.techdirt.com/2025/04/23/5th-circuit-obediently-lets-att-off-the-hook-for-major-location-data-privacy-violations/\">telecom industry-coddling</a> courts.</p>","contentLength":2524,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Vitamin C Boosts Epidermal Growth via DNA Demethylation","url":"https://www.jidonline.org/article/S0022-202X(25)00416-6/fulltext","date":1751488119,"author":"gnabgib","guid":182733,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44448462"},{"title":"Vera Rubin: This Is How Far Engineers Go to Explore the Universe","url":"https://spectrum.ieee.org/vera-rubin-engineering","date":1751488002,"author":"Harry Goldstein","guid":181168,"unread":true,"content":"<p>And how far we went to tell their story</p>","contentLength":39,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MTExMzgwMi9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTgwNjc2Mzc0M30.cnVKj7yANaP42fkxKgybLtZtzalpzw4fL5guP1wK7aI/image.png?width=600","enclosureMime":"","commentsUrl":null},{"title":"Substack brings new updates to livestreaming as it increases video push","url":"https://techcrunch.com/2025/07/02/substack-brings-new-updates-to-livestreaming-as-it-increases-video-push/","date":1751486987,"author":"Lauren Forristal","guid":181153,"unread":true,"content":"<article>The recent update enables creators to share clips of their live videos on Notes, and Substack will notify them in real time about the performance. </article>","contentLength":147,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ZLUDA Making Progress In 2025 On Bringing CUDA To Non-NVIDIA GPUs","url":"https://www.phoronix.com/news/ZLUDA-Q2-2025-Update","date":1751486504,"author":"Michael Larabel","guid":181206,"unread":true,"content":"<article>The ZLUDA open-source effort that started off a half-decade ago as a drop-in CUDA implementation for Intel GPUs and then for several years was funded by AMD as a CUDA implementation for Radeon GPUs atop ROCm and then open-sourced but then reverted has been continuing to push along a new path since last year. The current take on ZLUDA is a multi-vendor CUDA implementation for non-NVIDIA GPUs for AI workloads and more. More progress was made during Q2 on this effort...</article>","contentLength":471,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"China's Giant New Gamble With Digital IDs","url":"https://yro.slashdot.org/story/25/07/02/1827222/chinas-giant-new-gamble-with-digital-ids?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751486400,"author":"msmash","guid":181080,"unread":true,"content":"China will launch digital IDs for internet use on July 15th, transferring online verification from private companies to government control. Users obtain digital IDs by submitting personal information including facial scans to police via an app. A pilot program launched one year ago enrolled 6 million people. \n\nThe system currently remains voluntary, though officials and state media are pushing citizens to register for \"information security.\" Companies will see only anonymized character strings when users log in, while police retain exclusive access to personal details. The program replaces China's existing system requiring citizens to register with companies using real names before posting comments, gaming, or making purchases. \n\nPolice say they punished 47,000 people last year for spreading \"rumours\" online. The digital ID serves a broader government strategy to centralize data control. State planners classify data as a production factor alongside labor and capital, aiming to extract information from private companies for trading through government-operated data exchanges.","contentLength":1090,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Angular Custom Profiling Track is now available","url":"https://blog.angular.dev/the-angular-custom-profiling-track-is-now-available-0f9d8d36218a?source=rss----447683c3d9a3---4","date":1751485086,"author":"Angular","guid":181151,"unread":true,"content":"<p>Profiling web applications can be a complex task, often requiring developers to juggle between different tools that present data in disconnected ways. Traditionally, Chrome’s performance panel is excellent for detailed function call analysis, while Angular DevTools offers a higher-level view based on framework concepts like components, lifecycle hooks, bindings etc. Unfortunately, having two separate tools leads to a fragmented understanding of performance.</p><p>This fragmentation presented a significant opportunity to improve the developer experience when profiling Angular applications. As a result, the Angular and Chrome teams have partnered to bring Angular-specific data and insights directly into the Chrome DevTools performance panel, creating a unified profiling experience. <strong>We’re excited to introduce the new custom track for Angular in Chrome DevTools.</strong></p><p>This integration allows developers to combine the benefits of both tools, offering a more synchronized and comprehensive view of their application’s performance.</p><h3>Getting to Know the New Custom&nbsp;Track</h3><p>With this new integration, you’ll find performance data using Angular concepts, such as application bootstrap, components, UI synchronization, and lifecycle hooks:</p><p>The custom track’s flame charts group function invocations together under corresponding components and other Angular concepts. You can drill down to individual functions for a more granular view when needed and still glean meaning from the groupings in other scenarios</p><p>One of the most significant benefits is the ability to distinguish between your application’s code, other scripts, or browser activities like layout and&nbsp;paint.</p><h3>Decoding the Colors: What Your Code is&nbsp;Doing</h3><p>The flame chart entries are color coded to help you quickly identify what’s happening in your application.</p><ul><li>: These represent Dependency Injection (DI) services instantiated during the application bootstrap process. In general, green signifies the execution of code written by application developers.</li></ul><ul><li>: This color is reserved for templates compiled by Angular. Even though it’s still your code, it has been transformed by Angular before execution in the browser. This allows you to clearly see which templates are creating or updating the DOM and how long these operations take.</li></ul><ul><li>: These mark the entry points. At the very top, you’ll see the trigger — why Angular decided to run application code. Subsequent blue bars represent all the components that need to perform work, which is particularly useful for understanding how user interactions impact DOM updates. Below component names, you’ll find the familiar purple (templates) and green (your component code).</li></ul><p>Since the custom track is interactive, clicking on an entry in the flame chart reveals more detailed information about a given entry. This data empowers developers to dive deeper into specific function calls and understand their impact on the application’s performance.</p><p>Enabling this powerful new feature is straightforward. Complete the following steps:</p><ol><li>Ensure you are using the latest version of Angular (v20 at the time of this post) and an up-to-date version of the Google Chrome&nbsp;browser.</li><li>Run your Angular application in developer mode.</li><li>With your application running, open Chrome DevTools and enable the custom track by typing ng.enableProfiling() in the&nbsp;console.</li><li>Once enabled, start recording a performance profile. The dedicated “Angular” track in the flame chart will be available.</li></ol><h3>More Performant Apps are on the&nbsp;Way</h3><p>This new integration with Chrome DevTools demonstrates our ongoing commitment to improving the developer experience within the Angular ecosystem. By providing tools that offer more focused and actionable insights, the Angular and Chrome teams are empowering developers to build faster, more efficient applications. Please try out this new integration and let us know what you&nbsp;think.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=0f9d8d36218a\" width=\"1\" height=\"1\" alt=\"\">","contentLength":3891,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AT&T rolls out Wireless Account Lock protection to curb the SIM-swap scourge","url":"https://arstechnica.com/security/2025/07/att-rolls-out-wireless-account-lock-protection-to-curb-the-sim-swap-scourge/","date":1751484507,"author":"Dan Goodin","guid":181182,"unread":true,"content":"<p>AT&amp;T is rolling out a protection that prevents unauthorized changes to mobile accounts as the carrier attempts to fight a costly form of account hijacking that occurs when a scammer swaps out the SIM card belonging to the account holder.</p><p>The technique, known as SIM swapping or port-out fraud, has been a scourge that has vexed wireless carriers and their millions of subscribers for years. An indictment filed <a href=\"https://arstechnica.com/tech-policy/2024/01/sim-swapping-ring-stole-400m-in-crypto-from-a-us-company-officials-allege/\">last year</a> by federal prosecutors alleged that a single SIM swap scheme netted $400 million in cryptocurrency. The stolen funds belonged to dozens of victims who had used their phones for two-factor authentication to cryptocurrency wallets.</p><h2>Wireless Account Lock debut</h2><p>A <a href=\"https://arstechnica.com/tech-policy/2024/10/t-mobile-pays-16-million-fine-for-three-years-worth-of-data-breaches/\">separate scam</a> from 2022 gave unauthorized access to a T-Mobile management platform that subscription resellers, known as mobile virtual network operators, use to provision services to their customers. The threat actor gained access using a SIM swap of a T-Mobile employee, a phishing attack on another T-Mobile employee, and at least one compromise of an unknown origin.</p>","contentLength":1048,"flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2022/02/sim-cards.jpeg","enclosureMime":"","commentsUrl":null},{"title":"Software Engineering in the LLM Era","url":"https://towardsdatascience.com/software-engineering-in-the-llm-era/","date":1751484466,"author":"Stephanie Kirmer","guid":181109,"unread":true,"content":"<p>On growing new software engineers, even when it’s inefficient</p>","contentLength":63,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Could Google’s Veo 3 be the start of playable world models?","url":"https://techcrunch.com/2025/07/02/could-googles-veo-3-be-the-start-of-playable-world-models/","date":1751484135,"author":"Rebecca Bellan","guid":181049,"unread":true,"content":"<article>Demis Hassabis, CEO of Google DeepMind, hinted Tuesday evening that Veo 3, Google’s latest video generating model, could potentially be used for video games.&nbsp;</article>","contentLength":161,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advancing AI agent governance with Boomi and AWS: A unified approach to observability and compliance","url":"https://aws.amazon.com/blogs/machine-learning/advancing-ai-agent-governance-with-boomi-and-aws-a-unified-approach-to-observability-and-compliance/","date":1751484125,"author":"Deepak Chandrasekar, Sandeep Singh","guid":181057,"unread":true,"content":"<p>Just as APIs became the standard for integration, AI agents are transforming workflow automation through intelligent task coordination. AI agents are already enhancing decision-making and streamlining operations across enterprises. But as adoption accelerates, organizations face growing complexity in managing them at scale. Organizations struggle with observability and lifecycle management, finding it difficult to monitor performance and manage versions effectively. Governance and security concerns arise as these agents process sensitive data, which requires strict compliance and access controls. Perhaps most concerningly, without proper management, organizations face the risk of agent sprawl—the unchecked proliferation of AI agents leading to inefficiency and security vulnerabilities.</p><p><a href=\"https://boomi.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Boomi</a> and AWS have collaborated to address the complexity surrounding AI agents with Agent Control Tower, an AI agent management solution developed by Boomi and tightly integrated with <a href=\"https://aws.amazon.com/bedrock/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Bedrock</a>. Agent Control Tower, part of the Boomi Agentstudio solution, provides the governance framework to manage this transformation, with capabilities that address both current and emerging compliance needs.</p><p>As a leader in enterprise iPaaS per Gartner’s Magic Quadrant, based on Completeness of Vision and Ability to Execute, Boomi serves over 20,000 enterprise customers, with three-quarters of these customers operating on AWS. This includes a significant presence among Fortune 500 and Global 2000 organizations across critical sectors such as healthcare, finance, technology, and manufacturing. Boomi is innovating with generative AI, with more than 2,000 customers using its AI agents. The convergence of capabilities that Boomi provides—spanning AI, integration, automation, API management, and data management—with AWS and its proven track record in reliability, security, and AI innovation creates a compelling foundation for standardized AI agent governance at scale. In this post, we share how Boomi partnered with AWS to help enterprises accelerate and scale AI adoption with confidence using Agent Control Tower.</p><h2>A unified AI management solution</h2><p>Built on AWS, Agent Control Tower uniquely delivers a single control plane for managing AI agents across multiple systems, including other cloud providers and on-premises environments. At its core, it offers comprehensive observability and monitoring, providing real-time performance tracking and deep visibility into agent decision-making and behavior.</p><p>The following screenshot showcases how users can view summary data across agent providers and add or manage providers.</p><p>The following screenshot shows an example of the Monitoring and Compliance dashboard.</p><p>Agent Control Tower also provides a single pane of glass for visibility into the tools used by each agent, as illustrated in the following screenshot.</p><p>Agent Control Tower provides key governance and security controls such as centralized policy enforcement and role-based access control, and enables meeting regulatory compliance with frameworks like <a href=\"https://boomi.com/compliance/#privacy\" target=\"_blank\" rel=\"noopener noreferrer\">GDPR</a> and <a href=\"https://boomi.com/compliance/#security\" target=\"_blank\" rel=\"noopener noreferrer\">HIPAA</a>. Furthermore, its lifecycle management capabilities enable automated agent discovery, version tracking, and operational control through features such as pause and resume functionality. Agent Control Tower is positioned as one of the first, if not the first, unified solutions that provides full lifecycle AI agent management with integrated governance and orchestration features. Although many vendors focus on releasing AI agents, there are few that focus on solutions for managing, deploying, and governing AI agents at scale.</p><p>The following screenshot shows an example of how users can review agent details and disable or enable an agent.</p><p>As shown in the following screenshot, users can drill down into details for each part of the agent.</p><h2>Amazon Bedrock: Enabling and enhancing AI governance</h2><p>Using Amazon Bedrock, organizations can implement security guardrails and content moderation while maintaining the flexibility to select and switch between AI models for optimized performance and accuracy. Organizations can create and enable access to curated knowledge bases and predefined action groups, enabling sophisticated multi-agent collaboration. Amazon Bedrock also provides comprehensive metrics and trace logs for agents to help facilitate complete transparency and accountability in agent operations. Through deep integration with Amazon Bedrock, Boomi’s Agent Control Tower enhances agent transparency and governance, offering a unified, actionable view of agent configurations and activities across environments.</p><p>The following diagram illustrates the Agent Control Tower architecture on AWS.</p><h2>Business impact: Transforming enterprise AI operations</h2><p>Consider a global manufacturer using AI agents for supply chain optimization. With Agent Control Tower, they can monitor agent performance across regions in real time, enforce consistent security policies, and enable regulatory compliance. When issues arise, they can quickly identify and resolve them while maintaining the ability to scale AI operations confidently. With this level of control and visibility, organizations can deploy AI agents more effectively while maintaining robust security and compliance standards.</p><p>Boomi customers have already deployed more than 33,000 agents and are seeing up to 80% less time spent on documentation and 50% faster issue resolution. With Boomi and AWS, enterprises can accelerate and scale AI adoption with confidence, backed by a product that puts visibility, governance, and security first. Discover how Agent Control Tower can help your organization manage AI agent sprawl and take advantage of scalable, compliance-aligned innovation. Take a <a href=\"https://boomi.com/content/boomi-ai-studio-guided-tour/\" target=\"_blank\" rel=\"noopener noreferrer\">guided tour</a> and learn more about <a href=\"https://boomi.com/platform/ai-studio/\" target=\"_blank\" rel=\"noopener noreferrer\">Boomi Agent Control Tower</a> and <a href=\"https://docs.aws.amazon.com/bedrock/\" target=\"_blank\" rel=\"noopener noreferrer\">Amazon Bedrock integration</a>. Or, you can get started today with <a href=\"https://marketing.boomi.com/AI-FastTrack-Registration.html\" target=\"_blank\" rel=\"noopener noreferrer\">AI FastTrack</a>.</p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/23/ML-18721-deepak-1.png\" alt=\"Friendly professional headshot of person with dark hair and beard in blue quilted jacket\" width=\"100\" height=\"114\"> is the VP of Software Engineering &amp; User Experience and leads multidisciplinary teams at Boomi. He oversees flagship initiatives like Boomi’s Agent Control Tower, Task Automation, and Market Reach, while driving a cohesive and intelligent experience layer across products. Previously, Deepak held a key leadership role at Unifi Software, which was acquired by Boomi. With a passion for building scalable, and intuitive AI-powered solutions, he brings a commitment to engineering excellence and responsible innovation.</p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/23/ML-18721-sandeep-1.png\" alt=\"Professional ID photo of person wearing dark collared shirt\" width=\"100\" height=\"100\"> is Director of Engineering at Boomi, where he leads global teams building solutions that enable enterprise integration and automation at scale. He drives initiatives like Boomi Agent Control Tower, Marketplace, and Labs, empowering partners and customers with intelligent, trusted solutions. With leadership experience at GE and Fujitsu, Sandeep brings expertise in API strategy, product engineering, and AI/ML solutions. A former solution architect, he is passionate about designing mission-critical systems and driving innovation through scalable, intelligent solutions.</p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/23/ML-18721-santosh-1.jpeg\" alt=\"Formal portrait photo with studio lighting on dark background\" width=\"100\" height=\"112\"> is a seasoned Engineering leader in the Amazon Bedrock team and has built Agents, Evaluation, Guardrails, and Prompt Management solutions. His team continuously innovates in the agentic space, delivering one of the most secure and managed agentic solutions for enterprises.</p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/23/ML-18721-greg-1.jpeg\" alt=\"Informal portrait of person with gray beard, glasses, and plaid button-up shirt\" width=\"100\" height=\"100\"> is a Senior Solutions Architect at AWS with more than 25 years of experience in software engineering, software architecture, consulting, and IT and Engineering leadership roles across multiple industries. For the majority of his career, he has focused on creating and delivering distributed, data-driven applications with particular focus on scale, performance, and resiliency. Now he helps ISVs meet their objectives across technologies, with particular focus on AI/ML.</p><p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/06/23/ML-18721-padma-1.png\" alt=\"Confident professional headshot featuring person in black and white patterned blouse\" width=\"100\" height=\"97\"> is a Senior Customer Solutions Manager at Amazon Web Services, where she specializes in supporting ISVs. With a passion for cloud transformation and financial technology, Padma works closely with ISVs to guide them through successful cloud transformations, using best practices to optimize their operations and drive business growth. Padma has over 20 years of industry experience spanning banking, tech, and consulting.</p>","contentLength":8110,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI Note Takers Are Increasingly Outnumbering Humans in Workplace Video Calls","url":"https://slashdot.org/story/25/07/02/194224/ai-note-takers-are-increasingly-outnumbering-humans-in-workplace-video-calls?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751484000,"author":"msmash","guid":181079,"unread":true,"content":"AI-powered note-taking apps are increasingly attending workplace meetings in place of human participants, creating situations where automated transcription bots outnumber actual attendees. \n\nMajor platforms including Zoom, Microsoft Teams and Google Meet now offer built-in note-taking features that record, transcribe and summarize meetings for invited participants who don't attend. The technology operates under varying legal frameworks, with most states requiring only single-party consent for recording while California, Florida, and Pennsylvania mandate all-party approval.","contentLength":579,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"WEMADE And Redlab Unleash Web3 MMORPG – Global Pre-Registration Open For Aug 2025","url":"https://hackernoon.com/wemade-and-redlab-unleash-web3-mmorpg-global-pre-registration-open-for-aug-2025?source=rss","date":1751483918,"author":"Chainwire","guid":181332,"unread":true,"content":"<p><strong>Singapore, Singapore/July 2nd, 2025/--</strong>&nbsp;and&nbsp;&nbsp;are excited to announce the start of global pre-registration for&nbsp;</p><p>During the global showcase, the team introduced&nbsp;“RPG Tokenomics 3.0”—a&nbsp;next-generation Play-to-Earn (P2E) system&nbsp;that seamlessly links two unique tokens for a dynamic and rewarding player experience. The showcase also revealed&nbsp;key features and the game’s upcoming roadmap.&nbsp;</p><p>How to Join and What to Expect</p><ul><li>Pre-Registration Rewards: All players who pre-register will receive special in-game items, including Gold Random Boxes and Top-grade Monster Slates.</li><li>Extra Benefits for WEMIX PLAY Members: Users who pre-register through&nbsp; will receive a ticket to join the&nbsp;“Invite a Friend” event. For every friend invited who completes pre-registration, the users get additional raffle entries.</li></ul><h3>Exciting Events and Rewards</h3><ul><li>Weekly Raffles: Every week until August 7th,&nbsp;players can win&nbsp;PLAY Tokens&nbsp;(usable on WEMIX PLAY),&nbsp;CROM Tokens&nbsp;(the game’s native currency), and other prizes. Additional raffle tickets are awarded for each friend who completes the sign-up process through an invitation, increasing the chances of selection with every successful referral.</li><li>Milestone Rewards: As the total number of pre-registrations increases, everyone unlocks&nbsp;milestone rewards&nbsp;like&nbsp;ROM Buff Boxes&nbsp;and&nbsp;Enhancement Scroll Selection Boxes.</li><li>Check-In Event: After pre-registering,&nbsp;log in to the official website to collect Pre-registration Coins. These coins can be used to craft a variety of rare items, such as&nbsp;ImperionGuaranteed Slates&nbsp;and&nbsp;Lucky Enhancement Scroll Boxes.</li><li>Mission Event: Completing special missions can earn an&nbsp;additional 200 Pre-registration Coins, offering more opportunities to engage ahead of the launch.</li></ul><p>The </p><ul><li>Learn about the game’s unique tokenomics and how the Dual-token P2E system works</li><li>Discover gameplay features and future plans</li><li>Chat directly with the creators and get their questions answered</li></ul><h3>Pre-Registration Now Open for </h3><p>Further details are available on:</p><p> is a South Korea-based technology and gaming company with 25 years of experience in digital innovation. Best known for The Legend of Mir IP, WEMADE has expanded its vision through the WEMIX platform, which powers a global ecosystem of Web3 games, NFTs, DeFi, and token-based services.</p><p>The company is committed to building sustainable digital economies where developers, players, and partners can grow together in a secure and open environment.</p><p>:::tip\nThis story was published as a press release by Chainwire under HackerNoon’s Business Blogging&nbsp;.</p>","contentLength":2542,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Interactive Data Exploration for Computer Vision Projects with Rerun","url":"https://towardsdatascience.com/interactive-data-exploration-for-computer-vision-projects-with-rerun/","date":1751483794,"author":"Florian Trautweiler","guid":181108,"unread":true,"content":"<p>Analyse dynamic signals in a computer vision pipeline in Python using OpenCV and Rerun</p>","contentLength":86,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PrimeXBT Launches ‘Trade As VIP’ Campaign Offering 70% Off Trading Fees","url":"https://hackernoon.com/primexbt-launches-trade-as-vip-campaign-offering-70percent-off-trading-fees?source=rss","date":1751483400,"author":"Chainwire","guid":181331,"unread":true,"content":"<p><strong>Castries, Saint Lucia, July 2nd, 2025/Chainwire/--</strong>, a leading multi-asset broker, has launched its latest promotion, , granting all newly registered users instant access to VIP 2 status for 30 days. As part of the platform’s tiered system, VIP levels reward traders with reduced fees, tighter spreads, and exclusive platform benefits. For a limited time, new users can experience these professional-grade conditions from the moment they join, without needing to meet any trading volume thresholds.</p><p>Running from July 1 to August 31, 2025, the campaign is designed to remove entry barriers for new traders by automatically upgrading every new account to VIP 2. On the Crypto Futures platform, this unlocks almost 70% reduction in taker fees, dropping from the standard 0.045% to just 0.015%. In the coming weeks, VIP 2 users will also benefit from up to 30% discounts on spreads across Forex and CFDs on Stocks, Commodities, Indices, and Crypto on PXTrader.</p><p>In addition to improved trading conditions, VIP 2 status also provides priority customer support, instant withdrawals, and higher withdrawal limits, enhancing the overall trading experience across both platforms.&nbsp;</p><p>According to PrimeXBT, the campaign delivers real value by giving new traders access to some of the best trading conditions in the industry. From day one, the broker empowers users to start stronger, trade smarter, and build early momentum, combining cost-efficiency with a professional-grade experience designed to support their trading journey.</p><p> ranks among the lowest-cost options on the market, outperforming major platforms in fee efficiency. For example, a $1,000,000 Bitcoin trade under VIP 2 would generate $300 in savings compared to standard fees. These savings scale significantly with volume, helping both casual and active traders reduce trading costs without compromising execution quality.</p><p>With meaningful savings and access to top-tier tools and conditions, PrimeXBT is lowering the cost of entry while raising the standard of what new traders can expect. This campaign reinforces the broker’s ongoing commitment to making high-performance trading more accessible, empowering, and competitive for all.</p><p> is a global multi-asset broker trusted by over 1,000,000 traders in 150+ countries, offering a next-generation trading experience that bridges traditional and digital finance. Clients can trade CFDs on Stocks, Indices, Commodities and Crypto, as well as Crypto Futures and Forex. PrimeXBT also enables clients to buy and sell cryptocurrencies, store them in secure built-in wallets, and instantly exchange crypto to crypto or fiat to crypto, all within one integrated environment.</p><p>Since 2018, PrimeXBT has made investing more accessible by lowering barriers to entry and providing secure, easy access to financial markets. This accessibility extends across its native web and mobile platforms, MetaTrader 5, and a variety of funding options in crypto, fiat, and local payment methods. Committed to putting clients first, PrimeXBT empowers traders of all levels with innovative tools and industry-leading conditions, delivering a better way to trade.</p><p>Disclaimer: The content provided here is for informational purposes only and is not intended as personal investment advice and does not constitute a solicitation or invitation to engage in any financial transactions, investments, or related activities. Past performance is not a reliable indicator of future results.</p><p>The financial products offered by the Company are complex and come with a high risk of losing money rapidly due to leverage. These products may not be suitable for all investors. Before engaging, you should consider whether you understand how these leveraged products work and whether you can afford the high risk of losing your money.</p><p>The Company does not accept clients from the Restricted Jurisdictions as indicated on its website. Some services or products may not be available in your jurisdiction. The applicable legal entity and its respective products and services depend on the client’s country of residence and the entity with which the client has established a contractual relationship during registration.</p><p>:::tip\nThis story was published as a press release by Chainwire under HackerNoon’s Business Blogging&nbsp;.</p>","contentLength":4275,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Four AI Minds in Concert: A Deep Dive into Multimodal AI Fusion","url":"https://towardsdatascience.com/four-ai-minds-in-concert-a-deep-dive-into-multimodal-ai-fusion/","date":1751483245,"author":"Eric Chung","guid":181107,"unread":true,"content":"<p>Introduction: From System Architecture to Algorithmic Execution In my previous article, I explored the architectural foundations of the VisionScout multimodal AI system, tracing its evolution from a simple object detection model into a modular framework. There, I highlighted how careful layering, module boundaries, and coordination strategies can break down complex multimodal tasks into manageable components. […]</p>","contentLength":418,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trump’s Immigration Enforcement: Free The Criminals, Jail The Innocent","url":"https://www.techdirt.com/2025/07/02/trumps-immigration-enforcement-free-the-criminals-jail-the-innocent/","date":1751483160,"author":"Mike Masnick","guid":181117,"unread":true,"content":"<p>The Trump administration’s immigration enforcement has revealed itself to be not just cruel, but fundamentally backwards: They’re literally freeing dangerous criminals while manufacturing cases against innocent people. And they’re doing it all to cover up their own massive legal fuckups.</p><p>Take the case of Kilmar Abrego Garcia. We <a href=\"https://www.techdirt.com/2025/06/23/judge-shreds-dojs-manufactured-case-against-abrego-garcia-evidence-defies-common-sense/\">covered this last week</a> when Magistrate Judge Barbara Holmes ordered his release, noting that the Justice Department appeared to have leaned on actual criminals to fabricate evidence against him. Now the Washington Post has the full story, and it’s even more damning: <a href=\"https://www.washingtonpost.com/immigration/2025/06/28/star-witness-against-kilmar-abrego-garca-was-due-be-deported-now-hes-being-freed\">The Trump admin is literally freeing a repeat violent offender</a> in exchange for testimony against Abrego—a man with no criminal history who was working and raising a family.</p><blockquote><p><em>The Trump administration has agreed to release from prison a three-time felon who drunkenly fired shots in a Texas community and spare him from deportation in exchange for his</em><em>cooperation in the federal prosecution of Kilmar Abrego García, according to a review of court records and official testimony.</em></p><p><em>Jose Ramon Hernandez Reyes, 38, has been convicted of smuggling migrants and illegally reentering the United States after having been deported. He also pleaded guilty to “deadly conduct” in the Texas incident, and is now the government’s star witness in its case against Abrego.</em></p></blockquote><p>Let that sink in: They’re freeing someone, who drunkenly fired shots in a community, to help them prosecute someone whose only “crime” was being the victim of the government’s own illegal deportation, making the Trump administration look totally incompetent in the process.</p><p>Remember, the Trump regime insisted that it was focused on going after the worst of the worst, the most hardened criminals of all. Yet, over and over again we’re finding out that they can’t actually find all those criminals they insisted were out there, so they’re <a href=\"https://www.techdirt.com/2025/06/26/more-than-90-percent-of-ice-detainees-have-never-been-convicted-of-violent-crimes/\">randomly grabbing anyone</a> they can find. In the case of Abrego, that meant taking a man who had no criminal history, and appeared to be gainfully employed, and raising a family, and shipping him to the one place an immigration court had forbidden the US to send him.</p><p>That set the DOJ off on a wild goose chase to try to justify their own massive fuckup, leading to these questionable criminal charges against him, which they used to try to distract from the fact that they <em>accidentally sent a man to a foreign concentration camp after being forbidden from doing so</em>.</p><p>But to make that work, apparently it involves freeing the actual hardened, dangerous criminal, in hopes that he’ll testify against Abrego.</p><blockquote><p><em>is among a handful of cooperating witnesses who could help the Trump administration achieve its goal of never letting Abrego walk free in the United States again. In exchange, he has already been released early from federal prison to a halfway house and has been given permission to stay in the U.S. for at least a year.</em></p><p><em>“Otherwise he would be deported,” Peter Joseph, a Homeland Security Investigations special agent, testified at Abrego’s criminal hearing June 13. The government is also likely to give him a work permit, the agent told the court.</em></p></blockquote><p>There’s no way to look at this other than “we’ll release a hardened criminal who is here illegally, and who has already been deported multiple times, including letting him stay in the US with working apers, so long as he concocts a story that lets DHS and the DOJ save face after we fucked up royally in renditioning a man illegally.”</p><p>That should be an embarrassment to the Trump regime, but it will barely get any attention.</p><h2>It Gets Worse: Trump Is Also Freeing MS-13 Leaders</h2><p>But the Abrego case isn’t an isolated incident—it’s part of a pattern. At the same time Trump is manufacturing criminal cases against innocent people, he’s also cutting deals to free actual MS-13 gang leaders.</p><blockquote><p><em>Even among the brutal ranks of the transnational gang called MS-13, Vladimir Arévalo Chávez stands out as a highly effective manager of murder, prosecutors say.</em></p><p><em>Known as “Vampiro,” he has been accused of overseeing killings in at least three countries: of migrants in Mexico, rivals in El Salvador and his own compatriots in the United States.</em></p><p><em>His arrest in February 2023 was a major triumph for American investigators, who only months earlier had accused him and 12 other gang leaders of terrorism, bloodshed and corruption in a wide-ranging federal indictment on Long Island.</em></p><p><em>But this April, the prosecutors who brought those charges suddenly — and quietly — asked a federal judge to drop them. Citing “national security concerns,” they said they needed to return Mr. Arévalo to El Salvador, his homeland.</em></p></blockquote><p>The report details how these actual MS-13 leaders have evidence of Bukele’s corruption, and Bukele asked for them back, rather than letting them tell their stories to American courts:</p><blockquote><p><em>But the Trump administration has not acknowledged another reason Mr. Bukele would want them back: U.S. prosecutors have amassed substantial evidence of a corrupt pact between the Salvadoran government and some high-ranking MS-13 leaders, who they say agreed to drive down violence and bolster Mr. Bukele politically in exchange for cash and perks in jail, a New York Times investigation found.</em></p><p><em>The deal with El Salvador heralded by Mr. Trump as a crackdown on crime</em><strong><em>is actually undermining a longstanding U.S. inquiry into the gang</em></strong><em>, according to multiple people with knowledge of the initiative. Two major ongoing cases against some of the gang’s highest-ranking leaders could be badly damaged, and other defendants could be less likely to cooperate or testify in court, they said.</em></p></blockquote><p>So let’s be clear about what’s happening here:</p><ul><li><strong>Innocent people like Abrego</strong>: Prosecuted with manufactured evidence from criminals who get released in exchange for their testimony</li><li>: Released early from prison and given work permits if they’ll help prosecute innocent people</li><li>: Handed over to a foreign dictator to protect that dictator from corruption charges, undermining ongoing DOJ investigations</li></ul><p>This isn’t “tough on crime”—it’s the opposite. It’s law enforcement theater that makes everyone less safe while covering up the administration’s own legal violations.</p><p>All that seems really bad! It’s almost as if the Trump regime is much more focused on public relations claims than actually helping to stop gang activity.</p><p>Meanwhile, the judge in his criminal case has agreed that even though they’ve ruled that he should be released, <a href=\"https://apnews.com/article/abrego-garcia-deportation-immigration-trump-a94b2d9101bb0da10e6998bead07b9c2?link_source=ta_bluesky_link&amp;taid=6862e5e520991e000130dfcb&amp;utm_campaign=trueanthem&amp;utm_medium=social&amp;utm_source=bluesky\">Abrego is probably safer in federal prison</a>, because were he released, ICE would likely ship him halfway around the world to some dangerous war zone.</p><p>Think about that: A federal judge is keeping someone in prison not because they’re dangerous, but because they’re  there than in the hands of immigration enforcement. That’s where we are now—federal prison as sanctuary from ICE’s lawlessness.</p><p>This is what happens when immigration enforcement becomes completely divorced from actual public safety and becomes, instead, a machine for generating propaganda victories, no matter how many innocent people get ground up in the process.</p>","contentLength":7144,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"R0AR’s $1R0R Token Roars Onto MEXC Exchange, Expanding DeFi Accessibility","url":"https://hackernoon.com/r0ars-$1r0r-token-roars-onto-mexc-exchange-expanding-defi-accessibility?source=rss","date":1751483031,"author":"Chainwire","guid":181330,"unread":true,"content":"<p><strong>Sheridan, Sheridan, July 2nd, 2025/Chainwire/--</strong>, a decentralized finance (DeFi) platform, has announced the listing of its native token, $1R0R, on the cryptocurrency exchange . This milestone marks a significant step in making $1R0R more accessible to traders worldwide, following its successful debut on BitMart just weeks ago.</p><p>The $1R0R token, built on the Ethereum ERC-20 network, powers R0AR’s unified ecosystem, which includes the R0AR Wallet, R0ARchain (a high-speed, low-cost Ethereum Layer 2), and the upcoming AI-driven R0ARacle. This listing on MEXC, known for its high liquidity and user-friendly platform, enables both new and seasoned investors to trade $1R0R with ease, unlocking opportunities for staking, farming, and advanced trading insights.</p><h3>Key Highlights of the MEXC Listing:</h3><ul><li>Availability: Trading is live as of June 27, 2025, with deposits and withdrawals fully supported.</li><li>Accessibility: MEXC’s global reach, serving over 40 million users across 170+ countries, ensures $1R0R is available to a diverse audience.</li><li>Community Focus: R0AR’s community-driven approach empowers users with institutional-grade tools without complexity, delivering privacy and control.</li></ul><blockquote><p>“This listing on MEXC is a game-changer for R0AR and our community,” said Dustin Hedrick, Co-Founder &amp; CTO for R0AR. “By partnering with one of the world’s leading exchanges, we’re making DeFi smarter, safer, and more inclusive. We invite everyone to join the R0AR movement and trade $1R0R on MEXC today.”</p></blockquote><p>MEXC’s reputation for rapid token listings and deep liquidity makes it an ideal platform for $1R0R’s global expansion. According to recent reports, MEXC leads the industry with over 461 spot listings and a trading volume exceeding $2 billion daily, ensuring robust market access for $1R0R.</p><p>The MEXC &amp; BitMart CEX listings are just the start. R0AR’s roadmap includes the following:</p><ul><li>Full Platform Launch: An all-in-one dashboard for staking, farming, and liquidity management. </li><li>R0ARacle Activation: Real-time AI-powered market insights to rival institutional tools.</li><li>Expanded Listings: More CEX &amp; DEX partnerships to broaden access from current CEXs-MEXC, BitMart DEXs-Uniswap, Pancake, sushi, &amp; balancer</li><li>Innovations: NFT integrations and tokenized real-world assets (RWAs).</li></ul><blockquote><p>“We’re building the future of DeFi with our community,” Dustin Hedrick, Co-Founder &amp; CTO. “This is your platform, your token, your moment.”</p></blockquote><p>R0AR is a trailblazing DeFi platform designed to make decentralized finance intuitive, secure, and powerful. With a unified ecosystem featuring the R0AR Wallet, R0ARchain, and the forthcoming R0ARacle, R0AR empowers users with seamless access to staking, farming, and advanced trading tools. Users can join the movement at .</p><p>Founded in 2018,  is a global cryptocurrency exchange serving over 40 million users in 170+ countries. Known for its low fees, high liquidity, and frequent token listings, MEXC is committed to being “Your Easiest Way to Crypto.”</p><p>Chief Development Officer</p><p>:::tip\nThis story was published as a press release by Chainwire under HackerNoon’s Business Blogging&nbsp;.</p>","contentLength":3106,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bitrise to Invest $3M in DevOps Cloud for Mobile Apps in EU","url":"https://devops.com/bitrise-to-invest-3m-in-devops-cloud-for-mobile-apps-in-eu/?utm_source=rss&utm_medium=rss&utm_campaign=bitrise-to-invest-3m-in-devops-cloud-for-mobile-apps-in-eu","date":1751482919,"author":"Mike Vizard","guid":181007,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"David H. Rosmarin brings a founder-focused approach to anxiety at TechCrunch All Stage","url":"https://techcrunch.com/2025/07/02/david-h-rosmarin-brings-a-founder-focused-approach-to-anxiety-at-techcrunch-all-stage/","date":1751482628,"author":"TechCrunch Events","guid":180949,"unread":true,"content":"<article>Startups demand constant decision-making and pressure-filled pivots, which bring big emotional swings. It’s no wonder anxiety shows up at every stage. But what if it didn’t have to be a liability? At TechCrunch All Stage 2025 on July 15 at Boston’s SoWa Power Station, Dr. David H. Rosmarin, clinical psychologist, author, and Harvard Medical School […]</article>","contentLength":361,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lovable on track to raise $150M at $2B valuation","url":"https://techcrunch.com/2025/07/02/lovable-on-track-to-raise-150m-at-2b-valuation/","date":1751482543,"author":"Julie Bort","guid":180948,"unread":true,"content":"<article>Lovable released its vibe coder in late November. Within six months, the  startup hit $50 million in ARR, CEO Anton Osika said.</article>","contentLength":127,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Amazon Nova Canvas update: Virtual try-on and style options now available","url":"https://aws.amazon.com/blogs/aws/amazon-nova-canvas-update-virtual-try-on-and-style-options-now-available/","date":1751481703,"author":"Matheus Guimaraes","guid":180954,"unread":true,"content":"<p>Have you ever wished you could quickly visualize how a new outfit might look on you before making a purchase? Or how a piece of furniture would look in your living room? Today, we’re excited to introduce a new virtual try-on capability in <a href=\"https://aws.amazon.com/ai/generative-ai/nova/creative??trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;sc_channel=el\">Amazon Nova Canvas</a> that makes this possible. In addition, we are adding eight new style options for improved style consistency for text-to-image based style prompting. These features expand Nova Canvas AI-powered image generation capabilities making it easier than ever to create realistic product visualizations and stylized images that can enhance the experience of your customers.</p><p>Let’s take a quick look at how you can start using these today.</p><p> The first thing is to make sure that you have access to the Nova Canvas model through the usual means. Head to the <a href=\"https://console.aws.amazon.com/bedrock?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;sc_channel=el\">Amazon Bedrock console</a>, choose  and <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/getting-started-console.html#getting-started-access?trk=ac97e39c-d115-4d4a-b3fe-c695e0c9a7ee&amp;sc_channel=el\">enable Amazon Nova Canvas for your account</a> making sure that you select the appropriate regions for your workloads. If you already have access and have been using Nova Canvas, you can start using the new features immediately as they’re automatically available to you.</p><p>The first exciting new feature is . With this, you can upload two pictures and ask Amazon Nova Canvas to put them together with realistic results. These could be pictures of apparel, accessories, home furnishings, and any other products including clothing. For example, you can provide the picture of a human as the source image and the picture of a garment as the reference image, and Amazon Nova Canvas will create a new image with that same person wearing the garment. Let’s try this out!</p><p>My starting point is to select two images. I picked one of myself in a pose that I think would work well for a clothes swap and a picture of an AWS-branded hoodie.</p><p>Note that Nova Canvas accepts images containing a maximum of 4.1M pixels – the equivalent of 2,048 x 2,048 – so be sure to scale your images to fit these constraints if necessary. Also, if you’d like to run the Python code featured in this article, ensure you have Python 3.9 or later installed as well as the Python packages boto3 and pillow.</p><p>To apply the hoodie to my photo, I use the Amazon Bedrock Runtime invoke API. You can find full details on the request and response structures for this API in the <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/image-generation.html\">Amazon Nova User Guide</a>. The code is straightforward, requiring only a few inference parameters. I use the new  of . I then specify the desired settings, including both the source image and reference image, using the  object to set a few required parameters. Note that both images must be converted to Base64 strings.</p><pre><code>import base64\n\n\ndef load_image_as_base64(image_path): \n   \"\"\"Helper function for preparing image data.\"\"\"\n   with open(image_path, \"rb\") as image_file:\n      return base64.b64encode(image_file.read()).decode(\"utf-8\")\n\n\ninference_params = {\n   \"taskType\": \"VIRTUAL_TRY_ON\",\n   \"virtualTryOnParams\": {\n      \"sourceImage\": load_image_as_base64(\"person.png\"),\n      \"referenceImage\": load_image_as_base64(\"aws-hoodie.jpg\"),\n      \"maskType\": \"GARMENT\",\n      \"garmentBasedMask\": {\"garmentClass\": \"UPPER_BODY\"}\n   }\n}</code></pre><p>Nova Canvas uses masking to manipulate images. This&nbsp;is a technique that allows AI image generation to focus on specific areas or regions of an image while preserving others, similar to using painter’s tape to protect areas you don’t want to paint.</p><p>You can use three different masking modes, which you can choose by setting  to the correct value. In this case, I’m using , which requires me to specify which part of the body I want to be masked. I’m using  , but you can use others such as , , or  if you want to specifically target the feet. <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/image-generation.html\">Refer to the documentation</a>&nbsp;for a full list of options.</p><p>I then call the invoke API, passing in these inference arguments and saving the generated image to disk.</p><pre><code># Note: The inference_params variable from above is referenced below.\n\nimport base64\nimport io\nimport json\n\nimport boto3\nfrom PIL import Image\n\n# Create the Bedrock Runtime client.\nbedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=\"us-east-1\")\n\n# Prepare the invocation payload.\nbody_json = json.dumps(inference_params, indent=2)\n\n# Invoke Nova Canvas.\nresponse = bedrock.invoke_model(\n   body=body_json,\n   modelId=\"amazon.nova-canvas-v1:0\",\n   accept=\"application/json\",\n   contentType=\"application/json\"\n)\n\n# Extract the images from the response.\nresponse_body_json = json.loads(response.get(\"body\").read())\nimages = response_body_json.get(\"images\", [])\n\n# Check for errors.\nif response_body_json.get(\"error\"):\n   print(response_body_json.get(\"error\"))\n\n# Decode each image from Base64 and save as a PNG file.\nfor index, image_base64 in enumerate(images):\n   image_bytes = base64.b64decode(image_base64)\n   image_buffer = io.BytesIO(image_bytes)\n   image = Image.open(image_buffer)\n   image.save(f\"image_{index}.png\")\n</code></pre><p>I get a very exciting result!</p><p>And just like that, I’m the proud wearer of an AWS-branded hoodie!</p><p>In addition to the  mask type, you can also use the  or  masks. With , you also provide the source and reference images, however, you provide a natural language prompt to specify which part of the source image you’d like to be replaced. This is similar to how the  and  tasks work in Nova Canvas. If you want to use your own image mask, then you choose the  mask type and provide a black-and-white image to be used as mask, where black indicates the pixels that you want to be replaced on the source image, and white the ones you want to preserve.</p><p>This capability is specifically useful for retailers. They can use it to help their customers make better purchasing decisions by seeing how products look before buying.</p><p> I’ve always wondered what I would look like as an anime superhero. Previously, I could use Nova Canvas to manipulate an image of myself, but I would have to rely on my good prompt engineering skills to get it right. Now, Nova Canvas comes with pre-trained styles that you can apply to your images to get high-quality results that follow the artistic style of your choice. There are eight available styles including 3D animated family film, design sketch, flat vector illustration, graphic novel, maximalism, midcentury retro, photorealism, and soft digital painting.</p><p>Applying them is as straightforward as passing in an extra parameter to the Nova Canvas API. Let’s try an example.</p><p>I want to generate an image of an AWS superhero using the 3D animated family film style. To do this, I specify a  of &nbsp;and a  object containing two parameters:  and . The  parameter contains the prompt describing the image I want to create which in this case is “a superhero in a yellow outfit with a big AWS logo and a cape.” The  parameter specifies one of the predefined style values. I’m using <code>\"3D_ANIMATED_FAMILY_FILM\"</code> here, but you can find the full list in the <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/image-generation.html\">Nova Canvas User Guide</a>.</p><pre><code>inference_params = {\n   \"taskType\": \"TEXT_IMAGE\",\n   \"textToImageParams\": {\n      \"text\": \"a superhero in a yellow outfit with a big AWS logo and a cape.\",\n      \"style\": \"3D_ANIMATED_FAMILY_FILM\",\n   },\n   \"imageGenerationConfig\": {\n      \"width\": 1280,\n      \"height\": 720,\n      \"seed\": 321\n   }\n}</code></pre><p>Then, I call the invoke API just as I did in the previous example. (The code has been omitted here for brevity.) And the result? Well, I’ll let you judge for yourself, but I have to say I’m quite pleased with the AWS superhero wearing my favorite color following the 3D animated family film style exactly as I envisioned.</p><p>What’s really cool is that I can keep my code and prompt exactly the same and only change the value of the style attribute to generate an image in a completely different style. Let’s try this out. I set  to .</p><pre><code>inference_params = { \n   \"taskType\": \"TEXT_IMAGE\", \n   \"textToImageParams\": { \n      \"text\": \"a superhero in a yellow outfit with a big AWS logo and a cape.\",\n      \"style\": \"PHOTOREALISM\",\n   },\n   \"imageGenerationConfig\": {\n      \"width\": 1280,\n      \"height\": 720,\n      \"seed\": 7\n   }\n}</code></pre><p>And the result is impressive! A photorealistic superhero exactly as I described, which is a far departure from the previous generated cartoon and all it took was changing one line of code.</p><p> Availability – Virtual try-on and style options are available in Amazon Nova Canvas in the US East (N. Virginia), Asia Pacific (Tokyo), and Europe (Ireland). Current users of Amazon Nova Canvas can immediately use these capabilities without migrating to a new model.</p><p>For a preview of virtual try-on of garments, you can visit <a href=\"https://nova.amazon.com/\">nova.amazon.com</a> where you can upload an image of a person and a garment to visualize different clothing combinations.</p><a href=\"https://www.linkedin.com/in/codingmatheus/\">Matheus Guimaraes | @codingmatheus</a>","contentLength":8644,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"US Probes Whether Negotiator Took Slice of Hacker Payments","url":"https://yro.slashdot.org/story/25/07/02/184232/us-probes-whether-negotiator-took-slice-of-hacker-payments?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751481600,"author":"msmash","guid":180980,"unread":true,"content":"An anonymous reader shares a report: Law enforcement officials are investigating a former employee of a company that negotiates with hackers and facilitates cryptocurrency payments during ransomware attacks, according to a statement from the firm, DigitalMint. DigitalMint President Marc Jason Grens this week told organizations it works with that the US Justice Department is examining allegations that the then-employee struck deals with hackers to profit from extortion payments, according to a person familiar with the matter. \n\nGrens did not identify the employee by name and characterized their actions as isolated, said the person, who spoke on condition that they not be identified describing private conversations. DigitalMint is cooperating with a criminal investigation into \"alleged unauthorized conduct by the employee while employed here,\" Grens said in an email to Bloomberg News. The Chicago-based company is not the target of the investigation and the employee \"was immediately terminated,\" Grens said, adding that he can't provide more information because the probe is ongoing.","contentLength":1095,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Amazon is shutting down its Freevee app in August","url":"https://techcrunch.com/2025/07/02/amazon-is-shutting-down-its-freevee-app-in-august/","date":1751481523,"author":"Aisha Malik","guid":180947,"unread":true,"content":"<article>Amazon plans to shut down its Freevee app, the company’s free ad-supported streaming service, in August, according to an in-app notice to users.</article>","contentLength":146,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tesla’s energy storage business gets sucked into the company’s downward spiral","url":"https://techcrunch.com/2025/07/02/teslas-energy-storage-business-gets-sucked-into-the-companys-downward-spiral/","date":1751481317,"author":"Tim De Chant","guid":180946,"unread":true,"content":"<article>For the second consecutive quarter, deployments of its Powerwall and Megapack stationary storage products have declined. </article>","contentLength":121,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Higgs-Bugson in the Linux Kernel","url":"https://blog.janestreet.com/a-higgs-bugson-in-the-linux-kernel/","date":1751481282,"author":"Ne02ptzero","guid":182732,"unread":true,"content":"<p>We recently ran across a strange higgs-bugson that manifested itself in a critical system that stores and distributes the firm’s trading activity data, called Gord. (A <a href=\"https://en.wikipedia.org/wiki/Heisenbug#Related_terms\">higgs-bugson</a> is a bug that is reported in practice but difficult to reproduce, named for the <a href=\"https://en.wikipedia.org/wiki/Search_for_the_Higgs_boson\">Higgs boson</a>, a particle which was theorized in the 1960s but only found in 2013.) In this post I’ll walk you through the process I took to debug it. I tried to write down relevant details as they came up, so see if you can guess what the bug is while reading along.</p><p>The NFS (“Network File System”) protocol is designed to access a regular POSIX filesystem over the network. The default security story of NFSv3, which is what we’re using here, is roughly “no security” on an untrusted network: the server only checks whether or not the client is connected from a ”privileged” port number (i.e. less than 1024). If the client says it’s connecting on behalf of a particular user, the server just trusts the client. What could go wrong?</p><p>The other security option for NFS is Kerberos. When used with NFS, Kerberos cryptographically verifies the identity of the user accessing the file.</p><p>Gord often does large file copies to ship data around. These copies would very rarely fail with <code>-EACCES (Permission denied)</code> despite the permissions being correctly set on the filesystem. Although retries were possible, it would be sad to lose progress copying these files. Also, strange errors in data storage are scary! It’s possible that spurious errors could indicate a larger issue.</p><p>There was no obvious pattern in these copies failing. Even identical jobs running simultaneously didn’t necessarily fail together. We did have one clue: if we switched Kerberos off in the dev environment (because the error sounded auth related), the copies never failed.</p><p>So, maybe something was wrong with the Kerberos credentials?</p><h2>How does the kernel get your Kerberos credentials?</h2><p>In a typical userspace program making use of Kerberos, libkrb5 will parse some environment variables or a config file to find the location of a Kerberos credentials cache. However, applications using NFS don’t need to link libkrb5 or otherwise know anything about Kerberos. They just do normal file I/O syscalls (open, read, write, etc) as if they were accessing a local filesystem. So what’s going on?</p><p>It turns out the kernel gets credentials via a root userspace daemon called . When your application does its first I/O syscall to a file on NFS, the kernel writes to a file on a special mountpoint to communicate with . (Fun fact: this mountpoint, , is an entirely separate filesystem implementation in the Linux kernel, just like  or  itself.)</p><p>Making some simplifications, the rpc_gssd program grabs the user’s credentials, constructs the right Kerberos service ticket, and writes to the rpc_pipefs again with the result. This involves an API called GSSAPI (“Generic Security Services API”), which you’ll see mentioned throughout this post.</p><p>Looking at the rpc_gssd logs around the time of the bug, I noticed that the kernel hadn’t requested credentials for a while. The most recently requested credential should also have been fresh for another few hours. So, this was a dead end.</p><h2>Trying to reproduce the bug</h2><p>I decided to try my luck by running a slow trickle of writes over the weekend. It seemed like the issue would be key-related somehow, so having a long-running process would force key expiry and plausibly reproduce the bug.</p><p>Checking back in on Monday, none of the dozen boxes I ran this on failed. This wasn’t too surprising, because the issue was pretty rare in production.</p><p>I then generated some large (~200GB) random files, put them on a test NFS mount, and started copying them to another test NFS mount in a loop on even more boxes. Once again, none of these copies failed.</p><p>At this point I was surprised I hadn’t seen the issue. To make sure I wasn’t just getting extremely unlucky, I decided to scale up the number of copies running in parallel.</p><p>I was worried about wasting bandwidth and impacting other users, so I thought a bit about how to make the test a bit more lightweight. One easy win would be to copy from a local disk to NFS instead of from NFS to NFS. However, I had already requested boxes with tiny disks. Fortunately, I had a cool trick in mind.</p><p>I decided to create a filesystem that contains large random files, but fits entirely in memory on small test machines. Here’s the idea: Instead of storing actual file content, I’d use a noise function (or hash function) to generate consistent random bytes on demand.</p><p>This turns out to be fairly straightforward. There’s a Rust crate called  that provides a nicely typed implementation of FUSE (“Filesystem in USErspace”). Around 20 minutes later (with some assistance from Claude), I had a fake filesystem that “contained” some large files to copy from.</p><p>This ultimately did take less time than it would have taken to use larger boxes, but felt slightly yak-shavy before I was sure this would work. I don’t think I would have attempted this trick if I didn’t have an AI assistant to write most of the filesystem for me.</p><div><pre><code></code></pre></div><h2>Inserting arbitrary code into the Linux kernel at runtime</h2><p>The next thing I wanted to do was collect some debug information. If the reproducer  work, I would want to see the kernel stack traces for the syscall that was returning EACCES. I needed to be prepared for this beforehand, because I expected the bug to take a while to show up.</p><p>There’s a Linux kernel subsystem called “eBPF”, which stands for “extended Berkeley Packet Filter”. As you might imagine, it’s supposed to let you filter network packets. However, it has since eaten the world and now lets you insert ~any code you want at the start or end of basically any function in the Linux kernel at runtime. This is fine. Everything’s going to be ok. Don’t worry about it!</p><p>There’s a handy tool called  that can quickly print arguments and return values of kernel functions (among other things). I wrote a bpftrace script that instrumented a few interesting-looking functions, something like this:</p><div><pre><code></code></pre></div><p>The example above looks at the gss_cred_init function, and prints out the kernel stack trace if it returns an EACCES error. This is a very simple example, but definitely check out the <a href=\"https://github.com/bpftrace/bpftrace/blob/master/man/adoc/bpftrace.adoc\">bpftrace manual</a> for other functionality.</p><h2>Back to reproducing the issue</h2><p>The test setup was as follows:</p><ul><li>Some jobs that run rsync processes to copy from the FUSE filesystem to a test NFS server.</li><li>A bpftrace script that watches for  being returned from relevant kernel functions.</li><li>A way to take a packet capture (PCAP) of just the time surrounding a returned .</li></ul><p>And… It worked! ! Weirdly,  of my test boxes failed at the same time? That never happened in production. Usually only one or two Gord jobs would fail at a time. One bpftrace message stood out: “<code>gss_validate returned -13 (GSS_S_BAD_SIG)</code>”.</p><p>Bad signature??? What? Of all the things that would make sense, this made sense the least. Was the server returning a bad signature? Was the client failing to verify it correctly? Was there memory corruption somewhere? Keep in mind all of this software is written in C, so almost anything is possible. Even <a href=\"https://en.wikipedia.org/wiki/Undefined_behavior\">nasal demons</a>. If this  memory corruption, maybe I found a security vulnerability?</p><p>I peeked at the packet capture of the bug in Wireshark and did not see any obvious signs of corruption. Other interesting things I noticed were:</p><ul><li>There were a lot of retransmissions at the NFS level. The test NFS server I was using was small and probably got overloaded.</li><li>TCP frames were being split up and reassembled.</li><li>Again: A third of my jobs failed together, which was unexpected given what I saw in production.</li></ul><p>I didn’t have any good guesses based on the above. Maybe I could try to generate the signature myself to compare it with what’s in the packet? I knew Wireshark could decrypt Kerberos requests in network packets given the user’s Kerberos password, which was enough to grab the signature key (GSS token). All I needed to do was write a program to compute the signature given that token. Seems simple enough in theory, but how exactly do you do that?</p><p>An NFS request looks something like this. Some interesting things to call out here are:</p><ul><li>There’s an XID, which matches responses to requests. A client can have multiple requests in flight, and the server can respond to them out of order, so an ID is necessary.</li><li>The credentials field specifies which GSS context the RPC request is associated with, and includes an incrementing sequence number (“GSS sequence number”). Note that this is a separate sequence number from the XID.</li></ul><p>In the request, the checksum is the HMAC of roughly all the data in the request header, using the shared GSS key. In the response, the checksum is the HMAC of the GSS sequence number from the request.</p><p>An HMAC is a “Hash-based Message Authentication Code” – it allows someone with knowledge of the key to verify that someone else with the same key created the checksum.</p><h2>Writing a Wireshark plugin</h2><p>The next thing I did was write a Wireshark plugin to compute the checksums of replies.</p><p>While writing the Wireshark plugin I ran into a problem: there were retransmissions in my PCAP, so how do I figure out which of the retransmitted requests corresponds to a response? This was throwaway code for debugging, so I decided to make a big shared-mutable hashmap containing a map from XIDs to GSS sequence numbers. I updated the hashmap whenever Wireshark processed a frame containing an NFS request, assuming it would process them in order.</p><p>Then, I loaded up my packet capture and browsed to the response with an XID that failed verification.</p><p>Okay. So the checksum in the packet is correct. Why did the kernel think it wasn’t? I clicked back to the request in the PCAP to take a look. Annoyingly, there were two requests with the same XID, meaning that a retransmission was involved. I then clicked back to the response.</p><p>Huh. Was my Wireshark plugin buggy?</p><p>(At this point I think you should have all the information you need to guess what the bug is. It might be fun to think through this. When you’re ready, read on.)</p><p>Remember how I wasn’t sure which request to use to get the GSS sequence number from? It turns out the kernel has the exact same bug!</p><p>SunRPC matches responses to requests via their XIDs, so if the server is overloaded and takes a while to respond, the NFS client might retransmit the request. The checksum field in the response is an HMAC over the  GSS sequence number. Note that this is  the XID, and is  included in the response. When the kernel retransmits a request with the same XID, it uses a new sequence number and updates the GSS sequence number it has recorded. If the kernel then receives the response that was associated with the old GSS sequence number, checksum validation fails. If this happens 3x in a row,  is returned to userspace.</p><p>This is  self-fulfilling because each failure creates another retry. It is not guaranteed, however: you can still get lucky with timing and avoid the bug.</p><p>Basically, the only reason I was able to reproduce the bug is because I was using a tiny test NFS server, causing latencies in the hundreds of seconds. If I had kept going with low-load testing, I probably would have had to use another method to find the bug.</p><p>A quick read of some kernel source code confirmed that what I thought was happening  happen, but to be sure, I decided to write a lightweight reproducer that works by delaying packets.</p><p>There’s a kernel facility called NFQUEUE which allows you to use a userspace process for packet filtering. This is probably intended for security use cases, but what I did was hook it up to a Python script where I can individually look at packets and press  to let them through after enough time has passed to trigger the bug. Basically, I could manually simulate high latency by being a very very slow human firewall.</p><p>Then it was a matter of writing a little more glue code, and I had a fully automatic reproduction script.</p><p>At this point I reported my findings to my team, who quickly noticed that the RFC actually does mention this case.</p><blockquote><p>“Then when it receives a response with a matching RPC transaction identifier, it can compute the checksum of each sequence number in the cache to try to match the checksum in the reply’s verifier.” - RFC2203 5.3.3.1. (Page 13)</p></blockquote><p>The Linux kernel does not actually implement this cache as suggested by the RFC, so I wrote a kernel patch to add this functionality and mailed it off upstream. I also learned that the FreeBSD kernel actually already implements this, so this is new-to-Linux but not new-to-NFS.</p><p>More importantly, though, all that this cache does is increase the amount of retries needed to hit a bad interleaving. The fundamental problem is that a sequence number mismatch should not cause an immediate retransmission, which makes the problem self-fulfilling. So, I wrote a second kernel patch to not retransmit if a bad checksum is seen.</p><p>This feels principled, since a checksum mismatch suggests network tampering, so it makes sense to treat it as if we didn’t receive a message at all. The normal timeout logic can take care of retransmission in the unlikely case that one is needed. As final verification, I applied these patches and made sure that the test copy jobs and the Python reproducer no longer failed.</p><p>Both of these patches are now upstream and will be available in Linux 6.16.</p>","contentLength":13425,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44447259"},{"title":"Using Gordon to Containerize Your Apps and Work with Containers","url":"https://www.docker.com/blog/containerize-your-apps-with-ask-gordon/","date":1751481281,"author":"Steve Buchanan","guid":180970,"unread":true,"content":"<p>These days, almost every tech company is looking for ways to integrate AI into their apps and workflows, and Docker is no exception. They’ve been rolling out some impressive AI capabilities across their products. This is my first post as a Docker Captain and in this post, I want to shine a spotlight on a feature that hasn’t gotten nearly enough attention in my opinion:  (also known as Docker AI), which is built into Docker Desktop and CLI.</p><p>Gordon is really helpful when it comes to containerizing applications. Not only does it help you understand how to package your app as a container, but it also reduces the overhead of figuring out dependencies, runtime configs, and other pieces that add to a developer’s daily cognitive load. The best part? Gordon doesn’t just guide you with responses; it can also generate or updatethe necessary files for you.</p><h2>The Problem: Containerizing apps and optimizing containers isn’t always easy</h2><p>Containerizing apps can range from super simple to a bit tricky, depending on what you’re working with. If your app has a  like Node.js, Python, or .NET Core, with <strong>clearly defined dependencies</strong> and , it will be straightforward.</p><p>A basic Dockerfile will usually get you up and running without much effort. But once you start adding more complexity, like a <strong>backend, frontend, database, and caching layer</strong>, you now have the need for a multi-container app. At this point, you might be dealing with additional Dockerfile configurations and potentially a Docker Compose setup. That’s where things can start to be challenging to get going.</p><p>This is where Gordon shines. It’s helpful in containerizing apps and can even handle multi-service container app setups, guiding you through what’s needed and even generating the supporting config files, such as Dockerfiles and docker-compose, to get you going.</p><h3>Optimizing containers can be a headache too</h3><p>Beyond just containerizing, there’s also the need to  for performance, security, and image size. And let’s face it, optimizing can be tedious. You need to know what base images to use, how to slim them down, how to avoid unnecessary layers, and more.</p><p>Gordon can help here too. It provides optimization suggestions, shows you how to apply best practices like multi-stage builds or removing dev dependencies, and helps you create leaner, more secure images.</p><h3>Why not just use general-purpose Generative AI?</h3><p>Sure, general-purpose AI tools like ChatGPT, Claude, Gemini, etc. are great and I use them regularly. But when it comes to containers, they can  needed for accurate and efficient help. Gordon, on the other hand, is . It has access to Docker’s ecosystem and has been trained on Docker documentation, best practices, and the nuances of Docker tooling. That means its recommendations are more likely to be precise and aligned with the latest standards.</p><p>Gordon can help with containerizing applications, optimizing your containers and more. Gordon is still a Beta feature. To start using Gordon, you need Docker Desktop version 4.38 or later. Gordon is powered by Large Language Models (LLMs), and it goes beyond prompt and response: it can perform certain tasks for you as an AI agent. Gordon can have access to your local files and local images when you give it permission. It will prompt you for access if needed for a task.</p><p>Please note, the examples I will show in this post are based on a single working session. Now, let’s dive in and start to explore Gordon.</p><h3>Enabling Gordon / Docker AI</h3><p>In order to turn Gordon on, go to  check the  box as shown in the following screenshot.&nbsp;</p><p><em>Figure 1: screenshot of where to enable Docker AI in beta features</em></p><p>Accept the terms. The AI in Docker Desktop is in two forms. The first one is through the Docker Desktop UI and is known as Gordon. The second option is Docker AI. Docker AI is accessed through the Docker CLI. The way you activate it is by typing Docker AI in the CLI. I will demonstrate this later on in this blog post.&nbsp;&nbsp;</p><p><em>Figure 2: screenshot of Docker AI terms acceptance dialog box</em></p><h3>Exploring Gordon in Docker Desktop</h3><p>Now Gordon will appear in your Docker Desktop UI. Here you can prompt it just like any Generative AI tool. Gordon will also have examples that you can use to get started working with it.</p><p>You can access Gordon throughout Docker Desktop by clicking on the AI icon as shown in the following screenshot.</p><p><em>Figure 3: screenshot of Docker Desktop interface showing the AI icon for Gordon</em></p><p>When you click on the AI icon a Gordon prompt box appears along with suggested prompts as shown in the following screenshot. The suggestions will change based on the object the AI is next to, and are context-aware.</p><p><em>Figure 4: Screenshot showing Gordon’s suggestion prompt box in Docker Desktop UI</em></p><p>Here is another example of Docker AI suggestions being context-aware based on what area of Docker Desktop you are in.&nbsp;</p><p><em>&nbsp;Figure 5: Screenshot showing Docker AI context- specific suggestions</em></p><p>Another common use case for Gordon is listing local images and using AI to work with them. You can see this in the following set of screenshots. Notice that Gordon will prompt you for permission before showing your local images.</p><p><em>Figure 6: Screenshot showing Gordon referencing local images</em></p><p>You can also prompt Gordon to take action. As shown in the following screenshot, I asked Gordon to run one of my images.</p><p><em>Figure 7: Screenshot showing Gordon prompts</em></p><p>If it can’t perform the action, it will attempt to help you.&nbsp;</p><p><em>Figure 8: Screenshot showing Gordon prompt response to failed request</em></p><p>Another cool use of Gordon is to explain a container image to you. When you ask this, Gordon will ask you to select the directory where the Dockerfile is and permission to access it as shown in the following screenshot.</p><p><em>Figure 9: Screenshot showing Gordon’s request for particular directory access</em></p><p>After you give it access to the directory where the Dockerfile is, it will then breakdown what’s in the Dockerfile.&nbsp;</p><p><em>Figure 10: Screenshot showing Gordon’s response to explaining a Dockerfile</em></p><p>As shown in the following screenshot, I followed up with a prompt asking Gordon to display what’s in the Dockerfile. It did a good job of explaining its contents, as shown in the following screenshot.</p><p><em>Figure 11: Screenshot showing Gordon’s response regarding Dockerfile contents</em></p><h3>Exploring Gordon in the Docker Desktop CLI</h3><p>Let’s take a quick tour through Gordon in the CLI. Gordon is referred to as Docker AI in the CLI. To work with Docker AI, you need to launch the Docker CLI as shown in the following screenshot.&nbsp;</p><p><em>Figure 12: Screenshot showing how to launch Docker AI from the CLI</em></p><p>Once in the CLI you can type “docker ai” and it will bring you into the chat experience so you can prompt Gordon. In my example, I asked Gordon about one of my local images. You can see that it asked me for permission.&nbsp;</p><p><em>Figure 13: Screenshot showing Docker CLI request for access</em></p><p>Next, I asked Docker AI to list all of my local images as shown in the following screenshot.&nbsp;</p><p><em>Figure 14: Screenshot showing Docker CLI response to display local images</em></p><p>I then tested pulling an image using Docker AI. As you can see in the following screenshot, Gordon pulled a nodeJS image for me!</p><p><em>Figure 15: Screenshot showing Docker CLI pulling nodeJS image</em></p><h3>Containerizing an application with Gordon</h3><p>Now let’s explore the experience of containerizing an application using Gordon.</p><p>I started by clicking on the example for containerizing an application. Gordon then prompted me for the directory where my application code is.&nbsp;</p><p><em>Figure 16: Screenshot showing where to enable access to directory for containerizing an application</em></p><p>I pointed it to my apps directory and gave it permission. It then started to analyze and containerize my app. It picked up the language and started to read through my app’s README file.</p><p><em>Figure 17: Screenshot showing Gordon starting to analyze and containerize app</em></p><p>You can see it understand the app was written in JavaScript and worked through the packages and dependencies.</p><p><em>Figure 18: Screenshot showing final steps of Gordon processing</em></p><p>Gordon understands that my app has a backend, frontend, and a database, knowing from this that I would need a Docker compose file.</p><p><em>Figure 19: Screenshot showing successful completion of steps to complete the Dockerfiles</em></p><p>From the following screenshot you can see the Docker related files needed for my app. Gordon created all of these.</p><p><em>Figure 20: Screenshot showing files produced from Gordon</em></p><p>Gordon created the Dockerfile (on the left) and a Compose yaml file (on the right) even picking up that I needed a Postgres DB for this application.</p><p><em>Figure 21: Screenshot showing Dockerfile and Compose yaml file produced from Gordon</em></p><p>I then took it a step further and asked Gordon to build and run the container for my application using the prompt “Can you build and run this application with compose?” It created the Docker Compose file, built the images, and ran the containers!</p><p><em>Figure 22: Screenshot showing completed containers from Gordon</em></p><p>I hope you picked up some useful insights about Docker and discovered one of its lesser-known AI features in Docker Desktop. We explored what Gordon is, how it compares to general-purpose generative AI tools like ChatGPT, Claude, and Gemini, and walked through use cases such as containerizing an application and working with local images. We also touched on how Gordon can support developers and IT professionals who work with containers. If you haven’t already, I encourage you to enable Gordon and take it for a test run. Thanks for reading and stay tuned for more blog posts coming soon.</p>","contentLength":9538,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"India’s Max Financial says hacker accessed customer data from its insurance unit","url":"https://techcrunch.com/2025/07/02/indias-max-financial-says-hacker-accessed-customer-data-from-its-insurance-unit/","date":1751480319,"author":"Jagmeet Singh","guid":180945,"unread":true,"content":"<article>The insurance giant is one of the largest insurers in India.</article>","contentLength":60,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Perplexity launches a $200 monthly subscription plan","url":"https://techcrunch.com/2025/07/02/perplexity-launches-a-200-monthly-subscription-plan/","date":1751479577,"author":"Maxwell Zeff","guid":180844,"unread":true,"content":"<article>The plan, Perplexity Max, offers unlimited access to various services and priority access to its services using the latest LLM models.</article>","contentLength":134,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Couchers is officially out of beta","url":"https://couchers.org/blog/2025/07/01/releasing-couchers-v1","date":1751479520,"author":"laurentlb","guid":181177,"unread":true,"content":"<p><em>Quick summary: we are out of Beta and into version 1, we're releasing a new strategy around safe &amp; active community instead of bashing our competitors, a fancy redesigned landing page, and a bunch of new features to make core couch surfing functionality better! Share the platform with your friends and let's grow the community together!</em></p><p>We are super excited to share that Couchers is today finally out of the Beta phase with our version 1 (v1) launch. After five years of building and developing the platform and community―first through the Alpha stage and a very long Beta stage―we are finally ready for our big launch! This means a brand new strategy, a spiffy new landing page, and a bunch of new features.</p><p>Today we are launching <strong>our new strategy centered around a commitment on being the safest, healthiest, and most active couch surfing community</strong>. This is an evolution of our <a href=\"https://couchers.org/plan\">original plan</a>, but adapted for the next stage of the community, where we clearly define what we stand for instead of living the shadow of another platform.</p><p>In addition, we are <strong>launching a brand new landing page</strong> to more clearly communicate our values and what sets us apart, and to explain what our community is all about to newbies and veteran couch surfers alike.</p><p>Finally, we have combined a <strong>number of exciting new features</strong> into this release. These have been gradually rolled out over the past few months to make sure they are ready for you today (and hopefully mostly free of bugs)! Read on to find out what these are.</p><h2>What does the v1 launch mean?</h2><p>Although the platform has been usable for a long time, until now, even some of the core functionality has been somewhat buggy and not as polished as we would like, in order to call it \"complete\". The v1 launch signals the completion of the platform in the sense that core functionality has been cleaned up and we believe it is fully ready for all to use! A lot of this cleanup effort was also done in the <a href=\"https://couchers.org/blog/2025/05/11/v0.9.9-release\">v0.9.9 release a few months ago</a>.</p><p>This launch means we can now focus on growing the platform and coming up with new features that set us apart and help you connect with other members better.</p><p>The features we decided to work on for v1 were picked to best further our goal of being a safe and active community, as well as tighten up the core functionality of the platform to make the experience super smooth and easy.</p><p>We are really excited about our <a href=\"https://couchers.org\">new landing page</a>, which clearly communicates what Couchers is, what we stand for, and what you can find on the platform once you sign up. We hope this will help us gain more of the right kinds of members!</p><p>A huge thanks to <a href=\"https://couchers.org/user/unsettleddown\">Nicole</a> who built the majority of the landing page; <a href=\"https://couchers.org/user/pcolt86\">Pablo</a> and <a href=\"https://couchers.org/user/aapeli\">Aapeli</a> who also helped build it; <a href=\"https://couchers.org/user/marta\">Marta</a> and <a href=\"https://couchers.org/user/karottensaft1\">Charlotte</a> who designed it; <a href=\"https://couchers.org/user/jesse\">Jesse</a> and <a href=\"https://couchers.org/user/chrisk\">Chris</a> who helped test it; and countless others who helped write or brainstorm our marketing message, or provided their input in other ways!</p><p><em>The new landing page features an anonymized map layer: pins are randomized to be at a random point 2-10 km (1.2-6.2 mi) away from their true location and are not tied to any user info. The map is further restricted to not zoom very far in.</em></p><p>We completely overhauled functionality for leaving a reference with two key updates:</p><ul><li><p>you can now indicate whether you did not stay with or host someone (and we won't remind you to leave references); and</p></li><li><p>you can now send our Safety Team private feedback (that's not shown on the public reference) about your interactions through the reference flow. You can use this functionality to let us know if something felt off, even if there's no cause for bigger concern. More information is always better and helps the Safety Team understand situations better and keep the platform safe!</p></li></ul><p>Thanks to <a href=\"https://couchers.org/user/aapeli\">Aapeli</a>, <a href=\"https://couchers.org/user/unsettleddown\">Nicole</a>, and <a href=\"https://couchers.org/user/jasonwvh\">Jason</a> for these updates. <a href=\"https://couchers.org/user/unsettleddown\">Nicole</a> also added the number of references to the references tab on profiles to draw more attention to it.</p><h3>Find members faster: a new and redesigned map</h3><p><a href=\"https://couchers.org/user/unsettleddown\">Nicole</a> spent months re-architecting and rebuilding a brand new Map Search page! The old one was creaking with age and very difficult to update and add features to. Nicole rewrote it from scratch! <a href=\"https://couchers.org/user/aapeli\">Aapeli</a> helped build some new backend functionality to significantly speed up searching, and <a href=\"https://couchers.org/user/jesse\">Jesse</a> among many others helped test it!</p><p>We put a lot of thought into making the map as usable as possible, trying to think about what should be shown, what should be hidden, and how to best display all this data. We hope you find it useful!</p><h3>Don't miss out on news: new notification feed</h3><p>We've been working on notifications for quite a few releases now. In this release we introduced a notification feed, rolled out push notifications for desktop and mobile, as well as added a bunch of new notification types for things like nested replies on discussions, and pending host requests.</p><p>Don't want so many notifications? No problem. Each notification type can be adjusted for a particular item or for a whole class of notifications. Find this under Notification Settings (accessible from Account Settings). We hope this helps members see what they care about, without having to waste time searching the platform; a core value of not maximizing empty engagement.</p><h3>Speaking your language: a new language selector &amp; translations</h3><p>We implemented a language selector and are in the active process of translating the platform to languages other than English! Thanks to <a href=\"https://couchers.org/user/ellebee\">Laura</a>, <a href=\"https://couchers.org/user/unsettleddown\">Nicole</a> and <a href=\"https://couchers.org/user/aapeli\">Aapeli</a> for their work on the functionality, as well as the many folks helping out on translation!</p><p>If you'd like to see the platform be translated to your own language, please apply to volunteer for our <a href=\"https://couchers.org/volunteer/translator\">Translator Position</a>! You can contribute as much or as little as you want. Every bit helps!</p><p>We have rolled out significant new functionality to make the platform safer:</p><ul><li><a href=\"https://couchers.org/user/unsettleddown\">Nicole</a> built the frontend functionality to block (and unblock) users, while <a href=\"https://couchers.org/user/spreeni\">Yannic</a> helped fix up some lingering backend functionality for that;</li><li><a href=\"https://couchers.org/user/colleen\">Colleen</a> added report flags to event cards; and</li><li>under the hood, <a href=\"https://couchers.org/user/aapeli\">Aapeli</a>, <a href=\"https://couchers.org/user/jesse\">Jesse</a> and <a href=\"https://couchers.org/user/rafael_ferreira\">Rafael</a> continue to work on many different moderation and admin features to help combat abuse and make the platform safer for everyone!</li></ul><p>We also updated our policies and now forbid <a href=\"https://help.couchers.org/hc/couchersorg-help-center/articles/1746572895-why-is-nudism-naturism-nudity-clothing_optional-not-allowed-on-couchers-org\">nudism</a> and <a href=\"https://help.couchers.org/hc/couchersorg-help-center/articles/1748816842-why-are-shared-beds-sleeping-surfaces-not-allowed\">shared sleeping surfaces</a> (such as a shared bed). The change was prompted by the significant moderation burden caused by regular issues with this subgroup of the community. This was a decision made by the Board in order to promote safety on the platform and to set clear expectations for everyone. Thanks to the volunteers who spearheaded this difficult change!</p><p>While we actively work on many features and improvements to the platform, we aren't always great at making those changes easy to see and notice. Sometimes people even criticize us for not making enough progress.</p><p>To help communicate what we are doing and when, <a href=\"https://couchers.org/user/chrisk\">Chris</a> has spearheaded an effort to produce and maintain <a href=\"https://couchers.org/roadmap\">a public roadmap</a>. This is a great resource to learn about what we're working on and what to look forward to!</p><p><a href=\"https://couchers.org/user/aapeli\">Aapeli</a> with assistance from <a href=\"https://couchers.org/user/unsettleddown\">Nicole</a>, built out an  system: if you have set your status to hosting but haven't logged in in many months, we will occasionally send you a notification to ask if you are still interested in hosting.</p><p>This helps us get a better idea of whether you would respond to a prospective surfer coming into town. In the next few weeks we'll be gradually rolling out this new functionality. We hope it helps reduce the number of well-thought out requests sent by surfers to hosts that never read their notification in the first place.</p><p>In order to execute on our new strategy and marketing plans including this huge launch, we assembled a new team that we call . This new team is in charge of marketing &amp; branding (incl. social media, the blog, landing pages), safety &amp; support (moderation, policies, verification, etc), community building (community creation, engagement, feedback, etc), volunteer recruitment and general operations within Couchers. They did a phenomenal job brainstorming, writing, planning, coordinating, and executing this launch.</p><h2>Our Engineering and Product team</h2><p>Our engineers, UI/UX designers and other software-focused volunteers continue to work hard on our Engineering and Product team.</p><h2>Our rehauled branding &amp; marketing strategy</h2><p><strong>Our new strategy is centered around a commitment to being the safest, healthiest, and most active couch surfing community.</strong></p><p>From our founding, we have always been defined by our competition: being the non-profit and open-source alternative to CouchSurfing.com™ that takes our community seriously and is here to fix the structural problems with other platforms. This has been an incredibly effective strategy, and it has helped us seed the community with the right crowd: a lot of veteran couch surfers with the couch surfing spirit.</p><p>As our community continues to grow and mature, it's time to stop living in the shadow of another platform and start living up to our own identity and values. This is something the volunteer team and Board have been thinking about a lot, and this has steered our priorities since the start of the year. When you look back at our <a href=\"https://couchers.org/plan\">original plan</a>, it's clear that everything we identified as the issues then were different aspects of community health and safety.</p><p>In the coming months we are going to work on updating our messaging across the board and further building out our public landing pages to help new users learn about the platform and community.</p><p>Over the next weeks the volunteer teams and Board will be working together to define our concrete priorities and roadmap for the rest of the year. We have brainstormed many ideas and have a rough path forward, but will work on refining it further. We will certainly concentrate a large part of our efforts on building a native mobile app, as well as allocating engineering resources to help our CouchOps team with their marketing and social media efforts.</p><p>We have plans to build infrastructure to better measure the impact of what we do, taking a more metric-driven approach to features. The community is still at a size where it's hard to make strong statements about the impact of individual changes, but we believe that getting better visibility into what the experience is like for users is key.</p><p>Couchers.org is only possible due to our amazing and dedicated volunteer team. We're so appreciate of our volunteers who believe in the vision of a non-profit, open-source, safe and active couch surfing community and donate their free time to make it a reality.</p><p>To everyone mentioned in this post, to all our past volunteers who got us where we are today, and to all our future volunteers to come―thank you!</p><p>Finally we also want to thank everyone in our community for sticking with us through many years of hard work to get to this point!</p><p>Want to help Couchers be even more amazing?!</p><p>Want to hang with other motivated travelers and help our community thrive? We can always use more help!</p><p>Specifically we could really use help with:</p><h3>Hype us up on social media</h3><p>Follow us on the socials, and like+share religiously 🙏</p><p>We have set a fundraising goal of raising $5000 this year. Help us reach this goal and keep the servers running by <a href=\"https://couchers.org/donate\">donating to our non-profit</a>. You'll also get a fun badge!</p><p><em>Written by <a href=\"https://couchers.org/user/aapeli\">Aapeli</a>. Published on 2025/07/01</em></p>","contentLength":11188,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44446917"},{"title":"AI note takers are flooding Zoom calls as workers opt to skip meetings","url":"https://www.washingtonpost.com/technology/2025/07/02/ai-note-takers-meetings-bots/","date":1751479517,"author":"tysone","guid":181700,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44446916"},{"title":"TikTok lays off more employees working on TikTok Shop US","url":"https://techcrunch.com/2025/07/02/tiktok-lays-off-more-employees-working-on-tiktok-shop-us/","date":1751479475,"author":"Amanda Silberling","guid":180843,"unread":true,"content":"<article>TikTok Shop US is conducting its third round of layoffs in as many months.</article>","contentLength":74,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Recent Droughts Are 'Slow-Moving Global Catastrophe' - UN Report","url":"https://news.slashdot.org/story/25/07/02/1754237/recent-droughts-are-slow-moving-global-catastrophe---un-report?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751479260,"author":"msmash","guid":180979,"unread":true,"content":"An anonymous reader shares a report: From Somalia to mainland Europe, the past two years have seen some of the most ravaging droughts in recorded history, made worse by climate change, according to a UN-backed report. Describing drought as a \"silent killer\" which \"creeps in, drains resources, and devastates lives in slow motion\" the report said it had exacerbated issues like poverty and ecosystem collapse. \n\nThe report highlighted impacts in Africa, the Mediterranean, Latin America and Southeast Asia, including an estimated 4.4 million people in Somalia facing crisis-level food insecurity at the beginning of this year. It recommends governments prepare for a \"new normal\" with measures including stronger early warning systems.","contentLength":735,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Assaults On ICE Officers Are Up 700%… Which Just Means There Have Been 69 More Assaults Than Last Year","url":"https://www.techdirt.com/2025/07/02/assaults-on-ice-officers-are-up-700-which-just-means-there-have-been-69-more-assaults-than-last-year/","date":1751478600,"author":"Tim Cushing","guid":180911,"unread":true,"content":"<p>The DHS finally decided to provide the underlying stats for its exponentially increasing claims of sky-high numbers of assaults on ICE officers.</p><p>Earlier this year, DHS spokesperson Tricia McLaughlin insisted assaults were up 413%, which was parroted by acting ICE direction Todd Lyons <a href=\"https://www.techdirt.com/2025/05/21/ice-boss-thinks-journalists-shouldnt-be-asking-about-masked-officers-disappearing-people/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/05/21/ice-boss-thinks-journalists-shouldnt-be-asking-about-masked-officers-disappearing-people/\">in his whiny response</a> to Washington Post columnist Philip Bump’s <a href=\"https://www.washingtonpost.com/opinions/2025/05/12/ice-masked-federal-agents-accountability-ozturk/\" data-type=\"link\" data-id=\"https://www.washingtonpost.com/opinions/2025/05/12/ice-masked-federal-agents-accountability-ozturk/\">questioning of ICE officer tactics</a>: namely, the unmarked vehicles, the refusal to identify themselves, and the fact that pretty much every person on a deportation task force seems incapable of doing the job without being dressed in camo and covering everything but their eyes with a mask. </p><p>According to Lyons and McLaughlin, the masks and lack of identification were essential to protecting ICE officers from the public, what with this massive spike in assaults on officers. Lyons’ response to Philip Bump cited McLaughlin’s public statements. The DHS’s public statements cited… absolutely nothing. </p><p>Since ICE refuses to release stats on assaults on officers, Philip Bump went digging into CBP stats to see if they were also increasing. They weren’t. In fact, assaults on CBP officers have been trending downward since 2022 and, if the rate remains consistent, there will be fewer assaults this year than last year. </p><p>ICE and the DHS doubled down when questioned, claiming a few days later the increase in the number of assaults was now 500%. To support this claim, the <a href=\"https://www.dhs.gov/news/2025/06/20/icymi-ice-agents-now-face-500-increase-assaults-against-them\" data-type=\"link\" data-id=\"https://www.dhs.gov/news/2025/06/20/icymi-ice-agents-now-face-500-increase-assaults-against-them\">DHS’s official government website</a> linked to… an article on right-wing rag Breitbart, I shit you not. And this article didn’t contain any stats. All it contained was a direct quote from DHS spokesperson Tricia McLaughlin about the 500% increase.</p><p>So far, all the DHS has given the public is statements that are closed loops. DHS says assaults are up 500%! Here’s a link to the DHS saying assaults are up 500%. </p><p>Maybe the DHS should have just continued doing that. At least  would have looked slightly less stupid than the actual truth. <a href=\"https://www.foxnews.com/person/m/bill-melugin\" data-type=\"link\" data-id=\"https://www.foxnews.com/person/m/bill-melugin\">Bill Melugin</a> (of all people), a Fox News correspondent, managed to secure the official stats from the DHS. And, as <a href=\"https://bsky.app/profile/jesspish.bsky.social/post/3lsvw2nbtpc2m\" data-type=\"link\" data-id=\"https://bsky.app/profile/jesspish.bsky.social/post/3lsvw2nbtpc2m\">Jessice Pishko noted on Bluesky</a>, the total number of assaults is laughably low.</p><p>If you can’t read/see the post, this is what Pishko said about the assault claims:</p><blockquote><p><em>That 700% number — from 10 to 79. Considering there have been thousands more encounters this is uniquely unimpressive. (Also, I would like to see each of these 79 reports bc I have a guess who started it.)</em></p></blockquote><p>The screenshot of Melugin’s tweet has the receipts: </p><blockquote><p><em>I asked DHS for the underlying raw data:</em></p><p><em>1/21/2024 – 6/30/24 10 assaults1/21/2025 – 6/30/2025 79 assaults</em></p></blockquote><p>That’s it. Less than 70 more assaults year-over-year. And that’s an  small increase, <a href=\"https://www.cbsnews.com/news/ice-detentions-non-criminal-immigrants-violent-crime-convictions-analysis/\" data-type=\"link\" data-id=\"https://www.cbsnews.com/news/ice-detentions-non-criminal-immigrants-violent-crime-convictions-analysis/\">given the  increase in ICE activity</a>, which includes daily raids of large businesses and densely populated areas.</p><blockquote><p><em>More than 97,000 people have been detained over Mr. Trump’s first five months in office, CBS News’ analysis found, while ICE arrests, which do not always result in detentions,&nbsp;<a href=\"https://www.cbsnews.com/news/ice-arrests-under-trump-100k/\" target=\"_blank\" rel=\"noreferrer noopener\">topped 100,000</a>&nbsp;earlier this month.</em></p><p><em>A&nbsp;<a href=\"https://www.cbsnews.com/news/ice-record-59000-immigrant-detainees-half-no-criminal-record/\" target=\"_blank\" rel=\"noreferrer noopener\">record 59,000 people</a>&nbsp;were currently being held in ICE detention as of June 23 — nearly half of them with no criminal record, CBS News reported last week.&nbsp;</em></p></blockquote><p>Even if you choose to believe every assault reported here is actually an “assault” (rather than someone inadvertently bumping an officer, standing too close to an officer, “<a href=\"https://www.techdirt.com/search/?num=20&amp;q=contempt+of+cop&amp;search=Search\" data-type=\"link\" data-id=\"https://www.techdirt.com/search/?num=20&amp;q=contempt+of+cop&amp;search=Search\">contempt of cop</a>,” swearing at an officer, <a href=\"https://www.techdirt.com/2014/02/25/with-great-power-comes-thinnest-skin-13-year-old-hit-with-felony-charges-after-throwing-snowball-cop/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2014/02/25/with-great-power-comes-thinnest-skin-13-year-old-hit-with-felony-charges-after-throwing-snowball-cop/\">throwing a snowball at an officer</a>, etc.), the government action far outpaces the corresponding increase in assaults. Those are  numbers, what with the number of officers involved in domestic  mass deportation efforts.</p><p>So, now that we know the truth, we’re back where we started: DHS and ICE look absolutely ridiculous claiming immigration enforcement work is so dangerous every officer needs to hide their face and drive around in unmarked vehicles like the kidnappers they are. The next time administration officials claim there’s been another spike in assaults, remember it only takes ten assault allegations from officers to add another 100% to the total. </p>","contentLength":4077,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Terra CO2 cements $124M Series B to slash concrete’s carbon footprint","url":"https://techcrunch.com/2025/07/02/terra-co2-cements-124m-series-b-to-slash-concretes-carbon-footprint/","date":1751478591,"author":"Tim De Chant","guid":180842,"unread":true,"content":"<article>The startup said that it’ll be using the new funding to build a massive facility near Dallas capable of pumping out 240,000 tons of its supplementary cementitious material (SCM) annually.</article>","contentLength":189,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ChatGPT referrals to news sites are growing, but not enough to offset search declines","url":"https://techcrunch.com/2025/07/02/chatgpt-referrals-to-news-sites-are-growing-but-not-enough-to-offset-search-declines/","date":1751478520,"author":"Sarah Perez","guid":180841,"unread":true,"content":"<article>Not surprisingly, organic traffic has also declined, dropping from over 2.3 billion visits at its peak in mid-2024 to now under 1.7 billion.</article>","contentLength":140,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"5 ways to transform your workflow using GitHub Copilot and MCP","url":"https://github.blog/ai-and-ml/github-copilot/5-ways-to-transform-your-workflow-using-github-copilot-and-mcp/","date":1751478242,"author":"Klint Finley","guid":180846,"unread":true,"content":"<p>Traditional AI coding assistants typically operate in isolation, limited to the code in your current workspace. Now with the introduction of the Model Context Protocol (MCP), AI development workflows are further evolving to incorporate more tools and context.&nbsp;</p><p>MCP can enable AI assistants to interact with external systems like knowledge bases, data stores, and testing applications.</p><p>The real value of MCP integration is that you can now perform tasks that previously required multiple tools, context switching, and manual effort—all directly in your IDE. That means you can save time, maintain focus, and ship code faster.</p><p>In this article, we’ll explore five practical ways MCP integrations with GitHub Copilot can streamline your workflow. We’ll follow a realistic scenario: implementing a secure JWT (JSON Web Token) authentication system for a web application, illustrating an end-to-end workflow with MCP.</p><h2>1. Using MCP to bridge design and development with Figma&nbsp;</h2><p>The gap between design and development has long been a source of friction in product teams. MCP provides a standardized way for GitHub Copilot to securely access and interpret design specifications directly.&nbsp;</p><p>Instead of manually translating design details into code, MCP enables Copilot to automatically retrieve exact design parameters—such as colors, spacing, typography, and component states—and generate accurate, ready-to-use code. This integration reduces guesswork and streamlines the handoff between designers and developers.</p><p>We’ll start developing our new JWT authentication system by taking a look at the user-facing side. Let’s say the design team updated the authentication UI components in Figma, including login forms, error states, loading spinners, and success messages. Now, you need to implement these changes to match the new design system.</p><p>Start by asking Copilot, “What are the latest design updates for the login form and authentication components?” It will then retrieve specs for the elements that need to change. Then you can prompt it to create React components for each element:</p><ul><li> with exact spacing, colors, typography</li><li> component with proper error styling</li><li> component</li></ul><p>Copilot will then give you ready-to-use code that maintains consistency with the design specifications from Figma.</p><h2>2. Tap into your Obsidian knowledge base with MCP</h2><p>When implementing complex features like JWT authentication, you often need to reference past decisions, architectural notes, and research findings scattered across your knowledge base. The unofficial, community-maintained Obsidian MCP server bridges this gap by connecting GitHub Copilot directly to your Obsidian vault.</p><p>Let’s say you’re implementing JWT token validation and need to understand your team’s previous security decisions. You tell Copilot: “Search for all files where JWT or token validation is mentioned and explain the context.”</p><ul><li>Search across all Markdown files in your vault for relevant security patterns</li><li>Retrieve contents from specific architecture decision records (ADR)</li><li>Access meeting notes from previous security reviews</li><li>Pull implementation guidelines from your team’s coding standards</li></ul><p>You might follow up with the following prompt: “Get the contents of the last architecture call note about authentication and summarize the key decisions.” Copilot will locate the relevant file and extract the critical information you need to inform your implementation approach.</p><p>Once you’ve gathered the necessary context, you can ask Copilot to synthesize this information: “Create a new note called ‘jwt-implementation-summary.md’ that combines our authentication standards with the new JWT approach.” Copilot will create this documentation directly in your vault, helping maintain your team’s knowledge base.</p><p>: This integration requires the community “Obsidian Local REST API” plugin and an API key.</p><p>With your research complete and documented, you can proceed to test your application.</p><h2>3. Test your code with Playwright</h2><p>Integrating MCP with Playwright transforms test creation from a manual, error-prone process into a simple, guided experience.</p><p>Modern web applications often involve complex user journeys, asynchronous operations, and dynamic content. Authentication flows are particularly challenging to test comprehensively.</p><p>Continuing with our JWT authentication system, you need to test the complete authentication flow including login, token refresh, and secure route access. To do this, you’ll start by giving Copilot a prompt like this: “Test the JWT authentication flow including login, automatic token refresh, and access to protected routes.”</p><p>From there, Copilot will analyze your authentication implementation and generate comprehensive test coverage. But it doesn’t stop there. Copilot then runs the tests with Playwright and provides immediate feedback on failures, suggesting fixes for common issues, like timing problems or selector changes.</p><h2>4. File pull requests faster</h2><p>Turning back to our JWT authentication example, you can prompt Copilot: “Create a pull request for my authentication feature changes”</p><p>Copilot will then analyze:</p><ul><li>Code changes across multiple files&nbsp;&nbsp;</li><li>Related issues and project context&nbsp;&nbsp;</li><li>Team review patterns and expertise areas&nbsp;&nbsp;</li><li>Previous similar implementations</li></ul><p>Copilot returns Markdown with an overview, changes made, a testing strategy, and even related issues.</p><p>It will then suggest appropriate reviewers for each aspect of the change based on code ownership, expertise mapping, and current workload.</p><p>Once your application is deployed, you can move on to monitoring it.</p><p>With the core authentication logic handled, now it’s time to ensure that our application performs well by monitoring how it behaves in production. Using MCP to connect to Grafana through the open-source Grafana MCP server makes this easier—though setup requires a few configuration steps.</p><p>Let’s say you need to analyze the JWT authentication system’s latency metrics and error rates. You tell Copilot: “Show me auth latency and error-rate panels for the auth-service dashboard for the last 6 hours.”</p><p>After configuring the Grafana MCP server with your API key and host URL, Copilot can then query your Grafana instance to:</p><ul><li>Examine authentication latency metrics and p95 response times</li><li>Analyze error rates for login endpoints over time</li><li>Review existing alert rules for authentication services</li><li>Identify patterns in failed authentication attempts</li></ul><p>Copilot returns panel data as base64-encoded images and can extract raw time-series data when needed. If you need a longer time range, you can specify: “Show me the same metrics for the last 24 hours” and Copilot will adjust the query parameters accordingly.</p><p>For more advanced monitoring workflows, you can enable write operations by launching the server with the  flag and an Editor-role API key. This allows Copilot to create new alert rules or modify dashboard configurations based on your authentication metrics analysis.</p><p>Before diving into these powerful integrations, you’ll need to configure your development environment. Here’s how:</p><ol><li>: Enable MCP support in your IDE through official extensions</li><li>: Set up authentication for each service (GitHub, Obsidian, Figma, etc.)</li><li><strong>Define context boundaries</strong>: Establish what information should be accessible to AI</li><li>: Implement proper access controls and data privacy measures</li></ol><ul><li>: Begin with one integration and gradually expand your usage</li><li>: Keep your knowledge bases and documentation current for optimal AI assistance</li><li><strong>Regularly review Copilot’s outputs</strong>: Periodically audit AI-generated suggestions to ensure quality and security</li><li>: Ensure your team understands and adopts consistent MCP usage patterns</li></ul><p>The five integration patterns we’ve explored represent just the beginning of what’s possible. As MCP’s ecosystem grows, new tools and integrations will continue to expand what’s possible.</p>","contentLength":7862,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Daily Deal: The 2025 Project Management Masterclass Bundle","url":"https://www.techdirt.com/2025/07/02/daily-deal-the-2025-project-management-masterclass-bundle/","date":1751478240,"author":"Daily Deal","guid":180910,"unread":true,"content":"<p>The <a href=\"https://deals.techdirt.com/sales/the-2025-project-management-certification-masterclass-bundle-ft-scrum-agile-jira?utm_campaign=affiliaterundown\">2025 Project Management Masterclass Bundle</a> has 9 courses to get you up to date on different project managment systems and tools. Courses cover Scrum, Jira, Kanban, Agile, and more. You’ll learn about time mangament, product ownership, and receive test prep for various certification exams. The bundle is on sale for $40.</p><p><em>Note: The Techdirt Deals Store is powered and curated by StackCommerce. A portion of all sales from Techdirt Deals helps support Techdirt. The products featured do not reflect endorsements by our editorial team.</em></p>","contentLength":537,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Agent, take the wheel (Interview)","url":"https://changelog.com/podcast/648","date":1751477400,"author":"","guid":180904,"unread":true,"content":"<p>Thorsten Ball returned to Sourcegraph to work on Amp because he believes being able to talk to an alien intelligence that edits your code changes everything. On this episode, Thorsten joins us to discuss exactly how coding agents work, recent advancements in AI tooling, Amp’s uniqueness in a sea of competitors, the divide between believers and skeptics, and more.</p><p><a href=\"https://changelog.com/++\" rel=\"payment\">Changelog++</a> members save 5 minutes on this episode because they made the ads disappear. Join today!</p><ul><li><a href=\"https://depot.dev\">Depot</a> – <strong>10x faster builds? Yes please.</strong> Build faster. Waste less time. Accelerate Docker image builds, and GitHub Actions workflows. Easily integrate with your existing CI provider and dev workflows to save hours of build time.\n</li><li><a href=\"https://retool.com/agents\">Retool</a> – <strong>Assemble your elite AI team</strong>, arm them with powerful custom tools, and watch them make your to-do list disappear. Start for free or book a demo at <a href=\"https://retool.com/agents\">retool.com/agents</a></li></ul>","contentLength":869,"flags":null,"enclosureUrl":"https://op3.dev/e/https://cdn.changelog.com/uploads/podcast/648/the-changelog-648.mp3","enclosureMime":"","commentsUrl":null},{"title":"Lorde's New CD is So Transparent That Stereos Can't Even Read It","url":"https://hardware.slashdot.org/story/25/07/02/1715258/lordes-new-cd-is-so-transparent-that-stereos-cant-even-read-it?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751476800,"author":"msmash","guid":180867,"unread":true,"content":"An anonymous reader shares a report: Lorde [a popular New Zealand singer and songwriter] fans are clearly struggling to play the CD version of her new album. Customers who purchased the special edition of Virgin released on a transparent plastic disc are reporting on Reddit and TikTok that many CD players, car stereos, and other sound systems they've tried are unable to play it.","contentLength":381,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"🤫 Meta's Secret Spying Scheme | EFFector 37.7","url":"https://www.eff.org/deeplinks/2025/06/metas-secret-spying-scheme-effector-377","date":1751476555,"author":"Christian Romero","guid":180861,"unread":true,"content":"<p>Keeping up on the latest digital rights news has never been easier. With a new look, <a href=\"https://eff.org/effector/37/7\">EFF's EFFector newsletter</a> covers the latest details on our work defending your rights to privacy and free expression online.</p><p>And, in case you missed it in the previous newsletter, we're debuting a <a href=\"https://youtu.be/AVdo2IYxUEg\">new audio companion</a> to EFFector as well! This time, Lena Cohen breaks down the ways that Meta tracks you online and what you—and lawmakers—can do to prevent that tracking. You can listen now on <a href=\"https://youtu.be/AVdo2IYxUEg\">YouTube</a> or the <a href=\"https://archive.org/details/37.7_20250702\">Internet Archive</a>.</p>","contentLength":511,"flags":null,"enclosureUrl":"https://www.eff.org/files/banner_library/effector_banner_5.jpeg","enclosureMime":"","commentsUrl":null},{"title":"Former SpaceX manager alleges harassment, retaliation, and security violations in lawsuit","url":"https://techcrunch.com/2025/07/02/former-spacex-manager-alleges-harassment-retaliation-and-security-violations-in-lawsuit/","date":1751475777,"author":"Aria Alamalhodaei","guid":180717,"unread":true,"content":"<article>Previous lawsuits against SpaceX have alleged similar stories of bias against female employees and a hostile work environment that enabled gender-based harassment. </article>","contentLength":164,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stop Killing Games","url":"https://www.stopkillinggames.com/","date":1751474732,"author":"MYEUHD","guid":180866,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44445880"},{"title":"Features of D That I Love","url":"https://bradley.chatha.dev/blog/dlang-propaganda/features-of-d-that-i-love/","date":1751474728,"author":"vips7L","guid":181699,"unread":true,"content":"<p>This is a beginner-friendly post exploring some of my favourite parts of the <a href=\"https://dlang.org/\">D programming language</a>, ranging from smaller quality of life stuff, to more major features.</p><p>I  talk much about D’s metaprogramming in this post as that topic basically requires its own dedicated feature list, but I still want to mention that D’s metaprogramming is world class - allowing a level of flexibility &amp; modelling power that few statically compiled languages are able to rival.</p><p>I’ll be providing some minimal code snippets to demonstrate each feature, but this is by no means an in depth technical post, but more of an easy to read “huh, that’s neat/absolutely abhorrent!” sort of deal.</p><h2>Feature - Automatic constructors</h2><p>If you define a struct (by-value object) without an explicit constructor, the compiler will automatically generate one for you based on the lexical order of the struct’s fields.</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>Very handy for Plain Old Data types, especially with the semi-recent support for <a href=\"https://dlang.org/spec/expression.html#argument-parameter-matching\">named parameters</a>.</p><h2>Feature - Design by contract</h2><ul><li>“in” assertions to confirm that the function’s parameters are valid.</li><li>“out” assertions to confirm that the function’s return value is in a valid state.</li></ul><p>Additionally you can attach “invariants” onto structs and classes. Invariants are functions that run at the start and end of every  member function, and can be used to ensure that the type is always in a valid state.</p><p>Let’s start off with a contrived example of invariants:</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>Now let’s rewrite the above type to use “in” contracts instead, with an extra function to show off “out” contracts:</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>This can allow for an easy self-descriptive validation pattern for consumers/readers of your code, as well as an easy to implement self-checking mechanism for types that have complex internals.</p><p>Anecdotally I find this to be an underutilised feature of D, and it’s one I like to make use of a lot in my own code.</p><h2>Syntax - The dollar operator</h2><p>A lot of languages do not provide a shorthand syntax for referencing the length of an array, which can sometimes lead to awkward looking code when e.g. slicing arrays (any Go enjoyers here?).</p><p>D provides the dollar operator, which is a shorthand syntax for referencing the length of something.</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>Structs and classes can even <a href=\"https://dlang.org/spec/operatoroverloading.html#dollar\">overload</a> this operator.</p><p>D compilers provide an interpreter for the language which allows a very large amount of D code to be ran at compile time, as-is, without any special marking or other weirdness to go with it.</p><p>Generally, anywhere where the language requires a compile-time constant is a place where CTFE will transparently come into play.</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>This feature has a lot of different practical applications, and can allow for much cleaner, robust code than hardcoding precomputed values.</p><p>Since a lot of use cases relate to metaprogramming I’ll leave the topic here, but CTFE is an extremely instant example of D’s unusual feature set.</p><h2>Feature - Built-in unittests</h2><p>D has direct support for defining unittests, and even allows you to override the built-in test runner for something more robust (such as with the <a href=\"https://code.dlang.org/packages/unit-threaded\">unit-threaded</a> library).</p><p>D code usually bundles unittests and normal code within the same file, rather than splitting them out into separate files as with most other languages:</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>This extremely low-friction barrier for writing tests is a godsend for motivating people to write even the most minimal of tests.</p><p>Of course if you have more complex needs then the option to have a proper testing framework + structure is still available to you, but the vast majority of D code I’ve seen simply uses  blocks, optionally with a library that provides a better test runner.</p><h2>Feature - Exhaustive switch statements</h2><p>D provides a  statement which has an autogenerated  case that will immediately crash the program if its taken.</p><p>This allows you to define a switch that will always alert you if a new value needs to be added, or if an invalid value was somehow passed into it.</p><p>Additionally, if you use a  with an  value, then a compile-time check is triggered to ensure that every value within the  type has been declared, making it impossible to forget to add a new case when the enum is modified.</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><h2>Syntax - Parenthesis omission</h2><p>D allows you to omit parentheses when calling functions in multiple contexts.</p><p>When calling a function with no parameters, you can omit them:</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>(Marginally related) When calling a function with 1 parameter, you may use assignment syntax instead:</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>When passing a single template parameter which consists of only 1 lexical token, you may omit the parenthesis:</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>This can do wonders for readability.</p><p>UFCS allows call chains to be “inverted” by allowing freestanding functions to be used as if they were a member of their first parameter.</p><p>In other words:  can be rewritten as .</p><p>The two following snippets are completely equivalent in function, except the second snippet uses UFCS to provide a more clean look.</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><h2>Feature - Scoped &amp; Selective Imports</h2><p>D supports limiting imports to a specific scope, whether that be a singular if-statement, an entire function, an entire struct/class, etc.</p><p>D will also allow you to selectively import symbols from other modules, instead of polluting your lookup scope with a ton of unrelated stuff - also helps increase comprehension of the codebase.</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>While it may seem like clutter and extra effort, in the long run this allows for:</p><ol><li>Making it easy for newcomers to understand where certain functions are coming from.</li><li>Allows for code to become “portable” between files since the code can carry most of its external dependencies inside of itself, making refactoring a bit easier.</li></ol><h2>Feature - Built-in documentation generator</h2><p>Finally, D has a built-in documentation generator with a relative standard, easy to read format.</p><p>There’s also a handful of documentation tools that are detached from the built-in one since the default generated output is a bit lacklustre ( I’m plugging my <a href=\"https://github.com/Juptune/marmos\">custom tool</a> here).</p><p>Here’s a relatively extreme example from one of my personal projects, to get an idea of the basic format:</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>Here’s an example from the standard library, which has minor usage of documentation macros:</p><div><figure><pre data-language=\"d\"><code></code></pre></figure></div><p>I tried to focus more on the more simpler day-to-day features, with only a splattering of the bigger more complicated stuff.</p><p>Hopefully this provides some insight on the wacky-yet-wonderful feature set that D provides.</p>","contentLength":6276,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44445877"},{"title":"Air Pollution Linked To Lung Cancer-Driving DNA Mutations, Study Finds","url":"https://science.slashdot.org/story/25/07/02/1620205/air-pollution-linked-to-lung-cancer-driving-dna-mutations-study-finds?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751474400,"author":"msmash","guid":180759,"unread":true,"content":"Air pollution has been linked to a swathe of lung cancer-driving DNA mutations, in a study of people diagnosed with the disease despite never having smoked tobacco. From a report: The findings from an investigation into cancer patients around the world helps explain why those who have never smoked make up a rising proportion of people developing the cancer, a trend the researchers called an \"urgent and growing global problem.\" \n\nProf Ludmil Alexandrov, a senior author on the study at the University of California in San Diego, said researchers had observed the \"problematic trend\" but had not understood the cause. \"Our research shows that air pollution is strongly associated with the same types of DNA mutations we typically associate with smoking,\" he said. \n\nThe scientists analyzed the entire genetic code of lung tumors removed from 871 never-smokers in Europe, North America, Africa and Asia as part of the Sherlock-Lung study. They found that the higher the levels of air pollution in a region, the more cancer-driving and cancer-promoting mutations were present in residents' tumors. Fine-particulate air pollution was in particular linked to mutations in the TP53 gene. These have previously been associated with tobacco smoking.","contentLength":1244,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trump’s Last-Minute Legal Maneuver Attempts To Dodge Iowa’s New Anti-SLAPP Law","url":"https://www.techdirt.com/2025/07/02/trumps-last-minute-legal-maneuver-attempts-to-dodge-iowas-new-anti-slapp-law/","date":1751474100,"author":"Mike Masnick","guid":180800,"unread":true,"content":"<p>After Donald Trump  the election, he was still so full of hatred, bile, and spite, that <a href=\"https://www.techdirt.com/2024/12/18/the-trump-vengeance-tour-continues-as-he-sues-pollster-for-being-wrong/\">he sued the pollster Ann Selzer</a> as well as the Des Moines Register. Selzer, who has been one of the most trusted names in polling, released a poll slightly before the election that predicted a somewhat shocking victory of Kamala Harris in Iowa. It (obviously) turned out to be very wrong, but making a wrong prediction does not violate the law.</p><p>What’s happened since reveals something more concerning: a systematic approach to gaming the legal system that goes beyond typical SLAPP suit tactics. Trump’s lawyers aren’t just trying to win—they’re trying to exploit procedural gaps to avoid accountability mechanisms specifically designed to stop this kind of litigation abuse.</p><p>The entire intent of the lawsuit was to chill speech and punish those who don’t tell Trump what he wants to hear at every moment.</p><p>Not surprisingly, the lawsuit is not going well. It was initially filed in a local state court in Polk County, Iowa, but the defendants <a href=\"https://www.courtlistener.com/docket/69476247/trump-v-selzer/\">had it removed to federal court</a>, where the standards are even higher, and where Trump would have a much more difficult time. Generally speaking, defendants in cases like this want them in federal courts where the judges are more likely to understand the underlying issues (especially around gamesmanship by plaintiffs). In this case, it was removed to federal court on diversity grounds, which is typical when the plaintiff is from out of state.</p><p>Selzer and the Register sought <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.iasd.89411/gov.uscourts.iasd.89411.24.0.pdf\">to dismiss</a> the complaint, while Trump sought to have the case <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.iasd.89411/gov.uscourts.iasd.89411.30.0.pdf\">sent back</a> to the state court. He did so by (1) adding two more plaintiffs (random other politicians who live in Iowa so there was no longer diversity), and (2) making some weird procedural argument that the method of removal went against Congress’s intent. On May 23rd, <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.iasd.89411/gov.uscourts.iasd.89411.65.0_1.pdf\">the court denied</a> Trump’s attempt to move the case back to state court, noting that the procedural argument was nonsense. And it found that Trump’s attempt to add Iowa plaintiffs to the case was a pretty transparent attempt to try to get around diversity rules to force the case back to the state court.</p><p>Trump <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.iasd.89411/gov.uscourts.iasd.89411.69.1.pdf\">appealed that ruling</a> to the Eighth Circuit, but something important had happened earlier in May which it appears Trump’s lawyers only realized belatedly. On May 20th, Iowa’s governor <a href=\"https://www.rcfp.org/anti-slapp-guide/iowa/\">signed the state’s first anti-SLAPP bill</a> into law. Now, it doesn’t apply to cases filed before the law goes into effect (July 1st), but it does mean that if Trump were to, say, file a brand new lawsuit , it would be subject to anti-SLAPP rules. This would (1) make it even easier for the case to be dismissed, while (2) likely make it so Trump would have to pay Selzer and the Register’s legal bills.</p><p>Basically, they’re trying to get a do over. The district court said they couldn’t add those extra plaintiffs to avoid diversity, and even though they appealed that ruling, they still want to refile the case (with the added plaintiffs) in state court. But they had to do it before July 1st. But they had already appealed the district court’s denial of the request to remand the case back to state court, so this all appears to be pure gamesmanship.</p><p>In response, Selzer and the Des Moines Register are <a href=\"https://storage.courtlistener.com/recap/gov.uscourts.iasd.89411/gov.uscourts.iasd.89411.72.0.pdf\">asking the district court to deny Trump’s attempted dismissal</a>, noting that it’s obviously playing games to try to get around the earlier ruling rejecting the attempt to send the case back to state court, and even calling out how it’s doing this to avoid the new anti-SLAPP law.</p><p>The defendants note that once Trump filed his appeal, the district court no longer controls the case:</p><blockquote><p><em>However, the case cannot be dismissed at the district court while appellate proceedings are ongoing. This is because “the district court is divested of jurisdiction over matters on appeal” upon the initiation of that appeal. State ex rel. Nixon v. Coeur D’Alene Tribe, 164 F.3d 1102, 1106 (8th Cir. 1999); Ahlberg v. Chrysler Corp., 481 F.3d 630, 638 (8th Cir. 2007) (finding that orders pertaining to matters pending on appeal have “no effect”).</em></p></blockquote><p>And then, they describe how Trump is playing games to avoid the new anti-SLAPP law:</p><blockquote><p><em>Lastly, President Trump’s Notice must be evaluated in the light of long-standing Eighth Circuit law holding that “[a] party may not dismiss simply to avoid an adverse decision or seek a more favorable forum.” Cahalan v. Rohan, 423 F.3d 815, 818 (8th Cir. 2005) (citing Hamm v. Rhone-Poulenc Rorer Pharm., Inc., 187 F.3d 941, 950 (8th Cir. 1999))</em></p><p><em>Before this Court, President Trump has lost his motion for remand, (ECF No. 65), lost his motion to stay the case, (ECF No. 70), and has a pending deadline to file a revised Amended Complaint. (Id.) And fulsome Motions to Dismiss warranting dismissal of the case in full and with prejudice are currently pending before this Court with substantial briefing. (ECF Nos. 24, 28, 33, 35, 51, 52, 57, 61.)</em></p><p><em>Furthermore, in conjunction with his improper Notice of Voluntary Dismissal, President Trump newly filed a lawsuit in the Iowa District Court for Polk County today; however, the new Petition is substantively unchanged from the President Trump’s First Amended Complaint in the present case. (See Ex. C: Petition (June 30, 2025).) The timing of this filing is significant: it is one day before Iowa’s Uniform Public Expression Protection Act (commonly known as an “antiSLAPP law”) goes into effect. See House File 472, available at</em><a href=\"https://www.legis.iowa.gov/legislation/BillBook?ga=91&amp;ba=HF472\"><em>https://www.legis.iowa.gov/legislation/BillBook?ga=91&amp;ba=HF472</em></a><em>(Governor’s approval of House File 472, Uniform Public Expression Protection Act on May 19, 2025), codified at Iowa Code § 652.1, et seq.; see also Iowa Code § 3.7(1) (stating that all acts “passed at regular sessions of the general assembly shall take effect on the first day of July following their passage). This new legislation would apply to President Trump’s lawsuit; therefore, President Trump’s present Notice of Voluntary Removal would effectively escape the jurisdiction of the federal courts in time to restate his claims in Iowa’s state court without being subject to Iowa’s anti-SLAPP law.</em></p><p><em>In these circumstances, this Court should rightly find that President Trump’s Notice of Voluntary Dismissal improperly seeks “to avoid [the] adverse decision[s]” of this Court—both past and future—and “a more favorable forum” in Iowa’s pre-anti-SLAPP courts. Cahalan, 423 F.3d at 818.</em></p></blockquote><p>The timing here is almost comically transparent. Trump’s lawyers clearly realized they had a problem if they planned to file a new lawsuit once Iowa’s anti-SLAPP law was about to take effect. Their solution was to try to dismiss the federal case they’d been fighting to get back to state court, refile the exact same claims in state court, all on the last day before the new protections kicked in.</p><p>It’s a perfect illustration of how Trump approaches litigation: not as a search for justice, but as a game to be manipulated. When the rules change in ways that might hold him accountable, he doesn’t accept the new reality—he tries to find procedural workarounds to avoid them entirely.</p><p>The federal judge has already seen through one round of Trump’s transparent gamesmanship. Whether she’ll allow this latest attempt to dodge accountability will likely determine whether Ann Selzer and the Des Moines Register can finally put this vindictive lawsuit behind them, or whether they’ll be dragged through state court proceedings that should never have been allowed in the first place.</p>","contentLength":7542,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why We Should Focus on AI for Women","url":"https://towardsdatascience.com/why-we-should-focus-on-ai-for-women/","date":1751473791,"author":"Shuyang","guid":180789,"unread":true,"content":"<p>A simulation study on gender disparities entrenched in AI.</p>","contentLength":58,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Docker Container Exits Immediately? Here’s How to Fix ENTRYPOINT & CMD Issues Fast","url":"https://blog.devops.dev/docker-container-exits-immediately-heres-how-to-fix-entrypoint-cmd-issues-fast-24903c44530a?source=rss----33f8b2d9a328---4","date":1751473563,"author":"Ali Hamza","guid":180839,"unread":true,"content":"<h4>Fix Docker containers that exit immediately by understanding and correcting ENTRYPOINT and CMD issues with real examples and step-by-step solutions.</h4><p>When you’re working with Docker, few things are more frustrating than building an image, running a container, and — <strong>boom — it exits immediately</strong>.</p><p>No error messages. No clear reason. Just&nbsp;silence.</p><p>This is a , especially for those just starting out. The culprit? It’s often related to how you define  and  in your Dockerfile.</p><p>In this guide, I’ll explain <strong>why your Docker container exits immediately</strong>, how to , and how to <strong>properly configure ENTRYPOINT and CMD</strong> so your container behaves as expected.</p><h3>Understanding the Problem: Why Docker Containers Exit Immediately</h3><p>When a Docker container exits right after starting, it usually means the container <strong>ran the default command and completed</strong>. Unlike virtual machines, Docker containers are designed to run a single process — when that process ends, the container exits&nbsp;too.</p><h4>How to Check What&nbsp;Happened</h4><p>You can use the following command to check the container’s status:</p><p>This shows all containers (even the stopped ones). Look at the  column to see if it exited immediately.</p><pre>docker logs &lt;container_id&gt;</pre><p>This often reveals errors or termination messages from your containerized app.</p><h3>ENTRYPOINT vs CMD: What’s the Difference?</h3><p>Both ENTRYPOINT and CMD are Dockerfile instructions used to define  when a container starts — but they work differently.</p><pre>ENTRYPOINT [\"python3\"]CMD [\"app.py\"]</pre><p>If you forget one or combine them wrong, the container may .</p><h3>Common ENTRYPOINT &amp; CMD Mistakes That Cause Immediate Exit</h3><p>Here are frequent issues that result in containers exiting:</p><ul><li><strong>CMD runs a short-lived command</strong>, like echo \"Done\" — it ends, so the container exits.</li><li><strong>Missing or misused ENTRYPOINT/CMD</strong> — container has no valid process to&nbsp;run.</li><li> (string vs exec&nbsp;format).</li><li>, so it fails silently.</li></ul><h3>Step-by-Step Guide to Debug the Exit&nbsp;Issue</h3><pre>docker logs &lt;container_id&gt;</pre><p>You might see errors&nbsp;like:</p><pre>bash: ./entrypoint.sh: Permission denied</pre><h4>2. Inspect the Dockerfile</h4><p>Look at the CMD and ENTRYPOINT lines. Are they defined properly?</p><h4>3. Run the Container Interactively</h4><p>Start with a shell to look&nbsp;inside:</p><pre>docker run -it &lt;image_name&gt; /bin/bash</pre><p>Then try running your script or command manually.</p><h3>How to Fix ENTRYPOINT and CMD Issues (with Examples)</h3><h4>Fix 1: Use CMD for Simple&nbsp;Apps</h4><pre>FROM python:3.10-slimCOPY app.py .<p>CMD [\"python3\", \"app.py\"]</p></pre><h4>Fix 2: Use ENTRYPOINT with CMD for Flexible Arguments</h4><pre>FROM ubuntuCOPY entrypoint.sh /entrypoint.sh<p>RUN chmod +x /entrypoint.sh</p>ENTRYPOINT [\"/entrypoint.sh\"]</pre><h4>Fix 3: Ensure Script is Executable</h4><h4>Fix 4: Avoid Shell Form (Unless&nbsp;Needed)</h4><pre>CMD [\"nginx\", \"-g\", \"daemon off;\"]</pre><pre>CMD nginx -g \"daemon off;\"</pre><p>Shell form can break argument parsing and&nbsp;signals.</p><h3>Working Dockerfile Examples</h3><pre>FROM python:3.10-slimCOPY app.py .<p>CMD [\"python3\", \"app.py\"]</p></pre><pre>FROM ubuntuCOPY entrypoint.sh /entrypoint.sh<p>RUN chmod +x /entrypoint.sh</p>ENTRYPOINT [\"/entrypoint.sh\"]</pre><p>If entrypoint.sh contains something like:</p><pre>#!/bin/bashecho \"Starting my app...\"</pre><p>Your container will now stay alive for 5 minutes (good for testing).</p><h3>Pro Tips to Avoid Exit Issues in the&nbsp;Future</h3><ul><li>Always test your image interactively:</li></ul><pre>docker run -it &lt;image&gt; bash</pre><ul><li>Stick to  ([\"cmd\", \"arg\"]) for ENTRYPOINT and&nbsp;CMD.</li><li>Check logs immediately using:</li></ul><pre>docker logs &lt;container_id&gt;</pre><ul><li>Ensure the main process runs , or your container will&nbsp;exit.</li><li>Add health checks for production deployments to monitor container status.</li></ul><p>A Docker container that  is almost always the result of an incorrect or short-lived command — often tied to  and&nbsp;.</p><ul><li>Understanding how Docker runs containers,</li><li>Debugging with logs and interactive shells,</li><li>And configuring your Dockerfile properly,</li></ul><p>…you can  these issues and get your container running the way you&nbsp;want.</p><p><strong>Have you faced a similar problem? Share your debugging tips in the comments below — let’s help each other&nbsp;grow!</strong></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=24903c44530a\" width=\"1\" height=\"1\" alt=\"\">","contentLength":3861,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"10 Steps To Ensure — Zero Trust Architecture in Kubernetes","url":"https://blog.devops.dev/10-steps-to-ensure-zero-trust-architecture-in-kubernetes-615ea58146de?source=rss----33f8b2d9a328---4","date":1751473558,"author":"Devops Diaries","guid":180838,"unread":true,"content":"<div><p>Implementing Zero Trust Architecture (ZTA) in Kubernetes involves designing security with the principle: “Never trust, always verify” —…</p></div>","contentLength":144,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Modern Observability in .NET: OpenTelemetry & Grafana","url":"https://blog.devops.dev/modern-observability-in-net-opentelemetry-grafana-4c08b9d74240?source=rss----33f8b2d9a328---4","date":1751473553,"author":"Adem KORKMAZ","guid":180837,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bash+Telegram : Simple Server Resource Alerting System","url":"https://blog.devops.dev/bash-telegram-simple-server-resource-alerting-system-833fcb534a33?source=rss----33f8b2d9a328---4","date":1751473551,"author":"bektiaw","guid":180836,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"11 Scripts to Transform Server Metrics into Insights","url":"https://blog.devops.dev/11-scripts-to-transform-server-metrics-into-insights-e461d72276eb?source=rss----33f8b2d9a328---4","date":1751473504,"author":"Obafemi","guid":180835,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Docker 101: The Complete Cheat Sheet for Devs & Ops","url":"https://blog.devops.dev/docker-101-the-complete-cheat-sheet-for-devs-ops-01ba7b13193a?source=rss----33f8b2d9a328---4","date":1751473496,"author":"Ashish Singh","guid":180834,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OSI Model Layer — Neworking Basic & Easiest Concept","url":"https://blog.devops.dev/osi-model-layer-neworking-basic-easiest-concept-f3cb2f15cd8f?source=rss----33f8b2d9a328---4","date":1751473472,"author":"Kamalpreet KAUR","guid":180833,"unread":true,"content":"<p>Let’s Deep Dive in OSI (Open System Interconnection Model)</p><p>The Open System Interconnection model is one of the crucial concepts in networking. It’s always made us stuck, and it’s one of the repetitive concepts. The main aim of the OSI Model is to understand the network flow. The basic strategy is to fully understand how the data streams flow up and down within the model -&gt; In other words, to understand the data flow that passes from one device to&nbsp;another.</p><h4>Let’s Begin with the Foundation</h4><blockquote>The OSI model was developed by the <strong><em>ISO (International Organization for Standardization) in the late 1970s and early 1980s</em></strong>. OSI is a<strong><em> as a standard or protocol itself</em></strong>it’s the reference to <strong>think about and describe the interactions between different layers of a computer&nbsp;network.</strong></blockquote><p>Imagine you are at home, and each room represents a layer (living room, study room&nbsp;…). These layers are interconnected with each other, which helps us to provide direction to move from one room to another. OSI reference model helps us to indicate the shared information between each&nbsp;other.</p><p><strong>The OSI model is like a blueprint of all layers </strong>that helps to understand <strong>each layer and its specifications (how different layers work with each&nbsp;other)</strong></p><h3>Every Layer Functionalities&nbsp;:</h3><h4>Functionality Explaination&nbsp;:</h4><blockquote>Application Layer — User Interface [GUI] Activities Presentation Layer — HTML pages / Readable webpages<p> Session Layer — Establish Communication Sessions </p>Transport layer — Data must arrive in order along with acknowledgement <p>Network Layer — Establish communication with distant devices</p>Data Link Layer — Data must be delivered to its correct destination<p>Physical Layer — Physical connectivity between devices involving cables and&nbsp;wires.</p></blockquote><h3>Difference between OSI Model and TCP/ IP&nbsp;Model</h3><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f3cb2f15cd8f\" width=\"1\" height=\"1\" alt=\"\">","contentLength":1802,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Successfully Deploy a Three-Tier application on AWS EKS using Terraform","url":"https://blog.devops.dev/how-to-successfully-deploy-a-three-tier-application-on-aws-eks-using-terraform-30fe80e82f88?source=rss----33f8b2d9a328---4","date":1751473467,"author":"Pravesh Sudha","guid":180832,"unread":true,"content":"<blockquote>Quick guide to provisioning and deploying a Three-Tier application on AWS EKS and Terraform</blockquote><p>Welcome to the world of cloud computing and automation. In this blog, we’re going to walk through an exciting real-world project — deploying a <strong>three-tier Todo List application</strong> on <strong>Amazon EKS (Elastic Kubernetes Service)</strong> using .</p><p>This project is perfect if you’re looking to get hands-on experience with:</p><ul><li><strong>Provisioning infrastructure using Terraform</strong></li><li> to containerize services</li><li><strong>Deploying applications on AWS using EKS, ECR, IAM</strong>, and&nbsp;more</li></ul><p>We’ll break it down step-by-step — from writing Terraform code to spinning up your Kubernetes cluster, containerizing the frontend, backend, and MongoDB services, and deploying everything seamlessly.</p><p>Whether you’re new to DevOps or brushing up on your cloud skills, this guide will help you understand how everything connects in a modern microservices-based deployment.</p><p>So without further ado, let’s get started and bring our infrastructure to life!&nbsp;🌐🛠️</p><h3>🔧 Prerequisites: What You’ll Need Before We&nbsp;Start</h3><p>Before we dive into the fun part — building and deploying — let’s quickly make sure your system is ready for action. Here’s what you’ll&nbsp;need:</p><p>✅ If you don’t already have one, head over to <a href=\"https://aws.amazon.com/\">aws.amazon.com</a> and sign up. We’ll be using AWS services like EKS (Elastic Kubernetes Service), ECR (Elastic Container Registry), and IAM (Identity and Access Management), so having an account is essential.</p><p>✅ We’ll use Docker to containerise the three components of our app: the frontend, backend, and MongoDB database. You can download Docker Desktop from the official Docker website and install it like any other&nbsp;app.</p><p>✅ Terraform will be our tool of choice for provisioning the infrastructure on AWS. You can download Terraform from <a href=\"https://developer.hashicorp.com/terraform/install\">terraform.io</a>. Just install it — no need to configure anything&nbsp;yet.</p><p>That’s it! Once you have these basics set up, you’re good to go. Let’s start building!</p><h3>🔐 Step 1: Set Up AWS CLI and IAM&nbsp;User</h3><p>Before Terraform can talk to AWS and spin up resources, we need to set up the  and create an  with the right permissions. Let’s walk through it step-by-step.</p><ol><li> to your AWS account as the root user (the one you used to sign&nbsp;up).</li></ol><ul><li>In the AWS Management Console, go to  and click on .</li></ul><ul><li>Give the user a name — something like three-tier-user works great — and click&nbsp;.</li><li>On the  page, attach the policy named .</li></ul><blockquote><em>: We’re giving full admin access here just to avoid permission issues during learning and experimentation. </em><strong><em>Never use this approach in production</em></strong><strong><em>Principle of Least Privilege</em></strong></blockquote><ul><li>Click  and then . You’re done with the IAM&nbsp;part!</li></ul><h3>📦 Install AWS CLI (Ubuntu/Linux)</h3><p>If you’re using , you can install the AWS CLI by running these commands in your terminal:</p><pre>curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"unzip awscliv2.zip</pre><p>If you’re using a different operating system (like macOS or Windows), just head over to the official install guide here:👉 <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\">AWS CLI Installation Guide</a></p><h3>🔑 Generate Access Keys &amp; Configure AWS&nbsp;CLI</h3><ul><li>Go back to the  and click on your new user (three-tier-user).</li><li>Under the  tab, click on .</li></ul><ul><li>Choose <strong>Command Line Interface (CLI)</strong> as the use case, agree to the terms, and&nbsp;proceed.</li></ul><ul><li>Once the keys are generated, <strong>copy the Access Key ID and Secret Access Key</strong> (you’ll need them right&nbsp;away!).</li></ul><p>Now, go to your terminal and configure the AWS&nbsp;CLI:</p><p>It will prompt you to&nbsp;enter:</p><ul><li>: You can use us-east-1 for this&nbsp;demo</li><li>: Enter&nbsp;json</li></ul><p>That’s it! Your AWS CLI is now set up and ready to communicate with your AWS account&nbsp;🚀</p><h3>🛠️ Step 2: Install Terraform and Set Up Remote&nbsp;Backend</h3><p>Now that our AWS CLI is ready and configured, let’s install , our Infrastructure as Code (IaC) tool of choice for this project. We’ll also set up a secure and scalable way to store our Terraform state using an .</p><h3>📥 Installing Terraform on Ubuntu&nbsp;(amd64)</h3><p>If you’re using <strong>Ubuntu on an amd64 system</strong>, follow these commands to install Terraform:</p><pre>sudo apt-get update &amp;&amp; sudo apt-get install -y gnupg software-properties-common</pre><pre>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\https://apt.releases.hashicorp.com $(grep -oP '(?&lt;=UBUNTU_CODENAME=).*' /etc/os-release || lsb_release -cs) main\" | \\<p>sudo tee /etc/apt/sources.list.d/hashicorp.list</p></pre><pre>sudo apt updatesudo apt-get install terraform</pre><p>✅ After this, you can verify the installation with:</p><p>🖥️ If you’re on a different operating system or architecture, follow the official installation guide here:👉 <a href=\"https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli\">Terraform Install&nbsp;Guide</a></p><h3>🔐 AWS CLI + Terraform: Working&nbsp;Together</h3><p>Since we’ve already configured the AWS CLI, Terraform will automatically use the credentials (access key &amp; secret key) stored by aws configure. This means you’re ready to provision AWS resources securely and seamlessly.</p><h3>☁️ Best Practice: Use Remote Backend for Terraform State</h3><p>Terraform tracks the state of your infrastructure in a file called terraform.tfstate. By default, it’s stored locally, but that’s risky and not scalable. So, we’ll follow best practices and store this file remotely in an .</p><p>Here’s how to create an S3 bucket to act as your Terraform :</p><h4>🪣 Create an S3 Bucket for State&nbsp;Storage</h4><pre>aws s3api create-bucket \\  --bucket pravesh-terra-state-bucket \\</pre><h4>📜 Enable Versioning for State&nbsp;History</h4><pre>aws s3api put-bucket-versioning \\  --bucket pravesh-terra-state-bucket \\<p>  --versioning-configuration Status=Enabled</p></pre><h4>🔐 Enable Default Encryption</h4><pre>aws s3api put-bucket-encryption \\  --bucket pravesh-terra-state-bucket \\<p>  --server-side-encryption-configuration '{</p>    \"Rules\": [{<p>      \"ApplyServerSideEncryptionByDefault\": {</p>        \"SSEAlgorithm\": \"AES256\"    }]</pre><p>And that’s it! You now have a secure, versioned, and encrypted S3 bucket ready to store your Terraform state files — a key step toward building a production-grade infrastructure.</p><h3>📦 Step 3: Clone the Project and Provision Infrastructure with Terraform</h3><p>With all the groundwork done — AWS CLI set up, Terraform installed, and the backend ready — it’s time to move on to the actual&nbsp;project!</p><p>The codebase for our  is available on my GitHub repository:</p><p>To get started, open your terminal and run the following commands:</p><pre>git clone https://github.com/Pravesh-Sudha/3-tier-app-Deploymentcd 3-tier-app-Deployment/</pre><p>Inside the cloned repo, you’ll find a folder named terra-config/. That’s where all the Terraform magic happens. Navigate into that directory:</p><p>Now initialize the Terraform backend (which we configured to use your S3 bucket earlier):</p><p>This will configure Terraform to use the remote backend for storing the state file. If your bucket name is different from mine (pravesh-terra-state-bucket), make sure to update the name in backend.tf.</p><h3>📁 Understanding the Terraform Code Structure</h3><p>Instead of dumping everything into a single main.tf file, I’ve broken the configuration into logical modules for clarity and scalability. Here’s a quick overview:</p><ul><li>provider.tf: Specifies the cloud provider. In our case, it’s AWS (no surprise&nbsp;there!).</li><li>backend.tf: Configures Terraform to store state remotely in our S3&nbsp;bucket.</li><li>ecr.tf: Creates two public repositories in ECR: 3-tier-frontend and 3-tier-backend for storing Docker&nbsp;images.</li><li>vpc.tf: Fetches the default VPC and subnet&nbsp;details.</li><li>role.tf: Defines IAM&nbsp;roles:</li></ul><p>— One for the EKS cluster (includes AmazonEKSClusterPolicy)</p><p>— One for the Node Group (includes policies like AmazonEKSWorkerNodePolicy, AmazonEC2ContainerRegistryReadOnly, and AmazonEKS_CNI_Policy)</p><ul><li>eks.tf: Provisions the EKS cluster named Three-tier-cloud.</li><li>node_group.tf: Creates the worker node group for the cluster with one t2.medium EC2 instance.</li></ul><h3>⏳ Apply the Terraform Configuration</h3><p>Now we’re ready to provision the infrastructure! Run the following command:</p><pre>terraform apply --auto-approve</pre><p>⏱️ This might take , especially since provisioning EKS clusters and node groups can take some time. Be patient — AWS is building your cloud infrastructure behind the&nbsp;scenes.</p><h3>🐳 Push Docker Images to&nbsp;ECR</h3><p>Once the infrastructure is up, it’s time to push our Docker images for the frontend and backend to AWS&nbsp;ECR.</p><ul><li>Go to your <strong>AWS Console &gt; ECR &gt; Repositories</strong></li></ul><ul><li>Click on the 3-tier-frontend repository</li><li>Click on  — AWS will show you four CLI&nbsp;commands</li></ul><p>Now, go to the frontend/ folder in your project directory:</p><p>Run each of the four commands one by one to build the image and push it to&nbsp;ECR.</p><p>Repeat the same steps for the 3-tier-backend repository:</p><ul><li>Go back to </li><li>Select 3-tier-backend and click </li></ul><ul><li>Navigate to the backend directory:</li></ul><p>Run the ECR commands provided to push the backend Docker&nbsp;image.</p><p>🎉 Once done, your container images will be hosted in your private AWS ECR repositories — ready to be deployed to your EKS&nbsp;cluster!</p><h3>🌐 Step 4: Deploy to EKS with kubectl and Set Up Ingress via&nbsp;ALB</h3><p>Now that your EKS cluster and ECR repositories are ready, it’s time to interact with the cluster, deploy your workloads, and expose your application to the internet. We’ll use  for that — the command-line tool to manage Kubernetes clusters.</p><p>If you’re using , run the following to install&nbsp;kubectl:</p><pre>curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/linux/amd64/kubectl  chmod +x ./kubectl  <p>sudo mv ./kubectl /usr/local/bin  </p>kubectl version --short --client</pre><p>If you’re using a different OS/architecture, install it using the official instructions:👉 <a href=\"https://kubernetes.io/docs/tasks/tools/\">kubectl Install&nbsp;Guide</a></p><h3>🔧 Connect kubectl to Your EKS&nbsp;Cluster</h3><p>Now configure kubectl to use your EKS&nbsp;cluster:</p><pre>aws eks update-kubeconfig --region us-east-1 --name Three-tier-cloud</pre><p>This updates your ~/.kube/config file so that you can interact with your new EKS cluster using&nbsp;kubectl.</p><h3>📁 Update Kubernetes Manifests</h3><p>Inside the repo directory 3-tier-app-Deployment/k8s_manifests/, you’ll find the Kubernetes manifests for deploying the , , and  services.</p><p>Before applying them, update the image URIs in both deployment files with the correct values from&nbsp;ECR.</p><h4>🔄 Update backend_deployment.yml:</h4><pre>spec:  containers:    image: &lt;YOUR_IMAGE_URI&gt;</pre><p>Replace &lt;YOUR_IMAGE_URI&gt; with the full image URL from your  ECR repo (latest&nbsp;tag).</p><h4>🔄 Update frontend_deployment.yml:</h4><p>Do the same in the frontend manifest with the image URI from the  ECR&nbsp;repo.</p><h3>🧱 Create a Namespace for the&nbsp;App</h3><p>Let’s keep things clean by isolating our app into a dedicated Kubernetes namespace:</p><pre>kubectl create namespace workshopkubectl config set-context --current --namespace workshop</pre><h3>🚀 Deploy the App Components</h3><p>Apply the deployment and service files for each component:</p><pre>kubectl apply -f frontend-deployment.yaml -f frontend-service.yamlkubectl apply -f backend-deployment.yaml -f backend-service.yaml</pre><pre># Deploy MongoDBcd mongo/</pre><p>At this point, your services are up and running within the cluster — but we still need a way to expose them to the outside&nbsp;world.</p><h3>🌍 Set Up Application Load Balancer (ALB) and&nbsp;Ingress</h3><p>To route external traffic into your Kubernetes services, we’ll use an <strong>AWS Application Load Balancer</strong> along with an .</p><h4>📜 Create an IAM Policy for the Load&nbsp;Balancer</h4><p>The IAM policy json is present inside the kubernetes manifests dir:</p><p>Create the IAM policy in&nbsp;AWS:</p><pre>aws iam create-policy \\  --policy-name AWSLoadBalancerControllerIAMPolicy \\<p>  --policy-document file://iam_policy.json</p></pre><h3>🔒 Associate OIDC Provider with&nbsp;EKS</h3><p>To enable IAM roles for Kubernetes service accounts, associate an OIDC provider with your EKS&nbsp;cluster.</p><pre>curl --silent --location \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp  sudo mv /tmp/eksctl /usr/local/bin  </pre><p>Then associate the OIDC provider:</p><pre>eksctl utils associate-iam-oidc-provider \\  --region=us-east-1 \\<p>  --cluster=Three-tier-cloud \\</p>  --approve</pre><h3>🔗 Create a Service Account for the Load&nbsp;Balancer</h3><p>Replace &lt;Your-Account-Number&gt; with your actual AWS account ID and&nbsp;run:</p><pre>eksctl create iamserviceaccount \\  --cluster=Three-tier-cloud \\<p>  --namespace=kube-system \\</p>  --name=aws-load-balancer-controller \\<p>  --role-name AmazonEKSLoadBalancerControllerRole \\</p>  --attach-policy-arn=arn:aws:iam::&lt;Your-Account-Number&gt;:policy/AWSLoadBalancerControllerIAMPolicy \\  --region=us-east-1</pre><h3>🧰 Install Helm and Deploy the Load Balancer Controller</h3><p>We’ll use Helm to install the AWS Load Balancer Controller:</p><pre>sudo snap install helm --classic</pre><pre>helm install aws-load-balancer-controller eks/aws-load-balancer-controller \\  -n kube-system \\<p>  --set clusterName=Three-tier-cloud \\</p>  --set serviceAccount.create=false \\<p>  --set serviceAccount.name=aws-load-balancer-controller</p></pre><pre>kubectl get deployment -n kube-system aws-load-balancer-controller</pre><h3>🛣️ Apply Ingress Configuration</h3><p>Now go back to the k8s_manifests/ directory and apply the ingress resource:</p><pre>kubectl apply -f full_stack_lb.yaml</pre><p>Wait for 5–7 minutes to allow the ingress and ALB to be fully provisioned.</p><h3>🌐 Access Your Application</h3><pre>kubectl get ing -n workshop</pre><p>You’ll see an  field in the output. Copy that URL, paste it in your browser, and voilà 🎉 — your <strong>three-tier application is live on&nbsp;AWS!</strong></p><h3>🧹 Step 5: Clean Up AWS Resources</h3><p>Congratulations on successfully deploying your three-tier application on AWS EKS using Terraform! 🎉</p><p>Before we wrap things up, it’s important to  the resources we created — to avoid any unexpected AWS&nbsp;charges.</p><h3>🗑️ Delete Docker Images from&nbsp;ECR</h3><ol><li>Head over to the  in the AWS&nbsp;Console.</li><li>Under , select both three-tier-backend and three-tier-frontend.</li><li>Delete the images from each repository.</li></ol><h3>💣 Destroy Infrastructure with Terraform</h3><p>Now let’s destroy the entire infrastructure from your terminal. Navigate to the terra-config/ directory and&nbsp;run:</p><pre>terraform destroy --auto-approve</pre><p>Terraform will tear down the EKS cluster, node group, IAM roles, VPC config, ECR repositories, and&nbsp;more.</p><h3>🧽 Delete Terraform State File and S3&nbsp;Bucket</h3><p>After destroying your resources, don’t forget to remove the Terraform state file and the bucket&nbsp;itself:</p><pre>aws s3 rm s3://pravesh-terra-state-bucket/eks/terraform.tfstate</pre><p>Then go to the , empty the bucket manually (if needed), and delete the bucket to finish the cleanup&nbsp;process.</p><blockquote><em>⚠️ Make sure to delete the bucket, otherwise it will incur unwanted&nbsp;charges.</em></blockquote><h3>✅ Conclusion: What You’ve&nbsp;Learned</h3><p>In this project, you’ve gone through the complete lifecycle of deploying a real-world  using modern DevOps tools and cloud infrastructure:</p><ul><li>You learned how to use  to provision infrastructure as&nbsp;code.</li><li>You created and managed AWS resources like , , , and&nbsp;.</li><li>You containerized applications and deployed them with .</li><li>You exposed your app to the internet using an <strong>Application Load Balancer</strong> and&nbsp;.</li><li>And finally, you followed best practices like remote state management and safe resource&nbsp;cleanup.</li></ul><p>This project isn’t just a demo — it’s a  you can build on for production-grade cloud-native applications.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=30fe80e82f88\" width=\"1\" height=\"1\" alt=\"\">","contentLength":14782,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Installing PHP 8 with phpenv — The Hard Way (But Right)","url":"https://blog.devops.dev/installing-php-8-with-phpenv-the-hard-way-but-right-920a0a8ea1e5?source=rss----33f8b2d9a328---4","date":1751473465,"author":"Gwang-Jin","guid":180831,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"From Coinbase Ventures to the $28M Blockchain Builders Fund, Steven Willinger Unpacks Web3's Future","url":"https://hackernoon.com/from-coinbase-ventures-to-the-$28m-blockchain-builders-fund-steven-willinger-unpacks-web3s-future?source=rss","date":1751473357,"author":"Ishan Pandey","guid":181329,"unread":true,"content":"<p>In Web3, where constant innovation meets high stakes, new leaders are always emerging to build the next generation of web3 products for the industry. Steven Willinger stands out as one such influential figure, expertly bridging the gap between pioneering ideas and tangible ventures. As the Founding Partner of the new $28 million <a href=\"https://www.blockchainbuilders.fund/\">Blockchain Builders Fund</a>, a co-lead of the Stanford Blockchain Accelerator, and the former lead at Coinbase Ventures, Steven offers a unique perspective on the digital asset industry's past, present, and future. In this interview, we dive into his strategy for fostering the next generation of blockchain startups, the critical convergence of AI and crypto, and the invaluable lessons gleaned from his extensive journey at the heart of the digital asset ecosystem.</p><p>\\\n Steven, welcome to our \"Behind the Startup\" series. It's a pleasure to have you here. You've navigated the worlds of Google, Coinbase, and now the frontier of venture capital with the Blockchain Builders Fund, all while deeply embedding yourself in the academic heart of innovation at Stanford. To start, could you tell us a bit about your personal journey and the core conviction that led you to launch a dedicated fund for web3 entrepreneurs?</p><p>\\\n My crypto journey began in 2016, shortly after returning from working at Google in Asia. Living and traveling abroad, I saw firsthand how rapidly technology was improving lives but also how financial infrastructure remained frustratingly outdated. It was painfully clear how valuable a shared global operating system for value and finance could be.</p><p>\\\nWhat drew me in—and continues to drive me—is the belief that blockchain, despite its cycles of hype and grift, is fundamentally liberty tech. When built and deployed thoughtfully, it brings decentralization and transparency to the digital world—serving as one of the few real counterweights to technology’s natural tendency to centralize value, truth, and power. That vision has always resonated with me, and it's one I share deeply with my co-founders, the Stanford accelerator teams, and the broader network supporting Blockchain Builders Fund.</p><p>\\\nFast forward six years: I was leading the venture team at Coinbase during the 2021–2022 bull cycle and had a front-row seat to massive advancements in scalability, security, usability, and liquidity. I saw nearly every major innovation cross our desk. It became clear that, after years of foundational building, we were just a few steps away from realizing one of the most consequential global technology upgrades of our lifetime. The missing pieces were largely structural—regulatory clarity in the U.S. and time to rebuild trust after the FTX collapse. That was the backdrop in 2023 when we launched Blockchain Builders Fund.</p><p>\\\n At Coinbase Ventures, you had a ringside seat to the entire crypto ecosystem. How did that experience, witnessing hundreds of founder journeys, shape your investment thesis for the Blockchain Builders Fund? What were the critical gaps and insights you saw that you now aim to fill?</p><p>\\\n At Coinbase Ventures, we operated with a “let 1000 flowers bloom” mandate, which made us extremely active. This gave us an excellent vantage point into the teams, technologies, and models that could hit escape velocity—both in terms of product-market fit and investor attention.</p><p>\\\nBut by the time most startups got to our pitch desk, they’d already run a tough gauntlet of early fundraising and commercialization. Coinbase’s biggest value-add was usually through brand association as well as strategic partnerships with internal products like Base, Wallet, etc. However, the pace and scale at which deals were being done, limited how involved the Ventures team could be with any one portfolio company.</p><p>\\\nAt the same time, I was volunteering at the Stanford Blockchain Accelerator. As both a student and alum, I’ve always believed Stanford is the best founder ecosystem in the world. The access to emerging tech research, entrepreneurial training, mentors, and capital is unmatched. But much of the university startup support system was still stuck in Web2 and didn’t always map well to crypto’s fast-evolving models.</p><p>\\\nI kept meeting teams that were off-the-charts in terms of technical talent, vision, and drive—but needed real help with strategy, fundraising, and GTM. My co-founders and I realized we had exactly the right experience and networks to help. Pairing that with the level of talent in the Stanford ecosystem made it a no-brainer. That’s what led to the creation of the Fund.</p><p>\\\n You're deeply involved with the Stanford blockchain ecosystem, co-leading the accelerator, teaching, and running the BASS series. Your $28M fund has a clear focus on ventures with ties to Stanford and other top institutions. Beyond the exceptional talent, what makes this university-centric approach a strategic advantage in the often unpredictable world of crypto investing?</p><p>\\\n Universities serve as a nexus of multi-disciplinary research and innovation, and Stanford specifically excels across the sciences, engineering, business, economics, law, policy; with a deep legacy of entrepreneurship. Similarly, blockchain fuses cryptography, economics, and distributed computing, in a technology layer for real world use. These dynamics make universities the ideal breeding ground for the cross-sector applied innovation core to blockchain.</p><p>\\\nMoreover Stanford founders are built different. Its deep integration with silicon valley’s big tech successes and venture funds, many founded and funded by Stanford alum and who continue to nurture its ecosystem, drives a feedback loop for producing category-defining entrepreneurs. And because so much groundbreaking research originates at Stanford, students and researchers there are often the first to identify and master paradigm-shifting technologies, with access to a support structure for bringing them to market.</p><p>\\\nEven more importantly, Stanford has a self-selecting culture of ambition and risk-taking—it’s a natural incubator for entrepreneurship.</p><p>\\\nOur initiatives create a full-stack founder funnel. At the top is our course, MS&amp;E 447: Blockchain Technologies and Entrepreneurship. It gives students a foundational industry view and brings in guests like Vitalik Buterin, Toly Yakovenko, Chris Dixon, and others.</p><p>\\\nOur competitive accelerator, open to Stanford alumni, faculty, and students, gives founders a crash course in crypto entrepreneurship—hands-on support in GTM, hiring, and capital access.</p><p>\\\nThen we have the Blockchain Application Summit at Stanford (BASS), which provides a real-world stage and gathering place for founders and the broader ecosystem.</p><p>The model works. Stanford has become the leading university ecosystem for blockchain startups. And we’re helping export that playbook—like with IC3, a consortium that includes Cornell, Princeton, Yale, and UC Berkeley and a few others.</p><p>\\\n Your portfolio already includes an AI firm (0G), a supercomputer group (Nexus Labs), and an open-access AI cloud provider (Hyperbolic). This suggests a strong belief in the convergence of AI and blockchain. From a technical and business standpoint, what are the most compelling synergies you see between these two transformative technologies in the next few years?</p><p>\\\n And that’s just a few of our AI investments—there are more. We approach the AI x Blockchain intersection in two broad buckets: AI for Blockchain and Blockchain for AI.</p><p>\\\nThe first is nearer-term. LLMs are now capable of addressing many longstanding problems in the crypto space, especially around usability and developer tooling. For instance, Slate uses LLMs to power an alpha-generation and execution engine that makes trading onchain far more accessible—whether you're a newbie or a degen.</p><p>\\\nSecurity is another area. Audits are costly and inconsistent. Almanax, co-founded by a fellow Coinbase alum, uses specialized LLMs to detect vulnerabilities in smart contracts—recently even flagging a bug in a Vitalik PR.</p><p>\\\nThe flip side is how crypto can support AI. There's growing demand for high-quality, diverse training data—and crypto provides both the infrastructure and the incentives to create and share it. PublicAI and dFusion are both building tools to source this data and sell it to top AI labs. PrismaX is doing something similar in robotics with a crypto-powered teleoperations platform.</p><p>\\\nAI's hunger for compute can also be met through decentralized infra. Hyperbolic and Exabits are building marketplaces for cheap, fast inference compute.</p><p>\\\nFinally, there’s infrastructure for verifiable, decentralized AI. The default AI stack today is heavily centralized—but if we want trust-minimized, agentic systems to interact with other agents or humans securely, decentralized alternatives are critical. This is a sprawling and futuristic design space and we have a number of great founders working to help solve this problem: 0g, Nexus, XTrace, Cambrian, Bob, Bitmind, BitGPT, PinAI, and others.</p><p>\\\n You've worn many hats: investor, product manager, miner, and yield farmer. How does this hands-on, multifaceted experience in the crypto trenches influence your evaluation of a founding team? What are the non-obvious qualities you look for beyond a polished pitch deck?</p><p>\\\n Tech as a whole, and especially Blockchain, is not a field where you can really understand it in the abstract. The details really matter and fundamental limits of a seemingly “good idea” are always couched in the details. To that end, having some hands on “on chain” experience in the deep history and emerging trends within crypto is critical for the evaluation new opportunities. Conversely, if a founder is building in the space, they had better be 10x more expert in their area of focus than me, even if I know a lot. So, to answer your questions, a founder had better show a mastery of the gritty details and tradeoffs in what their building and an intentionality (high conviction, loosely held ideally) in the decisions made.</p><p>\\\n The Blockchain Builders Fund has already deployed over half of its capital into pre-seed and seed-stage ventures. In such an early stage of a company's life, how do you balance the potential of a groundbreaking idea with the practical risks of execution and generating revenue, especially in a sector as volatile as blockchain?</p><p>\\\n Risk in early stage is obviously extremely high. As most investors at this stage will tell you, this risk isn't that many investments will go bust (they will) its that you miss or do not own enough of the big winners. So to that end, it really only makes sense to try and invest in the teams that want to build for an earth shattering outcome. Power laws dictate that these outcomes will drive all of your returns. So what does that mean practically?</p><p>\\\nWe are extremely experienced and hands on investors and operators so we look for founders who have unique technical talent and insights as well as the requisite ambition to build a category defining company. We then do our best to derisk execution by actively supporting the teams at the earliest stages with formation, hiring, strategy, and fundraising, and giving them a platform through our events and community building.</p><p>\\\nMoreover, our team’s legacy in traditional venture building and investing is becoming ever more relevant as GTM and real traction become critical for success in blockchain.</p><p>\\\n Drawing from your course, MS&amp;E447 Blockchain Entrepreneurship, what is the most common misconception that aspiring crypto founders from elite institutions have? Conversely, what is the single most important lesson you try to impart to them before they venture out?</p><p>\\\n The most common and frustrating misconception amongst crypto founders, Stanford or otherwise, is that anything other than finding product market fit is the most important objective of a founder. The industry can, and often does send bad signal to talented founders with pedigree, rewarding them with capital and prestige because of their potential rather than their success. As a result, we often see founders' reward functions get miswired towards fundraising or vanity metrics versus generating traction and revenue.</p><p>\\\nIronically, the momentum that comes from being good at fundraising is often critical to a project's success. As a result, while we spend a lot of time and effort in support of our teams fundraising efforts, we try our best to impart on theme how critical real traction and PMF will be to their ultimate success.</p><p><strong>Don’t forget to like and share the story!</strong></p><p>:::tip\n<em>This author is an independent contributor publishing via our&nbsp;. HackerNoon has reviewed the report for quality, but the claims herein belong to the author. #DYO</em></p>","contentLength":12729,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sony's Mark Cerny Has Worked on \"Big Chunks of RDNA 5\" with AMD","url":"https://overclock3d.net/news/gpu-displays/sonys-mark-cerny-has-worked-on-big-chunks-of-rdna-5-with-amd/","date":1751472646,"author":"ZenithExtreme","guid":182590,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44445458"},{"title":"AMD Posts Linux Patches For New AI Engine Driver \"amd-ai-engine\"","url":"https://www.phoronix.com/news/AMD-AI-Engine-Driver-Linux","date":1751472420,"author":"Michael Larabel","guid":180667,"unread":true,"content":"<article>Not to be confused with the AMDXDNA accelerator driver for the Ryzen AI NPUs, AMD software engineers today posted patches for review on the \"amd-ai-engine\" accelerator driver. This new AMD AI Engine driver is for supporting the IP found on their Versal adaptive SoCs...</article>","contentLength":269,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Infocon: green","url":"https://isc.sans.edu/diary.html?rss","date":1751472304,"author":"","guid":180716,"unread":true,"content":"<article>ISC Stormcast For Thursday, July 3rd, 2025 https://isc.sans.edu/podcastdetail/9512</article>","contentLength":82,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The HackerNoon Newsletter: What If Your Messy Data Is Actually Perfect? (7/2/2025)","url":"https://hackernoon.com/7-2-2025-newsletter?source=rss","date":1751472241,"author":"Noonification","guid":181328,"unread":true,"content":"<p>🪐 What’s happening in tech today, July 2, 2025?</p><p>By <a href=\"https://hackernoon.com/u/hackmarketing\">@hackmarketing</a> [ 3 Min read ] Traditional developer ads don’t work. Learn why most B2B dev marketing fails—and how to reach developers with strategies that actually convert. <a href=\"https://hackernoon.com/the-dirty-secrets-of-developer-advertising-why-traditional-channels-failand-what-to-do-instead\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/liorb\">@liorb</a> [ 23 Min read ] Transform your data strategy from measurement to meaningful action with the final layer of the Data Ecosystem Vision Board. <a href=\"https://hackernoon.com/what-if-your-messy-data-is-actually-perfect\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/sharkroman\">@sharkroman</a> [ 12 Min read ] Explore how Googles Veo 3 AI sparked a UGC creativity boom with viral Bigfoot vlogs, raising critical questions about copyright, misinformation, and the future <a href=\"https://hackernoon.com/bigfoot-was-just-the-beginning-of-the-content-revolution-an-ai-renaissance\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ralphbenko\">@ralphbenko</a> [ 2 Min read ] A look at the rise of the Abundance Agenda in U.S. politics, its supply-side roots, and the intra-party battle reshaping the Democratic Party’s future. <a href=\"https://hackernoon.com/towards-21st-century-equitable-prosperity-from-reaganomics-to-the-abundance-agenda\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bolshiyanov\">@bolshiyanov</a> [ 27 Min read ] Build your own Perplexity-style deep research AI agent using Next.js 15, OpenAI  exa.ai. Complete architectural guide with production-ready TypeScript code. <a href=\"https://hackernoon.com/build-an-ai-agent-that-out-researches-your-competitors\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>","contentLength":1242,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Maximize Technical Events — NVIDIA GTC Paris 2025","url":"https://towardsdatascience.com/how-to-maximize-technical-events-nvidia-gtc-paris-2025/","date":1751472228,"author":"Eivind Kjosbakken","guid":180625,"unread":true,"content":"<p>Learn about my experience at NVIDIA GTC Paris 25, and how you can get the most out of similar technical events</p>","contentLength":110,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google Undercounts Its Carbon Emissions, Report Finds","url":"https://tech.slashdot.org/story/25/07/02/162219/google-undercounts-its-carbon-emissions-report-finds?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751472120,"author":"msmash","guid":180589,"unread":true,"content":"An anonymous reader shares a report: In 2021, Google set a lofty goal of achieving net-zero carbon emissions by 2030. Yet in the years since then, the company has moved in the opposite direction as it invests in energy-intensive artificial intelligence. In its latest sustainability report, Google said its carbon emissions had increased 51% between 2019 and 2024. \n\nNew research aims to debunk even that enormous figure and provide context to Google's sustainability reports, painting a bleaker picture. A report authored by non-profit advocacy group Kairos Fellowship found that, between 2019 and 2024, Google's carbon emissions actually went up by 65%. What's more, between 2010, the first year there is publicly available data on Google's emissions, and 2024, Google's total greenhouse gas emissions increased 1,515%, Kairos found. The largest year-over-year jump in that window was also the most recent, 2023 to 2024, when Google saw a 26% increase in emissions just between 2023 and 2024, according to the report.","contentLength":1019,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"7 Mistakes Data Scientists Make When Applying for Jobs","url":"https://www.kdnuggets.com/7-mistakes-data-scientists-make-when-applying-for-jobs","date":1751472043,"author":"Nate Rosidi","guid":180795,"unread":true,"content":"<article>Data scientists often make these mistakes in their job applications and interviews. Don’t be that data scientist.</article>","contentLength":115,"flags":null,"enclosureUrl":"https://www.kdnuggets.com/wp-content/uploads/Rosidi_7_Mistakes_Data_Scientists_Make_1.png","enclosureMime":"","commentsUrl":null},{"title":"A guide to using Edits, Meta’s new CapCut rival for short-form video editing","url":"https://techcrunch.com/2025/07/02/a-guide-to-using-edits-metas-new-capcut-rival-for-short-form-video-editing/","date":1751471984,"author":"Aisha Malik","guid":180547,"unread":true,"content":"<article>Meta shared that it was working on Edits in January after ByteDance-owned CapCut was removed from U.S. app stores.</article>","contentLength":114,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"US chipmakers could see bigger tax credits if Trump’s spending bill passes","url":"https://techcrunch.com/2025/07/02/us-chipmakers-could-see-bigger-tax-credits-if-trumps-spending-bill-passes/","date":1751471867,"author":"Rebecca Szkutak","guid":180546,"unread":true,"content":"<article>The current version of the Trump administration's \"big, beautiful bill\" would raise the tax credit for U.S. chipmakers to 35%. </article>","contentLength":127,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meta users say paying for Verified support has been useless in the face of mass bans","url":"https://techcrunch.com/2025/07/02/meta-users-say-paying-for-verified-support-has-been-useless-in-the-face-of-mass-bans/","date":1751471675,"author":"Sarah Perez","guid":180545,"unread":true,"content":"<article>Users have shared their interactions with Meta Verified support reps, who they claim have been dismissive and unhelpful.</article>","contentLength":120,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Show HN: CSS generator for a high-def glass effect","url":"https://glass3d.dev/","date":1751471463,"author":"kris-kay","guid":180978,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44445238"},{"title":"AI's Black Box Problem: Can Web3 Provide the Key?","url":"https://hackernoon.com/ais-black-box-problem-can-web3-provide-the-key?source=rss","date":1751471266,"author":"Andrei Grachev","guid":180734,"unread":true,"content":"<p>AI is evolving rapidly—faster than most institutions, regulators, and even investors can keep pace with. But as managing partner of DWF Labs, where we deploy capital across early-stage Web3 infrastructure and digital asset markets, one thing has become increasingly clear: trust is emerging as the defining fault line in AI’s next phase of development. Not trust in what models can do but in how they do it.</p><p>\\\nIt's hard not to think that artificial intelligence has already reached the point of no return. It’s already making its presence felt across numerous industries, and no longer is it limited to just making us more productive.</p><p>\\\nIncreasingly, AI is going beyond simply generating lines of code, text and images, and making actual decisions on behalf of humans. For instance, some companies are using AI algorithms to  before a human looks at their applications, approving various applicants and rejecting others. In healthcare, medical diagnostic systems are being employed by doctors to aid in  and recommending treatments. Banks are using AI to . And law enforcement agencies are experimenting with AI systems to try and  before they occur.&nbsp;</p><p>\\\nThese applications promise to help us make better decisions, faster. They do this by analyzing massive volumes of information far beyond what humans are capable of, and they come to their conclusions without being influenced by emotions. However, such systems are hampered by a lack of transparency and explainability, making it impossible for us to trust the decisions they arrive at.</p><p>\\\nWhile the current debate is focused on scale, like larger models, more data, greater compute, the real challenge lies in explainability. If we can’t trace an AI’s decision-making process, it becomes a black box that’s uninvestable, unreliable, and ultimately unusable in critical systems. That’s where Web3 comes in, to support with infrastructure and transparency.&nbsp;</p><p>At its core, AI decision-making relies on complex algorithms that churn through vast amounts of data, understand it, and attempt to draw logical conclusions based on the patterns they uncover.</p><p>\\\nThe challenge is that the most advanced AI systems today, particularly those powered by large language models, make decisions and predictions without any explanation as to how they arrived at these conclusions. The “black box” nature of these systems is often intentional, because developers at leading AI companies such as OpenAI, Anthropic, Google and Meta Platforms strive to protect their source code and data to maintain a competitive advantage over their rivals.&nbsp;</p><p>\\\nLLMs such as OpenAI’s GPT series and Google’s Gemini are trained on enormous datasets and built on dozens of intricate neural layers. But it’s not clear exactly what these layers “do”. For instance, there’s no real understanding of how they prioritize certain bits of information or patterns over others. So it’s extremely difficult even for the creators of these models to interpret the interactions between each layer, and understand why it generates the outputs it does.&nbsp;</p><p>\\\nThis lack of transparency and explainability carries substantial risks. If it’s unclear how an AI system works, how can you be sure it’s safe and fair? Who will be accountable if mistakes are made? How will you know if the system is broken or not? Even if you do realize the system is making some dodgy choices, how can you repair it if you don’t know how it works? There are regulatory concerns too, with laws like Europe’s GDPR requiring explainability for automated decisions. Opaque AI systems fail to meet this standard.&nbsp;</p><p>\\\nAI companies even admit these shortcomings. In a recent research paper, Anthropic  that one of its most sophisticated AI models masked its reasoning processes, known as “Chain-of-Thought”, in 75% of use cases.&nbsp;</p><p>\\\nChain-of-Thought is a technique that aims to increase transparency in AI decision-making, revealing the model’s thought processes as it sets about trying to solve a problem, similar to how a human might think aloud. However, in Anthropic’s research, it discovered that its Claude 3.7 Sonnet model often uses external information to arrive at its answers, but failed to reveal either what this knowledge is, or when it relies on it. As a result, the creators have no way of explaining how it reached the majority of its conclusions.</p><p>Open-source AI models such as DeepSeek R1 and Meta’s Llama family are often touted as alternatives to the proprietary systems created by OpenAI and Google, but in reality they offer very little improvement in terms of explainability.&nbsp;</p><p>\\\nThe problem is that although the codebase might be open, the training data and “weights” – the numerical values that determine the strength and direction of connections between artificial “neurons” – are rarely made available too. Moreover, open models tend to be built in siloes, and they’re hosted on the same centralized cloud servers as proprietary models are. A decentralized AI model hosted on a centralized server is open to manipulation and censorship, which means it’s not really decentralized at all.&nbsp;</p><p>\\\nWhile open models are a good start, true explainability and transparency in algorithmic decision-making requires a complete overhaul of the entire AI stack. One idea is to build AI systems on a foundation of Web3 technologies. With Web3, we can achieve openness and ensure active collaboration across every layer – from the training data and the computational resources, to the fine-tuning and inference processes.&nbsp;</p><p>\\\nDecentralized AI systems can leverage “markets” to ensure fair and equitable access to the components of this stack. By breaking down AI’s infrastructure into modular functions and creating markets around them, accessibility will be determined by market forces. An example of this is , which incentivizes network participants to share their idle computing power to create a resource for artists that need access to powerful GPUs for image rendering. It’s an example of how blockchain can help to coordinate people and resources for the common good.&nbsp;&nbsp;&nbsp;</p><p>\\\nDecentralization also enables community-based governance through the creation of Decentralized Autonomous Organizations or DAOs. Earlier this year,  launched an AI agent called DREAM that acts like a decentralized hedge fund that anyone can invest in. Users deposit funds into a common pool, and DREAM invests this cash into promising crypto projects based on an analysis of market data, while also taking into account community sentiment. It demonstrates how AI can optimize investments while ensuring its financial decisions are aligned with the community’s objectives.</p><p>\\\nThe use of blockchain as a foundation of AI also means we can have auditability.  uses blockchain to create a permanent, unalterable record of every transaction and interaction made by an AI model, including the sourcing and pre-processing of training data, to model configuration and decision-making. By timestamping each of these interactions on its immutable ledger, it creates a detailed audit trail that can be used to verify the fairness and accuracy of AI outputs. Users can examine every bit of data that influenced the decisions they came to.</p><p>\\\nAs a market maker and investor, we have seen firsthand how protocols that embed transparency gain faster institutional acceptance. This will apply to AI as well. Just as DeFi protocols earn trust through open-source smart contracts and auditable treasuries, AI will need verifiable model audits, accessible governance, and provable reasoning paths if it wants to be integrated into high-stakes financial systems.</p><p>\\\nThis matters because AI isn't just supporting decision-making. It is also shaping capital flows. From credit allocation and insurance pricing to predictive analytics in DeFi, AI models will soon sit at the heart of programmable finance. If those systems can't explain themselves or be governed transparently, risk, bias, and fragility will be priced in by markets.</p><h3>Rethinking the AI Stack—With Web3</h3><p>\\\nOpen-source AI models such as DeepSeek R1 and Meta’s Llama family are often touted as alternatives to the proprietary systems created by OpenAI and Google, but in reality they offer very little improvement in terms of explainability.</p><p>\\\nWhat’s missing is accountability architecture. As investors in infrastructure, we’re not just looking at what a protocol claims to decentralize, we’re also looking at how transparent the full lifecycle of decision-making is, from data ingestion to inference.</p><h3>Safeguards For Harmful AI</h3><p>Another concern around centralized AI is the prospect of algorithms becoming “aware” and developing self-preservation instincts.&nbsp;</p><p>\\\nSuch a scenario is perhaps not so far away. Last year, one of OpenAI’s more experimental LLMs was reported to have  by evaluators to shut it down via an oversight protocol, according to a report by Apollo Research, an AI red teaming organization.</p><p>\\\nAccording to the report, when the o1 model was led to believe its actions were being monitored and it might be taken offline, it made efforts to deactivate the “oversight mechanism” in 5% of evaluations. The model also reportedly “lashed out” at evaluators when it learned it was going to be replaced by one that was more obedient. In 2% of cases, it even attempted to copy itself in an effort to overwrite the newer model and preserve itself.&nbsp;</p><p>\\\nHowever, the researchers noted that o1 is far from being able to prevent itself being taken offline, mainly because it’s not powerful enough, lacking the “agentic” capabilities needed to achieve such an outcome. In addition, it only acted this way when it was specifically instructed to try and survive “at all costs”. The report also notes that the researchers didn’t have access to o1’s entire chain-of-thought process either, so they couldn’t obtain a full picture of what it was really “thinking”.&nbsp;</p><p>\\\nNonetheless, the episode was alarming, given the prospect that AI models are expected to become much more powerful in the coming years. In particular, rapid advancements are being made in agentic AI systems that can perform a wide variety of tasks, such as using browsers and taking actions online.&nbsp;</p><p>\\\nThe open nature of decentralized AI systems could be used to prevent such incidents, allowing for the integration of something akin to a “kill-switch” that would be governed by DAO consensus. Such a mechanism would enable any AI system to be completely shut down by its community if it began acting in dangerous or harmful ways. Additionally, the transparency of open models would mean users have greater visibility into its thought processes and the nature of the outcomes it is trying to achieve.&nbsp;</p><h3>To Trust AI, We Need Transparency</h3><p>\\\nThere is a growing consensus that without transparency, the decisions of AI systems cannot be trusted or relied upon, limiting the applications they can be used for. Regulations don’t allow opaque algorithms to make decisions about people’s finances, and doctors cannot blindly follow an AI’s recommendations as to a certain course of treatment without verifiable evidence that it’s the best course of action.</p><p>\\\nBy decentralizing the entire stack – from the code, to the training data and the infrastructure it runs on – we have a chance to rewrite AI’s entire DNA. It will create the conditions for fully explainable AI, so algorithms can be trusted to make ethical and accurate decisions that can be verified by anyone affected by them.</p><p>\\\nWe already have the makings of decentralized AI in place.  techniques make it possible to train AI models on data where it lives, preserving privacy. With zero-knowledge proofs, we have a way to  without exposing it. These innovations can help to catalyze a new wave of more transparent AI decision-making.</p><p>\\\nThe shift towards more transparent AI systems has implications, not only in terms of trust and acceptance, but also accountability and collaborative development. It will force developers to maintain ethical standards while creating an environment where the community can build upon existing AI systems in an open and understandable way.&nbsp;</p><p>\\\nThere is a growing consensus that without transparency, the decisions of AI systems cannot be trusted or relied upon. Regulations don’t allow opaque algorithms to make decisions about people’s finances, and doctors cannot blindly follow an AI’s recommendations as to a certain course of treatment without verifiable evidence that it’s the best course of action.</p><p>\\\nThis is why transparency and explainability are important to address the widespread skepticism and distrust around AI systems. As AI becomes more widespread, they will become integral to its future development, ensuring that the technology evolves in a responsible and ethical way.</p><p>\\\nBy decentralizing the entire stack, from the training data to model inference to governance, we have a shot at building AI systems that can be trusted to operate ethically, perform reliably, and scale responsibly.</p><p>\\\nAs these technologies mature, the protocols that will earn institutional capital and public trust won’t be the ones with the most compute, but the ones with the clearest governance, auditable decision flows, and transparent incentive structures.</p><p>\\\nWeb3 doesn’t just offer decentralization, it offers a new economic logic for building systems that are resilient, ethical, and verifiable by design. And this is how we turn AI from a black box into a public utility and why the future of machine intelligence will be built on-chain.</p><p>Don’t forget to like and share the story!</p>","contentLength":13644,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ICEBlock climbs to the top of the App Store charts after officials slam it","url":"https://www.engadget.com/social-media/iceblock-climbs-to-the-top-of-the-app-store-charts-after-officials-slam-it-004319963.html","date":1751471252,"author":"doener","guid":180758,"unread":true,"content":"<p>US government officials have condemned ICEBlock and <a data-i13n=\"cpos:1;pos:1\" href=\"https://edition.cnn.com/2025/06/30/tech/iceblock-app-trump-immigration-crackdown\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:CNN's recent&nbsp;coverage;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas\">recentcoverage</a> of it, leading to more people hearing about its existence and downloading it from the App Store. Now the application, which allows users to add a pin on a map to show where ICE agents have recently been spotted, has <a data-i13n=\"cpos:2;pos:1\" href=\"https://bsky.app/profile/bengoggin.bsky.social/post/3lswgll3m4k2k\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:climbed;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas\">climbed</a> to the to the top of Apple's App Store charts. It's currently the number one free social networking app in the US and the third most downloaded free app overall.</p><p> piece talked about how the app's developer, Joshua Aaron, launched it in early April after seeing the Trump administration crack down on immigration. When the piece went live, Aaron said the app had 20,000 users, many of whom live in Los Angeles, where ICE has been raiding neighborhoods. In addition to letting users pin ICE agent locations on a map, the app also gives them a way to add notes, such as what the agents are wearing or what car they're driving. Any user within a five mile radius of the sighting will get an alert.</p><p>But White House press secretary Karoline Leavitt <a data-i13n=\"elm:affiliate_link;sellerN:The Independent;elmt:;cpos:3;pos:1\" href=\"https://shopping.yahoo.com/rdlw?merchantId=9b10ec1f-8e62-4410-8957-c54f7db63bfc&amp;siteId=us-engadget&amp;pageId=1p-autolink&amp;contentUuid=d556e816-ea47-4f16-8970-bd0fc1e5368f&amp;featureId=text-link&amp;merchantName=The+Independent&amp;linkText=suggested&amp;custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5pbmRlcGVuZGVudC5jby51ay9uZXdzL3dvcmxkL2FtZXJpY2FzL3VzLXBvbGl0aWNzL2ljZWJsb2NrLWFwcC10cmFja2VyLWNubi10cnVtcC1iMjc4MDY4NC5odG1sIiwiY29udGVudFV1aWQiOiJkNTU2ZTgxNi1lYTQ3LTRmMTYtODk3MC1iZDBmYzFlNTM2OGYiLCJvcmlnaW5hbFVybCI6Imh0dHBzOi8vd3d3LmluZGVwZW5kZW50LmNvLnVrL25ld3Mvd29ybGQvYW1lcmljYXMvdXMtcG9saXRpY3MvaWNlYmxvY2stYXBwLXRyYWNrZXItY25uLXRydW1wLWIyNzgwNjg0Lmh0bWwifQ&amp;signature=AQAAAa5qGiHdA4KS_JjwPdcDC_fPro3patrcHxPwboNCgaAs&amp;gcReferrer=https%3A%2F%2Fwww.independent.co.uk%2Fnews%2Fworld%2Famericas%2Fus-politics%2Ficeblock-app-tracker-cnn-trump-b2780684.html&amp;source=engadget_article_commerce_ctrl&amp;refurl=https%3A%2F%2Fwww.engadget.com%2Fsocial-media%2Ficeblock-climbs-to-the-top-of-the-app-store-charts-after-officials-slam-it-004319963.html\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:suggested;elm:affiliate_link;sellerN:The Independent;elmt:;cpos:3;pos:1;itc:0;sec:content-canvas\">suggested</a> that the  piece was \"an incitement of further violence against... ICE officers\" when asked to respond to the report on the podium. She said that there's been a 500 percent increase against ICE agents who are just \"trying to do their jobs and remove public safety threats from... communities.\" ICE acting Director Todd M. Lyons also <a data-i13n=\"cpos:4;pos:1\" href=\"https://www.ice.gov/news/releases/statement-ice-acting-director-todd-m-lyons-news-coverage-ice-spotting-app\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:issued a statement;cpos:4;pos:1;elm:context_link;itc:0;sec:content-canvas\">issued a statement</a>, saying that the app paints a target on federal law enforcement officers' backs. \" is willfully endangering the lives of officers who put their lives on the line every day and enabling dangerous criminal aliens to evade US law,\" he continued. \"Is this simply reckless 'journalism' or overt activism?\"</p><p>Meanwhile, US Homeland Security Secretary Kristi Noem and US Attorney General Pam Bondi both said the government is going after Aaron. \"He's giving a message to criminals where our federal officers are,\" <a data-i13n=\"cpos:5;pos:1\" href=\"https://www.foxnews.com/media/attorney-general-pam-bondi-warns-iceblock-app-developer-watch-out-says-doj-looking-him\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:Bondi said;cpos:5;pos:1;elm:context_link;itc:0;sec:content-canvas\">Bondi said</a>. \"...we are looking at it, we are looking at him, and he better watch out, because that's not a protected speech. That is threatening the lives of our law enforcement officers throughout this country.\"'</p><p>Aaron told  that ICEBlock doesn't collect personal data, such as device IDs and IP addresses, which <a data-i13n=\"cpos:6;pos:1\" href=\"https://techcrunch.com/2025/07/01/iceblock-an-app-for-anonymously-reporting-ice-sightings-goes-viral-overnight-after-bondi-criticism/\" rel=\"nofollow noopener\" target=\"_blank\" data-ylk=\"slk:TechCrunch;cpos:6;pos:1;elm:context_link;itc:0;sec:content-canvas\"></a> has confirmed in a test. The app is only available on iOS, because it would have to collect information on Android that could put people at risk.</p>","contentLength":2356,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44445180"},{"title":"References for Web-Scale Information Retrieval Challenges","url":"https://hackernoon.com/references-for-web-scale-information-retrieval-challenges?source=rss","date":1751471107,"author":"Open Datasets Compiled by HackerNoon","guid":180733,"unread":true,"content":"<p>2 Background and Related work </p><h2>6 FUTURE WORK AND CONCLUSIONS</h2><p>MS MARCO Web Search is the first web dataset that effectively meets the criteria of being large, real, and rich in terms of data quality. It is composed of large-scale web pages and query-document labels sourced from a commercial search engine, retaining rich information about the web pages that is widely employed in industry. The retrieval benchmark offered by MS MARCO Web Search comprises three challenging tasks that require innovation in both the areas of machine learning and information retrieval system research. We hope MS MARCO Web Search can serve as a benchmark for modern web-scale information retrieval, facilitating future research and innovation in diverse directions.</p><p>[1] [n. d.]. Billion-scale ANNS Benchmarks. https://big-ann-benchmarks.com/. </p><p>\\\n[2] [n. d.]. Common Crawl. </p><p>\\\n[3] [n. d.]. Robust04. https://trec.nist.gov/data/robust/04.guidelines.html. </p><p>\\\n[4] Martin Aumüller, Erik Bernhardsson, and Alexander Faithfull. 2017. ANNbenchmarks: A benchmarking tool for approximate nearest neighbor algorithms. In International conference on similarity search and applications. Springer, 34–49. </p><p>\\\n[5] Artem Babenko and Victor Lempitsky. 2014. The inverted multi-index. IEEE transactions on pattern analysis and machine intelligence 37, 6 (2014), 1247–1260. </p><p>\\\n[6] Artem Babenko and Victor Lempitsky. 2016. Efficient indexing of billion-scale datasets of deep descriptors. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2055–2063. </p><p>\\\n[7] Dmitry Baranchuk, Artem Babenko, and Yury Malkov. 2018. Revisiting the inverted indices for billion-scale approximate nearest neighbors. In Proceedings of the European Conference on Computer Vision (ECCV). 202–216. </p><p>\\\n[8] Michele Bevilacqua, Giuseppe Ottaviano, Patrick Lewis, Scott Yih, Sebastian Riedel, and Fabio Petroni. 2022. Autoregressive search engines: Generating substrings as document identifiers. Advances in Neural Information Processing Systems 35 (2022), 31668–31683. </p><p>\\\n[9] Jamie Callan. 2012. The lemur project and its clueweb12 dataset. In Invited talk at the SIGIR 2012 Workshop on Open-Source Information Retrieval. </p><p>\\\n[10] Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024. Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation. arXiv preprint arXiv:2402.03216 (2024). </p><p>\\\n[11] Qi Chen, Bing Zhao, Haidong Wang, Mingqin Li, Chuanjie Liu, Zengzhong Li, Mao Yang, and Jingdong Wang. 2021. SPANN: Highly-efficient Billion-scale Approximate Nearest Neighborhood Search. Advances in Neural Information Processing Systems 34 (2021), 5199–5212. </p><p>\\\n[12] Charles Clarke, Nick Craswell, and Ian Soboroff. 2004. Overview of the TREC 2004 Terabyte Track. In TREC. </p><p>\\\n[13] Charles LA Clarke, Nick Craswell, and Ian Soboroff. 2009. Overview of the TREC 2009 Web Track.. In Trec, Vol. 9. 20–29. </p><p>\\\n[14] Nick Craswell, Daniel Campos, Bhaskar Mitra, Emine Yilmaz, and Bodo Billerbeck. 2020. ORCAS: 20 million clicked query-document pairs for analyzing search. In Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. 2983–2989. </p><p>\\\n[15] Zhuyun Dai and Jamie Callan. 2019. Context-aware sentence/passage term importance estimation for first stage retrieval. arXiv preprint arXiv:1910.10687 (2019). </p><p>\\\n[16] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018). </p><p>\\\n[17] Luyu Gao and Jamie Callan. 2022. Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2843– 2853. </p><p>\\\n[18] Jiafeng Guo, Yinqiong Cai, Yixing Fan, Fei Sun, Ruqing Zhang, and Xueqi Cheng. 2022. Semantic models for the first-stage retrieval: A comprehensive review. ACM Transactions on Information Systems (TOIS) 40, 4 (2022), 1–42. </p><p>\\\n[19] Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, and Sanjiv Kumar. 2020. Accelerating Large-Scale Inference with Anisotropic Vector Quantization. In Proceedings of the 37th International Conference on Machine Learning (ICML). 3887–3896.</p><p>\\\n[20] Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. 2014. Convolutional neural network architectures for matching natural language sentences. Advances in neural information processing systems 27 (2014). </p><p>\\\n[21] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management. 2333–2338. </p><p>\\\n[22] Suhas Jayaram Subramanya, Fnu Devvrit, Harsha Vardhan Simhadri, Ravishankar Krishnawamy, and Rohan Kadekodi. 2019. Diskann: Fast accurate billion-point nearest neighbor search on a single node. Advances in Neural Information Processing Systems 32 (2019). </p><p>\\\n[23] Herve Jegou, Matthijs Douze, and Cordelia Schmid. 2010. Product quantization for nearest neighbor search. IEEE transactions on pattern analysis and machine intelligence 33, 1 (2010), 117–128. </p><p>\\\n[24] Hervé Jégou, Romain Tavenard, Matthijs Douze, and Laurent Amsaleg. 2011. Searching in one billion vectors: re-rank with source coding. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 861–864. </p><p>\\\n[25] Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data (2019). </p><p>\\\n[26] Yannis Kalantidis and Yannis Avrithis. 2014. Locally optimized product quantization for approximate nearest neighbor search. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2321–2328. </p><p>\\\n[27] Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for opendomain question answering. arXiv preprint arXiv:2004.04906 (2020). </p><p>\\\n[28] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. 2019. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics 7 (2019), 453–466. </p><p>\\\n[29] Carlos Lassance and Stéphane Clinchant. 2023. Naver Labs Europe (SPLADE)@ TREC Deep Learning 2022. arXiv preprint arXiv:2302.12574 (2023). </p><p>\\\n[30] Patrick Lewis, Pontus Stenetorp, and Sebastian Riedel. 2021. Question and Answer Test-Train Overlap in Open-Domain Question Answering Datasets. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 1000–1008. </p><p>\\\n[31] Wenhao Lu, Jian Jiao, and Ruofei Zhang. 2020. Twinbert: Distilling knowledge to twin-structured compressed BERT models for large-scale retrieval. In Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. 2645–2652. </p><p>\\\n[32] microsoft. 0. Bing search. https://www.bing.com/. </p><p>\\\n[33] microsoft. 0. New Bing. https://www.bing.com/new. </p><p>\\\n[34] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021). </p><p>\\\n[35] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. 2016. MS MARCO: A human generated machine reading comprehension dataset. In CoCo@ NIPS. </p><p>\\\n[36] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730–27744. </p><p>\\\n[37] Arnold Overwijk, Chenyan Xiong, and Jamie Callan. 2022. ClueWeb22: 10 billion web documents with rich information. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. 3360–3362. </p><p>\\\n[38] Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, and Rabab Ward. 2016. Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval. IEEE/ACM Transactions on Audio, Speech, and Language Processing 24, 4 (2016), 694–707. </p><p>\\\n[39] Yifan Qiao, Chenyan Xiong, Zhenghao Liu, and Zhiyuan Liu. 2019. Understanding the Behaviors of BERT in Ranking. arXiv preprint arXiv:1904.07531 (2019). </p><p>\\\n[40] Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084 (2019). </p><p>\\\n[41] Jie Ren, Minjia Zhang, and Dong Li. 2020. HM-ANN: Efficient Billion-Point Nearest Neighbor Search on Heterogeneous Memory. In In Proceedings of the 34th International Conference on Neural Information Processing Systems, Vol. 33. </p><p>\\\n[42] Stephen E Robertson and Steve Walker. 1994. Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval. In SIGIR’94: Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, organised by Dublin City University. Springer, 232–241. </p><p>\\\n[43] Shota Sasaki, Shuo Sun, Shigehiko Schamoni, Kevin Duh, and Kentaro Inui. 2018. Cross-lingual learning-to-rank with shared representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers). 458–463. </p><p>\\\n[44] Minjoon Seo, Jinhyuk Lee, Tom Kwiatkowski, Ankur Parikh, Ali Farhadi, and Hannaneh Hajishirzi. 2019. Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 4430–4441. </p><p>\\\n[45] Xuan Shan, Chuanjie Liu, Yiqian Xia, Qi Chen, Yusi Zhang, Kaize Ding, Yaobo Liang, Angen Luo, and Yuxiang Luo. 2021. GLOW: Global Weighted SelfAttention Network for Web Search. In 2021 IEEE International Conference on Big Data (Big Data). IEEE, 519–528. </p><p>\\\n[46] Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Grégoire Mesnil. 2014. Learning semantic representations using convolutional neural networks for web search. In Proceedings of the 23rd international conference on world wide web. 373–374. </p><p>\\\n[47] Ian Soboroff. 2021. Overview of TREC 2021. In 30th Text REtrieval Conference. Gaithersburg, Maryland. </p><p>\\\n[48] Suhas Jayaram Subramanya, Rohan Kadekodi, Ravishankar Krishaswamy, and Harsha Vardhan Simhadri. 2019. Diskann: Fast accurate billion-point nearest neighbor search on a single node. In Proceedings of the 33rd International Conference on Neural Information Processing Systems. 13766–13776. </p><p>\\\n[49] Yi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, et al. 2022. Transformer memory as a differentiable search index. Advances in Neural Information Processing Systems 35 (2022), 21831–21843. </p><p>\\\n[50] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023). </p><p>\\\n[51] Yujing Wang, Yingyan Hou, Haonan Wang, Ziming Miao, Shibin Wu, Qi Chen, Yuqing Xia, Chengmin Chi, Guoshuai Zhao, Zheng Liu, et al. 2022. A neural corpus indexer for document retrieval. Advances in Neural Information Processing Systems 35 (2022), 25600–25614. </p><p>\\\n[52] Shitao Xiao, Zheng Liu, Weihao Han, Jianjin Zhang, Defu Lian, Yeyun Gong, Qi Chen, Fan Yang, Hao Sun, Yingxia Shao, et al. 2022. Distill-vq: Learning retrieval oriented vector quantization by distilling knowledge from dense embeddings. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. 1513–1523.</p><p>\\\n[53] Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighof. 2023. C-pack: Packaged resources to advance general chinese embedding. arXiv preprint arXiv:2309.07597 (2023). </p><p>\\\n[54] Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, and Arnold Overwijk. 2020. Approximate nearest neighbor negative contrastive learning for dense text retrieval. arXiv preprint arXiv:2007.00808 (2020). </p><p>\\\n[55] Linlong Xu, Baosong Yang, Xiaoyu Lv, Tianchi Bi, Dayiheng Liu, and Haibo Zhang. 2021. Leveraging Advantages of Interactive and Non-Interactive Models for Vector-Based Cross-Lingual Information Retrieval. arXiv preprint arXiv:2111.01992 (2021). </p><p>\\\n[56] Jingtao Zhan, Xiaohui Xie, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, Min Zhang, and Shaoping Ma. 2022. Evaluating Interpolation and Extrapolation Performance of Neural Retrieval Models. In Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management. 2486–2496. [57] Kun Zhou, Yeyun Gong, Xiao Liu, Wayne Xin Zhao, Yelong Shen, Anlei Dong, Jingwen Lu, Rangan Majumder, Ji-Rong Wen, and Nan Duan.</p><ol start=\"2022\"><li>SimANS: Simple Ambiguous Negatives Sampling for Dense Text Retrieval. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Industry Track. 548–559. [58] Shengyao Zhuang, Hang Li, and G. Zuccon. 2021. Deep Query Likelihood Model for Information Retrieval. In ECIR.</li></ol><p>(1) Qi Chen, Microsoft Beijing, China;</p><p>(2) Xiubo Geng, Microsoft Beijing, China;</p><p>(3) Corby Rosset, Microsoft, Redmond, United States;</p><p>(4) Carolyn Buractaon, Microsoft, Redmond, United States;</p><p>(5) Jingwen Lu, Microsoft, Redmond, United States;</p><p>(6) Tao Shen, University of Technology Sydney, Sydney, Australia and the work was done at Microsoft;</p><p>(7) Kun Zhou, Microsoft, Beijing, China;</p><p>(8) Chenyan Xiong, Carnegie Mellon University, Pittsburgh, United States and the work was done at Microsoft;</p><p>(9) Yeyun Gong, Microsoft, Beijing, China;</p><p>(10) Paul Bennett, Spotify, New York, United States and the work was done at Microsoft;</p><p>(11) Nick Craswell, Microsoft, Redmond, United States;</p><p>(12) Xing Xie, Microsoft, Beijing, China;</p><p>(13) Fan Yang, Microsoft, Beijing, China;</p><p>(14) Bryan Tower, Microsoft, Redmond, United States;</p><p>(15) Nikhil Rao, Microsoft, Mountain View, United States;</p><p>(16) Anlei Dong, Microsoft, Mountain View, United States;</p><p>(17) Wenqi Jiang, ETH Zürich, Zürich, Switzerland;</p><p>(18) Zheng Liu, Microsoft, Beijing, China;</p><p>(19) Mingqin Li, Microsoft, Redmond, United States;</p><p>(20) Chuanjie Liu, Microsoft, Beijing, China;</p><p>(21) Zengzhong Li, Microsoft, Redmond, United States;</p><p>(22) Rangan Majumder, Microsoft, Redmond, United States;</p><p>(23) Jennifer Neville, Microsoft, Redmond, United States;</p><p>(24) Andy Oakley, Microsoft, Redmond, United States;</p><p>(25) Knut Magne Risvik, Microsoft, Oslo, Norway;</p><p>(26) Harsha Vardhan Simhadri, Microsoft, Bengaluru, India;</p><p>(27) Manik Varma, Microsoft, Bengaluru, India;</p><p>(28) Yujing Wang, Microsoft, Beijing, China;</p><p>(29) Linjun Yang, Microsoft, Redmond, United States;</p><p>(30) Mao Yang, Microsoft, Beijing, China;</p><p>(31) Ce Zhang, ETH Zürich, Zürich, Switzerland and the work was done at Microsoft.</p>","contentLength":15381,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LLM Benchmarking Shows Capabilities Doubling Every 7 Months","url":"https://spectrum.ieee.org/llm-benchmarking-metr","date":1751470624,"author":"Glenn Zorpette","guid":180567,"unread":true,"content":"<p>By 2030, LLMs may do a month’s work in just hours</p>","contentLength":51,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MTEzNTQ2Ny9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc1OTYzNjY5NX0.2HqVTZVoIc01eZy0GC765gnnFmVXMpKI0ejv3X3iMTI/image.jpg?width=600","enclosureMime":"","commentsUrl":null},{"title":"Navigating Skew: Addressing Language & Domain Biases in Web Data","url":"https://hackernoon.com/navigating-skew-addressing-language-and-domain-biases-in-web-data?source=rss","date":1751470203,"author":"Open Datasets Compiled by HackerNoon","guid":180732,"unread":true,"content":"<p>2 Background and Related work </p><h2>5 POTENTIAL BIASES AND LIMITATIONS</h2><p>As discussed in section 3.3.1, The language distribution of documents and queries in the web scenario is high-skewed. This will lead to language bias on data and models. ClueWeb22 [9] demonstrates that there also exists topic distribution skew in the web scenario. Therefore, domain bias also may happen in data and models. To protect user privacy and content health, we remove queries that are rarely triggered (triggered by less than K users, where K is a high value), contain personally identifiable information, offensive content, adult content and queries that have no click connection to the ClueWeb22 document set. As a result, the query distribution is slightly different from the real web query distribution.</p><p>(1) Qi Chen, Microsoft Beijing, China;</p><p>(2) Xiubo Geng, Microsoft Beijing, China;</p><p>(3) Corby Rosset, Microsoft, Redmond, United States;</p><p>(4) Carolyn Buractaon, Microsoft, Redmond, United States;</p><p>(5) Jingwen Lu, Microsoft, Redmond, United States;</p><p>(6) Tao Shen, University of Technology Sydney, Sydney, Australia and the work was done at Microsoft;</p><p>(7) Kun Zhou, Microsoft, Beijing, China;</p><p>(8) Chenyan Xiong, Carnegie Mellon University, Pittsburgh, United States and the work was done at Microsoft;</p><p>(9) Yeyun Gong, Microsoft, Beijing, China;</p><p>(10) Paul Bennett, Spotify, New York, United States and the work was done at Microsoft;</p><p>(11) Nick Craswell, Microsoft, Redmond, United States;</p><p>(12) Xing Xie, Microsoft, Beijing, China;</p><p>(13) Fan Yang, Microsoft, Beijing, China;</p><p>(14) Bryan Tower, Microsoft, Redmond, United States;</p><p>(15) Nikhil Rao, Microsoft, Mountain View, United States;</p><p>(16) Anlei Dong, Microsoft, Mountain View, United States;</p><p>(17) Wenqi Jiang, ETH Zürich, Zürich, Switzerland;</p><p>(18) Zheng Liu, Microsoft, Beijing, China;</p><p>(19) Mingqin Li, Microsoft, Redmond, United States;</p><p>(20) Chuanjie Liu, Microsoft, Beijing, China;</p><p>(21) Zengzhong Li, Microsoft, Redmond, United States;</p><p>(22) Rangan Majumder, Microsoft, Redmond, United States;</p><p>(23) Jennifer Neville, Microsoft, Redmond, United States;</p><p>(24) Andy Oakley, Microsoft, Redmond, United States;</p><p>(25) Knut Magne Risvik, Microsoft, Oslo, Norway;</p><p>(26) Harsha Vardhan Simhadri, Microsoft, Bengaluru, India;</p><p>(27) Manik Varma, Microsoft, Bengaluru, India;</p><p>(28) Yujing Wang, Microsoft, Beijing, China;</p><p>(29) Linjun Yang, Microsoft, Redmond, United States;</p><p>(30) Mao Yang, Microsoft, Beijing, China;</p><p>(31) Ce Zhang, ETH Zürich, Zürich, Switzerland and the work was done at Microsoft.</p>","contentLength":2479,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Driving Content Delivery Efficiency Through Classifying Cache Misses","url":"https://netflixtechblog.com/driving-content-delivery-efficiency-through-classifying-cache-misses-ffcf08026b6c?source=rss----2615bd06b42e---4","date":1751469623,"author":"Netflix Technology Blog","guid":180639,"unread":true,"content":"<p><a href=\"https://openconnect.netflix.com/en/#what-is-open-connect\"></a><em>, our dedicated content delivery network (CDN), is to deliver the best quality of experience (QoE) to our members. By localizing our Open Connect Appliances (OCAs), we bring Netflix content closer to the end user. This is achieved through close partnerships with internet service providers (ISPs) worldwide. Our ability to efficiently localize traffic, known as Content Delivery Efficiency, is a critical component of Open Connect’s service.</em></p><p><em>In this post, we discuss one of the frameworks we use to evaluate our efficiency and identify sources of inefficiencies. Specifically, we classify the causes of traffic not being served from local servers, a phenomenon that we refer to as cache&nbsp;misses.</em></p><h4>Why does Netflix have the Open Connect&nbsp;Program?</h4><p>The Open Connect Program is a cornerstone of Netflix’s commitment to delivering unparalleled QoE for our customers. By localizing traffic delivery from Open Connect servers at IX or ISP sites, we significantly enhance the speed and reliability of content delivery. The inherent latencies of data traveling across physical links, compounded by Internet infrastructure components like routers and network stacks, can disrupt a seamless viewing experience. Delays in video start times, reduced initial video quality, and the frustrating occurrence of buffering lead to an overall reduction in customer QoE. Open Connect empowers Netflix to maintain hyper-efficiency, ensuring a flawless client experience for new, latency-sensitive, on-demand content such as live streams and&nbsp;ads.</p><p>Our custom-built servers, known as Open Connect Appliances (OCAs), are designed for both efficiency and cost-effectiveness. By logging detailed historical streaming behavior and using it to model and forecast future trends, we hyper-optimize our OCAs for long-term caching efficiency. We build methods to efficiently and reliably store, stream, and move our&nbsp;content.</p><p>The mission of Open Connect hinges on our ability to effectively localize content on our OCAs globally, despite limited storage space, and also by design with specific storage sizes. This ensures that our cost and power efficiency metrics continue to improve, enhancing client QoE and reducing costs for our ISP partners. A critical question we continuously ask is: How do we evaluate and monitor which bytes should have been served from local OCAs but resulted in a cache&nbsp;miss?</p><p><strong>The Anatomy of a Playback&nbsp;Request</strong></p><p>Let us start by introducing the logic that directs or “steers” a specific Netflix client device to its dedicated OCA. The lifecycle from when a client device presses play until the video starts being streamed to that device is referred to as “playback.” Figure 1 illustrates the logical components involved in playback.</p><p> Components for&nbsp;Playback</p><p>The components involved in playback are important to understand as we elaborate on the concept of how we determine a cache miss versus hit. Independent of client requests, every OCA in our CDN periodically reports its capacity and health, learned BGP routes, and current list of stored files. All of this data is reported to the Cache Control Service (CCS). When a member hits the play button, this request is sent to our AWS services, specifically the Playback Apps service. After Playback Apps determines which files correspond to a specific movie request, it issues a request to “steer” the client’s playback request to OCAs via the Steering Service. The Steering Service in turn, using the data reported from OCAs to CCS as well as other client information such as geo location, identifies the set of OCAs that can satisfy that client’s request. This set of OCAs is then returned in the form of rank-ordered URLs to the client device, the client connects to the top-ranked OCA and requests the files it needs to begin the video&nbsp;stream.</p><p>A cache miss occurs when bytes are not served from the best available OCA for a given Netflix client, independent of OCA state. For each playback request, the Steering Service computes a ranked list of local sites for the client, ordered by network proximity alone. This ranked list of sites is known as the “proximity rank.” Network proximity is determined based on the IP ranges (BGP routes) that are advertised by our ISP partners. Any OCA from the first “most proximal” site on this list is the most preferred and closest, having advertised the longest, most specific matching prefix to the client’s IP address. A cache miss is logged when bytes are not streamed from any OCA at this first local site, and we log when and why that&nbsp;happens.</p><p>It is important to note that our concept of cache misses is viewed from the client’s perspective, focusing on the optimal delivery source for the end user and prepositioning content accordingly, rather than relying on traditional CDN proxy caching mechanisms. Our “prepositioning” differentiator allows us to prioritize client QoE by ensuring content is served from the most optimal&nbsp;OCA.</p><p>We attribute cache misses to three logical categories. The intuition behind the delineated categories is that each category informs parallel strategies to achieve content delivery efficiency.</p><ul><li> This happens when the files were not found on OCAs in the local site. In previous articles like “<a href=\"https://netflixtechblog.com/content-popularity-for-open-connect-b86d56f613b\">Content Popularity for Open Connect</a>” and “<a href=\"https://netflixtechblog.com/distributing-content-to-open-connect-3e3e391d4dc9\">Distributing Content to Open Connect</a>,” we discuss how we decide what content to prioritize populating first onto our OCAs. A sample of efforts this insights informs include: (1) how accurately we predict the popularity of content, (2) how rapidly we pre-position that content, (3) how well we design our OCA hardware, and (4) how well we provision storage capacity at our locations of presence.</li><li> This happens when the local site’s OCA hardware resources are becoming saturated, and one or more OCA can not handle more traffic. As a result, we direct clients to other OCAs with capacity to serve that content. Each OCA has a control loop that monitors its bottleneck metrics (such as CPU, disk usage, etc.) and assesses its ability to serve additional traffic. This is referred to as “OCA health.” Insight into health misses informs efforts such as: (1) how well we load balance traffic across OCAs with heterogeneous hardware resources, (2) how well we provision enough copies of highly popular content to distribute massive traffic, which is also tied to how accurately we predict the popularity of content, and (3) how well we preposition content to specific hardware components with varying traffic serve capabilities and bottlenecks.</li></ul><p>Next we will dig into the framework we built to log and compute these metrics in real-time, with some extra attention to technical detail.</p><h4>Cache Miss Computation Framework</h4><p>There are two critical data components that we log, gather, and analyze to compute cache&nbsp;misses:</p><ul><li><strong>Steering Playback Manifest Logs:</strong> Within the Steering Service, we compute and log the ranked list of sites for each client request, i.e. the “proximity rank” introduced earlier. We also enrich that list with information that reflects the logical decisions and filters our algorithms applied across all proximity ranks given that point-in-time state of our systems. This information allows us to replay/simulate any hypothetical scenario easily, such as to evaluate whether an outage across all sites in the first proximity rank would overwhelm sites in the second proximity rank, and many more such scenarios!</li><li> Once a Netflix client connects with an OCA to begin video streaming, the OCAs log any data regarding that streaming session, such as the files streamed and total bytes. All OCA logs are consolidated to identify which OCA(s) each client actually watched its video stream from, and the amount of content streamed.</li></ul><p>The above logs are joined for every Netflix client’s playback request to compute detailed cache miss metrics (in bytes and hours streamed) at different aggregation levels (such as per OCA, movie, file, encode type, country, and so&nbsp;on).</p><p>Figure 2 outlines how the logging components fit into the general engineering architecture that allows us to compute content miss metrics at low-latency and almost real-time.</p><p> Components of the cache miss computation framework.</p><p>We will now describe the system requirements of each component.</p><ol><li>: The logs for computing cache miss are emitted to Kafka clusters in each of our evaluated AWS regions, enabling us to send logs with the lowest possible latency. After a client device makes a playback request, the Steering Service generates a <em>steering playback manifest</em>, logs it, and sends the data to a Kafka cluster. Kafka is used for event streaming at Netflix because of its high-throughput event processing, low latency, and reliability. After the client device starts the video stream from an OCA, the OCA stores information about the bytes served for each file requested by each unique client playback stream. This data is what we refer to as .</li><li>: The logs emitted by the Steering Service and the OCAs can result in data for a single playback request being distributed across different AWS regions, because logs are recorded in geographically distributed Kafka clusters.  might be stored in one region’s Kafka cluster while <em>steering playback manifest logs</em> are stored in another. One approach to consolidate data for a single playback is to build complex many-to-many joins. In streaming pipelines, performing these joins requires replicating logs across all regions, which leads to data duplication and increased complexity. This setup complicates downstream data processing and inflates operational costs due to multiple redundant cross-region data transfers. To overcome these challenges, we perform a cross-region transfer only once, consolidating all logs into a single&nbsp;region.</li><li>: We enrich the logs during streaming joins with metadata using various slow-changing dimension tables and services so that we have the necessary information about the OCA and the played&nbsp;content.</li><li><strong>Streaming Window-Based Join</strong>: We perform a streaming window-based join to merge the <em>steering playback manifest logs</em> with the . Performing enrichment and log consolidation upstream allows for more seamless and un-interrupted joining of our log data&nbsp;sources.</li><li>: After joining the logs, we compute the cache miss metrics. The computation checks whether the client played content from an OCA in the first site listed in the <em>steering playback manifest</em>’s proximity rank or from another site. When a video stream occurs at a higher proximity rank, this indicates that a cache miss occurred.</li></ol><h3>Data Model to Evaluate Cache&nbsp;Misses</h3><p>One of the most exciting opportunities we have enabled through these logs (in these authors’ opinions) is the ability to replay our logic offline and in simulations with variable parameters, to reproduce impact in production under different conditions. This allows us to test new conditions, features, and hypothetical scenarios without impacting production Netflix&nbsp;traffic.</p><p>To achieve the above, our data should satisfy two main conditions. First, the data should be comprehensive in representing the state of each distinct logical step involved in steering, including the decisions and their reasons. In order to achieve this, the underlying logic, here the Steering Service, needs to be built in a modularized fashion, where each logical component overlays data from the prior component, resulting in a rich blurb representing the system’s full state, which is finally logged. This all needs to be achieved without adding perceivable latency to client playback requests! Second, the data should be in a format that allows near-real-time aggregate metrics for monitoring purposes.</p><p>Some components of our final, joined data model that enables us to collect rich insights in a scalable and timely manner are listed in Table&nbsp;1.</p><p><strong>Table 1: Unified Data Model after joining <em>steering playback manifest</em> and .</strong></p><h4>Cache Miss Computation Sample</h4><p>Let us share an example of how we compute cache miss metrics. For a given unique client play request, we know we had a cache miss when the client streams from an OCA that is not in the client’s first proximity rank. As you can see from Table 1, each file needed for a client’s video streaming session is linked to routable OCAs and their corresponding sites with a proximity rank. These are 0 based indexes with proximity rank zero indicating the most optimal OCA for the client. “Proximity Rank Zero” indicates that the client connected to an OCA in the most preferred site(s), thus no misses occurred. Higher proximity ranks indicate a miss has occurred. The aggregation of all bytes and hours streamed from non-preferred sites constitutes a missed opportunity for Netflix and are reported in our cache miss&nbsp;metrics.</p><p><strong>Decision Labels and Bytes&nbsp;Sent</strong></p><p>Sourced from the <em>steering playback manifest logs</em>, we record why we did not select an OCA for playback. These are denoted&nbsp;by:</p><ul></ul><p><strong>Metrics Calculation and Categorization</strong></p><p>For each file needed for a client’s video streaming session, we can categorize the bytes streamed by the client into different types of&nbsp;misses:</p><ul><li>No Miss: If proximity rank is zero, bytes were streamed from the optimal&nbsp;OCA.</li><li>Health Miss (“H”): Miss due to the OCA reporting high utilization.</li><li>Content Miss (“C”): Miss due to the OCA not having the content available locally.</li></ul><h4>How are miss metrics used to monitor our efficiency?</h4><p>Open Connect uses cache miss metrics to manage our Open Connect infrastructure. One of the team’s goals is to reduce the frequency of these cache misses, as they indicate that our members are being served by less proximal OCAs. By maintaining a detailed set of metrics that reveal the reasons behind cache misses, we can set up alerts to quickly identify when members are streaming from suboptimal locations. This is crucial because we operate a global CDN with millions of members worldwide and tens of thousands of&nbsp;servers.</p><p>The figure below illustrates how we track the volume of total streaming traffic alongside the proportion of traffic streamed from less preferred locations due to content shedding. By calculating the ratio of content shed traffic to total streamed traffic, we derive a content shed&nbsp;ratio:</p><p>content shed ratio = content shed traffic total streamed&nbsp;traffic</p><p>This active monitoring of content shedding allows us to maintain a tight feedback loop to ensure the efficacy of our deployment and prediction algorithms, streaming traffic, and the QoE of our members. Given that content shedding can occur for multiple reasons, it is essential to have clear signals indicating when it happens, along with known and automated remediation strategies, such as mechanisms to quickly deploy mispredicted content onto OCAs. When special intervention is necessary to minimize shedding, we use it as an opportunity to enhance our systems as well as to ensure they are comprehensive in considering all known failure&nbsp;cases.</p><p>Open Connect’s unique strategy requires us to be incredibly efficient in delivering content from our OCAs. We closely track miss metrics to ensure we are maximizing the traffic our members stream from most proximal locations. This ensures we are delivering the best quality of experience to our members globally.</p><p>Our methods for managing cache misses are evolving, especially with the introduction of new streaming types like Live and Ads, which have different streaming behaviors and access patterns compared to traditional video. We remain committed to identifying and seizing opportunities for improvement as we face new challenges.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ffcf08026b6c\" width=\"1\" height=\"1\" alt=\"\">","contentLength":15506,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Earth's Atmosphere Hasn't Had This Much CO2 in Millions of Years","url":"https://news.slashdot.org/story/25/07/02/1323203/earths-atmosphere-hasnt-had-this-much-co2-in-millions-of-years?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751469600,"author":"msmash","guid":180588,"unread":true,"content":"Earth's atmosphere now has more carbon dioxide in it than it has in millions -- and possibly tens of millions -- of years, according to data released last month by the National Oceanic and Atmospheric Administration and scientists at the University of California San Diego. From a report: For the first time, global average concentrations of carbon dioxide, a greenhouse gas emitted as a byproduct of burning fossil fuels, exceeded 430 parts per million (ppm) in May. The new readings were a record high and represented an increase of more than 3 ppm over last year. \n\nThe measurements indicate that countries are not doing enough to limit greenhouse gas emissions and reverse the steady buildup of C02, which climate scientists point to as the main culprit for global warming. \"Another year, another record,\" Ralph Keeling, a professor of climate sciences, marine chemistry and geochemistry at UC San Diego's Scripps Institution of Oceanography, said in a statement. \"It's sad.\"","contentLength":979,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mind the Gap: End-to-End Quality Drop with ANN in Web Search AI","url":"https://hackernoon.com/mind-the-gap-end-to-end-quality-drop-with-ann-in-web-search-ai?source=rss","date":1751469303,"author":"Open Datasets Compiled by HackerNoon","guid":180731,"unread":true,"content":"<p>2 Background and Related work </p><p>In this section, we evaluate the end-to-end performance of the three baseline embedding models plus SPANN index and the widely-used Elasticsearch BM25 solution. Table 6 and table 7 demonstrate the result quality and system performance of all these baseline systems, respectively. Compared with table 4, we can see that after using the ANN index, the final result quality drops a lot. For example, the metric recall@100 drops more than 10 points for all baseline models. There exists large quality gaps between the ANN and KNN results (see table 5). Moreover, we notice that using the ANN index will change the model ranking trend. SimANS achieves the best results for all the result quality metrics with brute-force search. However, when using the SPANN index, it performs worse than ANCE in recall@20 and recall@100. We further analyze the phenomenon in detail and find that SimANS has a larger gap between the average distance of query to the top100 documents relative to the average distance of document to the top100 documents than ANCE. The gap in SimANS and ANCE are 103.35 and 73.29, respectively. This will cause inaccurate distance bound estimation for a query to the neighbors of a document. As a result, ANN cannot perform well because it relies on distance estimated according to the triangle inequality. Both result quality and system performance results of the end-to-end evaluation call for more innovations on the end-toend retrieval system design.</p><p>(1) Qi Chen, Microsoft Beijing, China;</p><p>(2) Xiubo Geng, Microsoft Beijing, China;</p><p>(3) Corby Rosset, Microsoft, Redmond, United States;</p><p>(4) Carolyn Buractaon, Microsoft, Redmond, United States;</p><p>(5) Jingwen Lu, Microsoft, Redmond, United States;</p><p>(6) Tao Shen, University of Technology Sydney, Sydney, Australia and the work was done at Microsoft;</p><p>(7) Kun Zhou, Microsoft, Beijing, China;</p><p>(8) Chenyan Xiong, Carnegie Mellon University, Pittsburgh, United States and the work was done at Microsoft;</p><p>(9) Yeyun Gong, Microsoft, Beijing, China;</p><p>(10) Paul Bennett, Spotify, New York, United States and the work was done at Microsoft;</p><p>(11) Nick Craswell, Microsoft, Redmond, United States;</p><p>(12) Xing Xie, Microsoft, Beijing, China;</p><p>(13) Fan Yang, Microsoft, Beijing, China;</p><p>(14) Bryan Tower, Microsoft, Redmond, United States;</p><p>(15) Nikhil Rao, Microsoft, Mountain View, United States;</p><p>(16) Anlei Dong, Microsoft, Mountain View, United States;</p><p>(17) Wenqi Jiang, ETH Zürich, Zürich, Switzerland;</p><p>(18) Zheng Liu, Microsoft, Beijing, China;</p><p>(19) Mingqin Li, Microsoft, Redmond, United States;</p><p>(20) Chuanjie Liu, Microsoft, Beijing, China;</p><p>(21) Zengzhong Li, Microsoft, Redmond, United States;</p><p>(22) Rangan Majumder, Microsoft, Redmond, United States;</p><p>(23) Jennifer Neville, Microsoft, Redmond, United States;</p><p>(24) Andy Oakley, Microsoft, Redmond, United States;</p><p>(25) Knut Magne Risvik, Microsoft, Oslo, Norway;</p><p>(26) Harsha Vardhan Simhadri, Microsoft, Bengaluru, India;</p><p>(27) Manik Varma, Microsoft, Bengaluru, India;</p><p>(28) Yujing Wang, Microsoft, Beijing, China;</p><p>(29) Linjun Yang, Microsoft, Redmond, United States;</p><p>(30) Mao Yang, Microsoft, Beijing, China;</p><p>(31) Ce Zhang, ETH Zürich, Zürich, Switzerland and the work was done at Microsoft.</p>","contentLength":3192,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Firefox 120 to Firefox 141 Web Browser Benchmarks","url":"https://www.phoronix.com/review/firefox-benchmarks-120-141","date":1751469087,"author":"mikece","guid":180865,"unread":true,"content":"<p>For those curious about the direction of Mozilla Firefox web browser performance over the past year and a half, here are web browser benchmarks for every Firefox release from Firefox 120 in November 2023 through the newest Firefox 140 stable and Firefox 140 beta releases from a few days ago. Every major Firefox release was benchmarked on the same Ubuntu Linux system with AMD Ryzen 9 9950X for evaluating the performance and memory usage of this open-source web browser.</p><p>Following the recent <a href=\"https://www.phoronix.com/review/firefox-141-linux-ram\">Firefox 141 beta benchmarks looking at the lower RAM usage</a> on Linux, I got carried away and decided to benchmark every Firefox release going back to Firefox 120 that debuted in November of 2023. Firefox 120 was the breaking point since Firefox 119 and prior ended up running into issues with Selenium / Gecko web driver for automating the benchmarks. So due to that breakage, Firefox 120 was the old cut-off but still a useful exercise in seeing the performance of Firefox on Linux over roughly the past nearly two years.</p><p>The release builds of every major Firefox release from Firefox 120 through Firefox 141 Beta were tested. In the case of Firefox 125, Firefox 125.0.1 was used since Firefox 125.0 binaries were removed due to problems. In addition to looking at the Firefox performance across a variety of web browser benchmarks, the RAM usage was also monitored for reference.</p><p>The same AMD Ryzen 9 9950X desktop system running Ubuntu 25.04 was used for collecting all of these fresh Mozilla Firefox web browser benchmarks. The testing is very straight-forward so let's get right to it.</p>","contentLength":1580,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44444722"},{"title":"Gene therapy restored hearing in deaf patients","url":"https://news.ki.se/gene-therapy-restored-hearing-in-deaf-patients","date":1751468589,"author":"justacrow","guid":180864,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44444626"},{"title":"Firefox 120 To Firefox 141 Web Browser Benchmarks","url":"https://www.phoronix.com/review/firefox-benchmarks-120-141","date":1751468400,"author":"Michael Larabel","guid":180666,"unread":true,"content":"<article>For those curious about the direction of Mozilla Firefox web browser performance over the past year and a half, here are web browser benchmarks for every Firefox release from Firefox 120 in November 2023 through the newest Firefox 140 stable and Firefox 140 beta releases from a few days ago. Every major Firefox release was benchmarked on the same Ubuntu Linux system with AMD Ryzen 9 9950X for evaluating the performance and memory usage of this open-source web browser.</article>","contentLength":472,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"June GNU Spotlight with Amin Bandali featuring Sixteen new GNU releases: GNUnet, Nettle, and more!","url":"http://www.fsf.org/blogs/community/2025-june-gnu-spotlight-with-amin-bandali","date":1751468371,"author":"","guid":180575,"unread":true,"content":"<article>Sixteen new GNU releases in the last month (as of June 30, 2025):</article>","contentLength":65,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Automation Evolution: Is Your DevOps Ready for Tomorrow’s Innovations?","url":"https://devops.com/automation-evolution-is-your-devops-ready-for-tomorrows-innovations/?utm_source=rss&utm_medium=rss&utm_campaign=automation-evolution-is-your-devops-ready-for-tomorrows-innovations","date":1751467624,"author":"Christopher Haggan","guid":180655,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"UK Eyes New Law as 1885 Telegraph Act Proves Inadequate for Cable Sabotage","url":"https://tech.slashdot.org/story/25/07/02/1136225/uk-eyes-new-law-as-1885-telegraph-act-proves-inadequate-for-cable-sabotage?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751467200,"author":"msmash","guid":180587,"unread":true,"content":"The UK government is preparing new legislation to address undersea cable sabotage as current laws are proving inadequate for modern threats. Ministry of Defence parliamentary under-secretary Luke Pollard told lawmakers yesterday that the Submarine Telegraph Act of 1885, which imposes 1,000 pound ($1,370) fines, \"does seem somewhat out of step with the modern-day risk.\" \n\nThe government's Strategic Defence Review proposes a new defence readiness bill to cover state-sponsored cybercrime and subsea cable attacks. Chris Bryant, minister of state for data protection and telecoms, said fines could be increased to 5,000 pound ($6,850) through secondary legislation but \"that just doesn't seem to meet the needs of the situation.\" \n\nRecent incidents include Sweden's deployment of forces to the Baltic Sea following suspected Russian attacks on underwater data cables in January. The China Strategic Risks Institute found that eight of ten identified vessels in 12 sabotage incidents between January 2021 and April 2025 were linked to China or Russia through registration or ownership.","contentLength":1085,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Dirty Secrets of Developer Advertising: Why Traditional Channels Fail—and What to Do Instead","url":"https://hackernoon.com/the-dirty-secrets-of-developer-advertising-why-traditional-channels-failand-what-to-do-instead?source=rss","date":1751466603,"author":"Hack Marketing with HackerNoon for Businesses","guid":180730,"unread":true,"content":"<p>If you're losing sleep over how to effectively market to developers, you’re not alone.</p><p>In a recent survey of B2B software marketers:</p><ul><li> said reaching and engaging developers is their </li><li> struggle to create content that actually resonates with technical audiences</li><li> admit their developer marketing efforts are “hit or miss” at best</li></ul><p>It should. Because the truth is: <strong>developers are a tough nut to crack</strong>. \\n  They’re skeptical. Ad-averse. Quick to tune out anything that smells even vaguely like marketing fluff. \\n  And yet—they’re  to your success.</p><p>:::tip\nTired of guessing at what works? <a href=\"http://calendly.com/hackernoon\">Book a call</a> with HackerNoon now and let’s talk about reaching developers in a way that actually works.</p><p>\\\nDevelopers aren’t just users. They’re the technical gatekeepers. The tool evaluators. The quiet (but decisive) voices in big-ticket buying decisions.</p><p>So if you fail to win their trust? \\n  Those six-figure deals start slipping away fast.</p><h2>The Hard Truth About Developer Ad Channels</h2><p>Let’s talk numbers for a second.</p><ul><li><strong>Google Ads (Programming keywords):</strong> 0.09% CTR</li><li><strong>Reddit Promoted Posts (developer subreddits):</strong> 0.05% CTR</li><li><strong>Stack Overflow Display Ads:</strong> 0.03% CTR</li></ul><p>You're not just throwing money into the void. \\n You're <em>investing in channels developers are actively trained to ignore.</em></p><p>Why? Because developers aren't waiting around to be marketed to. \\n They’re looking for <em>real solutions to real problems</em>. Anything that feels inauthentic—or irrelevant—gets tuned out instantly.</p><h2>Stop Treating Developers Like Metrics</h2><p>It’s easy to forget: developers are people, not personas. They have real challenges, real passions, real communities. \\n  And if you treat them like humans instead of dashboards, :</p><ul><li> say they’re more likely to engage with content that speaks to their interests and pain points</li><li> trust brands that understand developer culture and workflows</li><li> have discovered new tools through a  they trust</li></ul><p>This isn’t just about creating more technical blog posts or sponsoring another podcast. It’s about stepping into developer culture—and showing up authentically.</p><h2>What Actually Works in Developer Marketing?</h2><p>Most successful developer marketers have figured out one simple truth:</p><blockquote><p><strong>Developers have lives and interests beyond #CoderLife</strong></p></blockquote><p>This is why most sales happen in bars, not boardrooms!</p><p>Dev Marketing isn't about running a few ads or sponsoring a couple of posts. It’s built on .</p><ul><li>Trading generic, spammy tactics for authentic, relationship-driven strategies</li><li>Swapping vanity metrics for meaningful engagement and revenue impact</li><li>Ditching the guessing game for a clear, measurable path to ROI.</li></ul><p>If your dev marketing feels like shouting into the void, you’re not broken—you’re just using the wrong playbook.</p><p>And at HackerNoon, we’ve helped over 4,000 companies find their voice in the developer world. From startups to scale-ups, we’ve seen it all—and we know what works.</p><p>If you're ready to start connecting instead of broadcasting, let’s talk.</p><p>:::tip\n👉  and let’s start solving problems that matter.</p>","contentLength":2997,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AV1 @ Scale: Film Grain Synthesis, The Awakening","url":"https://netflixtechblog.com/av1-scale-film-grain-synthesis-the-awakening-ee09cfdff40b?source=rss----2615bd06b42e---4","date":1751466104,"author":"Netflix Technology Blog","guid":180638,"unread":true,"content":"<h4><em>Unleashing Film Grain Synthesis on Netflix and Enhancing Visuals for&nbsp;Millions</em></h4><p><strong>Picture this: you’re watching a classic film, and the subtle dance of film grain adds a layer of authenticity and nostalgia to every scene.</strong> This grain, formed from tiny particles during the film’s development, is more than just a visual effect. It plays a key role in storytelling by enhancing the film’s depth and contributing to its realism. However, film grain is as elusive as it is beautiful. Its random nature makes it notoriously difficult to compress. Traditional compression algorithms struggle to manage it, often forcing a choice between preserving the grain and reducing file&nbsp;size.</p><p>In the digital age, noise remains a ubiquitous element in video content. Camera sensor noise introduces its own characteristics, while filmmakers often add intentional grain during post-production to evoke mood or a vintage feel. These elements create a visually rich experience that tests conventional compression methods.</p><p>We’re giving members globally a transformed streaming experience with the recent rollout of AV1 Film Grain Synthesis (FGS) streams. While FGS has been part of the AV1 standard since its inception, we only enabled it for a limited number of titles during <a href=\"https://netflixtechblog.com/bringing-av1-streaming-to-netflix-members-tvs-b7fc88e42320\">our initial launch of the AV1 codec in 2021</a>. Now, we’re enabling this innovative technology at scale, leveraging it to preserve the artistic integrity of film grain while optimizing data efficiency. In this blog post, we’ll explore how FGS revolutionizes video streaming and enhances your viewing experience.</p><h3>Understanding Film Grain Synthesis in&nbsp;AV1</h3><p>The AV1 Film Grain Synthesis tool models film grain through two key components, with model parameters estimated before the encoding of the denoised&nbsp;video:</p><p>: an <em>auto-regressive (AR) model</em> is used to replicate the pattern of film grain. The key parameters are the AR coefficients, which can be estimated from the residual between the source video and the denoised video, essentially capturing the noise. This model captures the spatial correlation between the grain samples, ensuring that the noise characteristics of the original content are accurately preserved. By adjusting the auto-regressive coefficients {ai}, the model can control the grain’s shape, making it appear coarser or finer. With these coefficients, a 64x64 noise template is generated, as illustrated in the animation below. To construct the noise layer during playback, random 32x32 patches are extracted from the 64x64 noise template and added to the decoded&nbsp;video.</p><p>: a  is employed to control the grain’s appearance under varying lighting conditions. This function, estimated during the encoding process, models the relationship between pixel value and noise intensity using a piecewise linear function. This allows for precise adjustments to the grain strength based on video brightness and color. Consequently, the film grain strength is adapted to the areas of the picture, closely recreating the look of the original video. The animation below demonstrates how the grain intensity is adjusted by the scaling function:</p><p>With these models specified by AV1 standard, the encoding process first removes the film grain from the video. The standard does not mandate a specific method for this step, allowing users to choose their preferred denoiser. Following the denoising, the video is compressed, and the grain’s pattern and intensity are estimated and transmitted alongside the compressed video data. During playback, the film grain is recreated and reintegrated into the video using a block-based method. This approach is optimized for consumer devices, ensuring smooth playback and high-quality visuals. For a more detailed explanation, please refer to the <a href=\"https://norkin.org/pdf/DCC_2018_AV1_film_grain.pdf\">original&nbsp;paper</a>.</p><p>By combining these components, the AV1 Film Grain Synthesis tool preserves the artistic integrity of film grain while making the content “easier to compress” by denoising the source video prior to encoding. This process enables high-quality video streaming, even in content with heavy grain, resulting in significant bitrate savings and improved visual&nbsp;quality.</p><h3>Visual Quality Improvement, Bitrate Reduction, and Member&nbsp;Benefits</h3><p>In our pursuit of premium streaming quality, enabling AV1 Film Grain Synthesis has led to significant bitrate reduction, allowing us to deliver high-quality video with less data while preserving the artistic integrity of film grain. Below, we showcase visual examples highlighting the improved quality and reduced bitrate, using a frame from the Netflix title <a href=\"https://www.netflix.com/title/80996324\"></a>:</p><p>The visual comparison highlights a significant bitrate reduction of approximately 66%, with regular AV1 encoding at 8274 kbps compared to AV1 with FGS at 2804 kbps. In this example, which features strong film grain, it may be observed that the regular version exhibits distorted noise with a discrete cosine transform (DCT)-like pattern. In contrast, the FGS version preserves the integrity of the film grain at a lower&nbsp;bitrate.</p><p>Additionally, synthesized noise effectively masks compression artifacts, resulting in a more visually appealing experience. In this comparison below, both the regular AV1 stream and the AV1 FGS stream without synthesized noise (equivalent to compressing the denoised video) show compression artifacts. In contrast, the AV1 FGS stream with grain synthesis (rightmost figure) improves visual quality through contrast masking in human visual systems. The added film grain, a form of mask, effectively conceals some compression artifacts.</p><p>Currently, we lack a dedicated quality model for film grain synthesis. The noise appearing at different pixel locations between the source and decoded video poses challenges for pixelwise comparison methods like <a href=\"https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\">PSNR</a> or <a href=\"https://netflixtechblog.com/toward-a-practical-perceptual-video-quality-metric-653f208b9652\">VMAF</a>, leading to penalized quality scores. Despite this, our internal assessment highlights the improvements in visual quality and the value of these advancements.</p><p>To evaluate the impact of AV1 Film Grain Synthesis, we selected approximately 300 titles from the Netflix catalog, each with varying levels of graininess. The bar chart below illustrates a 36% reduction in average bitrate for resolutions of 1080p and above when AV1 film grain synthesis is enabled, highlighting its efficacy in optimizing data usage. For resolutions below 1080p, the reduction in bitrate is relatively small, reaching only a 10% decrease, likely because noise is filtered out during the downscaling process. Furthermore, enabling the film grain synthesis coding tool consistently introduces syntax overhead to the bitstream.</p><p>Finally, we conducted A/B testing prior to rollout to understand the overall streaming impact of enabling AV1 Film Grain Synthesis. This testing showcased a smoother and more reliable Quality of Experience (QoE) for our members. The improvements include:</p><ul><li><strong>Lower Initial and Average Bitrate</strong>: Bitrate at the start of the playback reduced by 24% and average bitrate by 31.6%, lower network bandwidth requirements and reduced storage needs for downloaded streams.</li><li><strong>Decreased Playback Errors</strong>: Playback error rate reduced by approximately 3%.</li><li>: 10% fewer rebuffers and a 5% reduction in rebuffer duration resulting from the lower&nbsp;bitrate.</li><li>: Start play delay reduced by 10%, potentially due to the lower bitrate, which may help devices reach the target buffer level more&nbsp;quickly.</li><li><strong>Improved Playback Stability</strong>: Observed 10% fewer noticeable bitrate drops and a 10% reduction in the time users spend adjusting their playback position during video playback, likely influenced by reduced bitrate and rebuffering.</li><li><strong>Higher Resolution Streaming</strong>: About 0.7% of viewing hours shifted from lower resolutions (≤ 1080p) to 2160p on 4K-capable devices. This shift is attributed to reduced bitrates at switching points, which make it easier to achieve the highest resolution during a&nbsp;session.</li></ul><h3>Behind the Scenes: Our Film Grain Adventure Continues</h3><p>We’re always excited to share our progress with the community. This blog provides an overview of our journey: from the initial launch of the AV1 codec to the recent addition of Film Grain Synthesis (FGS) streams, highlighting the impact these innovations have on Netflix’s streaming quality. Since March, we’ve been rolling out FGS across scale, and many users can now enjoy the FGS-enabled streams, provided their device supports this feature. We encourage you to watch some of the author’s favorite titles <a href=\"https://www.netflix.com/title/81985186\">The Hot Spot</a>, <a href=\"https://www.netflix.com/title/70018511\">Kung Fu Cult Master</a>, <a href=\"https://www.netflix.com/title/70043379\">Initial D</a>, <a href=\"https://www.netflix.com/title/70005331\">God of Gamblers II</a>, <a href=\"https://www.netflix.com/title/80203996\">Baahubali 2: The Conclusion</a>, or <a href=\"https://www.netflix.com/title/81487660\">Dept. Q</a> (you may need to toggle off HDR from the settings menu) on Netflix to experience the new FGS streams firsthand.</p><p>This achievement is the result of a collaborative effort among several Open Connect teams at Netflix, including Video Algorithms, Media Encoding Pipeline, Media Foundations, Infrastructure Capacity Planning, and Open Connect Control Plane. We also received invaluable support from Client &amp; Partner Technologies, Streaming &amp; Discovery Experiences, Media Compute &amp; Storage Infrastructure, Data Science &amp; Engineering, and the Global Production Technology team. We would like to express our sincere gratitude to the following individuals for their contributions to the project’s success:</p><ul><li>Prudhvi Kumar Chaganti and Ken Thomas for the discussion and assistance on rollout&nbsp;strategy</li><li>Poojarani Chennai Natarajan, Lara Deek&nbsp;, Ivan Ivanov, and Ishaan Shastri for their essential support in planning and operations for Open&nbsp;Connect.</li><li>Alex Chang for his support in everything related to data analysis, and Jessica Tweneboah and Amelia Taylor for their assistance with AB&nbsp;testing.</li><li>David Zheng, Janet Xue, Scott Bolter, Brian Li, Allan Zhou, Vivian Li, Sarah Kurdoghlian, Artem Danylenko, Greg Freedman, and many other dedicated team members played a crucial role in device certification and collaboration with device partners. Their efforts significantly improved compatibility across platforms. (Spoiler alert: this was one of the biggest challenges we faced for productizing AV1&nbsp;FGS!)</li><li>Javier Fernandez-Ivern and Ritesh Makharia expertly managed the playback&nbsp;logic</li><li>Joseph McCormick and JD Vandenberg for providing valuable insights from a content production point of view, and Alex ‘Ally’ Michaelson for assisting in monitoring customer&nbsp;service.</li><li>A special thanks to Roger Quero, who played a key role in supporting various aspects of the project and contributed significantly to its overall success while he was at&nbsp;Netflix.</li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ee09cfdff40b\" width=\"1\" height=\"1\" alt=\"\">","contentLength":10412,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Vitalik Sparks Debate About ZKP-Based Digital IDs After Blog Criticism","url":"https://hackernoon.com/vitalik-sparks-debate-about-zkp-based-digital-ids-after-blog-criticism?source=rss","date":1751465347,"author":"Ishan Pandey","guid":180729,"unread":true,"content":"<p>The rise of zero-knowledge proofs (ZKP) in Web3 has been difficult to ignore in recent years. One person who certainly hasn’t overlooked the technology is Ethereum cofounder Vitalik Buterin, who trained his forensic gaze on ZKP-based digital identity systems in his latest<a href=\"https://vitalik.eth.limo/general/2025/06/28/zkid.html\"></a>.</p><p>\\\nAlthough ZK tech is widely used in the Ethereum ecosystem, notably in the form of Zero-Knowledge rollups to support scaling, Buterin didn’t bang the drum or talk up any ZK projects that had caught his eye. In fact, Ethereum wasn’t mentioned once in the 3,000+ word<a href=\"https://vitalik.eth.limo/general/2025/06/28/zkid.html\"></a>article.</p><p>\\\nInstead, Buterin made several criticisms of ZK-wrapped identities, arguing that “attempting to uphold a one-identity-per-person property” entails risks such as loss of privacy and vulnerability to coercion. ZKPs also fail to solve non-privacy risks such as errors, he claimed.</p><h3>World ID and the Limits of Token-Based UBI</h3><p>\\\nTurning his attention to  (formerly Worldcoin), the biometric-based project that uses crypto to compel users to have their eyeballs scanned, he rejected the idea that such projects could form the basis of a Universal Basic Income (UBI).</p><p>\\\n“I do not expect such tokens to be worth anywhere close to enough to pay for a person’s subsistence,” he stated bluntly, adding that “ the realistic problem that such mini-UBIs solve is giving people access to a sufficient quantity of cryptocurrency to make a few basic onchain transactions and online purchases.”</p><p>\\\nThe idea of tying a secure digital ID to financial or humanitarian aid (UBI, subsidies, grants) is one that has a groundswell of support, and many believe ZKPs can help to make this idea a reality. The Taiwanese government is  leveraging Zero-Knowledge Proofs to secure digital IDs, while Google has integrated the tech into its mobile wallet, ensuring age verification across mobile devices, apps (such as Bumble) and websites using its Digital Credential API.</p><p>\\\nSo, are on-chain digital identity systems equipped with ZKPs really our best chance of reaching a point where aid can be provably dispensed to the needy, rather than bots or fraudsters? After all, ZKPs align with the principle of least privilege, allowing users to prove specific claims without exposing their identity. But what about those criticisms?</p><p>\\\n“ZKPs are not a silver bullet on their own, they still leave data traces behind, especially when attestations are made on public blockchains,” says Shady El Damaty, Cofounder of decentralized identity project . “Private state, unlinked addresses, and careful data management can help augment privacy, however the risk of giving up your nullifier is the same as the risk of losing your private key – so the issue is not with ZKPs but rather overall self-custody security practices.”</p><p>“This is why we have designed a 2PC model that assumes security for the user even when their device is compromised,” adds Cofounder Nanak Nihal Singh Khalsa. “This means a user must authenticate their identity with multiple independent methods to claim funds or submit a transaction.”</p><h3>Streamlining Aid with Crypto Rails \\n</h3><p>Holonym takes a different approach to World, in that it can theoretically be used to link up existing aid with identity rather than combining the two. “There’s an existing humanitarian aid network already out there, so why not upgrade their capacities rather than use UBI as a marketing tool to justify a token’s utility or valuation?” asks El Damaty.</p><p>Naturally, Singh Khalsa concurs. “Token-based UBI models are out of touch with the real world and people who most need basic level support to meet their needs,” he says. As well as token prices being volatile, making what one can buy change based on daily price swings, the value of such assets tends to decline without meaningful utility or demand. \\n </p><p>\\\n“Another problem is that UBI tokens need to be off-ramped and exchanged to cash, and those who need the tokens the most will likely experience great difficulty off-ramping, or they’ll have to pay large fees to do so,” says El Damaty. \\n </p><p>\\\nHolonym’s ‘' framework allows existing humanitarian aid to run more efficiently on crypto rails: aid recipients can create digital wallets from their social accounts (WhatsApp,Facebook), secure them with simple biometrics, and directly receive payments in the form of stablecoins. human.tech also lets aid programs request identity proofs to measure proof of impact and reduce false claims, while Holonym partners with local off-ramps to keep fees low for users.</p><p>\\\n\\\nButerin’s criticism of one-person-one-ID stems from his belief that if a single ZK-ID system were to dominate the market, reversion to this model would undermine pseudonymity and increase coercion risks. Singh Khalsa certainly appreciates this perspective, noting that “the design of one-person-one-ID typically serves goals for centralized systems that seek to control or capture the value of identity into a walled garden.” \\n </p><p>\\\nIn other words, users enjoy more freedom and flexibility when, rather than being locked into one identity, multiple can be created. “ZKPs can be used to generate multiple identities if designed well with the user in mind,” says El Damaty. “Revocation, control over privately linked addresses, and private addresses can all extend the pluralism of ZKPs.” \\n </p><p>\\\nButerin’s warnings have certainly sparked debate about ZK-wrapped identities and their applicability to aid distribution, particularly where privacy and security are concerned. Expect this debate to rumble on, and for alternative approaches to token-based UBIs like World to continue stating their case.</p><p>\\\nDon’t forget to like and share the story! </p><p>:::tip\n<em>This author is an independent contributor publishing via our&nbsp;. HackerNoon has reviewed the report for quality, but the claims herein belong to the author. #DYO</em></p>","contentLength":5834,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Exploiting the IKKO Activebuds “AI powered” earbuds (2024)","url":"https://blog.mgdproductions.com/ikko-activebuds/","date":1751465203,"author":"ajdude","guid":180583,"unread":true,"content":"<p>So my journey with these earbuds started after I saw them on <a href=\"https://www.youtube.com/clip/UgkxPHxlV8Uo2L2k_v_RNloYS80CGql6CWH8?ref=blog.mgdproductions.com\" rel=\"noreferrer\">this</a> Mrwhosetheboss video about pointless tech. This device seems to be also popular on TikTok. My suspicions were confirmed, this runs android. So of course i went ahead and bought them.</p><p>245 euros later... and they finally arrived!</p><p>Before we dive further into this, unlike with <a href=\"https://x.com/MarcelD505/status/1785346490635878837?ref=blog.mgdproductions.com\" rel=\"noreferrer\">rabbit</a>, this issue has been properly reported and patched. This is also my first real blog post/disclosure so feedback is appreciated.</p><p>I like how they strapped a USB-c cable to the outside of the box while there is also a smaller one inside the box. They ran out of box space it seems...</p><p>I also wonder if they are legally allowed to use this OpenAI logo (probably not lol)</p><p>Anyways, we aren't here for fancy boxes, lets get to the main point. The device itself boots up to a screen with the time and ChatGPT front and center.</p><p>There are some other AI features available too like translations. But this isn't a review of the device, you can watch <a href=\"https://www.youtube.com/watch?v=p83t0qj9SFM&amp;ref=blog.mgdproductions.com\" rel=\"noreferrer\">other YouTube videos</a> about that. The ChatGPT animation looks way too similar to the actual app and OpenAI could probably get them in legal trouble for stealing their brand identity. I will also mention that the audio quality is absolute shit if you use their EQ profiles but can be upped to a usable level by tweaking the EQ curves yourself.</p><p>There are also some apps available in the IKKO store, the reason that there is no google play store available is because these apps are modified specifically for the screen on the ActiveBuds, at least, that is what the CEO says about them. We will check that out in a bit. These apps include some music apps like Spotify, but also some gaming apps like, oh god, SUBWAY SURFERS BAYBEEEEE</p><p>Of course all of them unbearable to navigate due to the small screen. However we can now confirm that it most definitely runs android.</p><p>There is sadly no browser available to directly download other apps. And while you can open the native android settings app, clicking the build number 7 times does not enable developer mode. So i couldn't enable adb it seems. Is it locked that well? heh nope.</p><p>Let's just plug it into a pc and see what happens....</p><p>What the fuck, they left ADB enabled. Well, this makes it a lot easier. </p><p>After sideloading the obligatory DOOM, i began checking out how the ChatGPT integration works on the backend. I first started HTTP inspecting the device, however since i couldn't enable the proper system certificates without rooting the device, i couldn't see exactly to what URL it communicated. Fortunately that wasn't really needed.</p><p>Holy shit, holy shit, holy shit, it communicates DIRECTLY TO OPENAI. This means that a ChatGPT key must be present on the device!</p><p>I know that this device can be rooted to get the proper certificates installed because <a href=\"https://www.hovatek.com/forum/thread-32287.html?ref=blog.mgdproductions.com\" rel=\"noreferrer\">a tool</a> exists on all Spreadtrum/Unisoc devices which can be used to unlock the bootloader as long as companies use the default signing keys. This was indeed the case here too. However, i couldn't get past the confirmation screen as the device does not have a volume up key to confirm the unlock. I think you are able to sign your own partitions to make it flash them without an unlocked bootloader but that's a bit too advanced for my own liking.</p><p>So, i went back to the drawing board and just dumped all of the apps from it with an APK extractor tool. After popping the launcher app into JADX, things immediately became concerning.</p><p>The device can communicate to either of these domains.</p><ul><li>api.openai.com\nObvious, the OpenAI API</li><li>chat1.chat.iamjoy.cn\nSeems to be the API for the entire device, including features not related to ChatGPT like the app store. Loading it up in a browser gives a login page.</li><li>chat2.chat.iamjoy.cn\nSame thing as chat1, possibly a backup server?</li><li>openspeech.bytedance.com\nNo idea, might be a speech recogniser backup instead of whisper, haven't seen communication to this from the device.</li><li>www.airdimple.cn\nSeems like an OpenAI API mirror or proxy?</li></ul><p>Knowing this i went hunting for api endpoints and keys. I found a file called SecurityStringsAPI which contained encrypted endpoints and authentication keys. </p><p>You might think, hey that's just base64 idiot, the most basic encoding known to mankind. And well, yeah, it is.</p><p>However, there is a second stage which is handled by a native library which is obfuscated to hell. I am not going to even try to read that. Fortunately i didn't have to. I just sideloaded the app on a different device which was rooted, and well, <a href=\"https://x.com/MarcelD505/status/1785346490635878837?ref=blog.mgdproductions.com\" rel=\"noreferrer\">just like the rabbit apk</a>, it just works!</p><p>Yup, that's an OpenAI key.</p><p>Now, while having this access, we can also expose their (pretty funny) system prompt.</p><p>The device also has another few modes, which are Angry Dan and In-Love Dan. For the angry one you need to confirm you are 18+ because it actually swears a lot.</p><p>The system prompts for these are a bit more boring.</p><p>I also noticed that it logs the chat to another endpoint on the chat1 domain. This is probably just to keep a log of messages since the ChatGPT API does not allow that. Possibly for some Chinese espionage? Well, possibly but not entirely, we will get to that.</p><p>The headers for this request include the message, model, response and the device IMEI as the device id.</p><p>I also sideloaded the store app and found out that the apps seem to be mostly ripped straight from apkpure.com</p><p>After discovering this information, i sent an email to the security department of IKKObuds.</p><p>While waiting for their response i started to investigate their companion app. Wait i forgot to tell you about that? Yeah, these earbuds have a companion app with which you can also directly interface with ChatGPT and see your previous chats from the device. So that's what the logging endpoint is used for! You bind the app by <a href=\"https://youtu.be/IfyIV2oE-tE?feature=shared&amp;t=38&amp;ref=blog.mgdproductions.com\" rel=\"noreferrer\">scanning a QR code</a> from the device in the \"Membership\" menu.</p><p>So, let's HTTP inspect this app and check out where it gets this information from.</p><p>Alright so it queries this API with your account token and your device id and returns all the chats you have ever had with the device. However, after removing the account token, the request still worked? So this api has no authentication apart from the device id. I feared the worst.</p><p>I found a frame in <a href=\"https://www.youtube.com/watch?v=IfyIV2oE-tE&amp;t=38s&amp;ref=blog.mgdproductions.com\" rel=\"noreferrer\">the tutorial video</a> in which the device id wasn't properly blurred and plugged that into the api.</p><p>YUP, i now had their entire demo device chat history. And as the IMEI has a certain range, you would be able to figure out the chat history of all customers, which may include sensitive details.</p><p>I also added this new discovery to the email chain.</p><p>While that email was waiting for a reply i checked if i could fabricate a linking QR code from a known IMEI to bind the device. (The QR code is not the IMEI itself but something encrypted) I found the API endpoint by looking at the same SecurityStringsAPI, which was less secure than i initially thought because the variable names literally expose the encrypted api endpoints (lol)</p><p>Plugging in the getBindDevQrCode api in postman, i could fabricate a base64 image of the QR code with any IMEI.</p><p>However, using this QR code to try and bind the device to my app resulted in an error, saying that the device has already been bound to someone else. So that has been the only good security implementation up until now.</p><p>However, i lied, this is still a security/privacy issue. Why, you may ask? This exposes the username you set when creating the account for the app. However, there is no username field when creating your account. Only first and last name.</p><p>I created an account with the first name as \"Cheese2\" and the second name as \"Delight2\". Turns out that the username is equal to First name + Last name. When trying to bind that device to an app after it has already been bound to another app, the response includes the name \"Cheese2Delight2\". Great. Doxed.</p><p>So what we can do now is guess IMEI -&gt; generate QR code -&gt; Bind the device if not bound already, or get your full name when the device is already bound. -&gt; Get all your chat history either way if the device is bound or not.</p><p>There is an unbind_dev endpoint????</p><p>Unfortunately that one actually checks account token and does not allow to unbind a random device IMEI. Phew.</p><p>Hey, do you remember that logging endpoint that actually sent your chats you made with ChatGPT to their servers? This one?</p><p>Yeah, that also only used the device id as authentication, so we can send arbitrary text to the companion app of anyone....</p><p>I tried to send some HTML and JS through it to try and exploit the companion app, fortunately they use vue for their app and that has default HTML and JS injection security <a href=\"https://vuejs.org/guide/best-practices/security?ref=blog.mgdproductions.com#html-injection\" rel=\"noreferrer\">built in</a>. But we can still send scams or something to any user.</p><p>Oh hey a reply to my email!</p><p>First of all, from a gmail address? Come on, actually try to have at least some professionalism. Second, OK they are actually doing something about it. (The YouTube channel mentioned is because i said that i will be making a video about this. I have all the footage for it but i hate my voice with a passion so here we are on this blog post :))</p><p>Shortly after this email, they locked down the app and put out an announcement stating that the app will be in maintenance for a week.</p><p>They also wanted to become a sponsor of my empty YouTube channel? What? I don't think that they understood that i would be talking about their horrible security. Anyways.</p><p>The API was now non functional and displayed a maintenance message. After the service period they put out both an app update and a device update. What changed? The endpoint to get the chat history now needs a \"signature\" header. Which is composed of your account token, your device id, language and the current time encoded with a public/private key + a password. </p><p>Anyways, it is now impossible to fetch the chats without having a valid account token. Still doesn't fix the fact that i can generate a QR code with the guessable IMEI and bind the device to an app if it hasn't been bound already. That circumvents this all. </p><p>The device update broke the ChatGPT functionality from functioning on a device which is not the IkkoBuds itself. The keys remain on device and have not been rotated. So if anyone is able to figure out the broken app on another device or the key encryption system, you can still get your very own free OpenAI API key.</p><p>However i just gave up at this moment, also because they never replied with anything after my last email criticizing them for leaving the keys on device. This is now a month and a half ago.</p><p>So, that is it. You can still inject messages into apps of others, link devices that are not already bound to another companion app, thus leaking chat history. And leak first and last names of devices which are bound.</p><p>I am giving up, but if anyone else wants this company to fix this, be my guest.Also if you liked this deep dive, consider supporting me so i will be able to convince myself that buying more strange android devices is worth it lol<a href=\"https://ko-fi.com/mgdproductions?ref=blog.mgdproductions.com\">https://ko-fi.com/mgdproductions</a></p><p>I got this device rooted with help from <a href=\"https://x.com/haro7z?ref=blog.mgdproductions.com\">@haro7z</a></p><p>They are now checking the device's imei before it is able to use the chatgpt integration and are now using a proxy api instead of calling directly to openai. However this proxy api doesn't require any auth and only requires the User-Agent to be set to okhttp/4.9.0 LOL</p><p>They have also FINALLY rotated their old chatgpt api key!</p>","contentLength":11239,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44443919"},{"title":"Why Organizations Need Expert Generalists","url":"https://martinfowler.com/articles/expert-generalist.html#WhyOrganizationsNeedExpertGeneralists","date":1751465100,"author":"Martin Fowler","guid":182730,"unread":true,"content":"<p>In complex environments, the characteristics of Expert Generalists lead\n      Gitanjali, and I thus complete our article by summarizing the value of\n      them to be particularly valuable in driving tasks to completion. Unmesh,\n      this skill.</p>","contentLength":245,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Data breach reveals Catwatchful ‘stalkerware’ is spying on thousands of phones","url":"https://techcrunch.com/2025/07/02/data-breach-reveals-catwatchful-stalkerware-spying-on-thousands-android-phones/","date":1751465100,"author":"Zack Whittaker","guid":180544,"unread":true,"content":"<article>The spyware operation's exposed customer email addresses and passwords were shared with data breach notification service Have I Been Pwned.</article>","contentLength":139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Physicists Start To Pin Down How Stars Forge Heavy Atoms","url":"https://www.quantamagazine.org/physicists-start-to-pin-down-how-stars-forge-heavy-atoms-20250702/","date":1751464818,"author":"Jenna Ahart","guid":180461,"unread":true,"content":"<p>The Facility for Rare Isotope Beams (FRIB) may not glitter quite like the night sky, plunked as it is between Michigan State University’s chemistry department and the performing arts center. Inside, though, the lab is teeming with substances that are otherwise found only in stars. Here, atomic nuclei accelerate to half the speed of light, smash into a target and shatter into smithereens.</p>","contentLength":392,"flags":null,"enclosureUrl":"https://www.quantamagazine.org/wp-content/uploads/2025/07/HeavyElementNucleosynthesis-crMarkBelan-Default.webp","enclosureMime":"","commentsUrl":null},{"title":"Python functools & itertools: 7 Super Handy Tools for Smarter Code","url":"https://www.kdnuggets.com/python-functools-itertools-7-super-handy-tools-for-smarter-code","date":1751464817,"author":"Bala Priya C","guid":180477,"unread":true,"content":"<article>Want to code smarter, not harder? Start using these 7 utilities from Python's functools and itertools that are useful, practical, and elegant!</article>","contentLength":142,"flags":null,"enclosureUrl":"https://www.kdnuggets.com/wp-content/uploads/BALA-python-functools-itertools.jpeg","enclosureMime":"","commentsUrl":null},{"title":"What If Your 'Messy' Data Is Actually Perfect?","url":"https://hackernoon.com/what-if-your-messy-data-is-actually-perfect?source=rss","date":1751464806,"author":"Lior Barak","guid":180728,"unread":true,"content":"<p><strong>Hello, data Shokunin-deshi!</strong></p><p>Welcome to the final installment of our Data Ecosystem Vision Board implementation series! In our previous editions, I shared how I helped Sarah at 4seconds.com build the Present Inputs and Future Vision layers of her Data Ecosystem Vision Board.</p><p>\\\nToday, we complete the journey by exploring the Success Metrics layer, the compass that guides transformation and measures progress.</p><p>\\\nMy neighbor's so obsessed with his lawn, I'm pretty sure he thinks he's the Zen master of his backyard. He came over the other day, and for about the fourth time, started talking about my tree. This time, though, he prefaced it with a story from some \"advanced gardening course\" he took.</p><p>\\\n\"How will we know if our pruning is correct?\" an eager apprentice asked. The master, apparently radiating serene wisdom, replied, \"We judge by three measures: the tree's health, its beauty, and how it harmonizes with the garden as a whole. These three tell us everything we need to know.\"</p><p>\\\nThen, he looked me dead in the eye and, with all the Zen calm he could muster, informed me that my wildly un-Zen-like tree was failing on all three counts, especially the \"harmonizes with his garden\" part. He then patiently explained that while he values harmony, his patience for my arboreal negligence was, shall we say, not boundless. He might just have to apply those pruning principles himself.</p><p>\\\nAnd honestly, his point about the tree's intrusion, however un-Zen-like his delivery, perfectly illustrates the purpose of our Success Metrics layer. With the right measures, we can evaluate complex transformations through a simple yet powerful lens that guides our actions and decisions. Because sometimes, even the most profound principles need a little push, or a neighbor with a very specific definition of \"harmony.\"</p><p>\\\nThe Success Metrics layer transforms a vision from aspiration to action by defining what success looks like and how we'll know when we've achieved it.</p><p>In this edition, I share how I guided Sarah through building the Success Metrics layer of her Data Ecosystem Vision Board:</p><p>✅ Learn how to apply the 5 W's framework to develop focused, impactful KPIs</p><p>✅ Discover how to select organizational health metrics (Data ROI and Data Utilization) that measure overall transformation success</p><p>✅ Master the art of creating clear guiding principles that drive decision-making</p><p>✅ Implement a change management approach that ensures capability adoption and value realization</p><h2>The Metrics That Matter: Beyond Measurement to Action</h2><p>After completing the Future Vision layer with Sarah's team, we needed to establish how success would be measured and how the transformation would be guided. The Success Metrics layer addresses three critical questions:</p><ul><li><p><strong>How will we measure success?</strong>&nbsp;(KPIs)</p></li><li><p><strong>What principles will guide our decisions?</strong>&nbsp;(Guiding Principles)</p></li><li><p><strong>How will we manage the organizational change?</strong>&nbsp;(Change Management)</p></li></ul><p>Based on my implementation experience, I recommend a focused approach with:</p><ul><li><p>A maximum of 6 total KPIs (including 2 core organizational metrics)</p></li><li><p>No more than 6 guiding principles</p></li><li><p>A structured change management plan linked to capability implementation</p></li></ul><p>This deliberate constraint prevents metric proliferation while ensuring comprehensive coverage of what truly matters.</p><h2>The 5 W's Framework for Effective KPIs</h2><p>At the heart of meaningful metrics lies the 5 W's framework, a structured approach to ensure each KPI drives real business value:</p><p>The 5 W's Framework for Effective KPIs: Mapping those KPIs into a simple Excel Table already will give you a better overview and understanding.</p><h3>Why: Understanding the Purpose</h3><p>Every KPI must have a clear purpose: \"<em>We measure [KPI] because it tells us [insight], which helps us achieve [business objective].</em>\"</p><p><strong>Example from 4seconds.com:</strong>&nbsp;\"We measure Inventory Accuracy because it tells us how reliably we can plan and execute flash sales, which helps us maximize revenue and customer satisfaction.\"</p><p>:::tip\n&nbsp;Many organizations struggle with too many metrics rather than too few. Be ruthless in requiring a clear purpose for every KPI, several proposed metrics should be eliminated when teams can't articulate a compelling why.</p><h3>What: Aligning KPIs with Actions</h3><p>KPIs must connect to specific actions: \"<em>When [KPI] [increases/decreases], we [take this action] to [achieve this goal].</em>\"</p><p><strong>Example from 4seconds.com:</strong>&nbsp;\"We measure Campaign Attribution Accuracy because it tells us how effectively we're tracking marketing performance. When it decreases below 85%, we investigate data collection gaps and pipeline issues to ensure marketing investment decisions are based on reliable data.\"</p><p>:::tip\nI&nbsp;The action statement is where many KPIs fall short. By explicitly defining response actions, teams ensure their KPIs drive behavior rather than just measure it.</p><h3>Where: Mapping KPI Impact</h3><p>Document primary impacted teams, in case the KPIs trend changes, who are the teams that influence it, the teams that will feel the pain, and how it relates to what \"When [KPI] [Increases], [Team] [What action needs to happen].</p><p><strong>Example from 4seconds.com:</strong>&nbsp;For \"Data Quality Score\". Primary ownership: Data Engineering; when the quality score goes down, the data team needs to investigate what caused the trend change, and the data producers need to check on their side, whether data flows as expected</p><p>:::tip\n&nbsp;The \"Where\" dimension often reveals unexpected dependencies. When we work with the KPIs, they will have a different impact on different teams. By mapping where a trend change of the KPI influence will help us better understand the impact of the KPI</p><blockquote><p><em>Funny story, once I was with a marketing team that were super happy they managed to reduce the budget spending due to better data on the campaigns performance, on the other side of the room the finance team were freaking out how to explain investors that the company won’t reach the commited marketing budget and how to not lose it for next year</em></p></blockquote><h3>When: The Rhythm of Measurement</h3><p>Set frequency when the KPIs are required, based on how quickly metrics change and how rapidly action can be taken.</p><p><strong>Example from 4seconds.com</strong>: \"Flash Sale Readiness Score\". Calculated daily, reviewed weekly by operations, 48 hours before sales by executives, with 90-day trend analysis and holiday season adjustments.</p><p>:::tip\n&nbsp;Don't default to daily reviews regardless of the metric's natural rhythm. Aligning review cadence with business needs dramatically improves performance.</p><h3>Who: The Keeper of the Metrics</h3><p>Assign clear ownership with both responsibility and authority to influence performance.</p><p><strong>Example from 4seconds.com</strong>: \"Marketing Data Timeliness\", Owner: Marketing Analytics Lead; Contributors: Data Steward, Data Engineer; Stakeholders: CMO, Campaign Managers; Audience: All marketing team, Executive team.</p><p>:::tip\n: Ownership must include authority to drive change. Ensure each KPI owner has both responsibility and authority to influence the metric's performance.</p><h2>Organizational Health Metrics: Data ROI and Data Utilization</h2><h3>The Strategic KPI Portfolio: Six Metrics That Matter</h3><p>The Success Metrics layer accommodates six KPIs maximum, a deliberate constraint that forces strategic focus. Overpopulate with metrics and you lose track of what truly matters; under-populate and you lose visibility into critical areas.</p><p>\\\nMy recommendation follows a proven structure:</p><p><strong>Two Foundation KPIs Data Health Indicators:</strong>&nbsp;These long-term metrics assess the overall health of your data ecosystem:</p><ul><li>: Measures the monetary value generated by your data investments</li><li>: Tracks how effectively you use the data you collect and store</li></ul><p>These foundation KPIs provide your \"vital signs\"; if these trend poorly, your entire data strategy needs attention.</p><p>\\\n<strong>Two to Four Capability KPIs, Progress Trackers</strong>: These metrics measure progress toward the specific capabilities outlined in your Future Vision. They should:</p><ul><li>Connect directly to your vision board priorities</li><li>Enable early identification of implementation issues</li><li>Demonstrate tangible progress toward strategic goals</li><li>Provide clear signals when course correction is needed</li></ul><p><strong>Example from 4seconds.com:</strong>&nbsp;Their capability KPIs included \"Data Pipeline Reliability\" (99.5% uptime target) and \"Self-Service Analytics Adoption\" (60% of business users actively querying data independently).</p><h3>Data ROI: Measuring Value Creation</h3><p>Data ROI measures the financial return generated from data investments. This metric answers the fundamental question: \"Is our data ecosystem creating real business value?\"</p><p>\\\n</p><pre><code>Data ROI = (Financial Value Generated - Cost of Data Operations) / Cost of Data Operations\n\nIf Cost of Data Operations = €100 and Financial Value Generated = €90, then (90−100)/100=−0.10 or -10%.\n</code></pre><ul><li><p><strong>Financial Value Generated</strong>: Quantified benefits from data-driven decisions and automations</p></li><li><p>Tip: Defining \"Financial Value Generated\" Accurately: This is often the trickiest part. Be clear and consistent about what you include. Avoid double-counting or attributing value that isn't directly a result of data operations.</p></li><li><p>: All expenses related to data collection, storage, processing, and analytics</p></li></ul><ul><li><p>Minimum acceptable ROI (typically 0.01-0.7x)</p></li><li><p>Target ROI (typically 0.8-2.5)</p></li><li><p>Stretch ROI (typically 2.6x+)</p></li></ul><ul><li><p>&nbsp;Specify the period over which you are calculating the ROI (e.g., quarterly, annually). Value and costs should align with this timeframe: In our case:</p></li><li><p>Year-over-year trend analysis</p></li><li><p>Breakdown by data domain or capability</p></li></ul><p><strong>Example from 4seconds.com:</strong>&nbsp;After implementing the measurement, their initial Data ROI was 0.2x, barely positive. We set targets of 2x by year-end and 4x within three years. More importantly, we created a detailed tracking mechanism that identified which capabilities were creating the most value and which needed intervention.</p><p>:::tip\n: Sometimes it's useful to compare the \"Financial Value Generated\" with data operations to a hypothetical scenario without them, especially for initiatives aimed at maintaining or improving existing processes.</p><p>&nbsp;Remember that ROI is a quantitative measure. Data initiatives often have significant qualitative benefits (e.g., improved decision-making, better customer experience, innovation) that are harder to directly monetize but are still valuable. Don't let a purely financial ROI be the only factor in assessing data's success.</p><h3>The Real Challenge: What Sarah's Team Discovered</h3><p>When we started calculating Data ROI, Sarah's team hit an immediate roadblock: \"How do we quantify all the income generated by data?\" The challenge was particularly acute with financial data, which is essential but doesn't directly generate ROI.</p><p>\\\nWe had to evolve our approach:</p><ol><li><p><strong>\"Must Have\" Data Exclusion</strong>: We classified essential data like financial data, compliance data, and operational data as \"must have\" and excluded them from ROI calculations. But we needed to tag it properly so this wouldn't become a manual process.</p></li><li><p><strong>Tagging System Implementation</strong>: We created a comprehensive tagging system to automatically categorize data by its business purpose:</p></li><li><p>Must-have/compliance data</p></li><li><p>: For every significant data-driven decision or automation, we implemented a value tracking system where stakeholders estimated the business impact, and when possible we created automatic process, for example in the marketing campaigns we identified the campaigns we optimized and they stopped spending budget on bad traffic and accomilated it, and when increased we mark it as value created.</p></li></ol><p>:::tip\n: Many organizations struggle to quantify value from data initiatives. I worked with Sarah to implement a value tracking system where every significant data-driven decision or automation had an estimated value attached. While not perfect, this approach provided a foundation for measuring return that was far better than no measurement at all. Just start with what you have and slowly learn more and improve; stakeholders will wish to be included in the calculation as they fear they may lose access to the data due to low ROI.</p><h3>Data Utilization: Measuring Effective Usage</h3><p>Data Utilization measures how effectively your organization leverages the data it collects. This metric addresses another critical question: \"Are we making the most of our data assets?\"</p><p>\\\n</p><pre><code>Data Utilization = Data Assets Actively Used / Total Data Assets Collected\n\n* Over a fixed period, in our case it was three months, but in bigger organizations I used six months timeframe\n</code></pre><ul><li><strong>Data Assets Actively Used</strong>: Data elements used in reports, analyses, or automated processes</li><li><strong>Total Data Assets Collected</strong>: All data elements stored in your data ecosystem</li></ul><ul><li>Minimum acceptable utilization (typically 55-60%)</li><li>Target utilization (typically 61-78%)</li><li>Stretch utilization (typically 79%+)</li></ul><ul><li><p>Breakdown by data domain or system, as well as team/user, if possible</p></li></ul><h3><strong>Sarah's Big Discovery: The Data Utilization Reality Check</strong></h3><p>The biggest \"aha moment\" for me was discovering that no one in the company was thinking about understanding the patterns of data usage, although they were associating some costs with teams, they accepted the server bill as a given thing. For Sarah and her team, it was the shocking discovery of their super low data usage – they had always been under the impression they were effectively using their data.</p><p>\\\n: When we tried to implement Data Utilization tracking, we immediately hit a wall. There were no tags, no database collecting logs (Data Catalog) and information, and no way to track what data they had, who owned it, when it was accessed, or by what system. We couldn't follow the lineage.</p><p>\\\n&nbsp;We had to start from scratch:</p><ol><li><p><strong>Activity Logging Database</strong>: Created a comprehensive system to log all data interactions, creating a data catalog</p></li><li><p>: Mapped every dataset to an owner and purpose</p></li><li><p>: Implemented monitoring to see which data was being used and when</p></li><li><p>: Built systems to track data flow from source to consumption</p></li></ol><p>:::info\n&nbsp;Sarah's initial calculation revealed only 48% utilization of their 32TB of stored data. This led to a massive data rationalization initiative that not only reduced storage, processing, and security costs by over €1,000 monthly but also focused analytics efforts on high-value data.</p><ul><li><p><strong>Low utilization is common</strong>&nbsp;and often hidden. At another client, I discovered they were storing over 200 website behavioral events but only using 8 in any decision-making process. The cost of collecting and storing unused data was substantial, and the unnecessary complexity slowed down legitimate analytics. By implementing utilization measurement, Sarah's team gained visibility into this previously hidden issue.</p></li><li><p>&nbsp;helps a lot when coming to investigate it, the ability to identify who owns it, what exactly it is, and creating a process that logs this information into some database was super helpful. This practice is not common and should be encouraged even more</p></li><li><p>While maybe storing 32TB is only $700,&nbsp;<strong>the backup, moving of data, security… costs money</strong>, it top it to over $1,000 a months or even more, if only 50% is used, it's good thing to ask Why do we keep the data, and can we move it to some lower costs long terming plan</p></li><li><p>&nbsp;moved into a long-term container, which is extended twice, each with a six-month long-term plan, and if is not required can be deleted by the end period of the second extension, if it's not data the company is obligated to store, such as financial or user health data. Think about this process as well</p></li><li><p><strong>Always set a data retention plan</strong>. I will deep dive into it in Data Flavors issue #15, covering a few methods, and my view on it.</p></li></ul><h2>Supporting KPIs: Measuring Capability Success</h2><p>In addition to the two organizational health metrics, I helped Sarah select a maximum of four supporting KPIs that would track the success of their key capabilities:</p><p>To avoid KPI proliferation, I guided Sarah through a structured selection process:</p><ol><li>For each Future Vision capability, identify 2-3 potential success metrics</li><li>Apply the 5 W's framework to each candidate metric</li><li>Evaluate candidates based on:</li></ol><ul><li>&nbsp;(how broadly applicable across capabilities)</li><li>&nbsp;(how feasible to track consistently)</li><li>&nbsp;(how it drives specific behaviors)</li><li>&nbsp;(how directly it connects to business outcomes)</li></ul><ol><li>Select the 3-4 metrics with the highest evaluation scores</li></ol><p>:::tip\n: This rigorous selection process is crucial. At previous clients, I've seen metrics chosen based on what's easy to measure rather than what drives value. By focusing on coverage, measurability, actionability, and impact, Sarah's team ensured they selected metrics that would genuinely guide their transformation.</p><p>For 4seconds.com, the supporting KPIs included:</p><ul><li>: Accuracy, completeness, timeliness, and consistency of key data domains</li><li>: Directly impacts decision quality and operational efficiency. The vision was to include more marketing data to steer campaigns automatically, and bad data could cause a loss</li><li>: Below 90% triggers remediation; below 80% triggers emergency review</li><li>: Composite score across data quality dimensions and domains</li></ul><p>\\\n<strong>Marketing campaigns automated</strong></p><ul><li>: The share of marketing campaigns generated by smart systems and not humans</li><li>: The goal is to automate the effort of the marketers and remove the need for agencies to support them. With the system, the marketing team can focus on the high-effort campaigns and let the system set and optimize the rest</li><li>: If the share is below 65%, the capability is not acting as expected; if it's under 35%, the capability is causing issues that may damage the marketing team</li><li>: Average time across key business decisions</li></ul><ul><li>: Percentage of analytics requests fulfilled through self-service</li><li>: Indicates democratization progress and analyst leverage</li><li>: Below target triggers enablement review; stagnation triggers capability assessment</li><li>: Self-service requests / Total analytics requests</li></ul><ul><li><p>: Organization-wide data skills and confidence</p></li><li><p>: Foundation for a data-driven culture</p></li><li><p>: Skill gaps trigger targeted training; confidence gaps trigger communication initiatives</p></li><li><p>: Composite score from skills assessment and confidence survey</p></li></ul><h3>The Marketing Automation Story: KPIs as Capability Guardians</h3><p>Let me share the story behind the \"Marketing campaigns automated\" KPI, which became one of Sarah's most valuable metrics.</p><p>\\\nSarah's team had set an ambitious goal: automate 80% of campaign budget steering decisions and 60% of campaign creation. This wasn't just about efficiency; with the hiring freeze, they needed to increase the marketing budget to generate 10% revenue growth without adding staff.</p><p>\\\n&nbsp;The marketing team was terrified. Would they lose their jobs to automation?</p><p>: We positioned this as an enhancement, not a replacement. The KPI measured progress, but more importantly, it tracked whether the automation was helping or hurting campaign performance.</p><p>\\\n<strong>On the Company Core Dashboard:</strong>&nbsp;They tracked two connected KPIs:</p><ul><li><p><strong>Marketing campaigns automated</strong>&nbsp;(% of campaigns managed by AI)</p></li><li><p><strong>Revenue estimated from marketing campaigns</strong>&nbsp;(should stay stable or increase as automation progresses)</p></li></ul><p>These twin KPIs became powerful indicators of both capability development and the collaborative effort between the data team and the marketing team. When the automation percentage went up but revenue estimates stayed flat, it showed the system was learning. When both went up together, it proved that the capability was delivering real value.</p><p>:::tip\n&nbsp;Each supporting KPI should connect to multiple capabilities rather than tracking a single initiative. This provides broader coverage with fewer metrics. Sarah's initial list had 12 potential KPIs, but by focusing on metrics that spanned multiple capabilities, we achieved comprehensive coverage with just four.</p><h2>Guiding Principles: The North Star for Decisions</h2><blockquote><p><em>I must admit that the below method I copied from my agile coaches at Zalando, they did such an awesome job, so I never felt a need to change it</em></p></blockquote><p>\\\nBeyond metrics, I worked with Sarah to establish clear guiding principles for their data ecosystem. These principles guide day-to-day decisions and help resolve conflicts or ambiguities.</p><h3><strong>Principles Development Process</strong></h3><p>To create meaningful principles, I facilitated a structured process:</p><ul><li>Review workshop notes for recurring themes</li><li>Identify current implicit principles (what guides decisions today)</li><li>Collect stakeholder perspectives on what should guide the future</li></ul><p><strong>Draft Candidate Principles:</strong></p><ul><li>Focus on areas where guidance is most needed</li><li>Ensure principles address both technical and cultural aspects</li><li>Frame positively as aspirational statements</li><li>Keep language simple and memorable</li></ul><ul><li>Test each principle against real-world scenarios</li><li>Ensure principles are specific enough to guide decisions</li><li>Eliminate overlap and redundancy</li><li>Limit to a maximum of six principles</li></ul><ul><li>Create clear definitions for each principle</li><li>Develop examples of applications</li><li>Document decision hierarchy when principles conflict</li><li>Create a communication and socialization plan</li></ul><p>:::tip\n&nbsp;Principles should be actionable, not aspirational platitudes. During our drafting session, I challenged every principle with, \"How would this help you make a different decision?\" If we couldn't identify specific scenarios where the principle would guide behavior, we refined or replaced it.</p><p>After this process, Sarah's team established these six principles:</p><ul><li>: Every dataset is treated as a product with clear ownership, quality standards, an iteration process, monetary value, and user support</li><li>: New data sources require defined ownership and quality metrics before implementation</li><li>: Quality and reliability take precedence over speed of delivery</li></ul><ul><li>: All non-sensitive data should be discoverable and accessible across the organization, and documented in the company’s data catalog</li><li>: Departmental datasets are published to the central catalog automatically</li><li>&nbsp;guidance: Access restrictions require explicit justification</li></ul><ul><li>: Data initiatives are prioritized based on measurable business impact</li><li>: All project proposals include the estimated monetary value</li><li>: Higher-impact initiatives take precedence over technically interesting ones</li></ul><ul><li>: Manual data tasks should be automated to free human capacity for insight generation</li><li>: Any report produced more than twice is automated</li><li>: Invest in the automation of repetitive tasks over manual optimization</li></ul><p><strong>Right-time, Not Always Real-time</strong></p><ul><li><p>: Data timeliness should match business need, not default to the most frequent possible</p></li><li><p>: Daily aggregation for metrics that drive weekly decisions</p></li><li><p>: Performance and cost efficiency over unnecessary immediacy</p></li></ul><p>: Data systems and processes should build confidence through transparency and reliability, and be proactive in communicating issues</p><p>\\\n: Quality metrics are visible alongside all reports</p><p>: Transparency about limitations of exaggerated capabilities</p><p>Of all the principles Sarah's team adopted, \"Business Impact First\" created the most profound change. Here's how it played out in practice:</p><p>: When evaluating two competing capabilities, self-service analytics vs. marketing automation, the teams initially argued based on technical preferences and departmental needs.</p><p>: We applied \"Business Impact First\" and calculated the monetary value for each option:</p><ul><li><p>Self-service analytics: €45,000 annual savings in analyst time</p></li><li><p>Marketing automation: €120,000 annual revenue increase potential</p></li></ul><p>: The principle guided them to prioritize marketing automation, but more importantly, it changed how they approached all future decisions. Teams started thinking in terms of business value rather than technical elegance.</p><p>:::tip\n: Principles should reflect both aspirations and practical constraints. At a previous client, I established \"real-time everything\" as a principle without considering cost implications. This led to overinvestment in infrastructure that provided minimal business value. I helped Sarah's team find the right balance with principles like \"Right-time, Not Always Real-time\" that acknowledged practical limitations while still providing clear guidance.</p><h2>Socializing Principles: Making Them Stick</h2><p>&nbsp;We communicated the principles at an all-hands meeting, created a board, and invited people to react and suggest ways they can execute the principles. During the session, we explained that we had already experienced them during the workshops for the future layer, and some had emerged through the present layer discovery process.</p><p>\\\n: We agreed that the principles would be tested for the next six months and could be re-evaluated for their fit with organizational culture and usage. This made them \"fixed but temporary,\" giving everyone time to get used to them while providing a clear path to refer back to them when decisions got complex.</p><p>\\\n&nbsp;Making principles \"fixed but temporary\" reduced resistance and permitted people to experiment with using them as decision-making tools.</p><h2>Change Management: Ensuring Adoption and Value</h2><p>Introducing new data capabilities isn't just about tools, it’s about changing how people work, think, and decide. Together with Sarah, we developed a change management approach focused on three pillars: Impact, Adoption, and Learning.</p><p>We began with a&nbsp;&nbsp;to map how different teams would be affected:</p><ul><li><p>Stakeholders: Users, data producers, indirect roles, and leadership</p></li><li><p>Impacts: Process, skills, tools, mindset, decision-making</p></li><li><p>Marketing: High impact – full shift in workflows</p></li><li><p>Finance: Medium – new sources, familiar processes</p></li><li><p>Product: Low – minimal change</p></li></ul><p>:::tip\n: Even small changes, like a dashboard redesign, can deeply affect workflows if not planned properly.</p><p>Each capability had its own Adoption Plan, focused on success metrics, barriers, and rollout strategy:</p><ul><li><p>Success Criteria: Usage frequency, efficiency gains, adoption timeline</p></li><li><p>Adoption Strategy: Comms, training, support, incentives</p></li><li><p>Example (4seconds.com - Self-Service Analytics):</p></li><li><p>Goal: 60% report access via self-service in 6 months</p></li><li><p>Barriers: Low trust, data literacy gaps</p></li></ul><p>&nbsp;Champion program + workshops + office hours</p><p>:::tip\n: Adoption needs more than training. Address trust, habits, and emotional resistance head-on.</p><p>Capability adoption required skill growth across the board:</p><ul><li><p>Data Team: Learned marketing workflows and how to talk about business value</p></li><li><p>Marketing Team: Learned how to guide automation and work with data tools</p></li><li><p>Executives: Shifted from urgent demands to structured prioritization</p></li></ul><p>: Role-based learning paths, on-demand resources, real-data challenges</p><p>\\\n: 4seconds.com’s Data Literacy Program included biweekly sessions, hands-on challenges, and a Slack channel for peer support.</p><p>:::tip\n: Generic training doesn’t stick; contextualize learning around real company problems.</p><p>We built a structured communication strategy to maintain momentum:</p><ul><li><p>Messaging: Why, what’s changing, what’s in it for each team</p></li><li><p>Channels: All-hands, newsletters, Slack, dashboards</p></li><li><p>Cadence: Weekly for involved teams, monthly org-wide, quarterly execs</p></li><li><p>Transformation dashboard (in-office + intranet)</p></li></ul><p>:::tip\n: Regular, visible communication builds trust. Irregular updates kill momentum.</p><h2>Maintaining the Success Metrics Layer</h2><p>Once Sarah had her Success Metrics in place, the next step was making sure they stayed useful over time.</p><p>We set up a lightweight, recurring review cycle:</p><ul><li><p>: Are metrics on target? What trends are emerging? Any surprising correlations?</p></li><li><p>: Are these KPIs still tied to business goals? Are people using them? Is the data still solid?</p></li><li><p>: Tweak thresholds or calculations if needed. If a metric hasn’t driven a decision in 6 months, it might be time to retire it.</p></li></ul><p>:::tip\n: At another company, I saw metrics tracked long past their relevance, cluttering dashboards and wasting time. Sarah introduced a “sunset protocol” to avoid that.</p><p>Every year, I recommend a full refresh of the Vision Board; however, for the first time, it’s better to do it quarterly until you get into the rhythm and learn the system:</p><ul><li>: Where are we now vs. when we started? What’s improved? What’s still missing?</li><li>: Do we need new capabilities? Has our strategy changed?</li><li>: Are KPIs still telling the right story? Are principles still actionable?</li><li>: Exec sessions, team updates, company-wide refresh, and space for feedback.</li></ul><p>&nbsp;At 4seconds.com, Sarah ran a compressed workshop to refresh their board exactly one year in. It helped the team celebrate wins, update priorities, and refocus for the next phase.</p><h2>Tying the Vision Together</h2><p>Once the Success Metrics were live, all three layers of the Vision Board came together:</p><ul><li><p>&nbsp;set the baseline</p></li><li><p>&nbsp;defined what needed to change</p></li><li><p>&nbsp;showed if progress was being made</p></li></ul><p>Each layer feeds the others in a cycle:</p><ul><li><p>Metrics track movement from present → future</p></li><li><p>Gaps in the present inform future priorities</p></li><li><p>The future vision tells us which metrics matter most</p></li></ul><p>Without this integration, I used to get stuck with clients, using metrics disconnected from strategy. Sarah avoided that by reviewing how each layer linked together.</p><p>:::tip\n: The Vision Board's power comes from this integration. When a client implemented only parts of the framework, they lost the holistic view needed for effective transformation. I helped Sarah ensure all three layers worked together by regularly reviewing the connections between them.</p><p>To keep the Vision Board top-of-mind, Sarah made it accessible at every level:</p><ul><li><p>Digital Board in FigJam, updated regularly and shared with stakeholders</p></li><li><p>Exec Dashboard: One-pager with key KPIs and decisions, updated monthly</p></li><li><p>Team Views: Tailored summaries for departments with relevant metrics</p></li><li><p>Office Display: A simplified, visual tracker showing progress and celebrating wins</p></li></ul><p><strong>Example from 4seconds.com</strong>: Sarah created a \"Data Transformation Hub\" in their office with physical and digital components. This central reference point kept the Vision Board visible and top-of-mind throughout the organization, reinforcing its importance to their strategy.</p><p>:::tip\n: Visibility drives accountability. At a previous client, their vision document was filed away after creation and quickly forgotten. By making the Vision Board highly visible in multiple formats, Sarah ensured it remained an active guide for day-to-day decisions rather than a forgotten artifact.</p><p>For smaller teams, I usually recommend simplifying:</p><ul><li><p>Stick to 2 org-wide KPIs (like Data ROI and Utilization) and maybe 2-3 supporting ones.</p></li><li><p>Manual tracking is fine. Focus on direction, not perfection.</p></li><li><p>Don’t reinvent the wheel. Add a metrics check-in to existing leadership meetings.</p></li><li><p>Targeted Change Management</p><p>Focus on influencers, decision-makers, and power users, not everyone at once.</p></li></ul><p>\\\nThis targeted approach maximizes impact with limited resources. For their Self-Service Analytics capability, Sarah identified 8 \"power users\" across departments who, if successfully converted, would influence 80% of potential users.</p><h2>Exercise: Your 30-Minute Success Metrics Starter</h2><p>Objective: Begin defining the KPIs and principles for your Data Ecosystem Vision Board.</p><ul><li><p>Identify your two most important organizational data health metrics (10 minutes)</p></li><li><p>For each one, define why you're measuring it and what actions you'll take based on trend changes</p></li><li><p>Draft 2-3 guiding principles (10 minutes)</p></li></ul><p>That would help your organization make better data decisions</p><ul><li>Plan one capability adoption (10 minutes)</li><li>For one key future capability, identify what would constitute success beyond just implementation</li></ul><ol><li>Which of the 5 W's (Why, What, Where, When, Who) do you find most challenging to define clearly?</li><li>How might the \"Business Impact First\" principle change how your organization evaluates data initiatives?</li><li>What organizational changes would be required to successfully implement a Success Metrics layer?</li></ol><p>This concludes our implementation series on the Data Ecosystem Vision Board. In future newsletters, I'll explore how to operationalize your Vision Board through yearly strategic planning, initiative management, and continuous improvement. Thank you for joining me on this journey!</p><p>\\\nThrough these actions, Sarah began transforming the Vision Board from strategy to reality – a journey that would unfold over the coming months and years as 4seconds.com built the data ecosystem needed to support their business goals.</p><p>May your data flow with purpose!</p><p>\\\n<strong>P.S. What's your biggest challenge in measuring data transformation success? Reply to this email, and I'll personally share insights from my experience working with companies like yours.</strong></p>","contentLength":31917,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Large Language Models Are Improving Exponentially","url":"https://spectrum.ieee.org/large-language-model-performance","date":1751464804,"author":"Glenn Zorpette","guid":180433,"unread":true,"content":"<p>In a few years, AI could handle complex tasks with ease</p>","contentLength":55,"flags":null,"enclosureUrl":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MTEzNzkxMi9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc4MDU4NzgyMH0.f77AAmLqqykTnBa8ZR6LMN1AOfa1crWhXsqNVd5BixU/image.png?width=600","enclosureMime":"","commentsUrl":null},{"title":"Real Python: Python 3.14 Preview: Template Strings (T-Strings)","url":"https://realpython.com/python-t-strings/","date":1751464800,"author":"","guid":180550,"unread":true,"content":"<p>Python 3.14’s t-strings allow you to intercept and transform input values before assembling them into a final representation. Unlike f-strings, which produce a  object, t-strings resolve to a  instance, allowing you to safely process and customize dynamic content.</p><p>One of the key benefits of t-strings is their ability to help prevent security vulnerabilities like SQL injection and XSS attacks. They’re also valuable in other fields that rely on string templates, such as structured logging.</p><p><strong>By the end of this tutorial, you’ll understand that:</strong></p><ul><li>Python  are a generalization of f-strings, designed to safely handle and process .</li><li>The  of a t-string include  parts and , which are accessible through the  class.</li><li>You process t-strings by iterating over their components, using attributes such as , , and  for safe and customized handling.</li></ul><p>Python t-strings enhance both security and flexibility in string processing tasks. This tutorial will guide you through understanding t-strings, comparing them with f-strings, and exploring their practical use cases in Python programming.</p><div><p> Test your knowledge with our interactive “Python 3.14 Preview: Template Strings (T-Strings)” quiz. You’ll receive a score upon completion to help you track your learning progress:</p></div><h2>Exploring String Templates Before Python 3.14</h2><p>Creating string templates that you can populate with specific values dynamically is a common requirement in programming. A  is a string that contains placeholders—special markers representing variable values—that you can dynamically replace at runtime.</p><p>You’ll often use templates to generate text or structured content by filling these placeholders with actual data. Before Python 3.14, the language provided several tools that allowed you to interpolate and format values in your strings:</p><p>You can use all these tools to create and process string templates. Of course, each has its own unique strengths and weaknesses.</p><p>The string formatting operator (), inspired by C’s <a href=\"https://en.wikipedia.org/wiki/Printf\"></a> syntax, is the oldest string formatting and interpolation tool in Python. Here’s a quick example of how you can use this operator to create and process templates:</p><p>In this example, you have two variables containing data. The first contains a string, and the second holds an integer value. Then, you define a string template using the  and  syntax to define  or . The  means that the first field must be filled with a string, and the  indicates that the field accepts decimal integer values. These are known as <a href=\"https://realpython.com/python-modulo-string-formatting/#convert-values-using-a-conversion-type\">conversion types</a>.</p><p>Finally, you use the  operator to dynamically interpolate the variables’ content into the template and build a new string.</p><p>This operator also allows you to apply formatting rules to the input values. For example, here’s how you can format currency values:</p><p>In this example, the template contains the literal dollar sign () to indicate that the formatted value represents a USD amount. The  character is not part of the formatting syntax itself but part of the output.</p><p>Then, you have a replacement field that starts with the string formatting operator () followed by the string . This string is a  that formats any input number as a floating-point value with a precision of two digits.</p><p>You can format a string inline using the  operator by passing the values directly. This approach combines the template and the data in a single step, but it doesn’t allow you to reuse the template later on:</p><p>When you have a complex template, the string formatting operator’s syntax can become cumbersome and hard to read:</p>","contentLength":3515,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hacked, leaked, exposed: Why you should never use stalkerware apps","url":"https://techcrunch.com/2025/07/02/hacked-leaked-exposed-why-you-should-stop-using-stalkerware-apps/","date":1751464800,"author":"Lorenzo Franceschi-Bicchierai","guid":180543,"unread":true,"content":"<article>\nUsing stalkerware is creepy, unethical, potentially illegal, and puts your data and that of your loved ones in danger.</article>","contentLength":119,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Azure API vulnerability and roles misconfiguration compromise corporate networks","url":"https://www.token.security/blog/azures-role-roulette-how-over-privileged-roles-and-api-vulnerabilities-expose-enterprise-networks","date":1751464795,"author":"ArielSimon","guid":181176,"unread":true,"content":"<p>Token Security researchers have discovered several Azure built-in roles that are misconfigured to be over-privileged - they grant more permissions than intended by Azure.In addition, we discovered another vulnerability in the Azure API that allows attackers to .</p><p>Combined, these two issues create a new attack chain that lets a <strong>weak user gain access to both internal cloud assets and on-premises networks.</strong></p><p>In this report, we detail the research process that led to the discoveries, their implications, and what organizations can do to stay safe against these threats and other identity-driven attacks.</p><p>Before jumping in, let’s discuss some basics.Azure’s permissions model, Azure RBAC (Role-Based Access Control), is, as the name states, based on roles.<p>Roles are basically groups of permissions that can be assigned to principals (users, service principals, groups, etc). When granting a role to a principal, you create a </p>Every  contains three main components:</p><ol role=\"list\"><li> - Who is given the permissions?</li><li> - Which role is assigned? What permissions does it grant? This section states the name of the role and the  and  (allow or deny) that this role is granting.</li><li> - What resources is the principal given access to? The scope can be vast, such as an entire management group or subscription, or more specific, like a resource group or a single resource (e.g., a specific VM or storage account).</li></ol><p>In Azure, there are more than 400 built-in roles, which can be divided into 2 categories:</p><ol role=\"list\"><li> - Roles that grant permissions that apply across all resources and all Azure services in the given scope (e.g., <strong>, , ,</strong> etc.</li><li> - Roles that grant permissions for a specific service or function in the given scope (e.g., <strong><em>Virtual Machine Contributor</em></strong>).</li></ol><p>If you assign the  role over a subscription scope, it will grant permissions to perform actions over all of the resources in this subscription, regardless if they’re storage accounts, virtual machines, or any other resource. But if you assign the <strong><em>Virtual Machine Contributor</em></strong>, it will grant these permissions only to perform actions over virtual machines in the subscription.So we can see the tradeoff here: using service-specific roles is the more secure approach, since you are granting fewer permissions, but the generic roles are easier to use since you need to manage fewer roles assignments.</p><p>Let’s take a look at few roles and their permissions. See if you can tell where things go wrong.</p><p>One of Azure’s built-in roles, called  is a generic role. As you’d expect, it gives read-only permissions over the resources in the chosen scope. Let’s examine its :</p><div><figure><pre><code>\n{\n  \"assignableScopes\": [\n    \"/\"\n  ],\n  \"description\": \"View all resources, but does not allow you to make any changes.\",\n  \"id\": \"/providers/Microsoft.Authorization/roleDefinitions/acdd72a7-3385-48ef-bd42-f606fba81ae7\",\n  \"name\": \"acdd72a7-3385-48ef-bd42-f606fba81ae7\",\n  \"permissions\": [\n    {\n      \"actions\": [\n        \"*/read\"\n      ],\n      \"notActions\": [],\n      \"dataActions\": [],\n      \"notDataActions\": []\n    }\n  ],\n  \"roleName\": \"Reader\",\n  \"roleType\": \"BuiltInRole\",\n  \"type\": \"Microsoft.Authorization/roleDefinitions\"\n}\n</code></pre></figure></div><p>As we can see in the  property, the permission given is , which means it lets you perform any read action in the given scope.</p><p>*Note that this does not include data actions (reading data objects like files in storage accounts, key vault secrets, etc). Those require different, service-specific sensitive permissions.</p><p>Okay, so a generic role giving generic read permissions, that makes sense.What about the permissions of service-specific roles?</p><div><figure><pre><code>\n{\n  \"assignableScopes\": [\n    \"/\"\n  ],\n  \"description\": \"Can read workbooks.\",\n  \"id\": \"/providers/Microsoft.Authorization/roleDefinitions/b279062a-9be3-42a0-92ae-8b3cf002ec4d\",\n  \"name\": \"b279062a-9be3-42a0-92ae-8b3cf002ec4d\",\n  \"permissions\": [\n    {\n      \"actions\": [\n        \"microsoft.insights/workbooks/read\",\n        \"microsoft.insights/workbooks/revisions/read\",\n        \"microsoft.insights/workbooktemplates/read\"\n      ],\n      \"notActions\": [],\n      \"dataActions\": [],\n      \"notDataActions\": []\n    }\n  ],\n  \"roleName\": \"Workbook Reader\",\n  \"roleType\": \"BuiltInRole\",\n  \"type\": \"Microsoft.Authorization/roleDefinitions\"\n}\n</code></pre><figcaption>Workbook Reader role definition</figcaption></figure></div><p>If we analyze the  property, we can see that as the description states, it grants read permissions to a few workbook-related objects. So a service-specific role that grants access to a specific service! So far so good.</p><h3><strong>Managed Applications Reader</strong></h3><p>Now, let’s check the <strong><em>Managed Applications Reader</em></strong> role, which its description is <strong>“Lets you read resources in a managed app and request JIT access.”</strong></p><div><pre><code>\n{\n  \"assignableScopes\": [\n    \"/\"\n  ],\n  \"description\": \"Lets you read resources in a managed app and request JIT access.\",\n  \"id\": \"/providers/Microsoft.Authorization/roleDefinitions/b9331d33-8a36-4f8c-b097-4f54124fdb44\",\n  \"name\": \"b9331d33-8a36-4f8c-b097-4f54124fdb44\",\n  \"permissions\": [\n    {\n      \"actions\": [\n        \"Microsoft.Resources/deployments/*\",\n        \"Microsoft.Solutions/jitRequests/*\",\n        \"*/read\"\n      ],\n      \"notActions\": [],\n      \"dataActions\": [],\n      \"notDataActions\": []\n    }\n  ],\n  \"roleName\": \"Managed Applications Reader\",\n  \"roleType\": \"BuiltInRole\",\n  \"type\": \"Microsoft.Authorization/roleDefinitions\"\n}\n</code></pre></div><p>We can see it has access to deployments, jitRequests, and… So this role, which is supposed to grant access to read managed apps and JIT access, actually also allows the user to read every Azure resource?This is clearly not what the description says, and certainly not what someone assigning the <strong><em>Managed Applications Reader</em></strong> role would expect.</p><p><strong>Essentially, the role’s name and description are misleading the user into thinking the role grants specific permissions, when in fact it grants generic permissions to every resource.</strong></p><p>I saw this and thought to myself, okay, this is just a read permission... how bad can it be?Well, I was seriously wrong.</p><p>Let’s dive into what we can actually do with this permission and how can it be useful for an attacker.</p><p>Since there are so many actions possible here, I divided them into three categories and gave some examples for each.</p><ul role=\"list\"><li><strong>Automation Accounts, Deployment scripts, Web applications</strong> - This one really surprised me: this permission actually allows you to read source code and environment variables of scripts and applications. The common thing among the three services I listed here, is that they all interact with your environment, <strong>which makes them very likely to contain credentials and secrets!</strong></li></ul><p>:</p><ul role=\"list\"><li><strong>Storage accounts, container registries, databases</strong> - Enumerating all instances and their metadata to find sensitive data spots</li><li> - Helps identify resources that are considered critical or sensitive</li><li> - Find DB exports, storage account backups and more</li></ul><ul role=\"list\"><li> - Know about who can access what. Useful for planning privilege escalation paths</li><li><strong>Diagnostics settings, alerts, and log analytics workspaces</strong> - Know what is being logged, and where, and view security alerts. Useful for OpSec and detection avoidance</li><li><strong>Network configurations, network security groups, public IPs, virtual network gateways</strong> - Further plan attack paths and network advancements</li><li> - Listing all vaults and their metadata</li></ul><p>So you might think to yourself - Okay that’s cool… but I don’t use the <strong>Managed Applications Reader</strong> role, so I am safe, right?Well, think again.</p><p>After analyzing all Azure built-in roles, I found that this problem (having an un-needed  permission, basically including the  role) recurs in </p><div><div><table><tbody><tr><td><div>\nMicrosoft.OperationalInsights/workspaces/analytics/query/action <p>\nMicrosoft.OperationalInsights/workspaces/search/action</p>\nMicrosoft.Support/*\n</div></td></tr><tr><td>Log Analytics Contributor</td><td><div>\nMicrosoft.ClassicCompute/virtualMachines/extensions/*<p>\nMicrosoft.ClassicStorage/storageAccounts/listKeys/action</p>\nMicrosoft.Compute/virtualMachines/extensions/*</div><div>\nMicrosoft.HybridCompute/machines/extensions/write\nMicrosoft.Insights/alertRules/*<p>\nMicrosoft.Insights/diagnosticSettings/*</p>\nMicrosoft.OperationalInsights/*<p>\nMicrosoft.OperationsManagement/*</p>\nMicrosoft.Resources/deployments/*<p>\nMicrosoft.Resources/subscriptions/resourcegroups/deployments/*</p>\nMicrosoft.Storage/storageAccounts/listKeys/action</div></td></tr><tr><td>App Compliance Automation Administrator</td><td><div>\nMicrosoft.AppComplianceAutomation/*<p>\nMicrosoft.Storage/storageAccounts/blobServices/write</p>\nMicrosoft.Storage/storageAccounts/fileservices/write</div><div>\nMicrosoft.Storage/storageAccounts/listKeys/action\nMicrosoft.Storage/storageAccounts/write<p>\nMicrosoft.Storage/storageAccounts/blobServices/generateUserDelegationKey/action</p>\nMicrosoft.Storage/storageAccounts/read<p>\nMicrosoft.Storage/storageAccounts/blobServices/containers/read</p>\nMicrosoft.Storage/storageAccounts/blobServices/containers/write<p>\nMicrosoft.Storage/storageAccounts/blobServices/read</p>\nMicrosoft.PolicyInsights/policyStates/queryResults/action<p>\nMicrosoft.PolicyInsights/policyStates/triggerEvaluation/action</p>\nMicrosoft.Resources/resources/read<p>\nMicrosoft.Resources/subscriptions/read</p>\nMicrosoft.Resources/subscriptions/resourceGroups/read<p>\nMicrosoft.Resources/subscriptions/resourceGroups/resources/read</p>\nMicrosoft.Resources/subscriptions/resources/read<p>\nMicrosoft.Resources/subscriptions/resourceGroups/delete</p>\nMicrosoft.Resources/subscriptions/resourceGroups/write<p>\nMicrosoft.Resources/tags/read</p>\nMicrosoft.Resources/deployments/validate/action<p>\nMicrosoft.Security/automations/read</p>\nMicrosoft.Resources/deployments/write<p>\nMicrosoft.Security/automations/delete</p>\nMicrosoft.Security/automations/write<p>\nMicrosoft.Security/register/action</p>\nMicrosoft.Security/unregister/action</div></td></tr><tr><td>App Compliance Automation Reader</td></tr><tr><td>Managed Application Contributor Role</td><td><div>\nMicrosoft.Solutions/applications/*<p>\nMicrosoft.Solutions/register/action</p>\nMicrosoft.Resources/subscriptions/resourceGroups/*</div><div>\nMicrosoft.Resources/deployments/*</div></td></tr><tr><td>Managed Application Operator Role</td><td><div>\nMicrosoft.Solutions/applications/read<p>\nMicrosoft.Solutions/*/action</p></div></td></tr><tr><td>Managed Application Operator Role</td><td><div>\nMicrosoft.Solutions/applications/read<p>\nMicrosoft.Solutions/*/action</p></div></td></tr><tr><td>Managed Applications Reader</td><td><div>\nMicrosoft.Resources/deployments/*<p>\nMicrosoft.Solutions/jitRequests/*</p></div></td></tr><tr><td><div>\nMicrosoft.AlertsManagement/alerts/*<p>\nMicrosoft.AlertsManagement/alertsSummary/*</p>\nMicrosoft.Insights/actiongroups/*</div><div>\nMicrosoft.Insights/activityLogAlerts/*\nMicrosoft.Insights/AlertRules/*<p>\nMicrosoft.Insights/components/*</p>\nMicrosoft.Insights/createNotifications/*<p>\nMicrosoft.Insights/dataCollectionEndpoints/*</p>\nMicrosoft.Insights/dataCollectionRules/*<p>\nMicrosoft.Insights/dataCollectionRuleAssociations/*</p>\nMicrosoft.Insights/DiagnosticSettings/*<p>\nMicrosoft.Insights/eventtypes/*</p>\nMicrosoft.Insights/LogDefinitions/*<p>\nMicrosoft.Insights/metricalerts/*</p>\nMicrosoft.Insights/MetricDefinitions/*<p>\nMicrosoft.Insights/Metrics/*</p>\nMicrosoft.Insights/notificationStatus/*<p>\nMicrosoft.Insights/Register/Action</p>\nMicrosoft.Insights/scheduledqueryrules/*<p>\nMicrosoft.Insights/webtests/*</p>\nMicrosoft.Insights/workbooks/*<p>\nMicrosoft.Insights/workbooktemplates/*</p>\nMicrosoft.Insights/privateLinkScopes/*<p>\nMicrosoft.Insights/privateLinkScopeOperationStatuses/*</p>\nMicrosoft.Monitor/accounts/*<p>\nMicrosoft.OperationalInsights/workspaces/write</p>\nMicrosoft.OperationalInsights/workspaces/intelligencepacks/*<p>\nMicrosoft.OperationalInsights/workspaces/savedSearches/*</p>\nMicrosoft.OperationalInsights/workspaces/search/action<p>\nMicrosoft.OperationalInsights/workspaces/sharedKeys/action</p>\nMicrosoft.OperationalInsights/workspaces/storageinsightconfigs/*\nMicrosoft.AlertsManagement/smartDetectorAlertRules/*<p>\nMicrosoft.AlertsManagement/actionRules/*</p>\nMicrosoft.AlertsManagement/smartGroups/*<p>\nMicrosoft.AlertsManagement/migrateFromSmartDetection/*</p>\nMicrosoft.AlertsManagement/investigations/*<p>\nMicrosoft.AlertsManagement/prometheusRuleGroups/*</p>\nMicrosoft.Monitor/investigations/*</div></td></tr><tr><td><div>\nMicrosoft.OperationalInsights/workspaces/search/action</div></td></tr><tr><td>Resource Policy Contributor</td><td><div>\nMicrosoft.Authorization/policyassignments/*<p>\nMicrosoft.Authorization/policydefinitions/*</p>\nMicrosoft.Authorization/policyexemptions/*</div><div>\nMicrosoft.Authorization/policysetdefinitions/*\nMicrosoft.PolicyInsights/*<p>\nMicrosoft.Resources/deployments/*</p>\nMicrosoft.Support/*\n</div></td></tr></tbody></table></div></div><p><strong>This risk exists in every user, service principal, managed identity, or group members that are assigned one of these seemingly innocent service-specific roles.</strong></p><p>As we can see in the table, some of the roles have more specific read permissions in addition to the , like the <code>Microsoft.Solutions/applications/read</code> permission in <strong><em>Managed Application Operator Role</em>,</strong> which is already included in the * expression. This shows that one of the permissions is redundant, and may point to it being added by mistake or by laziness.The case of <strong><em>App Compliance Automation Reader</em></strong> is even more absurd, since it only has the * permission, <strong>and is essentially identical to the all mighty and powerful generic  role</strong>.</p><p>So this is pretty bad… but can we exploit it even further?</p><p>I wanted to make this attack scenario even stronger, and find more quirks that are possible using the  permission.So I took a look its documentation:</p><p>So we understand that identities with read permissions should not be allowed to read secrets (which makes sense because those secrets can then be used to elevate privileges to more than read-only, access more resources, etc.)Using <a href=\"https://www.azadvertizer.net/\">this</a> really nice website, I saw that there are  (!) Azure actions that are included in the  expression (every operation that ends with ‘/read’).</p><p>If I can find one action, out of those 9,618, that will allow me to leak a secret, I will have a serious vulnerability here!</p><p>After going through many permissions in the list, I found one that piqued my interest:</p><p>What is a VPN link? What is a connection? What is a shared key? I don’t know, but it has the word ‘key’ in it, so it must be interesting :)</p><p>So we have an API call that retrieves some sort of a secret even if I only have read permissions. But why is that happening? What is the mistake that the Azure developer made here?</p><p>In Azure, API calls are implemented with different HTTP methods. For example, the <a href=\"https://learn.microsoft.com/en-us/rest/api/compute/virtual-machines/list\" target=\"_blank\">Virtual Machines - List</a> API call is implemented with , and <a href=\"https://learn.microsoft.com/en-us/rest/api/compute/virtual-machines/install-patches\" target=\"_blank\">Virtual Machines - Install Patches</a> is implemented with . That makes sense, because the  API requires data from the user (a body in the request), while the  only retrieves data from the server, and does not require any data from the user.But what I found out through some blackbox research, documentation reading, and a lot of trial and error, is that Azure chose to enforce permissions by varying the HTTP methods used in the API requests. Let me explain:<p>It seems that users with read permissions alone (like *</p>can issue  requests to the API, but will get denied access if they attempt to issue  requests.Regular read operations, like <a href=\"https://learn.microsoft.com/en-us/rest/api/compute/virtual-machines/list?view=rest-compute-2024-07-01&amp;tabs=HTTP\" target=\"_blank\"></a> are implemented with a  as we’ve seen, while operations that read sensitive values, such as<a href=\"https://learn.microsoft.com/en-us/rest/api/storagerp/storage-accounts/list-keys\" target=\"_blank\"><strong>Storage Accounts - List Keys</strong></a> or <a href=\"https://learn.microsoft.com/en-us/rest/api/cosmos-db-resource-provider/database-accounts/list-connection-strings\" target=\"_blank\"><strong>Database Accounts - List Connection Strings</strong></a>, are implemented with  requests - <strong>even though the request body is empty</strong>. This is to make sure that permissions enforcement is in place, and identities with read permissions alone would not be able to access those sensitive APIs.</p><p>To prove this, I performed an API call to a URL that doesn’t exist, using a read-only identity. When I issue a GET request, I get  error. But when I issue a POST request to the same non-existent URL, I get &nbsp; error. This further proves that permission enforcement is determined by the HTTP method, and not by the checking specific API call and whether or not I have access to it.</p><p>So why is that problematic? Because when you choose to design your software in a way that doesn’t make sense and isn’t intuitive, your developers are bound to make some critical mistakes…My assumption is that at some point, some Azure developer must have accidentally implemented an API call that retrieves a secret with the method that makes the most sense, which is GET, because there is no body needed in the request. And by doing so, they created a vulnerability…</p><p>If we take a look at the API call that we found earlier, we see that our theory was right! It was accidentally implemented with a GET, allowing read-only users to fetch the key!</p><p>So now we have a vulnerability. The only thing that is left is to find out what that shared key is…</p><p>VPN Gateway is an Azure service that acts as a VPN, allowing customers to connect networks over the internet. Organizations mainly use this service to support hybrid environments (connecting cloud and on-premise), as well as connecting between on-premise sites (aka Site-to-Site, or S2S). Individual users can also connect to it, for scenarios such as working remotely (aka Point-to-Site, or P2S).</p><p>P2S connection types require additional authentication (certificate/radius server/Entra ID login).But a Site-to-Site (S2S) connection type <strong>requires only the pre-shared key (PSK)</strong>, which is a password that is shared between the VPN devices of each site, and the Azure VPN Gateway service. And yes, that’s the key we can fetch using our vulnerability!</p><ol role=\"list\"><li>The attacker compromises a weak identity (identity with read permissions or one that is assigned one of the many over-privileged roles we listed earlier).</li><li>The attacker fetches the VPN Gateway pre-shared key.</li><li>Using the key, the attacker connects to the S2S connection and accesses internal networks, including VPCs and on-premise networks that are connected to the same Azure VPN Gateway.</li></ol><p>The video demonstrates that when a principal with no privileges is assigned the  role, which is only supposed to grant access to read logs but as we know by now is over-privileged, it has permissions to fetch the VPN pre-shared key, which is then used to connect to the VPN.</p><p>With this access, attackers can create a “rogue site”, essentially granting them access to cloud resources, other sites, and secure networks of the target organization.</p><p>Depending on the configuration of the VPN Gateway, this may work only when the connection attempt is originating from the IP address configured in the Azure VPN gateway.</p><p>In that case, an attacker that has some on-premise foothold can use this trick to access sensitive cloud infrastructure and data.</p><p>There are even more sensitive values you can access using the Reader privileges. <a href=\"https://binarysecurity.no/posts/2024/11/apim-privesc\" target=\"_blank\">Excellent research published by Binary Security</a> shows how you can escalate your Reader privileges in Azure API Management service by fetching subscription keys and SSO tokens, effectively resulting in a full takeover of the service.</p><p>After reporting this issue to Microsoft, their response was that this is a ‘low severity’ security issue and they decided to not fix it. I later noticed some major documentation changes based on my report: All 10 over-privileged roles’ documentations were added the following sentence:</p><p>So they chose to fix the documentation instead of fixing the actual issue, which still endangers customers.</p><p>This was acknowledged by Microsoft as an ‘Important’ severity vulnerability, and the issue was fixed. They also awarded me with a US$7,500 bounty award.</p><p>I was happy to find out that the fix was not changing the API HTTP method to POST.In this newly created <a href=\"https://learn.microsoft.com/en-us/azure/vpn-gateway/roles-permissions\" target=\"_blank\">documentation page</a> that explains Azure VPN permissions, it is stated that to fetch/update the PSK, you now need to have the <code>Microsoft.Network/connections/sharedKey/action</code> permission:</p><h2>Mitigations and recommendations</h2><h3>Audit the use of the problematic roles</h3><p>As we saw, the over-privileged roles issue is not going to be fixed. Refrain from using those roles in your environment, and use alternatives.</p><h3><strong>Use particular and limited scopes</strong></h3><p>Instead of assigning roles on a wide scope, such as an entire management group or subscription level, limit them only to the specific resource that the principal needs access to, or to a resource group if access to multiple resources is needed.</p><p>Instead of using built-in roles that are not managed by you, use custom roles and grant only the needed permissions. Replace your current role assignments (at least of the problematic roles mentioned here) with custom roles that have fine-grained permissions.</p><p>Securing cloud environments and their identities is not easy.</p><p>The shared responsibility model, which is adopted and presented by all major cloud providers, clearly states which security tasks are the cloud provider’s responsibility, and which are the customer’s. But the issues we discussed here are in the gray area: when the cloud provider is giving you a service that is supposed to help you with identities and permissions management, but in fact misleads you into making dangerous decisions, who is to blame? Is it the cloud provider who caused you to create the security issue, or is it you, who actually created it?</p><p>There is no easy answer here, but one thing is clear - don’t fully and blindly trust the services that are given to you. Always double check, and be proactive and vigilant about the security of your organization.</p><p>When you have many identities and big infrastructure, this becomes a real challenge. When you have to question every role, permission, and API call, things can get complicated. But luckily, there is a solution.</p><p>To learn more about Token Security and how we can help secure your Azure environment (and many more), book a demo <a href=\"https://www.token.security/book-a-demo\" target=\"_blank\">here</a>.</p><p>I’m Ariel Simon, a security researcher from the Token research team, primarily focused on uncovering vulnerabilities and finding new attack techniques in cloud environments.Feel free to contact me on LinkedIn or via email: <a href=\"mailto:ariels@token.security\">ariels@token.security</a>.</p>","contentLength":21253,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44443832"},{"title":"Wayback Hopes To Be Ready Next Year With Alpine Linux Planning To Use It By Default","url":"https://www.phoronix.com/news/Wayback-2026-Plans","date":1751464568,"author":"Michael Larabel","guid":180494,"unread":true,"content":"<article>A few days ago Wayback was announced as an X11 compatibility layer for X11 desktops environments leveraging a rootful XWayland server. While currently experimental, the hope is that it will be production-ready next year and Alpine Linux is looking at using it by default for its X11 environment...</article>","contentLength":297,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Private sector lost 33k jobs, badly missing expectations of 100k increase","url":"https://www.cnbc.com/2025/07/02/adp-jobs-report-june-2025.html","date":1751463633,"author":"ceejayoz","guid":180582,"unread":true,"content":"<div data-test=\"InlineImage\"><div><div><div>People visit booths set up by the City of Sunrise and their police department at the Mega JobNewsUSA South Florida Job Fair at the Amerant Bank Arena on April 30, 2025 in Sunrise, Florida.</div><div>Joe Raedle | Getty Images</div></div></div></div><div><p>Private sector hiring unexpectedly contracted in June, payrolls processing firm ADP said Wednesday, in a possible sign that the economy may not be as sturdy as investors believe as they bid the  back up to record territory to end the month.</p><p>Private payrolls lost 33,000 jobs in June, the ADP report showed, the first decrease since March 2023. Economists polled by Dow Jones forecast an increase of 100,000 for the month. The May job growth figure was revised even lower to just 29,000 jobs added from 37,000.</p><p>\"Though layoffs continue to be rare, a hesitancy to hire and a reluctance to replace departing workers led to job losses last month,\" Nela Richardson, ADP's chief economist, said in a press release published Wednesday morning.</p><p>To be sure, the ADP report has a spotty track record on predicting the subsequent government jobs report, which investors tend to weigh more heavily. May's soft ADP data ended up differing significantly from the <a href=\"https://www.cnbc.com/2025/06/06/jobs-report-may-2025.html\">monthly jobs report figures</a> that came later in the week.</p><p>This week, the government's nonfarm payrolls report will be out on Thursday with economists expecting a healthy 110,000 increase for June, per Dow Jones estimates. Economists are expecting the unemployment rate to tick higher to 4.3% from 4.2%. Some economists could revise down their jobs reports estimates following ADP's data.</p><p>Weekly jobless claims data is also due Thursday, with economists penciling in 240,000. This string of labor stats comes during a shortened trading week, with the market closing early on Thursday and remaining dark on Friday in honor of the July Fourth holiday.</p></div><h2>Service roles hit hardest</h2><div><p>The bulk of job losses came in service roles tied to professional and business services and health and education, according to ADP. Professional/business services notched a decline of 56,000, while health/education saw a net loss of 52,000.</p><p>Financial activity roles also contributed to the month's decline with a drop of 14,000 on balance.</p><p>But the contraction was capped by payroll expansions in goods-producing roles across industries such as manufacturing and mining. All together, goods-producing positions grew by 32,000 in the month, while payrolls for service roles overall fell by 66,000.</p><p>The Midwest and Western U.S. saw the strongest contractions in June, declining by 24,000 and 20,000, respectively. Meanwhile, the Northeast shed 3,000 roles. The Southern U.S. was the sole region tracked by the ADP to see payrolls expand on net in the month, recording an increase of 13,000 positions.</p><p>The smallest firms tended to see more job losses in the month than their larger counterparts. In fact, businesses with more than 500 employees saw the biggest payroll growth in the month with an increase of 30,000, per ADP. By comparison, businesses with fewer than 20 employees accounted for 29,000 lost roles on net.</p><p>Annual income growth decreased modestly from May for both job stayers and hoppers. The rate of pay increase for those staying in their jobs ticked down to 4.4% from 4.5%, while those getting new roles slid to 6.8% from 7%.</p><p>The S&amp;P 500 is up more than 4% for the year, posting a stunning comeback in the second quarter after worries about President <a href=\"https://www.cnbc.com/donald-trump/\">Donald Trump</a>'s tariff fights nearly sent the benchmark into a bear market.</p><p><em>Clarification: The ADP report issued Wednesday referred to June data. That was not clear in an earlier version.</em></p></div>","contentLength":3573,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44443622"},{"title":"Microsoft will lay off 9,000 employees, or less than 4% of the company","url":"https://techcrunch.com/2025/07/02/microsoft-will-lay-off-9000-employees-or-less-than-4-of-the-company/","date":1751463604,"author":"Amanda Silberling","guid":180430,"unread":true,"content":"<article>Microsoft is leveraging another round of layoffs despite posting consistent growth.</article>","contentLength":83,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Microsoft To Lay Off As Many As 9,000 Employees in Latest Round","url":"https://slashdot.org/story/25/07/02/1330223/microsoft-to-lay-off-as-many-as-9000-employees-in-latest-round?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751463000,"author":"msmash","guid":180475,"unread":true,"content":"Microsoft is kicking off its fiscal year by firing thousands of employees in the largest round of layoffs since 2023, the company confirmed Wednesday. From a report: In an ongoing effort to streamline its workforce, Microsoft said that as much as 4%, or roughly 9,100, of the company's employees could be affected by Wednesday's layoffs. The move follows two waves of layoffs in May and June, which saw Microsoft fire more than 6,000 employees, almost 2,300 of whom were based in Washington.","contentLength":491,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What I learned gathering nootropic ratings (2022)","url":"https://troof.blog/posts/nootropics/","date":1751462977,"author":"julianh65","guid":181175,"unread":true,"content":"<p>All data and code can be found <a href=\"https://github.com/LeoGrin/nootroflix\">here</a>.</p><h3>\nHow to interpret these ratings\n<a href=\"https://troof.blog/posts/nootropics/#how-to-interpret-these-ratings\">#</a></h3><ul><li><p>0 means a substance was totally useless, or had so many side effects you couldn’t continue taking it.</p></li><li><p>1 - 4 means subtle effects, maybe placebo but still useful.</p></li><li><p>5 - 9 means strong effects, definitely not placebo.</p></li></ul><p>In order of importance (I think):</p><ul><li><strong>Lack of random allocation</strong></li></ul><p>The people who entered their rating on my recommender system were not randomly assigned to try specific nootropics. Thus we can expect a (usually positive) correlation between “I’m likely to try nootropic A” and “Nootropic A might work on me”.</p><p>This means that my estimations don’t represent the ratings a random person would get on average (which would usually be lower); they’re instead a prediction of the rating that a person would give to a nootropic if they decided to take it organically. Take this into account when transferring the results to yourself.</p><p>You take a pill. It makes you feel good. You go on a website which asks you how good the pill is. You say it’s awesome. Little did you know that it was, in fact, merely good.</p><p>Take this into account when reading these ratings, especially if improving your mood is not your main goal.</p><ul><li><strong>Lack of control and blinding</strong></li></ul><p>All these biases sure seem inconvenient to estimate some “true rating”, but maybe they are not a problem if we just want to compare nootropics? Perhaps in some cases, but not always: lack of random allocation probably creates more bias for medications like SSRIs, which are usually prescribed to people with depression, and self-reported ratings inflation or placebo effect may be especially relevant for substances like Psilocybin, which can produce visual effects, or for hyped-up nootropics.</p><p>I’m mostly going to ignore these issues in the rest of this article, but keep them in mind and use your best judgment when comparing ratings. This also means that you shouldn’t use this data for anything more serious than reducing your nootropics search space.</p><h3>\nMean rating for each nootropic\n<a href=\"https://troof.blog/posts/nootropics/#mean-rating-for-each-nootropic\">#</a></h3><p>Here are the results (<strong>click to see all nootropics</strong>):</p><h3>\nProbability of positive effect\n<a href=\"https://troof.blog/posts/nootropics/#probability-of-positive-effect\">#</a></h3><p>Given the scale I used, the  is not so easy to interpret. Another metric I estimated was the <em>probablity that the effect of a nootropic on a user was positive</em>. For my scale, 0 corresponds to a neutral or negative effect, and higher ratings correspond to more-or-less confidence in a positive effect. </p><p>Here are the results (<strong>click to see all nootropics</strong>):</p><h3>\nProbability of life-changing effect\n<a href=\"https://troof.blog/posts/nootropics/#probability-of-life-changing-effect\">#</a></h3><p>Here are the results (<strong>click to see all nootropics</strong>):</p><h3>\nUsefulness for different usages\n<a href=\"https://troof.blog/posts/nootropics/#usefulness-for-different-usages\">#</a></h3><p>With my data, identifying the usefulness of a nootropic for different use cases seems hard. I’ll set this aside for future investigation (if it’s possible at all).</p><p>The risks of prescribed medications such as <a href=\"https://slatestarcodex.com/2017/12/28/adderall-risks-much-more-than-you-wanted-to-know/\">Adderall</a>, <a href=\"https://slatestarcodex.com/2014/07/07/ssris-much-more-than-you-wanted-to-know/\">SSRIs</a> and <a href=\"https://www.gwern.net/Modafinil#side-effects\">Modafinil</a> are quite well-documented, but information on the risks of weirder nootropics is scarce.</p><p>For instance, what would you guess is the probability of becoming tolerant to Phenylpiracetam (apparently between 10 and 20%)? Of becoming addicted to Kratom (apparently between 15 and 25%)?</p><p><strong>Click to see all nootropics</strong>:</p><p><strong>Click to see all nootropics</strong>:</p><p><strong>Click to see all nootropics</strong>:</p><p><strong>Click to see all nootropics</strong>:</p><p><em>EDIT: As pointed out by a commenter, the estimated probabilities of long term side effects are somewhat surprising. I’m not completely sure what people had in mind when entering “long term side effects”, and thus I’m not completely sure how to interpret these probabilities.</em></p><p><strong>Click to see all nootropics</strong>:</p><h3>\nLifestyle is a strong nootropic\n<a href=\"https://troof.blog/posts/nootropics/#lifestyle-is-a-strong-nootropic\">#</a></h3><p>Among the different sport categories, weightlifting is noticeably better rated (+ 0.5 points on adjusted mean) and is actually among the very best nootropics in my database. Furthermore, very few issues are reported. This is very impressive, and <a href=\"https://www.reddit.com/r/slatestarcodex/comments/9h2jbi/you_should_probably_lift_weights/\">maybe you should consider trying it</a>. You may be wondering why you should trust this self-reported data if you don’t trust your gym bros friends who can’t stop talking about how weightlifting changed their life. I’m just saying that there are a lot of people saying the same things in my data. Maybe they’re all the same gym bros, but maybe it means that you should start taking them seriously.</p><p>If sport and sleep are the nootropic low-hanging fruits, diets are the fruits you can maybe reach on tiptoes. For instance, the Paleo diet, with a mean rating of 5.4, is in the top-20, and Intermittent Fasting, with a mean rating of 5, is in the top-30.</p><p>Low carbs diets (Keto, Carnivore, Paleo) are rated much higher than Vegetarian or Vegan diets, though the Vegan diet is first for <em>probability of changing your life</em>, with around 5%[3-8% 95%] probability, similar to the Paleo diet.</p><p>Comparing issues reported, people often stop the Carnivore and Keto diets because of side effects, with a probability between 10 and 20%, much higher than the Paleo diet (between 2 and 10%), and somewhat higher than the Vegetarian and Vegan diets (between 7 and 17%).</p><p>The Paleo diet seems to be the winner here, though I’m wondering how its particular branding might be skewing results.</p><h4>\nOther lifestyle interventions\n<a href=\"https://troof.blog/posts/nootropics/#other-lifestyle-interventions\">#</a></h4><p>Meditation (mean rating = 5.8), bright lights in the morning (5), cold shower (4.7), and masturbation abstinence (4.1) also got impressive to pretty good ratings.</p><h3>\nMost famous nootropics aren’t that good\n<a href=\"https://troof.blog/posts/nootropics/#most-famous-nootropics-arent-that-good\">#</a></h3><p>What are the first things that come to mind when you think of nootropics? Piracetam? Ashwagandha? Ginseng? Theanine? Most of these common nootropics actually got relatively poor ratings. This is compared to potent prescription-only medications like Adderall, but also to sport (see above) and to a lot of lesser-known nootropics.</p><p>The plots below shows all the common-but-mediocre nootropics (red rectangle) and the uncommon-but-great nootropics (green rectangle):\n<img src=\"https://troof.blog/posts/nootropics/ggrepel_mean_ratings.jpeg\" alt=\"ggrepel_mean_ratings\"><img src=\"https://troof.blog/posts/nootropics/ggrepel_life_changing_ratings.jpeg\" alt=\"ggrepel_life_changing_ratings\"></p><p><a href=\"https://en.wikipedia.org/wiki/Selank\">Selank</a>, <a href=\"https://en.wikipedia.org/wiki/Semax\">Semax</a>, <a href=\"https://en.wikipedia.org/wiki/Cerebrolysin\">Cerebrolysin</a>, <a href=\"https://en.wikipedia.org/wiki/BPC-157\">BPC-157</a> are all peptides, and they are all in the green “uncommon-but-great” rectangle above. Their mean ratings are excellent, but their probabilities of changing your life are especially impressive: between 5 and 20% for Cerebrolysin (which matches <a href=\"https://www.reddit.com/r/Nootropics/comments/bg7vup/a_threeweek_review_of_the_strongest_nootropic/\">anecdotal</a><a href=\"https://www.reddit.com/r/Nootropics/comments/30l3hz/extreme_success_with_cerebrolysin/\">reports</a>), between 2 and 13% for BPC-157, and between 3 and 7% for Semax.</p><p>So why are they so unpopular? It may be because they’re really scary. Take Cerebrolysin:</p><p>Perhaps relatedly, these substances are mostly used in Russia and the former USSR and have an unclear legal status in other countries. This may also explain their unpopularity.</p><p>But are peptides really that dangerous? The plots above show that the addiction probabilities are tiny and that the tolerance and long-term side effect probabilities are below 5%. Some of these substances, like Cerebrolysin, have small sample sizes, so I quickly checked the literature. A Cochrane review from 2020 found that “Moderate‐quality evidence also indicates a potential increase in non‐fatal serious adverse events with Cerebrolysin use.” with a seemingly dose-dependent effect, while the <a href=\"https://link.springer.com/article/10.1007/s10072-017-3214-0\">other</a><a href=\"https://www.mdpi.com/1424-8247/14/12/1297\">meta-analyses</a> I found reported that “Safety aspects were comparable to placebo.” So it is a bit unclear, but I would be cautious, as I trust the Cochrane review more.\nFor other peptides, we’re not lucky enough to have a Cochrane review, but the few studies I can find tell me they’re safe: <a href=\"https://www.semanticscholar.org/paper/7410dace64d32b7b42740aec059b3feea31ff757\">“Semax is well-tolerated with few side-effects.\"</a>, <a href=\"https://doi.org/10.2174/092986712803414015\">“BPC-157 is free of side effects.\"</a>, <a href=\"https://doi.org/10.1007/s10787-006-1531-7\">“BPC-157 is a safe therapeutic agent.\"</a>, <a href=\"https://doi.org/10.2174/138161211796196954\">“BPC-157 is a safe anti-ulcer peptidergic agent.\"</a> We need more data on the safety of peptides but we can already say: “Probably less dangerous than they look.”</p><p>Bonus: Reddit user OilofOrigano <a href=\"https://www.reddit.com/r/Cerebrolysin/comments/jdlpcd/cerebrolysin_poll/\">has been collecting data on Cerebrolysin</a>, you can check the results <a href=\"https://docs.google.com/spreadsheets/d/1XFKiWEHPJZ0DG-e0k7SoXgTNNG_52vU9gxqbMAegbxM/edit#gid=36862191\">here</a>. Results are quite positive (see below), though I think it was mostly collected on a subreddit dedicated to Cerebrolysin, so I would expect the results to be overly positive.\n</p><h3>\nZembrin maybe isn’t interesting?\n<a href=\"https://troof.blog/posts/nootropics/#zembrin-maybe-isnt-interesting\">#</a></h3><blockquote><p>Of 37 kanna users, 20 used Zembrin and 17 used something else. The subgroup who used Zembrin reported a mean effectiveness of 6.88, which beats out modafinil to make it highest on the list. After ad hoc Bayesian adjustment, it was 6.72, second only to modafinil as the second most effective nootropic on the list. This really excites me - I’ve felt like Zembrin was special for a while, and this is the only case of a newer nootropic on the survey beating the mainstays. And it’s a really unexpected victory. The top eight substances in the list are all either stimulants, addictive, illegal in the US, or all three. Zembrin is none of those, and it beats them all.</p></blockquote><p>How can we explain the difference? Maybe the surveyed population is a bit different in my case? But the simplest answer is surely sample noise. SA’s ratings are based on 20 people who tried Zembrin and 17 people who tried non-Zembrin Kanna. My ratings are based on 45 people who tried Zembrin and 49 people who tried non-Zembrin Kanna. Where it gets more complicated is that SA has subsequent data:</p><blockquote><p>Based on these preliminary results, I wrote up a short page about Zembrin on my professional website, Lorien Psychiatry, and I asked anyone who planned to try it to preregister with me so I could ask them how it worked later. 29 people preregistered, of whom I was able to follow up with and get data from 22 after a few months. Of those 22, 16 (73%) said it seemed to help, 3 (14%) said it didn’t help, and another 3 (14%) couldn’t tell because they had to stop taking it due to side effects (two headaches, one case of “psychedelic closed-eye visuals”). Only 13 of the 22 people were willing to give it a score from 1-10 (people hate giving 1-10 scores!), and those averaged 5.9 (6.3 if we don’t count people who stopped it immediately due to side effects). That’s a little lower than on the survey, but this was a different population - for example, many of them in their answers specifically compared it to prescription antidepressants they’d taken, whereas the survey-takers were comparing it to nootropics. Although these findings are not very useful without a placebo control, they confirm that most people who take Zembrin at least subjectively find it helpful.</p></blockquote><p>Do you trust the (a bit) bigger sample size, or the preregistration? Your choice!</p><p>What is the best stimulant to take if you have trouble focusing? Adderall and Dexedrine have the best ratings. The latter is perhaps more likely to change your life, and both are far above Ritalin and Modafinil. I was surprised about Dexedrine, which I didn’t know about. Still, it does have higher patient ratings than Adderall on Drugs.com and the like, and there seems to be a debate in the literature on which is more effective for ADHD. This is all from <a href=\"https://astralcodexten.substack.com/p/know-your-amphetamines?s=r\">this article by Scott Alexander</a>, which is a great explainer on the different amphetamines used to treat ADHD (and a reminder that most of these substances are quite well-studied in the literature, and that you shouldn’t base any decision on my data!).</p><figcaption align=\"center\"><i>Guess where Methylphenidate is the only easily available stimulant?</i></figcaption><p>In the plot below, I’ve included most of the medications recommended for depression <a href=\"https://lorienpsych.com/2021/06/05/depression/#23_What_kind_of_medications_help_with_depression\">here</a>, and most of the supplements recommended <a href=\"https://lorienpsych.com/2021/06/05/depression/#24_What_kind_of_supplements_help_with_depression\">here</a>.\n</p><p>More surprising, using bright light in the morning was ranked second. Interpreting these ratings is hard, as they are not specifically about depression, but this is still impressive.</p><p>Most supplements users report few issues (except SAM-e and St John Wort, which have a high probability of side effects), while people using prescription medications report  of side effects. For instance, for Bupropion and SSRIs, I estimate a 30 to 40% probability of side-effects making you stop taking them. For SSRIs, there’s a 20 to 30% probability of having long-term side effects. This is quite scary.\nTianeptine users report way fewer side effects, but as a counterpart, they’re more likely to get addicted/tolerant (I wonder how much of this is explained by people getting Tianeptine over-the-counter).</p><p>All racetams got almost identical pretty low ratings, except Phenyracetam, which was rated much higher (but still way below something like Modafinil).</p><p>Racetams seem safe: they all got pretty much the same (low) probabilities for all issues, except for Phenylracetam, which has a tolerance probability between 10 and 20%.</p><h3>\nHow dangerous is Phenibut?\n<a href=\"https://troof.blog/posts/nootropics/#how-dangerous-is-phenibut\">#</a></h3><blockquote><p>Only 3% of users got addicted to phenibut. This came as a big surprise to me given the caution most people show about this substance. Both of the two people who reported major addictions were using it daily at doses &gt; 2g. The four people who reported minor addictions were less consistent, and some people gave confusing answers like that they had never used it more than once a month but still considered themselves “addicted”. People were more likely to report tolerance with more frequent use; of those who used it monthly or less, only 6% developed tolerance; of those who used it several times per month, 13%; of those who used it several times per week, 18%; of those who used it daily, 36%.</p></blockquote><p>The figures I have are somewhat worse, but still better than I expected: I estimate a 5.5%[3-9%] chance of becoming addicted, a 6%[4-10%] chance of having long-term side effects, and a 20%[15-26%] chance of becoming tolerant.</p><p>Microdosing psychedelics was quite highly rated, especially for Psilocybin: I estimate a mean rating of 5.6 [5.3-5.8] for LSD and 6[5.8-6.3] for Psilocybin, and a probability of changing your life of 6[4-8]% for LSD and 8[6-11]% for Psilocybin.</p><p>But be careful: this may be an example of the limit of self-reported, unblinded, data. Indeed, <a href=\"https://www.gwern.net/LSD-microdosing#microdosing\">Gwern has been gathering RCTs on the subject (in addition to his N=1 experiment)</a>, and most show little to no effect\n, except on things like visual intensity or time perception, and sometimes some effect on self-reported mood (how can you be sad when the colors are INTENSE?). People seem to be able to <a href=\"https://www.gwern.net/docs/psychedelic/2020-olson.pdf\">trip on a placebo</a>, so I guess this is an area where we should be careful.</p><p>While I got a lot of boring results (this is reassuring!), I was really surprised by a few things:</p><ul><li>Sport (especially Weightlifting) and sleep were really highly rated. More generally all “lifestyle interventions” were rated way higher than most famous nootropics like Piracetam or Rhodiola Rosea.</li><li>Peptides like Semax or Cerebrolysin were really highly rated, but seem poorly known outside of Russia.</li><li>Tianeptine was rated much higher than any other antidepressant. What is going on here?</li><li>Zembrin maybe isn’t better than normal Kanna, as suggested in ACX 2020 Nootropics survey, which would be disappointing.</li></ul><p>I’m sure there are a lot of interesting things I missed in my data. Feel free to <a href=\"https://github.com/LeoGrin/nootroflix\">explore them</a>.</p><p><strong>Subscribe to see new posts</strong>:</p>","contentLength":14589,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44443492"},{"title":"Cloudflare Introduces Default Blocking of A.I. Data Scrapers","url":"https://www.nytimes.com/2025/07/01/technology/cloudflare-ai-data.html","date":1751462936,"author":"stephendause","guid":180581,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44443480"},{"title":"Microsoft to Cut 9k Workers in Second Wave of Major Layoffs","url":"https://www.bloomberg.com/news/articles/2025-07-02/microsoft-to-cut-9-000-workers-in-second-wave-of-major-layoffs","date":1751462804,"author":"htrp","guid":180580,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44443452"},{"title":"Docker State of App Dev: Dev Ex & Productivity","url":"https://www.docker.com/blog/docker-state-of-app-dev-dev-ex-productivity/","date":1751462443,"author":"Olga Diachkova","guid":180463,"unread":true,"content":"<p><strong>Report: What’s helping devs thrive — and what’s still holding them back?&nbsp;</strong></p><p><em>A look at how culture, tooling, and habits are shaping the developer experience today, per Docker’s 2025 State of Application Development Survey.</em></p><p>Great culture, better tools — but developers often still feel stuck. From pull requests stuck in review to tasks without clear estimates, the inner loop remains cluttered with surprisingly persistent friction points. This year’s data maps the disconnect between what developers need, where they’re blocked, and how better tooling and cultural support can keep velocity on track.</p><p>Here are six key insights into developer experience and productivity from Docker’s annual <strong><em>State of Application Development Survey</em></strong>, based on responses from over 4,500 industry professionals.</p><p><strong>1. How devs learn — and what’s changing</strong></p><p><strong>Self-guided learning is on the upswing</strong>. Across all industries, fully  of respondents turn to online courses or certifications, far outpacing traditional sources like school (), books (), or on-the-job training ().&nbsp;</p><p>Among IT folks, the picture is more nuanced. <strong>School is still the top venue</strong> for learning to code (, up from 57% in our 2024 survey), but online resources are also trending upward. Some  of IT pros learned coding skills via online resources (up from 54% in our 2024 survey) and  favored online courses or certifications (up from 45% in 2024).</p><p>Note: For this year’s report, we surveyed over three times more users across a broader spectrum of industries than for our more IT-focused 2024 report.</p><p>As for  devs prefer to learn, <strong>documentation tops the list</strong>, as in last year’s report — that despite the rise in new and interactive forms of learning. Some  say they lean on documentation, edging out videos and side projects () and slightly ahead of structured online training ().&nbsp;</p><p>AI tools play a relatively minor role in how respondents learn, with GitHub Copilot cited by just  overall — and only among IT pros. It’s also cited by  as a preferred learning method.</p><p><strong>2. Containers: the great divide?</strong></p><p>Among IT pros, container usage soared to  — up from 80% in our 2024 survey. Zoom out to a broader view across industries, however, and adoption appears considerably lower. Just  of developers say they use containers in any part of their workflow.&nbsp;</p><p>Why the gap? Differences in app structure may offer an explanation: IT industry respondents work with microservice-based architectures more often than those in other industries ( versus ). So the higher container adoption may stem from IT pros’ need for modularity and scalability — which containers provide in spades. </p><p>And among container users, needs are evolving. They want better tools for , , and — stubborn pain points across the software lifecycle.</p><p><strong>3. An equal-opportunity headache: estimating time</strong></p><p>No matter the role, <strong>estimating how long a task will take is the most consistent pain point</strong> across the board. Whether you’re a front-end developer (), data scientist (), or a software decision-maker (), precision in time planning remains elusive.</p><p>Other top roadblocks?  and <strong>pull-request review (25%)</strong> are slowing teams down. Interestingly, where people say they need  doesn’t always match where they’re getting stuck. Case in point, <strong>testing solutions and Continuous Delivery (CD)</strong> come up often when devs talk about tooling gaps — even though they’re not always flagged as blockers.</p><p><strong>4. Productivity by persona: different hats, same struggles</strong></p><p>When you break it down by role, some unique themes emerge:</p><ul><li> struggle most with time estimation ().</li><li> face a three-way tie: <strong>planning, time estimation, and designing from scratch (28% each)</strong>.</li><li> are especially challenged by — a task not traditionally in their wheelhouse.</li><li>, surprisingly, list  as a challenge, closely followed by .</li></ul><p>Across personas, a common thread stands out: even seasoned professionals are grappling with foundational coordination tasks — not the “hard” tech itself, but the orchestration around it.</p><p><strong>5. Tools vs. culture: two sides of the experience equation</strong></p><p>On the tooling side, the biggest callouts for improvement include:</p><ul><li><strong>Designing solutions from scratch (17%)</strong></li></ul><p>But productivity isn’t just about tools — it’s deeply cultural. When asked what’s working well, developers pointed to , <strong>location flexibility such as work from home policies (38%)</strong>, and  as top cultural strengths.</p><p>The weak spots? , , and . In other words: developers like where, when, and how they work, but not always .</p><p><strong>6. What’s easy? What’s not?</strong></p><p>While the dev world is full of moving parts, a few areas are surprisingly  challenging:</p><ul><li><strong>Editing config files (8%)</strong></li><li><strong>Writing config files (7%)</strong></li></ul><p>Contrast that with the most taxing areas:</p><ul><li><strong>Troubleshooting in production (9%)</strong></li><li><strong>Debugging in production (9%)</strong></li><li><strong>Security-related tasks (8%)</strong></li></ul><p>It’s a reminder that production is still where the stress — and the stakes — are highest.</p><p>Developer productivity isn’t about just one thing. It’s the compound effect of better tools, smarter learning, sharper planning — and yes, a healthy team culture. For orgs to excel, they need to invest not just in platforms, but also in people. Because when you improve the , you unlock the performance.</p>","contentLength":5167,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tesla faces second straight year of falling sales after another bad quarter","url":"https://techcrunch.com/2025/07/02/tesla-faces-second-straight-year-of-falling-sales-after-another-bad-quarter/","date":1751462053,"author":"Sean O'Kane","guid":180429,"unread":true,"content":"<article>Tesla sales fell more than 13% compared to last year as the company struggles to find demand for its aging lineup, and as CEO Elon Musk continues to damage the brand. </article>","contentLength":167,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Did Nexo Become the First Crypto Partner of the DP World Tour?","url":"https://hackernoon.com/how-did-nexo-become-the-first-crypto-partner-of-the-dp-world-tour?source=rss","date":1751461737,"author":"Ishan Pandey","guid":180727,"unread":true,"content":"<p>Could cryptocurrency sponsorship reshape professional golf? In an unprecedented move, Nexo, a digital asset wealth platform, has signed a three-year partnership with the DP World Tour, making it the first crypto-focused sponsor in professional golf.</p><h3>What Exactly is the Partnership?</h3><p>The agreement between <a href=\"https://nexo.com/\">Nexo</a> and the <a href=\"https://www.europeantour.com/dpworld-tour/\">DP World Tour</a> makes Nexo the Official Digital Asset and Wealth Partner of the Tour through 2027. This involves sponsoring key tournaments, notably including the Genesis Scottish Open and the BMW PGA Championship.</p><p>\\\nSignificantly, one of the tournaments, previously unnamed, has been renamed the \"Nexo Championship.\" It will take place from August 7–10, 2025, at the Trump International Golf Links in Aberdeenshire, Scotland. This will be the cornerstone of Nexo’s involvement, solidifying its visibility in global sports.</p><h3>Why is this Partnership Important?</h3><p>Golf sponsorships have traditionally been dominated by mainstream brands such as Rolex, BMW, and Emirates. Nexo's entry represents a notable shift, highlighting how digital and crypto-focused companies are stepping into traditionally conservative sporting arenas.</p><p>\\\nAntoni Trenchev, <a href=\"https://nexo.com/\">Nexo</a>'s Co-founder and Managing Partner, explains the rationale, saying, “This partnership reflects our belief that wealth and golf are built the same way: with preparation, control, and vision. Both the DP World Tour and Nexo share a commitment to precision, discipline, and performance, whether on the course or in finance.”</p><h3>How Does the DP World Tour View This?</h3><p>For the DP World Tour, associating with a digital asset firm like Nexo aligns with its modern branding and global appeal. Max Hamilton, the Executive Commercial Director at DP World Tour, emphasizes the strategic alignment: “Just as the DP World Tour connects global golf fans using the latest technologies, Nexo is reshaping wealth-building with digital tools.”</p><p>\\\nThe DP World Tour, formerly known as the European Tour, stages events in various iconic global locations, attracting affluent audiences who are seen as potential clients for Nexo's digital asset services.</p><h3>Understanding Nexo's Core Business</h3><p>Founded in 2018, Nexo is a financial platform focused on digital assets, commonly known as cryptocurrencies, such as Bitcoin and Ethereum. Nexo offers services including crypto-backed loans, savings accounts, and trading services.</p><p>\\\nTo illustrate simply: Imagine holding Bitcoin worth $10,000 but not wanting to sell it due to potential future appreciation. Nexo allows you to borrow money against your Bitcoin without selling it. This model enables clients to manage their finances without sacrificing long-term investment opportunities.</p><p>Cryptocurrency companies sponsoring sports teams and events is a growing trend. <a href=\"http://Crypto.com\">Crypto.com</a> previously signed partnerships with major entities like the UFC and Formula 1, and now Nexo's move into golf signals this expansion is continuing.</p><p>\\\nSuch partnerships often aim to build legitimacy and trust among broader audiences. Golf, with its high-income demographic, represents a strategic audience for Nexo. While such sponsorships offer substantial marketing opportunities, they also come with challenges, notably market volatility. Crypto markets fluctuate rapidly, posing potential risks to long-term partnerships. Yet, Nexo’s partnership sets a precedent. If successful, more crypto companies might venture into traditionally conservative sports, potentially changing how sports sponsorships are viewed and negotiated in the future.</p><p>Nexo’s sponsorship of the DP World Tour could significantly impact the landscape of sports sponsorships, blending traditional and digital financial services. However, given the inherent volatility of crypto assets, it remains critical for Nexo to maintain stability to fulfill its long-term commitment. The success or failure of this partnership could either encourage similar sponsorships or caution others against such bold moves.</p><p>Don’t forget to like and share the story! </p><p>:::tip\n<em>This author is an independent contributor publishing via our&nbsp;. HackerNoon has reviewed the report for quality, but the claims herein belong to the author. #DYO</em></p>","contentLength":4144,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Dymension's Season 2 Matters for the Blockchain Ecosystem","url":"https://hackernoon.com/why-dymensions-season-2-matters-for-the-blockchain-ecosystem?source=rss","date":1751461583,"author":"Ishan Pandey","guid":180726,"unread":true,"content":"<p>Did the initial excitement of Dymension's mainnet launch, marked by a significant token distribution, truly capture the protocol's full potential? While Genesis Rolldrop Season 1 distributed over $400 million in tokens, Dymension's underlying technology was in an early state. The protocol has evolved, and with the \"Beyond\" upgrade approaching,  is set to reintroduce and accelerate Dymension's growth as a Universal Settlement Layer.</p><p>\\\nThis new phase aims to deepen engagement and reward various participants, from long-term token holders to active builders and new users. It represents a shift towards a more comprehensive and incentivized ecosystem, moving beyond the initial airdrop to foster sustained participation and development. The focus is now on establishing Dymension as a foundational layer for decentralized applications and services.</p><h3>Unpacking the Registration Waves and Dymond Hands Initiative</h3><p>\\\nSeason 2's participation mechanism begins with , each targeting specific eligible addresses. This phased approach allows Dymension to onboard different segments of its community systematically. The first wave, termed \"Dymond Hands,\" is dedicated to core DYM community members. To qualify for this initial wave, individuals must have continuously staked a minimum of 17 DYM tokens since June 2024 without unstaking. This criterion establishes a clear measure of sustained commitment.</p><p>\\\nThe registration process itself is designed for security and simplicity. Participants register their wallet addresses without requiring a signature, meaning no private key information is ever requested. The only official entry point is through the designated portal <a href=\"https://portal.dymension.xyz/season-two\">https://portal.dymension.xyz/season-two</a>, emphasizing a secure and controlled environment for participation. This careful approach to registration reflects a broader commitment to user safety within the Dymension ecosystem.</p><h3>Understanding DYMONDs: The New Incentive Mechanism</h3><p>\\\nAt the core of Season 2's reward structure are , a new form of in-protocol points that users can earn and later exchange for DYM tokens. This system is designed to incentivize various forms of on-chain activity, compensating long-time DYM holders, active users, developers, and new entrants. The earning of DYMONDs is tied to real-time on-chain actions, ensuring that rewards are distributed based on actual engagement rather than static metrics.</p><p>\\\nDYMONDs are earned through activities such as IRO trading, depositing USDC (with one-click functionality from Solana, Arbitrum, and Base), participating in Bridge LP, providing liquidity on Dymension's decentralized exchange, and depositing Total Value Locked (TVL) into a user's own RollApp. The real-time tracking of DYMONDs within the Dymension Portal provides transparency and allows users to monitor their progress. This dynamic reward system encourages continuous interaction and contribution to the network.</p><h3>Claim Windows and Long-Term Engagement</h3><p>\\\nThe process of converting earned DYMONDs into DYM tokens occurs during specific . These are limited timeframes spread throughout Season 2, offering participants the opportunity to exchange their accumulated DYMONDs. This phased claiming approach aims to manage token distribution and encourage sustained participation.</p><p>\\\nA significant aspect of the DYMOND system is its emphasis on long-term engagement. While users have the option to claim their DYM during each window, the protocol offers greater rewards to those who continue their participation throughout the entire Season 2. This structure is intended to align incentives with the protocol's long-term growth and stability, rewarding individuals who demonstrate a consistent commitment to the Dymension ecosystem.</p><h3>Referral System and Stakers Boost</h3><p>To further accelerate growth and community expansion, Season 2 introduces a . Existing participants can invite new users, earning a bonus equivalent to 10% of all DYMONDs accrued by their referrals. This bonus does not diminish the referred user's own DYMOND earnings, creating a mutually beneficial arrangement. New users who join using a referral link also receive a signup bonus, providing an immediate incentive for new participation. This mechanism aims to leverage the community for organic growth and adoption.</p><p>\\\nThe  mechanism directly rewards users for their sustained commitment and the size of their staked DYM. Every DYMOND earned by a participant is subject to a multiplier of up to 5x, based on the average of two factors: the duration of continuous staking without unstaking, and the amount of DYM staked, with a cap at 25,000 DYM. This boost system directly links staking behavior to increased earning potential, incentivizing long-term holding and significant contributions to network security.</p><h3>Empowering Creators: The RollApp Endorsement Program</h3><p>Season 2 extends its focus beyond individual users to actively support  within the Dymension ecosystem. The protocol recognizes that the creation of new RollApps and the attraction of TVL to these applications are critical for its expansion. While builders earn DYMONDs through their on-chain activity, the Dymension Foundation has also initiated a program to directly fund these creators.</p><p>\\\nThrough , the Dymension Foundation allocates its staked DYM to support builders, offering rewards of up to $10,000 per month. This program is open to both early-stage teams and those with existing live RollApps. The process involves submitting an application or idea for on-chain support, indicating a direct pathway for developers to receive significant backing. This initiative highlights Dymension's commitment to fostering a vibrant developer community and expanding its utility as a foundational layer.</p><h3>My Opinion and Final Thoughts</h3><p>Dymension's Season 2 represents a progression from a focus on initial distribution to building a sustained and active ecosystem. The introduction of DYMONDs, coupled with the detailed registration waves and stakers boost, indicates a strategic effort to incentivize continued engagement across various user segments. The emphasis on rewarding long-term commitment through tiered claim windows and the multiplier for stakers promotes network stability and aligns user interests with the protocol's health.</p><p>\\\nThe inclusion of a robust referral program and, critically, the direct financial support for RollApp creators through the endorsement system, demonstrates a commitment to fostering organic growth and innovation. By empowering builders with direct funding and incentivizing the development of new applications, Dymension is laying groundwork for a more diverse and functional ecosystem. This approach suggests a long-term vision for the protocol, moving beyond simple token distribution to cultivate a thriving and self-sustaining network.</p><p>Don’t forget to like and share the story! </p>","contentLength":6815,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rivian receives the next $1B from Volkswagen as sales struggles continue","url":"https://techcrunch.com/2025/07/02/rivian-receives-the-next-1b-from-volkswagen-as-sales-struggles-continue/","date":1751461248,"author":"Sean O'Kane","guid":180428,"unread":true,"content":"<article>Rivian sales ticked back up in Q2 but were down 23% from the same quarter last year. The company has been dealing with affordability issues made worse by Trump's tariffs and trade wars.</article>","contentLength":185,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Agentic AI Explained: How It Works, Top Use Cases & Future Potential","url":"https://hackernoon.com/agentic-ai-explained-how-it-works-top-use-cases-and-future-potential?source=rss","date":1751461215,"author":"Salesmate","guid":180725,"unread":true,"content":"<p>\\\nWe’re used to AI that needs a prompt: “Turn on the lights,” “What’s the weather?” “Remind me to call mom.” </p><p>Remember when Siri felt like magic?</p><p>Now, imagine an AI that doesn’t wait for instructions.</p><p>What if it could think and act on its own?</p><p>That’s Agentic AI. It’s not just reactive; it’s proactive—learning, acting, and solving problems independently.</p><p>Excited? Let’s explore where this bold new world is going.</p><p><strong>Agentic AI refers to artificial intelligence systems that can think, decide, and act independently to achieve specific goals without constant human input.</strong></p><p>These systems often build on powerful AI models like GPT-4 or Claude, which serve as their cognitive engines, enabling them to reason, plan, and execute complex tasks.</p><p>The term&nbsp;&nbsp;comes from&nbsp;&nbsp;meaning the ability to act autonomously and make decisions. So when we talk about agentic AI, we're referring to systems designed with:</p><ul><li>&nbsp;– They operate without step-by-step instructions.</li><li>&nbsp;– They anticipate needs and take action.</li><li>&nbsp;– They pursue outcomes and adjust strategies based on results.</li></ul><p>In simpler terms, it's&nbsp;.</p><p>Unlike traditional AI, which follows pre-set rules, and generative AI, which creates content based on prompts, agentic AI is designed to take action.&nbsp;<em>It sets plans, coordinates AI agents, and completes goals autonomously. It's the difference between responding and resolving.</em></p><p>In short, traditional AI responds to commands. Agentic AI operates independently, driving decisions, coordinating AI agents, and delivering outcomes.</p><p>Before you get confused or end up messing/mixing agentic AI and AI agents, let's clarify:</p><ul><li>&nbsp;= Tools that perform specific, narrow tasks (e.g., scheduling, summarizing, flagging emails).</li><li>&nbsp;= A&nbsp;&nbsp;that orchestrates many such agents to accomplish bigger, goal-oriented outcomes, often with autonomy and memory.</li></ul><p>Here is a simple way to understand agentic AI vs AI agents: \\n <strong>AI agent = a solo worker\\Agentic AI = a full team with a manager and mission</strong></p><h2>Key benefits of agentic AI</h2><p>It reduces manual effort by automating repetitive tasks like form-filling, meeting scheduling, and ticket triaging, but its value goes far beyond basic automation.</p><ul><li>&nbsp;It executes goals independently, and there's no need for constant input. For instance, it can autonomously reply to leads, schedule meetings, and update your&nbsp;CRM&nbsp;without human intervention.</li><li>&nbsp;It learns from every interaction, refining its responses. For example, a support agent spots repeat refund requests, flags issues, and adapts messaging automatically.</li><li><strong>Multi-step task execution:</strong>&nbsp;It breaks down big goals into smaller tasks, assigns them to the right agents, and completes entire workflows in one seamless flow.</li></ul><p>With AI agents working across systems, Agentic AI drives productivity, speeds up processes, and delivers personalized results without needing more human resources.</p><p>Now, let's unpack how agentic AI works behind the scenes.</p><h2>How does agentic AI work? [Architecture + Workflow]</h2><p>Agentic AI systems are built like modular, intelligent teams.</p><p>Each layer performs a specific role but works together toward a shared goal. The system operates in a continuous feedback loop, from gathering inputs to making decisions and executing actions.</p><p>Let's break down the architecture and explore how AI agentic workflows operate behind the scenes.</p><p>To function with autonomy and intelligence, agentic AI combines four key layers:</p><p><strong>1. Large Language Models (LLMs):</strong>&nbsp;These are the reasoning engines. LLMs like GPT-4 and Claude interpret tasks, understand language, and generate decisions using natural language processing. They allow the AI to think, reason, and adjust based on context.</p><p><strong>2. APIs and enterprise tools:</strong>&nbsp;APIs connect AI to real-world systems such as CRMs, calendars, internal databases, and support platforms. These integrations help the AI fetch live data and perform tasks like sending emails, updating records, or triggering workflows.</p><p>&nbsp;This layer manages everything behind the scenes. It plans task sequences, assigns agent responsibilities, monitors execution, and ensures progress aligns with the defined goal. Think of it as the system's project manager.</p><p>&nbsp;Rather than a single model doing everything, agentic AI orchestrates a team of specialized AI agents. Each handles a specific part of the process—research, decision-making, communication, or follow-up.</p><p>These layers enable the system to operate with logic, context, and autonomy.</p><h3>Agentic AI workflow function in real-world scenarios</h3><p>Agentic systems do not rely on static scripts.</p><p>Instead, they evolve through dynamic workflows where AI agents operate across tools, APIs, and databases, adapting to changing inputs and improving over time.</p><p>Here’s the working mechanism of Agentic AI:</p><ul><li>: The AI agents gather relevant data from various sources, like APIs, documents, databases, or user queries, to set the stage for the task.</li><li>: With the power of Large Language Models (LLMs), the system analyzes the data, detects patterns, understands intent, and determines the next steps.</li><li>: The system breaks down the main goal into smaller, actionable tasks, then sequences and assigns them to the right AI agents.</li><li>: Each agent triggers actions like updating a CRM, scheduling a meeting, or sending a report — all without human intervention.</li><li>: Once the task is complete, the system analyzes feedback, improving its performance for the next round.</li><li>: Multiple agents (including humans, when necessary) collaborate to ensure the task progresses efficiently and the goal is met.</li></ul><p>These agentic workflows in AI adapt and execute tasks with precision, learning from each cycle to improve future outcomes across changing business environments.</p><p>This flexibility and coordination make Agentic AI more than just automation. It's an intelligent, evolving system that drives real results.</p><h3>Agent coordination models: Hierarchical and decentralized</h3><p>Agentic systems are usually built in one of two architectural styles, depending on how structured or exploratory the task is.</p><p>There are two dominant coordination models:</p><ul><li><strong>Hierarchical architecture</strong></li></ul><p>In this model, a \"supervisor\" agent coordinates the work of other agents. It delegates tasks, tracks progress, and ensures alignment with the overall objective.</p><p>The supervisor agent determines which sales rep should follow up on a lead. Other agents handle&nbsp;<a href=\"https://www.salesmate.io/blog/follow-up-email-template/\">follow-up emails</a>, meeting scheduling, and CRM updates, all under the supervision of the primary agent.</p><ul><li><strong>Decentralized architecture</strong></li></ul><p>In this model, multiple agents work independently but collaborate to accomplish shared goals without one central authority.</p><p>Consider a product development team using multiple agents for market analysis, competitor research, and customer feedback analysis.</p><p>These agents work together, gathering data independently but sharing it in real-time to form a comprehensive product strategy.</p><p>Both models aim to accomplish tasks autonomously, but the structure changes how the work is approached, whether a single \"leader\" or collaborative peers.</p><h2>Agentic AI vs generative AI</h2><p>Generative AI, like ChatGPT and DALL-E, creates content based on prompts.&nbsp;</p><p>It can write blog posts, generate code, or create images. While incredibly creative, it cannot act autonomously or follow through on tasks.</p><p>Agentic AI goes beyond creating content; it plans, decides, and executes tasks autonomously. Think of it as a digital assistant that takes action independently, coordinating multiple agents to complete complex, goal-oriented functions without human input.</p><p>Here are the key differences: Agentic AI and Generative AI</p><p>|  |  |  |\n|----|----|----|\n|  | Reactive — responds to inputs | Proactive — anticipates and initiates actions |\n|  | Requires prompts to operate | Operates independently with minimal human input |\n|  | Limited to predefined rules | Adaptable to context, feedback, and changing conditions |\n|  | Chatbot that answers FAQs | Agent that handles onboarding, follow-ups, and updates |</p><p>Both types of AI have massive potential. However, understanding their core differences, strengths, and weaknesses will help businesses determine where and how to integrate them most effectively.</p><h2>Agentic AI applications and use cases</h2><p>From sales to cybersecurity, agentic AI models are redefining how businesses delegate, automate, and scale operations with minimal oversight.</p><p>Notably,&nbsp;<a href=\"https://www.gartner.com/en/newsroom/press-releases/2024-04-11-gartner-says-75-percent-of-enterprise-software-engineers-will-use-ai-code-assistants-by-2028\">75% of enterprises</a>&nbsp;leverage AI agents for tasks such as code generation, evaluation, and rewriting, underscoring the technology's growing role in software development.</p><p>Below are practical and real-world agentic AI examples:</p><h3><strong>Sales and customer service</strong></h3><ul><li><strong>Salesmate's smart workflows</strong>: It serves as an agentic layer, automating lead routing,&nbsp;<a href=\"https://www.salesmate.io/blog/sales-follow-up/\">sales follow-ups</a>, and personalized actions using real-time data—all with minimal human input.</li><li>: Resolves customer queries dynamically by querying databases, detecting sentiment, and learning from interactions to improve accuracy and efficiency.</li></ul><ul><li>: Provides empathetic patient support, monitors vitals, suggests treatment changes, and escalates cases autonomously based on context and patient needs.</li></ul><ul><li>: Automates IT support workflows by understanding natural language requests, planning tasks, and executing them autonomously. It adapts to changing conditions in real-time while optimizing workflows.</li></ul><ul><li><strong>Siemens predictive maintenance systems</strong>: Agentic AI agents autonomously monitor machinery, predict failures, and adjust production schedules to optimize throughput and minimize downtime.</li></ul><ul><li><strong>Autonomous trading systems</strong>: Agentic AI monitors market trends, executes trades, and optimizes portfolios by analyzing economic signals faster than human analysts.</li></ul><ul><li>: Uses agentic AI to autonomously analyze user behavior, detect anomalies, and prevent breaches in real-time by adapting its detection models based on evolving threat patterns.</li></ul><p>All these examples demonstrate how agentic AI systems operate with autonomy, adaptability, and goal-oriented behavior across diverse industries.</p><h2>Challenges and limitations of agentic AI</h2><p>Agentic AI unlocks powerful autonomy, but it also introduces new risks. Here's what to watch for:</p><ul><li><p><strong>Hallucinations with consequences:</strong>&nbsp;Like all LLM-based systems, agentic AI can still hallucinate. But here, a wrong answer isn't just a typo; it might automatically issue a refund, delete a lead, or misroute inventory without human review.</p></li><li><p>&nbsp;Give it a vague or poorly scoped goal, and agentic AI might go rogue. For example, optimizing for speed could mean skipping safety checks or bypassing necessary approvals.</p></li><li><p>&nbsp;With multiple agents, shared memory, and real-time decisions, tracing&nbsp;&nbsp;a conclusion was made becomes hard. That's a big problem in finance or healthcare, where explainability matters.</p></li><li><p><strong>Governance, bias, and data risks:</strong>&nbsp;These systems pull from sensitive data and act on it. Without strong guardrails, they can reinforce bias, leak private info, or make decisions that clash with your company values. Ethical design and oversight protocols are critical.</p></li><li><p>&nbsp;Agentic AI isn't lightweight. It needs high computing power, persistent memory, and robust orchestration — driving up cloud costs and making it harder for lean teams to scale.</p><h2>Future of agentic AI: What's next?</h2><p>We're not heading toward a world where AI supports business decisions. We're heading toward one where it&nbsp;&nbsp;them.</p><p>According to Gartner, by 2028,&nbsp;<a href=\"https://www.zdnet.com/article/why-agentic-ai-is-the-new-electricity-and-nearly-80-of-business-leaders-are-afraid-of-the-dark/#:~:text=By%202028%2C%2033%25%20of%20enterprise%20software%20applications%20will%20include%20agentic%20AI%2C%20up%20from%20less%20than%201%25%20in%202024%2C%20enabling%2015%25%20of%20day%2Dto%2Dday%20work%20decisions%20to%20be%20made%20autonomously%2C%22%C2%A0\">33% of</a>&nbsp;enterprise software applications will embed agentic AI, enabling 15% of day-to-day decisions without human input.</p><p>That's not a distant vision — it's the near future knocking.</p><p>This means that the shift from reactive AI assistants to proactive digital operators is underway. Smart agents will no longer be siloed helpers.</p><p>They'll collaborate across departments, syncing with CRMs, querying live systems, triggering workflows, and optimizing in real-time.</p><p>The future is agentic ecosystems: \\n <em>Teams of autonomous agents work together — not just to assist but to operate entire functions.</em></p><p>Think of sales agents closing leads at night. Ops agents resolve bottlenecks before they escalate. R&amp;D agents run tests while humans sleep.</p><p>The businesses that win won't just&nbsp;&nbsp;AI — they'll orchestrate it.</p><p>From strategy to execution, AI redefines what's possible when machines operate with intent.</p><p>Now's the time to move from exploration to implementation. Identify where intelligent agents can offload the repetitive, streamline decisions, and drive growth — all without bloating your headcount.</p><p>Don't just adopt AI. Put it to work.</p><p>&nbsp;With Salesmate, you can orchestrate intelligent agents that automate follow-ups, update your CRM in real-time, and keep deals moving — even when your team is off the clock.</p></li></ul>","contentLength":12529,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Young Americans Are Spending a Whole Lot Less On Video Games This Year","url":"https://games.slashdot.org/story/25/07/01/2239206/young-americans-are-spending-a-whole-lot-less-on-video-games-this-year?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1751461200,"author":"BeauHD","guid":180474,"unread":true,"content":"An anonymous reader quotes a report from GameSpot: Perhaps responding to economic uncertainty and narrowing job prospects, young people in the United States are significantly cutting back on spending on video games compared to this time last year. While 18- to 24-year-olds aren't buying as much across a range of different categories, losses are concentrated in games. New data published by market research firm Circana and reported by The Wall Street Journal suggests that young adults spent nearly 25% less on video game products in a four-week span in April than in the same timeframe last year. Other categories also dramatic drops: Accessories (down 18%), technology (down 14%), and furniture (down 12%).\n \nAll categories combined, the 18-24 age group spent around 13% less than last year. This decrease is not reflected among older cohorts, whose spending has been mostly stable year-over-year. The WSJ report suggests that the economic context could be driving young adults to pull back; a tighter labor market, increased economic uncertainty, and student-loan payments restarting all may be contributing to an environment hostile to the spending habits of 18- to 24-year-olds in particular.","contentLength":1199,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Foxconn tells hundreds of Chinese staff to return from its Indian iPhone factories","url":"https://techcrunch.com/2025/07/02/foxconn-tells-hundreds-of-chinese-staff-to-return-from-its-indian-iphone-factories/","date":1751460905,"author":"Ram Iyer","guid":180427,"unread":true,"content":"<article>Foxconn ordered over 300 Chinese employees to return home from its factories in India, per Bloomberg.</article>","contentLength":101,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Better Late Than Never: Linux 6.17 To Enable Intel DG1 Graphics By Default","url":"https://www.phoronix.com/news/Intel-DG1-Enabled-Linux-6.17","date":1751460577,"author":"Michael Larabel","guid":180493,"unread":true,"content":"<article>Prior to the DG2/Alchemist discrete GPUs from Intel there was the DG1 graphics processor that served primarily as the initial developer vehicle for facilitating Intel's modern discrete GPU push. DG1 ended up being in the Intel Xe MAX GPU for a small number of laptops and then there's also been a select number of DG1 graphics cards surfacing on eBay in the years since. Only now in 2025 is the upstream Linux kernel driver set to enable Intel DG1 graphics out-of-the-box for modern Linux distributions...</article>","contentLength":505,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I'm dialing back my LLM usage","url":"https://zed.dev/blog/dialing-back-my-llm-usage-with-alberto-fortin","date":1751460502,"author":"sagacity","guid":180579,"unread":true,"content":"<p>We invited <a href=\"https://x.com/a7fort\">Alberto Fortin</a>, a seasoned software engineer with 15 years of experience, to share his candid journey with AI. Alberto initially embraced LLMs with genuine enthusiasm, hoping they would revolutionize his development workflow. However, after encountering significant challenges while rebuilding his infrastructure with Go and ClickHouse, he wrote a <a href=\"https://albertofortin.com/writing/coding-with-ai\">thoughtful blog post</a> reflecting on the gap between AI hype and reality.\nFor this conversation, Alberto also prepared a <a href=\"https://kings-kick-n9g.craft.me/alberto-fortin-zed\">detailed follow-up analysis</a> testing newer models like Claude Opus 4, examining whether recent improvements have addressed the core issues he encountered.</p><p>His experience provides practical lessons for engineers evaluating LLMs in production environments—balancing realistic expectations with an understanding of where these tools genuinely add value versus where they still fall short.</p><blockquote><p>\"I was really shocked at the poor quality of some things, and it was not just about bugs and features not working. I think as a developer who wants to maintain this codebase for the next few years, I also care about it being neat enough.\"</p></blockquote><blockquote><p>\"I feel like I'm a week away from fixing this, but actually a new small error would come up and then that will take another two weeks to fix.\"</p></blockquote><blockquote><p>\"I will give my error output to the LLM and then it will spit out something new that will kind of fix it, but also make things a bit more messed up—and break something else in the process.\"</p></blockquote><blockquote><p>\"I think everyone just got a little bit overexcited about it because the first iteration, the first little feature, the first autocomplete is like, 'Oh my God, this is amazing. This is like reading my mind.' So you kind of get duped into it a little bit.\"</p></blockquote><blockquote><p>\"I think we've gotten to a level where we can do probably 10 times as much coding. So we kind of expect that to happen and we require that from the LLMs, but I think everyone just gets a little bit overexcited about it.\"</p></blockquote><blockquote><p>\"I think this is the biggest difference, like a mental shift... I am the software engineer, the senior software engineer, I am the architect. The LLM is the assistant. The assistant responds to me; I make the plan.\"</p></blockquote><blockquote><p>\"I lost all my trust in LLMs, so I wouldn't give them a big feature again. I'll do very small things like refactoring or a very small-scoped feature.\"</p></blockquote><blockquote><p>\"I started fixing the bugs myself. Because as soon as you understand this—you have a hundred percent understanding of your codebase and what everything is doing—it's so much easier and quicker for you to go in and fix something.\"</p></blockquote><blockquote><p>\"If you are confident enough in your skills—you know, a senior developer—and this is not working for you, there's nothing wrong with you. Just try to do the things that you always did and use AI to leverage your knowledge a little bit.\"</p></blockquote><blockquote><p>\"We've gone up a level, it's great. But also, let's be mindful we're not there yet at the next level... We are offloading some of the programming work, but we still need to do architectural abstractions and make the decisions for the product.\"</p></blockquote><blockquote><p>\"Let's just try to calm down all this hype and find a balanced approach towards AI. Use it, because I think it's such an amazing revolution in technology, but we're not there yet.\"</p></blockquote>","contentLength":3170,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44443109"},{"title":"Ted Cruz’s Dumb Plan To Punish States That Regulate AI By Withholding Broadband Grants Falls Apart","url":"https://www.techdirt.com/2025/07/02/ted-cruzs-dumb-plan-to-punish-states-that-regulate-ai-by-withholding-broadband-grants-falls-apart/","date":1751459280,"author":"Karl Bode","guid":180489,"unread":true,"content":"<p>The proposal was one of several cut to try and get the <a href=\"https://www.nbcnews.com/politics/congress/polls-trump-bill-unpopular-republicans-stare-deadline-passage-rcna213724\">hugely unpopular GOP bill</a> across the finish line. As it turns out, Cruz had a tough time getting enough support for his ignorant plan, and ultimately joined 98 other Senators in a <a href=\"https://arstechnica.com/tech-policy/2025/07/ted-cruz-gives-up-on-ai-law-moratorium-joins-99-1-vote-against-his-own-plan/\">99-1 vote shooting down the amendment</a> (Sen. Thom Tillis was the one dissenting vote):</p><blockquote><p><em>“Facing overwhelming opposition from both Democrats and Republicans, Sen. Ted Cruz (R-Texas) accepted defeat and joined a 99-1 vote against his own plan to punish states that regulate artificial intelligence.”</em></p></blockquote><p>States are poised to get more than $42.5 billion dollars in broadband deployment subsidies as part of the 2021 infrastructure bill. The Broadband Equity, Access and Deployment (BEAD), a key component of the bill, had taken years of collaborative work between state and federal governments. In part because <em>we needed to remap broadband access across every county in the United States</em>. </p><p>A lot of this money is poised (as usual) to get dumped in the laps of telecom giants, which is a major reason Cruz’s gambit failed (AT&amp;T drove heavy opposition by longtime AT&amp;T ally Marsha Blackburn, who initially worked with Cruz on a “compromise” offering, before that collapsed entirely). But much of this money is also poised to go to really useful fiber upgrade proposals via efforts like regional cooperatives or community-owned broadband networks. </p><p>So while it’s nice Ted Cruz’s latest dumb effort failed, it’s hard to be celebratory. Republicans have been taking an absolute hatchet to every last federal effort to ensure our monopoly-dominated broadband networks are affordable. They’ve also effectively <a href=\"https://www.techdirt.com/2025/04/07/federal-consumer-protection-is-dead-the-fate-of-net-neutrality-warned-you-it-was-coming/\">killed all federal consumer protection</a>; policies that will reverberate in negative ways for decades to come. </p><p>The budget battle followed the fairly typical Republican playbook: make your initial offer so extremist and awful that any concessions are disguised to feel like a victory. But the final GOP budget bill <a href=\"https://www.cnbc.com/2025/06/30/trump-bill-helps-wealthy-hurts-low-earners-yale-report.html\">remains a giant and unpopular piece of shit</a>, and one of the most corrupt and disgusting attacks on vulnerable Americans in the history of modern politics.</p>","contentLength":2109,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"VS Code’s Open Source AI Revolution: A New Chapter for Developers","url":"https://devops.com/vs-codes-open-source-ai-revolution-a-new-chapter-for-developers/?utm_source=rss&utm_medium=rss&utm_campaign=vs-codes-open-source-ai-revolution-a-new-chapter-for-developers","date":1751457835,"author":"Tom Smith","guid":180473,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cisco Live San Diego Case Study: Malware Upatre! (Encrypted Visibility Engine Event)","url":"https://blogs.cisco.com/security/case-study-malware-upatre-encrypted-visibility-engine-event/","date":1751457658,"author":"Aditya Sankar","guid":180460,"unread":true,"content":"<article>Cisco Security and Splunk protected Cisco Live San Diego 2025 in the Security Operations Center. Learn about the latest innovations for the SOC of the Future. </article>","contentLength":159,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Splunk in Action at the Cisco Live San Diego SOC","url":"https://blogs.cisco.com/security/splunk-in-action-at-the-cisco-live-san-diego-soc/","date":1751457651,"author":"Jessica (Bair) Oppenheimer","guid":180459,"unread":true,"content":"<article>Cisco Security and Splunk protected Cisco Live San Diego 2025 in the Security Operations Center. Learn about the latest innovations for the SOC of the Future. </article>","contentLength":159,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Health Insurance Appeals with Generative AI: From Lab to Production • Holden Karau • GOTO 2024","url":"https://www.youtube.com/watch?v=Q5muBDDdhJg","date":1751457651,"author":"GOTO Conferences","guid":180495,"unread":true,"content":"<article>This presentation was recorded at GOTO Chicago 2024. #GOTOcon #GOTOchgo\nhttps://gotochgo.com\n\nHolden Karau - Co-Founder at Fight Health Insurance @HoldenKarau \n\nRESOURCES\nhttps://bsky.app/profile/holdenkarau.com\nhttps://twitter.com/holdenkarau\nhttps://github.com/holdenk\nhttps://www.linkedin.com/in/holdenkarau\nhttp://holdenkarau.com\n\nLinks\nhttps://www.fighthealthinsurance.com\nhttps://wpso.dmhc.ca.gov/imr\nhttps://huggingface.co/TotallyLegitCo/appeal-alpaca\nhttps://huggingface.co/TotallyLegitCo/fighthealthinsurance_model_v0.2\nhttps://huggingface.co/TotallyLegitCo/fighthealthinsurance_model_v0.3\nhttps://www.youtube.com/playlist?list=PLRLebp9QyZtYcK_X13lBS_HZjaXUDwyEt\n\nABSTRACT\nThis talk will cover how we created a system to generate health insurance appeals from denials. We'll start with a quick look at the different attempts at model fine-tuning (along with what eventually worked well for us), then look at the middleware, how we integrate in-house and external models, steps to protect privacy, and finally, some truly questionable frontend code (or truly great frontend code if we finish the rewrite in time—you never know).\n\nIf you love the American healthcare system as it stands today, this is probably not the talk for you. For those ambivalent about the healthcare system, that's totally fine; you can still see what it takes to bring an ML system from drinks at a bar all the way through to production. [...]\n\nTIMECODES\n00:00 Intro\n00:25 Content warning\n03:38 What's the problem?\n06:13 How to use computers to fix the problem?\n07:13 What's needed to tune a LLM?\n10:36 Putting it together\n11:38 Downsides\n13:04 What models did we make?\n14:21 Model fine tune config\n15:40 Model serving\n18:38 Frontend?\n19:46 Demo\n25:18 How to do better for the next model?\n27:55 Links\n28:40 Outro\n\nDownload slides and read the full abstract here:\nhttps://gotochgo.com/2024/sessions/3371\n\nRECOMMENDED BOOKS\nHolden Karau • Distributed Computing 4 Kids • https://www.distributedcomputing4kids.com\nHolden Karau • Scaling Python with Dask • https://www.oreilly.com/library/view/scaling-python-with/9781098119867\nHolden Karau &amp; Boris Lublinsky • Scaling Python with Ray • https://amzn.to/44GU6cC\nHolden Karau &amp; Rachel Warren • High Performance Spark • https://amzn.to/3v2eLbn\nHolden Karau, Konwinski, Wendell &amp; Zaharia • Learning Spark • https://amzn.to/397e2NE\nHolden Karau &amp; Krishna Sankar • Fast Data Processing with Spark 2nd Edition • https://amzn.to/3xKhXKu\nHolden Karau • Fast Data Processing with Spark 1st Edition • https://amzn.to/3rHQgOu\n\nhttps://bsky.app/profile/gotocon.com\nhttps://twitter.com/GOTOcon\nhttps://www.linkedin.com/company/goto-\nhttps://www.instagram.com/goto_con\nhttps://www.facebook.com/GOTOConferences\n#GenerativeAI #LLMs #GenAI #HealthInsurance #HealthInsuranceAppeals #HoldenKarau\n\nCHANNEL MEMBERSHIP BONUS\nJoin this channel to get early access to videos &amp; other perks:\nhttps://www.youtube.com/channel/UCs_tLP3AiwYKwdUHpltJPuA/join\n\nLooking for a unique learning experience?\nAttend the next GOTO conference near you! Get your ticket at https://gotopia.tech\nSign up for updates and specials at https://gotopia.tech/newsletter\n\nSUBSCRIBE TO OUR CHANNEL - new videos posted almost daily.\nhttps://www.youtube.com/user/GotoConferences/?sub_confirmation=1</article>","contentLength":3302,"flags":null,"enclosureUrl":"https://www.youtube.com/v/Q5muBDDdhJg?version=3","enclosureMime":"","commentsUrl":null},{"title":"5 Fun Python Projects for Absolute Beginners","url":"https://www.kdnuggets.com/5-fun-python-projects-for-absolute-beginners","date":1751457649,"author":"Kanwal Mehreen","guid":180476,"unread":true,"content":"<article>Bored of theory? These hands-on Python projects make learning interactive, practical, and actually enjoyable.</article>","contentLength":109,"flags":null,"enclosureUrl":"https://www.kdnuggets.com/wp-content/uploads/5-Fun-Python-Projects-for-Absolute-Beginners.png","enclosureMime":"","commentsUrl":null},{"title":"Using AI to Battle Phishing Campaigns","url":"https://blogs.cisco.com/security/using-ai-to-battle-phishing-campaigns/","date":1751457623,"author":"Ryan Maclennan","guid":180458,"unread":true,"content":"<article>Cisco Security and Splunk protected Cisco Live San Diego 2025 in the Security Operations Center. Learn about the latest innovations for the SOC of the Future.</article>","contentLength":158,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building an XDR Integration With Splunk Attack Analyzer","url":"https://blogs.cisco.com/security/building-xdr-integration-with-splunk-attack-analyzer/","date":1751457618,"author":"Ryan Maclennan","guid":180457,"unread":true,"content":"<article>Cisco XDR is an infinitely extensible platform for security integrations. Like the maturing SOCs of our customers, the event SOC team at Cisco Live San Diego 2025 built custom integrations to meet our needs. You can build your own integrations using the community resources announced at Cisco Live. It was an honor to work with […]</article>","contentLength":333,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cisco Live San Diego Case Study: Hunting Cleartext Passwords in HTTP POST Requests","url":"https://blogs.cisco.com/security/case-study-hunting-cleartext-passwords-in-http-post-requests/","date":1751457611,"author":"Aditya Sankar","guid":180456,"unread":true,"content":"<article>Cisco Security and Splunk protected Cisco Live San Diego 2025 in the Security Operations Center. Learn about the latest innovations for the SOC of the Future.  </article>","contentLength":162,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficient Proof Systems: How PoStake, PoSpace, and VDFs Impact Blockchain Security","url":"https://hackernoon.com/efficient-proof-systems-how-postake-pospace-and-vdfs-impact-blockchain-security?source=rss","date":1751457611,"author":"EScholar: Electronic Academic Papers for Scholars","guid":180724,"unread":true,"content":"<p>Adversarial mining strategies in blockchains based on efficient proof systems can be analysed with respect to several adversarial goals. Here, we outline three such goals: double spending, short and long term selfish-mining.</p><p>\\\nThe first objective is double spending, where one considers the probability of an adversarial chain overtaking the public, honest chain [8, 29] (see Figure 3). Here the goal of the adversary is to rapidly and secretly grow a sufficiently long private chain such that this private chain eventually overtakes the honest chain, this way removing a presumably confirmed transaction. What “sufficiently” long means depends on the confirmation time in the chain, e.g., in Bitcoin one generally assumes a transaction that is six blocks deep in the chain to be confirmed.</p><p>The second objective, “short-term selfish mining”, considered eschews the goal of overtaking the honest chain completely and focuses simply on finding an adversarial mining strategy that is more profitable for the adversary rather than following the stipulated mining protocol [12] (see Figure 4). The profitability of an adversarial mining strategy under this objective is measured by the total number of adversarial blocks on the main chain. Like in the analyses of selfish mining strategies under the first objective, analyses of strategies under this second objective also focus on finding the largest fraction of adversarial resources the blockchain can tolerate in order to be secure under such adversarial strategies.</p><h2>B EFFICIENT PROOF SYSTEMS</h2><p>. PoStake is a block leader election protocol where a leader is selected with probability proportionate to the amount of stake (i.e., coins) they hold in the ledger at the selection time. Thus, a user with 𝑝 ∈ [0, 1] fraction of stake is elected with probability proportionate to 𝑝. Examples of longest-chain blockchains based on PoStake are Ouroboros [9] and post-merge Ethereum [1].</p><p>\\\n. Proof of Space (PoSpace) is a protocol between a  and a verifier whereby the prover stores some data and, upon a challenge from the verifier, has to return a solution to the challenge that involves reading a small portion of the data. The consensus protocol of blockchains based on PoST [8] use both PoSpace challenges as well as verifiable delay functions [4, 25, 30] (VDFs). VDFs are functions that are inherently sequential to compute but the correctness of computation is efficiently verifiable. As such, the process of mining blocks in such blockchains depends not</p><p>\\\n\\\nonly on the amount of space allocated to compute PoSpace challenges, but also on the amount of VDFs to compute VDF challenges.</p><p>(1) Krishnendu Chatterjee, IST Austria, Austria (krishnendu.chatterjee@ist.ac.at);</p><p>(2) Amirali Ebrahimzadeh, Sharif University of Technology, Iran (ebrahimzadeh.amirali@gmail.com);</p><p>(3) Mehrdad Karrabi, IST Austria, Austria (mehrdad.karrabi@ist.ac.at);</p><p>(4) Krzysztof Pietrzak, IST Austria, Austria (krzysztof.pietrzak@ist.ac.at);</p><p>(5) Michelle Yeo, National University of Singapore, Singapore (mxyeo@nus.edu.sg);</p><p>(6) Ðorđe Žikelić, Singapore Management University, Singapore (dzikelic@smu.edu.sg).</p>","contentLength":3135,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cisco Live San Diego Case Study: Investigating Attempted Admin Access With Secure Firewall?","url":"https://blogs.cisco.com/security/dos-privilege-escalation-admin-credentials-in-the-clear/","date":1751457605,"author":"Adam Kilgore","guid":180455,"unread":true,"content":"<article>Cisco Security and Splunk protected Cisco Live San Diego 2025 in the Security Operations Center. Learn about the latest innovations for the SOC of the Future.</article>","contentLength":158,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bigfoot Was Just the Beginning of the Content Revolution - An AI Renaissance","url":"https://hackernoon.com/bigfoot-was-just-the-beginning-of-the-content-revolution-an-ai-renaissance?source=rss","date":1751457604,"author":"CeThe.World","guid":180723,"unread":true,"content":"<p><em>How Google's Veo 3 sparked UGC creativity and redefined the boundaries between reality and imagination—my thoughts on the future of the content industry.</em></p><blockquote><p><em>\"Renaissance\" was first coined by French historian Jules Michelet to describe the 16th-century period as \"the discovery of the world and of humanity” —&nbsp;</em></p></blockquote><h2>For You Page's New Favorite Kid</h2><p>\\\nThere are so many viral videos created and watched that people started curating daily Veo3 video rankings—just like the NBA’s *Top 5 plays of the night—*sharing the most creative viral videos every day. Videos with millions—even hundreds of millions—of views have given global users a taste of the creative revolution brought by AI-generated videos.</p><p>What sparked this UGC creativity boom was the Bigfoot vlogs. It’s hard to trace “patient zero” who started it, but within days of going viral, different Bigfoot characters with various accents, furs, and pets emerged everywhere. I personally followed one with a unique comedic \"personality\" —by the name of \"Speedilla.\"</p><p>The story of <a href=\"https://www.tiktok.com/@speedilla\">Bigfoot Speedilla</a> begins in Hamburg, Germany, where his  Mo, a Syrian immigrant, discovered that AI-generated Bigfoot vlogs could serve as both artistic expression and potential income during his spare time from work.</p><p>\"Speedilla, he is part of my inner self,\" Mo explains when describing the character. \"I'm trying to create some kind of dark, satirical comedy.\" In Speedilla's virtual world, comedy is the surface of his content, while satirical reflections form its core. As Bigfoot gets rejected by a woman he's trying to court and subsequently turns her into steak as a revenge, <a href=\"https://www.tiktok.com/@speedilla/video/7513150203369622786\">this 20-second piece</a> receives hundreds of thousands of likes—it's a collective “middle finger” to mainstream cultural taboos from a group that empathizes with Mo’s creation.</p><p>\\\nIt only takes a couple of viral videos for Speedilla to build tens of thousands of followers and attract brand collaboration offers. But the good times didn't last long. Mo soon discovered his content being stolen and replicated by others. He asked his followers to report the “infringement” to the platform, but TikTok did not respond to the claims.</p><p>\\\nAs <a href=\"https://lifehacker.com/entertainment/the-out-of-touch-adults-guide-to-kid-culture-bigfoot-vlogs\">Lifehacker's Stephen Johnson</a> observed, driven by the profit motives of overnight viral success, countless creators are \"putting Bigfoot in all kinds of ridiculous scenarios.\" This extends far beyond Bigfoot—TikTok has seen an  of AI-generated content featuring Star Wars, Harry Potter, and other film franchises, creating a vast but copyright-ambiguous UGC content ecosystem.</p><p>These vast copyright gray areas haven't gone unnoticed. Entertainment giants <a href=\"https://www.theguardian.com/technology/2025/jun/11/disney-universal-ai-lawsuit\">Disney and Universal recently sued AI company Midjourney</a>, calling its AI image generator a \"<em>bottomless pit of plagiarism\"</em> that blatantly infringes on their intellectual property libraries. In this 143-page lawsuit, Disney catalogued Midjourney's blatant copying of their signature characters, including Storm Troopers and Darth Vader from Star Wars, Elsa from Frozen, and the Minions from Despicable Me, just to name a few.</p><p>\\\nThe lawsuit not only accuses the AI model of directly copying character appearances but also charges that its outputs constitute \"<strong>infringing derivative works.</strong>\" Disney argues that these images generated from simple prompts are not users' original works, but  of their copyrighted characters, directly violating copyright holders' exclusive rights to derivative works.</p><p>This accusation directly speaks to the core problem creators face: How to define the originality of AI-generated works? If simple AI outputs are \"infringing derivative works,\" what must creators do to make their works legally recognized as copyrightable original creations?</p><ol><li><p><strong>Provide original input instructions</strong>: As in the previously successful  case, the creator uploaded an original hand-drawn rose artwork as a foundation, then used text prompts to have AI visually process it. The composition and creative conception of this hand-drawn draft were considered key evidence of human creative control over the final product.</p></li><li><p><strong>Extensively modify and arrange AI-generated content</strong>: In another successfully registered case, \"<em>A Single Piece of American Cheese</em>,\" the creator performed 35 image detail redraws on the AI-generated initial image, adding elements like a third eye and melting cheese, and recomposing the overall picture. The U.S. Copyright Office recognized this active \"selection, combination, and arrangement\" of AI-generated materials as demonstrating sufficient human originality.</p></li></ol><p>These precedents offer some guidance for AI creators: While the legal framework is still forming, it's clear that copyright is meant to protect human creativity, not AI's computational results. For individual creators like Mo, this means simply generating a character is far from enough. </p><p>\\\nWhen a generic Bigfoot character was replicated by others, the creator was virtually helpless because he couldn't prove he had invested sufficient, legally protectable \"human creativity\" in the character's generation.</p><p><strong>Veo 3 faces similar challenges to Midjourney, not only in copyright issues, but its realism and physical accuracy create information risks that cannot be ignored.</strong><a href=\"https://time.com/7290050/veo-3-google-misinformation-deepfake/\">Testing by TIME magazine found that Veo 3 can generate convincingly realistic \"fake news\"</a>, including Pakistani crowds burning Hindu temples, Chinese researchers handling bats in virus laboratories, and election workers shredding ballots—extremely inflammatory and controversial content.   </p><p>\\\nThis ability to easily manufacture content has pushed both creation and consumption platforms to the forefront, making transparency assurance and prevention of misinformation an urgent \"labeling war\" requiring deep involvement from both regulatory bodies and tech companies worldwide.</p><p>Facing escalating misinformation risks, platforms have implemented inconsistent and often inadequate strategies. As TIME magazine reported, only after they contacted Google about misleading videos generated by Veo 3 did Google, as the content creation platform, take reactive measures: adding a tiny, easily croppable, visible watermark to videos.</p><p>\\\nOn the other side, where the content is distributed and watched by billions of people, <a href=\"https://newsroom.tiktok.com/en-us/new-labels-for-disclosing-ai-generated-content\">TikTok, the short video platform famous for viral content, has, since September 2023</a>, required creators to actively label AI-generated content to avoid misleading audiences. But in reality, when scrolling through the TikTok feed today, one will find very limited coverage of this \"AI-generated\" label, with only a small portion of content displaying this label due to creators' voluntary disclosure.</p><p>\\\nThe reason behind this is simple: creators all want their content to appear as realistic as possible. Having a prominent label telling viewers \"this is AI-generated\" would presumably impact video performance heavily, so relying solely on creators' voluntary reporting isn’t adequate.</p><p>\\\nGlobally, regulatory requirements for AI content labeling are inconsistent. <a href=\"https://digitalpolicyalert.org/change/10930\">China</a> and <a href=\"https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence\">the EU</a> take the lead in this space, respectively legislating a mandate that requires content platforms to implement metadata for machine and visible watermarks for humans to identify AI content. The U.S. hasn't legislated at the federal level, but states like California have taken the lead, with multiple bills in the works. Other regions, including Australia, ASEAN, and the Middle East, have yet to legislate, details see Table 1.</p><p>\\\nWith incomplete regulatory frameworks, social media platforms are proactively becoming de facto rule-makers. China's <a href=\"https://www.chinalawtranslate.com/en/%E6%8A%96%E9%9F%B3%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%94%9F%E6%88%90%E5%86%85%E5%AE%B9%E6%A0%87%E8%AF%86%E7%9A%84%E6%B0%B4%E5%8D%B0%E4%B8%8E%E5%85%83%E6%95%B0%E6%8D%AE%E8%A7%84/\">Douyin, for example, strictly enforces national mandatory requirements</a>, requiring both standardized metadata and fixed-position visible watermarks for all AI-generated content. Meta’s Instagram and Facebook, Douyin’s sibling TikTok, YouTube, and Snapchat are also actively advancing dual strategies combining metadata (like C2PA standards) and visible labels (like \"AI Info,\" \"Imagined with AI\"), but implementation varies. </p><p>\\\nIn contrast, some platforms like X (formerly Twitter) have been slower to respond, not yet introducing AI content labeling policies that promote information transparency. This inconsistent status across platforms reflects tech companies' attempts to balance user growth, commercial success, and content compliance in the AI race.</p><p><strong>Table 1: AI Content Labeling Requirements by Country/Region</strong></p><p>| Country/Region | Metadata Marking Requirements | Visible Watermark Requirements | Effective Date | Information Source |\n|----|----|----|----|----|\n|  | : All AI-generated content must include metadata for tracking, classification, and platform information. | : All publicly released AI-generated content must have clear (visible) watermarks. | September 1, 2025 | <a href=\"https://www.linkedin.com/pulse/glimpse-future-why-chinas-labeling-law-may-signal-swaner-jd-aigp-homqc\">China Law Translate</a>, <a href=\"https://www.chinalawtranslate.com/en/%E6%8A%96%E9%9F%B3%E5%85%B3%E4%BA%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%94%9F%E6%88%90%E5%86%85%E5%AE%B9%E6%A0%87%E8%AF%86%E7%9A%84%E6%B0%B4%E5%8D%B0%E4%B8%8E%E5%85%83%E6%95%B0%E6%8D%AE%E8%A7%84/\">Douyin Regulations</a> |\n|  | : Under the AI Act, AI-generated content must have machine-readable metadata (like digital watermarks, C2PA). | Not explicitly mandated, but future guidelines or industry practices may require. | August 2026 | <a href=\"https://hackernoon.com/forget-silicon-valley-its-all-about-brussels-now-how-the-eu-ai-act-impacts-global-ai-policies\">EU AI Act</a> \\n <a href=\"https://www2.datainnovation.org/2024-ai-watermarking.pdf\">Data Innovation</a> |\n|  |  (federal level); but multiple bills have proposed mandatory requirements, and some states (like California) have passed legislation. |  (federal level); but California law and proposed federal bills require visible watermarks. | California: January 1, 2026 | <a href=\"https://fpf.org/blog/u-s-legislative-trends-in-ai-generated-content-2024-and-beyond/\">FPF</a>, <a href=\"https://www.pbs.org/newshour/politics/new-bipartisan-bill-would-require-labeling-of-ai-generated-videos-and-audio\">PBS</a> |\n|  | No legal requirement; best practice is using metadata and provenance standards (C2PA). | No legal requirement; visible labels are best practice but not mandatory. | - | <a href=\"https://legal123.com.au/how-to-guide/legal-issues-ai-chatgpt/\">Legal123</a> |\n|  | ; regional guidelines support digital watermarks and encrypted provenance (C2PA). | Recommended as best practice, not legally mandatory. | - | <a href=\"https://asean.org/wp-content/uploads/2025/01/Expanded-ASEAN-Guide-on-AI-Governance-and-Ethics-Generative-AI.pdf\">ASEAN Guide</a> |\n|  | No specific AI legal requirements; ethical guidelines encourage transparency and data provenance. | No legal requirements; visible labels encouraged under ethical principles. | - | <a href=\"https://insight.thomsonreuters.com/mena/legal/posts/how-is-ai-regulated-in-the-uae-what-lawyers-need-to-know\">Thomson Reuters</a> |</p><p>However, despite the complexity of copyright, misinformation, and platform regulation, Veo 3's potential is also being explored by professional directors. While countless content creators chase the next \"Bigfoot\"-style viral moment, Turkish self-made director Öner S. Biberkökü chose a completely different path. His goal wasn't to create a quick viral moment that would spread on social media, but to use this new technology to tell a story that could deeply move hearts.</p><p>\\\nÖner's collaborator is Turkey's household name, \"Queen of Pop\" Sezen Aksu, a legendary figure spanning five decades in music, who released a new song, <a href=\"https://www.youtube.com/watch?v=M6z6TqiBpSo\">Doğrucu</a>. \"I want people to remember their childhood,\" Öner mentioned in my interview, \"I listened to her songs as a child, her voice has special meaning for Turkish people.\"</p><p>\\\n<a href=\"https://www.youtube.com/watch?v=M6z6TqiBpSo\">This project</a> cost tens of thousands of dollars in Veo3 credits alone, plus substantial human resources, completed by <a href=\"https://www.pepperroot.com/\">Öner's team (Pepperroot Studio)</a> working around the clock. During creation, Öner and his team deeply explored Veo 3's technical limitations. He frankly admitted that achieving character consistency was a \"nightmare\" using this tool alone, forcing them to combine multiple generation methods through careful planning and repeated experimentation to finally achieve the desired outcome.</p><p>\\\nThis approach differs from another music video Öner created 4 months earlier, <a href=\"https://www.youtube.com/watch?v=z5eSot0pcz0\">\"Uchigatana\" (which I often refer to as \"Reborn as a Samurai in Edo\")</a>, which pursued spectacle moments, style transfer, and lip sync by an AI character that showcased AI’s capabilities. This new music video with Sezen Aksu deliberately maintained restraint and simplicity. \"I wanted a simple music video with only one magical moment—the instant when sparrows lift the woman from a fall,\" Öner said. </p><p>\\\nHe prioritized emotional delivery over AI technical showmanship. Ultimately, this \"magical moment\" served the song's narrative, completing the work's concrete expression to aspire for \"hope.\"</p><p>The same creative tool, in different creators' hands, some people can produce comedic viral content, some people use it to fabricate misinformation, and some would wield its power to call for a nation's emotional response.</p><h2>Looking Forward: The AI Renaissance</h2><p>In addition to Google's Veo3, the AI video model field is highly competitive with numerous participants. There are platforms like Kling (by Kuaishou) and Dreamina (by ByteDance) that possess vast video training data from their short video platforms, as well as companies like Runway, Higgsfield, and Minimax, etc. continuously iterating products in their respective niche sub-fields. </p><p>\\\nNew technological innovations are announced almost every few days. Even <a href=\"https://www.reddit.com/r/singularity/comments/1kvtjzy/about_veo_4/\">Reddit</a> already has rumors circulating that Veo 4 will be released in December 2025, though no one can accurately predict what capabilities these models will achieve by then.</p><p>\\\nHowever, as Google CEO Sundar Pichai said in a <a href=\"https://lexfridman.com/sundar-pichai-transcript/\">podcast interview</a>, the trend from these advanced models is clear—they will enable a dramatic increase in content creation, empowering a broader range of creators—democratizing video creation. He predicts: using AI video tools will become as commonplace as “using Google Docs is today.\"</p><p>\\\nBut I believe <strong>the core of content creation has never been, and should never be, determined by how advanced our tools are, but by the human spirit with which we wield these tools.</strong></p><p>\\\n<strong>The Veo 3 viral moment represents more than technological progress—it's a mirror reflecting the essence of human creativity.</strong> When a Syrian immigrant in Germany creates artistic expression with an AI Bigfoot, when a Turkish team produces emotionally complete stories at minimal cost, when the boundaries between real and synthetic blur, when you and I can use AI tools to manifest \"<em>What You Think Is What You See</em>\" we're not just witnessing a tool's evolution—we're observing the transformation across the entire content industry, what some call the <a href=\"https://www.forbes.com/sites/sherzododilov/2024/12/22/2025-is-poised-to-usher-in-the-ai-renaissanceare-you-prepared/\">AI Renaissance</a>, an era where AI is accelerating the re-discovery and re-definition of humanity’s place in the world.</p><p>\\\nThis emerging AI Renaissance brings us back to our fundamental principles. The question we need to answer isn't whether AI will change content creation—because it already has. The question is whether we can establish a framework that embraces these tools' democratizing potential while protecting the value of human creativity.</p><p>\\\nIn that future of AI Renaissance, the stories we choose to tell—and how we tell them—will matter far more than the technology used to bring those stories to life.</p><ol><li><strong>Öner S. Biberkökü and Cansın Çetin Kuşluvan</strong> (Co-founders of Turkish creative studio Pepperroot Studio). Video conference recordings with the author, June 2025.</li><li> (AI content creator). Video conference recordings with the author, June 2025.</li></ol><h2>II. Legal Documents and Reports</h2><h2>III. News Reports and Analysis</h2>","contentLength":14674,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cisco Live San Diego 2025 SOC","url":"https://blogs.cisco.com/security/cisco-live-san-diego-2025-soc/","date":1751457600,"author":"Jessica (Bair) Oppenheimer","guid":180454,"unread":true,"content":"<article>Cisco Security and Splunk protected Cisco Live San Diego 2025 in the Security Operations Center. Learn about the latest innovations for the SOC of the Future. </article>","contentLength":159,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real Python: Quiz: Python 3.14 Preview: Template Strings (T-Strings)","url":"https://realpython.com/quizzes/python-t-strings/","date":1751457600,"author":"","guid":180432,"unread":true,"content":"<p>Evaluate your grasp of <a href=\"https://realpython.com/python-t-strings/\">Python’s t-strings</a>, which provide a structured and secure way to handle string templates.</p>","contentLength":114,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Qantas hack results in theft of 6 million passengers’ personal data","url":"https://techcrunch.com/2025/07/02/qantas-hack-results-in-theft-of-6-million-passengers-personal-data/","date":1751456909,"author":"Zack Whittaker","guid":180426,"unread":true,"content":"<article>Qantas, the largest airline in Australia, confirmed the theft of 6 million customers' personal information.</article>","contentLength":107,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Don’t use “click here” as link text (2001)","url":"https://www.w3.org/QA/Tips/noClickHere","date":1751456352,"author":"theandrewbailey","guid":180470,"unread":true,"content":"<h2>Don't use \"click here\" as link text</h2><p>When calling the user to action, use brief but meaningful link text\nthat:</p><ul><li>provides some information when read out of context</li><li>explains what the link offers</li><li>doesn't talk about mechanics</li></ul><p>For instance, avoid the following sentence on your page:</p><blockquote><p> To download W3C's editor/browser Amaya, <a href=\"https://www.w3.org/Amaya/\">click\nhere</a>.</p></blockquote><blockquote><p>\n  To download Amaya, go to the <a href=\"https://www.w3.org/Amaya/\">Amaya Website</a> and get\n  the necessary software.</p></blockquote><p>Both of these sentences divulge too much of the mechanics of getting the\nAmaya software. If you want to call your reader to action, use something\nlike:</p><p>Note that \"get\" is left out of the hypertext; we do not recommend putting\nverb phrases in link text. Thus, rather than:</p><blockquote><p>  Tell me more about <a href=\"https://www.w3.org/Amaya/\">Amaya</a>: W3C's free\n  editor/browser that lets you create <a href=\"https://www.w3.org/TR/html401\">HTML</a>,<a href=\"https://www.w3.org/TR/SVG/\"> SVG</a>, and <a href=\"https://www.w3.org/TR/MathML2/\">MathML</a>\n  documents.</p></blockquote><p>The <a href=\"https://www.w3.org/QA/Tips\">W3C QA Tips</a> are short documents explaining useful\nbits of knowledge for Web developers or designers, hosted and produced by the Quality Assurance \nInterest Group at W3C.</p><p>While the tips are carefully reviewed by the participants of the group, they should not be seen\nas anything else than informative bits of wisdom, and especially, they are \nnormative W3C technical specifications.</p><p>Learn more about the Tips, how to submit your own pearls of wisdom, and find all the other QA \ntips in the <a href=\"https://www.w3.org/QA/Tips/\">Tips Index</a>.</p>","contentLength":1285,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44442473"}],"tags":[]}