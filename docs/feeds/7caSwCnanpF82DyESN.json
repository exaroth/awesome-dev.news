{"id":"7caSwCnanpF82DyESN","title":"Official News","displayTitle":"Official News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":10,"items":[{"title":"From pixels to characters: The engineering behind GitHub Copilot CLI’s animated ASCII banner","url":"https://github.blog/engineering/from-pixels-to-characters-the-engineering-behind-github-copilot-clis-animated-ascii-banner/","date":1769619600,"author":"Aaron Winston","guid":425497,"unread":true,"content":"<p>Most people think ASCII art is simple, and a nostalgic remnant of the early internet. But when the GitHub Copilot CLI team asked for a small entrance banner for the new command-line experience, they discovered the opposite: An ASCII animation in a real-world terminal is one of the most constrained UI engineering problems you can take on.</p><p>Part of what makes this even more interesting is the moment we’re in. Over the past year, CLIs have seen a surge of investment as AI-assisted and agentic workflows move directly into the terminal. But unlike the web—where design systems, accessibility standards, and rendering models are well-established—the CLI world is still fragmented. Terminals behave differently, have few shared standards, and offer almost no consistent accessibility guidelines. That reality shaped every engineering decision in this project.</p><p>Different terminals interpret ANSI color codes differently. Screen readers treat fast-changing characters as noise. Layout engines vary. Buffers flicker. Some users override global colors for accessibility. Others throttle redraw speed. There is no canvas, no compositor, no consistent rendering model, and no standard animation framework.</p><p>So when an animated Copilot mascot flying into the terminal appeared, it looked playful. But behind it was serious engineering work, unexpected complexity, a custom design toolchain, and a tight pairing between a designer and a long-time CLI engineer.</p><p>That complexity only became fully visible once the system was built. In the end, animating a three-second ASCII banner required over 6,000 lines of TypeScript—most of it dedicated not to visuals, but to handling terminal inconsistencies, accessibility constraints, and maintainable rendering logic.</p><p>This is the technical story of how it came together.</p><h2>Why animated ASCII is a hard engineering problem</h2><p>Before diving into the build process, it’s worth calling out why this problem space is more advanced than it looks.</p><h3>Terminals don’t have a canvas</h3><p>Unlike browsers (DOM), native apps (views), or graphics frameworks (GPU surfaces), terminals treat output as a . There’s no native concept of:</p><ul></ul><p>Because of this, every “frame” has to be manually repainted using cursor movements and redraw commands. There’s no compositor smoothing anything over behind the scenes. Everything is stdout writes + ANSI control sequences.</p><h3>ANSI escape codes are inconsistent, and terminal color is its own engineering challenge</h3><p>ANSI escape codes like  (bright magenta) or  (cursor home) behave differently across terminals—not just in how they render, but in <em>whether they’re supported at all</em>. Some environments (like Windows Command Prompt or older versions of PowerShell) have limited or no ANSI support without extra configuration.</p><p>But even in terminals that do support ANSI, the hardest part isn’t the cursor movement. It’s the colors.</p><p>When you’re building a CLI, you realistically have three approaches:</p><ol><li>This guarantees broad compatibility, but makes it harder to highlight meaning or guide users’ attention—especially in dense CLI output.</li><li><strong>Use richer color modes (3-bit, 4-bit, 8-bit, or truecolor)</strong> that aren’t uniformly supported or customizable. This introduces a maintenance headache: Different terminals, themes, and accessibility profiles render the same color codes differently, and users often disagree about what “good” colors look like.</li><li><strong>Use a minimal, customizable palette (usually 4-bit colors)</strong> that most terminals allow users to override in their preferences. This is the safest path, but it limits how accurately you can represent a brand palette—and it forces you to design for environments with widely varying contrast and theme choices.</li></ol><p>For the Copilot CLI animation, this meant treating color as a  system, not a literal one: Instead of committing specific RGB values, the team mapped high-level “roles” (eyes, goggles, shadow, border) to ANSI colors that degrade gracefully across different terminals and accessibility settings.</p><h3>Accessibility is a first-class concern</h3><p>Terminals are used by developers with a wide range of visual abilities—not just blind users with screen readers, but also low-vision users, color-blind users, and anyone working in high-contrast or customized themes.</p><ul><li>Rapid re-renders can create auditory clutter for screen readers</li><li>Color-based meaning must degrade safely, since bold, dim, or subtle hues may not be perceivable</li><li>Low-vision users may not see contrast differences that designers expect</li><li>Animations must be opt-in, not automatic</li><li>Clearing sequences must avoid confusing assistive technologies</li></ul><p>This is also why the Copilot CLI animation ended up behind an opt-in flag early on—accessibility constraints shaped the architecture from the start.&nbsp;</p><p>These constraints guided every decision in the Copilot CLI animation. The banner had to work when colors were overridden, when contrast was limited, and even when the animation itself wasn’t visible.</p><h3>Ink (React for the terminal) helps, but it’s not an animation engine</h3><p><a href=\"https://github.com/vadimdemedes/ink\">Ink</a> lets you build terminal interfaces using React components, but:</p><ul><li>It re-renders on every state change</li><li>It doesn’t manage frame deltas</li><li>It doesn’t synchronize with terminal paint cycles</li><li>It doesn’t solve flicker or cursor ghosting</li></ul><p>Which meant animation logic had to be handcrafted.</p><h3>Frame-based ASCII animation has no existing workflow for designers</h3><p>There are tools for ASCII art, but virtually none for:</p><ul><li>Multi-color ANSI previews</li><li>Generating Ink-ready components</li><li>Testing contrast and accessibility</li></ul><p>Even existing ANSI preview tools don’t simulate how different terminals remap colors or handle cursor updates, which makes accurate design iteration almost impossible without custom tooling. So the team had to build one.</p><h2>Part 1: A request that didn’t fit any workflow</h2><p>Cameron Foxly (<a href=\"https://github.com/cameronfoxly\">@cameronfoxly</a>), a brand designer at GitHub with a background in animation, was asked to create a banner for the Copilot CLI.</p><p>“Normally, I’d build something in After Effects and hand off assets,” Cameron said. “But engineers didn’t have the time to manually translate animation frames into a CLI. And honestly, I wanted something more fun.”</p><p>He’d seen the static ASCII intro in Claude Code and knew Copilot deserved more personality.</p><p>The 3D Copilot mascot flying in to reveal the CLI logo felt right. But after attempting to create just  frame manually, the idea quickly ran into reality.</p><p>“It was a nightmare,” Cameron said. “If this is going to exist, I need to build my own tool.”</p><h2>Part 2: Building an ASCII animation editor from scratch</h2><p>Cameron opened an empty repository in VS Code, and began asking GitHub Copilot for help scaffolding an animation MVP that could:</p><ul><li>Read text files as frames</li><li>Clear the screen without flicker</li></ul><p>Within an hour, he had a working prototype that was monochrome, but functional.</p><h3>Simplified early animation loop</h3><p>Below is a simplified example variation of the frame loop logic Cameron prototyped:</p><pre><code>import fs from \"fs\";\nimport readline from \"readline\";\n\n/**\n * Load ASCII frames from a directory.\n */\nconst frames = fs\n  .readdirSync(\"./frames\")\n  .filter(f =&gt; f.endsWith(\".txt\"))\n  .map(f =&gt; fs.readFileSync(`./frames/${f}`, \"utf8\"));\n\nlet current = 0;\n\nfunction render() {\n  // Move cursor to top-left of terminal\n  readline.cursorTo(process.stdout, 0, 0);\n\n  // Clear the screen below the cursor\n  readline.clearScreenDown(process.stdout);\n\n  // Write the current frame\n  process.stdout.write(frames[current]);\n\n  // Advance to next frame\n  current = (current + 1) % frames.length;\n}\n\n// 75ms = ~13fps. Higher can cause flicker in some terminals.\nsetInterval(render, 75);</code></pre><p>This introduced the first major obstacle: color. The prototype worked in monochrome, but the moment color was added, inconsistencies across terminals—and accessibility constraints—became the dominant engineering problem.</p><h2>Part 3: ANSI color theory and the real-world limitations</h2><p>The Copilot brand palette is vibrant and high-contrast, which is great for web but exceptionally challenging for terminals.</p><ul><li>256-color mode (extended)</li><li>Sometimes truecolor (“24-bit”) but inconsistently</li></ul><p>Even in 256-color mode, terminals remap colors based on:</p><ul></ul><p>Which means you can’t rely on exact hues. You have to design with variability in mind.</p><p>Cameron needed a way to paint characters with ANSI color roles while previewing how they look in different terminals.</p><p>He took a screenshot of the <a href=\"https://en.wikipedia.org/wiki/ANSI_escape_code#Colors\">Wikipedia ANSI table</a>, handed it to Copilot, and asked it to scaffold a palette UI for his tool.</p><pre><code>function applyColor(char, color) {\n  // Minimal example: real implementation needed support for roles,\n  // contrast testing, and multiple ANSI modes.\n  const codes = {\n    magenta: \"\\x1b[35m\",\n    cyan: \"\\x1b[36m\",\n    white: \"\\x1b[37m\"\n  };\n\n  return `${codes[color]}${char}\\x1b[0m`; // Reset after each char\n}</code></pre><p>This enabled Cameron to paint ANSI-colored ASCII like you would in Photoshop, one character at a time.</p><p>But now he had to export it into the real Copilot CLI codebase.</p><h2>Part 4: Exporting to Ink (React for the terminal)</h2><p><a href=\"https://github.com/vadimdemedes/ink\">Ink</a> is a React renderer for building CLIs using JSX components. Instead of writing to the DOM, components render to stdout.</p><p>Cameron asked Copilot to help generate an Ink component that would:</p><ul><li>Animate them with state updates</li><li>Integrate cleanly into the CLI codebase</li></ul><h3>Simplified Ink frame renderer</h3><pre><code>import React from \"react\";\nimport { Box, Text } from \"ink\";\n\n/**\n * Render a single ASCII frame.\n */\nexport const CopilotBanner = ({ frame }) =&gt; (\n  &lt;Box flexDirection=\"column\"&gt;\n    {frame.split(\"\\n\").map((line, i) =&gt; (\n      &lt;Text key={i}&gt;{line}&lt;/Text&gt;\n    ))}\n  &lt;/Box&gt;\n);</code></pre><p>And a minimal animation wrapper:</p><pre><code>export const AnimatedBanner = () =&gt; {\n  const [i, setI] = React.useState(0);\n\n  React.useEffect(() =&gt; {\n    const id = setInterval(() =&gt; setI(x =&gt; (x + 1) % frames.length), 75);\n    return () =&gt; clearInterval(id);\n  }, []);\n\n  return &lt;CopilotBanner frame={frames[i]} /&gt;;\n};</code></pre><p>This gave Cameron the confidence to open a pull request (his first engineering pull request in nine years at GitHub).</p><p>“Copilot filled in syntax I didn’t know,” Cameron said. “But I still made all the architectural decisions.”</p><p>Now it was time for the engineering team to turn a prototype into something production-worthy.</p><h2>Part 5: Terminal animation isn’t solved technology</h2><p>Andy Feller (<a href=\"https://github.com/andyfeller\">@andyfeller</a>), a long-time GitHub engineer behind the GitHub CLI, partnered with Cameron to bring the animation into the Copilot CLI codebase.</p><p>Unlike browsers—which share rendering engines, accessibility APIs, and standards like WCAG—terminal environments are a patchwork of behaviors inherited from decades-old hardware like the VT100. There’s no DOM, no semantic structure, and only partial agreement on capabilities across terminals. This makes even “simple” UI design problems in the terminal uniquely challenging, especially as AI-driven workflows push CLIs into daily use for more developers.</p><p>“There’s no framework for terminal animations,” Andy explained. “We had to figure out how to do this without flickering, without breaking accessibility, and across wildly different terminals.”</p><p>Andy broke the engineering challenges into four broad categories:</p><h3>Challenge 1: From banner to ready without flickering</h3><p>Most terminals repaint the entire viewport when new content arrives. At the same time, CLIs come with a strict usability expectation: when developers run a command, they want to get to work immediately. Any animation that flickers, blocks input, or lingers too long actively degrades the experience.</p><p>This created a core tension the team had to resolve: how to introduce a brief, animated banner without slowing startup, stealing focus, or destabilizing the terminal render loop.</p><p>In practice, this was complicated by the fact that terminals behave differently under load. Some:</p><ul><li>Reveal cleared frames momentarily</li><li>Buffer output differently</li><li>Repaint the cursor region inconsistently</li></ul><p>To avoid flicker while keeping the CLI responsive across popular terminals like iTerm2, Windows Terminal, and VS Code, the team had to carefully coordinate several interdependent concerns:</p><ul><li>Keeping the animation under three seconds so it never delayed user interaction</li><li>Separating static and non-static components to minimize unnecessary redraws</li><li>Initializing MCP servers, custom agents, and user setup without blocking render</li><li>Working within Ink’s asynchronous re-rendering model</li></ul><p>The result was an animation treated as a non-blocking, best-effort enhancement—visible when it could be rendered safely, but never at the expense of startup performance or usability.</p><h3>Challenge 2: Brand color mapping in ANSI</h3><p>“ANSI color consistency simply doesn’t exist,” Andy said.&nbsp;</p><p>Most modern terminals support 8-bit color, allowing CLIs to choose from 256 colors. However, how those colors are actually rendered varies widely based on terminal themes, OS settings, and user accessibility overrides. In practice, CLIs can’t rely on exact hues—or even consistent contrast—across environments.</p><p>The Copilot banner introduced an additional complexity: although it’s rendered using text characters, the block-letter Copilot logo functions as a , not readable body text. Under accessibility guidelines, non-text graphical elements have different contrast requirements than text, and they must remain perceivable without relying on fine detail or precise color matching.</p><p>To account for this, the team deliberately chose a minimal 4-bit ANSI palette—one of the few color modes most terminals allow users to customize—to ensure the animation remained legible under high-contrast themes, low-vision settings, and color overrides.</p><p>This meant the team had to:</p><ul><li>Treat the Copilot wordmark as non-text graphical content with appropriate contrast requirements</li><li>Select ANSI color codes that  the Copilot palette without relying on exact hues</li><li>Satisfy WCAG contrast guidance for both text and non-text elements</li><li>Ensure the animation remained legible in light and dark terminals</li><li>Degrade gracefully when users override terminal colors for accessibility</li><li>Test color combinations across multiple terminal emulators and theme configurations</li></ul><p>Rather than encoding brand colors directly, the animation maps semantic roles—such as borders, eyes, highlights, and text—to ANSI color slots that terminals can reinterpret safely. This allows the banner to remain recognizable without assuming control over the user’s color environment.</p><h3>Challenge 3: Making the animation maintainable</h3><p>Cameron’s prototype was a great starting point for Andy to incorporate into the Copilot CLI but it wasn’t without its challenges:</p><ul><li>Banner consisted of ~20 animation frames covering an 11×78 area</li><li>There are ~10 animation elements to stylize in any given frame</li><li>Needed a way to separate the text of the frame from the colors involved</li><li>Each frame mapped hard coded colors to row and column coordinates</li><li>Each frame required precise timing to display Cameron’s vision</li></ul><p>First, the animation was broken down into distinct animation elements that could be used to create separate light and dark themes:</p><pre><code>type AnimationElements =\n    | \"block_text\"\n    | \"block_shadow\"\n    | \"border\"\n    | \"eyes\"\n    | \"head\"\n    | \"goggles\"\n    | \"shine\"\n    | \"stars\"\n    | \"text\";\n\ntype AnimationTheme = Record&lt;AnimationElements, ANSIColors&gt;;\n\nconst ANIMATION_ANSI_DARK: AnimationTheme = {\n    block_text: \"cyan\",\n    block_shadow: \"white\",\n    border: \"white\",\n    eyes: \"greenBright\",\n    head: \"magentaBright\",\n    goggles: \"cyanBright\",\n    shine: \"whiteBright\",\n    stars: \"yellowBright\",\n    text: \"whiteBright\",\n};\n\nconst ANIMATION_ANSI_LIGHT: AnimationTheme = {\n    block_text: \"blue\",\n    block_shadow: \"blackBright\",\n    border: \"blackBright\",\n    eyes: \"green\",\n    head: \"magenta\",\n    goggles: \"cyan\",\n    shine: \"whiteBright\",\n    stars: \"yellow\",\n    text: \"black\",\n};</code></pre><p>Next, the overall animation and subsequent frames would capture content, color, duration needed to animate the banner:</p><pre><code>interface AnimationFrame {\n    title: string;\n    duration: number;\n    content: string;\n    colors?: Record&lt;string, AnimationElements&gt;; // Map of \"row,col\" positions to animation elements\n}\n\ninterface Animation {\n    metadata: {\n        id: string;\n        name: string;\n        description: string;\n    };\n    frames: AnimationFrame[];\n}</code></pre><p>Then, each animation frame was captured to separate frame content from stylistic and animation details, resulting in over 6,000 lines of TypeScript to safely animate three seconds of the Copilot logo across terminals with wildly different rendering and accessibility behaviors:</p><pre><code>    const frames: AnimationFrame[] = [\n        {\n            title: \"Frame 1\",\n            duration: 80,\n            content: `\n┌┐\n││\n\n\n\n\n\n\n\n││\n└┘`,\n            colors: {\n                \"1,0\": \"border\",\n                \"1,1\": \"border\",\n                \"2,0\": \"border\",\n                \"2,1\": \"border\",\n                \"10,0\": \"border\",\n                \"10,1\": \"border\",\n                \"11,0\": \"border\",\n                \"11,1\": \"border\",\n            },\n        },\n        {\n            title: \"Frame 2\",\n            duration: 80,\n            content: `\n┌──     ──┐\n│         │\n █▄▄▄\n ███▀█\n ███ ▐▌\n ███ ▐▌\n   ▀▀█▌\n   ▐ ▌\n    ▐\n│█▄▄▌     │\n└▀▀▀    ──┘`,\n            colors: {\n                \"1,0\": \"border\",\n                \"1,1\": \"border\",\n                \"1,2\": \"border\",\n                \"1,8\": \"border\",\n                \"1,9\": \"border\",\n                \"1,10\": \"border\",\n                \"2,0\": \"border\",\n                \"2,10\": \"border\",\n                \"3,1\": \"head\",\n                \"3,2\": \"head\",\n                \"3,3\": \"head\",\n                \"3,4\": \"head\",\n                \"4,1\": \"head\",\n                \"4,2\": \"head\",\n                \"4,3\": \"goggles\",\n                \"4,4\": \"goggles\",\n                \"4,5\": \"goggles\",\n                \"5,1\": \"head\",\n                \"5,2\": \"goggles\",\n                \"5,3\": \"goggles\",\n                \"5,5\": \"goggles\",\n                \"5,6\": \"goggles\",\n                \"6,1\": \"head\",\n                \"6,2\": \"goggles\",\n                \"6,3\": \"goggles\",\n                \"6,5\": \"goggles\",\n                \"6,6\": \"goggles\",\n                \"7,3\": \"goggles\",\n                \"7,4\": \"goggles\",\n                \"7,5\": \"goggles\",\n                \"7,6\": \"goggles\",\n                \"8,3\": \"eyes\",\n                \"8,5\": \"head\",\n                \"9,4\": \"head\",\n                \"10,0\": \"border\",\n                \"10,1\": \"head\",\n                \"10,2\": \"head\",\n                \"10,3\": \"head\",\n                \"10,4\": \"head\",\n                \"10,10\": \"border\",\n                \"11,0\": \"border\",\n                \"11,1\": \"head\",\n                \"11,2\": \"head\",\n                \"11,3\": \"head\",\n                \"11,8\": \"border\",\n                \"11,9\": \"border\",\n                \"11,10\": \"border\",\n            },\n        },</code></pre><p>Finally, each animation frame is rendered building segments of text based on consecutive color usage with the necessary ANSI escape codes:</p><pre><code>           {frameContent.map((line, rowIndex) =&gt; {\n                const truncatedLine = line.length &gt; 80 ? line.substring(0, 80) : line;\n                const coloredChars = Array.from(truncatedLine).map((char, colIndex) =&gt; {\n                    const color = getCharacterColor(rowIndex, colIndex, currentFrame, theme, hasDarkTerminalBackground);\n                    return { char, color };\n                });\n\n                // Group consecutive characters with the same color\n                const segments: Array&lt;{ text: string; color: string }&gt; = [];\n                let currentSegment = { text: \"\", color: coloredChars[0]?.color || theme.COPILOT };\n\n                coloredChars.forEach(({ char, color }) =&gt; {\n                    if (color === currentSegment.color) {\n                        currentSegment.text += char;\n                    } else {\n                        if (currentSegment.text) segments.push(currentSegment);\n                        currentSegment = { text: char, color };\n                    }\n                });\n                if (currentSegment.text) segments.push(currentSegment);\n\n                return (\n                    &lt;Text key={rowIndex} wrap=\"truncate\"&gt;\n                        {segments.map((segment, segIndex) =&gt; (\n                            &lt;Text key={segIndex} color={segment.color}&gt;\n                                {segment.text}\n                            &lt;/Text&gt;\n                        ))}\n                    &lt;/Text&gt;\n                );\n            })}</code></pre><h2>Challenge 4: Accessibility-first design</h2><ul><li>Respect global color overrides both in terminal and system preferences</li><li>After the first use, avoid animations unless explicitly enabled via the Copilot CLI configuration file</li><li>Minimize ANSI instructions that can confuse assistive tech</li></ul><p>“CLI accessibility is under researched,” Andy noted. “We’ve learned a lot from users who are blind as well as users with low vision, and those lessons shaped this project.”</p><p>Because of this, the animation is opt-in and gated behind its own flag—so it’s not something developers see by default. And when developers run the CLI in –screen-reader mode, the banner is automatically skipped so no decorative characters or motion are sent to assistive technologies.</p><h2>Part 6: An architecture built to scale</h2><p>By the end of the refactor, the team had:</p><ul><li>Frames stored as plain text</li><li>Themes as simple mappings</li><li>A runtime colorization step</li><li>Ink-driven timing and rendering</li><li>A maintainable foundation for future animations</li></ul><p>This pattern—storing frames as plain text, layering semantic roles, and applying themes at runtime—isn’t specific to Copilot. It’s a reusable approach for anyone building terminal UIs or animations.</p><h2>Part 7: What this project reveals about building for the terminal</h2><p>A “simple ASCII banner” turned into:</p><ul><li>A frame-based animation tool that didn’t exist</li><li>A custom ANSI color palette strategy</li><li>A maintainable rendering architecture</li><li>Accessibility-first CLI design choices</li><li>A designer’s first engineering contribution</li><li>Real-world testing across diverse terminals</li><li>Open source contributions from the community</li></ul><p>“The most rewarding part was stepping into open source for the first time,” Cameron said. “With Copilot, I was able to build out&nbsp; my MVP ASCII animation tool into a full open source app at <a href=\"http://ascii-motion.app\">ascii-motion.app</a>,. Someone fixed a typo in my <a href=\"https://github.com/CameronFoxly/Ascii-Motion\">README</a>, and it made my day.”</p><p>As Andy pointed out, building accessible experiences for CLIs is still largely unexplored territory and far behind the tooling and standards available for the web.</p><p>Today, developers are already contributing to Cameron’s ASCII Motion tool, and the Copilot CLI team can ship new animations without rebuilding the system.</p><p>This is what building for the terminal demands: deep understanding of constraints, discipline around accessibility, and the willingness to invent tooling where none exists.</p><h3>Use GitHub Copilot in your terminal</h3><p>The GitHub Copilot CLI brings AI-assisted workflows directly into your terminal — including commands for explaining code, generating files, refactoring, testing, and navigating unfamiliar projects.</p>","contentLength":23045,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Year recap and future goals for the GitHub Innovation Graph","url":"https://github.blog/news-insights/policy-news-and-insights/year-recap-and-future-goals-for-the-github-innovation-graph/","date":1769616000,"author":"Kevin Xu","guid":425496,"unread":true,"content":"<p>Today’s data release marks our second full year of regular releases since the<a href=\"https://github.blog/news-insights/policy-news-and-insights/announcing-the-github-innovation-graph/\"> launch of the GitHub Innovation Graph</a>. The Innovation Graph serves as a stable, regularly updated source for aggregated statistics on public software development activity around the world, informing public policy, strengthening research, guiding funding decisions, and equippingorganizations with the evidence needed to build secure and resilient AI systems.&nbsp;&nbsp;</p><p>Let’s take a look back at some of the progress the Innovation Graph has helped drive.&nbsp;</p><p>One of the most rewarding aspects of the past year has been seeing the growing range of research questions addressed with Innovation Graph data. Recent papers have explored everything from global collaboration networks to the institutional foundations of digital capabilities.</p><p>These studies showcase how network analysis techniques can be applied to Innovation Graph data, in addition to&nbsp; <a href=\"https://github.blog/news-insights/policy-news-and-insights/thats-a-wrap-github-innovation-graph-in-2024/#academic-papers\">earlier work we referenced last year</a> linking open source to economic value, innovation measurement, labor markets, and AI-driven productivity through other methodologies.</p><h3>Historical Institutions and Modern Digital Capabilities: New Evidence from GitHub in Africa</h3><p>Research by an economist at the Federal Reserve Board uses GitHub data to examine how the density of Protestant mission stations correlates with present-day participation in digital production across African countries.</p><h3>The Structure of Cross-National Collaboration in Open-Source Software Development</h3><p>Researchers from MIT, Carnegie Mellon, and the University of Chicago analyze international collaboration patterns in the Innovation Graph’s economy collaborators dataset, shedding light on how common colonial histories influence modern software development collaboration activities.</p><ul><li>Xu, Henry, et al. “The Structure of Cross-National Collaboration in Open-Source Software Development,” (November 10, 2025). Available at doi.org/10.1145/3746252.3761237.</li></ul><h3>Small-World Phenomenon of Global Open-Source Software Collaboration on GitHub</h3><p>A social network analysis by researchers at Midwestern State University and Tarleton State University highlights the tightly connected, <a href=\"https://en.wikipedia.org/wiki/Six_degrees_of_separation\">small-world</a> structure of global OSS collaboration.</p><ul><li>Zhang, Guoying, et al. “Small-World Phenomenon of Global Open-Source Software Collaboration on Github: A Social Network Analysis.” <em>Journal of Global Information Management</em> Vol. 33, No. 1 (2025). Available at doi.org/10.4018/JGIM.387412.&nbsp;</li></ul><p>These researchers extend countries’ software economic complexity into the digital economy by leveraging the geographic distribution of programming languages in open source software, showing that software economic complexity predicts GDP, income inequality, and emissions, which have important policy implications.</p><p>The Innovation Graph and related GitHub datasets were featured prominently in academic and policy discussions at a wide range of venues, including:</p><p>Once again, Innovation Graph data contributed to several flagship reports, including:</p><p>We continue to value these opportunities to support macro-level measurement efforts, and we’re equally excited by complementary work that dives deeper into regional, institutional, and community-level dynamics.</p><p>As we move through 2026, we’re grateful for the community that has formed around the Innovation Graph, and we’re looking forward to building the next chapter together. Our focus will be on deepening collaboration, welcoming new perspectives, and creating clearer pathways for people to apply the Innovation Graph data in their own contexts, from strategy and research to product development and policy.</p>","contentLength":3607,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Experimenting with Gateway API using kind","url":"https://kubernetes.io/blog/2026/01/28/experimenting-gateway-api-with-kind/","date":1769558400,"author":"","guid":424094,"unread":true,"content":"<p>This document will guide you through setting up a local experimental environment with <a href=\"https://gateway-api.sigs.k8s.io/\">Gateway API</a> on <a href=\"https://kind.sigs.k8s.io/\">kind</a>. This setup is designed for learning and testing. It helps you understand Gateway API concepts without production complexity.</p><div role=\"alert\">This is an experimentation learning setup, and should not be used for production. The components used on this document are not suited for production usage.\nOnce you're ready to deploy Gateway API in a production environment,\nselect an <a href=\"https://gateway-api.sigs.k8s.io/implementations/\">implementation</a> that suits your needs.</div><ul><li>Set up a local Kubernetes cluster using kind (Kubernetes in Docker)</li><li>Deploy <a href=\"https://github.com/kubernetes-sigs/cloud-provider-kind\">cloud-provider-kind</a>, which provides both LoadBalancer Services and a Gateway API controller</li><li>Create a Gateway and HTTPRoute to route traffic to a demo application</li><li>Test your Gateway API configuration locally</li></ul><p>This setup is ideal for learning, development, and experimentation with Gateway API concepts.</p><p>Before you begin, ensure you have the following installed on your local machine:</p><ul><li> - Required to run kind and cloud-provider-kind</li><li> - The Kubernetes command-line tool</li><li> - Kubernetes in Docker</li><li> - Required to test the routes</li></ul><p>Create a new kind cluster by running:</p><p>This will create a single-node Kubernetes cluster running in a Docker container.</p><h3>Install cloud-provider-kind</h3><ul><li>A LoadBalancer controller that assigns addresses to LoadBalancer-type Services</li><li>A Gateway API controller that implements the Gateway API specification</li></ul><p>It also automatically installs the Gateway API Custom Resource Definitions (CRDs) in your cluster.</p><p>Run cloud-provider-kind as a Docker container on the same host where you created the kind cluster:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p> On some systems, you may need elevated privileges to access the Docker socket.</p><p>Verify that cloud-provider-kind is running:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>You should see the container listed and in a running state. You can also check the logs:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><h2>Experimenting with Gateway API</h2><p>Now that your cluster is set up, you can start experimenting with Gateway API resources.</p><p>cloud-provider-kind automatically provisions a GatewayClass called . You'll use this class to create your Gateway.</p><p>It is worth noticing that while kind is not a cloud provider, the project is named as  as it provides features that simulate a cloud-enabled environment.</p><p>The following manifest will:</p><ul><li>Create a new namespace called </li><li>Deploy a Gateway that listens on port 80</li><li>Accept HTTPRoutes with hostnames matching the  pattern</li><li>Allow routes from any namespace to attach to the Gateway.\n: In real clusters, prefer Same or Selector values on the <a href=\"https://gateway-api.sigs.k8s.io/reference/spec/#fromnamespaces\"> namespace selector</a> field to limit attachments.</li></ul><p>Apply the following manifest:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>Then verify that your Gateway is properly programmed and has an address assigned:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><pre tabindex=\"0\"><code>NAME CLASS ADDRESS PROGRAMMED AGE\ngateway cloud-provider-kind 172.18.0.3 True 5m6s\n</code></pre><p>The PROGRAMMED column should show True, and the ADDRESS field should contain an IP address.</p><h3>Deploy a demo application</h3><p>Next, deploy a simple echo application that will help you test your Gateway configuration. This application:</p><ul><li>Echoes back request details including path, headers, and environment variables</li><li>Runs in a namespace called </li></ul><p>Apply the following manifest:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>Now create an HTTPRoute to route traffic from your Gateway to the echo application.\nThis HTTPRoute will:</p><ul><li>Respond to requests for the hostname <code>some.exampledomain.example</code></li><li>Route traffic to the echo application</li><li>Attach to the Gateway in the  namespace</li></ul><p>Apply the following manifest:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>The final step is to test your route using curl. You'll make a request to the Gateway's IP address with the hostname <code>some.exampledomain.example</code>. The command below is for POSIX shell only, and may need to be adjusted for your environment:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>You should receive a JSON response similar to this:</p><div><pre tabindex=\"0\"><code data-lang=\"json\"></code></pre></div><p>If you see this response, congratulations! Your Gateway API setup is working correctly.</p><p>If something isn't working as expected, you can troubleshoot by checking the status of your resources.</p><p>First, inspect your Gateway resource:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>Look at the  section for conditions. Your Gateway should have:</p><ul><li> - The Gateway was accepted by the controller</li><li> - The Gateway was successfully configured</li><li> populated with an IP address</li></ul><h3>Check the HTTPRoute status</h3><p>Next, inspect your HTTPRoute:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>Check the  section for conditions. Common issues include:</p><ul><li>ResolvedRefs set to False with reason ; this means that the backend Service doesn't exist or has the wrong name</li><li>Accepted set to False; this means that the route couldn't attach to the Gateway (check namespace permissions or hostname matching)</li></ul><p>Example error when a backend is not found:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>If the resource statuses don't reveal the issue, check the cloud-provider-kind logs:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>This will show detailed logs from both the LoadBalancer and Gateway API controllers.</p><p>When you're finished with your experiments, you can clean up the resources:</p><h3>Remove Kubernetes resources</h3><p>Delete the namespaces (this will remove all resources within them):</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>Stop and remove the cloud-provider-kind container:</p><div><pre tabindex=\"0\"><code data-lang=\"shell\"></code></pre></div><p>Because the container was started with the  flag, it will be automatically removed when stopped.</p><p>Finally, delete the kind cluster:</p><p>Now that you've experimented with Gateway API locally, you're ready to explore production-ready implementations:</p><ul><li>: Explore the <a href=\"https://gateway-api.sigs.k8s.io/\">Gateway API documentation</a> to learn about advanced features like TLS, traffic splitting, and header manipulation</li><li>: Experiment with path-based routing, header matching, request mirroring and other features following <a href=\"https://gateway-api.sigs.k8s.io/guides/getting-started/\">Gateway API user guides</a></li></ul><p>This  setup is for development and learning only.\nAlways use a production-grade Gateway API implementation for real workloads.</p>","contentLength":5400,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"7 learnings from Anders Hejlsberg: The architect behind C# and TypeScript","url":"https://github.blog/developer-skills/programming-languages-and-frameworks/7-learnings-from-anders-hejlsberg-the-architect-behind-c-and-typescript/","date":1769534248,"author":"Aaron Winston","guid":423919,"unread":true,"content":"<p>Anders Hejlsberg’s work has shaped how millions of developers code. Whether or not you recognize his name, you likely have touched his work: He’s the creator of Turbo Pascal and Delphi, the lead architect of C#, and the designer of TypeScript.&nbsp;</p><p>We sat down with Hejlsberg to discuss his illustrious career and what it’s felt like to watch his innovations stand up to real world pressure. In a long-form conversation, Hejlsberg reflects on what language design looks like once the initial excitement fades, when performance limits appear, when open source becomes unavoidable, and how AI can impact a tool’s original function.</p><p>What emerges is a set of patterns for building systems that survive contact with scale. Here’s what we learned.</p><p><em>Watch the full interview above.</em></p><h2>Fast feedback matters more than almost anything else</h2><p>Hejlberg’s early instincts were shaped by extreme constraints. In the era of 64KB machines, there was no room for abstraction that did not pull its weight.</p><p>“You could keep it all in your head,” he recalls.</p><blockquote><p>When you typed your code, you wanted to run it immediately.</p></blockquote><p>Turbo Pascal’s impact did not come from the Pascal language itself. It came from shortening the feedback loop. Edit, compile, run, fail, repeat, without touching disk or waiting for tooling to catch up. That tight loop respected developers’ time and attention.</p><p>The same idea shows up decades later in TypeScript, although in a different form. The language itself is only part of the story. Much of TypeScript’s value comes from its tooling: incremental checking, fast partial results, and language services that respond quickly even on large codebases.</p><p>The lesson here is not abstract. Developers can apply this directly to how they evaluate and choose tools. Fast feedback changes behavior. When errors surface quickly, developers experiment more, refactor more confidently, and catch problems closer to the moment they are introduced. When feedback is slow or delayed, teams compensate with conventions, workarounds, and process overhead.&nbsp;</p><p>Whether you’re choosing a language, framework, or internal tooling, responsiveness matters. Tools that shorten the distance between writing code and understanding its consequences tend to earn trust. Tools that introduce latency, even if they’re powerful, often get sidelined.&nbsp;</p><h2>Scaling software means letting go of personal preferences&nbsp;</h2><p>As Hejlsberg moved from largely working alone to leading teams, particularly during the Delphi years, the hardest adjustment wasn’t technical.</p><p>It was learning to let go of personal preferences.</p><blockquote><p>You have to accept that things get done differently than you would have preferred. Fixing it would not really change the behavior anyway.</p></blockquote><p>That mindset applies well beyond language design. Any system that needs to scale across teams requires a shift from personal taste to shared outcomes. The goal stops being code that looks the way you would write it, and starts being code that many people can understand, maintain, and evolve together. C# did not emerge from a clean-slate ideal. It emerged from conflicting demands. Visual Basic developers wanted approachability, C++ developers wanted power, and Windows demanded pragmatism.</p><p>The result was not theoretical purity. It was a language that enough people could use effectively.</p><p>Languages do not succeed because they are perfectly designed. They succeed because they accommodate the way teams actually work.</p><h2>Why TypeScript extended JavaScript instead of replacing it</h2><p>TypeScript exists because JavaScript succeeded at a scale few languages ever reach. As browsers became the real cross-platform runtime, teams started building applications far larger than dynamic typing comfortably supports.</p><p>Early attempts to cope were often extreme. Some teams compiled other languages into JavaScript just to get access to static analysis and refactoring tools.</p><p>That approach never sat well with Hejlsberg.</p><p>Telling developers to abandon the ecosystem they were already in was not realistic. Creating a brand-new language in 2012 would have required not just a compiler, but years of investment in editors, debuggers, refactoring tools, and community adoption.</p><p>Instead, TypeScript took a different path. It extended JavaScript in place, inheriting its flaws while making large-scale development more tractable.</p><p>This decision was not ideological, but practical. TypeScript succeeded because it worked with the constraints developers already had, rather than asking them to abandon existing tools, libraries, and mental models.&nbsp;</p><p>The broader lesson is about compromise. Improvements that respect existing workflows tend to spread while improvements that require a wholesale replacement rarely do. In practice, meaningful progress often comes from making the systems you already depend on more capable instead of trying to start over.</p><h2>Visibility is a part of what makes open source work</h2><p>TypeScript did not take off immediately. Early releases were nominally open source, but development still happened largely behind closed doors.</p><p>That changed in 2014 when the project moved to GitHub and adopted a fully public development process. Features were proposed through pull requests, tradeoffs were discussed in the open, and issues were prioritized based on community feedback.</p><p>This shift made decision-making visible. Developers could see not just what shipped, but why certain choices were made and others were not. For the team, it also changed how work was prioritized. Instead of guessing what mattered most, they could look directly at the issues developers cared about.</p><p>The most effective open source projects do more than share code. They make decision-making visible so contributors and users can understand how priorities are set, and why tradeoffs are made.</p><h2>Leaving JavaScript as an implementation language was a necessary break</h2><p>For many years, TypeScript was self-hosted. The compiler was written in TypeScript and ran as JavaScript. This enabled powerful browser-based tooling and made experimentation easy.</p><p>Over time, however, the limitations became clear. JavaScript is single-threaded, has no shared-memory concurrency, and its object model is flexible (but expensive). As TypeScript projects grew, the compiler was leaving a large amount of available compute unused.</p><p>The team reached a point where further optimization would not be enough. They needed a different execution model.</p><p>The controversial decision was to port the compiler to Go.</p><p>This was not a rewrite. The goal was semantic fidelity. The new compiler needed to behave exactly like the old one, including quirks and edge cases. Rust, despite its popularity, would have required significant redesign due to ownership constraints and pervasive cyclic data structures. Go’s garbage collection and structural similarity made it possible to preserve behavior while unlocking performance and concurrency.</p><p>The result was substantial performance gains, split between native execution and parallelism. More importantly, the community did not have to relearn the compiler’s behavior.</p><p>Sometimes the most responsible choice isn’t the most ambitious one, but instead preserves behavior, minimizes disruption, and removes a hard limit that no amount of incremental optimization can overcome.</p><h2>In an AI-driven workflow, grounding matters more than generation</h2><p>Hejlberg is skeptical of the idea of AI-first programming languages. Models are best at languages they have already seen extensively, which naturally favors mainstream ecosystems like JavaScript, Python, and TypeScript.</p><p>But AI does change things when it comes to tooling.</p><p>The traditional IDE model assumed a developer writing code and using tools for assistance along the way. Increasingly, that relationship is reversing. AI systems generate code. Developers supervise and correct. Deterministic tools like type checkers and refactoring engines provide guardrails that prevent subtle errors.</p><p>In that world, the value of tooling is not creativity. It is accuracy and constraint. Tools need to expose precise semantic information so that AI systems can ask meaningful questions and receive reliable answers.</p><p>The risk is not that AI systems will generate bad code. Instead, it’s that they will generate plausible, confident code that lacks enough grounding in the realities of a codebase.&nbsp;</p><p>For developers, this shifts where attention should go. The most valuable tools in an AI-assisted workflow aren’t the ones that generate the most code, but the ones that constrain it correctly. Strong type systems, reliable refactoring tools, and accurate semantic models become essential guardrails. They provide the structure that allows AI output to be reviewed, validated, and corrected efficiently instead of trusted blindly.&nbsp;</p><h2>Why open collaboration is critical</h2><p>Despite the challenges of funding and maintenance, Hejlberg remains optimistic about open collaboration. One reason is institutional memory. Years of discussion, decisions, and tradeoffs remain searchable and visible.</p><p>That history does not disappear into private email threads or internal systems. It remains available to anyone who wants to understand how and why a system evolved.</p><p>Despite the challenges of funding and maintenance, Hejlsberg remains optimistic about open collaboration. And a big reason is institutional memory.</p><p>“We have 12 years of history captured in our project,” he explains. “If someone remembers that a discussion happened, we can usually find it. The context doesn’t disappear into email or private systems.”</p><p>That visibility changes how systems evolve. Design debates, rejected ideas, and tradeoffs remain accessible long after individual decisions are made. For developers joining a project later, that shared context often matters as much as the code itself.</p><h2>A pattern that repeats across decades</h2><p>Across four decades of language design, the same themes recur:</p><ul><li>Fast feedback loops matter more than elegance</li><li>Systems need to accommodate imperfect code written by many people</li><li>Behavioral compatibility often matters more than architectural purity</li><li>Visible tradeoffs build trust</li></ul><p>These aren’t secondary concerns. They’re fundamental decisions that determine whether a tool can adapt as its audience grows. Moreover, they ground innovation by ensuring new ideas can take root without breaking what already works.</p><p>For anyone building tools they want to see endure, those fundamentals matter as much as any breakthrough feature. And that may be the most important lesson of all.</p>","contentLength":10459,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cluster API v1.12: Introducing In-place Updates and Chained Upgrades","url":"https://kubernetes.io/blog/2026/01/27/cluster-api-v1-12-release/","date":1769529600,"author":"","guid":424050,"unread":true,"content":"<p><a href=\"https://cluster-api.sigs.k8s.io/\">Cluster API</a> brings declarative management to Kubernetes cluster lifecycle, allowing users and platform teams to define the desired state of clusters and rely on controllers to continuously reconcile toward it.</p><p>Similar to how you can use StatefulSets or Deployments in Kubernetes to manage a group of Pods, in Cluster API you can use KubeadmControlPlane to manage a set of control plane Machines, or you can use MachineDeployments to manage a group of worker Nodes.</p><p>The <a href=\"https://github.com/kubernetes-sigs/cluster-api/releases/tag/v1.12.0\">Cluster API v1.12.0</a> release expands what is possible in Cluster API, reducing friction in common lifecycle operations by introducing in-place updates and chained upgrades.</p><h2>Emphasis on simplicity and usability</h2><p>With v1.12.0, the Cluster API project demonstrates once again that this community is capable of delivering a great amount of innovation, while at the same time minimizing impact for Cluster API users.</p><p>What does this mean in practice?</p><p>Users simply have to change the <a href=\"https://cluster-api.sigs.k8s.io/user/concepts#cluster\">Cluster</a> or the <a href=\"https://cluster-api.sigs.k8s.io/user/concepts#machine\">Machine</a> spec (just as with previous Cluster API releases), and Cluster API will automatically trigger in-place updates or chained upgrades when possible and advisable.</p><p>Like Kubernetes does for Pods in Deployments, when the <a href=\"https://cluster-api.sigs.k8s.io/user/concepts#machine\">Machine</a> spec changes also Cluster API performs rollouts by creating a new Machine and deleting the old one.</p><p>This approach, inspired by the principle of immutable infrastructure, has a set of considerable advantages:</p><ul><li>It is simple to explain, predictable, consistent and easy to reason about with users and engineers.</li><li>It is simple to implement, because it relies only on two core primitives, create and delete.</li><li>Implementation does not depend on Machine-specific choices, like OS, bootstrap mechanism etc.</li></ul><p>As a result, Machine rollouts drastically reduce the number of variables to be considered when managing the lifecycle of a host server that is hosting Nodes.</p><p>However, while advantages of immutability are not under discussion, both Kubernetes and Cluster API are undergoing a similar journey, introducing changes that allow users to minimize workload disruption whenever possible.</p><p>Over time, also Cluster API has introduced several improvements to immutable rollouts, including:</p><p>The new <a href=\"https://github.com/kubernetes-sigs/cluster-api/blob/main/docs/proposals/20240807-in-place-updates.md\">in-place update</a> feature in Cluster API is the next step in this journey.</p><p>With the v1.12.0 release, Cluster API introduces support for <a href=\"https://cluster-api.sigs.k8s.io/tasks/experimental-features/runtime-sdk/implement-in-place-update-hooks\">update extensions</a> allowing users to make changes on existing machines in-place, without deleting and re-creating the Machines.</p><p>Both KubeadmControlPlane and MachineDeployments support in-place updates based on the new update extension, and this means that the boundary of what is possible in Cluster API is now changed in a significant way.</p><p>How do in-place updates work?</p><p>The simplest way to explain it is that once the user triggers an update by changing the desired state of Machines, then Cluster API chooses the best tool to achieve the desired state.</p><p>The news is that now Cluster API can choose between immutable rollouts and in-place update extensions to perform required changes.</p><p>Importantly, this is not immutable rollouts vs in-place updates; Cluster API considers both valid options and selects the most appropriate mechanism for a given change.</p><p>From the perspective of the Cluster API maintainers, in-place updates are most useful for making changes that don't otherwise require a node drain or pod restart; for example: changing user credentials for the Machine. On the other hand, when the workload will be disrupted anyway, just do a rollout.</p><p>Nevertheless, Cluster API remains true to its extensible nature, and everyone can create their own update extension and decide when and how to use in-place updates by trading in some of the benefits of immutable rollouts.</p><p><a href=\"https://cluster-api.sigs.k8s.io/tasks/experimental-features/cluster-class/\">ClusterClass</a> and managed topologies in Cluster API jointly provided a powerful and effective framework that acts as a building block for many platforms offering Kubernetes-as-a-Service.</p><p>Now with v1.12.0 this feature is making another important step forward, by allowing users to upgrade by more than one Kubernetes minor version in a single operation, commonly referred to as a <a href=\"https://github.com/kubernetes-sigs/cluster-api/blob/main/docs/proposals/20250513-chained-and-efficient-upgrades-for-clusters-with-managed-topologies.md\">chained upgrade</a>.</p><p>This allows users to declare a target Kubernetes version and let Cluster API safely orchestrate the required intermediate steps, rather than manually managing each minor upgrade.</p><p>The simplest way to explain how chained upgrades work, is that once the user triggers an update by changing the desired version for a Cluster, Cluster API computes an upgrade plan, and then starts executing it. Rather than (for example) update the Cluster to v1.33.0 and then v1.34.0 and then v1.35.0, checking on progress at each step, a chained upgrade lets you go directly to v1.35.0.</p><p>Executing an upgrade plan means upgrading control plane and worker machines in a strictly controlled order, repeating this process as many times as needed to reach the desired state. The Cluster API is now capable of managing this for you.</p><p>Cluster API takes care of optimizing and minimizing the upgrade steps for worker machines, and in fact worker machines will skip upgrades to intermediate Kubernetes minor releases whenever allowed by the Kubernetes version skew policies.</p><p>Also in this case extensibility is at the core of this feature, and <a href=\"https://cluster-api.sigs.k8s.io/tasks/experimental-features/runtime-sdk/implement-upgrade-plan-hooks\">upgrade plan runtime extensions</a> can be used to influence how the upgrade plan is computed; similarly, <a href=\"https://cluster-api.sigs.k8s.io/tasks/experimental-features/runtime-sdk/implement-lifecycle-hooks\">lifecycle hooks</a> can be used to automate other tasks that must be performed during an upgrade, e.g. upgrading an addon after the control plane update completed.</p><p>From our perspective, chained upgrades are most useful for users that struggle to keep up with Kubernetes minor releases, and e.g. they want to upgrade only once per year and then upgrade by three versions (n-3 → n). But be warned: the fact that you can now easily upgrade by more than one minor version is not an excuse to not patch your cluster frequently!</p><p>I would like to thank all the contributors, the maintainers, and all the engineers that volunteered for the release team.</p><p>The reliability and predictability of Cluster API releases, which is one of the most appreciated features from our users, is only possible with the support, commitment, and hard work of its community.</p><p>Kudos to the entire Cluster API community for the v1.12.0 release and all the great releases delivered in 2025!\n​​\nIf you are interested in getting involved, learn about\n<a href=\"https://cluster-api.sigs.k8s.io/contributing\">Cluster API contributing guidelines</a>.</p><p>If you read the <a href=\"https://cluster-api.sigs.k8s.io/user/manifesto\">Cluster API manifesto</a>, you can see how the Cluster API subproject claims the right to remain unfinished, recognizing the need to continuously evolve, improve, and adapt to the changing needs of Cluster API’s users and the broader Cloud Native ecosystem.</p><p>As Kubernetes itself continues to evolve, the Cluster API subproject will keep advancing alongside it, focusing on safer upgrades, reduced disruption, and stronger building blocks for platforms managing Kubernetes at scale.</p><p>Innovation remains at the heart of Cluster API, stay tuned for an exciting 2026!</p>","contentLength":6886,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rust at Scale: An Added Layer of Security for WhatsApp","url":"https://engineering.fb.com/2026/01/27/security/rust-at-scale-security-whatsapp/","date":1769526009,"author":"","guid":423809,"unread":true,"content":"<ul></ul><h2></h2><h2>2015 Android Vulnerability: A Wake-up Call for Media File Protections</h2><p><a href=\"https://www.cisa.gov/news-events/alerts/2015/07/28/stagefright-android-vulnerability\" target=\"_blank\" rel=\"noopener\"></a></p><h2></h2><h2>How Rust Fits In To WhatsApp’s Approach to App Security</h2><p><a href=\"https://www.whatsapp.com/security/advisories\" target=\"_blank\" rel=\"noopener\"></a></p><p><a href=\"https://research.nccgroup.com/2021/10/27/public-report-whatsapp-end-to-end-encrypted-backups-security-assessment/\" target=\"_blank\" rel=\"noopener\"></a><a href=\"https://engineering.fb.com/2021/10/20/security/static-analysis-award/\" target=\"_blank\" rel=\"noopener\"></a><a href=\"https://bugbounty.meta.com/\" target=\"_blank\" rel=\"noopener\"></a><a href=\"https://bugbounty.meta.com/blog/15th-anniversary-2025/\" target=\"_blank\" rel=\"noopener\"></a></p><ol></ol><h2></h2>","contentLength":126,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Help shape the future of open source in Europe","url":"https://github.blog/news-insights/policy-news-and-insights/help-shape-the-future-of-open-source-in-europe/","date":1769523364,"author":"Mathias Schindler","guid":423795,"unread":true,"content":"<p>At GitHub, we believe that open source is a primary driver of innovation, security, and economic competitiveness. The European Union is currently at a pivotal moment in defining how it supports this ecosystem, and it wants to hear from you, the builders.</p><p>The European Commission is planning to adopt an open source strategy called “<a href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/16213-European-Open-Digital-Ecosystems_en\">Towards European Open Digital Ecosystems</a>“. This initiative is not about passing new laws; instead the EU is looking to develop a strategic framework and funding measures to help the EU open source sector scale up and become more competitive. This effort aims to strengthen the EU’s technological sovereignty by supporting open source software and hardware across critical sectors like AI, cloud computing, and cybersecurity.&nbsp;</p><p>We’ve been advocating for this kind of support for a long time. For instance, we previously highlighted the <a href=\"https://github.blog/open-source/maintainers/we-need-a-european-sovereign-tech-fund/\">need for a European Sovereign Tech Fund</a> to invest in the maintenance of critical basic open source technologies such as libraries or programming languages. This new strategy is a chance to turn those kinds of ideas into official EU policy.</p><p>You can read GitHub’s response to the European Commission <a href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/16213-European-Open-Digital-Ecosystems/F33367935_en\">here</a>.&nbsp; Brand new data from GitHub Innovation Graph shows that the EU is a global open source powerhouse: There are now almost 25 million EU developers on GitHub, who made over 155 million contributions to public projects in the last year alone.</p><p>The EU wants to help European companies turn open source projects into successful businesses, which is an admirable goal with plenty of opportunities to achieve it. For example, the EU can create better conditions for open source businesses by making it easier for them to participate in public procurement and access the growth capital they need to turn great code into sustainable products. By supporting the business models and infrastructure that surround it, the EU can turn its massive developer talent into long-term economic leadership.</p><p>It is important to understand, though, that not all open source projects can be turned into commercial products—and that commercialization is not every developer’s goal. A successful EU open source policy should also support the long-term sustainability of non-commercially produced open source components that benefit us all.</p><p>That is why the European Commission needs to hear the full spectrum of experiences from the community—from individual maintainers, startups, companies, and researchers. Over 900 people have already shared their views, and we encourage you to join them. The European Commission is specifically looking for responses covering these five topics:</p><ol><li>: What is standing in the way of open source adoption and sustainable open source contributions in the EU?</li><li>: How does open source benefit the public and private sectors?</li><li>: What should the EU do to support open source?</li><li>: Which technologies (e.g., AI, IoT, or Cloud) should be the focus?</li><li>: In which industries (e.g., automotive or manufacturing) could open source increase competitiveness and cybersecurity?</li></ol><p>The “Call for Evidence” is your opportunity to help shape the future tech policy of the EU. It only takes a few minutes to provide your perspective. <a href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/16213-European-Open-Digital-Ecosystems_en\">Submit your feedback</a> by February 3 (midnight CET). Your voice is essential to ensuring that the next generation of European digital policy is built with the needs of real developers in mind.</p><p>At GitHub Developer Policy, we are always open to feedback from developers. Please do not hesitate to <a href=\"https://github.com/about/developer-policy/\">contact us</a> as well.</p>","contentLength":3500,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Power agentic workflows in your terminal with GitHub Copilot CLI","url":"https://github.blog/ai-and-ml/github-copilot/power-agentic-workflows-in-your-terminal-with-github-copilot-cli/","date":1769453689,"author":"Dylan Birtolo","guid":421671,"unread":true,"content":"<p>Since <a href=\"https://github.com/features/copilot/cli?utm_source=blog-agentic-wflows-cli-features-cta&amp;utm_medium=blog&amp;utm_campaign=jan26postuniverse\">GitHub Copilot CLI</a> launched in public preview in September 2025, we’ve been shipping frequent regular updates and advancements.. Below, we’ll show you what makes Copilot CLI so special, why it’s great to have an agentic AI assistant right in your terminal, and how we’re building the Copilot CLI to connect more broadly to the rest of the GitHub Copilot ecosystem.</p><p><em> This blog is based on a GitHub Universe 2025 presentation. Watch below to see the functionality in action. 👇</em></p><h2>Bringing the CLI to where you work</h2><p>If you use GitHub Copilot in VS Code or in a similar IDE, consider how often you spend your entire working day in the IDE, trying to avoid doing anything in any other working environment. We kept this thought top of mind when we conceptualized the GitHub Copilot CLI.</p><p>Developers spend time using  to connect to servers, debug things in containers, triage issues on <a href=\"http://github.com\">github.com</a>, manage CI/CD pipelines, and write deployment scripts. There’s a lot of work that doesn’t neatly map into an individual IDE or even a multipurpose code editor like VS Code.&nbsp;</p><p>To make sure that we brought the GitHub CLI to developers where they already are, it made sense to go through the terminal. After all, the terminal transcends all the different applications on your computer and, in the right hands, is where you can accomplish any task with fine-grained control. Bringing GitHub Copilot into the CLI and giving it access to the broader GitHub ecosystem lets you spend more time getting your work done, and less time hunting down man pages and scouring through documentation to learn how to do something.</p><h2>Showcasing the GitHub CLI functionality</h2><p>Often, the first step with a project is getting up to speed on it. Let’s consider an example where you’re filling in for a friend on a project, but you don’t know anything about it—you don’t know the codebase, the language, or even the framework.</p><p>You’ve received a request to update a feedback form because the UI elements are not laid out correctly. Specifically, the  button overlaps the form itself, obscuring some fields. Whoever submitted the bug included a screenshot showing the UI error.</p><p>To get started, you can launch the GitHub CLI and ask it to clone the repository.</p><pre><code>Clone the feedback repo and set us up to run it</code></pre><p>After sending this prompt, Copilot will get you everything you need: It will reference the documentation associated with the repository and figure out any dependencies you need in order to successfully run it. It’s a fast way to get started, even if you’re not familiar with the dependencies required.</p><p>Copilot will prompt you before running any commands to make sure that it has permission to do so. It will tell you what it’s doing and make sure that you authorize any commands before it runs them.</p><p>Now let’s say that your repository is set up and you go to run the server, but you receive an error that the port is already in use. This can be a workflow killer. You know that there are commands you can run in the terminal to identify the process using the port and safely shut it down, but you might not remember the exact syntax to do so. To make this much easier, you can just hand the task over to Copilot.</p><p>Without you needing to look up the commands, Copilot can determine the PID using the port. You can then either kill the process yourself or hand that task over to Copilot so you can focus on other tasks.</p><pre><code>Find and kill the process on port 3000</code></pre><p>Continuing with our example, you now have the repository up and running and can verify the error with the  button. However, you don’t want to look through all of the code files to try and find what the bug might be. Why not have Copilot take a look first and see if it can identify any obvious issues?</p><p>Copilot can analyze images, so you can use the image supplied in the bug report. Upload the screenshot showing the error to the repository, and ask Copilot if it has any ideas on how to fix the bug.</p><pre><code>Fix the big shown in @FIX-THIS.PNG</code></pre><p>Copilot will attempt to find and fix the issue, supplying a list of suggested changes. You can then review the changes and decide whether or not to have Copilot automatically apply the fixes. And we’re able to do all of this in the terminal thanks to the GitHub CLI.</p><p>However, before uploading these changes to the repository, the team has very strict accessibility requirements. You might not be familiar with what these are, but in this example, the team has a custom agent that defines them. It has all the right MCP tools to check on the guardrails, so you can leverage the agent to do an accessibility review of any proposed changes.</p><p>This command provides a list of available custom agents, so you can select the appropriate one you want to use. Once you select the appropriate agent, simply ask it to look over the proposed changes.</p><p>This prompt sets the coding agent to work, looking at your changes. If it finds any issues, it will let you know and suggest updates to make sure your changes are aligned with its instructions. This can be immensely powerful with the appropriate agents to leverage to provide checks on your code.</p><p>Finally, let’s say you want to know if there are any open issues that map to the work that you’ve done, but you don’t want to manually search through all of the open issues. Luckily, Copilot CLI ships with the GitHub MCP server, so you can look up anything on the GitHub repository without needing to manually go to <a href=\"http://github.com\">github.com</a>.</p><pre><code>Are there any open issues that map to the work we're doing?</code></pre><p>The GitHub MCP server will then go through and search through all of the issues and identify any that might match the work that you’ve addressed. If it pulls up issues that aren’t completely resolved by the work that you’ve done, you can still delegate this work to a coding agent so that you can continue working on whatever you’re focused on.</p><pre><code>/delegate Finish fixing the issue outlined in #1 and use the playright MCP server to ensure that it's fixed</code></pre><p>The  command dispatches a coding agent to work on the task for you in the background while you turn your attention to other areas. It will open a pull request for future work that the coding agent performs. This is identical to <a href=\"https://docs.github.com/en/copilot/concepts/agents/coding-agent/about-coding-agent\">the standard Copilot coding agent workflow</a>—just started through GitHub Copilot CLI.</p><h2>Headless operation for scripting and automation</h2><p>GitHub Copilot CLI has even more functionality than what we’ve previously showcased. You can now perform tasks headlessly in the Copilot CLI. Remember the example where we talked about identifying and killing the process running on port 3000? You could do this through the CLI with the following command.</p><pre><code>copilot --allow-all-tools -p \"Kill the process using port 3000\"</code></pre><p>Copilot will then use the appropriate commands to identify and kill that process. While this is a simple example, you can think of more complex scenarios where you could hook this up into a script or actions workflow and reuse it over and over again.</p><p>Note that this included the flag –allow-all-tools, which is probably not something you want to include in an actual environment unless you’re running in a container. Luckily, we provide several flags that you can pass to only allow access to certain directories and tools. You can even restrict Copilot from using specific commands, so you can guarantee that a human is always involved, such as with pushing up to a repository.</p><p>To see a list of possible flags, run the following command.</p><p>You can authenticate interactively with a login command or by using a personal access token. This way, you can use this with automations. We’re also actively working on more authentication methods that are more enterprise friendly.</p><h2>Trying the Copilot CLI yourself</h2><p>We’re constantly shipping updates and are always looking for feedback from our users. We have several open issues and are tracking the items that customers want to see. If you want to see what we’re working on and provide feedback, check out <a href=\"https://github.com/github/copilot-cli\">our public GitHub Copilot CLI repository</a>.</p><p>And if you want to get started, it’s incredibly easy. It’s available for Windows (both WSL and natively in PowerShell), Mac OS, and Linux. We provide several platform-specific ways to install the CLI in <a href=\"https://github.com/github/copilot-cli?tab=readme-ov-file#installation\">the Copilot CLI README</a>.</p><p>Give it a try and come join the conversation on our public repository to help us build the best terminal-based AI system we possibly can. We look forward to hearing your feedback!</p>","contentLength":8393,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Community Stories, Code Samples, and Signal Forms!","url":"https://blog.angular.dev/community-stories-code-samples-and-signal-forms-7d0294475610?source=rss----447683c3d9a3---4","date":1769189859,"author":"Angular","guid":419603,"unread":true,"content":"<p>This week, we’re sharing powerful stories and hands-on code! The Angular community is defined by its willingness to share , provide , and dive deep into major features like .</p><p>Check out these valuable resources from Angular&nbsp;experts:</p><p><strong>Have you integrated Signal Forms or the new Control Flow into your app yet?</strong> Share your experience or a snippet of your&nbsp;code!</p><p> Use  to share your favorite Angular resources.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7d0294475610\" width=\"1\" height=\"1\" alt=\"\">","contentLength":405,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Build an agent into any app with the GitHub Copilot SDK","url":"https://github.blog/news-insights/company-news/build-an-agent-into-any-app-with-the-github-copilot-sdk/","date":1769094104,"author":"Mario Rodriguez","guid":418238,"unread":true,"content":"<p>Building agentic workflows from scratch is hard.&nbsp;</p><p>You&nbsp;have to&nbsp;manage context across turns, orchestrate tools and commands, route between models, integrate MCP servers, and think through permissions, safety boundaries, and failure modes. Even before you&nbsp;reach&nbsp;your actual product logic,&nbsp;you’ve&nbsp;already&nbsp;built a small platform.&nbsp;</p><p><a href=\"https://github.com/github/copilot-sdk?utm_source=blog-cli-sdk-repo-cta&amp;utm_medium=blog&amp;utm_campaign=cli-sdk-jan-2026\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Copilot SDK</a>&nbsp;(now in technical preview) removes that burden.&nbsp;It&nbsp;allows you to take the&nbsp;same Copilot agentic core that powers GitHub Copilot CLI and embed it in any application.&nbsp;&nbsp;</p><p>This&nbsp;gives you programmatic access to the same production-tested execution loop that powers&nbsp;<a href=\"https://github.com/features/copilot/cli?utm_source=blog-announcement-cli-sdk&amp;utm_medium=blog&amp;utm_campaign=cli-sdk-jan-2026\" target=\"_blank\" rel=\"noreferrer noopener\">GitHub Copilot CLI</a>.&nbsp;That means instead of wiring your own planner, tool loop, and runtime, you can embed that agentic loop directly into your application and build on top of it for any use case.&nbsp;</p><p>You also get&nbsp;Copilot CLI’s&nbsp;support for&nbsp;multiple AI&nbsp;models, custom tool definitions, MCP server integration, GitHub authentication, and real-time streaming.</p><h2>What’s&nbsp;new in GitHub Copilot CLI&nbsp;&nbsp;</h2><p>Copilot CLI&nbsp;lets you&nbsp;plan&nbsp;projects or features,&nbsp;modify&nbsp;files, run commands, use custom agents, delegate tasks to the cloud, and more, all without leaving your terminal.&nbsp;</p><p>Since we first introduced&nbsp;it,&nbsp;we’ve&nbsp;been expanding&nbsp;Copilot’s&nbsp;agentic workflows&nbsp;so it:&nbsp;</p><ul><li>&nbsp;with&nbsp;persistent&nbsp;memory, infinite sessions, and intelligent compaction.&nbsp;</li><li>&nbsp;with explore, plan, and review workflows where you can choose which model you want at each&nbsp;step.&nbsp;</li><li>with custom agents, agent skills, full MCP support, and async task delegation.&nbsp;</li></ul><h2>How does&nbsp;the SDK&nbsp;build&nbsp;on top of&nbsp;Copilot&nbsp;CLI?&nbsp;</h2><p>The SDK takes the agentic power of Copilot CLI (the planning, tool use, and multi-turn execution loop) and makes it available in your favorite programming language.&nbsp;This makes it possible to integrate&nbsp;Copilot&nbsp;into any environment. You can build GUIs that use AI&nbsp;workflows,&nbsp;create personal tools that level up your productivity, or&nbsp;run custom internal agents in your enterprise workflows.&nbsp;&nbsp;</p><p>Our teams have already&nbsp;used&nbsp;it&nbsp;to build&nbsp;things&nbsp;like:&nbsp;</p><ul><li>YouTube chapter generators&nbsp;</li><li>Custom GUIs for their agents&nbsp;</li><li>Speech-to-command workflows to run apps on their desktops&nbsp;</li><li>Games where you can compete with AI&nbsp;</li></ul><p>Think of the Copilot SDK&nbsp;as an&nbsp;execution&nbsp;platform that lets you reuse the same agentic loop behind the Copilot CLI, while GitHub handles authentication, model management, MCP servers, custom agents, and chat sessions plus streaming. That means&nbsp;&nbsp;are in control of what gets&nbsp;built&nbsp;on top of those building blocks.</p>","contentLength":2525,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["official"]}