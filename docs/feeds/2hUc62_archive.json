{"id":"2hUc62","title":"Blog","displayTitle":"Blog","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":88,"items":[{"title":"Conditional types in TypeScript","url":"https://2ality.com/2025/02/conditional-types-typescript.html","date":1739577600,"author":"Dr. Axel Rauschmayer","guid":204,"unread":true,"content":"<p>In TypeScript, conditional types let us make decisions (think if-then-else expressions) – which is especially useful in generic types. They are also an essential tool for working with union types because they let use “loop” over them. Read on if you want to know how all of that works.</p>","contentLength":291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Django Weblog: DjangoCongress JP 2025 Announcement and Live Streaming!","url":"https://www.djangoproject.com/weblog/2025/feb/14/djangocongress-jp-2025-announcement-and-livestream/","date":1739571130,"author":"","guid":341,"unread":true,"content":"<p>It will be streamed on the following YouTube Live channels:</p><p>This year there will be talks not only about Django, but also about FastAPI and other asynchronous web topics. There will also be talks on Django core development, Django Software Foundation (DSF) governance, and other topics from around the world. Simultaneous translation will be provided in both English and Japanese.</p><ul><li>The Async Django ORM: Where Is it?</li><li>Speed at Scale for Django Web Applications</li><li>Implementing Agentic AI Solutions in Django from scratch</li><li>Diving into DSF governance: past, present and future</li></ul><ul><li>Getting Knowledge from Django Hits: Using Grafana and Prometheus</li><li>Culture Eats Strategy for Breakfast: Why Psychological Safety Matters in Open Source</li><li>µDjango. The next step in the evolution of asynchronous microservices technology.</li></ul><p>A public viewing of the event will also be held in Tokyo. A reception will also be held, so please check the following connpass page if you plan to attend.</p>","contentLength":948,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Eli Bendersky: Decorator JITs - Python as a DSL","url":"https://eli.thegreenplace.net/2025/decorator-jits-python-as-a-dsl/","date":1739569771,"author":"","guid":340,"unread":true,"content":"<p>Spend enough time looking at Python programs and packages for machine learning,\nand you'll notice that the \"JIT decorator\" pattern is pretty popular. For\nexample, this JAX snippet:</p><div><pre></pre></div><div><pre></pre></div><p>In both cases, the function decorated with  doesn't get executed by the\nPython interpreter in the normal sense. Instead, the code inside is more like\na DSL (Domain Specific Language) processed by a special purpose compiler built\ninto the library (JAX or Triton). Another way to think about it is that Python\nis used as a  to describe computations.</p><p>In this post I will describe some implementation strategies used by libraries to\nmake this possible.</p><div><h2>Preface - where we're going</h2><p>The goal is to explain how different kinds of  decorators work by using\na simplified, educational example that implements several approaches from\nscratch. All the approaches featured in this post will be using this flow:</p> Expr IR --&gt; LLVM IR --&gt; Execution\" /&gt; Expr IR --&gt; LLVM IR --&gt; Execution\" class=\"align-center\" src=\"https://eli.thegreenplace.net/images/2025/decjit-python.png\" /&gt;\n<p>These are the steps that happen when a Python function wrapped with\nour educational  decorator is called:</p><ol><li>The function is translated to an \"expression IR\" - .</li><li>This expression IR is converted to LLVM IR.</li><li>Finally, the LLVM IR is JIT-executed.</li></ol><p>First, let's look at the  IR. Here we'll make a big simplification -\nonly supporting functions that define a single expression, e.g.:</p><div><pre></pre></div><p>Naturally, this can be easily generalized - after all, LLVM IR can be used to\nexpress fully general computations.</p><p>Here are the  data structures:</p><div><pre></pre></div><p>To convert an  into LLVM IR and JIT-execute it, we'll use this function:</p><div><pre></pre></div><p>It uses the  class to actually generate LLVM IR from .\nThis process is straightforward and covered extensively in the resources I\nlinked to earlier; take a look at <a href=\"https://github.com/eliben/code-for-blog/blob/main/2025/decjit/exprcode.py\">the full code here</a>.</p><p>My goal with this architecture is to make things simple, but .\nOn one hand - there are several simplifications: only single expressions are\nsupported, very limited set of operators, etc. It's very easy to extend this!\nOn the other hand, we could have just trivially evaluated the \nwithout resorting to LLVM IR; I do want to show a more complete compilation\npipeline, though, to demonstrate that an arbitrary amount of complexity can\nbe hidden behind these simple interfaces.</p><p>With these building blocks in hand, we can review the strategies used by\n decorators to convert Python functions into s.</p></div><div><p>Python comes with powerful code reflection and introspection capabilities out\nof the box. Here's the  decorator:</p><div><pre></pre></div><p>This is a standard Python decorator. It takes a function and returns another\nfunction that will be used in its place ( ensures that\nfunction attributes like the name and docstring of the wrapper match the\nwrapped function).</p><div><pre></pre></div><p>After  is applied to , what  holds is the\nwrapper. When  is called, the wrapper is invoked with\n.</p><p>The wrapper obtains the AST of the wrapped function, and then uses\n to convert this AST into an :</p><div><pre></pre></div><p>When  finishes visiting the AST it's given, its\n field will contain the  representing the function's\nreturn value. The wrapper then invokes  with this .</p><p>Note how our decorator interjects into the regular Python execution process.\nWhen  is called, instead of the standard Python compilation and\nexecution process (code is compiled into bytecode, which is then executed\nby the VM), we translate its code to our own representation and emit LLVM from\nit, and then JIT execute the LLVM IR. While it seems kinda pointless in this\nartificial example, in reality this means we can execute the function's code\nin any way we like.</p><div><h3>AST JIT case study: Triton</h3><p>This approach is almost exactly how the Triton language works. The body of a\nfunction decorated with  gets parsed to a Python AST, which then\n- through a series of internal IRs - ends up in LLVM IR; this in turn is lowered\nto <a href=\"https://docs.nvidia.com/cuda/parallel-thread-execution/\">PTX</a> by the\n<a href=\"https://llvm.org/docs/NVPTXUsage.html\">NVPTX LLVM backend</a>.\nThen, the code runs on a GPU using a standard CUDA pipeline.</p><p>Naturally, the subset of Python that can be compiled down to a GPU is limited;\nbut it's sufficient to run performant kernels, in a language that's much\nfriendlier than CUDA and - more importantly - lives in the same file with the\n\"host\" part written in regular Python. For example, if you want testing and\ndebugging, you can run Triton in \"interpreter mode\" which will just run the\nsame kernels locally on a CPU.</p><p>Note that Triton lets us import names from the  package\nand use them inside kernels; these serve as the  for the language\n- special calls the compiler handles directly.</p></div></div><div><p>Python is a fairly complicated language with  of features. Therefore,\nif our JIT has to support some large portion of Python semantics, it may make\nsense to leverage more of Python's own compiler. Concretely, we can have it\ncompile the wrapped function all the way <a href=\"https://github.com/python/cpython/blob/main/InternalDocs/interpreter.md\">to bytecode</a>,\nand start our translation from there.</p><p>Here's the  decorator that does just this :</p><div><pre></pre></div><p>The Python VM is a stack machine; so we emulate a stack to convert the\nfunction's bytecode to  IR (a bit like an <a href=\"https://en.wikipedia.org/wiki/Reverse_Polish_notation\">RPN evaluator</a>).\nAs before, we then use our  utility function to lower\n to LLVM IR and JIT execute it.</p><p>Using this JIT is as simple as the previous one - just swap \nfor :</p><div><pre></pre></div><div><h3>Bytecode JIT case study: Numba</h3><p><a href=\"https://numba.pydata.org/\">Numba</a> is a compiler for Python itself. The idea\nis that you can speed up specific functions in your code by slapping a\n decorator on them. What happens next is similar in spirit to\nour simple , but of course much more complicated because it\nsupports a very large portion of Python semantics.</p><p>Numba uses the Python compiler to emit bytecode, just as we did; it then\nconverts it into its own IR, and then to LLVM using .</p><p>By starting with the bytecode, Numba makes its life easier (no need to rewrite\nthe entire Python compiler). On the other hand, it also makes some analyses\n, because by the time we're in bytecode, a lot of semantic information\nexisting in higher-level representations is lost. For example, Numba has to\nsweat a bit to recover control flow information from the bytecode (by\nrunning it through a special interpreter first).</p></div></div><div><p>The two approaches we've seen so far are similar in many ways - both rely on\nPython's introspection capabilities to compile the source code of the JIT-ed\nfunction to some extent (one to AST, the other all the way to bytecode), and\nthen work on this lowered representation.</p><p>The tracing strategy is very different. It doesn't analyze the source code of\nthe wrapped function at all - instead, it  its execution by means of\nspecially-boxed arguments, leveraging overloaded operators and functions, and\nthen works on the generated trace.</p><p>The code implementing this for our smile demo is surprisingly compact:</p><div><pre></pre></div><p>Each runtime argument of the wrapped function is assigned a , and\nthat is placed in a , a placeholder class which lets us\ndo operator overloading:</p><div><pre></pre></div><p>The remaining key function is :</p><div><pre></pre></div><p>To understand how this works, consider this trivial example:</p><div><pre></pre></div><p>After the decorated function is defined,  holds the wrapper function\ndefined inside . When  is called, the wrapper runs:</p><ol><li>For each argument of  itself (that is  and ), it creates\na new  holding a . This denotes a named variable in\nthe  IR.</li><li>It then calls the wrapped function, passing it the boxes as runtime\nparameters.</li><li>When (the wrapped)  runs, it invokes . This is caught by the overloaded\n operator of , and it creates a new  with\nthe s representing  and  as children. This\n is then returned .</li><li>The wrapper unboxes the returned  and passes it to\n to emit LLVM IR from it and JIT execute it with the\nactual runtime arguments of the call: .</li></ol><p>This might be a little mind-bending at first, because there are two different\nexecutions that happen:</p><ul><li>The first is calling the wrapped  function itself, letting the Python\ninterpreter run it as usual, but with special arguments that build up the IR\ninstead of doing any computations. This is the .</li><li>The second is lowering this IR our tracing step built into LLVM IR and then\nJIT executing it with the actual runtime argument values ; this is\nthe .</li></ul><p>This tracing approach has some interesting characteristics. Since we don't\nhave to analyze the source of the wrapped functions but only trace through\nthe execution, we can \"magically\" support a much richer set of programs, e.g.:</p><div><pre></pre></div><p>This  with our basic . Since Python variables are\nplaceholders (references) for values, our tracing step is oblivious to them - it\nfollows the flow of values. Another example:</p><div><pre></pre></div><p>This also just works! The created  will be a long chain of \nadditions of 's runtime values through the loop, added to the \nfor .</p><p>This last example also leads us to a limitation of the tracing approach; the\nloop cannot be  - it cannot depend on the function's arguments,\nbecause the tracing step has no concept of runtime values and wouldn't know\nhow many iterations to run through; or at least, it doesn't know this unless\nwe want to perform the tracing run for every runtime execution .</p><div><h3>Tracing JIT case study: JAX</h3><p>The <a href=\"https://jax.readthedocs.io/en/latest/\">JAX ML framework</a> uses a tracing\napproach very similar to the one described here. The first code sample in this\npost shows the JAX notation. JAX cleverly wraps Numpy with its own version which\nis traced (similar to our , but JAX calls these boxes \"tracers\"),\nletting you write regular-feeling Numpy code that can be JIT optimized and\nexecuted on accelerators like GPUs and TPUs via <a href=\"https://github.com/openxla\">XLA</a>. JAX's tracer builds up an underlying IR (called\n<a href=\"https://jax.readthedocs.io/en/latest/jaxpr.html\">jaxpr</a>) which can then be\nemitted to XLA ops and passed to XLA for further lowering and execution.</p><p>For a fairly deep overview of how JAX works, I recommend reading the\n<a href=\"https://jax.readthedocs.io/en/latest/autodidax.html\">autodidax doc</a>.</p><p>As mentioned earlier, JAX has <a href=\"https://jax.readthedocs.io/en/latest/jit-compilation.html\">some limitations</a>\nwith things like data-dependent control flow in native Python. This won't work,\nbecause there's control flow\nthat depends on a runtime value ():</p><div><pre></pre></div><p>When  is executed, JAX will throw an exception, saying something\nlike:</p><blockquote>\nThis concrete value was not available in Python because it depends on the\nvalue of the argument count.</blockquote><p>As a remedy, JAX has its\nown built-in intrinsics from the <a href=\"https://jax.readthedocs.io/en/latest/jax.lax.html\">jax.lax package</a>.\nHere's the example rewritten in a way that actually works:</p><div><pre></pre></div><p> (and many other built-ins in the  package) is something JAX\ncan trace through, generating a corresponding XLA operation (XLA has support for\n<a href=\"https://openxla.org/xla/operation_semantics\">While loops</a>, to which this\n can be lowered).</p><p>The tracing approach has clear benefits for JAX as well; because it only cares\nabout the flow of values, it can handle arbitrarily complicated Python code,\nas long as the flow of values can be traced. Just like the local variables and\ndata-independent loops shown earlier, but also things like closures. This makes\nmeta-programming and templating easy .</p></div></div><div><p>The full code for this post is available <a href=\"https://github.com/eliben/code-for-blog/tree/main/2025/decjit\">on GitHub</a>.</p></div>","contentLength":10514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Friday Squid Blogging: Squid the Care Dog","url":"https://www.schneier.com/blog/archives/2025/02/friday-squid-blogging-squid-the-care-dog.html","date":1739552738,"author":"Bruce Schneier","guid":177,"unread":true,"content":"<p>The Vanderbilt University Medical Center has a pediatric care dog named “<a href=\"https://news.vumc.org/2025/02/03/pediatric-nursing-grand-rounds-on-impact-of-squid-the-facility-dog-is-feb-12/\">Squid</a>.”</p>","contentLength":84,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Upcoming Speaking Engagements","url":"https://www.schneier.com/blog/archives/2025/02/upcoming-speaking-engagements-43.html","date":1739552481,"author":"Bruce Schneier","guid":176,"unread":true,"content":"<p>This is a current list of where and when I am scheduled to speak:</p><ul><li>I’m speaking at <a href=\"https://boskone.org/\">Boskone 62</a> in Boston, Massachusetts, USA, which runs from February 14-16, 2025. My talk is at 4:00 PM ET on the 15th.</li></ul>","contentLength":200,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hugo van Kemenade: Improving licence metadata","url":"https://hugovk.dev/blog/2025/improving-licence-metadata/","date":1739545860,"author":"","guid":339,"unread":true,"content":"<p><a href=\"https://peps.python.org/pep-0639/\" target=\"_blank\" rel=\"noreferrer\">PEP 639</a> defines a spec on how to document licences\nused in Python projects.</p><p>Change  as follows.</p><p>I usually use Hatchling as a build backend, and support was added in 1.27:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Replace the freeform  field with a valid SPDX license expression, and add\n which points to the licence files in the repo. There’s often only one,\nbut if you have more than one, list them all:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Optionally delete the deprecated licence classifier:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Then make sure to use a PyPI uploader that supports this.</p><p>pip can also show you the metadata:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>A lot of work went into this. Thank you to PEP authors\n<a href=\"https://github.com/pombredanne\" target=\"_blank\" rel=\"noreferrer\">Philippe Ombredanne</a> for creating the first draft in\n2019, to <a href=\"https://github.com/cam-gerlach\" target=\"_blank\" rel=\"noreferrer\">C.A.M. Gerlach</a> for the second draft in 2021,\nand especially to <a href=\"https://karolinasurma.eu/\" target=\"_blank\" rel=\"noreferrer\">Karolina Surma</a> for getting the third\ndraft finish line and helping with the implementation.</p><p>And many projects were updated to support this, thanks to the maintainers and\ncontributors of at least:</p>","contentLength":878,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI and Civil Service Purges","url":"https://www.schneier.com/blog/archives/2025/02/ai-and-civil-service-purges.html","date":1739538202,"author":"Bruce Schneier","guid":175,"unread":true,"content":"<p>Donald Trump and Elon Musk’s chaotic approach to reform is upending government operations. Critical functions have been <a href=\"https://www.theguardian.com/us-news/2025/feb/05/musk-doge-takeover-usaid\">halted</a>, tens of thousands of federal staffers are being encouraged to <a href=\"https://www.wsj.com/lifestyle/careers/federal-workers-accept-buyout-offers-be1c00fb\">resign</a>, and congressional mandates are being <a href=\"https://thehill.com/business/5124133-democrats-bill-treasury-system-musk/\">disregarded</a>. The next phase: The Department of Government Efficiency <a href=\"https://www.nytimes.com/2025/02/03/technology/musk-allies-ai-government.html\">reportedly</a> wants to use AI to cut costs. According to , Musk’s group has started to <a href=\"https://www.washingtonpost.com/nation/2025/02/06/elon-musk-doge-ai-department-education/\">run sensitive data</a> from government systems through AI programs to analyze spending and determine what could be pruned. This may lead to the elimination of human jobs in favor of automation. As one government official who has been tracking Musk’s DOGE team told the, the ultimate aim is to use AI to replace “<a href=\"https://www.washingtonpost.com/business/2025/02/08/doge-musk-goals/\">the human workforce with machines</a>.” (Spokespeople for the White House and DOGE did not respond to requests for comment.)</p><p>Using AI to make government more efficient is a worthy pursuit, and this is not a new idea. The Biden administration disclosed more than 2,000 <a href=\"https://github.com/ombegov/2024-Federal-AI-Use-Case-Inventory\">AI applications</a> in development across the federal government. For example, <a href=\"https://www.dhs.gov/ai/use-case-inventory/fema\">FEMA</a> has started using AI to help perform damage assessment in disaster areas. The <a href=\"https://ai.cms.gov/assets/CMS_AI_Playbook.pdf\">Centers for Medicare and Medicaid Services</a> has started using AI to look for fraudulent billing. The idea of replacing dedicated and principled civil servants with AI agents, however, new—and complicated.</p><p>The civil service—the massive cadre of employees who operate government agencies—plays a vital role in translating laws and policy into the operation of society. New presidents can issue sweeping executive orders, but they often have no real effect until they actually change the behavior of public servants. Whether you think of these people as essential and <a href=\"https://www.washingtonpost.com/opinions/interactive/2024/michael-lewis-conclusion-who-is-government/\">inspiring</a> do-gooders, boring bureaucratic functionaries, or as agents of a “<a href=\"https://www.theatlantic.com/health/archive/2024/11/deep-state-public-health-trump-kennedy/680621/\">deep state</a>,” their sheer number and continuity act as ballast that resists institutional change.</p><p>This is why Trump and Musk’s actions are so significant. The more AI decision making is integrated into government, the easier change will be. If human workers are widely replaced with AI, executives will have unilateral authority to instantaneously alter the behavior of the government, profoundly raising the stakes for transitions of power in democracy. Trump’s unprecedented purge of the civil service might be the last time a president needs to replace the human beings in government in order to dictate its new functions. Future leaders may do so at the press of a button.</p><p>To be clear, the use of AI by the executive branch doesn’t have to be disastrous. In theory, it could allow new leadership to swiftly implement the wishes of its electorate. But this could go very badly in the hands of an authoritarian leader. AI systems concentrate power at the top, so they could allow an executive to effectuate change over sprawling bureaucracies instantaneously. Firing and replacing tens of thousands of human bureaucrats is a huge undertaking. Swapping one AI out for another, or modifying the rules that those AIs operate by, would be much simpler.</p><p>Social-welfare programs, if automated with AI, could be redirected to systematically benefit one group and disadvantage another with a single prompt change. Immigration-enforcement agencies could prioritize people for investigation and detainment with one instruction. Regulatory-enforcement agencies that monitor corporate behavior for malfeasance could turn their attention to, or away from, any given company on a whim.</p><p>Even if Congress were motivated to fight back against Trump and Musk, or against a future president seeking to bulldoze the will of the legislature, the absolute power to command AI agents would make it easier to subvert legislative intent. AI <a href=\"https://www.techpolicy.press/anatomy-of-an-ai-coup/\">has the power to diminish</a> representative politics. Written law is never fully determinative of the actions of government—there is always wiggle room for presidents, appointed leaders, and civil servants to exercise their own judgment. Whether intentional or not, whether charitably or not, each of these actors uses discretion. In human systems, that discretion is widely distributed across many individuals—people who, in the case of career civil servants, usually outlast presidencies.</p><p>Today, the AI ecosystem is dominated by a small number of corporations that decide how the most widely used AI models are designed, which data they are trained on, and which instructions they follow. Because their work is <a href=\"https://crfm.stanford.edu/fmti/paper.pdf\">largely secretive and unaccountable</a> to public interest, these tech companies are capable of making changes to the bias of AI systems—either generally or with aim at specific governmental use cases—that are invisible to the rest of us. And these private actors are both vulnerable to coercion by political leaders and self-interested in appealing to their favor. Musk himself created and funded xAI, now one of the world’s largest AI labs, with an <a href=\"https://www.zdnet.com/article/i-tried-xs-anti-woke-grok-ai-chatbot-the-results-were-the-opposite-of-what-i-expected/\">explicitly ideological</a> mandate to generate anti-“woke” AI and <a href=\"https://www.wired.com/llm-political-bias/\">steer</a> the wider AI industry in a similar direction.</p><p>But there’s a second way that AI’s transformation of government could go. AI development could happen inside of transparent and accountable public institutions, alongside its continued development by Big Tech. Applications of AI in democratic governments could be focused on benefitting public servants and the communities they serve by, for example, making it easier for non-English speakers to access government services, making ministerial tasks such as processing routine applications more efficient and reducing backlogs, or helping constituents weigh in on the policies deliberated by their representatives. Such AI integrations should be done gradually and carefully, with public oversight for their design and implementation and monitoring and guardrails to avoid unacceptable bias and harm.</p><p>Governments around the world are demonstrating how this could be done, though it’s early days. <a href=\"https://talktothecity.org\">Taiwan</a> has pioneered the use of AI models to facilitate deliberative democracy at an unprecedented scale. Singapore has been a leader in the development of <a href=\"https://www.brookings.edu/articles/how-public-ai-can-strengthen-democracy/\">public AI</a> models, built <a href=\"https://sea-lion.ai\">transparently</a> and with <a href=\"https://www.undp.org/policy-centre/singapore/blog/pairing-ai-public-sector-impact-singapore\">public-service use cases</a> in mind. <a href=\"https://www.canada.ca/en/government/system/digital-government/digital-government-innovations/responsible-use-ai/algorithmic-impact-assessment.html\">Canada</a> has illustrated the role of disclosure and public input on the consideration of AI use cases in government. Even if you do not trust the current White House to follow any of these examples, U.S. states—which have much greater contact and influence over the daily lives of Americans than the federal government—could lead the way on this kind of responsible development and deployment of AI.</p><p>As the political theorist <a href=\"https://wwnorton.com/books/9781631496943\">David Runciman</a> has written, AI is just another in a long line of artificial “machines” used to govern how people live and act, not unlike corporations and states before it. AI doesn’t replace those older institutions, but it changes how they function. As the Trump administration forges stronger ties to Big Tech and AI developers, we need to recognize the potential of that partnership to steer the future of democratic governance—and act to make sure that it does not enable future authoritarians.</p><p><em>This essay was written with Nathan E. Sanders, and originally appeared in <a href=\"https://www.theatlantic.com/technology/archive/2025/02/doge-ai-plans/681635/\">The Atlantic</a>.</em></p>","contentLength":7136,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real Python: The Real Python Podcast – Episode #239: Behavior-Driven vs Test-Driven Development &amp; Using Regex in Python","url":"https://realpython.com/podcasts/rpp/239/","date":1739534400,"author":"","guid":118,"unread":true,"content":"<p>What is behavior-driven development, and how does it work alongside test-driven development? How do you communicate requirements between teams in an organization? Christopher Trudeau is back on the show this week, bringing another batch of PyCoder's Weekly articles and projects.</p>","contentLength":279,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Daniel Roy Greenfeld: Building a playing card deck","url":"https://daniel.feldroy.com/posts/2025-02-deck-of-cards","date":1739526604,"author":"","guid":338,"unread":true,"content":"<article>Today is Valentine's Day. That makes it the perfect day to write a blog post about showing how to not just build a deck of cards, but show off cards from the heart suite.</article>","contentLength":170,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Risky Biz Soap Box: Run your own open source IDP with Authentik","url":"https://risky.biz/soapbox93/","date":1739492664,"author":"","guid":785,"unread":true,"content":"<article></article>","contentLength":0,"flags":null,"enclosureUrl":"https://dts.podtrac.com/redirect.mp3/media3.risky.biz/soapbox93.mp3","enclosureMime":"","commentsUrl":null},{"title":"Mapped types in TypeScript","url":"https://2ality.com/2025/02/mapped-types-typescript.html","date":1739491200,"author":"Dr. Axel Rauschmayer","guid":203,"unread":true,"content":"<p>A mapped type is a loop over keys that produces an object or tuple type and looks as follows:</p><pre><code>{[]: }\n</code></pre><p>In this blog post, we examine how mapped types work and see examples of using them. Their most importing use cases are transforming objects and mapping tuples.</p>","contentLength":259,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bojan Mihelac: Prefixed Parameters for Django querystring tag","url":"http://code.informatikamihelac.com/en/query-string-with-prefixed-parameters/","date":1739482638,"author":"","guid":337,"unread":true,"content":"<article>An overview of Django 5.1's new querystring tag and how to add support for prefixed parameters.</article>","contentLength":95,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Coding Interviews were HARD Until I Learned These 20 Tips","url":"https://blog.algomaster.io/p/20-coding-interviews-tips","date":1739467827,"author":"Ashish Pratap Singh","guid":751,"unread":true,"content":"<p>I gave my first  in 2016—and failed. I failed the next five interviews as well before finally landing my first job at .</p><p>Since then, I’ve interviewed with many companies and faced my fair share of rejections. However, over the years, my failure rate in coding interviews dropped significantly.</p><p>By 2022, with just 1.5 months of focused preparation, I successfully cleared interviews at  and .</p><p>Surprisingly, my success wasn’t due to a dramatic improvement in problem-solving skills. The real game-changer was my approach— and  during the interview.</p><p>In this article, I’ll share  that made coding interviews significantly easier for me.</p><p>These tips cover everything you need to know, including:</p><ul><li><p>How to systematically approach coding interview problems</p></li><li><p>Key concepts and patterns you should know</p></li><li><p>The type of problems you should practice</p></li><li><p>How to choose the right algorithm for a given problem</p></li><li><p>Techniques to optimize your solution</p></li><li><p>How to communicate your thought process effectively</p></li></ul><p>By applying these strategies, you’ll be able to tackle coding interviews with confidence and massively increase your chances of success.</p><p>In a coding interview, interviewers want to see how well you , , and  under pressure.</p><p>Here's a breakdown of what they look for:</p><ol><li><p><strong>Understanding the problem</strong>: Do you ask clarifying questions instead of making assumptions to ensure you fully understand the problem?</p></li><li><p>: Can you decompose the problem into smaller, manageable parts?</p></li><li><p>: Can you design an optimal solution in terms of time and space complexity?</p></li><li><p>: Do you handle edge cases like empty inputs, duplicates, large values, or special conditions?</p></li><li><p>: Can you explain why one approach is better than another?</p></li><li><p>: Do you have a strong grasp of data structures and algorithms, and can you choose the right one for the problem?</p></li><li><p>Can you quickly compute the time and space complexity of your solution?</p></li><li><p><strong>Explaining your thought process</strong>: Can you clearly articulate your approach and why it works?</p></li><li><p>: Are you receptive to hints and able to adjust your approach accordingly?</p></li><li><p>: Do you follow good coding practices (meaningful variable names, proper indentation, modular functions etc..)?</p></li><li><p><strong>Improving the initial solution</strong>: Can you optimize and refine your first solution when prompted?</p></li><li><p>Are you able to tackle variations of the original problem?</p></li><li><p>Can you manually walk through your code with sample inputs to verify correctness?</p></li></ol><p>Most coding interviews last </p><p>Depending on the company and interviewer, you may be asked to solve 2-3easy/medium problems or 1 hard problem with follow-ups.</p><p>Lets assume you are given one problem, with a follow up in a 45-minute interview. Here’s how you can optimally allocate your time:</p><ol><li><p>The interviewer may ask you to introduce yourself. Prepare a concise 1-2 minute introduction that highlights your background, experience, and key strengths. Practice it beforehand so that you can deliver it smoothly.</p></li><li><p><strong>Understand the Problem (5-10 mins):  </strong>Carefully read the problem statement, ask clarifying questions, and walk through sample inputs and expected outputs.</p></li><li><p><strong>Plan the Approach (10-20 mins): </strong>Brainstorm possible solutions, evaluate trade-offs, and discuss time and space complexity.</p></li><li><p><strong>Implement the Code (20-30 mins): </strong>Write a clean, modular and readable code.</p></li><li><p>Dry-run your code with sample inputs, debug any issues, and ensure edge cases are handled.</p></li><li><p><strong>Follow-ups and Wrap Up (35-45 mins): </strong>Answer follow up questions, and ask thoughtful questions to the interviewer about the company, role, or team.</p></li></ol><p>One of the biggest mistakes candidates make in coding interviews is jumping into coding too soon.</p><p>If you don't fully understand the question, you might end up solving the </p><p>Here’s how to ensure you grasp the problem before coding:</p><h4><strong>Read the Problem Carefully</strong></h4><p>Take a moment to absorb the problem statement. Rephrase it in your own words to confirm your understanding. </p><p>Identify the expected input/output format and any hidden constraints.</p><p>If anything is unclear, ask questions before diving into the solution. Interviewers appreciate when you seek clarity. Never assume details that aren’t explicitly mentioned in the problem statement.</p><p>Common clarifications include:</p><ul><li><p>Are there duplicate values?</p></li><li><p>Can the input be empty? If so, what should the output be?</p></li><li><p>Should the solution handle negative numbers?</p></li><li><p>Should the output maintain the original order of elements?</p></li><li><p>Is the graph directed or undirected?</p></li><li><p>Does the input contain only lowercase English letters, or can it have uppercase, digits, or special characters?</p></li><li><p>What should happen if multiple solutions exist? Should I return any valid solution, or does the problem have specific requirements?</p></li></ul><h4><strong>Walk Through Input/Output Examples</strong></h4><p>Once you understand the problem statement and constraints, go over a few input and output examples to make sure you get it.</p><p>Draw them out if it helps, especially for visual data structures like trees or graphs.</p><p>Try to take examples that cover different scenarios of the problem. Think about any  that might come up.</p>","contentLength":4908,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/61c3f6c0-4027-4d37-b4a7-a30fc183fa12_1602x1032.png","enclosureMime":"","commentsUrl":null},{"title":"Peter Bengtsson: get in JavaScript is the same as property in Python","url":"http://www.peterbe.com/plog/get-in-javascript-is-the-same-as-property-in-python","date":1739450516,"author":"","guid":336,"unread":true,"content":"<article>Prefix a function, in an object or class, with `get` and then that acts as a function call without brackets. Just like Python's `property` decorator.</article>","contentLength":149,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to add a directory to your PATH","url":"https://jvns.ca/blog/2025/02/13/how-to-add-a-directory-to-your-path/","date":1739449676,"author":"Julia Evans","guid":11,"unread":true,"content":"<p>I was talking to a friend about how to add a directory to your PATH today. It’s\nsomething that feels “obvious” to me since I’ve been using the terminal for a\nlong time, but when I searched for instructions for how to do it, I actually\ncouldn’t find something that explained all of the steps – a lot of them just\nsaid “add this to ”, but what if you’re not using bash? What if your\nbash config is actually in a different file? And how are you supposed to figure\nout which directory to add anyway?</p><p>So I wanted to try to write down some more complete directions and mention some\nof the gotchas I’ve run into over the years.</p><p>Here’s a table of contents:</p><h3>step 1: what shell are you using?</h3><p>If you’re not sure what shell you’re using, here’s a way to find out. Run this:</p><ul><li>if you’re using , it’ll print out </li><li>if you’re using , it’ll print out </li><li>if you’re using , it’ll print out an error like “In fish, please use\n$fish_pid” ( isn’t valid syntax in fish, but in any case the error\nmessage tells you that you’re using fish, which you probably already knew)</li></ul><p>Also bash is the default on Linux and zsh is the default on Mac OS (as of\n2024). I’ll only cover bash, zsh, and fish in these directions.</p><h3>step 2: find your shell’s config file</h3><ul><li>in zsh, it’s probably </li><li>in bash, it might be , but it’s complicated, see the note in the next section</li><li>in fish, it’s probably <code>~/.config/fish/config.fish</code> (you can run  if you want to be 100% sure)</li></ul><h3>a note on bash’s config file</h3><p>Bash has three possible config files: , , and .</p><p>If you’re not sure which one your system is set up to use, I’d recommend\ntesting this way:</p><ol><li>add  to your </li><li>If you see “hi there”, that means  is being used! Hooray!</li><li>Otherwise remove it and try the same thing with </li><li>You can also try  if the first two options don’t work.</li></ol><p>(there are a lot of elaborate flow charts out there that explain how bash\ndecides which config file to use but IMO it’s not worth it and just testing is\nthe fastest way to be sure)</p><h3>step 3: figure out which directory to add</h3><p>Let’s say that you’re trying to install and run a program called \nand it doesn’t work, like this:</p><pre><code>$ npm install -g http-server\n$ http-server\nbash: http-server: command not found\n</code></pre><p>How do you find what directory  is in? Honestly in general this is\nnot that easy – often the answer is something like “it depends on how npm is\nconfigured”. A few ideas:</p><ul><li>Often when setting up a new installer (like , , , etc),\nwhen you first set it up it’ll print out some directions about how to update\nyour PATH. So if you’re paying attention you can get the directions then.</li><li>Sometimes installers will automatically update your shell’s config file\nto update your  for you</li><li>Sometimes just Googling “where does npm install things?” will turn up the\nanswer</li><li>Some tools have a subcommand that tells you where they’re configured to\ninstall things, like:\n<ul><li>Node/npm:  (then append )</li><li>Go:  (then append )</li><li>asdf: <code>asdf info | grep ASDF_DIR</code> (then append  and )</li></ul></li></ul><h3>step 3.1: double check it’s the right directory</h3><p>Once you’ve found a directory you think might be the right one, make sure it’s\nactually correct! For example, I found out that on my machine,  is\nin . I can make sure that it’s the right directory by trying to\nrun the program  in that directory like this:</p><pre><code>$ ~/.npm-global/bin/http-server\nStarting up http-server, serving ./public\n</code></pre><p>It worked! Now that you know what directory you need to add to your ,\nlet’s move to the next step!</p><h3>step 4: edit your shell config</h3><p>Now we have the 2 critical pieces of information we need:</p><ol><li>Which directory you’re trying to add to your PATH (like  )</li><li>Where your shell’s config is (like , , or <code>~/.config/fish/config.fish</code>)</li></ol><p>Now what you need to add depends on your shell:</p><p>Open your shell’s config file, and add a line like this:</p><pre><code>export PATH=$PATH:~/.npm-global/bin/\n</code></pre><p>(obviously replace  with the actual directory you’re trying to add)</p><p>You can do the same thing as in bash, but zsh also has some slightly fancier\nsyntax you can use if you prefer:</p><pre><code>path=(\n  $path\n  ~/.npm-global/bin\n)\n</code></pre><p>In fish, the syntax is different:</p><pre><code>set PATH $PATH ~/.npm-global/bin\n</code></pre><p>(in fish you can also use , some notes on that <a href=\"https://jvns.ca/blog/2025/02/13/how-to-add-a-directory-to-your-path/#a-note-on-fish-add-path\">further down</a>)</p><h3>step 5: restart your shell</h3><p>Now, an extremely important step: updating your shell’s config won’t take\neffect if you don’t restart it!</p><ol><li>open a new terminal (or terminal tab), and maybe close the old one so you don’t get confused</li><li>Run  to start a new shell (or  if you’re using zsh, or  if you’re using fish)</li></ol><p>I’ve found that both of these usually work fine.</p><p>And you should be done! Try running the program you were trying to run and\nhopefully it works now.</p><p>If not, here are a couple of problems that you might run into:</p><h3>problem 1: it ran the wrong program</h3><p>If the wrong  of a is program running, you might need to add the\ndirectory to the  of your PATH instead of the end.</p><p>For example, on my system I have two versions of  installed, which I\ncan see by running :</p><pre><code>$ which -a python3\n/usr/bin/python3\n/opt/homebrew/bin/python3\n</code></pre><p>The one your shell will use is the .</p><p>If you want to use the Homebrew version, you need to add that directory\n() to the  of your PATH instead, by putting this in\nyour shell’s config file (it’s  instead of the usual )</p><pre><code>export PATH=/opt/homebrew/bin/:$PATH\n</code></pre><pre><code>set PATH ~/.cargo/bin $PATH\n</code></pre><h3>problem 2: the program isn’t being run from your shell</h3><p>All of these directions only work if you’re running the program . If you’re running the program from an IDE, from a GUI, in a cron job,\nor some other way, you’ll need to add the directory to your PATH in a different\nway, and the exact details might depend on the situation.</p><ul><li>use the full path to the program you’re running, like <code>/home/bork/bin/my-program</code></li><li>put the full PATH you want as the first line of your crontab (something like\nPATH=/bin:/usr/bin:/usr/local/bin:….). You can get the full PATH you’re\nusing in your shell by running .</li></ul><p>I’m honestly not sure how to handle it in an IDE/GUI because I haven’t run into\nthat in a long time, will add directions here if someone points me in the right\ndirection.</p><h3>problem 3: duplicate  entries making it harder to debug</h3><p>If you edit your path and start a new shell by running  (or , or\n), you’ll often end up with duplicate  entries, because the shell\nkeeps adding new things to your  every time you start your shell.</p><p>Personally I don’t think I’ve run into a situation where this kind of\nduplication breaks anything, but the duplicates can make it harder to debug\nwhat’s going on with your  if you’re trying to understand its contents.</p><p>Some ways you could deal with this:</p><ol><li>If you’re debugging your , open a new terminal to do it in so you get\na “fresh” state. This should avoid the duplication.</li><li>Deduplicate your  at the end of your shell’s config  (for example in\nzsh apparently you can do this with )</li><li>Check that the directory isn’t already in your  when adding it (for\nexample in fish I believe you can do this with <code>fish_add_path --path /some/directory</code>)</li></ol><p>How to deduplicate your  is shell-specific and there isn’t always a\nbuilt in way to do it so you’ll need to look up how to accomplish it in your\nshell.</p><h3>problem 4: losing your history after updating your </h3><p>Here’s a situation that’s easy to get into in bash or zsh:</p><ol><li>Run  to reload your config</li><li>Press the up arrow a couple of times to rerun the failed command (or open a new terminal)</li><li>The failed command isn’t in your history! Why not?</li></ol><p>This happens because in bash, by default, history is not saved until you exit\nthe shell.</p><p>Some options for fixing this:</p><ul><li>Instead of running  to reload your config, run  (or\n in zsh). This will reload the config inside your current\nsession.</li><li>Configure your shell to continuously save your history instead of only saving\nthe history when the shell exits. (How to do this depends on whether you’re\nusing bash or zsh, the history options in zsh are a bit complicated and I’m\nnot exactly sure what the best way is)</li></ul><p>When you install  (Rust’s installer) for the first time, it gives you\nthese instructions for how to set up your PATH, which don’t mention a specific\ndirectory at all.</p><pre><code>This is usually done by running one of the following (note the leading DOT):\n\n. \"$HOME/.cargo/env\"        \t# For sh/bash/zsh/ash/dash/pdksh\nsource \"$HOME/.cargo/env.fish\"  # For fish\n</code></pre><p>The idea is that you add that line to your shell’s config, and their script\nautomatically sets up your  (and potentially other things) for you.</p><p>This is pretty common (for example <a href=\"https://github.com/Homebrew/install/blob/deacfa6a6e62e5f4002baf9e1fac7a96e9aa5d41/install.sh#L1072-L1087\">Homebrew</a> suggests you eval ), and there are\ntwo ways to approach this:</p><ol><li>Just do what the tool suggests (like adding  to your shell’s config)</li><li>Figure out which directories the script they’re telling you to run would add\nto your PATH, and then add those manually. Here’s how I’d do that:\n<ul><li>Run  in my shell (or the fish version if using fish)</li><li>Run <code>echo \"$PATH\" | tr ':' '\\n' | grep cargo</code> to figure out which directories it added</li><li>See that it says  and shorten that to </li><li>Add the directory  to PATH (with the directions in this post)</li></ul></li></ol><p>I don’t think there’s anything wrong with doing what the tool suggests (it\nmight be the “best way”!), but personally I usually use the second approach\nbecause I prefer knowing exactly what configuration I’m changing.</p><p>fish has a handy function called  that you can run to add a directory to your  like this:</p><pre><code>fish_add_path /some/directory\n</code></pre><p>This is cool (it’s such a simple command!) but I’ve stopped using it for a couple of reasons:</p><ol><li>Sometimes  will update the  for every session in the\nfuture (with a “universal variable”) and sometimes it will update the \njust for the current session and it’s hard for me to tell which one it will\ndo. In theory the docs explain this but I could not understand them.</li></ol><p>Hopefully this will help some people. Let me know (on Mastodon or Bluesky) if\nyou there are other major gotchas that have tripped you up when adding a\ndirectory to your PATH, or if you have questions about this post!</p>","contentLength":9872,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DOGE as a National Cyberattack","url":"https://www.schneier.com/blog/archives/2025/02/doge-as-a-national.html","date":1739448206,"author":"Bruce Schneier","guid":174,"unread":true,"content":"<p>In the span of just weeks, the US government has experienced what may be the most consequential security breach in its history—not through a sophisticated cyberattack or an act of foreign espionage, but through official orders by a billionaire with a poorly defined government role. And the implications for national security are profound.</p><p>First, it was reported that people associated with the newly created Department of Government Efficiency (DOGE) had <a href=\"https://bsky.app/profile/wyden.senate.gov/post/3lh5ejpwncc23\">accessed</a><a href=\"https://www.nytimes.com/2025/02/01/us/politics/elon-musk-doge-federal-payments-system.html\">the</a><a href=\"https://nymag.com/intelligencer/article/elon-musk-doge-treasury-access-federal-payments.html\">US</a><a href=\"https://therecord.media/union-groups-sue-treasury-over-giving-doge-access-to-data\">Treasury</a> computer system, giving them the ability to collect data on and potentially control the department’s roughly <a href=\"https://fiscal.treasury.gov/fds/\">$5.45 trillion</a> in annual federal payments.</p><p>Then, we learned that uncleared DOGE personnel had gained access to <a href=\"https://www.nbcnews.com/politics/national-security/usaid-security-leaders-removed-refusing-elon-musks-doge-employees-acce-rcna190357\">classified</a> data from the US Agency for International Development, possibly copying it onto their own systems. Next, the Office of Personnel Management—which holds detailed personal data on millions of federal employees, including those with security clearances—<a href=\"https://fedscoop.com/opm-email-federal-workforce-lawsuit-server-privacy-security/\">was</a><a href=\"https://www.yahoo.com/tech/elon-musk-seizes-computer-system-171738117.html\">compromised</a>. After that, <a href=\"https://www.reuters.com/world/us/doge-aides-search-medicare-agency-payment-systems-fraud-wsj-reports-2025-02-05/\">Medicaid and Medicare records</a> were compromised.</p><p>Meanwhile, only partially redacted names of CIA employees <a href=\"https://thehill.com/policy/national-security/5129170-cia-email-employee-identities/\">were sent</a> over an unclassified email account. DOGE personnel are also reported to be <a href=\"https://www.washingtonpost.com/nation/2025/02/06/elon-musk-doge-ai-department-education/\">feeding</a> Education Department data into artificial intelligence software, and they have also <a href=\"https://www.reuters.com/world/us/three-doge-members-raise-access-concerns-us-energy-department-sources-say-2025-02-07/\">started working</a> at the Department of Energy.</p><p>This story is moving very fast. On Feb. 8, a federal judge <a href=\"https://www.reuters.com/legal/us-judge-temporarily-blocks-musks-doge-accessing-payment-systems-2025-02-08/\">blocked</a> the DOGE team from accessing the Treasury Department systems any further. But given that DOGE workers have already copied data and possibly installed and modified software, it’s unclear how this fixes anything.</p><p>In any case, breaches of other critical government systems are likely to follow unless federal employees stand firm on the protocols protecting national security.</p><p>The systems that DOGE is accessing are not esoteric pieces of our nation’s infrastructure—they are the <a href=\"https://www.lawfaremedia.org/article/elon-musk-weaponizes-the-government\">sinews of government</a>.</p><p>For example, the Treasury Department systems contain the technical blueprints for how the federal government moves money, while the Office of Personnel Management (OPM) network contains information on who and what organizations the government employs and contracts with.</p><p>What makes this situation unprecedented isn’t just the scope, but also the method of attack. Foreign adversaries typically spend years attempting to penetrate government systems such as these, using stealth to avoid being seen and carefully hiding any tells or tracks. The Chinese government’s 2015 breach of <a href=\"https://www.washingtonpost.com/world/national-security/chinese-hackers-breach-federal-governments-personnel-office/2015/06/04/889c0e52-0af7-11e5-95fd-d580f1c5d44e_story.html\">OPM</a> was a significant US security failure, and it illustrated how personnel data could be used to identify intelligence officers and compromise national security.</p><p>In this case, external operators with <a href=\"https://www.wired.com/story/elon-musk-government-young-engineers/\">limited experience</a> and minimal oversight are doing their work in plain sight and under massive public scrutiny: gaining the highest levels of <a href=\"https://talkingpointsmemo.com/edblog/musk-cronies-dive-into-treasury-dept-payments-code-base\">administrative access</a> and making changes to the United States’ most sensitive networks, potentially introducing new security vulnerabilities in the process.</p><p>But the most alarming aspect isn’t just the access being granted. It’s the systematic dismantling of security measures that would detect and prevent misuse—including standard incident response protocols, auditing, and change-tracking mechanisms—<a href=\"https://www.theguardian.com/us-news/2025/feb/02/usaid-officials-put-on-leave-musk-doge\">by</a> removing the career officials in charge of those security measures and replacing them with inexperienced operators.</p><p>The Treasury’s computer systems have such an impact on national security that they were designed with the same principle that guides nuclear launch protocols: No single person should have unlimited power. Just as launching a nuclear missile requires two separate officers turning their keys simultaneously, making changes to critical financial systems traditionally requires multiple authorized personnel working in concert.</p><p>This approach, known as “separation of duties,” isn’t just bureaucratic red tape; it’s a fundamental security principle as old as banking itself. When your local bank processes a large transfer, it requires two different employees to verify the transaction. When a company issues a major financial report, separate teams must review and approve it. These aren’t just formalities—they’re essential safeguards against corruption and error. These measures have been <a href=\"https://www.wired.com/story/elon-musk-government-young-engineers/\">bypassed or ignored</a>. It’s as if someone found a way to rob Fort Knox by simply declaring that the new official policy is to fire all the guards and allow unescorted visits to the vault.</p><p>The implications for national security are <a href=\"https://techcrunch.com/2025/02/05/the-biggest-breach-of-u-s-government-data-is-under-way/\">staggering</a>. Sen. Ron Wyden said his office had learned that the attackers gained <a href=\"https://securityaffairs.com/173776/security/elon-musk-s-doge-granted-full-access-to-sensitive-treasury-systems.html\">privileges</a> that allow them to modify core programs in Treasury Department computers that verify federal payments, access encrypted keys that secure financial transactions, and alter audit logs that record system changes. Over at OPM, reports indicate that individuals associated with DOGE <a href=\"https://www.rawstory.com/elon-musk-doge-lawsuit/\">connected</a> an unauthorized server into the network. They are also reportedly <a href=\"https://gizmodo.com/elon-musks-doge-running-highly-sensitive-government-data-through-ai-report-2000560381\">training</a><a href=\"https://www.washingtonpost.com/nation/2025/02/06/elon-musk-doge-ai-department-education/\">AI</a> software on all of this sensitive data.</p><p>This is much more critical than the initial unauthorized access. These new servers have unknown capabilities and configurations, and there’s no evidence that this new code has gone through any rigorous security testing protocols. The AIs being trained are certainly not secure enough for this kind of data. All are ideal targets for any adversary, foreign or domestic, also seeking access to federal data.</p><p>There’s a reason why every modification—hardware or software—to these systems goes through a complex planning process and includes sophisticated access-control mechanisms. The national security crisis is that these systems are now much more vulnerable to dangerous attacks at the same time that the legitimate system administrators trained to protect them have been <a href=\"https://www.reuters.com/world/us/musk-aides-lock-government-workers-out-computer-systems-us-agency-sources-say-2025-01-31/\">locked out</a>.</p><p>By modifying core systems, the attackers have not only compromised current operations, but have also left behind vulnerabilities that could be exploited in future attacks—giving adversaries such as Russia and China an <a href=\"https://therecord.media/doge-opm-treasury-cybersecurity\">unprecedented</a><a href=\"https://cyberscoop.com/musk-doge-opm-treasury-breach/\">opportunity</a>. These countries have long targeted these systems. And they don’t just want to gather intelligence—they also want to understand how to disrupt these systems in a crisis.</p><p>Now, the technical details of how these systems operate, their security protocols, and their vulnerabilities are now potentially exposed to unknown parties without any of the usual safeguards. Instead of having to breach heavily fortified digital walls, these parties &nbsp;can simply walk through doors that are being propped open—and then erase evidence of their actions.</p><p>The security implications span three critical areas.</p><p>First, system manipulation: External operators can now modify operations while also altering audit trails that would track their changes. Second, data exposure: Beyond accessing personal information and transaction records, these operators can copy entire system architectures and security configurations—in one case, the technical blueprint of the country’s federal payment infrastructure. Third, and most critically, is the issue of system control: These operators can alter core systems and authentication mechanisms while disabling the very tools designed to detect such changes. This is more than modifying operations; it is modifying the infrastructure that those operations use.</p><p>To address these vulnerabilities, three immediate steps are essential. First, unauthorized access must be revoked and proper authentication protocols restored. Next, comprehensive system monitoring and change management must be reinstated—which, given the difficulty of cleaning a compromised system, will likely require a complete system reset. Finally, thorough audits must be conducted of all system changes made during this period.</p><p>This is beyond politics—this is a matter of national security. Foreign national intelligence organizations will be quick to take advantage of both the chaos and the new insecurities to steal US data and install backdoors to allow for future access.</p><p>Each day of continued unrestricted access makes the eventual recovery more difficult and increases the risk of irreversible damage to these critical systems. While the full impact may take time to assess, these steps represent the minimum necessary actions to begin restoring system integrity and security protocols.</p><p>Assuming that anyone in the government still cares.</p><p><em>This essay was written with Davi Ottenheimer, and originally appeared in <a href=\"https://foreignpolicy.com/2025/02/11/doge-cyberattack-united-states-treasury/\">Foreign Policy</a>.</em></p>","contentLength":8433,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GenAI Patterns: Reranker","url":"https://martinfowler.com/articles/gen-ai-patterns/#reranker","date":1739441760,"author":"Martin Fowler","guid":192,"unread":true,"content":"<p>LLMs struggle with large amounts of context. <b>Bharani\n      Subramaniam</b> and I explain how to mitigate this common RAG\n      problem with a <a href=\"https://martinfowler.com/articles/gen-ai-patterns/#reranker\">Reranker</a> which takes the document\n      fragments from the retriever, and ranks them according to their usefulness.</p>","contentLength":253,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EuroPython: EuroPython February 2025 Newsletter","url":"https://blog.europython.eu/europython-february-2025-newsletter/","date":1739435771,"author":"","guid":335,"unread":true,"content":"<p>Hope you&amp;aposre all having a fantastic February. We sure have been busy and got some exciting updates for you as we gear up for EuroPython 2025, which is taking place once again in the beautiful city of Prague. So let&amp;aposs dive right in!</p><p>EuroPython 2025 is right around the corner and our programme team is hard at work putting together an amazing lineup. But we need your help to shape the conference! We received over 572 fantastic proposals, and now it’s time for Community Voting! 🎉 If you&amp;aposve attended EuroPython before or submitted a proposal this year, you’re eligible to vote.</p><p>📢 More votes = a stronger, more diverse programme! Spread the word and get your EuroPython friends to cast their votes too.</p><p>🏃The deadline is , so don’t miss your chance!</p><p>Want to play a key role in building an incredible conference? Join our review team and help select the best talks for EuroPython 2025! Whether you&amp;aposre a Python expert or an enthusiastic community member, your insights matter.</p><p>We’d like to also thank the over 100 people who have already signed up to review! For those who haven’t done so yet, please remember to accept your Pretalx link and get your reviews in by </p><p>You can already start reviewing proposals, and each review takes as little as 5 minutes. We encourage reviewers to go through at least 20-30 proposals, but if you can do more, even better! With almost 600 submissions to pick from, your help ensures we curate a diverse and engaging programme.</p><p>🏃The deadline is Monday next week, so don’t delay!</p><p>EuroPython isn’t just present at other Python events—we actively support them too! As a community sponsor, we love helping local PyCons grow and thrive. We love giving back to the community and strengthening Python events across Europe! 🐍💙</p><p>The EuroPython team had a fantastic time at PyCon + Web in Berlin, meeting fellow Pythonistas, exchanging ideas, and spreading the word about EuroPython 2025. It was great to connect with speakers, organizers, and attendees.&nbsp;</p><p>Ever wondered how long it takes to walk from Berlin to Prague? A huge thank you to our co-organizers, Cheuk, Artur, and Cristián, for answering that in their fantastic lightning talk about EuroPython!</p><img src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeeVCMBckwBAVXDAhKyHXq8LJVHJysbWS61RNAeilg_qHzHZgzbC1SALu5u3qS-YjyjSQoUE3zIzVCcSHNj26mzPf43RP4PgcV3iUJPzcu_gAEXO25atB6gn7ZQ8O4Pu6vGttw_MQ?key=7MRGElcwE05wjMSe8jkdrI9g\" alt=\"alt\" width=\"512\" height=\"344\"><p>We had some members of the EuroPython team at FOSDEM 2025, connecting with the open-source community and spreading the Python love! 🎉 We enjoyed meeting fellow enthusiasts, sharing insights about the EuroPython Society, and giving away the first EuroPython 2025 stickers. If you stopped by—thank you and we hope to see you in Prague this July.</p><img src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXd6Dp3RdSY2Wm04WwjDJE6NP1fW_NRCUEVZws-cdneLjGf0gvbq7WWphC8AHEwS0qJsAT6ao4Nm36N3e2QhN15S-w1Xmv1AJxEo0480IWXXwLAVhXZ_TcR5qDW31Hf40hYeDKJzyw?key=7MRGElcwE05wjMSe8jkdrI9g\" alt=\"alt\" width=\"517\" height=\"388\"><h2>🦒 Speaker Mentorship Programme</h2><p>The signups for The Speaker Mentorship Programme closed on 22nd January 2025. We’re excited to have matched 43 mentees with 24 mentors from our community. We had an increase in the number of mentees who signed up and that’s amazing! We’re glad to be contributing to the journey of new speakers in the Python community. A massive thank you to our mentors for supporting the mentees and to our mentees; we’re proud of you for taking this step in your journey as a speaker.&nbsp;</p><p>26 mentees submitted at least 1 proposal. Out of this number, 13 mentees submitted 1 proposal, 9 mentees submitted 2 proposals, 2 mentees submitted 3 proposals, 1 mentee submitted 4 proposals and lastly, 1 mentee submitted 5 proposals. We wish our mentees the best of luck. We look forward to the acceptance of their proposals.</p><p>In a few weeks, we will host an online panel session with 2–3 experienced community members who will share their advice with first-time speakers. At the end of the panel, there will be a Q&amp;A session to answer all the participants’ questions.</p><p>You can watch the recording of the previous year’s workshop here:</p><p>EuroPython is one of the largest Python conferences in Europe, and it wouldn’t be possible without our sponsors. We are so grateful for the companies who have already expressed interest. If you’re interested in sponsoring EuroPython 2025 as well, please reach out to us at <a href=\"mailto:sponsoring@europython.eu\">sponsoring@europython.eu</a>.</p><h2>🎤 EuroPython Speakers Share Their Experiences</h2><p>We asked our past speakers to share their experiences speaking at EuroPython. These videos have been published on YouTube as shorts, and we&amp;aposve compiled them into brief clips for you to watch.</p><p>A big thanks goes to Sebastian Witowski, Jan Smitka, Yuliia Barabash, Jodie Burchell, Max Kahan, and Cheuk Ting Ho for sharing their experiences.</p><p>Why You Should Submit a Proposal for EuroPython? Part 2</p><p>Why You Should Submit a Proposal for EuroPython? Part 3</p><h2>📊 EuroPython Society Board Report&nbsp;</h2><p>The EuroPython conference wouldn’t be what it is without the incredible volunteers who make it all happen. 💞 Behind the scenes, there’s also the EuroPython Society—a volunteer-led non-profit that manages the fiscal and legal aspects of running the conference, oversees its organization, and works on a few smaller projects like the grants programme. To keep everyone in the loop and promote transparency, the Board is sharing regular updates on what we’re working on.</p><p>That&amp;aposs all for now! Keep an eye on your inbox and our website for more news and announcements. We&amp;aposre counting down the days until we can come together in Prague to celebrate our shared love for Python. 🐍❤️</p><p>Cheers,The EuroPython Team</p>","contentLength":5275,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Giampaolo Rodola: psutil: drop Python 2.7 support","url":"https://gmpy.dev/blog/2025/psutil-drop-python-27-support","date":1739401200,"author":"","guid":333,"unread":true,"content":"<p>About dropping Python 2.7 support in psutil, 3 years ago\n<a href=\"https://github.com/giampaolo/psutil/issues/2014#issuecomment-969263432\">I stated</a>:</p><blockquote><p>Not a chance, for many years to come. [Python 2.7] currently represents 7-10%\nof total downloads, meaning around 70k / 100k downloads per day.</p></blockquote><p>Only 3 years later, and to my surprise, <strong>downloads for Python 2.7 dropped to\n0.36%</strong>! As such, as of psutil 7.0.0, I finally decided to drop support for\nPython 2.7!</p><p>These are downloads per month:</p><div><pre><code></code></pre></div><p>According to <a href=\"https://archive.is/wip/knzql\">pypistats.org</a> Python 2.7 downloads\nrepresents the 0.28% of the total, around 15.000 downloads per day.</p><p>Maintaining 2.7 support in psutil had become increasingly difficult, but still\npossible. E.g. I could still run tests by using <a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/setup.py#L76-L85\">old PYPI\nbackports</a>.\nGitHub Actions could still be\n<a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/.github/workflows/build.yml#L77-L112\">tweaked</a>\nto run tests and produce 2.7 wheels on Linux and macOS. Not on Windows though,\nfor which I had to use a separate service (Appveyor). Still, the amount of\nhacks in psutil source code necessary to support Python 2.7 piled up over the\nyears, and became quite big. Some disadvantages that come to mind:</p><ul><li>Having to maintain a Python compatibility layers like\n  <a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/psutil/_compat.py\">psutil/_compat.py</a>.\n  This translated in extra extra code and extra imports.</li><li>The C compatibility layer to differentiate between Python 2 and 3 (<code>#if\n  PY_MAJOR_VERSION &lt;= 3</code>, etc.).</li><li>Dealing with the string vs. unicode differences, both in Python and in C.</li><li>Inability to use modern language features, especially f-strings.</li><li>Inability to freely use s, which created a difference on how CONSTANTS\n  were exposed in terms of API.</li><li>Having to install a specific version of  and other (outdated)\n  <a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/setup.py#L76-L85\">deps</a>.</li><li>Relying on the third-party Appveyor CI service to run tests and produce 2.7\n  wheels.</li><li>Running 4 extra CI jobs on every commit (Linux, macOS, Windows 32-bit,\n  Windows 64-bit) making the CI slower and more subject to failures (we have\n  quite a bit of flaky tests).</li><li>The distribution of 7 wheels specific for Python 2.7. E.g. in the previous\n  release I had to upload:</li></ul><div><pre><code>psutil-6.1.1-cp27-cp27m-macosx_10_9_x86_64.whl\npsutil-6.1.1-cp27-none-win32.whl\npsutil-6.1.1-cp27-none-win_amd64.whl\npsutil-6.1.1-cp27-cp27m-manylinux2010_i686.whl\npsutil-6.1.1-cp27-cp27m-manylinux2010_x86_64.whl\npsutil-6.1.1-cp27-cp27mu-manylinux2010_i686.whl\npsutil-6.1.1-cp27-cp27mu-manylinux2010_x86_64.whl\n</code></pre></div><p>The removal was done in\n<a href=\"https://github.com/giampaolo/psutil/pull/2481\">PR-2841</a>, which removed around\n1500 lines of code (nice!). . In doing so, in the doc I\nstill made the promise that the 6.1.* serie will keep supporting Python 2.7\nand will receive  (no new features). It will be\nmaintained in a specific <a href=\"https://github.com/giampaolo/psutil/tree/python2\">python2\nbranch</a>. I explicitly kept\nthe\n<a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/setup.py\">setup.py</a>\nscript compatible with Python 2.7 in terms of syntax, so that, when the tarball\nis fetched from PYPI, it will emit an informative error message on . The user trying to install psutil on Python 2.7 will see:</p><div><pre><code>$pip2installpsutil\nAsofversion.0.0psutilnolongersupportsPython.7.\nLatestversionsupportingPython.7ispsutil.1.X.\nInstallitwith:.\n</code></pre></div><p>As the informative message states, users that are still on Python 2.7 can still\nuse psutil with:</p><div><pre><code>pip2 install psutil==6.1.*\n</code></pre></div>","contentLength":2975,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kay Hayen: Nuitka Release 2.6","url":"https://nuitka.net/posts/nuitka-release-26.html","date":1739401200,"author":"","guid":334,"unread":true,"content":"<li><p> Path normalization to native Windows format was required\nin more places for the  variant of .</p><p>The  function doesn’t normalize to native Win32\npaths with MSYS2, instead using forward slashes. This required manual\nnormalization in additional areas. (Fixed in 2.5.1)</p></li><li><p> Fix, give a proper error when extension modules asked to\ninclude failed to be located. instead of a proper error message.\n(Fixed in 2.5.1)</p></li><li><p>Fix, files with illegal module names (containing ) in their\nbasename were incorrectly considered as potential sub-modules for\n. These are now skipped. (Fixed in 2.5.1)</p></li><li><p> Improved stability by preventing crashes when stubgen\nencounters code it cannot handle. Exceptions from it are now ignored.\n(Fixed in 2.5.1)</p></li><li><p> Addressed a crash that occurred when encountering\nassignments to non-variables. (Fixed in 2.5.1)</p></li><li><p> Fixed a regression introduced in 2.5 release that could\nlead to segmentation faults in exception handling for generators.\n(Fixed in 2.5.2)</p></li><li><p> Corrected an issue where dictionary copies of large\nsplit directories could become corrupted. This primarily affected\ninstance dictionaries, which are created as copies until updated,\npotentially causing problems when adding new keys. (Fixed in 2.5.2)</p></li><li><p> Removed the assumption that module dictionaries\nalways contain only strings as keys. Some modules, like\n on macOS, use non-string keys. (Fixed in 2.5.2)</p></li><li><p> Ensured that the  option correctly\naffects the C compilation process. Previously, only individual\ndisables were applied. (Fixed in 2.5.2)</p></li><li><p> Fixed a crash that could occur during compilation\nwhen unary operations were used within binary operations. (Fixed in\n2.5.3)</p></li><li><p> Corrected the handling of\n<code></code>, which could lead to crashes. (Fixed\nin 2.5.4)</p></li><li><p> Resolved a segmentation fault occurring at runtime\nwhen calling  with only keyword arguments.\n(Fixed in 2.5.5)</p></li><li><p> Harmless warnings generated for x64 DLLs on arm64 with\nnewer macOS versions are now ignored. (Fixed in 2.5.5)</p></li><li><p> Addressed a crash in Nuitka’s dictionary code that\noccurred when copying dictionaries due to internal changes in Python\n3.13. (Fixed in 2.5.6)</p></li><li><p> Improved onefile mode signing by applying\n to the signature of binaries, not just\napp bundles. (Fixed in 2.5.6)</p></li><li><p> Corrected an issue where too many paths were added as\nextra directories from the Nuitka package configuration. This\nprimarily affected the  package, which currently relies\non the  import hack. (Fixed in 2.5.6)</p></li><li><p> Prevented crashes on macOS when creating onefile\nbundles with Python 2 by handling negative CRC32 values. This issue\nmay have affected other versions as well. (Fixed in 2.5.6)</p></li><li><p> Restored the functionality of code provided in\n, which was no longer being applied due to a\nregression. (Fixed in 2.5.6)</p></li><li><p> Suppressed the app bundle mode recommendation when it is\nalready in use. (Fixed in 2.5.6)</p></li><li><p> Corrected path normalization when the output directory\nargument includes “~”.</p></li><li><p> GitHub Actions Python is now correctly identified as a\nHomebrew Python to ensure proper DLL resolution. (Fixed in 2.5.7)</p></li><li><p> Fixed a reference leak that could occur with\nvalues sent to generator objects. Asyncgen and coroutines were not\naffected. (Fixed in 2.5.7)</p></li><li><p> The  scan now correctly handles\ncases where both a package init file and competing Python files\nexist, preventing compile-time conflicts. (Fixed in 2.5.7)</p></li><li><p> Resolved an issue where handling string constants in\nmodules created for Python 3.12 could trigger assertions, and modules\ncreated with 3.12.7 or newer failed to load on older Python 3.12\nversions when compiled with Nuitka 2.5.5-2.5.6. (Fixed in 2.5.7)</p></li><li><p> Corrected the tuple code used when calling certain\nmethod descriptors. This issue primarily affected a Python 2\nassertion, which was not impacted in practice. (Fixed in 2.5.7)</p></li><li><p> Updated resource readers to accept multiple\narguments for <code></code>, and correctly handle\n and  as keyword-only arguments.</p></li><li><p> The platform encoding is no longer used to decode\n logs. Instead,  is used, as it is sufficient for\nmatching filenames across log lines and avoids potential encoding\nerrors. (Fixed in 2.5.7)</p></li><li><p> Requests to statically link libraries for \nare now ignored, as these libraries do not exist. (Fixed in 2.5.7)</p></li><li><p> Fixed a memory leak affecting the results of\nfunctions called via specs. This primarily impacted overloaded hard\nimport operations. (Fixed in 2.5.7)</p></li><li><p> When multiple distributions for a package are found,\nthe one with the most accurate file matching is now selected. This\nimproves handling of cases where an older version of a package (e.g.,\n) is overwritten with a different variant (e.g.,\n), ensuring the correct version is used for\nNuitka package configuration and reporting. (Fixed in 2.5.8)</p></li><li><p> Prevented a potential crash during onefile\ninitialization on Python 2 by passing the directory name directly\nfrom the onefile bootstrap, avoiding the use of  which\nmay not be fully loaded at that point. (Fixed in 2.5.8)</p></li><li><p> Preserved necessary  environment variables on\nWindows for packages that require loading DLLs from those locations.\nOnly  entries not pointing inside the installation prefix are\nremoved. (Fixed in 2.5.8)</p></li><li><p> Corrected the  check to function\nproperly when distribution names and package names differ. (Fixed in\n2.5.8)</p></li><li><p> Improved package name resolution for Anaconda\ndistributions by checking conda metadata when file metadata is\nunavailable through the usual methods. (Fixed in 2.5.8)</p></li><li><p> Normalized the downloaded gcc path to use native Windows\nslashes, preventing potential compilation failures. (Fixed in 2.5.9)</p></li><li><p> Restored static libpython functionality on Linux by\nadapting to a signature change in an unexposed API. (Fixed in 2.5.9)</p></li><li><p> Prevented  from being resurrected when a\nfinalizer is attached, resolving memory leaks that could occur with\n in the presence of exceptions. (Fixed in 2.5.10)</p></li><li><p> Suppressed the gcc download prompt that could appear during\n output on Windows systems without MSVC or with an\nimproperly installed gcc.</p></li><li><p>Ensured compatibility with monkey patched  or \nfunctions, which are used in some testing scenarios.</p></li><li><p> Improved the determinism of the JSON statistics\noutput by sorting keys, enabling reliable build comparisons.</p></li><li><p> Fixed a memory leak in  with finalizers,\nwhich could lead to significant memory consumption when using\n and encountering exceptions.</p></li><li><p> Optimized empty generators (an optimization result) to\navoid generating unused context code, eliminating C compilation\nwarnings.</p></li><li><p> Fixed a reference leak affecting the  value\nin . While typically , this could lead to\nobservable reference leaks in certain cases.</p></li><li><p> Improved handling of  and \nresurrection, preventing memory leaks with  and\n, and ensuring correct execution of  code in\ncoroutines.</p></li><li><p> Corrected the handling of  objects\nresurrecting during deallocation. While not explicitly demonstrated,\nthis addresses potential issues similar to those encountered with\ncoroutines, particularly for old-style coroutines created with the\n decorator.</p></li><li><p> Fixed a potential crash during runtime trace collection by\nensuring timely initialization of the output mechanism.</p></li>","contentLength":6936,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EuroPython Society: Board Report for January 2025","url":"https://www.europython-society.org/board-report-for-january-2025/","date":1739372917,"author":"","guid":332,"unread":true,"content":"<p>The top priority for the board in January was finishing the hiring of our event manager. We’re super excited to introduce Anežka Müller! Anežka is a freelance event manager and a longtime member of the Czech Python community. She’s a member of the Pyvec board, co-organizes PyLadies courses, PyCon CZ, Brno Pyvo, and Brno Python Pizza. She’ll be working closely with the board and OPS team, mainly managing communication with service providers. Welcome onboard! </p><p>Our second priority was onboarding teams. We’re happy that we already have the Programme team in place—they started early and launched the Call for Proposals at the beginning of January. We’ve onboarded a few more teams and are in the process of bringing in the rest.</p><p>Our third priority was improving our grant programme in order to support more events with our limited budget and to make it more clear and transparent. We went through past data, came up with a new proposal, discussed it, voted on it, and have already published it on our <a href=\"https://www.europython-society.org/changes-in-the-grants-programme-for-2025/\">blog</a>. </p><ul><li>Updating onboarding/offboarding checklists for Volunteers and Board Members</li><li>Various infrastructure updates including new website deployment and self-hosted previews for Pull Requests to the website.</li><li>Setting up EPS AWS account.</li><li>Working out the Grant Guidelines update for 2025</li><li>Attending PyConWeb and FOSDEM</li><li>Reviewing updates to the Sponsors setup and packages for 2025</li><li>More documentation, sharing know-how and reviewing new proposals.</li></ul><ul><li>Brand strategy: Analysis of social media posts from previous years and web analytics. Call with a European open-source maintainer and a call with a local events organizer about EP content.</li><li>Comms &amp; design: Call for proposal announcements, EP 2024 video promotions, speaker mentorship, and newsletter. Video production - gathering videos from speakers, video post-production, and scheduling them on YouTube shorts, and social media.</li><li>Event management coordination: Calls with the event manager and discussions about previous events.</li><li>Grants: Work on new grant guidelines and related comms.</li><li>Team onboarding: Calls with potential comms team members and coordination.</li><li>PR: Delivering a lightning talk at FOSDEM.</li></ul><ul><li>Offboarding the old board</li><li>Onboarding new team members</li><li>Administrative work on Grants</li></ul><ul><li>Worked on the Grants proposal</li><li>Follow-up with team members</li><li>Community outreach: FOSDEM</li></ul><ul><li>Working on various infrastructure updates, mostly related to the website.</li><li>Reviewing Pull Requests for the website and the internal bot</li><li>Working on the infrastructure team proposal.</li></ul><ul><li>Timeline: Discussion with the Programme Team, and planning to do the same with the other teams.</li><li>Visa Request letter: Setup and Test Visa Request Automation for the current year</li><li>Team selection discussion with past volunteers</li></ul>","contentLength":2708,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python Morsels: Avoid over-commenting in Python","url":"https://www.pythonmorsels.com/avoid-comments/","date":1739372739,"author":"","guid":331,"unread":true,"content":"<h2>Documenting instead of commenting</h2><p>Here is a comment I would not write in my code:</p><div><pre><code></code></pre></div><p>That comment seems to describe what this code does... so why would I  write it?</p><p>I do like that comment, but I would prefer to write it as a <a href=\"https://www.pythonmorsels.com/docstrings/\" target=\"_blank\">docstring</a> instead:</p><div><pre><code></code></pre></div><p>Documentation strings are for conveying the purpose of function, class, or module, typically at a high level.\nUnlike comments, they can be read by Python's built-in  function:</p><div><pre><code></code></pre></div><p>Docstrings are also read by other documentation-oriented tools, like <a href=\"https://www.sphinx-doc.org\" target=\"_blank\">Sphinx</a>.</p><h2>Non-obvious variables and values</h2><p>Here's a potentially helpful comment:</p>","contentLength":557,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real Python: Python Keywords: An Introduction","url":"https://realpython.com/python-keywords/","date":1739368800,"author":"","guid":117,"unread":true,"content":"<p>Python keywords are reserved words with specific functions and restrictions in the language. Currently, Python has thirty-five keywords and four soft keywords. These keywords are always available in Python, which means you don’t need to import them. Understanding how to use them correctly is fundamental for building Python programs.</p><p><strong>By the end of this tutorial, you’ll understand that:</strong></p><ul><li>There are  and  in Python.</li><li>You can get a list of all keywords using  from the  module.</li><li> in Python act as keywords only in specific contexts.</li><li> are keywords that have been deprecated and turned into functions in Python 3.</li></ul><p>In this article, you’ll find a basic introduction to all Python keywords and soft keywords along with other resources that will be helpful for learning more about each keyword.</p><div><p> Test your knowledge with our interactive “Python Keywords: An Introduction” quiz. You’ll receive a score upon completion to help you track your learning progress:</p><div><div><a href=\"https://realpython.com/quizzes/python-keywords/\"></a><p>In this quiz, you'll test your understanding of Python keywords and soft keywords. These reserved words have specific functions and restrictions in Python, and understanding how to use them correctly is fundamental for building Python programs.</p></div></div></div><p>Python keywords are special reserved words that have specific meanings and purposes and can’t be used for anything but those specific purposes. These keywords are always available—you’ll never have to import them into your code.</p><p>Python keywords are different from Python’s <a href=\"https://docs.python.org/3/library/functions.html\">built-in functions and types</a>. The built-in functions and types are also always available, but they aren’t as restrictive as the keywords in their usage. </p><p>An example of something you  do with Python keywords is assign something to them. If you try, then you’ll get a . You won’t get a  if you try to assign something to a built-in function or type, but it still isn’t a good idea. For a more in-depth explanation of ways keywords can be misused, check out <a href=\"https://realpython.com/invalid-syntax-python/#misspelling-missing-or-misusing-python-keywords\">Invalid Syntax in Python: Common Reasons for SyntaxError</a>.</p><p>There are <a href=\"https://docs.python.org/3/reference/lexical_analysis.html#keywords\">thirty-five keywords</a> in Python. Here’s a list of them, each linked to its relevant section in this tutorial:</p><p>Two keywords have additional uses beyond their initial use cases. The  keyword is also <a href=\"https://realpython.com/atom.xml#the-else-keyword-used-with-loops\">used with loops</a> and <a href=\"https://realpython.com/atom.xml#the-else-keyword-used-with-try-and-except\">with  and </a> in addition to in conditional statements. The  keyword is most commonly used in  statements, but also used <a href=\"https://realpython.com/atom.xml#the-as-keyword-used-with-with\">with the  keyword</a>.</p><p>The list of Python keywords and soft keywords has changed over time. For example, the  and  keywords weren’t added until Python 3.7. Also, both  and  were keywords in Python 2.7 but were turned into built-in functions in Python 3 and no longer appear in the keywords list.</p><p>As mentioned above, you’ll get an error if you try to assign something to a Python keyword. Soft keywords, on the other hand, aren’t that strict. They syntactically act as keywords only in certain conditions.</p><p>This new capability was made possible thanks to the introduction of the <a href=\"https://realpython.com/python39-new-features/#a-more-powerful-python-parser\">PEG parser</a> in Python 3.9, which changed how the interpreter reads the source code.</p><p>Leveraging the PEG parser allowed for the introduction of <a href=\"https://realpython.com/structural-pattern-matching/\">structural pattern matching</a> in Python. In order to use intuitive syntax, the authors picked , , and  for the pattern matching statements. Notably,  and  are widely used for this purpose in many other programming languages.</p><p>To prevent conflicts with existing Python code that already used , , and  as variable or function names, Python developers decided to introduce the concept of soft keywords.</p><p>Currently, there are four  in Python:</p><p>You can use the links above to jump to the soft keywords you’d like to read about, or you can continue reading for a guided tour.</p><h2>Value Keywords: , , </h2><p>There are three Python keywords that are used as values. These values are <a href=\"https://python-patterns.guide/gang-of-four/singleton/\">singleton</a> values that can be used over and over again and always reference the exact same object. You’ll most likely see and use these values a lot.</p><p>There are a few terms used in the sections below that may be new to you. They’re defined here, and you should be aware of their meaning before proceeding:</p>","contentLength":4020,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EuroPython Society: Changes in the Grants Programme for 2025","url":"https://www.europython-society.org/changes-in-the-grants-programme-for-2025/","date":1739366190,"author":"","guid":330,"unread":true,"content":"<ul><li>We are increasing transparency and reducing ambiguity in the guidelines.</li><li>We would like to support more events with our limited budget</li><li>We’ve introduced caps for events in order to make sure all grants are fairly given and we can support more communities.</li><li>We’ve set aside 10% of our budget for the local community. </li></ul><p>The EPS introduced a Grant Programme in 2017. Since then, we have granted almost EUR 350k through the programme, partly via EuroPython Finaid and by directly supporting other Python events and projects across Europe. In the last two years, the Grant Programme has grown to EUR 100k per year, with even more requests coming in.</p><p>With this growth come new challenges in how to distribute funds fairly so that more events can benefit. Looking at data from the past two years, we’ve often been close to or over our budget. The guidelines haven’t been updated in a while. As grant requests become more complex, we’d like to simplify and clarify the process, and better explain it on our website.</p><p>We would also like to acknowledge that EuroPython, when traveling around Europe, has an additional impact on the host country, and we’d like to set aside part of the budget for the local community.</p><p>The Grant Programme is also a primary funding source for EuroPython Finaid. To that end, we aim to allocate 30% of the total Grant Programme budget to Finaid, an increase from the previous 25%.</p><ul><li>We’ve updated the <a href=\"https://www.europython-society.org/grants\">text on our website</a>, and split it into multiple sub-pages to make it easier to navigate. The website now includes a checklist of what we would like to see in a grant application, and a checklist for the Grants Workgroup – so that when you apply for the Grant you already know the steps that it will go through later and when you can expect an answer from us.</li><li>We looked at the data from previous years, and size and timing of the grant requests. With the growing number and size of the grants, to make it more accessible to smaller conferences and conferences happening later in the year, we decided to introduce max caps per grant and split the budget equally between the first and second half of the year. We would also explicitly split the total budget into three categories – 30% goes to the EuroPython finaid, 10% is reserved for projects in the host country. The remaining 60% of the budget goes to fund other Python Conferences. This is similar to the split in previous years, but more explicit and transparent.</li></ul><p>Using 2024 data, and the budget available for Community Grants (60% of total), we’ve simulated different budget caps and found a sweet spot at 6000EUR, where we are able to support all the requests with most of the grants being below that limit. For 2025 we expect to receive a similar or bigger number of requests.</p><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><img src=\"https://www.europython-society.org/content/images/2025/02/image-1.png\" alt=\"alt\" width=\"1418\" height=\"496\"><p>We are introducing a special 10% pool of money to be used on projects in the host country (in 2025 that’s again Czech Republic). This pool is set aside at the beginning of the year, with one caveat that we would like to deploy it in the first half of the year. Whatever is left unused goes back to the Community Pool to be used in second half of the year.</p><ul><li>Fairer Funding: By spreading our grants out during the year, conferences that happen later won’t miss out.</li><li>Easy to Follow: Clear rules and deadlines cut down on confusion about how much you can get and what it’s for.</li><li>Better Accountability: We ask for simple post-event reports so we can see where the money went and what impact it made.</li><li>Stronger Community: Funding more events grows our Python network across Europe, helping everyone learn, connect, and collaborate.</li></ul>","contentLength":3581,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Delivering Malware Through Abandoned Amazon S3 Buckets","url":"https://www.schneier.com/blog/archives/2025/02/delivering-malware-through-abandoned-amazon-s3-buckets.html","date":1739362164,"author":"Bruce Schneier","guid":173,"unread":true,"content":"<p>Here’s a <a href=\"https://labs.watchtowr.com/8-million-requests-later-we-made-the-solarwinds-supply-chain-attack-look-amateur/\">supply-chain attack</a> just waiting to happen. A group of researchers searched for, and then registered, abandoned Amazon S3 buckets for about $400. These buckets contained software libraries that are still used. Presumably the projects don’t realize that they have been abandoned, and still ping them for patches, updates, and etc.</p><blockquote><p>The TL;DR is that this time, we ended up discovering ~150 Amazon S3 buckets that had previously been used across commercial and open source software products, governments, and infrastructure deployment/update pipelines—and then abandoned.</p><p>Naturally, we registered them, just to see what would happen—”how many people are really trying to request software updates from S3 buckets that appear to have been abandoned months or even years ago?”, we naively thought to ourselves.</p></blockquote><p>Turns out they got eight million requests over two months.</p><p>Had this been an actual attack, they would have modified the code in those buckets to contain malware and watch as it was incorporated in different software builds around the internet. This is basically the SolarWinds attack, but much more extensive.</p><p>But there’s a second dimension to this attack. Because these update buckets are abandoned, the developers who are using them also no longer have the power to patch them automatically to protect them. The mechanism they would use to do so is now in the hands of adversaries. Moreover, often—but not always—losing the bucket that they’d use for it also removes the original vendor’s ability to identify the vulnerable software in the first place. That hampers their ability to communicate with vulnerable installations.</p><p>Software supply-chain security is an absolute mess. And it’s not going to be easy, or cheap, to fix. Which means that it won’t be. Which is an even worse mess.</p>","contentLength":1821,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real Python: Quiz: Python Keywords: An Introduction","url":"https://realpython.com/quizzes/python-keywords/","date":1739361600,"author":"","guid":116,"unread":true,"content":"<p>Python keywords are reserved words with specific functions and restrictions in the language. These keywords are always available in Python, which means you don’t need to import them. Understanding how to use them correctly is fundamental for building Python programs.</p>","contentLength":269,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Zato Blog: Modern REST API Tutorial in Python","url":"https://zato.io/en/blog/modern-rest-api-tutorial-in-python.html","date":1739347200,"author":"","guid":329,"unread":true,"content":"<div>\n  2025-02-12, by Dariusz Suchojad\n<img src=\"https://upcdn.io/kW15bqq/raw/root/static/blog/authors/dsuch.webp\" alt=\"\" width=\"35\"></div><p>Great APIs don't win theoretical arguments - they just prefer to work reliably and to make developers' lives easier.</p><p>Here's a tutorial on what building production APIs is really about: creating interfaces that are practical in usage,\nwhile keeping your systems maintainable for years to come.</p>","contentLength":326,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kushal Das: pass using stateless OpenPGP command line interface","url":"https://kushaldas.in/posts/pass-using-stateless-openpgp-command-line-interface.html","date":1739337973,"author":"","guid":328,"unread":true,"content":"<p><a href=\"https://kushaldas.in/posts/using-openpgp-card-tool-git-with-git.html\">Yesterday</a> I wrote about how\nI am using a different tool for  signing and verification. Next, I\nreplaced my  usage. I have a <a href=\"https://kushaldas.in/github.com/kushaldas/password-store/compare/master...card\">small\npatch</a> to use\nstateless OpenPGP command line interface (SOP). It is an implementation\nagonostic standard for handling OpenPGP messages. You can read the whole <a href=\"https://datatracker.ietf.org/doc/draft-dkg-openpgp-stateless-cli/\">SPEC\nhere</a>.</p><pre><code>cargo install rsop rsop-oct\n</code></pre><p>And copied the bash script from my repository to the path somewhere.</p><p>The  binary from  follows the same SOP standard but uses the\ncard to signing/decryption. I stored my public key in\n<code>~/.password-store/.gpg-key</code> file, which is in turn used for encryption.</p><p>Here nothing changed related my daily  usage, except the number of time I am typing my  :)</p>","contentLength":669,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Risky Business #779 -- DOGE staffer linked to The Com","url":"https://risky.biz/RB779/","date":1739330328,"author":"","guid":784,"unread":true,"content":"<article></article>","contentLength":0,"flags":null,"enclosureUrl":"https://dts.podtrac.com/redirect.mp3/media3.risky.biz/RB779.mp3","enclosureMime":"","commentsUrl":null},{"title":"GenAI Patterns: Query Rewriting","url":"https://martinfowler.com/articles/gen-ai-patterns/#query-rewrite","date":1739307480,"author":"Martin Fowler","guid":191,"unread":true,"content":"<p>Users often have difficulty writing the most effective queries.\n       and I explain <a href=\"https://martinfowler.com/articles/gen-ai-patterns/#query-rewrite\">Query Rewriting</a>:\n      getting an LLM to formulate alternative queries to send to a RAG's\n      retriever. </p>","contentLength":192,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PyCoder’s Weekly: Issue #668: NumPy, Compiling Python 1.0, BytesIO, and More (Feb. 11, 2025)","url":"https://pycoders.com/issues/668","date":1739302200,"author":"","guid":327,"unread":true,"content":"<div><p> In this video course, you’ll learn how to use NumPy by exploring several interesting examples. You’ll read data from a file into an array and analyze structured arrays to perform a reconciliation. You’ll also learn how to quickly chart an analysis &amp; turn a custom function into a vectorized function.</p></div><div><p> This tutorial will help you master Python string splitting. You’ll learn to use , , and  to effectively handle whitespace, custom delimiters, and multiline text, which will level up your data parsing skills.</p></div><div><p> Python developers use Posit Package Manager to mirror public &amp; internally developed repos within their firewalls. Get reporting on known vulnerabilities to proactively address potential threats. High-security environments can even run air-gapped.</p></div><div><p> The author was recently invited with other senior devs to give a lightning talk on their personal development philosophy. This post captures those thoughts.</p></div><img src=\"https://pycoders.com/issues/668/open/feed\" width=\"1\" height=\"1\" alt=\"alt\"><p><em>[ Subscribe to 🐍 PyCoder’s Weekly 💌 – Get the best Python news, articles, and tutorials delivered to your inbox once a week <a href=\"https://pycoders.com/?utm_source=pycoders&amp;utm_medium=feed&amp;utm_campaign=footer\">&gt;&gt; Click here to learn more</a> ]</em></p>","contentLength":1084,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python Insider: Python 3.14.0 alpha 5 is out","url":"https://pythoninsider.blogspot.com/2025/02/python-3140-alpha-5-is-out.html","date":1739291158,"author":"","guid":326,"unread":true,"content":"<p>Here comes the antepenultimate alpha.</p><p><strong>This is an early developer preview of Python\n3.14</strong></p><p>Python 3.14 is still in development. This release, 3.14.0a5, is the\nfifth of seven planned alpha releases.</p><p>Alpha releases are intended to make it easier to test the current\nstate of new features and bug fixes and to test the release process.</p><p>During the alpha phase, features may be added up until the start of\nthe beta phase (2025-05-06) and, if necessary, may be modified or\ndeleted up until the release candidate phase (2025-07-22). Please keep\nin mind that this is a preview release and its use is\n recommended for production environments.</p><p>Many new features for Python 3.14 are still being planned and\nwritten. Among the new major new features and changes so far:</p><p>The next pre-release of Python 3.14 will be the penultimate alpha,\n3.14.0a6, currently scheduled for 2025-03-14.</p><p>2025-01-29 marked the start of a new lunar year, the Year of the\nSnake 🐍 (and the Year of Python?).</p><p>For centuries, π was often approximated as 3 in China. Some time\nbetween the years 1 and 5 CE, astronomer, librarian, mathematician and\npolitician Liu Xin (劉歆) calculated π as 3.154.</p><p>Around 130 CE, mathematician, astronomer, and geographer Zhang Heng\n(張衡, 78–139) compared the celestial circle with the diameter of the\nearth as 736:232 to get 3.1724. He also came up with a formula for the\nratio between a cube and inscribed sphere as 8:5, implying the ratio of\na square’s area to an inscribed circle is √8:√5. From this, he\ncalculated π as √10 (~3.162).</p><p>Third century mathematician Liu Hui (刘徽) came up with an algorithm\nfor calculating π iteratively: calculate the area of a polygon inscribed\nin a circle, then as the number of sides of the polygon is increased,\nthe area becomes closer to that of the circle, from which you can\napproximate π.</p><p>This algorithm is similar to the method used by Archimedes in the 3rd\ncentury BCE and Ludolph van Ceulen in the 16th century CE (see <a href=\"https://blog.python.org/2024/11/python-3140-alpha-2-released.html\">3.14.0a2\n  release notes</a>), but Archimedes only went up to a 96-sided polygon\n(96-gon). Liu Hui went up to a 192-gon to approximate π as 157/50 (3.14)\nand later a 3072-gon for 3.14159.</p><p>Liu Hu wrote a commentary on the book The Nine Chapters on the\nMathematical Art which included his π approximations.</p><p>In the fifth century, astronomer, inventor, mathematician,\npolitician, and writer Zu Chongzhi (祖沖之, 429–500) used Liu Hui’s\nalgorithm to inscribe a 12,288-gon to compute π between 3.1415926 and\n3.1415927, correct to seven decimal places. This was more accurate than\nHellenistic calculations and wouldn’t be improved upon for 900\nyears.</p><p>Thanks to all of the many volunteers who help make Python Development\nand these releases possible! Please consider supporting our efforts by\nvolunteering yourself or through organisation contributions to the <a href=\"https://www.python.org/psf-landing/\">Python Software\nFoundation</a>.</p><p>Regards from a remarkably snowless Helsinki,</p><p>Your release team, Hugo van KemenadeSteve Dower</p>","contentLength":2941,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real Python: Building a Python Command-Line To-Do App With Typer","url":"https://realpython.com/courses/build-command-line-todo-app-typer/","date":1739282400,"author":"","guid":115,"unread":true,"content":"<p>Building an application to manage your  can be an interesting project when you’re learning a new programming language or trying to take your skills to the next level. In this video course, you’ll build a functional to-do application for the command line using Python and <a href=\"https://typer.tiangolo.com/\">Typer</a>, which is a relatively young library for creating powerful command-line interface (CLI) applications in almost no time.</p><p>With a project like this, you’ll apply a wide set of core programming skills while building a real-world application with real features and requirements.</p><p><strong>In this video course, you’ll learn how to:</strong></p><ul><li>Build a functional  with a  in Python</li><li>Use Typer to add , , and  to your to-do app</li><li>Test your Python to-do application with Typer’s  and </li></ul>","contentLength":734,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trusted Execution Environments","url":"https://www.schneier.com/blog/archives/2025/02/trusted-encryption-environments.html","date":1739275716,"author":"Bruce Schneier","guid":172,"unread":true,"content":"<p>Really good—and detailed—<a href=\"https://dl.acm.org/doi/pdf/10.1145/3634737.3644993\">survey</a> of Trusted Execution Environments (TEEs.)</p>","contentLength":77,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kushal Das: Using openpgp-card-tool-git with git","url":"https://kushaldas.in/posts/using-openpgp-card-tool-git-with-git.html","date":1739272360,"author":"","guid":325,"unread":true,"content":"<p>One of the power of Unix systems comes from the various small tools and how\nthey work together. One such new tool I am using for some time is for  &amp;  using OpenPGP and my Yubikey for the actual signing\noperation via\n<a href=\"https://crates.io/crates/openpgp-card-tool-git\">openpgp-card-tool-git</a>. I\nreplaced the standard  for this usecase with the  command from this\nproject.</p><h3>Installation &amp; configuration</h3><pre><code>cargo install openpgp-card-tool-git\n</code></pre><p>Then you will have to configuration your (in my case the global configuration) git configuration.</p><pre><code>git config --global gpg.program &lt;path to oct-git&gt;\n</code></pre><p>I am assuming that you already had it configured before for signing, otherwise\nyou have to run the following two commands too.</p><pre><code>git config --global commit.gpgsign true\ngit config --global tag.gpgsign true\n</code></pre><p>Before you start using it, you want to save the pin in your system keyring.</p><p>Use the following command.</p><p>That is it, now your  will sign the commits using  tool.</p><p>In the next blog post I will show how to use the other tools from the \n<a href=\"https://crates.io/users/hko-s\">author</a> for various different OpenPGP oeprations.</p>","contentLength":1007,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stateful vs. Stateless Architecture","url":"https://blog.algomaster.io/p/stateful-vs-stateless-architecture","date":1739263586,"author":"Ashish Pratap Singh","guid":750,"unread":true,"content":"<p>When a client interacts with a server, there are two ways to handle it:</p><ul><li><p> The client includes all necessary data in each request, so the server doesn’t store any prior information.</p></li><li><p> The server retains some data from previous requests, making future interactions dependent on past state.</p></li></ul><blockquote><p>In software systems,  refers to any data that persists across requests, such as user sessions, shopping carts, or authentication details.</p></blockquote><p>The choice between stateless and stateful architecture can affect scalability, performance, complexity, and cost.</p><p>In this article, we’ll break down both the approaches, their advantages and trade-offs, and when to use each—with real-world examples.</p><p>If you’re finding this newsletter valuable and want to deepen your learning, consider becoming a .</p><p>As a paid subscriber, you'll receive an <strong>exclusive deep-dive article</strong> every week, access to a structured100+topics and interview questions, and other .</p><p>In a , the system remembers client or process data () across multiple requests.</p><p>Once a client connects, the server holds on to certain details—like user preferences, shopping cart contents, or authentication sessions—so the client doesn’t need to resend everything with each request.</p><p>Stateful systems typically store the state data in a database or in-memory storage.</p><blockquote><p> During online shopping, when you add items to your cart, the website remembers your selections. If you navigate away to browse more items and then return to your cart, your items are still there, waiting for you to check out.</p></blockquote><h2>Common Patterns in Stateful Architecture</h2><p>If you use  session storage (i.e., each app server keeps its own sessions locally), you can configure your load balancer for “sticky sessions.” </p><p>This means: Once a client is assigned to , all subsequent requests from that client are routed to .</p><blockquote><p>: If Server A fails, the user’s session data is lost or the user is forced to re-log in. Sticky sessions are also less flexible when scaling because you can’t seamlessly redistribute user traffic to other servers.</p></blockquote><h3>2. Centralized Session Store</h3><p>A more robust approach is to store session data in a  or  store (e.g., Redis). </p><ul><li><p>: All servers can access and update session data for any user. Any server can handle any request, because the session data is not tied to a specific server’s memory.</p></li></ul><blockquote><p>: You introduce network overhead and rely on an external storage. If the centralized storage fails, you lose session data unless you have a fallback strategy.</p></blockquote><ul><li><p><strong>Personalized Experiences:</strong> Stateful systems can deliver highly tailored interactions, as they remember user preferences and past actions.</p></li><li><p> Users can seamlessly resume activities where they left off, even if they disconnect and reconnect.</p></li><li><p> Certain operations can be faster because the server already possesses necessary data.</p></li></ul><ul><li><p> Maintaining state for a large number of users can become resource-intensive and complex, as each server needs to keep track of specific sessions.</p></li><li><p> Managing and synchronizing state across multiple servers (if needed) introduces additional challenges.</p></li><li><p> If a server holding a user's state fails, their session data might be lost.</p></li></ul><ul><li><p><strong>E-commerce Shopping Carts</strong> – Stores cart contents and user preferences across multiple interactions, even if the user navigates away and returns.</p></li><li><p><strong>Video Streaming Services (Netflix, YouTube)</strong> – Remembers user watch progress, recommendations, and session data for a seamless experience.</p></li><li><p><strong>Messaging Apps (WhatsApp, Slack)</strong> – Maintains active user sessions and message history for real-time communication.</p></li></ul><p>In a  architecture, the server does  preserve client-specific data between individual requests.</p><ul><li><p>Each request is treated as , with no memory of previous interactions.</p></li><li><p>Every request must include <strong>all necessary information</strong> for processing.</p></li><li><p>Once the server responds, it <strong>discards any temporary data</strong> used for that request.</p></li></ul><blockquote><p>: Most  follow a stateless design. For instance, when you request weather data from a public API, you must provide all required details (e.g., location) in each request. The server processes it, sends a response, and forgets the interaction.</p></blockquote><h2>Common Patterns in Stateless Architecture</h2><h3>1. Token-Based Authentication (JWT)</h3><p>A very popular way to implement statelessness is through tokens, particularly  (JSON Web Tokens):</p><ol><li><p><strong>Client Authenticates Once</strong>: The user logs in using credentials (username/password) for the first time, and the server issues a signed .</p></li><li><p>: The client includes JWT token in each request (e.g., <code>Authorization: Bearer &lt;token&gt;</code> header).</p></li><li><p>: The server validates the token’s signature and any embedded claims (e.g., user ID, expiry time).</p></li><li><p>: The server does  need to store session data; it just verifies the token on each request.</p></li></ol><blockquote><p>Many APIs, including OAuth-based authentication systems, use JWTs to enable stateless, scalable authentication.</p></blockquote><p>Stateless architectures benefit from , ensuring that repeated requests produce the same result. This prevents inconsistencies due to network retries or client errors.</p><p> A  request with the same payload  updates the user’s data but doesn’t create duplicates.</p><blockquote><p>Idempotent APIsensures consistency and reliability, especially in distributed systems where requests might be retried automatically.</p></blockquote><ul><li><p> Stateless systems are inherently easier to scale horizontally. New servers can be added effortlessly, as they don't need to maintain any specific user sessions.</p></li><li><p> Since servers don't track state, the architecture is generally simpler and easier to manage.</p></li><li><p> The failure of a single server won't disrupt user sessions, as data isn't tied to specific servers.</p></li><li><p>With no session data stored on the server, you free up memory that would otherwise be reserved for session management.</p></li><li><p><strong>Easier to Cache Responses: </strong>Since requests are self-contained, caching layers (like CDNs) can more easily store and serve responses.</p></li></ul><ul><li><p> Stateless systems can't provide the same level of personalization or context awareness as stateful systems without additional effort (like using cookies or tokens).</p></li><li><p>The client must keep track of the authentication token or relevant data. If it loses the token, it must re-authenticate.</p></li><li><p> Every request needs to carry all the required information, potentially leading to larger payloads.</p></li></ul><ol><li><p><strong>Microservices Architecture: </strong>Each service handles requests independently, relying on external databases or caches instead of maintaining session data.</p></li><li><p><strong>Public APIs (REST, GraphQL): </strong>Clients send tokens with each request, eliminating the need for server-side sessions.</p></li><li><p>Tokens are securely stored on the device and sent with every request to authenticate users.</p></li><li><p>Stateless endpoints make caching easier since responses depend only on request parameters, not stored session data. A CDNcan cache and serve repeated requests, improving performance and reducing backend load.</p></li></ol><p>There's no one-size-fits-all answer when choosing between stateful and stateless architectures.</p><p>The best choice depends on your application’s needs, scalability goals, and user experience expectations.</p><h3><strong>When to Choose Stateful Architecture</strong></h3><p>Stateful systems are ideal when <strong>user context and continuity</strong> are critical. </p><p>Consider a stateful approach if your application:</p><ul><li><p>Requires personalization (e.g., user preferences, session history)</p></li><li><p>Needs real-time interactions (e.g., chat applications, multiplayer gaming)</p></li><li><p>Manages multi-step workflows (e.g., online banking transactions, checkout processes)</p></li><li><p>Must retain authentication sessions for security and convenience</p></li></ul><blockquote><p> A shopping cart in an e-commerce app should persist, so users don’t have to re-add items after refreshing the page.</p></blockquote><h3><strong>When to Choose Stateless Architecture</strong></h3><p>Stateless systems work best when <strong>scalability, simplicity, and resilience</strong> are top priorities. </p><p>Use a stateless approach if your application:</p><ul><li><p>Handles a high volume of requests and needs to scale efficiently</p></li><li><p>Doesn’t require storing client-specific data between requests</p></li><li><p>Needs fast, distributed processing without server dependencies</p></li><li><p>Must ensure reliability and failover readiness</p></li></ul><blockquote><p> A weather API doesn’t need to remember previous requests. Each query includes the location, and the response is processed independently.</p></blockquote><h3><strong>Hybrid Approaches: The Best of Both Worlds</strong></h3><p>Many modern applications  stateful and stateless components for flexibility.</p><p>This hybrid approach allows:</p><ul><li><p>Stateless APIs for core functionality, ensuring high scalability</p></li><li><p>Stateful sessions for personalization, improving user experience</p></li><li><p>External session stores (e.g., Redis) to manage state while keeping app servers stateless</p></li></ul><blockquote><p> A video streaming platform (e.g., Netflix) uses a stateless backend for streaming but retains stateful user sessions to track watch history and recommendations.</p></blockquote><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><p>If you have any questions or suggestions, leave a comment.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQ1NjU1MjUyLCJpYXQiOjE3MjE1MjE3MzEsImV4cCI6MTcyNDExMzczMSwiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.2cNY811YEugd5iH9XJQhakBzyahGqF7PcATBlFj5J2w&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re enjoying this newsletter and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":8861,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/7e4801c3-e3aa-4ab6-8fe6-759af4a1f91a_1684x1196.png","enclosureMime":"","commentsUrl":null},{"title":"Django Weblog: DSF member of the month - Lily Foote","url":"https://www.djangoproject.com/weblog/2025/feb/10/dsf-member-of-the-month-lily-foote/","date":1739249491,"author":"","guid":324,"unread":true,"content":"<p>For February 2025, we welcome Lily Foote (<a href=\"https://fosstodon.org/@lilyf\">@lilyf</a>) as our DSF member of the month! ⭐</p><p>Lily Foote is a contributor to Django core for many years, especially on the ORM. She is currently a member of the Django 6.x <a href=\"https://docs.djangoproject.com/en/dev/internals/organization/#steering-council\">Steering Council</a> and she has been a DSF member since March 2021. \nYou can learn more about Lily by visiting <a href=\"https://github.com/LilyFoote\">her GitHub profile</a>.</p><p>Let’s spend some time getting to know Lily better!</p><h4>Can you tell us a little about yourself (hobbies, education, etc)</h4><p>My name is Lily Foote and I’ve been contributing to Django for most of my career. I’ve also recently got into Rust and I’m excited about using Rust in Python projects. When I’m not programming, I love hiking, climbing and dancing (Ceilidh)! I also really enjoying playing board games and role playing games (e.g. Dungeons and Dragons).</p><h4>How did you start using Django?</h4><p>I’d taught myself Python in my final year at university by doing <a href=\"https://projecteuler.net/\">Project Euler</a> problems and then decided I wanted to learn how to make a website. Django was the first Python web framework I looked at and it worked really well for me.</p><h4>What other framework do you know and if there is anything you would like to have in Django if you had magical powers?</h4><p>I’ve done a small amount with Flask and FastAPI. More than any new features, I think the thing that I’d most like to see is more long-term contributors to spread the work of keeping Django awesome.</p><h4>What projects are you working on now?</h4><p>The side project I’m most excited about is <a href=\"https://github.com/LilyFoote/django-rusty-templates\">Django Rusty Templates</a>, which is a re-implementation of Django’s templating language in Rust.</p><h4>Which Django libraries are your favorite (core or 3rd party)?</h4><h4>What are the top three things in Django that you like?</h4><p>Django Conferences, the mentorship program Djangonaut Space and the whole community!</p><h4>You have been a mentor multiple times with GSoC and Djangonaut Space program, what is required according to you to be a good mentor?</h4><p>I think being willing to invest time is really important. Checking in with your mentees frequently and being an early reviewer of their work. I think this helps keep their motivation up and allows for small corrections early on.</p><h4>Any advice for future contributors?</h4><p>Start small and as you get more familiar with Django and the process of contributing you can take on bigger issues. Also be patient with reviewers – Django has high standards, but is mostly maintained by volunteers with limited time.</p><p>Yes! It’s a huge honour! Since January, we’ve been meeting weekly and it feels like we’ve hardly scratched the surface of what we want to achieve. The biggest thing we’re trying to tackle is how to improve the contribution experience – especially evaluating new feature ideas – without draining everyone’s time and energy.</p><h4>You have a lot of knowledge in the Django ORM, how did you start to contribute to this part?</h4><p>I added the Greatest and Least expressions in Django 1.9, with the support of one of the core team at the time. After that, I kept showing up (especially at conference sprints) and finding a new thing to tackle.</p><h4>Is there anything else you’d like to say?</h4><p><strong>Thank you for doing the interview, Lily!</strong></p>","contentLength":3110,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quansight Labs Blog: PEP 517 build system popularity","url":"https://labs.quansight.org/blog/pep-517-build-system-popularity","date":1739232000,"author":"","guid":322,"unread":true,"content":"<article>Analysis of PEP 517 build backends used in 8000 top PyPI packages</article>","contentLength":65,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Seth Michael Larson: Building software for connection (#2: Consensus)","url":"https://sethmlarson.dev/building-software-for-connection-consensus?utm_campaign=rss","date":1739232000,"author":"","guid":323,"unread":true,"content":"<p>In the <a href=\"http://sethmlarson.dev/building-software-for-connection-local-first\">previous article</a> we concluded that a persistent always-on internet\nconnection isn't required for software to elicit feelings of connection between humans.</p><div><div><p>Building on this conclusion: let's explore how Animal Crossing software was able to intercommunicate without requiring\na centralized server and infrastructure and the trade-offs for these design decisions.</p></div></div><h2>Distributing digital goods without the internet</h2><p>Animal Crossing has over 1,000 unique items that need to be collected\nfor a complete <a href=\"https://nookipedia.com/wiki/Catalog\">catalog</a>, including furniture, wallpapers, clothing, parasols, and carpets.\nMany of these items are quite rare or were only programmed to be accessible\nthrough an official Nintendo-affiliated distribution such as a magazine or online contest.</p><p>Beyond official distributions, it's clear Animal Crossings' designer, Katsuya Eguchi,\nwanted players to  to complete their catalogs.\nThe game incentivized trading items between towns by assigning\none “<a href=\"https://nookipedia.com/wiki/Fruit\">native fruit</a>” (Apple, Orange, Cherry, Peach, or Pear) and\nrandomly making a subset of items harder to find than others depending\non a <a href=\"https://nookipedia.com/wiki/Group\">hidden “item group” variable</a> (either A, B, or C).</p><p>Items could be exchanged between players when one player visits another town,\nbut this required physically bringing your memory card to another\nplayers' GameCube. The GameCube might have come with a handle, but the 'cube wasn't exactly a . Sharing a physical space isn't something you can do with everyone or on a regular basis.</p><div><div><p>So what did Katsuya Eguchi design for Animal Crossing? To allow for item distributions from magazines and contests and to make player-to-player item sharing easier Animal Crossing included a feature called “<a href=\"https://nookipedia.com/wiki/Secret_code\">secret codes</a>”.</p><p>This feature worked by allowing players to exchange 28-character codes with Tom Nook for items. Players could also generate codes for their friends to “send” an item from their own game to a different town. Codes could be shared by writing them on a paper note, instant message, or text message.</p></div></div><h2>The forgotten durability of offline software</h2><div><div><p>\nThis <a href=\"https://www.reddit.com/r/Gamecube/comments/1gqfbae\">Reddit comment thread</a> from the GameCube subreddit was the initial inspiration for this entire series.\nThe post is about someone's niece who just started playing Animal Crossing for the first time.\nThe Redditor asked folks to send items to their nieces' town using the secret code system.\n</p><p>This ended up surprising many folks that this system \n in a game that was over 23 years old!\nFor reference, Nintendo Wi-Fi Connection and Nintendo Network were only available for 8 and 13 years respectively.\nBelow are a handful of the comments from the thread:</p><blockquote><ul><li>“For real does this still work lol?”</li></ul></blockquote></div></div><p>It's hard not to take these comments as indicators that something is\n with internet-connected software today. What had to go wrong for a \nsystem continuing to work to ? Many consumers' \nexperience with \nsoftware products\ntoday is that they become useless e-waste after some far-away service is \ndiscontinued a few years after purchase.</p><p>My intuition from this is that software that <em>requires centralized servers and infrastructure to function</em>\nwill have shorter lifetimes than software which is offline or only\nopportunistically uses online functionality.</p><p>I don't think this is particularly insightful,\nmore dependencies always means less resilience. But if we're building software for human connection then the software\nshould optimally only be limited by the <em>availability of humans to connect</em>.</p><h2>What is centralization good for?</h2><div><div><p>Animal Crossings' secret code system is far from perfect. The system is easily abusable, as the same secret codes can be\nreused over-and-over by the same user to duplicate items without ever expiring. The only limit was that 3 codes could be used per day.</p></div></div><p>Not long after Animal Crossing's release\nthe secret code algorithm was <a href=\"https://togenyanweb.appspot.com/Yokai/eplus/eplus.html\">reverse-engineered</a> so secret codes \nfor any item could be created for any town and recipient name as if they came from an official Nintendo distribution.\nThis was possible because the secret code system relied on \"<a href=\"https://en.wikipedia.org/wiki/Security_through_obscurity\">security through obscurity</a>\".</p><p>Could  be the answer to preventing these abuses?</p><p>The most interesting property that a centralized authority approach\nprovides is : forcing everyone to play by the same rules. By storing\nthe “single source-of-truth” a central authority is able to prevent abuses\nlike the ones mentioned above.</p><p>For example, a centralized “secret code issuing server” could generate\nnew unique codes per-use and check each code's validity\nagainst a database to prevent users from generating their\nown illegitimate codes or codes being re-used multiple times.</p><p>The problem with\ncentralized consensus is it tends to be  to cover the entire software state.\nA centralized server can generate codes perfectly, but how can that same server\n that the items you're exchanging for codes were obtained legitimately? To know this\nthe server would <em>also need to track item legitimacy</em>, leading to software which requires\nan internet connection to operate.</p><p>This is optimal from a correctness perspective, but as was noted earlier,\nI suspect that if such a server was a mandatory part of the secret code system\nin Animal Crossing that the system <em>would likely not be usable today</em>.</p><p>This seems like a trade-off, <em>which future would you rather have?</em></p><h2>Redesigning Animal Crossing secret codes</h2><p>If I were designing Animal Crossings' secret code system with modern hardware, what would it look like?\nHow can we keep the offline fall-back while providing consensus and being less\nabusable, especially for official distributions.</p><p>I would likely use a <a href=\"https://en.wikipedia.org/wiki/Public-key_cryptography\">public-key cryptographic</a> system for official distributions,\nembedding a certificate that could be used to “verify” that specific secret codes\noriginated from the expected centralized entity. Codes that are accepted would be\nrecorded to prevent reusing the same code multiple times in the same town.\nUsing public-key cryptography prevents the\nsystem from being reverse-engineered to distribute arbitrary items until the certificate\nprivate key was cracked.</p><p>For sharing items between players I would implement a system where each town\ngenerated a public and private key and the public key was shared to other towns\nwhenever the software was able to, such as when a player visited the other town.\nPlayers would only be able to send items to players that they have visited\n(which for Animal Crossing <em>required physical presence</em>, more on this later!)</p><p>Each sender could store a <a href=\"https://en.wikipedia.org/wiki/Cryptographic_nonce\">nonce</a> value for\neach potential recipient. Embedding that nonce into the secret code would allow\nthe recipients' software to verify that the specific code hadn't been used yet.\nThe nonce wouldn't have to be long to avoid simple reusing of codes.</p><p>Both above systems would require much more data to be embedded into each “secret\ncode” compared to the 28-character codes from the GameCube. For this I would\nuse QR codes to embed over 2KB of data into a single QR code. Funnily enough,\nAnimal Crossing New Leaf and onwards <a href=\"https://nookipedia.com/wiki/QR_code\">use QR code technology</a> for players to share design patterns.</p><p>This design is still abusable if users can modify their software or hardware\nbut doesn't suffer from the trivial-to-exploit flaws of Animal Crossing's secret code system.</p><h2>Decentralized global consensus?</h2><div><div><p>What if we could have the best of both worlds: we want consensus\nthat is both  and . At least today, we are out of luck.</p><p>Decentralized global consensus is <a href=\"https://bitcoin.org/bitcoin.pdf\">technologically feasible</a>, but the existing solutions\n(mostly blockchains)\nare expensive (both in energy and capital) and can't handle throughput on any sort of \nmeaningful scale.</p></div></div><p>There are many other decentralized consensus systems that \nare able to form “pockets” of <em>useful peer-to-peer consensus</em> using a fraction of\nthe resources, such as email, <a href=\"https://en.wikipedia.org/wiki/BitTorrent\">BitTorrent</a>, <a href=\"https://activitypub.rocks/\">ActivityPub</a>, and <a href=\"https://nostr.com/\">Nostr</a>.\nThese systems are only possible by adding  or by only guaranteeing .</p><h2>When is global consensus needed?</h2><p>Obviously global consensus is important for certain classes of software like \nfinancial, civics, and infrastructure, but I wonder how the necessity\nof consensus in software changes for software with different risk\nprofiles.</p><p>For software which has fewer risks associated with misuse is there as much\nneed for global consensus?\nHow can  be designed to reduce risk and require\nless consensus to be effective? If global consensus and centralized \nservers become unnecessary, can we expect  to be usable \non much longer timescales, <em>essentially for as long as there are users?</em></p>","contentLength":8378,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python Morsels: Newlines and escape sequences in Python","url":"https://www.pythonmorsels.com/newlines-and-escape-sequences/","date":1739200649,"author":"","guid":321,"unread":true,"content":"<p>This string contains a newline character:</p><div><pre><code></code></pre></div><p>That's what  represents: a newline character.</p><p>If we print this string, we'll see that  becomes an  newline:</p><p>Why does Python represent a newline as ?</p><h2>Escape sequences in Python</h2><p>Every character in a Python …</p>","contentLength":244,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Pairwise Authentication of Humans","url":"https://www.schneier.com/blog/archives/2025/02/pairwise-authentication-of-humans.html","date":1739188841,"author":"Bruce Schneier","guid":171,"unread":true,"content":"<p>Here’s an <a href=\"https://ksze.github.io/PeerAuth/\">easy</a> system for two humans to remotely authenticate to each other, so they can be sure that neither are digital impersonations.</p><blockquote><p>To mitigate that risk, I have developed this simple solution where you can setup a unique time-based one-time passcode (TOTP) between any pair of persons.</p><ol><li>Two people, Person A and Person B, sit in front of the same computer and open this page;\n</li><li>They input their respective names (e.g. Alice and Bob) onto the same page, and click “Generate”;\n</li><li>The page will generate two TOTP QR codes, one for Alice and one for Bob;\n</li><li>Alice and Bob scan the respective QR code into a TOTP mobile app (such as Authy or Google Authenticator) on their respective mobile phones;\n</li><li>In the future, when Alice speaks with Bob over the phone or over video call, and wants to verify the identity of Bob, Alice asks Bob to provide the 6-digit TOTP code from the mobile app. If the code matches what Alice has on her own phone, then Alice has more confidence that she is speaking with the real Bob.</li></ol></blockquote>","contentLength":1006,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TypeScript: extracting parts of composite types via infer","url":"https://2ality.com/2025/02/typescript-infer-operator.html","date":1739145600,"author":"Dr. Axel Rauschmayer","guid":202,"unread":true,"content":"<p>In this blog post, we explore how we can extract parts of composite types via the  operator.</p><p>It helps if you are loosely familiar with conditional types. You can check out section <a href=\"https://exploringjs.com/tackling-ts/ch_computing-with-types-overview.html#conditional-types\">“Conditional types”</a> in “Tackling TypeScript”&nbsp;to read up on them.</p>","contentLength":252,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TypeDoc: testing code examples in doc comments","url":"https://2ality.com/2025/02/testing-typedoc-examples.html","date":1739059200,"author":"Dr. Axel Rauschmayer","guid":201,"unread":true,"content":"<p>TypeDoc now lets us refer to parts of other files via . In this blog post, I explain how that works and why it’s useful.</p>","contentLength":122,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"UK Is Ordering Apple to Break Its Own Encryption","url":"https://www.schneier.com/blog/archives/2025/02/uk-is-ordering-apple-to-break-its-own-encryption.html","date":1739030192,"author":"Bruce Schneier","guid":170,"unread":true,"content":"<p>The  is <a href=\"https://www.washingtonpost.com/technology/2025/02/07/apple-encryption-backdoor-uk/\">reporting</a> that the UK government has served Apple with a “technical capability notice” as defined by the 2016 Investigatory Powers Act, requiring it to break the Advanced Data Protection encryption in iCloud for the benefit of law enforcement.</p><p>This is a big deal, and something we in the security community have worried was coming for a while now.</p><blockquote><p>The law, known by critics as the Snoopers’ Charter, makes it a criminal offense to reveal that the government has even made such a demand. An Apple spokesman declined to comment.</p><p>Apple can appeal the U.K. capability notice to a secret technical panel, which would consider arguments about the expense of the requirement, and to a judge who would weigh whether the request was in proportion to the government’s needs. But the law does not permit Apple to delay complying during an appeal.</p><p>In March, when the company was on notice that such a requirement might be coming, it told Parliament: “There is no reason why the U.K. [government] should have the authority to decide for citizens of the world whether they can avail themselves of the proven security benefits that flow from end-to-end encryption.”</p></blockquote><p>Apple is likely to turn the feature off for UK users rather than break it for everyone worldwide. Of course, UK users will be able to spoof their location. But this might not be enough. According to the law, Apple would not be able to offer the feature to anyone who is in the UK at any point: for example, a visitor from the US.</p><p>And what happens next? Australia has <a href=\"https://www.homeaffairs.gov.au/about-us/our-portfolios/national-security/lawful-access-telecommunications/assistance-and-access-industry-assistance-framework\">a law</a> enabling it to ask for the same thing. Will it? Will even more countries follow?</p>","contentLength":1618,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TypeScript: the satisfies operator","url":"https://2ality.com/2025/02/satisfies-operator.html","date":1738972800,"author":"Dr. Axel Rauschmayer","guid":200,"unread":true,"content":"<p>TypeScript’s  operator lets us check the type of a value (mostly) without influencing it. In this blog post, we examine how exactly it works and where it’s useful.</p>","contentLength":167,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Seeking Purity","url":"http://lucumr.pocoo.org/2025/2/8/seeking-purity","date":1738972800,"author":"Armin Ronacher","guid":346,"unread":true,"content":"<p>The concept of purity — historically a guiding principle in social and\nmoral contexts — is also found in passionate, technical discussions.  By\nthat I mean that purity in technology translates into adherence to a set\nof strict principles, whether it be functional programming, test-driven\ndevelopment, serverless architectures, or, in the case of Rust, memory\nsafety.</p><div><p>Rust positions itself as a champion of memory safety, treating it as a\nnon-negotiable foundation of good software engineering.  I love Rust: it's\nprobably my favorite language.  It probably won't surprise you that I have\nno problem with it upholding memory safety as a defining feature.</p><p>Rust aims to achieve the goal of memory safety via safe abstractions, a\ncompile time borrow checker and a type system that is in service of those\nsafe abstractions.  It comes as no surprise that the Rust community is\nalso pretty active in codifying a new way to <a href=\"https://www.ralfj.de/blog/2020/12/14/provenance.html\">reason about pointers</a>.  In many ways,\nRust pioneered completely new technical approaches and it it widely\nheralded as an amazing innovation.</p><p>However, as with many movements rooted in purity, what starts as a\ntechnical pursuit can evolve into something more ideological.  Similar to\nhow moral purity in political and cultural discourse can become charged,\nso does the discourse around Rust, which has been dominated by the pursuit\nof memory safety.  Particularly within the core Rust community itself,\ndiscussion has moved beyond technical merits into something akin to\nideological warfare.  The fundamental question of “Is this code memory\nsafe?”, has shifted to “Was it made memory safe in the  way?”.\nThis distinction matters because it introduces a purity test that values\nmethodology over outcomes.  Safe C code, for example, is often dismissed\nas impossible, not necessarily because it  impossible, but because it\nlacks the strict guarantees that Rust's borrow checker enforces.\nSimilarly, using Rust’s  blocks is increasingly frowned upon,\ndespite their intended purpose of enabling low-level optimizations when\nnecessary.</p><p>This ideological rigidity creates significant friction when Rust\ninterfaces with other ecosystems (or gets introduced there), particularly\nthose that do not share its uncompromising stance.  For instance, the role\nof Rust in the Linux kernel has been a hot topic.  The Linux kernel\noperates under an entirely different set of priorities.  While memory\nsafety is important there is insufficient support for adopting Rust in\ngeneral.  The kernel is an old project and it aims to remain maintainable\nfor a long time into the future.  For it to even consider a rather young\nprogramming language should be seen as tremendous success for Rust and\nalso for how open Linus is to the idea.</p><p>Yet that introduction is balanced against performance, maintainability,\nand decades of accumulated engineering expertise.  Many of the kernel\ndevelopers, who have found their own strategies to write safe C for\ndecades, are not accepting the strongly implied premise that their work is\ninherently flawed simply because it does not adhere to Rust's strict\npurity rules.</p><p>Tensions rose when a kernel developer advocating for Rust's inclusion took\nto social media to push for changes in the Linux kernel development\nprocess.  The public shaming tactic failed, <a href=\"https://lkml.org/lkml/2025/2/6/1292\">leading the developer to\nconclude</a>:</p><blockquote>\n“If shaming on social media does not work, then tell me what does,\nbecause I'm out of ideas.”</blockquote><p>It's not just the kernel where Rust's memory safety runs up against the\ncomplexities of the real world.  Very similar feelings creep up in the\ngaming industry where people love to do wild stuff with pointers.  You do\nnot need large disagreements to see the purist approach create some\nfriction.  A <a href=\"http://lucumr.pocoo.org/2025/2/4/fat-rand/\">recent post of mine</a> for instance\ntriggered some discussions about the trade-offs between more dependencies,\nand moving unsafe to centralized crates.</p><p>I really appreciate that Rust code does not crash as much.  That part of\nRust, among many others, makes it very enjoyable to work with.  Yet I am\nentirely unconvinced that memory safety should trump everything, at least\nat this point in time.</p><p>What people want in the Rust in Linux situation is for the project leader\nto come in to declare support for Rust's call for memory safety above all.\nTo make the detractors go away.</p></div><div><h2>Python's Migration Lesson</h2><p>Hearing this call and discussion brings back memories.  I have lived\nthrough a purity driven shift in a community before.  The move from Python\n2 to Python 3 started out very much the same way.  There was an almost\nreligious movement in the community to move to Python 3 in a ratcheting\nmotion.  The idea that you <a href=\"http://lucumr.pocoo.org/2013/5/21/porting-to-python-3-redux/\">could maintain code bases that support both 2\nand 3</a> were initially very\nloudly rejected.  I took a lot of flak at the time (and for years after)\nfor advocating for a more pragmatic migration which burned me out a lot.\nThat feedback came both in person and online and it largely pushed me away\nfrom Python for a while.  Not getting behind the Python 3 train was seen\nas sabotaging the entire project.  However, a decade later, I feel\nsomewhat vindicated that it was worth being pragmatic about that\nmigration.</p><p>At the root of that discourse was a idealistic view of how Unicode could\nwork in the language and that you can move an entire ecosystem at once.\nBoth those things greatly clashed with the lived realities in many\nprojects and companies.</p><p>I am a happy user of Python 3 today.  This migration has also taught me\nthe important lesson not be too stuck on a particular idea.  It would have\nbeen very easy to pick one of the two sides of that debate.  Be stuck on\nPython 2 (at the risk of forking), or go all in on Python 3 no questions\nasked.  It was the path in between that was quite painful to advocate for,\nbut it was ultimately the right path.  I wrote about <a href=\"http://lucumr.pocoo.org/2016/11/5/be-careful-about-what-you-dislike/\">my lessons of that\nmigration a in 2016</a> and\nI think most of this still rings true.  That was motivated by even years\nlater people still reaching out to me who did not move to Python 3, hoping\nfor me to embrace their path.  Yet Python 3 has changed!  Python 3 is a\nmuch better language than it was when it first released.  It is a great\nlanguage because it's used by people solving real, messy problems and\nbecause it over time found answers for what to do, if you need to have\nboth Python 2 and 3 code in the wild.  While the world of Python 2 is\nlargely gone, we are still in a world where Unicode and bytes mix in\ncertain contexts.</p></div><div><p>Fully committing to a single worldview can be easier because you stop\nquestioning everything — you can just go with the flow.  Yet truths often\nreside on both sides.  Allowing yourself to walk the careful middle path\nenables you to learn from multiple perspectives.  You will face doubts and\nopen yourself up to vulnerability and uncertainty.  The payoff, however,\nis the ability to question deeply held beliefs and push into the unknown\nterritory where new things can be found.  You can arrive at a solution\nthat isn't a complete rejection of any side.  There is genuine value in\nwhat Rust offers—just as there was real value in what Python 3 set out to\naccomplish.  But the Python 3 of today isn't the Python 3 of those early,\nideological debates; it was shaped by a messy, slow, often contentious,\nyet ultimately productive transition process.</p><p>I am absolutely sure that in 30 years from now we are going to primarily\nprogram in memory safe languages (or the machines will do it for us) in\nenvironments where C and C++ prevail.  That glimpse of a future I can\nvisualize clearly.  The path to there however?  That's a different story\naltogether.  It will be hard, it will be impure.  Maybe the solution will\nnot even involve Rust at all — who knows.</p><p>We also have to accept that not everyone is ready for change at the same\npace. Forcing adoption when people aren't prepared only causes the\npendulum to swing back hard.  It's tempting to look for a single authority\nto declare “the one true way,” but that won't smooth out the inevitable\ncomplications.  Indeed, those messy, incremental challenges are part of how\nreal progress happens.  In the long run, these hard-won refinements tend\nto produce solutions that benefit all sides—if we’re patient enough to let\nthem take root.  The painful and messy transition is here to stay, and\nthat's exactly why, in the end, it works.</p></div>","contentLength":8311,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Friday Squid Blogging: The Colossal Squid","url":"https://www.schneier.com/blog/archives/2025/02/friday-squid-blogging-the-colossal-squid.html","date":1738965757,"author":"Bruce Schneier","guid":169,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The case for sans-io","url":"https://fasterthanli.me/articles/the-case-for-sans-io","date":1738954381,"author":"Amos Wenger","guid":18,"unread":true,"content":"<p data-bo=\"208\">The most popular option to decompress ZIP files from the Rust programming\nlanguage is a crate simply named <a href=\"https://lib.rs/crates/zip\">zip</a> — At the time of this writing, it has 48\nmillion downloads. It’s fully-featured, supporting various compression methods,\nencryption, and even supports writing zip files.</p><p data-bo=\"528\">However, that’s not the crate  uses to read ZIP files. Some\napplications benefit from using asynchronous I/O, especially if they decompress\narchives that they download from the network.</p><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#character-encoding-differences\"></a><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#platform-differences\"></a><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#the-end-of-central-directory-record\"></a><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#boundary-confusion\"></a><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#not-doing-any-i-o-at-all\"></a><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#the-structure-of-rc-zip\"></a><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#bringing-io-uring-into-it\"></a><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#plugging-rc-zip-into-monoio\"></a><a href=\"https://fasterthanli.me/articles/the-case-for-sans-io#closing-words\"></a>","contentLength":471,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Screenshot-Reading Malware","url":"https://www.schneier.com/blog/archives/2025/02/screenshot-reading-malware.html","date":1738941971,"author":"Bruce Schneier","guid":168,"unread":true,"content":"<p>Kaspersky is <a href=\"https://www.engadget.com/cybersecurity/kaspersky-researchers-find-screenshot-reading-malware-on-the-app-store-and-google-play-211011103.html\">reporting</a> on a new type of smartphone malware.</p><blockquote><p>The malware in question uses optical character recognition (OCR) to review a device’s photo library, seeking screenshots of recovery phrases for crypto wallets. Based on their assessment, infected Google Play apps have been downloaded more than 242,000 times. Kaspersky says: “This is the first known case of an app infected with OCR spyware being found in Apple’s official app marketplace.”</p></blockquote><p>That’s a tactic I have not heard of before.</p>","contentLength":503,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"From PDFs to Insights: Structured Outputs from PDFs with Gemini 2.0","url":"https://www.philschmid.de/gemini-pdf-to-data","date":1738886400,"author":"","guid":16,"unread":true,"content":"<article>Learn how to extract structured data from PDFs with Gemini 2.0 and Pydantic.</article>","contentLength":76,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Design a Real-Time Gaming Leaderboard - System Design Interview","url":"https://blog.algomaster.io/p/design-real-time-gaming-leaderboard","date":1738852955,"author":"Ashish Pratap Singh","guid":749,"unread":true,"content":"<p>A  is a ranked list of players, typically sorted by a specific metric such as score, points or level.</p><p> In a  leaderboard, updates happen almost instantly:</p><ol><li><p>A player’s score changes (e.g., after scoring a point or defeating an opponent).</p></li><li><p>The system updates that player’s rank immediately.</p></li><li><p>Other players can see the updated position without waiting or refreshing.</p></li></ol><p>This real-time aspect makes the user experience more dynamic and engaging. </p><p>However, it also introduces significant , such as:</p><ul><li><p>Efficiently retrieving Top-N players (e.g., Top 10 or Top 100).</p></li><li><p>Allowing players to quickly find their own rank without scanning the entire leaderboard.</p></li></ul><p>In this article, we will explore how to design a , , and  that can support above queries and enhance the user experience.</p><p>Before diving into the design, lets clearly define the functional and non-functional requirements of our real-time gaming leaderboard..</p><ul><li><p>: Display top N players (e.g., top 10, top 100) on the leaderboard and update it in real-time.</p></li><li><p>: Allow a player to query their current rank without scanning the entire leaderboard.</p></li><li><p> Provide the ability to retrieve a “slice” of the leaderboard around a specific player (e.g., ranks 45 to 55 if the player is rank 50).</p></li><li><p> Players can view past game scores and historical leaderboards for previous matches.</p></li></ul><h3>Non-Functional Requirements</h3><ul><li><p> Score changes should reflect immediately in the leaderboard.</p></li><li><p>: Leaderboard queries should return the results in milliseconds.</p></li><li><p>: System should support thousands of concurrent players submitting scores and fetching rankings.</p></li></ul><h3>Approach to Designing the System</h3><p>The most challenging aspects of building a real-time leaderboard is . Choosing the right storage system is critical to ensuring that queries can be executed efficiently without performance bottlenecks.</p><p>To simplify the design process, we will follow below approach:</p><ol><li><p>Clearly define the input/output structure of leaderboard queries and updates.</p></li><li><p><strong>Define the High-Level Architecture: </strong>Identify core system components and their interactions.</p></li><li><p>Choose the appropriate storage model optimized for fast leaderboard lookups and real-time updates.</p></li></ol><p>To support real-time leaderboard operations, we define a set of  that allow players to update scores, retrieve rankings, and query nearby ranks efficiently.</p><p>Updates a player's score incrementally</p><p>: <code>POST /leaderboard/score/update</code></p><pre><code><code>{\n  \"playerId\": \"player123\",\n  \"scoreDelta\": 50\n}</code></code></pre><blockquote><p>We will use relative score updates () rather than absolute updates.</p></blockquote><pre><code><code>{\n  \"playerId\": \"player123\",\n  \"updatedScore\": 1000,\n  \"currentRank\": 10\n}</code></code></pre><p>Retrieves the top-N players from the leaderboard, ranked by their scores.</p><p>: <code>GET /leaderboard/top?n=10</code></p><p>:  = number of top players to fetch (default 10, max 100, etc.)</p><pre><code><code>{\n  \"leaderboardId\": \"global\",\n  \"topPlayers\": [\n    { \"playerId\": \"playerA\", \"score\": 1500, \"rank\": 1 },\n    { \"playerId\": \"playerB\", \"score\": 1490, \"rank\": 2 },\n    // ...\n  ]\n}</code></code></pre><p>Allows a player to retrieve their current rank without scanning the entire leaderboard.</p><p>: <code>GET /leaderboard/rank/{playerId}</code></p><pre><code><code>{\n  \"playerId\": \"player123\",\n  \"score\": 1000,\n  \"rank\": 10\n}</code></code></pre><p>Retrieves players ranked around a given player, allowing for comparison with competitors of similar skill levels.</p><p>: <code>GET /leaderboard/nearby/{playerId}?range=5</code></p><p>:  indicates how many ranks above and below to fetch (e.g., 5 above, 5 below).</p><pre><code><code>{\n  \"playerId\": \"player123\",\n  \"startRank\": 45,\n  \"endRank\": 55,\n  \"players\": [\n    { \"playerId\": \"playerX\", \"score\": 1020, \"rank\": 44 },\n    { \"playerId\": \"player123\", \"score\": 1000, \"rank\": 45 },\n    { \"playerId\": \"playerZ\", \"score\": 995,  \"rank\": 46 },\n    // ...\n  ]\n}</code></code></pre><p> If a player is ranked 50th, this API allows them to see players ranked 45-55 for a competitive comparison.</p><h3>2.5 WebSockets for Real-Time Updates</h3><p>While REST APIs are good for on-demand queries, WebSockets or Server-Sent Events (SSEs) can push real-time leaderboard updates to subscribed users.</p><p>Players would subscribe to leaderboard updates, and receive updates instantly without polling.</p>","contentLength":3933,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbc07561-4165-42b9-a375-caaa33a2b6e3_2208x1668.png","enclosureMime":"","commentsUrl":null},{"title":"The DeepSeek Series: A Technical Overview","url":"https://martinfowler.com/articles/deepseek-papers.html","date":1738851420,"author":"Martin Fowler","guid":190,"unread":true,"content":"<p>The appearance of DeepSeek Large-Language Models has caused a lot of\n      discussion and angst since their latest versions appeared at the beginning\n      of 2025. But much of the value of DeepSeek's work comes from the papers\n      they have published over the last year. \n      provides <a href=\"https://martinfowler.com/articles/deepseek-papers.html\">an overview of these papers</a>, highlighting three main arcs in this\n      research: a focus on improving cost and memory efficiency, the use of HPC\n      Co-Design to train large models on limited hardware, and the development\n      of emergent reasoning from large-scale reinforcement learning</p>","contentLength":582,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Read-only accessibility in TypeScript","url":"https://2ality.com/2025/02/typescript-readonly.html","date":1738800000,"author":"Dr. Axel Rauschmayer","guid":199,"unread":true,"content":"<p>In this blog post, we look at how can make things “read-only” in TypeScript – mainly via the keyword .</p>","contentLength":108,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Some terminal frustrations","url":"https://jvns.ca/blog/2025/02/05/some-terminal-frustrations/","date":1738774620,"author":"Julia Evans","guid":10,"unread":true,"content":"<blockquote><p>What’s the most frustrating thing about using the terminal for you?</p></blockquote><p>1600 people answered, and I decided to spend a few days categorizing all the\nresponses. Along the way I learned that classifying qualitative data is not\neasy but I gave it my best shot. I ended up building a custom\n<a href=\"https://github.com/jvns/classificator\">tool</a> to make it faster to categorize\neverything.</p><p>As with all of my surveys the methodology isn’t particularly scientific. I just\nposted the survey to Mastodon and Twitter, ran it for a couple of days, and got\nanswers from whoever happened to see it and felt like responding.</p><p>Here are the top categories of frustrations!</p><p>I think it’s worth keeping in mind while reading these comments that</p><ul><li>40% of people answering this survey have been using the terminal for </li><li>95% of people answering the survey have been using the terminal for at least 4 years</li></ul><p>These comments aren’t coming from total beginners.</p><p>Here are the categories of frustrations! The number in brackets is the number\nof people with that frustration. I’m mostly writing this up for myself because\nI’m trying to write a zine about the terminal and I wanted to get a sense for\nwhat people are having trouble with.</p><p>People talked about struggles remembering:</p><ul><li>the syntax for CLI tools like awk, jq, sed, etc</li><li>keyboard shortcuts for tmux, text editing, etc</li></ul><blockquote><p>There are just so many little “trivia” details to remember for full\nfunctionality. Even after all these years I’ll sometimes forget where it’s 2\nor 1 for stderr, or forget which is which for  and .</p></blockquote><h3>switching terminals is hard (91)</h3><p>People talked about struggling with switching systems (for example home/work\ncomputer or when SSHing) and running into:</p><ul><li>OS differences in keyboard shortcuts (like Linux vs Mac)</li><li>systems which don’t have their preferred text editor (“no vim” or “only vim”)</li><li>different versions of the same command (like Mac OS grep vs GNU grep)</li><li>a shell they aren’t used to (“the subtle differences between zsh and bash”)</li></ul><p>as well as differences inside the same system like pagers being not consistent\nwith each other (git diff pagers, other pagers).</p><blockquote><p>I got used to fish and vi mode which are not available when I ssh into\nservers, containers.</p></blockquote><p>Lots of problems with color, like:</p><ul><li>programs setting colors that are unreadable with a light background color</li><li>finding a colorscheme they like (and getting it to work consistently across different apps)</li><li>color not working inside several layers of SSH/tmux/etc</li><li>not wanting color at all and struggling to turn it off</li></ul><p>This comment felt relatable to me:</p><blockquote><p>Getting my terminal theme configured in a reasonable way between the terminal\nemulator and fish (I did this years ago and remember it being tedious and\nfiddly and now feel like I’m locked into my current theme because it works\nand I dread touching any of that configuration ever again).</p></blockquote><p>Half of the comments on keyboard shortcuts were about how on Linux/Windows, the\nkeyboard shortcut to copy/paste in the terminal is different from in the rest\nof the OS.</p><p>Some other issues with keyboard shortcuts other than copy/paste:</p><ul><li>using  in a browser-based terminal and closing the window</li><li>the terminal only supports a limited set of keyboard shortcuts (no\n, no , no , lots of  shortcuts aren’t\npossible like )</li><li>the OS stopping you from using a terminal keyboard shortcut (like by default\nMac OS uses  for something else)</li><li>issues using emacs in the terminal</li><li>backspace not working (2)</li></ul><h3>other copy and paste issues (75)</h3><p>Aside from “the keyboard shortcut for copy and paste is different”, there were\na lot of OTHER issues with copy and paste, like:</p><ul><li>how tmux and the terminal emulator both do copy/paste in different ways</li><li>dealing with many different clipboards (system clipboard, vim clipboard, the\n“middle click” clipboard on Linux, tmux’s clipboard, etc) and potentially\nsynchronizing them</li><li>random spaces added when copying from the terminal</li><li>pasting multiline commands which automatically get run in a terrifying way</li><li>wanting a way to copy text without using the mouse</li></ul><p>There were lots of comments about this, which all came down to the same basic\ncomplaint – it’s hard to discover useful tools or features! This comment kind of\nsummed it all up:</p><blockquote><p>How difficult it is to learn independently. Most of what I know is an\nassorted collection of stuff I’ve been told by random people over the years.</p></blockquote><h3>steep learning curve (44)</h3><p>A lot of comments about it generally having a steep learning curve. A couple of\nexample comments:</p><blockquote><p>After 15 years of using it, I’m not much faster than using it than I was 5 or\nmaybe even 10 years ago.</p></blockquote><blockquote><p>That I know I could make my life easier by learning more about the shortcuts\nand commands and configuring the terminal but I don’t spend the time because it\nfeels overwhelming.</p></blockquote><p>Some issues with shell history:</p><ul><li>history not being shared between terminal tabs (16)</li><li>limits that are too short (4)</li><li>history not being restored when terminal tabs are restored</li><li>losing history because the terminal crashed</li><li>not knowing how to search history</li></ul><blockquote><p>It wasted a lot of time until I figured it out and still annoys me that\n“history” on zsh has such a small buffer;  I have to type “history 0” to get\nany useful length of history.</p></blockquote><ul><li>documentation being generally opaque</li><li>lack of examples in man pages</li><li>programs which don’t have man pages</li></ul><p>Here’s a representative comment:</p><blockquote><p>Finding good examples and docs. Man pages often not enough, have to wade\nthrough stack overflow</p></blockquote><p>A few issues with scrollback:</p><ul><li>programs printing out too much data making you lose scrollback history</li><li>resizing the terminal messes up the scrollback</li><li>GUI programs that you start in the background printing stuff out that gets in\nthe way of other programs’ outputs</li></ul><blockquote><p>When resizing the terminal (in particular: making it narrower) leads to\nbroken rewrapping of the scrollback content because the commands formatted\ntheir output based on the terminal window width.</p></blockquote><p>Lots of comments about how the terminal feels hampered by legacy decisions and\nhow users often end up needing to learn implementation details that feel very\nesoteric. One example comment:</p><blockquote><p>Most of the legacy cruft, it would be great to have a green field\nimplementation of the CLI interface.</p></blockquote><p>Lots of complaints about POSIX shell scripting. There’s a general feeling that\nshell scripting is difficult but also that switching to a different less\nstandard scripting language (fish, nushell, etc) brings its own problems.</p><blockquote><p>Shell scripting. My tolerance to ditch a shell script and go to a scripting\nlanguage is pretty low. It’s just too messy and powerful. Screwing up can be\ncostly so I don’t even bother.</p></blockquote><p>Some more issues that were mentioned at least 10 times:</p><ul><li>(31) inconsistent command line arguments: is it -h or help or –help?</li><li>(24) keeping dotfiles in sync across different systems</li><li>(23) performance (e.g. “my shell takes too long to start”)</li><li>(20) window management (potentially with some combination of tmux tabs, terminal tabs, and multiple terminal windows. Where did that shell session go?)</li><li>(17) generally feeling scared/uneasy (“The debilitating fear that I’m going\nto do some mysterious Bad Thing with a command and I will have absolutely no\nidea how to fix or undo it or even really figure out what happened”)</li><li>(16) terminfo issues (“Having to learn about terminfo if/when I try a new terminal emulator and ssh elsewhere.”)</li><li>(16) lack of image support (sixel etc)</li><li>(15) SSH issues (like having to start over when you lose the SSH connection)</li><li>(15) various tmux/screen issues (for example lack of integration between tmux and the terminal emulator)</li><li>(13) the terminal getting messed up for various reasons (pressing , ing a binary, etc)</li><li>(12) quoting/escaping in the shell</li><li>(11) various Windows/PowerShell issues</li></ul><p>There were also 122 answers to the effect of “nothing really” or “only that I\ncan’t do EVERYTHING in the terminal”</p><blockquote><p>Think I’ve found work arounds for most/all frustrations</p></blockquote><p>I’m not going to make a lot of commentary on these results, but here are a\ncouple of categories that feel related to me:</p><ul><li>remembering syntax &amp; history (often the thing you need to remember is something you’ve run before!)</li><li>discoverability &amp; the learning curve (the lack of discoverability is definitely a big part of what makes it hard to learn)</li><li>“switching systems is hard” &amp; “it feels outdated” (tools that haven’t really\nchanged in 30 or 40 years have many problems but they do tend to be always\n no matter what system you’re on, which is very useful and makes them\nhard to stop using)</li></ul><p>Trying to categorize all these results in a reasonable way really gave me an\nappreciation for social science researchers’ skills.</p>","contentLength":8518,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GenAI Patterns: RAG Limitations and Hybrid Retriever","url":"https://martinfowler.com/articles/gen-ai-patterns/#RagInPractice","date":1738767780,"author":"Martin Fowler","guid":189,"unread":true,"content":"<p>Today  and I outline four\n      limitations to the simple RAG from yesterday, and the pattern that\n      addresses the first of these: Hybrid Retriever. This tackles the\n      inefficiencies of embeddings-based search by combining it with other\n      search techniques.</p>","contentLength":269,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Risky Business #778 -- Musk's child soldiers seize control of FedGov IT systems","url":"https://risky.biz/RB778/","date":1738725890,"author":"","guid":783,"unread":true,"content":"<article></article>","contentLength":0,"flags":null,"enclosureUrl":"https://dts.podtrac.com/redirect.mp3/media3.risky.biz/RB778.mp3","enclosureMime":"","commentsUrl":null},{"title":"Panel at goto Copenhagen: \"Where is SW development Going","url":"https://www.youtube.com/watch?v=86-Dy5U2p5Y","date":1738682580,"author":"Martin Fowler","guid":188,"unread":true,"content":"<p> was on a panel at goto Copenhagen last September with Holly Cummings,\n      Trisha Gee, Dave Farley, and Daniel Terhorst-North. We discussed the\n      current state of software development and where it was heading. Given the\n      timing, there was much discussion about the role AI would play in our\n      profession's future.</p>","contentLength":328,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GenAI Patterns: Retrieval Augmented Generation (RAG)","url":"https://martinfowler.com/articles/gen-ai-patterns/#rag","date":1738681020,"author":"Martin Fowler","guid":187,"unread":true,"content":"<p>A pre-trained GenAI model lacks recent and specific information about a\n      domain.  and I explain how Retrieval\n      Augmented Generation (RAG) can fill that gap.</p>","contentLength":166,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What are ACID Transactions in Databases?","url":"https://blog.algomaster.io/p/what-are-acid-transactions-in-databases","date":1738647067,"author":"Ashish Pratap Singh","guid":748,"unread":true,"content":"<p>Imagine you’re running an e-commerce application. </p><p>A customer places an order, and your system needs to deduct the item from inventory, charge the customer’s credit card, and record the sale in your accounting system—all at once. </p><p>What happens if the payment fails but your inventory count has already been reduced? Or if your application crashes halfway through the process?</p><p>This is where  come into play. They ensure that all the steps in such critical operations happen reliably and consistently.</p><p>ACID is an acronym that refers to the set of 4 key properties that define a transaction: <strong>Atomicity, Consistency, Isolation,</strong> and </p><p>In this article, we’ll dive into what each of the ACID properties mean, why they are important, and how they are implemented in databases.</p><p>If you’re finding this newsletter valuable and want to deepen your learning, consider becoming a .</p><p>As a paid subscriber, you'll receive an <strong>exclusive deep-dive article</strong> every week, access to a structured100+topics and interview questions, and other .</p><p>A  in the context of databases is a sequence of one or more operations (such as inserting, updating, or deleting records) that the database treats as . It either fully succeeds or fully fails, with no in-between states.</p><p>When you send money to a friend, two things happen:</p><ol><li><p>Money is deducted from your account.</p></li><li><p>Money is added to their account.</p></li></ol><p>These two steps form . If either step fails, both are canceled.</p><p>Without transactions, databases could end up in inconsistent states. </p><ul><li><p>: Your money is deducted, but your friend never receives it.</p></li><li><p>: Two people booking the last movie ticket at the same time.</p></li></ul><p>Transactions solve these problems by enforcing rules like  (Atomicity, Consistency, Isolation, Durability).</p><p>Now, lets looks at each of the ACID properties.</p><p>Atomicity ensures that a transaction—comprising multiple operations—executes as a unit of work: it either  succeeds (commits) or  fails (rolls back). </p><p>If any part of the transaction fails, the entire transaction is rolled back, and the database is restored to a state exactly as it was before the transaction began.</p><blockquote><p>In a money transfer transaction, if the credit step fails, the debit step cannot be allowed to stand on its own. This prevents inconsistent states like “money disappearing” from one account without showing up in another.</p></blockquote><p>Atomicity abstracts away the complexity of manually undoing changes if something goes wrong.</p><h2>How Databases Implement Atomicity</h2><p>Databases use two key mechanisms to guarantee atomicity.</p><h4><strong>1. Transaction Logs (Write-Ahead Logs)</strong></h4><ul><li><p>Every operation is recorded in a  before it’s applied to the actual database table.</p></li><li><p>If a failure occurs, the database uses this log to  incomplete changes.</p></li></ul><p>Once the WAL entry is safely on disk, the database proceeds with modifying the in-memory pages that contain rows for  and .</p><p>When the operations succeed:</p><ol><li><p>The database marks  as  in the transaction log.</p></li><li><p>The newly updated balances for A and B will eventually get flushed from memory to their respective data files on disk.</p></li></ol><p>If the database crashes  the log entry is written but  the data files are fully updated, the WAL provides a way to recover:</p><ul><li><p>On restart, the database checks the WAL.</p></li><li><p>It sees  was committed.</p></li><li><p>It reapplies the  operations to ensure the final balances are correct in the data files.</p></li></ul><p>If the transaction had not committed (or was marked as “in progress”) at the time of the crash, the database would  those changes using information in the log, leaving the table as if the transaction never happened.</p><h4><strong>2. Commit/Rollback Protocols</strong></h4><ul><li><p>Databases provide commands like , , and </p></li><li><p>Any changes made between  and  are considered “in-progress” and won’t be permanently applied unless the transaction commits successfully.</p></li><li><p>If any step fails, or if you explicitly issue a , all changes since the start of the transaction are undone.</p></li></ul><p> in the context of ACID transactions ensures that any transaction will bring the database from one valid state to another valid state—never leaving it in a broken or “invalid” state.</p><p>It means that all the data integrity constraints, such as  (no duplicate IDs),  (related records must exist in parent tables), and (age can’t be negative), are satisfied before and after the transaction.</p><p>If a transaction tries to violate these rules, it will not be committed, and the database will revert to its previous state.</p><p>You have two tables in an e-commerce database:</p><ol><li><p> (with columns: , , etc.)</p></li><li><p> (with columns: , , , etc.)</p></li></ol><ul><li><p>: You can’t place an order for a product if  is greater than the  in the  table.</p></li></ul><ul><li><p>If the product’s  was 8 (less than what we’re trying to order), the database sees that the new value would be  which breaks the consistency rule (it should not go negative).</p></li><li><p>The transaction fails or triggers a rollback, preventing the database from ending in an invalid state.</p></li></ul><h2>How to Implement Consistency</h2><ol><li><p><strong>Database Schema Constraints</strong></p><ul><li><p>, , , ,  constraints, and other schema definitions ensure no invalid entries are allowed.</p></li></ul></li><li><p><strong>Triggers and Stored Procedures</strong></p><ul><li><p>Triggers can automatically check additional rules whenever rows are inserted, updated, or deleted.</p></li><li><p>Stored procedures can contain logic to validate data before committing.</p></li></ul></li><li><p><strong>Application-Level Safeguards</strong></p><ul><li><p>While the database enforces constraints at a lower level, applications often add extra checks—like ensuring business rules are followed or data is validated before it even reaches the database layer.</p></li></ul></li></ol><p> ensures that concurrently running transactions do not interfere with each other’s intermediate states.</p><p>Essentially, while a transaction is in progress, its updates (or intermediate data) remain invisible to other ongoing transactions—giving the illusion that each transaction is running sequentially, one at a time.</p><p>Without isolation, two or more transactions could read and write partial or uncommitted data from each other, causing incorrect or inconsistent results.</p><p>With isolation, developers can reason more reliably about how data changes will appear to other transactions.</p><p>To understand how isolation works, it helps to see what can go wrong without proper isolation.  Common concurrency anomalies include:</p><ol><li><ul><li><p>Transaction A reads data that Transaction B has modified but not yet committed.</p></li><li><p>If Transaction B then rolls back, Transaction A ends up holding an invalid or “dirty” value that never truly existed in the committed state.</p></li></ul></li><li><ul><li><p>Transaction A reads the same row(s) multiple times during its execution but sees different data because another transaction updated or deleted those rows in between A’s reads.</p></li></ul></li><li><ul><li><p>Transaction A performs a query that returns a set of rows. Another transaction inserts, updates, or deletes rows that match A’s query conditions.</p></li><li><p>If A re-runs the same query, it sees a different set of rows (“phantoms”).</p></li></ul></li></ol><p>Databases typically allow you to choose an , which balances data correctness with performance.</p><p>Higher isolation levels provide stronger data consistency but can reduce system performance by increasing the wait times for transactions. </p><p>Let's explore the four common isolation levels:</p><ol><li><ul><li><p>Allows dirty reads; transactions can see uncommitted changes.</p></li><li><p>Rarely used, as it can lead to severe anomalies.</p></li></ul></li><li><ul><li><p>A transaction sees only data that has been committed at the moment of reading.</p></li><li><p>Prevents dirty reads, but non-repeatable reads and phantom reads can still occur.</p></li></ul></li><li><ul><li><p>Ensures if you read the same rows multiple times within a transaction, you’ll get the same values (unless you explicitly modify them).</p></li><li><p>Prevents dirty reads and non-repeatable reads, but phantom reads may still happen (depending on the database engine).</p></li></ul></li><li><ul><li><p>The highest level of isolation, acting as if all transactions happen sequentially one at a time.</p></li><li><p>Prevents dirty reads, non-repeatable reads, and phantom reads.</p></li><li><p>Most expensive in terms of performance and concurrency because it can require more locking or more conflict checks.</p></li></ul></li></ol><h2>How Databases Enforce Isolation</h2><ul><li><p><strong>Pessimistic Concurrency Control</strong></p><ul><li><p>Rows or tables are locked so that no other transaction can read or write them until the lock is released.</p></li><li><p>Can lead to blocking or deadlocks if multiple transactions compete for the same locks.</p></li></ul></li></ul><h4>2. MVCC (Multi-Version Concurrency Control)</h4><ul><li><p><strong>Optimistic Concurrency Control</strong></p><ul><li><p>Instead of blocking reads, the database keeps multiple versions of a row.</p></li><li><p>Readers see a consistent snapshot of data (like a point-in-time view), while writers create a new version of the row when updating.</p></li><li><p>This approach reduces lock contention but requires carefully managing row versions and cleanup (vacuuming in PostgreSQL, for example).</p></li></ul></li></ul><ul><li><p>A form of MVCC where each transaction sees data as it was at the start (or a consistent point) of the transaction.</p></li><li><p>Prevents non-repeatable reads and dirty reads. Phantom reads may still occur unless the isolation level is fully serializable.</p></li></ul><p> ensures that once a transaction has been committed, the changes it made will survive, even in the face of power failures, crashes, or other catastrophic events. </p><p>In other words, once a transaction says “done,” the data is permanently recorded and cannot simply disappear.</p><h2>How Databases Ensure Durability</h2><h4>1. Transaction Logs (Write-Ahead Logging)</h4><p>Most relational databases rely on a  to preserve changes before they’re written to the main data files:</p><ol><li><p>: The intended operations (updates, inserts, deletes) are recorded in the WAL on durable storage (disk).</p></li><li><p>: Once the WAL entry is safely persisted, the database can mark the transaction as committed.</p></li><li><p><strong>Apply Changes to Main Data Files</strong>: The updated data eventually gets written to the main files—possibly first in memory, then flushed to disk.</p></li></ol><p>If the database crashes, it uses the WAL during :</p><ul><li><p>: Any committed transactions not yet reflected in the main files are reapplied.</p></li><li><p>: Any incomplete (uncommitted) transactions are rolled back to keep the database consistent.</p></li></ul><h4>2. Replication / Redundancy</h4><p>In addition to WAL, many systems use replication to ensure data remains durable even if hardware or an entire data center fails.</p><ul><li><p>: Writes are immediately copied to multiple nodes or data centers. A transaction is marked committed only if the primary and at least one replica confirm it’s safely stored.</p></li><li><p>: Changes eventually sync to other nodes, but there is a (small) window where data loss can occur if the primary fails before the replica is updated.</p></li></ul><p>Regular  provide a safety net beyond logs and replication. In case of severe corruption, human error, or catastrophic failure:</p><ul><li><p>: Capture the entire database at a point in time.</p></li><li><p><strong>Incremental/Differential Backups</strong>: Store changes since the last backup for faster, more frequent backups.</p></li><li><p>: Ensures backups remain safe from localized disasters, allowing you to restore data even if hardware is damaged.</p></li></ul><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><p>If you have any questions or suggestions, leave a comment.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/scalability?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQwMDc4MDk0LCJpYXQiOjE3Mzc1MzgxODMsImV4cCI6MTc0MDEzMDE4MywiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.xroFXQDDEPvo2FWnnt-G2Ji9MzYIDtJ68NRQX6sT8x8&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re finding this newsletter helpful and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":10887,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ceb65c-70e6-4f3e-9511-f6bc5da93d13_1308x1086.png","enclosureMime":"","commentsUrl":null},{"title":"Tutorial: publishing ESM-based npm packages with TypeScript","url":"https://2ality.com/2025/02/typescript-esm-packages.html","date":1738627200,"author":"Dr. Axel Rauschmayer","guid":198,"unread":true,"content":"<p>During the last two years, ESM support in TypeScript, Node.js and browsers has made a lot of progress. In this blog post, I explain my modern setup that is relatively simple – compared to what we had to do in the past:</p>","contentLength":220,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fat Rand: How Many Lines Do You Need To Generate A Random Number?","url":"http://lucumr.pocoo.org/2025/2/4/fat-rand","date":1738627200,"author":"Armin Ronacher","guid":345,"unread":true,"content":"<p>I recently wrote <a href=\"http://lucumr.pocoo.org/2025/1/24/build-it-yourself/\">about dependencies in Rust</a>.  The feedback, both within and outside\nthe Rust community, was very different.  A lot of people, particularly\nsome of those I greatly admire expressed support.  The Rust community, on\nthe other hand, was very dismissive on on Reddit and Lobsters.</p><p>Last time, I focused on the  crate, but I also want to\nshow you a different one that I come across once more: .  It has a\nsimilarly out-of-whack value-to-dependency ratio, but in a slightly\ndifferent way.  More than , you are quite likely to use\nit.  If for instance if you want to generate a random UUID, the \ncrate will depend on it.  Due to its nature it also has a high security\nexposure.</p><p>I don't want to frame this as “ is a bad crate”.  It's not a bad\ncrate at all!  It is however a crate that does not appear very concerned\nabout how many dependencies it has, and I want to put this in perspective:\nof all the dependencies and lines of codes it pulls in, how many does it\nactually use?</p><p>As the name implies, the  crate is capable of calculating random\nnumbers.  The crate itself has seen a fair bit of churn: for instance 0.9\nbroke backwards compatibility with 0.8.  So, as someone who used that\ncrate, I did what a responsible developer is supposed to do, and upgraded\nthe dependency.  After all, I don't want to be the reason there are two\nversions of  in the dependency tree.  After the upgrade, I was\nsurprised how fat that dependency tree has become over the last nine\nmonths.</p><p>Today, this is what the dependency tree looks like for the default feature\nset on macOS and Linux:</p><pre>x v0.1.0 (/private/tmp/x)\n└── rand v0.9.0\n    ├── rand_chacha v0.9.0\n    │   ├── ppv-lite86 v0.2.20\n    │   │   └── zerocopy v0.7.35\n    │   │       ├── byteorder v1.5.0\n    │   │       └── zerocopy-derive v0.7.35 (proc-macro)\n    │   │           ├── proc-macro2 v1.0.93\n    │   │           │   └── unicode-ident v1.0.16\n    │   │           ├── quote v1.0.38\n    │   │           │   └── proc-macro2 v1.0.93 (*)\n    │   │           └── syn v2.0.98\n    │   │               ├── proc-macro2 v1.0.93 (*)\n    │   │               ├── quote v1.0.38 (*)\n    │   │               └── unicode-ident v1.0.16\n    │   └── rand_core v0.9.0\n    │       ├── getrandom v0.3.1\n    │       │   ├── cfg-if v1.0.0\n    │       │   └── libc v0.2.169\n    │       └── zerocopy v0.8.14\n    ├── rand_core v0.9.0 (*)\n    └── zerocopy v0.8.14\n</pre><p>About a year ago, it looked like this:</p><pre>x v0.1.0 (/private/tmp/x)\n└── rand v0.8.5\n    ├── libc v0.2.169\n    ├── rand_chacha v0.3.1\n    │   ├── ppv-lite86 v0.2.17\n    │   └── rand_core v0.6.4\n    │       └── getrandom v0.2.10\n    │           ├── cfg-if v1.0.0\n    │           └── libc v0.2.169\n    └── rand_core v0.6.4 (*)\n</pre><p>So, let's investigate what all these dependencies do. The current version\npulls in quite a lot.</p><div><p>If you want to audit the entire dependency chain, you end up with\nmaintainers that form eight distinct groups:</p><ol><li>: rust core + various externals</li><li>: rust core + Alex Crichton</li><li> and : rust nursery + rust-random</li><li> and : Google (via two ICs there, Google\ndoes not publish)</li><li>: Andrew Gallant</li><li>, , , : David Tolnay</li></ol><p>If I also cared about WASM targets, I'd have to consider even more\ndependencies.</p></div><div><p>So let's vendor it.  How much code is there?  After removing all tests, we\nend up with  vendored taking up  disk\nspace.  Tokei reports .</p><p>Now this is a bit misleading, because like many times most of this is\nwithin .  But how much of  does \nneed?  A single function:</p><div><pre>: : -&gt; </pre></div><p>For that single function (and the information which DLL it needs link\ninto), we are compiling and downloading megabytes of .\nLonger term <a href=\"https://rust-lang.github.io/rfcs/2627-raw-dylib-kind.html\">this might not be necessary</a>, but today\nit is.</p><p>On Unix, it's harder to avoid  because it tries multiple APIs.\nThese are mostly single-function APIs, but some non-portable constants\nmake  difficult to avoid.</p><p>Beyond the platform dependencies, what else is there?</p><ul><li> (the 's picked default randon number generator)\nalone comes to 3,587 lines of code including 168 unsafe blocks.  If\nthe goal of using  was to avoid , there is still\na ton of  remaining.</li><li>The combination of , , , and\n comes to 49,114 lines of code.</li><li> clocks in at 3,000 lines of code.</li><li>The pair of  and  together?  14,004 lines\nof code.</li></ul><p>All of these are great crates, but do I need all of this just to generate a random number?</p></div><div><p>The Rust developer community <a href=\"https://www.reddit.com/r/rust/comments/1igjiip/rand_now_depends_on_zerocopy/\">on Reddit</a>\ndoesn't seem very concerned.  The main sentiment is that  now uses less\n so that's benefit enough.  While the total amount of unsafe\nprobably did not go down, that moved unsafe is is now in a common crate\nwritten by people that know how to use unsafe ().  There is\nalso the sentiment that all of this doesn't matter anyways, because we\nwill will all soon depend on  everywhere anyways, as more and\nmore dependencies are switching over to it.</p><p>Maybe this points to Rust not having a large enough standard library.\nPerhaps features like terminal size detection and random number generation\nshould be included.  That at least is what people pointed out on Twitter.</p><p>We already treat crates like , , and  as if they\nwere part of the standard library.  The difference is that I can trust the\nstandard library as a whole—it comes from a single set of authors, making\nauditing easier.  If these external, but almost standard crates were more\ncautious about dependencies and make it more of a goal to be auditable, we\nwould all benefit.</p><p>Or maybe this is just how Rust works now.  That would make me quite sad.</p><p> it looks like there is some appetite in  to improve on\nthis.</p><ul><li>a stripped down version of  (which does not require \nor most of the rust-crypto ecosystem) might replace :\n<a href=\"https://github.com/rust-random/rand/issues/934\">PR #934</a>.</li><li>if you use Rust 1.71 or later,  becomes mostly a\nno-op if you compile with .</li></ul><p><em>Edit: This post originally incorrectly said that getrandom depends on\nwindows-sys.  That is incorrect, it only depends on windows-targets.</em></p></div>","contentLength":6046,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Slow, flaky, and failing","url":"https://bitfieldconsulting.com/posts/slow-flaky-failing","date":1738242900,"author":"John Arundel","guid":17,"unread":true,"content":"<blockquote><p><em>If you find yourself working on a project with quite a few broken\nwindows, it’s all too easy to slip into the mindset of “All the rest of\nthis code is crap, I’ll just follow suit.”</em>\n—David Thomas &amp; Andrew Hunt, <a href=\"https://amzn.to/3yGUnhD\">“The\nPragmatic Programmer: Your Journey to Mastery”</a></p></blockquote><p>It’s one minute to ship time, and you hit “push” on the very last\ncommit. There it goes: the build is running. Every second counts now,\nand you watch the test output with increasing impatience. Why do the\ntests take so darned ?</p><p>And then, to your horror, the first red lights start to appear. “But\nthese were passing before, and I haven’t touched that code!” you wail.\nIt’s no good: your co-workers are already giving you the stink eye for\nbreaking the build and holding them up.</p><p>You’re not going to ship today, for one simple reason: your tests are\nslow, flaky, and failing. So what the hell?</p><p>Flaky tests sometimes fail, sometimes pass, regardless of whether the\nsystem is correct. There are many reasons for flaky tests, so let’s look\nat a couple of them, with some possible solutions.</p><p> can be a source of flakiness, as you probably\nknow from experience. In particular, fixed sleeps in tests are a bad\nidea (see the next section for more about these). Eliminate these\nwherever possible and replace them with code that only waits as long as\nstrictly necessary.</p><p>When you need to  timing itself, use the shortest\npossible interval. For example, don’t test a timer function with a\none-second duration when one millisecond would work just as well.</p><p>In some tests, as crazy as it sounds, the  can\naffect the test. One way to eliminate this cause of flakiness is by\nturning , and if necessary injecting a fake\n function to return a canned time of day.</p><p>Flakiness can also sometimes arise from .\nSome data structures in Go are inherently unordered: maps, for example.\nComparing these needs special care.</p><p>For example, iterating over a map comparing its elements is not good\nenough: the iteration order of maps is unspecified in Go. Instead, we\ncan use the  function to compare maps regardless\nof iteration order:</p><pre><code></code></pre><p>On the other hand, slices  inherently ordered, and so\n requires this:</p><pre><code></code></pre><p>But sometimes we don’t actually care about the order. Maybe we get\nthese results from some concurrent computations, and we don’t know what\norder they will show up in. We just want to know that we \nthe right results.</p><p>To compare two slices for equal , then, regardless\nof order, we can use  to sort them before the\ncomparison:</p><pre><code></code></pre><p>Whatever the cause of a flaky test suite, it’s a serious problem.\nLeft untreated, it will continuously erode value from the tests, until\neventually they become useless and ignored by all. It should be a red\nflag to hear something like “Oh yeah, that test just fails\nsometimes.”</p><p>As soon as you hear that, you know that the test has become useless.\nDelete it, if the flakiness really can’t be fixed. Thou shalt not suffer\na flaky test to live. As soon as it starts flaking, it stops being a\nuseful source of feedback, and bad tests are worse than no tests.</p><p>A  test is not the same thing as a flaky test: a\nbrittle test fails when you change something unrelated, whereas a flaky\ntest fails when it feels like it. Fixing brittle tests is usually a\nmatter of decoupling entangled components, or simply reducing the scope\n(and thus sharpening the focus) of the test.</p><p>On the other hand, flaky tests can require some time and effort to\nfind the underlying cause and address it. Only do this if the test is\nreally worth it; if not, just delete it.</p><p>What if some tests aren’t just flaky, but fail all the time, because\nbugs aren’t being fixed? This is a very dangerous situation, and without\nprompt action the tests will rapidly become completely useless.</p><p>Why? Because if tests are allowed to fail for a while without being\nfixed, people soon stop trusting them, or indeed paying \nattention to them: “Oh yeah, that test always fails.”</p><p>We can never have any failing tests, just as we can never have any\nbugs:</p><p>As soon as any test starts failing, fixing it should be everyone’s\ntop priority. No one is allowed to deploy any code change that’s not\nabout fixing this bug. Once you let one failing test slip through the\nnet, all the other tests become worthless.</p><p>This so-called  sounds radical, but\nit really isn’t. After all, what’s the alternative?</p><blockquote><p><em>The very first version of Microsoft Word for Windows was\nconsidered a “death march” project. Managers were so insistent on\nkeeping to the schedule that programmers simply rushed through the\ncoding process, writing extremely bad code, because bug-fixing was not a\npart of the formal schedule.</em><em>Indeed, the schedule became merely a checklist of features waiting\nto be turned into bugs. In the post-mortem, this was referred to as\n“infinite defects methodology”.</em>\n—Joel Spolsky, <a href=\"https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/\">“The\nJoel Test: 12 Steps to Better Code”</a></p></blockquote><p>Fixing bugs now is cheaper, quicker, and makes more business sense\nthan fixing them later. The product should be ready to ship at all\ntimes, without bugs.</p><p>If you already  a large backlog of bugs, or failing\ntests, but the company’s still in business, then maybe those bugs aren’t\nreally that critical after all. The best way out may be to declare\nvoluntary : just close all old bugs, or delete\nall failing tests. Bugs that people  care about will pretty\nsoon be re-opened.</p><p>My book <a href=\"https://bitfieldconsulting.com/books/tests\">The Power of Go: Tests</a> is all\nabout how to write  tests: not just box-ticking\nexercises to satisfy some bureaucratic manager, but tests that really\nadd value to the code, and make your work easier and more enjoyable.</p><p>Even the world’s greatest test suite does us no good, though, if it\ntakes too long to run. How long is too long? Well, if we’re running\ntests every few minutes, clearly even a few minutes is too long. We\nsimply won’t run the tests often enough to get the fast feedback we need\nfrom them.</p><blockquote><p><em>By running the test suite frequently, at least several times a\nday, you’re able to detect bugs soon after they are introduced, so you\ncan just look in the recent changes, which makes it much easier to find\nthem.</em>\n—Martin Fowler, <a href=\"https://martinfowler.com/bliki/SelfTestingCode.html\">“Self-Testing\nCode”</a></p></blockquote><p>One way or the other, then, we don’t want to be more than about five\nminutes away from passing tests. So, again, how long is \nlong for a test suite to run?</p><p>Kent Beck suggests that ten minutes is a psychologically significant\nlength of time:</p><blockquote><p><em>The equivalent of 9.8 m/s² is the ten-minute test suite. Suites\nthat take longer than ten minutes inevitably get trimmed, or the\napplication tuned up, so the suite takes ten minutes again.</em>\n—Kent Beck, <a href=\"https://amzn.to/3OR9pqg\">“Test-Driven Development\nby Example”</a></p></blockquote><p>We may perhaps call this psychological limit the .\nBeyond the ten-minute mark, the problem is so obvious to everybody that\npeople are willing to put effort into speeding up the test suite. Below\nthat time, people will probably grumble but put up with it.</p><p>That certainly doesn’t mean that a ten-minute test suite is okay:\nit’s not, for the reasons we’ve discussed. Let’s look at a few simple\nways to reduce the overall run-time of the test suite to something more\nmanageable.</p><ol type=\"1\"><li><p>. The inability to run certain\ntests in parallel is usually a design smell. Refactor so that each test\nhas its own world, touches no global state, and can thus run in\nparallel. Adding parallelism to a suite that doesn’t have it should\nspeed it up by about an order of magnitude.</p></li><li><p><strong>Eliminate unnecessary I/O</strong>. Once you go off the\nchip, things get slow. Do everything on the chip as far as possible,\navoiding I/O operations such as network calls or accessing disk files.\nFor example, you could use an  as an in-memory\nfilesystem, and memory-backed s and\ns instead of real files.</p></li><li><p>. Instead of calling some\nremote API, call a local fake instead. Local networking happens right in\nthe kernel, and while it’s still not , it’s a lot faster\nthan actually going out onto the wire.</p></li><li><p><strong>Share fixtures between tests</strong>. Any time you have\nsome expensive fixture setup to do, such as loading data into a\ndatabase, try to share its cost between as many tests as possible, so\nthat they can all use it. If necessary, do the setup in a single test\nand then run a bunch of subtests against it.</p><p>However, we need to be careful that the tests don’t then become flaky\nas a result of too much fixture sharing. A flaky test is worse than a\nslow test.</p></li><li><p>. A test that can’t proceed until\nsome concurrent operation has completed should use the “wait for\nsuccess” pattern (loop and retry, with a tiny delay, until the operation\nhas completed). This minimises wasted time, whereas a long fixed sleep\nmaximises it (or causes flaky tests, which is also bad).</p></li><li><p><strong>Throw hardware at the problem</strong>. When you’ve made\nthe test suite as fast as it can go and it’s still slow, just run it on\na faster computer. If the tests are mostly CPU-bound, rent a 256-core\ncloud machine and have it pull and run the tests on demand. CPU time\ncosts a lot less than programmer time, especially since hiring cheap\nprogrammers is a false economy.</p></li><li><p>. This is a last resort,\nbut it might come to that. If you have a few tests that simply\n be speeded up any more, and they’re dragging down the\nrest of the suite, extract them to a separate “slow test” suite, and run\nit on a schedule. Every night, perhaps; certainly no less frequently\nthan that. Even nightly isn’t great, but it’s better than not running\ntests at all.</p></li></ol>","contentLength":9340,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Local Diffusion Inference with Stable-Diffusion.cpp and Flux.1","url":"https://medium.com/@kyodo-tech/local-diffusion-inference-with-stable-diffusion-cpp-and-flux-1-5d1841fff9cf?source=rss-ac02ab142942------2","date":1738238284,"author":"Kyodo Tech","guid":90,"unread":true,"content":"<p><a href=\"https://github.com/leejet/stable-diffusion.cpp\">Stable-Diffusion.cpp</a> is designed for efficient, high-performance inference of Stable Diffusion models, especially on low-resource environments where traditional deep learning pipelines struggle. We provide an examination of SDcpp, its components, and the technical concepts that enable efficient inference of Stable Diffusion models on lower-end hardware such as CPUs and lightweight GPUs, such as Apple M-series chips. In particular, we’re looking at <a href=\"https://github.com/black-forest-labs/flux\">Flux.1</a>, a text-to-image model developed by <a href=\"https://blackforestlabs.ai/\">Black Forest&nbsp;Labs</a>.</p><h3>Introduction to Diffusion Models and Stable Diffusion</h3><p>Diffusion models, specifically Denoising Diffusion Probabilistic Models (DDPMs), have emerged as powerful generative frameworks capable of producing high-fidelity images from random noise through iterative denoising processes. Stable Diffusion extends the DDPM framework by incorporating text conditioning, allowing for the generation of images based on descriptive prompts. However, the computational demands of such models typically necessitate high-memory, high-bandwidth GPU resources, limiting their accessibility and scalability.</p><p>SDcpp addresses these limitations by providing an optimized inference framework that leverages techniques such as quantization, memory-efficient sampling, and optimized latent space representations to facilitate the deployment of Stable Diffusion models on devices with constrained computational resources. This paper delves into the architectural and algorithmic components of SDcpp, highlighting the methodologies that underpin its efficiency and performance.</p><p>The architecture is composed of several interdependent modules, each contributing to the inference process. First, it is <strong>loading the required models</strong> (1), including text encoders, the diffusion model, and the VAE decoder. It then performs  (2), tokenizing the input prompt and generating text embeddings using a CLIP-based model and an additional T5XXL text conditioning model. Next, it <strong>computes the conditioning graph</strong> (3), transforming embeddings to create a guidance vector for the diffusion process. The system then  (4) by iteratively refining a randomly initialized latent tensor using a noise schedule and a chosen sampling method, progressively steering it towards a structured latent representation in a number of . This step is the most compute-intensive, consuming roughly 90% of the total processing time. Once sampling completes, the pipeline <strong>decodes the latent representation</strong> (5) using a VAE model to reconstruct pixel-space information. Finally, it  (6) as an image file, completing the text-to-image generation process.</p><h4>Diffusion Model Core Components</h4><p>The diffusion model within SDcpp is the principal generative engine, responsible for transforming Gaussian noise into coherent images through a series of denoising . More steps allow finer details and smoother outputs but increase inference time, as each step requires additional computation. This process is governed by the DDPM framework, wherein the model iteratively refines the image by removing noise in a controlled manner. The diffusion model encompasses three primary components:</p><p><strong>UNet (Denoising Network):</strong> the UNet architecture employs an encoder-decoder structure with skip connections, enabling multi-scale feature extraction and reconstruction. The network predicts and removes noise at each denoising step, progressively enhancing image&nbsp;quality.</p><p><strong>Text Encoder (Conditioning Module):</strong> The text encoder converts textual prompts into latent embeddings that guide the denoising process. SDcpp supports multiple text encoders, including CLIP-L, CLIP-G, and T5XXL, each tailored for different model versions and memory considerations.</p><p><strong>Scheduler (Noise Controller):</strong> The scheduler orchestrates the noise removal strategy, dictating the temporal progression of denoising steps. It determines the rate and manner in which noise is reduced, balancing computational efficiency and image fidelity.</p><p>A recent model, <a href=\"https://huggingface.co/black-forest-labs/FLUX.1-schnell\"></a>&nbsp;, is optimized for low-resource environments, featuring a compact UNet architecture that accelerates inference by reducing the number of denoising steps. Flux.1 is designed for memory-efficient quantization and compatibility with the GGUF format, making it suitable for deployment on lightweight hardware. It reduces inference steps to only 4 steps and can achieve fast inference.</p><h4>Variational Autoencoder (VAE)</h4><p>VAEs facilitating the encoding of images into a lower-dimensional latent space. This reduction significantly diminishes computational and memory overhead while retaining high-resolution image details. Latent space is a <strong>compact mathematical representation</strong> of an image. Think of it as a highly efficient shorthand where only the most essential details are stored. Instead of storing every pixel, the image is encoded as numbers that describe its features. This makes it possible to work with images at a much lower computational cost. Stable Diffusion doesn’t generate images pixel by pixel. Instead, it creates images in latent space, where information is stored in a more compact and manageable way. Once the model finishes generating an image in this space, the VAE  it back into a high-resolution format that we can&nbsp;see.</p><p>Different VAEs can influence how well the final image looks. A generic VAE works for most images, but a model trained for a specific style, like anime or realistic photography, may use a custom VAE to better match its training data. A poorly matched VAE can cause color shifts, blurriness, or unwanted artifacts.</p><p>Technically, any model can use any VAE, but results vary. A VAE trained on cartoon-style images won’t reconstruct a photorealistic image correctly. This is why some models provide their own VAEs — they have been optimized to maintain details that matter most for a specific&nbsp;style.</p><h4>LoRA (Low-Rank Adaptation)</h4><p>LoRA facilitates model customization without the need to adjust the entire diffusion model. By modifying only a small subset of parameters (~10 million), LoRA significantly reduces memory usage compared to full model fine-tuning. Multiple LoRAs can be combined with weighted influences on the final image, enabling diverse stylistic and feature modifications. For instance, combining two LoRAs with different weights can be executed using the syntax &lt;lora:styleA:0.6&gt; &lt;lora:styleB:0.8&gt;. To optimize performance, it is advisable to minimize the number and strength of LoRAs, especially in memory-limited environments.</p><h4>Training and Inference File&nbsp;Formats</h4><p>The  is the standard PyTorch checkpoint format, that stores full precision weights and optimizer states. Supports training and fine-tuning but can execute arbitrary Python code, posing security risks. <strong>SafeTensors (.safetensors)</strong> is a safer alternative to CKPT, with structured, immutable storage and no executable code. Loads faster but still used mainly for training.</p><p><strong>GGUF (GPT-Generated Unified Format)</strong> is a binary model format introduced by llama.cpp, succeeding GGML. Initially designed for language models (like LLaMA models), GGUF has been adopted in diffusion models to enable efficient, quantized inference without reformatting model files into proprietary formats (e.g.,&nbsp;.ggml or&nbsp;.gguf conversions required previously). Traditional formats (.safetensors,&nbsp;.ckpt,&nbsp;.bin) store full-precision FP16/FP32 model weights, consuming significant VRAM. GGUF introduces quantization at multiple levels, storing models in 2-bit to 16-bit precision while maintaining compatibility with&nbsp;SDcpp.</p><p>Use GGUF for efficient inference on low-resource devices, prefer&nbsp;.safetensors for training.</p><p>In our experiments,  demonstrates an extremely fast denoising process, with images at 1 and 2 steps appearing nearly identical, suggesting that most structural information is determined in the very first iterations. By 4 steps, images diverge significantly, and by 6 steps, they change even more, indicating that additional steps introduce large variations rather than just refining details. Interestingly, <strong>Euler and Euler_a produce the best results</strong>, likely because they follow a balanced noise reduction trajectory, allowing structure to form naturally without over-smoothing or excessive deviations. Euler introduces noticeable changes between 3, 4, and 6 steps, including shifts in pose, face, and hair color, implying that it follows a latent space trajectory where small step changes can drastically impact the final result. Euler_a, being an ancestral sampler, adds controlled randomness at each step, further amplifying these changes. In contrast, <strong>LCM performs poorly with Flux 1</strong>, excessively blurring images, likely due to its tuning for models that require more iterative refinement, making it unsuitable for Flux 1’s fast-converging architecture. We observed that <strong>4 steps often produce better images</strong> than 5 or 6 steps, as extra iterations introduce unnecessary alterations instead of improving details, reinforcing that Flux 1 is optimized for extremely low-step inference. This is a stark contrast to Stable Diffusion models like SD 1.5 or SDXL, which typically require 20–50 steps for high-quality outputs. These findings highlight that Flux 1’s unique training favors fewer steps with the right sampler, making Euler and Euler_a better choices at around 4 steps, while models like LCM fail due to excessive denoising.</p><h4>Denoising Schedules and Sampling Integration</h4><p>Denoising schedules define a series of noise levels that guide reverse diffusion. These schedules set discrete or continuous noise decay steps, essentially parameterizing the stochastic differential equation used to reverse the diffusion process. Discrete schedules apply abrupt noise transitions, forcing the model to rapidly shift between latent states. In contrast, smooth schedules such as karras or exponential distribute noise reduction evenly, supporting more accurate latent&nbsp;updates.</p><p>Sampling methods numerically integrate these latent trajectories. Euler-type samplers update the latent state with fixed time step approximations, benefiting from stable transitions when paired with smooth noise decay. Latent Consistency Models (LCM) depend on gradual noise reduction; abrupt schedules can induce over-smoothing and detail loss. Our observations indicate that matching a sampling method’s sensitivity to noise decay with an appropriate denoising schedule is key to preserving image structure while ensuring efficient inference.</p><p>Flux.1’s behavior indicates that its training regime emphasizes rapid structure formation in early steps. Euler’s robustness across discrete, exponential, and karras schedules suggests that its integration of abrupt noise transitions still aligns well with Flux.1’s latent dynamics. LCM, being more sensitive to the noise decay, only works well with smoother schedules (exponential and karras) that provide gradual latent&nbsp;updates.</p><p>The failures with AYS and GITS imply that these schedules impose noise trajectories incompatible with Flux.1’s fast-convergence design. Their latent paths likely diverge from the model’s learned reverse diffusion trajectory, causing the state to collapse into uniform or noisy outputs rather than structured images. This sensitivity reinforces that Flux.1 is optimized for few-step denoising with specific noise decay characteristics, and departures from that — especially with schedules that enforce alternative trajectory regularity — can disrupt the image generation process.</p><p>Flux.1 departs from prior diffusion models by leveraging a T5-style text encoder instead of CLIP, allowing it to process full sentences fluently rather than relying on discrete token hierarchies. Unlike Stable Diffusion, where Booru-style tags and keyword emphasis are required for precision, <strong>Flux.1 understands natural language</strong> natively, reducing reliance on rigid token structures. Long, descriptive prompts yield better scene coherence, material accuracy, and relational awareness than fragmented keyword&nbsp;lists.</p><p>Trigger words are optional rather than mandatory, as the model activates concepts contextually rather than requiring explicit token matching. However, structured elements — short modifiers or category cues — can refine specificity without overpowering Flux.1’s broader language comprehension. The model is particularly strong at multi-concept blending, which traditionally caused token interference in CLIP-based architectures. Negative prompting is also more effective, reducing the unintended blending of attributes.</p><p>Flux.1 performs best with contextual and relational descriptions, leveraging semantic depth over isolated tokens. While Booru tags still function, hybrid prompting — mixing structured elements with full sentences — offers the best balance between control and generative adaptability.</p><p>LoRA functions differently in Flux.1 compared to Stable Diffusion. Since Flux.1 uses a T5-based encoder, LoRA activation does not require fixed trigger words but instead responds dynamically to natural descriptions. This allows LoRAs to integrate seamlessly into prompts without rigid dependencies.</p><p>Key parameters such as network dimension, alpha scaling, and captioning density influence performance. Higher network dimension strengthens adaptation but risks overfitting, while alpha scaling balances LoRA integration with the base model. <strong>Flux.1’s LoRAs benefit from mixed captioning strategies — varying between short tags and natural descriptions — ensuring activation without over-constraining the generative process.</strong> Unlike SDXL, which often requires explicit weight scaling (1.2–1.5x) to activate LoRAs, Flux.1 adapts LoRA strength more organically within context, reducing the need for manual weight adjustments.</p><p>To maximize LoRA performance in Flux.1, descriptive phrasing should replace rigid token triggers, using context-driven prompts to activate learned modifications naturally. Captions should balance specificity with generalization, ensuring LoRAs enhance rather than dominate the generative output.</p><h3>Optimization Strategies for Low-Resource Inference</h3><p>Quantization is a pivotal technique in reducing model size and memory usage by lowering the precision of model weights. SDcpp supports various quantization levels, each offering a different balance between memory efficiency and image&nbsp;quality:</p><ul><li> Reduces memory usage by approximately 75% compared to full precision (FP16) while maintaining good image quality. It introduces a slight computational overhead due to dequantization but is optimal for low-end hardware.</li><li> Offers slightly better precision than Q4 at the cost of requiring twice the memory. It is suitable for systems with more VRAM where higher image fidelity is&nbsp;desired.</li></ul><p>For lower-end hardware, Q4_K provides a good balance of speed and quality, while  is better for systems with more VRAM&nbsp;(&gt;16GB).</p><h4>Quantization Impact of Model&nbsp;Parts</h4><p>We’re loading a model, vae, clip, and t5, and can choose quantized parts for each. The model itself must be quantized due to memory constraints, but the VAE, CLIP, and T5 can remain in higher precision. We tested a q4_K model with safetensors in higher precision, and a fully quantized version where all parts were&nbsp;q4_0.</p><p>We observed <strong>a 2.5x slowdown with the fully quantized run</strong>, despite reduced memory usage. Likely due to increased dequantization overhead, precision mismatch-induced stalls, and reduced SIMD efficiency on the Apple M2. While background processes may have contributed to higher involuntary context switches (3.3M vs. 1.48M), they do not fully explain the slowdown. The quantization format (q4_K vs. q4_0) influences computational efficiency rather than raw inference speed, with q4_K employing grouped quantization, which improves data locality and reduces dequantization frequency, while q4_0 likely applies simpler per-tensor quantization, increasing compute overhead. The hybrid approach—quantizing only the diffusion model while keeping VAE, CLIP, and T5 in higher precision—seems to better utilize hardware by avoiding unnecessary precision conversion costs and leveraging FP computation optimizations. These results suggest that full quantization may degrade performance when not optimized for architectural strengths, particularly on FP-optimized hardware like the&nbsp;M2.</p><p>The sampling method determines the strategy by which noise is removed during the denoising process. Ancestral samplers introduce random variations at each step, leading to more diverse outputs, while fixed-step samplers follow a deterministic trajectory, yielding consistent results.</p><p>SDcpp integrates several sampling algorithms optimized for different performance criteria:</p><ul><li> A simple and fast method effective with a lower number of denoising steps, suitable for rapid inference.</li><li> Prioritizes image quality, requiring more steps and memory. It is ideal for applications where high detail is essential.</li><li><strong>Latent Consistency Models (LCM):</strong> Optimizes speed by drastically reducing the number of required denoising steps (e.g., 4–8 instead of 20–30), making it highly suitable for low-end systems. Users can specify the sampling method using the --sampling-method flag, such as --sampling-method lcm.</li></ul><p>Memory management is critical in ensuring that diffusion models run efficiently on constrained hardware. SDcpp employs several techniques to optimize memory&nbsp;usage:</p><ul><li> By processing the VAE decoder in smaller, manageable segments, VAE tiling minimizes peak memory&nbsp;usage.</li><li> Flash Attention optimizes memory allocation during UNet computations. On CUDA-enabled GPUs, it offers significant memory savings and speed improvements. Flash Attention can be activated via the --diffusion-fa flag.</li></ul><p>In our experiments on an Apple M2, enabling --vae-tiling reduced memory usage but increased execution time, suggesting a trade-off between efficiency and speed. When --diffusion-fa (Flash Attention) was enabled, execution time did not significantly improve. The combination of both options (vae-tiling and diffusion-fa) resulted in the  but also the , confirming that while these settings help on low-VRAM devices, they introduce performance overhead. The fastest run occurred with both options disabled, though it had the highest memory footprint.</p><p>Image resolution directly impacts both memory consumption and inference speed. Generating images at a resolution of 1280×640 requires approximately 2.5 times the memory of generating images at 512×512. To accommodate low-resource environments, users can opt for intermediate resolutions such as 768×384 or 1024×512, balancing image quality and computational efficiency.</p><h4>LoRA Delay and Conditioning Graph Recalculation</h4><p>When LoRA modules are applied, the conditioning graph must be recalculated due to LoRA’s modification of internal activations, which can reintroduce dependencies on structured tagging if the LoRA was trained on datasets requiring them. The conditioner parses and reweights prompt segments dynamically, adjusting token influence based on LoRA-induced shifts in the embedding space, ensuring compatibility between the altered diffusion model state and the input text. This recalibration process accounts for the delay seen post-LoRA application and before sampling, as the system must harmonize LoRA-induced parameter shifts with Flux.1’s inherently context-aware text encoding.</p><h4>Classifier-Free Guidance&nbsp;Scale</h4><p>CFG scale (Classifier-Free Guidance Scale) can be set with the --cfg-scale argument. It defaults to 7.0 and controls how strictly the model follows the text prompt, balancing adherence and creativity. Higher values (e.g., 10-15) force the model to generate images that closely match the prompt but can introduce artifacts, while lower values (e.g., 1-5) allow more randomness and artistic interpretation. It impacts performance slightly because higher CFG values increase the weight difference between conditional (prompted) and unconditional (random) predictions, requiring additional computation to balance them. However, the effect on inference speed is minor compared to factors like resolution, model architecture, and sampling&nbsp;steps.</p><p>Flux.1 seem to have been trained with  as target setting, meaning its internal weighting and contrast are optimized for that value. Lowering CFG to  reduces guidance too much, allowing excessive noise influence, resulting in darker, underexposed images. Raising it to 2.0 strengthens prompt adherence but overemphasizes highlights and contrast, making images appear overly bright. Unlike standard Stable Diffusion, where 7.0 is the default for balanced outputs, Flux.1’s tuning makes , with deviations causing unintended brightness shifts.</p><p>To analyze the impact of CFG scale on image generation, we generated eight images using CFG 1.0 and 2.0 across the Euler, LCM, iPNDM, and Euler_a samplers with 4 steps and a fixed seed of 42, using the prompt “a beautiful girl in futuristic Tokyo, neon lights,” comparing how different guidance levels influence brightness, contrast, and prompt adherence.</p><h4>Memory-Efficient Inference</h4><p>Running Flux.1 (schnell) on an Apple M2 (16GB RAM), we achieve inference without a GPU, completing a 256×256 image in 216.3s with 9.28GB RAM usage. The UNet required just 96.59MB, and VAE decoding used 416MB, demonstrating the efficiency of quantized GGUF&nbsp;models.</p><p>Our analysis of Stable-Diffusion.cpp and Flux.1 demonstrates that efficient local diffusion inference is feasible even on low-resource hardware, provided that model selection, quantization, and sampling strategies are optimized. Flux.1’s extremely low-step denoising makes it uniquely suited for fast inference, especially when paired with Euler and Euler_a samplers, which balance structure formation and controlled randomness. In contrast, models like LCM introduce excessive smoothing, making them unsuitable for Flux.1’s fast convergence.</p><p>We also observed that 4 steps yield optimal results with Flux.1, as additional iterations introduce unnecessary alterations rather than improving image fidelity. While our results indicate that full quantization introduces dequantization overhead and computational stalls, <em>external factors such as background system load may have influenced the extent of the observed slowdown</em>. Memory-efficient techniques such as VAE tiling and Flash Attention can reduce hardware requirements but may introduce performance trade-offs. Users should select Q4_K or similar quantization for lower-end hardware, as grouped quantization schemes appear to mitigate some of the performance penalties associated with fully quantized inference.</p><p>These findings highlight that with the right model architecture, quantization, and sampler choice, high-quality image generation is possible on constrained devices without relying on high-end GPUs. Future improvements may focus on further refining model architectures like Flux.1 and optimizing quantization methods for even faster, memory-efficient inference.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5d1841fff9cf\" width=\"1\" height=\"1\" alt=\"\">","contentLength":22810,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Design YouTube - System Design Interview","url":"https://blog.algomaster.io/p/design-youtube-system-design-interview","date":1738215950,"author":"Ashish Pratap Singh","guid":747,"unread":true,"content":"<p>With over  monthly active users,  is the second most visited website in the world—trailing only Google.</p><p>As a , it enables users to upload, watch, and interact with video content, while handling hundreds of millions of daily visitors, managing petabytes of data, and ensuring real-time video delivery across the globe.</p><p>In this article, we’ll explore the <strong>system design of a large-scale video streaming service like YouTube</strong> that can accommodate hundreds of millions of daily users and billions of views, all while maintaining low latency and high availability.</p><p>We’ll walk through every step of the design—from requirements and high-level architecture to database and API design—before diving deep into core use cases. </p><p>The concepts covered here are equally applicable to other large-scale video platforms such as  and .</p><p>Before diving into the design, lets outline the functional and non-functional requirements.</p><ul><li><p>Users should be able to  video files.</p></li><li><p>Uploaded videos must be  into multiple resolutions (e.g., 240p, 360p, 720p, 1080p) to support different network conditions and devices.</p></li></ul><ul><li><p>Users should be able to  videos in real-time with <strong>adaptive bitrate streaming</strong> to adjust quality based on network conditions.</p></li></ul><ul><li><p>Users can  for videos by title, tags, or description.</p></li><li><p>Users can  and  on videos.</p></li><li><p>Users should be able to create and subscribe to .</p></li></ul><h3><strong>Non-Functional Requirements:</strong></h3><ol><li><p> The system should support millions of concurrent users and thousands of video uploads per minute.</p></li><li><p> Core features like video upload, playback, and search should have minimal downtime.</p></li><li><p> Fast video streaming with minimal buffering and near-instantaneous search results.</p></li><li><p> Video files must be stored reliably, with redundancy mechanisms to prevent data loss due to hardware failures.</p></li><li><p> Optimize storage and bandwidth costs.</p></li></ol><ul><li><p><strong>Daily Active Users (DAU):</strong> 10 million</p></li><li><p> ~100,000 videos/day</p></li><li><p><strong>Average Videos Watched per User per Day:</strong> 5 videos</p></li><li><p> 500 MB.</p></li><li><p> 1 KB.</p></li></ul><ul><li><p>: 100,000 videos / day * 500 MB / video = 50 TB / day</p></li><li><p><strong>Daily Video Metadata Storage</strong>: 100,000 * 1KB = 100MB / day</p></li></ul><h4><strong>Network Bandwidth Estimation:</strong></h4><ul><li><p>10 million users × 5 videos/user = 50 million views/day </p></li><li><p><strong>Daily Bandwidth Requirements (without compression &amp; caching) </strong>: 50 million views * 500 MB / day = 25 PB / day</p></li></ul><p>Given the high storage and bandwidth requirements, leveraging  is the most practical approach:</p><ol><li><p><strong>Content Delivery Network (CDN):</strong> To cache frequently accessed videos closer to users and reduce latency.</p></li><li><p><strong>Blob Storage (e.g., AWS S3):</strong> To store video files reliably with redundancy.</p></li></ol><p>We can break the architecture of YouTube into two primary components: </p><ul><li><p> – Handles video playback, and delivery.</p></li><li><p><strong>Video Upload &amp; Processing</strong> – Manages user uploads, transcoding, and metadata storage.</p></li></ul><h2>3.1 Video Streaming Architecture</h2>","contentLength":2703,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23342c70-b11d-48c3-b30b-63ea245e5d2a_2026x1322.png","enclosureMime":"","commentsUrl":null},{"title":"How I Use AI: Meet My Promptly Hired Model Intern","url":"http://lucumr.pocoo.org/2025/1/30/how-i-ai","date":1738195200,"author":"Armin Ronacher","guid":344,"unread":true,"content":"<p>After Musk's acquisition of Twitter, many people I respect and follow\nmoved to Bluesky.  I <a href=\"https://bsky.app/profile/mitsuhiko.at\">created an account there</a> and made an honest attempt of\nmaking it my primary platform.  Sadly, I found Bluesky to be surprisingly\nhostile towards AI content.  There is an almost religious resistance to AI\non there, at least in whatever corner of the platform I ended up in.</p><p>Despite these challenges, some individuals on both Twitter and Bluesky\nhave shown genuine curiosity about my AI usage.  In this post, I want to\nshare how I use Large Language Models and why I find them so helpful.</p><p>Before moving on, I want to include an an important disclaimer: I am by no\nmeans an expert in AI; I'm mostly an enthusiastic user.  Absolutely\nnothing here is novel!  What I do here is pretty boring which to some\ndegree is the point.  I won't be covering underlying technology or my\nprogrammatic experience.  This is strictly about how I use AI as a “techy\nconsumer”.</p><p>In addition, as you read through this article you will probably figure out\nrather quickly that the way I use AI — despite being used in part for\ncontent creation — does not really impact intellectual property much.\nThat said, I'm curious and open to discussions about how we should be\ndealing with this problem.  Particularly on Bluesky a lot of the\nnegativity towards AI is related to watering down of copyrights and human\ncreation.  I don't know the answers to these things, but I think we need\nto have a productive dialog here rather than wishing for the technology to\ngo away.</p><div><p>In short: AI makes me significantly more productive.  I recently read\n<a href=\"https://x.com/aarondfrancis/\">Aaron Francis</a>'s Tweet about how he gets\na week's worth of productivity out of a day now thanks to AI.  I'm not\nanywhere close to that, but I use AI a lot now.  It has become\nindispensable for me for both content writing as well as programming.</p><p>Moreover, a common misconception is that AI is still at the level it was\nwhen ChatGPT first launched.  Many people tried it early, saw its\nlimitations, and never returned.  However, AI is evolving rapidly. If you\nhaven't kept up, you risk drawing inaccurate conclusions based on outdated\nimpressions.  In some sense I believe people who never tried to use AI\nyet, are in a better position to judge than the folks who used it two\nyears ago and never returned.</p></div><div><p>I work with a variety of AI tools, mostly because of professional\ncuriosity and to a smaller degree because each tool excels at something\nslightly different.  Here are the ones I use most often:</p><ul><li><a href=\"https://openwebui.com/\">Open WebUI</a>.  In short this is a Python web\napp that offers a chat interface similar to ChatGPT.\nUnlike ChatGPT, however, it lets you talk to different models.  First and\nforemost, I use this to talk to local models hosted by Ollama, but\nsecondarily I also use it to interface with other remote services like\nOpenAI, Anthropic and DeepSeek.</li><li><a href=\"https://github.com/simonw/llm\">Simon's llm</a>.  This is a command line\ntool with plenty of plugins that lets you prompt different models.  Think\nof it as a command-line version of Open WebUI.  It's particularly useful\nfor quick scripting and basic automation.</li><li><a href=\"https://ollama.com/\">Ollama</a>.  This allows me to run models locally\non my MacBook Pro M1 Max.  With the 64GB of RAM it has, it's a pretty\npotent machine for basic inference despite it being three years old.\nI'll explain later why I use local models.</li><li><a href=\"https://www.cursor.com/\">Cursor</a>.  It is a fork of Visual Studio\nCode with AI-based auto completion and code generation built-in.  It's\nmy go-to for programming with AI assistance at the moment.</li><li><a href=\"https://chatgpt.com/\">ChatGPT</a>.  Like probably most AI users, I use\nChatGPT, particularly on my phone.  I pay for the Plus subscription\nbecause I use it enough to get a lot of value out of it.  One\nsignificant use of this for me is in fact the voice mode (more on that\nlater).</li></ul><p>It's probably worth mentioning that you can get most of the benefits of this from just paying for a single AI\ntool.  I think as one expands their use, as especially as one gets better at writing prompts,\nthe desire naturally grows to use more tooling.  As for which models\n(and services) to use day to day I don't have a particular strong strategy\nand preferences change quickly.  For instance after DeepSeek's R1 release,\nI started exploring it quite a bit for programming — and it's doing a\nphenomenal job at it —&nbsp; and as of writing that's just a few days old.</p><p>If you want to run models locally, Apple Silicon machines currently offer\nsome of the best “bang for your buck” in terms of performance, power\nusage, and money.  With <a href=\"https://tailscale.com/\">tailscale</a>, I can even\naccess my MacBook's Open WebUI interface from my phone, as long as it is\npowered on.</p></div><div><p>One frequent concern I hear is “you cannot trust LLMs” as they tend to\nhallucinate.  I get this in particular when I explain that I frequently\nuse this as a replacement for Google!  However, I approach the risk of\nhallucination the same way I would when seeking advice from another human:\npeople can and are routinely wrong, and you learn to cross-check\nselectively.</p><p>I treat AI as I would a collaborator or a pretty good intern but I remain\nresponsible for the final outcome.  In this case the intern also happens\nto get better month by month as models improve.  And a bit like a human,\nthat digital intern has morals and wants to be argued with.  Except, of\ncourse, that some of those AI interns <a href=\"https://www.reddit.com/r/LocalLLaMA/comments/187oidh/deepseek_coder_7b_33b_thinks_its_trained_by_openai/\">don't want to talk about China</a>,\nwhile others get a stroke <a href=\"https://www.reddit.com/r/ChatGPT/comments/1h3rz4l/david_mayer_is_not_the_only_one_jonathan_zittrain/\">if you talk about certain people</a>.\nBut regardless of how good they get, in the end, it's my fault and my\nfault alone if I do the wrong thing.  I won't blame the AI and I need to\nspot check.</p><p>However, the logical conclusion of this is not that it's wrong all the time\nand you need to check everything, or that you cannot trust it at all.\nIt's similar to how you engage in a technical discussion with others about\na problem.  I have seen more than one situation where the conventional\nwisdom in the room is just wrong for a few minutes, until someone points\nout that we had it wrong.</p><p>Another major advantage is that AI tools are relatively open.  You can run\nmodels locally and integrate them with scripts.  Even the famous OpenAI\nwhich is not at all open is much more open than a Google search is.  For\ninstance, you can create a simple script for grammar-checking right from\nyour command line.</p><p>In other words, you  integrate it locally and nobody stops you.  By\ncontrast, many, many years ago I had a tool on my computer that allowed me\nto issue web searches and extract text from results.  That has stopped\nworking such a long time ago that I almost forgot about it.  It has\nstopped working because there is basically no competition in search, and\nGoogle does not want me to use it like that.</p><p>For instance, you can create a simple script for grammar checking right\nfrom your command line:</p><div><pre>phi4:latest\n ping -q -c1 google.com &gt;/dev/nullclaude-3-5-sonnet-latest\ncat\nllm -m  -s </pre></div><p>This script can automatically switch between a local model ( via\nOllama) and a remote one () based on internet\nconnectivity.  With a command like  in Vim, I can fix up\nsentences with a single step.</p><p>Or you can manipulate the contents of the clipboard like this:</p><pre>pbpaste | llm-spell | pbcopy &amp;&amp; say \"AI is done\"\n</pre></div><div><p>I don't let AI write my articles.  As a non-native Speaker, mistakes and\nlinguistic quirks are part of me.  That said, I do rely on AI tools for\nhelping me write.</p><p>Often, after I have made my first pass through a page, I ask an LLM to\nread through it and give me comments.  I have a Apple Note with various\nprompts I can use or I just come up with what I need in the moment.  The\nprocess is not particularly scripted out.  I basically talk to the LLM to\nfigure out what it thinks of the text, etc.</p><p>Here are some of the things I use AI for when writing:</p><ul><li> I compare the AI’s suggested revisions side by\nside with my original text and pick the changes I prefer.</li><li> AI often helps me see when my writing is too wordy.\nIn the days before AI, I often ended up with super long articles that\ndid not read well and that I did not publish.  Models like o1 are very\nhelpful in identifying things that don't need to be said.</li><li><strong>Writing Notes and finding key points:</strong> Here, I ask the AI to read\nthrough a draft “like a Computer Science 101 student” and take notes.\nThis helps me see if what it absorbed matches what I intended to\nconvey.</li><li>  I have a few prompts that asks the AI to\n“roast” or criticize my article, as if commenting on Reddit, Twitter,\nor Hacker News.  Even though these critiques seem shallow, they can\nsting, and they often highlight weaknesses in my argument or lack of\nclarity.  Even if they don't necessarily impact the writing, they\nprime me for some of the feedback I inevitably receive.</li><li> If I worry there's too much jargon, I use AI to\nresolve acronyms and point out technical terms I've used without\nexplanation, helping me make the text more accessible.</li></ul></div><div><p>This is probably the bulk of what I do and it falls into three major\ncategories.</p><ul><li><strong>Debugging and summarizing:</strong> Throwing stack traces and errors at an\nAI is usually a good first step in finding out where I should look,\nwhat might be wrong.  Sometimes it fixes a problem entirely by itself.\nI also sometimes just throw a long bug report or issue at the thing to\ntry to reason through it.</li><li> Sometimes you have an output, but you don't\nhave the input.  As an example I have a little side project to write a\ncommand line tool help generator, and AI is really good at taking the\noutput, “parsing“ it and creating a structure as input.  That is a\ngood first step to then generate out the code that should match again\nthat output.</li><li> lastly it just programs really well.  It can do\nsingle code snippets, it can generate complex stuff.  Particularly for\nprototyping it's amazing.</li></ul><p>Now it's not great at all languages.  I find it performs exceptionally\nwell at Python, somewhat okay at JavaScript and horrible at Rust.\nHowever, particularly if I wanna solve an algorithmic problem, I can often\niterate in Python until I have what I want, then ask it to translate it to\nRust.  That's from my experience at least a decent way to get going\nquickly on some harder problems.</p></div><div><p>Pair programming is fantastic, but not always possible if you're\nprogramming alone at home.  An LLM can serve as a stand-in discussion\npartner&nbsp;—&nbsp;a poor man's interlocutor.  Thankfully it's actually not all\nthat poor, because it's really good at telling you what stuff is called.\nThis is most fun if you do it with voice mode, but it also works quite\nwell in text.</p><p>Here a motivating example from voice mode:</p><blockquote><p> So, do you remember if you have, like, , it always copies from\nthe start, but if you keep concatenating to the same buffer, it's really\ninefficient. So, remember what the Big-O of that is if you do it in a loop,\nand wasn't there, like, a humorous name for this kind of algorithm?</p><p> You’re thinking of the “Schlemiel the Painter’s algorithm.” It’s a\nhumorous way of describing the inefficiency of repeatedly appending to a\nstring using operations like , which copies from the start each\ntime. The Big O complexity for this operation is O(n^2) if done repeatedly\nin a loop, since each  operation takes time proportional to the\ncurrent length of the string.</p></blockquote><p>It's also fun and educational for my kids.  They ask a lot of questions,\nand ChatGPT can tailor its explanations to their age level.  If the\nexplanation is still too advanced, I can immediately ask it to simplify\nfurther.  If it was too dumbed down, I can make it go the other way.  Now\nagain, there is always a risk that it gets it wrong, but that is okay.\nPart of all of this is to convey to the children the idea that we need to\nvalidate it and that being critical is important.</p><p>What makes ChatGPT so enjoyable here is that it's able to keep the\nconversation going — it has state.  Answered in large metric numbers?  Can\nalways ask it to scale to elephants or soccer fields.</p><p>ChatGPT is also incredibly helpful when having to work with multiple\nlanguages.  For a recent example, my kids have Greek friends and we tried\nto understand the difference between some Greek words that came up.  I\nhave no idea how to write it, Google translate does not understand my\nattempts of pronouncing them either.  However, ChatGPT does.  If I ask it\nin voice mode what “pa-me-spee-tee” in Greek means it knows what I tried\nto mumble and replies in a helpful manner.</p><p>Lastly the use on the go.  Sometimes I'm just not in a position where I\ncan actually write it down on a keyboard, but if I basically talk to\nChatGPT, it can transcribe it down and it will also remove some of my\n“um's” and it will just be there and I can copy-paste it later and edit\nit.  (To prove a point, I transcribed the previous sentence with the\nmobile app).  This is a very different experience than transcribing on iOS\nnatively.  It understands enough context of what I'm babbling that it will\nstart and stop transcribing.  Now this is not perfect, but pretty damn\ngood and incredibly helpful.</p><p>The multilingual aspect is particularly helpful because our family is\nmultilingual.  Being able to fluidly switch between German, Russian and\nEnglish is such a refreshing experience.</p></div><div><p>I mentioned earlier that I don't let LLMs write my texts.  I also don't\nuse AI to make illustrations, though I have in the past.  The reason is\nthat there is a certain style that goes along with these illustrations,\nwhich is just incredibly off-putting.  They are noticeably AI-generated,\nand typically quite low-quality.  People have taken to calling these\nimages “AI slop” and I personally respond really badly to it.  When\nsomeone throws me a pull request, an email or a text message that is\nobviously AI-generated without disclosing this, I immediately have a very\nlow opinion of them.</p><p>Slop like hallucinations are a problem, but they are only a problem if you\ndon't use your brain.  Even the worst slop can be the foundation of\nreally good content.  I'm a horrible artist, but I can use Illustrator.\nEven an AI slop image can help me trace the person in the pose I wanted.\nLikewise you can throw your notes into a document and let the AI imagine a\nstory around it.  You probably can't use that story right away, but you\ncan use it as potential inspiration.</p></div><div><p>AI tools, at their best, feel less like disruptive and dark magic and more\nlike a natural extension of the creative process as long as you see them\nas curious collaborators.  My approach isn't about outsourcing thinking,\nbut augmenting it: using LLMs to accelerate grunt work, untangle mental\nknots, and prototype ideas faster.  Skepticism is healthy, but dismissing\nAI outright risks missing its potential as a multiplier for those willing\nto engage critically.</p></div>","contentLength":14540,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mini-R1: Reproduce Deepseek R1 „aha moment“ a RL tutorial","url":"https://www.philschmid.de/mini-deepseek-r1","date":1738195200,"author":"","guid":15,"unread":true,"content":"<article>Reproduce Deepseek R1 „aha moment“ and train an open model using reinforcement learning trying to teach it self-verification and search abilities all on its own to solve the Countdown Game.</article>","contentLength":193,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Embeddings in GenAI Products","url":"https://martinfowler.com/articles/gen-ai-patterns/#embedding","date":1738166100,"author":"Martin Fowler","guid":185,"unread":true,"content":"<p>GenAI systems, like many modern AI approaches, have to handle vast\n      quantities of data, and find similarities between elements in an image or\n      chunk of words.  and I describe a key tool\n      to do this - <a href=\"https://martinfowler.com/articles/gen-ai-patterns/#embedding\">Embeddings</a> - transforming large data blocks into\n      numeric vectors so that embeddings near each other represent related\n      concepts</p>","contentLength":353,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bliki: Forest And Desert","url":"https://martinfowler.com/bliki/ForestAndDesert.html","date":1738155600,"author":"Martin Fowler","guid":186,"unread":true,"content":"<div><img src=\"https://martinfowler.com/bliki/images/forest-desert.png\"></div><p>The Forest and the Desert is a metaphor for thinking about software\n  development processes, developed by Beth Andres-Beck and hir father Kent Beck.\n  It posits that two communities of software developers have great difficulty\n  communicating to each other because they live in very different contexts, so\n  advice that applies to one sounds like nonsense to the other.</p><p>The desert is the common world of software development, where bugs are\n  plentiful, skill isn't cultivated, and communications with users is difficult.\n  The forest is the world of a well-run team that uses something like <a href=\"https://martinfowler.com/bliki/ExtremeProgramming.html\">Extreme Programming</a>, where developers swiftly put changes into\n  production, protected by their tests, code is invested in to keep it healthy,\n  and there is regular contact with The Customer.</p><p>Clearly Beth and Kent prefer The Forest (as do I). But the metaphor is more\n  about how description of The Forest and the advice for how to work there often\n  sounds nonsensical to those whose only experience is The Desert. It reminds us\n  that any lessons we draw about software development practice, or architectural\n  patterns, are governed by the context that we experienced them. It is possible\n  to change Desert into Forest, but it's difficult - often requiring people to do\n  things that are both hard and counter-intuitive. (It seems sadly easier for\n  The Forest to submit to desertification.) </p><p>In this framing I'm definitely a Forest Dweller, and seek with Thoughtworks\n  to cultivate a healthy forest for us and our clients. I work to explain The Forest to Desert\n  Dwellers, and help my fellow Forest Dwellers to make their forest even more\n  plentiful.</p><div><p>Kent Beck supplied the image, which he may have painstakingly drew pixel by\n    pixel. Or not.</p></div>","contentLength":1742,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Risky Business #777 -- It's SonicWall's turn","url":"https://risky.biz/RB777/","date":1738121388,"author":"","guid":782,"unread":true,"content":"<article></article>","contentLength":0,"flags":null,"enclosureUrl":"https://dts.podtrac.com/redirect.mp3/media3.risky.biz/RB777.mp3","enclosureMime":"","commentsUrl":null},{"title":"Computing with tuple types in TypeScript","url":"https://2ality.com/2025/01/typescript-tuples.html","date":1738108800,"author":"Dr. Axel Rauschmayer","guid":197,"unread":true,"content":"<p>JavaScript’s Arrays are so flexible that TypeScript provides two different kinds of types for handling them:</p><ul><li>Array types for arbitrary-length sequences of values that all have the same type – e.g.: </li><li>Tuple types for fixed-length sequences of values where each one may have a different type – e.g.: <code>[number, string, boolean]</code></li></ul><p>In this blog post, we look at the latter – especially how to compute with tuples at the type level.</p>","contentLength":427,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Emerging Patterns in Building GenAI Products","url":"https://martinfowler.com/articles/gen-ai-patterns/","date":1738068180,"author":"Martin Fowler","guid":184,"unread":true,"content":"<p>Everyone is fascinated about using generative AI these days, and my\n      colleagues are no exception. Some of them have had the opportunity to put\n      these system into practice, both as proof-of-concept, and more importantly\n      as production system. I've known  for\n      many years as a technology leader in India, he's been assembling the\n      lessons we've learned and I've worked with him to describe them as\n      patterns.</p><p>In this first installment, we look the limits of the base case of\n      Direct Prompting, and how we might assess the capability of a system using\n      Evals.</p>","contentLength":595,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Long Polling vs WebSockets","url":"https://blog.algomaster.io/p/long-polling-vs-websockets","date":1738038640,"author":"Ashish Pratap Singh","guid":746,"unread":true,"content":"<p>Whether you are playing an online game or chatting with a friend—updates appear in real-time without hitting .</p><p>Behind these seamless experiences lies a critical engineering decision: <strong>how to push real-time updates from servers to clients</strong>.</p><p>The traditional HTTP model was designed for request-response: <em>\"Client asks, server answers.\". </em>But in many real-time systems, the server needs to talk first and more often.</p><p>This is where  and  come into play—two popular methods for achieving real-time updates.</p><p>In this article, we’ll explore these two techniques, how they work, their pros and cons, and use cases.</p><p>If you’re finding this newsletter valuable and want to deepen your learning, consider becoming a .</p><p>As a paid subscriber, you'll receive an <strong>exclusive deep-dive article</strong> every week, access to a structured100+topics and interview questions, and other .</p><p>HTTP, the backbone of the web, follows a :</p><ol><li><p>The client (e.g., a browser or mobile app) sends a request to the server.</p></li><li><p>The server processes the request and sends back a response.</p></li></ol><p>This model is simple and works for many use-cases, but it has limitations:</p><ul><li><p> With plain HTTP, the server cannot proactively push data to the client. The client has to request the data periodically.</p></li><li><p> HTTP is stateless, meaning each request stands alone with no persistent connection to the server. This can be problematic if you need continuous exchange of data.</p></li></ul><p>To build truly real-time features—live chat, financial tickers, or gaming updates—you need a mechanism where the server can instantly notify the client when something changes.</p><p> is a technique that mimics real-time behavior by keeping HTTP requests open until the server has data.</p><p>Long Polling is an enhancement over traditional polling. In regular polling, the client repeatedly sends requests at fixed intervals (e.g., every second) to check for updates. This can be wasteful if no new data exists. </p><p>Long Polling tweaks this approach: the client asks the server for data and then “waits” until the server has something new to return or until a timeout occurs.</p><h3>How Does Long Polling Work?</h3><ol><li><p> to the server, expecting new data.</p></li><li><p><strong>Server holds the request open</strong> until it has an update or a timeout is reached.</p><ul><li><p>If there's new data, the server immediately responds.</p></li><li><p>If there’s no new data and the timeout is reached, the server responds with an empty or minimal message.</p></li></ul></li><li><p>Once the client receives a response—new data or a timeout—it <strong>immediately sends a new request</strong> to the server to keep the connection loop going.</p></li></ol><ul><li><p>Simple to implement (uses standard HTTP).</p></li><li><p>Supported universally since it uses standard HTTP, and it works reliably through firewalls and proxies.</p></li></ul><ul><li><p>Higher latency after each update (client must re-establish connection).</p></li><li><p>Resource-heavy on servers (many open hanging requests).</p></li></ul><ul><li><p>Simple chat or comment systems where real-time but slightly delayed updates (near real-time) are acceptable.</p></li><li><p>Notification systems for less frequent updates (e.g., Gmail’s \"new email\" alert).</p></li><li><p>Legacy systems where WebSockets aren’t feasible.</p></li></ul><h3>Code Example (JavaScript)</h3><p> provide a <strong>full-duplex, persistent connection</strong> between the client and the server.</p><p>Once established, both parties can send data to each other at any time, without the overhead of repeated HTTP requests.</p><ol><li><p> Client sends an HTTP request with .</p></li><li><p>: If supported, the server upgrades the connection to WebSocket (switching from  to ). After the handshake, client and server keep a TCP socket open for communication.</p></li><li><p><strong>Full-Duplex Communication:</strong> Once upgraded, data can be exchanged bidirectionally in real time until either side closes the connection.</p></li></ol><ol><li><p>Ultra-low latency (no repeated handshakes).</p></li><li><p>Lower overhead since there’s only one persistent connection rather than repeated HTTP requests.</p></li><li><p>Scalable for real-time applications that need to support large number of concurrent users.</p></li></ol><ol><li><p>More complex setup (requires the client and server to support WebSocket).</p></li><li><p>Some proxies and firewalls may not allow WebSocket traffic.</p></li><li><p>Complexity in implementation and handling reconnections/errors.</p></li><li><p>Server resource usage might grow if you have a large number of concurrent connections.</p></li></ol><ol><li><p>Live chat and collaboration tools (Slack, Google Docs, etc.).</p></li><li><p>Multiplayer online games with real-time state synchronization.</p></li><li><p>Live sports/financial dashboards that need to push frequent updates.</p></li></ol><h3>Code Example (JavaScript)</h3><p>Both methods achieve real-time updates, but your choice depends on your project’s requirements:</p><ol><li><ul><li><p> is easier to implement using standard libraries. Any environment that supports HTTP can handle it, often without extra packages.</p></li><li><p> require a bit more setup and a capable proxy environment (e.g., support in Nginx or HAProxy). However, many frameworks (e.g., Socket.io) simplify the process significantly.</p></li></ul></li><li><p><strong>Scalability and Performance</strong></p><ul><li><p> can become resource-intensive with a large number of simultaneous clients, due to multiple open connections waiting on the server side.</p></li><li><p> offer a more efficient, persistent connection and scale better for heavy, frequent data streams.</p></li></ul></li><li><ul><li><p> fits scenarios where data updates aren’t super frequent. If new data arrives every few seconds or minutes, long polling might be enough.</p></li><li><p> are better for high-frequency updates or two-way communication (e.g., multiple participants editing a document or interacting in a game).</p></li></ul></li><li><ul><li><p> typically works even in older networks or those with strict firewalls.</p></li><li><p> might face issues in certain corporate or older mobile environments, though this is less of a problem as the standard becomes more widespread.</p></li></ul></li></ol><blockquote><p>While both achieve real-time communication, WebSockets are generally more efficient for truly real-time applications, while Long Polling can be simpler to implement for less demanding scenarios.</p></blockquote><h4><strong>1. Server-Sent Events (SSE)</strong></h4><ul><li><p>Allows the server to push messages to the client over HTTP.</p></li><li><p>It's simpler than WebSockets for one-way communication, but not full-duplex.</p></li><li><p>Best suited for use cases like news feeds, real-time notifications, and status updates.</p></li></ul><ul><li><p>Commonly used in IoT for lightweight publish-subscribe messaging.</p></li><li><p>Specialized for device-to-device or device-to-server communication with minimal overhead.</p></li></ul><h4><strong>3. Libraries like Socket.io</strong></h4><ul><li><p>Provides an abstraction over WebSockets for easier real-time communication.</p></li><li><p>Automatically falls back to long polling if WebSockets are unsupported.</p></li><li><p>Ensures cross-browser compatibility with robust and reliable performance.</p></li></ul><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><p>If you have any questions or suggestions, leave a comment.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/scalability?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQwMDc4MDk0LCJpYXQiOjE3Mzc1MzgxODMsImV4cCI6MTc0MDEzMDE4MywiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.xroFXQDDEPvo2FWnnt-G2Ji9MzYIDtJ68NRQX6sT8x8&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re enjoying this newsletter and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":6609,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/90181ae6-4dcb-456f-a43a-7824d97c740b_2002x1472.png","enclosureMime":"","commentsUrl":null},{"title":"Podcast with Luca Rossi","url":"https://refactoring.fm/p/growing-the-development-forest-with","date":1737741660,"author":"Martin Fowler","guid":183,"unread":true,"content":"<p>Luca Rossi hosts a podcast (and newsletter) called Refactoring, so it's\n      obvious that we have some interests in common. The tile comes from me\n      leaning heavily on Beth Anders-Beck and Kent Beck's metaphor of <a href=\"https://refactoring.fm/bliki/ForestAndDesert.html\">The Forest and The Desert</a>. We talk\n      about the impact of AI on software development, the metaphor of technical\n      debt, and the current state of agile software development.</p>","contentLength":397,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Template literal types in TypeScript: parsing during type checking and more","url":"https://2ality.com/2025/01/template-literal-types.html","date":1737676800,"author":"Dr. Axel Rauschmayer","guid":196,"unread":true,"content":"<p>In this blog post, we take a closer look at template literal types in TypeScript: While their syntax is similar to JavaScript’s template literals, they operate at the type level. Their use cases include:</p><ul><li>Static syntax checking for string literals</li><li>Transforming the casing of property names (e.g. from hyphen case to camel case)</li><li>Concisely specifying large string literal union types</li></ul>","contentLength":379,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Build It Yourself","url":"http://lucumr.pocoo.org/2025/1/24/build-it-yourself","date":1737676800,"author":"Armin Ronacher","guid":343,"unread":true,"content":"<p>Another day, another <a href=\"http://lucumr.pocoo.org/2016/3/24/open-source-trust-scaling/\">rant</a><a href=\"http://lucumr.pocoo.org/2022/1/10/dependency-risk-and-funding/\">about</a><a href=\"http://lucumr.pocoo.org/2024/3/26/rust-cdo/\">dependencies</a>. from me.  This time I will ask you that we\nstart and support a vibe shift when it comes to dependencies.</p><p>You're probably familiar with the concept of “dependency churn.”  It's that\nnever-ending treadmill of updates, patches, audits, and transitive\ndependencies that we as developers love to casually install in the name of\nproductivity.  Who doesn't enjoy waiting for yet another \njust so you can get that fix for a bug you don't even have?</p><p>It's a plague in most ecosystems with good packaging solutions.\nJavaScript and Rust are particularly badly affected by that.  A brand new\nTokio project drags in 28 crates, a new Rocket project balloons that to\n172, and a little template engine like MiniJinja can exist with just a\nsingle dependency — while its CLI variant slurps up 142.</p><p>If that doesn't sound like a big deal, let's consider <a href=\"https://crates.io/crates/terminal_size\">terminal_size</a>.  It is a crate that does\nexactly what its name suggests: it figures out your terminal dimensions.\nThe underlying APIs it uses have effectively been stable since the earliest days of computing\nterminals—what, 50 years or so? And yet, for one function, terminal-size\nmanages to introduce three or four additional crates, depending on your\noperating system.  That triggers a whole chain reaction, so you end up\ncompiling thousands of other functions just to figure out if your terminal\nis 80x25 or 120x40.  That crate had 26 releases.  My own version of that\nthat I have stuck away in a project from 10 years ago still works without\na single update.  Because shocker: nothing about figuring out terminal\nsizes has changed.  </p><p>So why does  have so many updates if it's so stable?\nBecause it's build on top of platform abstraction libraries that\nconstantly churn, so it needs to update to avoid code duplication and\nblowing up compile times even more.</p><p>But “big supply chain” will tell you that you must do it this way.  Don't\nyou dare to copy paste that function into your library.  Or don't you date\nto use “unsafe” yourself.  You're not qualified enough to write unsafe\ncode, let the platform abstraction architects do that.  Otherwise someone\n<a href=\"https://github.com/geiger-rs/cargo-geiger\">will slap you</a>.  There are\nentire companies who are making a living of supplying you with the tools\nneeded to deal with your dependency mess.  In the name of security, we're\npushed to having dependencies and keeping them up to date, despite most of\nthose dependencies being the primary source of security problems.</p><p>The goal of code in many ways should be to be written in a way that it\ndoes not need updates.  It should eventually achieve some level of\nstability.  In the Rust ecosystem stable code is punished.  If you have a\nperfectly working dependency but you have a somewhat inactive bug tracker,\nRUSTSEC will come by and <a href=\"http://lucumr.pocoo.org/2024/3/26/rust-cdo/\">give you a chunk rating</a>.</p><p>But there  a simpler path.  You write code yourself.  Sure, it's more\nwork up front, but once it's written, it's done. No new crates, no waiting\nfor upsteam authors to fix that edge case.  If it's broken for you, you\nfix it yourself.  Code that works doesn't necessarily need the\nmaintenance treadmill.  Your code has a corner case?  Who cares.  This is\nthat vibe shift we need in the Rust world: celebrating fewer dependencies\nrather than more.</p><p>We're at a point in the most ecosystems where pulling in libraries is not\njust the default action, it's seen positively: “Look how modular and\ncomposable my code is!”  Actually, it might just be a symptom of never\nwanting to type out more than a few lines.</p><p>Now one will make the argument that it takes so much time to write all of\nthis.  It's 2025 and it's faster for me to have ChatGPT or Cursor whip up\na dependency free implementation of these common functions, than it is for\nme to start figuring out a dependency.  And it makes sense as for many\nsuch small functions the maintenance overhead is tiny and much lower than\nactually dealing with constant upgrading of dependencies.  The code is just\na few lines and you also get the benefit of no longer need to compile\nthousands of lines of other people's code for a single function.</p><p>But let's face it: corporate code review culture has also has infected\nOpen Source software.  Companies are more likely to reward engineers than\nscold them for pulling in that new “shiny library” that solves the problem\nthey never actually had.  That creates problems, so dependabot and friends\nwere born.  Today I just dread getting dependabot pull requests but on\nprojects but I have to accept it.  I'm part of an ecosystem with my stuff\nand that ecosystem is all about churn, churn, churn.  In companies you can\nalso keep entire internal engineering teams busy with vendoring\ndependencies, internal audits and upgrading things throughout the company.</p><p>Fighting this fight is incredibly hard!  Every new hire has been trained\non the idea that dependencies are great, that code reuse is great.  That\nhaving old code sitting around is a sign of bad engineering culture.</p><p>It's also hard to fight this in Open Source.  Years ago I wrote <a href=\"https://crates.io/crates/sha1_smol\">sha1-smol</a> which originally was just called\n.  It became the standard crate to calculate SHA1 hashes.\nEventually I was pressured to donate that package name to rust-crypto and\nto depend on the rest of the crypto ecosystem as it was so established.\nIf you want to use the new sha1 crate, you get to enjoy 10 dependencies.\nBut there was just no way around it, because that name in the registry is\nprecious and people also wanted to have trait compatibility.  It feels\ntiring to be the only person in a conversation pushing to keep the churn\ndown and dependencies low.</p><p>It's time to have a new perspective: we should give kudos to engineers who\nwrite a small function themselves instead of hooking in a transitive web\nof crates.  We should be suspicious of big crate graphs.  Celebrated are\nthe minimal dependencies, the humble function that just quietly does the\njob, the code that doesn't need to be touched for years because it was\ndone right once.</p><p>And sure, it's not black and white.  There are the important libraries\nthat solve hard problems.  Graphics libraries that abstract over complex\ndrivers, implementations of protocols like HTTP and QUIC.  I won't be able\nto get rid of tokio and I have no desire to.  But when you end up using\none function, but you compile hundreds, some alarm bell should go off.</p><p>We need that vibe shift.  To celebrate building it yourself when it's\nappropriate to do so.  To give credit to library authors who build low to\nno-dependency Open Source libraries.</p><p>For instance minijinja celebrates it in the readme:</p><pre>$ cargo tree\nminimal v0.1.0 (examples/minimal)\n└── minijinja v2.6.0 (minijinja)\n    └── serde v1.0.144\n</pre><p>And it has a PR to eventually <a href=\"https://github.com/mitsuhiko/minijinja/pull/539\">get rid of the last dependency</a>.  And sometime this\nyear I will make it my goal to go ahead proudly and trim down all that fat\nin my projects.</p>","contentLength":6833,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Master the Art of REST API Design","url":"https://blog.algomaster.io/p/master-the-art-of-rest-api-design","date":1737610478,"author":"Ashish Pratap Singh","guid":745,"unread":true,"content":"<p> is one of the most crucial steps in  and a key topic of discussion in .</p><p>A well-designed <a href=\"https://blog.algomaster.io/p/whats-an-api\">API</a> allows developers to easily integrate with a system while ensuring scalability and security.</p><p>Over the years, various  have emerged, including <strong>REST, GraphQL, gRPC, Webhooks and SOAP,</strong> each designed to address different needs.</p><p>However,  continue to dominate web development due to their simplicity, scalability, flexibility, widespread adoption and alignment with HTTP standards.</p><p>In this article, we will dive into covering:</p><ul><li><p> for building a well-structured, scalable, and secure RESTful API.</p></li><li><p><strong>Performance optimization techniques</strong> to enhance API efficiency and response times.</p></li></ul><p>REST (<strong>Representational State Transfer</strong>) is an architectural style for designing web services that enable communication between clients (e.g., web browsers, mobile apps) and servers over the .</p><p>REST uses HTTP methods (GET, POST, PUT, DELETE, etc.) to <strong>retrieve, create, update, and delete</strong> resources.</p><p>To build a well-designed REST APIyou must first understand the fundamentals of theHTTP protocol.</p><h3>1. HTTP Methods (Verbs) in REST APIs</h3><p>HTTP provides a set of  that define the type of operation to be performed on a resource.</p><p>In RESTful architectures, these methods typically map to CRUD operations:</p><p>It’s essential to use the correct HTTP method to make your API clear and intuitive. For example,  signals a read-only request to developers and should never modify server data, while  indicates data creation or an action that results in a change.</p><h3>2. REST is Resource-Oriented</h3><p>In RESTful API design, data is represented as , and each resource is identified by a <strong>Uniform Resource Identifier (URI)</strong>.</p><ul><li><p>→ A collection (or list) of books</p></li><li><p> → A specific book with ID 123</p></li></ul><p>An  is a combination of:</p><ul><li><p>An HTTP method (GET, POST, PUT etc.)</p></li><li><p>A resource URI (, )</p></li></ul><p>Each endpoint represents a specific operation on a resource.</p><ul><li><p> → Fetch all books</p></li><li><p> → Create a new book</p></li><li><p> → Delete the book with ID 123</p></li></ul><p>Using clear and consistent endpoints helps developers quickly understand how to interact with your API.</p><h3>4. HTTP Status Codes: Understanding API Responses</h3><p>Each API response includes an , which indicates the result of the request.</p><p>Using meaningful status codes is important for helping consumers of your API understand why a request might have failed and how they can fix or retry it.</p><p>Common status codes include:</p><ul><li><p>: The request was successfully received and processed.</p><ul><li><p>: The request succeeded.</p></li><li><p>: A new resource was successfully created.</p></li><li><p>: The request succeeded, but there is no content to return.</p></li></ul></li><li><p>: Further action is needed to complete the request (e.g., a different endpoint or resource location).</p></li><li><p>: There was an error in the request sent by the client.</p><ul><li><p>: The request was malformed or invalid.</p></li><li><p>: Authentication is required or has failed.</p></li><li><p>: The client does not have permission to access the resource.</p></li><li><p>: The requested resource does not exist.</p></li><li><p>: Rate limit exceeded.</p></li></ul></li><li><p>: The server encountered an error while processing the request.</p><ul><li><p><strong>500 Internal Server Error</strong>: A general error occurred on the server.</p></li><li><p>: The server is currently unable to handle the request, often due to maintenance or overload.</p></li></ul></li></ul><h2><strong>1. Define Clear Resource Naming Conventions</strong></h2><p>Using a <strong>consistent, intuitive, and hierarchical structure</strong> for API endpoints improves both readability and usability. The goal is to help developers quickly understand how to interact with your API without extensive documentation.</p><p>Since REST is resource-oriented, focus on  (nouns) rather than  (verbs) for your endpoints. The HTTP methods (, , etc.) already describe the action, so using verbs in the URL are redundant.</p><pre><code><code>GET /getAllUsers\nPOST /createNewOrder\nDELETE /removeProduct/123</code></code></pre><pre><code>GET /users\nPOST /orders\nDELETE /products/123</code></pre>","contentLength":3656,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64780231-6a91-4d72-8ea2-159d4cd71f4e_1504x1056.png","enclosureMime":"","commentsUrl":null},{"title":"How to align open LLMs in 2025 with DPO and and synthetic data","url":"https://www.philschmid.de/rl-with-llms-in-2025-dpo","date":1737590400,"author":"","guid":14,"unread":true,"content":"<article>Learn how to align LLMs using Hugging Face TRL and RLHF through Direct Preference Optimization (DPO) and on-policy synthetic data.</article>","contentLength":130,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Codemods in other languages","url":"https://martinfowler.com/articles/codemods-api-refactoring.html#CodemodsInOtherLanguages","date":1737561240,"author":"Martin Fowler","guid":182,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Risky Business #776 -- Trump will flex American cyber muscles","url":"https://risky.biz/RB776/","date":1737515895,"author":"","guid":781,"unread":true,"content":"<article></article>","contentLength":0,"flags":null,"enclosureUrl":"https://dts.podtrac.com/redirect.mp3/media3.risky.biz/RB776.mp3","enclosureMime":"","commentsUrl":null},{"title":"Pre-RFC - Rename annotations","url":"https://poignardazur.github.io//2025/01/22/rename-annotations/","date":1737504000,"author":"Olivier Faure","guid":743,"unread":true,"content":"<p>Let’s imagine you’re writing a crate.</p><p>Your crate has a single  file, with two modules and an arbitrary number of items:</p><div><div><pre><code></code></pre></div></div><p>After a while, you decide that Foobar should really be exported from the  module. It’s a breaking change, but you’re fine with releasing a new major version:</p><div><div><pre><code></code></pre></div></div><p>Any user previously importing from your crate will get this error when they bump the version number:</p><div><div><pre><code>error[E0432]: unresolved import `best_crate::bar::Foobar`\n  --&gt; src/lib.rs:12:5\n   |\n12 | use best_crate::bar::Foobar;\n   |     ^^^^^^^^^^^^^^^^^^^^^^^ no `Foobar` in `best_crate::bar`\n   |\nhelp: consider importing this struct instead\n   |\n12 | use best_crate::foo::Foobar;\n   |     ~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre></div></div><p>This isn’t ideal, but at least there’s the “consider importing this instead” message giving these users an easy way to fix this.</p><p>But now let’s say you decide that “Foobar” is a terrible name, and your struct should really be named “Foofoo” instead for consistency:</p><div><div><pre><code></code></pre></div></div><p>Now your users will get this message:</p><div><div><pre><code>error[E0432]: unresolved import `best_crate::bar::Foobar`\n  --&gt; src/lib.rs:12:5\n   |\n12 | use best_crate::bar::Foobar;\n   |     ^^^^^^^^^^^^^^^^^^^^^^^ no `Foobar` in `best_crate::bar`\n</code></pre></div></div><p>No message to help them figure out what to use instead.</p><p>Rust should have an attribute to inform the compiler that an item previously existed, but has been moved and/or renamed:</p><div><div><pre><code></code></pre></div></div><p>You might want to put the attribute on the “new” item instead, in which case the syntax would be:</p><div><div><pre><code></code></pre></div></div><p>You’d probably want both, for cases where either the module of origin is removed, or the destination is no longer in the same crate (e.g. because you’ve split your crate into sub-crates).</p><p>This diagnostic could help the compiler give more helpful error messages:</p><div><div><pre><code>error[E0432]: unresolved import `best_crate::bar::Foobar`\n  --&gt; src/lib.rs:12:5\n   |\n12 | use best_crate::bar::Foobar;\n   |     ^^^^^^^^^^^^^^^^^^^^^^^ no `Foobar` in `best_crate::bar`\n   |\nhelp: this item has been renamed to `best_crate::foo::Foofoo`\n   |\n12 | use best_crate::foo::Foofoo;\n   |     ~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre></div></div><p>Because the compiler is  that this is the correct move and not just guessing based on name similarity,  and similar tools would be able to automatically apply the rename.</p><p>Rename annotations would be helpful as a “grace period” after a crate’s major version change, but they would also be useful for purely internal refactors, using  to change  directives throughout your codebase.</p><p>All in all, this feels like a pretty useful feature which, thanks to the  namespace’s relaxed constraints, could be implemented relatively swiftly in the Rust toolchain.</p>","contentLength":2615,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What's an API?","url":"https://blog.algomaster.io/p/whats-an-api","date":1737437464,"author":"Ashish Pratap Singh","guid":744,"unread":true,"content":"<p>API stands for <strong>Application Programming Interface</strong>.</p><p>At its core, an API is a  that takes an  and gives you predictable </p><p>Think of an API as a  that enables applications to interact <strong>without needing direct access to each other's code or database</strong>.</p><p>Almost every digital service you use today—social media, e-commerce, online banking, ride-hailing apps—all of them are a bunch of APIs working together.</p><ul><li><p> – If you provide a city name as input (), the API returns the <strong>current temperature, humidity, and weather conditions</strong>.</p></li><li><p> – If you provide a <strong>pickup and destination address</strong>, the API finds the  and calculates the estimated fare.</p></li><li><p> – If you provide a list of numbers (), the API returns the  ().</p></li></ul><p>When engineers build APIs, they clearly define <strong>what inputs the API accepts</strong> and , ensuring consistent behavior across different applications.</p><p>APIs follow a simple  model:</p><ul><li><p>A client (such as a web app or mobile app) makes a request to an API.</p></li><li><p>The API (hosted on an API server) processes the request, interacts with the necessary databases or services, and prepares a response.</p></li><li><p>The API sends the response back to the client in a structured format (usually JSON or XML).</p></li></ul><p>Every API requires , and passing incorrect data can result in errors.</p><p>For example: If you tried putting your name into the Google Maps API as an input, that wouldn’t work very well.</p><p>Some APIs also <strong>require inputs in a specific format</strong>.</p><p>Example: The  might need the input as  instead of .</p><p>APIs often  to ensure they are correct before processing them, which helps maintain .</p><p>Just as APIs require , they also return .</p><p>For example, the  always returns <strong>coordinates in the same format</strong>.</p><pre><code>{   \"latitude\": 40.6892,   \"longitude\": -74.0445 }</code></pre><p>If the API can’t find the location, it provides an error response explaining why.</p><pre><code>{   \"error\": \"Invalid address format\",   \"code\": 400 }</code></pre><p>If you’re finding this newsletter valuable and want to deepen your learning, consider becoming a .</p><p>As a paid subscriber, you'll receive an <strong>exclusive deep-dive article</strong> every week, access to a structured100+topics and interview questions, and other .</p><p>The apps you use every day—whether it's <strong>Gmail, Instagram, Uber, or Spotify</strong>—are essentially <strong>a collection of APIs with a polished user interface (UI) on top</strong>.</p><p>Most applications follow the <strong>frontend/backend architecture</strong>, where:</p><ul><li><p>The  consists of APIs that handle <strong>data processing, business logic, and communication with databases</strong>.</p></li><li><p>The  is a <strong>graphical user interface (GUI)</strong> that interacts with these APIs, making applications user-friendly and accessible <strong>without requiring users to write code</strong>.</p></li></ul><p>Let’s break this down with a real-world example: .</p><p>Before the Uber app existed as a sleek, user-friendly experience, the company first built <strong>the core APIs that power ride-hailing services:</strong></p><ul><li><p>Calculating Fares &amp; Routes</p></li><li><p>Matching Riders &amp; Drivers</p></li></ul><p>These APIs run on Uber’s servers, forming the . Every time you request a ride, track your driver, or make a payment, these backend APIs handle the request.</p><p> are responsible for optimizing these APIs, improving ride-matching algorithms, securing transactions, and ensuring a smooth experience for millions of users.</p><p>The backend APIs handle , but they —which isn't practical for everyday users. That’s why companies build a <strong>frontend (user interface)</strong> on top of these APIs, allowing users to interact with the system .</p><p>When you enter your pickup &amp; destination address, the frontend sends an API request to  and displays available cars.</p><p>Once the trip is complete, the frontend may call the process payment API to display the receipt.</p><p>APIs come in different forms depending on , , and .</p><h3>1. Open APIs (Public APIs)</h3><p>Open APIs, also known as , are accessible to external developers with minimal restrictions.</p><p>Companies provide these APIs to encourage  to integrate their services and build new applications on top of them.</p><h4><strong>Example: YouTube Data API</strong></h4><p>Normally, when you use the , it makes  to fetch your video feed, search for content, or post comments. However, YouTube also provides a  that allows developers to access some of this functionality .</p><p>For example, the  allows developers to fetch video results based on a keyword. If you send a request to the API with <code>\"machine learning tutorial\"</code> as the search term, it will return a structured response (JSON format) containing a list of relevant videos, including <strong>titles, descriptions, thumbnails, and video links</strong>.</p><p>This is incredibly useful because it enables developers to build custom applications on top of YouTube.</p><h3>2. Internal APIs (Private APIs)</h3><p>, also known as , are designed xclusively for internal use within an organization. Unlike Open APIs, these are not accessible to external developers and are used to facilitate seamless communication between different internal systems within a company.</p><p>Let’s take  as an example. When you place an order, you might assume that a single system processes your request. In reality,  (order processing, inventory, payment, logistics etc..) work together behind the scenes to fulfill your order efficiently.</p><p>Each of these APIs , but they communicate through well-defined protocols to ensure a smooth and efficient process.</p><p>Internal APIs allow companies to break down their applications into <strong>smaller, manageable services</strong>, making it easier to scale. Developers can  across different projects, reducing  and speeding up development.</p><p>The first two types of APIs we discussed—<strong>Open APIs and Internal APIs</strong>—are functional and serve  like fetching weather data or booking a ride.</p><p>But there’s another category of APIs that developers use daily:  (also called  or ).</p><p>These APIs don’t connect different applications; instead, they provide predefined functions within a programming language or framework to make development easier.</p><p>Python’s built-in list API</p><p>When working with lists, Python provides a set of <strong>built-in functions (methods) to manipulate data</strong>.</p><pre><code>numbers = [5, 3, 8, 1, 4] numbers.sort()  # API call to sort the list  fruits = [\"apple\", \"banana\"] fruits.append(\"orange\")  # API call to add an element  fruits.pop()  # API call to remove the last element</code></pre><p>Instead of writing sorting algorithms from scratch, developers can use  or  in Python.</p><p>Code APIs are not just limited to built-in programming language functions. Take , an AI/ML library. It provides a  for training machine learning models without needing to implement complex mathematical operations from scratch.</p><p>For example, creating a  using TensorFlow's API is as simple as:</p><pre><code>import tensorflow as tf model = tf.keras.Sequential([tf.keras.layers.Dense(64, activation=\"relu\")])</code></pre><p>Programming APIs abstract away complexity so that developers can focus on building solutions rather than reinventing the wheel.</p><p>APIs communicate using different <strong>protocols and architectures</strong> that define how requests are sent, how responses are formatted, and how data is exchanged between systems.</p><h3>1. REST (Representational State Transfer)</h3><p>REST is the most widely used API communication method today. It is <strong>lightweight, stateless, and scalable</strong>, making it perfect for web services and mobile applications. </p><p>REST APIs follow a set of design principles and use  (GET, POST, PUT, DELETE) to perform operations.</p><p>REST APIs are based on , and each resource is accessed through a . The API follows the , meaning the client sends a request, and the server processes it and sends a response.</p><h4>Example: REST API for a Bookstore</h4><p><strong>Retrieve a list of books (GET Request):</strong></p><pre><code>GET https://api.bookstore.com/books</code></pre><pre><code>[   { \"id\": 1, \"title\": \"Clean Code\", \"author\": \"Robert C. Martin\" },   { \"id\": 2, \"title\": \"The Pragmatic Programmer\", \"author\": \"Andrew Hunt\" } ]</code></pre><h3>2. SOAP (Simple Object Access Protocol)</h3><p>SOAP is an older API communication method that <strong>relies on XML-based messaging</strong>. </p><p>Unlike REST, which is lightweight, SOAP is more structured and secure, making it ideal for banking, healthcare, and enterprise applications.</p><p>SOAP messages are sent using  and require a <strong>WSDL (Web Services Description Language) file</strong>, which defines the API's available functions and request structure.</p><h4><strong>Example: SOAP API for a Banking Service</strong></h4><p> Fetching account balance</p><pre><code>&lt;soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:bank=\"http://bank.example.com/\"&gt;    &lt;soapenv:Header/&gt;    &lt;soapenv:Body&gt;       &lt;bank:GetAccountBalance&gt;          &lt;bank:accountNumber&gt;123456&lt;/bank:accountNumber&gt;       &lt;/bank:GetAccountBalance&gt;    &lt;/soapenv:Body&gt; &lt;/soapenv:Envelope&gt; </code></pre><pre><code>&lt;soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\"&gt;    &lt;soapenv:Body&gt;       &lt;bank:GetAccountBalanceResponse&gt;          &lt;bank:balance&gt;5000.00&lt;/bank:balance&gt;       &lt;/bank:GetAccountBalanceResponse&gt;    &lt;/soapenv:Body&gt; &lt;/soapenv:Envelope&gt;</code></pre><p>GraphQL is an alternative to REST that <strong>allows clients to request exactly the data they need</strong>, making it more efficient for modern applications. Unlike REST, which requires multiple API calls to fetch related data, GraphQL can <strong>fetch all necessary data in a single request</strong>.</p><p>Instead of predefined endpoints, GraphQL exposes a , and the client sends queries to request specific fields.</p><h4>Example: Fetching a user's profile and their recent posts in a single request.</h4><pre><code>{   user(id: 123) {     name     email     posts {       title       likes     }   } }</code></pre><pre><code>{   \"data\": {     \"user\": {       \"name\": \"Alice\",       \"email\": \"alice@example.com\",       \"posts\": [         { \"title\": \"Hello World\", \"likes\": 100 },         { \"title\": \"GraphQL is Amazing!\", \"likes\": 200 }       ]     }   } }</code></pre><p>gRPC (Google Remote Procedure Call) is a <strong>high-performance API communication method</strong> that uses <strong>Protocol Buffers (Protobuf)</strong> instead of JSON or XML, making it faster and more efficient.</p><p>gRPC uses  instead of text-based formats, reducing payload size and it supports , meaning the client and server can send data at the same time.</p><p>Using an API might seem complex at first, but it follows a simple  pattern.</p><p>Here’s a guide on<strong> how to find, access, and interact with an API</strong> step by step:</p><h3><strong>Step 1: Find an API to Use</strong></h3><p>Before using an API, you need to  for your needs. APIs are available for different services like weather data, finance, social media, etc.</p><p><strong>Official API Documentation:</strong></p><h3><strong>Step 2: Read the API Documentation</strong></h3><p>API documentation explains <strong>how to use the API, available endpoints, authentication, and response formats</strong>.</p><p>The OpenWeatherMap API allows users to fetch real-time weather data. Here's a breakdown of its key components:</p><pre><code>https://api.openweathermap.org/data/3.0/weather?q=city_name&amp;appid=YOUR_API_KEY</code></pre><ul><li><p>: City name (e.g., )</p></li><li><p>: API Key (required for access)</p></li></ul><h3><strong>Step 3: Get API Access (API Key / Authentication)</strong></h3><p>Most APIs  to prevent unauthorized access and manage usage limits.</p><h4><strong>Common Authentication Methods:</strong></h4><ul><li><p>A unique key provided by the API service</p></li><li><p>Secure login via Google, Github, etc.</p></li><li><p>Token-based authentication</p></li><li><p>Username + password (Base64 encoded)</p></li></ul><p><strong>Example: Getting an API Key (OpenWeather API)</strong></p><ul><li><p>Sign up at https://home.openweathermap.org/users/sign_up.</p></li><li><p>Go to the  section and generate a key.</p></li><li><p>Use the API key in requests:</p></li></ul><pre><code>GET https://api.openweathermap.org/data/2.5/weather?q=London&amp;appid=YOUR_API_KEY</code></pre><h3><strong>Step 4: Test the API Using Postman or cURL</strong></h3><p>Before writing code,  to see how it responds.</p><h4><strong>Option 1: Using Postman (Recommended for Beginners)</strong></h4><ul><li><p>Click , enter the API endpoint URL (<code>https://api.openweathermap.org/data/3.0/weather?q=London&amp;appid=YOUR_API_KEY</code>).</p></li><li><p>Select  as the HTTP method.</p></li><li><p>Click  and view the response in .</p></li></ul><h4><strong>Option 2: Using cURL (For Command Line Users)</strong></h4><p>You can also test APIs directly from the  using .</p><pre><code>curl -X GET \"https://api.openweathermap.org/data/3.0/weather?q=New+York&amp;appid=YOUR_API_KEY\"</code></pre><h3><strong>Step 5: Write Code to Call the API</strong></h3><p>Now that you’ve tested the API, it’s time to <strong>integrate it into your application</strong>.</p><h4><strong>Example: Calling an API in Python</strong></h4><pre><code>import requests  url = \"https://api.openweathermap.org/data/3.0/weather?q=New York&amp;appid=YOUR_API_KEY\" response = requests.get(url)  if response.status_code == 200:     data = response.json()     print(f\"Temperature: {data['main']['temp']}°C\") else:     print(\"Error:\", response.status_code)</code></pre><ul><li><p> – Sends an API request.</p></li><li><p> – Converts response to JSON.</p></li><li><p><code>if response.status_code == 200</code> – Checks if the request was successful.</p></li></ul><h3><strong>Step 6: Handle Errors &amp; Rate Limits</strong></h3><p>APIs <strong>don’t always return perfect responses</strong>. You should handle:</p><ul><li><p> (e.g., wrong city name).</p></li><li><p> (e.g., expired API keys).</p></li><li><p> (e.g., exceeding request limits).</p></li></ul><h4><strong>Example: Handling API Errors in Python</strong></h4><pre><code>if response.status_code == 200:     data = response.json()     print(f\"Weather: {data['weather'][0]['description']}\") elif response.status_code == 401:     print(\"Error: Invalid API key\") elif response.status_code == 404:     print(\"Error: City not found\") else:     print(f\"Unexpected error: {response.status_code}\")</code></pre><h3>Step 7: Use API Responses in Your Application</h3><p>Once you fetch data from an API, you can <strong>display it dynamically in a web or mobile app</strong>.</p><p> You can build a weather dashboard using the OpenWeatherMap API.</p><ul><li><p>Fetch live weather data from the API.</p></li><li><p>Parse and extract relevant details (temperature, humidity, condition).</p></li><li><p>Display the weather report in a user-friendly format.</p></li></ul><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><p>If you have any questions or suggestions, leave a comment.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/scalability?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQwMDc4MDk0LCJpYXQiOjE3Mzc1MzgxODMsImV4cCI6MTc0MDEzMDE4MywiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.xroFXQDDEPvo2FWnnt-G2Ji9MzYIDtJ68NRQX6sT8x8&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re finding this newsletter helpful and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":13212,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/ae14a376-92a3-4ff6-a329-8e4f2a7ac9b5_1546x1074.png","enclosureMime":"","commentsUrl":null},{"title":"ECMAScript proposal: RegExp escaping","url":"https://2ality.com/2025/01/regexp-escape.html","date":1737417600,"author":"Dr. Axel Rauschmayer","guid":195,"unread":true,"content":"<p>The ECMAScript proposal <a href=\"https://github.com/tc39/proposal-regex-escaping\">“RegExp escaping”</a> (by Jordan Harband and Kevin Gibbons) specifies a function  that, given a string , creates an escaped version that matches  – if interpreted as a regular expression.</p><p>This proposal is currently at stage 3.</p>","contentLength":251,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"TypeScript enums: use cases and alternatives","url":"https://2ality.com/2025/01/typescript-enum-patterns.html","date":1737244800,"author":"Dr. Axel Rauschmayer","guid":194,"unread":true,"content":"<p>In this blog post, we take a closer look at TypeScript enums:</p><ul><li>What are their use cases?</li><li>What are the alternatives if we don’t want to use them?</li></ul><p>The blog post concludes with recommendations for what to use when.</p>","contentLength":209,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Automatic Server Reloading in Rust on Change: What is listenfd/systemfd?","url":"http://lucumr.pocoo.org/2025/1/19/what-is-systemfd","date":1737244800,"author":"Armin Ronacher","guid":342,"unread":true,"content":"<p>When I developed <a href=\"https://werkzeug.palletsprojects.com/\">Werkzeug</a> (and\nlater <a href=\"https://flask.palletsprojects.com/\">Flask</a>), the most\nimportant part of the developer experience for me was enabling fast, automatic\nreloading.  Werkzeug (and with it Flask), this is achieved by using two\nprocsses at all times.  The parent process holds on to the file descriptor\nof the socket on which the server listens, and a subprocess picks up that\nfile descriptor.  That subprocess restarts when it detects changes.  This\nensures that no matter what happens, there is no window where the browser\nreports a connection error.  At worst, the browser will hang until the\nprocess finishes reloading, after which the page loads successfully.  In\ncase the inner process fails to come up during restarts, you get an error\nmessage.</p><p>A few years ago, I wanted to accomplish the same experience for working\nwith Rust code which is why I wrote <a href=\"https://github.com/mitsuhiko/systemfd\">systemfd</a> and <a href=\"https://github.com/mitsuhiko/listenfd\">listenfd</a>.  I however realized that I\nnever really wrote here about how they work and disappointingly I think\nthose crates, and a good auto-reloading experience in Rust are largely\nunknown.</p><div><p>Firstly one needs to monitor the file system for changes.  While in theory\nI could have done this myself, there was already a tool that could do\nthat.</p><p>At the time there was <a href=\"https://crates.io/crates/cargo-watch\">cargo watch</a>.  Today one might instead use it\ntogether with the more generic <a href=\"https://github.com/watchexec/watchexec\">watchexec</a>.  Either one monitor your\nworkspace for changes and then executes a command.  So you can for\ninstance tell it to restart your program.  One of these will work:</p><pre>watchexec -r -- cargo run\ncargo watch -x run\n</pre><p>You will need a tool like that to do the watching part.  At this point I\nrecommend the more generic  which you can find on <a href=\"https://github.com/watchexec/watchexec/blob/main/doc/packages.md\">homebrew and\nelsewhere</a>.</p></div><div><p>But what about the socket?  The solution to this problem I picked comes\nfrom <a href=\"https://en.wikipedia.org/wiki/Systemd\">systemd</a>.  Systemd has a\n“protocol” that standardizes passing file descriptors from one process to\nanother through environment variables.  In systemd parlance this is called\n“socket activation,” as it allows systemd to only launch a program if\nsomeone started making a request to the socket.  This concept was\noriginally introduced by Apple as part of launchd.</p><p>To make this work with Rust, I created two crates:</p><ul><li><a href=\"https://github.com/mitsuhiko/systemfd\">systemfd</a> is the command\nline tool that opens sockets and passes them on to other programs.</li><li><a href=\"https://crates.io/crates/listenfd\">listenfd</a> is a Rust crate that\naccepts file descriptors from systemd or .</li></ul><p>It's worth noting that systemfd is not exclusivly useful to Rust.  The\nsystemd protocol can be implemented in other languages as well, meaning\nthat if you have a socket server written in Go or Python, you can also use\nsystemfd.</p><p>So here is how you use it.</p><p>First you need to add  to your project:</p><p>Then, modify your server code to accept sockets via listenfd before\nfalling back to listening itself on ports provided through command-line\narguments or configuration files.  Here is an example using  in\naxum:</p><div><pre>::::::::-&gt; -&gt; ::::::::::::::::</pre></div><p>The key point here is to accept socket 0 from the environment as a TCP\nlistener and use it if available.  If the socket is not provided (e.g.\nwhen launched without systemd/), the code falls back to opening a\nfixed port.</p></div><div><p>Finally you can use  /  together with :</p><pre>systemfd --no-pid -s http::8888 -- watchexec -r -- cargo run\nsystemfd --no-pid -s http::8888 -- cargo watch -x run\n</pre><p>This is what the parameters mean:</p><ul><li> needs to be first it's the program that opens the sockets.</li><li> is a flag prevents the PID from being passed.  This is necessary\nfor  to accept the socket.  This is a departure of the socket\npassing protocol from systemd which otherwise does not allow ports to be\npassed through another program (like ).  In short: when the\nPID information is not passed, then listenfd will accept the socket\nregardless.  Otherwise it would only accept it from the direct parent\nprocess.</li><li> tells  to open one TCP socket on port 8888.\nUsing  instead of  is a small improvement that will cause\nsystemfd to print out a URL on startup.</li><li> makes  restart the process when something\nchanges in the current working directory.</li><li> is the program that watchexec will start and re-start onm\nchanges.  In Rust this will first compile the changes and then run the\napplication.  Because we put  in, it will try to first accept\nthe socket from .</li></ul><p>The end result is that you can edit your code, and it will recompile\nautomatically and restart the server without dropping any requests.  When\nyou run it, and perform changes, it will look a bit like this:</p><pre>$ systemfd --no-pid -s http::5555 -- watchexec -r -- cargo run\n~&gt; socket http://127.0.0.1:5555/ -&gt; fd #3\n[Running: cargo run]\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.02s\n     Running `target/debug/axum-test`\n[Running: cargo run]\n   Compiling axum-test v0.1.0 (/private/tmp/axum-test)\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.52s\n     Running `target/debug/axum-test`\n</pre><p>For easier access, I recommend putting this into a  or similar\nso you can just run  and it runs the server in watch mode.</p><p>To install  you can use curl to bash:</p><pre>curl -sSfL https://github.com/mitsuhiko/systemfd/releases/latest/download/systemfd-installer.sh | sh\n</pre></div><div><p>Now how does this work on Windows?  The answer is that  and\n have a custom, proprietary protocol that also makes socket\npassing work on Windows.  That's a more complex system which involves a\nlocal RPC server.  However the system does also support Windows and the\ndetails about how it works are largely irrelevant for you as a user\n—&nbsp;unless you want to implement that protocol for another programming\nlanguage.</p></div><div><p>I really enjoy using this combination, but it can be quite frustrating to\nrequire so many commands, and the command line workflow isn't optimal.\nIdeally, this functionality would be better integrated into specific Rust\nframeworks like axum and provided through a dedicated cargo plugin.  In a\nperfect world, one could simply run , and everything\nwould work seamlessly.</p><p>However, maintaining such an integrated experience is a much more involved\neffort than what I have.  Hopefully, someone will be inspired to further\nenhance the developer experience and achieve deeper integration with Rust\nframeworks, making it more accessible and convenient for everyone.</p></div>","contentLength":6094,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Patterns of use of Vello crate","url":"https://poignardazur.github.io//2025/01/18/vello-analysis/","date":1737158400,"author":"Olivier Faure","guid":742,"unread":true,"content":"<p>This document tries to establish patterns among a list of crates and Github projects using the <a href=\"https://github.com/linebender/vello/\">Vello</a> renderer.</p><p>The crate list isn’t meant to be exhaustive, but it’s pretty large: I’ve sifted through maybe 40 or so reverse dependencies of the Vello repository, up to the point where most of the READMEs I read were along the lines of “WIP: quick experiment paint shapes with Vello”.</p><p>Don’t expect anything groundbreaking. My main focus is on common patterns among people using Vello’s <a href=\"https://docs.rs/vello/latest/vello/struct.Scene.html\"></a> API; most of this is going to be pretty dry.</p><p>I’ve mostly noticed two types of projects with Vello as a direct dependency:</p><ul><li> bridging Vello with some other format or framework, or providing wrapper functions for Vello’s API. Ex: , , etc.</li><li> that renders specific things with Vello.</li></ul><p>(Though in practice, a few blurred the lines, and a lot of projects that I put in one category or the other mostly ended up using Vello for example code or for very basic painting.)</p><p>The numbers (18 engine projects, 13 app-like projects) aren’t too surprising if you’re familiar with the “Rust has 50 game engines and 3 games” stereotype. They also match my “gut feeling” reading the code, where it feels like a lot more projects use Vello in a very systematized way, as some kind of middleware or optional backend than as a plug-and-play dependency to paint a bunch of shapes.</p><p>For instance, I saw almost no project calling the  function more than five times.</p><p>This is confounded by the fact that I only looked for direct dependents of Vello; I might have found more app projects looking for dependents of Masonry or bevy_vello. Maybe the painting-privitive-heavy code is in the dependents of one of those engine code projects I cited.</p><p>Graphite, for example, is a primitive-heavy 2D editor, but its use of Vello is bottlenecked through a middleware layer with its own internal representation.</p><p>In general, though, my impression is that the stereotype is mostly true.</p><p>Another interesting pattern is that code actually using Vello to paint things was often in amateur stub projects, which is good for our purposes: it tells us how people who have little experience with Vello end up using it.</p><h3>Fill and stroke arguments</h3><p> and  are the most used methods by a very wide margin.</p><p>As a reminder, their prototype is:</p><div><div><pre><code></code></pre></div></div><p>A lot code calling them looks like this:</p><div><div><pre><code></code></pre></div></div><p>Note the heavy usage of default values:</p><ul><li> is the default fill setting for most paint APIs.</li><li> creates a stroke with rount joins and caps, no dashes, and the given width.</li><li> is set to  for both methods.</li><li> is set to  for both methods.</li></ul><p>These patterns can be found throughout the projects I’ve linked. In total, I’ve counted:</p><ul><li>16 projects using  with ,  and .</li><li>10 projects using  with ,  and .</li><li>7 projects using  with , a transform and .</li><li>3 projects using  with , a transform and .</li></ul><p>Projects that used all the arguments of  or  were rare, and were generally written as middleware code passing these arguments from another source. For example:</p><div><div><pre><code></code></pre></div></div><p>These projects tended to have one instance code calling each Scene method in the entire repository.</p><p>Most of the projects I’ve looked at used the  and  API exclusively.\nFew of them used , , , etc.</p><p>In total, I’ve counted about a dozen projects using any of these APIs.</p><p>Those that did tended to be the “render any arbitrary SVG” kinds of projects.</p><p>Based on the above, I’d recommend having Vello export the following API:</p><div><div><pre><code></code></pre></div></div><ul><li> and  use the minimum number of arguments.</li><li> and  use an additional  argument.</li><li> and  use the full API.</li></ul><p>With this API, the  code I quoted would look like this:</p><div><div><pre><code></code></pre></div></div><p>This would also let us remove most of the helpers in  in Masonry.</p>","contentLength":3583,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Service Reliability Mathematics","url":"https://addyosmani.com/blog/service-reliability/","date":1737072000,"author":"","guid":78,"unread":true,"content":"<article>Service reliability is often reduced to a simple percentage but the reality is far more nuanced than those decimal points suggest. Lets explore what these numbers actually mean.</article>","contentLength":177,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to use Anthropic MCP Server with open LLMs, OpenAI or Google Gemini","url":"https://www.philschmid.de/mcp-example-llama","date":1737072000,"author":"","guid":12,"unread":true,"content":"<article>How to use Anthropic MCP Server with open LLMs, OpenAI or Google Gemini</article>","contentLength":71,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bite: How Deepseek R1 was trained","url":"https://www.philschmid.de/deepseek-r1","date":1737072000,"author":"","guid":13,"unread":true,"content":"<article>5 Minute Read on how Deepseek R1 was trained using Group Relative Policy Optimization (GRPO) and RL-focused multi-stage training approach.</article>","contentLength":138,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["blog"]}