{"id":"6SJ","title":"Go","displayTitle":"Go","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":115,"items":[{"title":"This is don't my first lerning.","url":"https://dev.to/consolvex/this-is-dont-my-first-lerning-279c","date":1740311946,"author":"Consolex","guid":9595,"unread":true,"content":"<p>I'am learning GOlang. \nMy English is bad, but i'am also learning Eng.</p>","contentLength":69,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"native WebP encoding version 1.0! üöÄ","url":"https://www.reddit.com/r/golang/comments/1iw8a68/native_webp_encoding_version_10/","date":1740310727,"author":"/u/Pretend-Ad1926","guid":9590,"unread":true,"content":"<p>I‚Äôm excited to announce nativewebp v1.0, a major milestone for our WebP encoder in Go! This version marks 1.0 because we now fully support the VP8L format, making nativewebp a complete solution for lossless WebP encoding. Alongside this, we‚Äôve added better compression, improved Go integration, and important bug fixes.</p><p>Here are some highlights of this release:</p><p><strong>Full VP8L Feature Support</strong></p><p>This release now fully supports all VP8L features, including LZ77, Color Caching, and transforms, ensuring more accurate and efficient encoding.</p><p><strong>Smarter Compression with Filter Selection for Predictor Transform</strong></p><p>We now analyze block entropy and automatically select the best filter per block, leading to much better compression.</p><p>nativewebp now includes a wrapper for <a href=\"http://golang.org/x/image/webp\">golang.org/x/image/webp</a>, so you can use Decode and image.Decode out of the box without extra imports.</p><p>Looking forward to your thoughts and feedback on the new release!</p>","contentLength":918,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Folang: Transpiler for F#-like functional languages ‚Äã‚Äãto Go","url":"https://www.reddit.com/r/golang/comments/1iw3tz7/folang_transpiler_for_flike_functional_languages/","date":1740292019,"author":"/u/karino2012","guid":9541,"unread":true,"content":"<p>I wrote a transpiler in Go that transpiles F#-like functional languages ‚Äã‚Äãto Go.</p><p>I design the language specifications from scratch to match Go, and named it Folang.</p><p>There are still many NYIs, but I have implemented it to the extent that it can be self-hosted, so I will post it on reddit.</p><ul><li>A transpiler that does not require anything other than Go to try</li><li>Argument types are inferred using F#-like syntax, and the arguments are generalized to become generic functions</li><li>The transpiler itself is 3600 lines of Folang code and about 500 lines of Go code</li></ul>","contentLength":546,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Practical Guide to ORM in GoFrame: From Basics to Advanced Relationships","url":"https://dev.to/jones_charles_ad50858dbc0/a-practical-guide-to-orm-in-goframe-from-basics-to-advanced-relationships-17fk","date":1740289507,"author":"Jones Charles","guid":9457,"unread":true,"content":"<p>If you're working with Go and looking for a powerful yet lightweight web framework, GoFrame might be just what you need. One of its standout features is the  package, which provides a robust ORM (Object-Relational Mapping) system. In this guide, I'll walk you through everything you need to know to effectively use ORM in your GoFrame projects.</p><ul><li>Setting up database connections</li><li>Working with transactions</li><li>Handling relationships (one-to-one, one-to-many, many-to-many)</li></ul><ul><li>Basic knowledge of Go programming</li><li>Go installed on your machine</li><li>MySQL or compatible database</li><li>Basic understanding of ORM concepts</li></ul><h2>\n  \n  \n  Getting Started: Database Configuration\n</h2><p>First things first, let's set up our database connection. GoFrame makes this super straightforward with a YAML configuration:</p><div><pre><code></code></pre></div><p>üí° : The  setting is fantastic during development as it shows you the actual SQL queries being executed. Remember to disable this in production!</p><h2>\n  \n  \n  Defining Your First Model\n</h2><p>Let's start with a simple user model. In GoFrame, models are just Go structs with special tags:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  CRUD Operations Made Easy\n</h2><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>More complex query with conditions:</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h2>\n  \n  \n  Working with Transactions\n</h2><p>Transactions are crucial for maintaining data integrity. Here's how to use them in GoFrame:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Advanced Feature: Relationships\n</h2><p>Perfect for user profiles or detailed information:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  One-to-Many Relationships\n</h3><p>Great for handling user comments or posts:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Many-to-Many Relationships\n</h3><p>Perfect for scenarios like course enrollment systems:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Best Practices and Tips üí°\n</h2><ol><li>: Include context in your database operations for better control and cancellation capabilities.</li><li>: Don't ignore error returns from database operations.</li><li> for operations that modify multiple tables.</li><li> appropriately based on your query patterns.</li><li>: Avoid putting business logic in your model structs.</li></ol><h2>\n  \n  \n  Common Gotchas to Watch Out For ‚ö†Ô∏è\n</h2><ul><li>Remember to properly close database connections</li><li>Be careful with large result sets - use pagination</li><li>Watch out for N+1 query problems</li><li>Don't forget to handle null values appropriately</li></ul><p>GoFrame's ORM system provides a powerful yet intuitive way to work with databases in Go. It strikes a great balance between functionality and simplicity, making it a solid choice for both small and large projects.</p><ul><li>Explore GoFrame's caching capabilities</li><li>Look into query optimization techniques</li><li>Learn about GoFrame's migration tools</li></ul><p>Let me know in the comments if you have any questions or if you'd like to see more GoFrame content! üöÄ</p>","contentLength":2473,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What is your logging, monitoring & observability stack for your golang app?","url":"https://www.reddit.com/r/golang/comments/1iw07rm/what_is_your_logging_monitoring_observability/","date":1740279237,"author":"/u/gwwsc","guid":9441,"unread":true,"content":"<p>My company uses papertrail for logging, prometheus and grafana for observability and monitoring.</p><p>I was not actively involved in the integration as it was done by someone else a few years ago and it works.</p><p>I want to do the same thing for my side project that I am working on for learning purpose. The thing I am confused about it should I first learn the basics about otel, collector agents etc? Or should I just dive in?</p><p>As a developer I get an itch if things are too abstracted away and I don't know how things are working. I want to understand the underlying concepts first before relying on abstraction.</p><p>What tools are you or your company using for this?</p>","contentLength":653,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Understanding Anonymous Functions in Go: A Practical Guide","url":"https://dev.to/abstractmusa/understanding-anonymous-functions-in-go-a-practical-guide-57hd","date":1740273116,"author":"Md Abu Musa","guid":9398,"unread":true,"content":"<h2><strong>What is an Anonymous Function?</strong></h2><p>An  is a function . Instead of being declared like a traditional named function, it is defined inline and assigned to a variable or executed immediately.</p><div><pre><code></code></pre></div><p>üìå Here,  holds an anonymous function that takes two integers and returns their sum.</p><h2><strong>Use Cases of Anonymous Functions</strong></h2><h3><strong>1Ô∏è‚É£ Passing Anonymous Functions as Arguments</strong></h3><p>Since functions can be passed as arguments, anonymous functions are useful for higher-order functions.</p><div><pre><code></code></pre></div><p>‚úÖ  Useful in callback functions or custom processing logic.</p><h3><strong>2Ô∏è‚É£ Using Anonymous Functions in Goroutines</strong></h3><p>Goroutines allow concurrent execution, and anonymous functions are a great way to define short-lived concurrent tasks.</p><div><pre><code></code></pre></div><p>‚úÖ  Running background tasks without defining a named function.</p><h3><strong>3Ô∏è‚É£ Returning Anonymous Functions (Closures)</strong></h3><p>Closures allow an anonymous function to capture variables from its surrounding scope.</p><div><pre><code></code></pre></div><p>‚úÖ  Creating  that retain state.</p><h3><strong>4Ô∏è‚É£ Storing Anonymous Functions in a Map</strong></h3><p>You can store anonymous functions in a map for dynamic execution.</p><div><pre><code></code></pre></div><p>‚úÖ  Implementing  or .</p><h2><strong>What is an IIFE (Immediately Invoked Function Expression)?</strong></h2><p>An <strong>IIFE (Immediately Invoked Function Expression)</strong> is an anonymous function that runs <strong>immediately after being defined</strong>.</p><div><pre><code></code></pre></div><p>‚úÖ  One-time setup logic, reducing unnecessary variable scope.</p><p>Anonymous functions in Go offer flexibility and concise coding, making them a powerful tool for:</p><ul><li><strong>Concurrent execution (Goroutines)</strong></li><li><strong>Closures (Retaining state)</strong></li><li><strong>One-time execution (IIFE)</strong></li></ul><p>By understanding and implementing anonymous functions effectively, you can write , , and  Go code.</p>","contentLength":1555,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Por que voc√™ deve repensar o uso de Regex em valida√ß√µes de strings em Go","url":"https://dev.to/renanbastos93/por-que-voce-deve-repensar-o-uso-de-regex-em-validacoes-de-strings-no-go-1cdi","date":1740269115,"author":"renanbastos93","guid":9401,"unread":true,"content":"<p>Quando falamos de valida√ß√£o de strings no Go, uma das solu√ß√µes mais comuns √© o uso de express√µes regulares (regex). No entanto, dependendo do contexto, o uso de regex pode ser menos eficiente do que alternativas mais simples. Em sistemas de alta performance, como os que lidam com grandes volumes de dados ou que precisam ser executados em ambientes com recursos limitados, √© importante considerar o impacto de cada escolha de implementa√ß√£o.</p><p>Embora regex seja uma ferramenta poderosa, sua utiliza√ß√£o indiscriminada pode resultar em impactos de performance, principalmente em Go, onde cada opera√ß√£o √© otimizada ao m√°ximo para garantir alta efici√™ncia. Neste post, vamos abordar um exemplo simples de valida√ß√£o de strings alfanum√©ricas, comparando o uso de regex com uma abordagem baseada em Unicode e explicando como otimizar o uso de regex no Go para obter melhores resultados.</p><p>O que acontece por tr√°s das cortinas: Regex vs Unicode\nA biblioteca  √© bastante √∫til, mas pode ser mais lenta do que valida√ß√µes feitas manualmente usando fun√ß√µes da biblioteca unicode. Isso ocorre porque o Go precisa compilar o regex e avaliar sua express√£o toda vez que √© usado dentro de um m√©todo. Isso consome mais tempo de CPU e mem√≥ria, especialmente em valida√ß√µes simples, como a checagem, se uma string cont√©m apenas caracteres alfanum√©ricos.</p><p>A alternativa, mais eficiente, √© iterar sobre a string e validar cada caractere individualmente, utilizando fun√ß√µes como unicode.IsLetter e unicode.IsDigit. Isso evita a sobrecarga de compilar o regex toda vez que a fun√ß√£o √© chamada e pode ser muito mais r√°pido para cen√°rios simples.</p><h2>\n  \n  \n  Exemplo pr√°tico: Comparando as abordagens\n</h2><p>Aqui est√° um exemplo em Go para comparar as duas abordagens: uma usando regex e outra utilizando Unicode diretamente.</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Implementa√ß√£o usando Unicode:\n</h3><div><pre><code></code></pre></div><h2>\n  \n  \n  Compara√ß√£o de Performance\n</h2><p>Vamos rodar alguns benchmarks para comparar a performance das duas abordagens.</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>Como voc√™ pode observar nos benchmarks acima, a vers√£o que usa Unicode √© significativamente mais r√°pida do que a vers√£o com regex. A vers√£o com Unicode realiza cerca de 18 milh√µes de opera√ß√µes por segundo, enquanto a vers√£o com regex realiza apenas cerca de 3 milh√µes.</p><p>Quando usamos regex, estamos criando e compilando uma express√£o regular toda vez que chamamos a fun√ß√£o. O processo de compila√ß√£o e execu√ß√£o da express√£o regular envolve mais passos do que simplesmente iterar sobre os caracteres da string com fun√ß√µes do unicode. Isso faz com que a execu√ß√£o com regex consuma mais tempo de CPU e mem√≥ria.</p><p>Isso n√£o significa que voc√™ deve parar de usar regex. Em casos mais complexos, onde voc√™ precisa de valida√ß√µes mais sofisticadas, regex pode ser a melhor escolha. No entanto, em valida√ß√µes simples, como a checagem de caracteres alfanum√©ricos, o uso de Unicode diretamente √© muito mais eficiente.</p><p>Dica de Performance: Compile Regex fora do m√©todo\nSe voc√™ optar por usar regex, uma boa pr√°tica √© compilar a express√£o regular fora do m√©todo, para que ela n√£o precise ser recompilada a cada chamada. Isso pode ajudar a reduzir o custo de performance de usar regex.</p><div><pre><code></code></pre></div><p>Ao compilar a express√£o regular uma vez e reutiliz√°-la, voc√™ reduz significativamente o impacto de performance.</p><p>Embora regex seja uma ferramenta poderosa e √∫til, seu uso em valida√ß√µes simples pode ser ineficiente, especialmente quando a performance √© uma prioridade. Em Go, alternativas como a utiliza√ß√£o da biblioteca unicode podem oferecer ganhos significativos de performance. Se for necess√°rio usar regex, lembre-se de compilar a express√£o regular fora do m√©todo para otimizar o desempenho.</p><p>Agora, repense como voc√™ est√° validando suas strings no seu projeto e escolha a abordagem mais eficiente para o seu caso!</p>","contentLength":3808,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Any open source project that shows a good example of unit test and integration test","url":"https://www.reddit.com/r/golang/comments/1ivv5eq/any_open_source_project_that_shows_a_good_example/","date":1740264003,"author":"/u/smartfinances","guid":9367,"unread":true,"content":"<p>As the title suggests. I have been adding various unit tests to my project but I am looking for suggestions/ideas on how to go about writing integration tests.</p><p>My project mostly entails reading from SQS, batching data based on some parameters and then writing the output to s3. probably, a very common pattern. Extending that the service reads from various SQS and batching is localised to one queue. So 10 queue creats 10 different outputs.</p><p>I am using localstack for development. I am not looking for examples of exactly the above use case but something similar that is interaction with db/external system and then giving some output would also do.</p>","contentLength":647,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Writing a file system in Go -- not FUSE, but a real FS","url":"https://www.reddit.com/r/golang/comments/1ivuz61/writing_a_file_system_in_go_not_fuse_but_a_real_fs/","date":1740263514,"author":"/u/Rich-Engineer2670","guid":9377,"unread":true,"content":"<p>I would say I'm crazy, but this both well established and redundant.....</p><p>Assume I wanted to write my own file system (education), with Golang -- not a fuse variant, but I literally am taking a file on a block device and treating it as a disk. If this were C, OK, I'd do the following:</p><ul><li>Define a binary boot block at LBA 0</li><li>Define a certain number of LBAs for boot code</li><li>Define a certain number of LBAs for partitions</li><li>Within each partition define the directories and free lists (FATs, clusters, etc...)</li><li>Have a bunch of free LBAs.</li></ul><p>In C, I could define structs and just write them out assuming they were packed. In Go, structs aren't C structs, so I need to constantly convert structs to binaries. Sure, I could use the binary package and a lot functions, but someone must have done this in a better way, or is the \"better way\" \"No, write your file systems in C....\"</p><p>I want to stay in Go, because everything else in the OS is in Go...</p>","contentLength":920,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Golang SQLite admin tool","url":"https://github.com/joelseq/sqliteadmin-go","date":1740258532,"author":"/u/lAdddd","guid":9320,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1ivt55s/golang_sqlite_admin_tool/"},{"title":"üöÄ Go Interface Nil Pitfall: Why Your Nil Check is Failing (and How to Fix It!) üîç","url":"https://dev.to/mx_tech/go-interface-nil-pitfall-why-your-nil-check-is-failing-and-how-to-fix-it-2ie7","date":1740253407,"author":"Moksh","guid":9284,"unread":true,"content":"<p>Have you ever encountered a situation where you check for nil, but the function still executes unexpectedly? </p><p>This is a common pitfall in Go when working with interfaces and nil values. Let's break it down. üëá</p><p><strong>üîç The Problem: A Failing Nil Check</strong>\nImagine we have an interface Notifier with a method Notify().</p><div><pre><code>package main\n\nimport \"fmt\"\n\n// Define an interface\ntype Notifier interface {\n    Notify()\n}\n\n// Define a struct\ntype Email struct {\n    Address string\n}\n\n// Implement the Notify method for Email\nfunc (e *Email) Notify() {\n    fmt.Println(\"Sending email to:\", e.Address)\n}\n\n// Function that processes Notifier entities\nfunc ProcessNotifiers(notifiers ...Notifier) {\n    for _, notifier := range notifiers {\n        if notifier == nil {\n            fmt.Println(\"Skipping nil notifier\")\n            continue\n        }\n        fmt.Println(\"Processing:\", notifier)\n        notifier.Notify()\n    }\n}\n\nfunc main() {\n    var email *Email  // Declaring a nil pointer of type *Email\n    var notifier Notifier = email // Assigning it to an interface\n\n    fmt.Println(notifier == nil)  // ‚ùå False! (unexpected)\n\n    ProcessNotifiers(notifier) // Will still call Notify() and panic!\n}\n</code></pre></div><ul><li><p>1Ô∏è‚É£ <strong>email is a nil pointer, but notifier is NOT nil!</strong></p><ul><li>When assigning email to notifier, Go stores its type info (*Email) in the interface.</li><li>This means the interface itself is not nil, even though the underlying value is nil.</li></ul></li><li><p>2Ô∏è‚É£ <strong>Our if notifier == nil check fails!</strong></p><ul><li>Even though email is nil, notifier still holds a valid interface value, so notifier == nil returns false.</li></ul></li><li><p>3Ô∏è‚É£ <strong>Calling notifier.Notify() causes a panic!</strong></p><ul><li>The method is called on a nil receiver, leading to a runtime error.</li></ul></li></ul><p><strong>‚úÖ The Fix: Proper Nil Checking</strong>\nInstead of checking if notifier == nil, use reflection to properly detect nil interfaces:</p><div><pre><code>import \"reflect\"\n\n// Properly check if an interface is nil\nfunc isNil(i interface{}) bool {\n    if i == nil {\n        return true\n    }\n    v := reflect.ValueOf(i)\n    return v.Kind() == reflect.Ptr &amp;&amp; v.IsNil()\n}\n\nfunc ProcessNotifiersFixed(notifiers ...Notifier) {\n    for _, notifier := range notifiers {\n        if isNil(notifier) {\n            fmt.Println(\"Skipping nil notifier\")\n            continue\n        }\n        fmt.Println(\"Processing:\", notifier)\n        notifier.Notify()\n    }\n}\n</code></pre></div><p><strong>‚úÖ Now, it properly skips the nil notifier and avoids the panic!</strong></p><p>\n ‚úî Interfaces holding nil pointers are NOT nil!<p>\n ‚úî Always check for nil pointers inside interfaces properly</p>\n ‚úî Use reflection to avoid hidden nil bugs</p><p>Have you run into this before? Let's discuss in the comments! üí¨üëá</p>","contentLength":2581,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Portsicle works!","url":"https://dev.to/amitsuthar69/how-portsicle-works-24k6","date":1740251380,"author":"Amit Suthar","guid":9283,"unread":true,"content":"<p><a href=\"https://portsicle.github.io/landing-page\" rel=\"noopener noreferrer\">Portsicle</a> is a reverse tunneling service that creates a public ingress endpoint for local servers, allowing developers to showcase their locally running applications to clients, stakeholders or to test APIs without deploying.</p><p>We all know that the most obvious way to allow an inbound traffic to a private network is through port forwarding. But we won't sit and configure our routers every time, we need a better solution.</p><p>But if we're not forwarding the port, then how can an external packet enter our private network without getting chocked by firewalls? </p><p>Here's where the concept of <a href=\"https://qbee.io/misc/reverse-ssh-tunneling-the-ultimate-guide/\" rel=\"noopener noreferrer\">Reverse Tunneling</a> comes into the picture. Reverse Tunneling is a technique used to establish a secure connection from a remote server back to a local machine. Portsicle beautifully manipulates this same technique to route traffic to local machine.</p><p>The idea is to have an intermediary remote (relay) server which will act as a bridge between local machine and the internet traffic. Anyone who wants to access someone's local server, will first visit to the remote server, which will then route the request to the local machine.</p><p>To achieve this, Portsicle provides a client CLI which connects to the remote server. The user can use the CLI command to initiate the tunnel. This means that the connection is now outbound (established by the local machine) and the firewall will just ignore it. This connection is then upgraded to a secure and persistent websocket tunnel.</p><p>Once a tunnel is established, the relay server provides a 'Public URL' for that session. Anyone on the internet can now access that particular local server with this public URL and the URL is only valid as long as the client is running along.</p><p>Steps to get the public url:</p><blockquote><p>note that 3000 has to be the port of the local server you wanted to expose.</p></blockquote><ul><li>You'll then receive the URL:\n</li></ul><div><pre><code>‚ùØ ./portsicle http -p 3000\n2025/02/23 00:26:33 Connected to remote server.\n2025/02/23 00:26:33 Your public url: https://portsicle.koyeb.app/a355bf62-f7c4-46e9-9d9b-1125d6343b3d\n</code></pre></div><p>Your local server is accessible with this link!</p><p>But how the traffic is \"forwarded\"??? Well, we simply convert the HTTP/HTTPS requests and responses into websocket messages and forward them between local client and the remote server.</p><p>We handle this forwarding for two cycles:</p><p>Take plain HTTP request =&gt; Convert it to a message object =&gt; send it across wire =&gt; reconstruct an HTTP request =&gt; send it to local server. </p><p>Client gets a response from local server =&gt; convert it to a response object =&gt; send it across wire =&gt; construct a response.  </p>","contentLength":2538,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"windows firewall for local Go web app","url":"https://www.reddit.com/r/golang/comments/1ivmbtd/windows_firewall_for_local_go_web_app/","date":1740241115,"author":"/u/jeevanism","guid":9298,"unread":true,"content":"<p>Every time I start my Go web app locally on Windows, I get a firewall error (see screenshot). The Windows Firewall blocks it, and I have to manually allow access. Why does this keep happening? Is there a way to fix this permanently?</p><p>NB : I am unable to attach the screenshot here :( </p>","contentLength":282,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DSBG, an open-source static site generator built with Go","url":"https://www.reddit.com/r/golang/comments/1ivl3o0/dsbg_an_opensource_static_site_generator_built/","date":1740237882,"author":"/u/tarjano","guid":9209,"unread":true,"content":"<p>This is my first big project built in Go, primarily to see if I could be as productive with it as I am with Python. I wanted to tackle a non-trivial project, so I aimed to include most of the functionality I envisioned for this type of tool. Here's what DSBG offers:</p><ul><li> Works with both Markdown and HTML source files.</li><li><strong>Automatic Tagging &amp; Filtering:</strong> Tags are generated from paths, with built-in tag filtering.</li><li><strong>Client-Side Fuzzy Search:</strong> Provides fast search over all content within the browser.</li><li><strong>Automatic RSS Feed Generation:</strong> Easily create RSS feeds for your blog.</li><li><strong>Watch Mode with Auto-Rebuild:</strong> For continuous feedback during development.</li><li> Includes 3 different themes, with the option to add your own custom CSS.</li><li> For major social networks.</li><li> Easily add analytics, comments, and more.</li></ul><p>The code might not be perfectly idiomatic, so any tips, suggestions, and feedback are very welcome!</p>","contentLength":870,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Understanding the init Function in Go: Purpose, Execution, and Best Practices","url":"https://dev.to/abstractmusa/understanding-the-init-function-in-go-purpose-execution-and-best-practices-2i9k","date":1740227616,"author":"Md Abu Musa","guid":9121,"unread":true,"content":"<p>In Go, the  is a special function that is automatically executed  when a package is initialized. It is primarily used for , such as initializing global variables, opening database connections, or registering dependencies.</p><h3><strong>Key Characteristics of  Function</strong>:\n</h3><ol><li><strong>No Arguments &amp; No Return Value</strong> ‚Äì The  function does not take parameters or return values.</li><li> ‚Äì It runs before  and does not require explicit invocation.</li><li><strong>Can Have Multiple  Functions</strong> ‚Äì A package can have multiple  functions, even across different files.</li><li><strong>Executed in Declaration Order</strong> ‚Äì If multiple  functions exist in a package, they are executed in the order in which they appear.</li></ol><h3><strong>Example 1: Basic  Usage</strong></h3><div><pre><code></code></pre></div><div><pre><code>Initializing...\nMain function running...\n</code></pre></div><p>‚úÖ The  function runs .</p><h3><strong>Example 2: Using  for Global Variable Initialization</strong></h3><div><pre><code></code></pre></div><h3><strong>Example 3:  in Multiple Files</strong></h3><p>üìå If a package has multiple files, all  functions run , in the order they appear.</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h4><strong>Output (execution order is preserved):</strong></h4><div><pre><code>Init from a.go\nInit from b.go\nMain function running...\n</code></pre></div><h3><strong>Example 4:  in a Different Package</strong></h3><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h4><strong>Output (Package-Level Execution Order)</strong></h4><div><pre><code>Initializing utils package...\nInitializing main package...\nMain function running...\nHello from utils!\n</code></pre></div><p>‚úÖ The  function in <strong>imported packages runs before the  function in </strong>.</p><ul><li>Initializing global variables.</li><li>Setting up logging configurations.</li><li>Registering dependencies (e.g., database connections).</li><li>Ensuring required setup before  runs.</li></ul><ul><li>Complex logic (prefer explicit initialization in ).</li><li>Business logic (should be in  or other functions).</li></ul><ul><li> runs <strong>automatically before </strong>.</li><li>It has  and .</li><li>Each package can have multiple  functions.</li><li> in  runs before  in .</li></ul>","contentLength":1588,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"API Application Monitoring - OpenTelemetry? Or something else?","url":"https://www.reddit.com/r/golang/comments/1ivhm7y/api_application_monitoring_opentelemetry_or/","date":1740227138,"author":"/u/_nullptr_","guid":9180,"unread":true,"content":"<p>I am writing a few different gRPC and HTTP (via gRPC Gateway) API servers for various heavy financial compute/IO operations (trading systems and market data). I am doing this as a single developer. These are mostly for me as a hobbyist, but may become commercial/cloud provided at some point with a nice polished UI frontend.</p><p>Given the nature of the applications, I want to know what is \"going on\" and be able to troubleshoot performance bottlenecks as they arise, see how long transactions take, etc. I want to standardize the support for this into my apiserver package so all my apps can leverage and it isn't an afterthought. That said, I don't want some huge overhead either, but just want to know the performance of my app when I want to (and not when I don't). I do think I want to instrument with logs, trace and metrics after thinking what each would give me in value.</p><p>Right now I am leaning towards just going full OpenTelemetry knowing that it is early and might not be fully mature, but that it likely will over time. I am thinking I will use stdlib  for logs with Otel handler only when needed else default to basic stdout handler. Do I want to use otel metrics/tracing directly? I am also thinking I want these others sent to a  handler by default (even stdout is too much noise), and only to a collector when configured at runtime. Is that possible with the Go Otel packages? Does this seem like the best strategy? How does stdlib  play into this? or doesn't it? Other ideas?</p>","contentLength":1487,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ensuring Interface Implementation at Compile Time in Go üõ†Ô∏è","url":"https://dev.to/abgeo/ensuring-interface-implementation-at-compile-time-in-go-3366","date":1740221032,"author":"Temuri Takalandze","guid":9061,"unread":true,"content":"<p>In Go, we can‚Äôt implicitly implement interfaces like in some other languages. To ensure a type implements an interface, we explicitly check this by trying to cast the type to the interface. If the type doesn‚Äôt match, Go will give a compile-time error, and the code won‚Äôt compile üö´</p><p>This compile-time check helps catch errors early, making sure your types conform to the expected interfaces. If Task doesn‚Äôt implement Executor properly, Go won‚Äôt compile the code, saving you from potential issues at runtime üë®‚Äçüíª</p>","contentLength":529,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dockerize GO environment with only go.mod and go.sum and no source code","url":"https://www.reddit.com/r/golang/comments/1ivfxtb/dockerize_go_environment_with_only_gomod_and/","date":1740220358,"author":"/u/muthunatsharma","guid":9112,"unread":true,"content":"<p>I need a docker container which has go packages downloaded, installed and compiled as mentioned in go.mod and go.sum. All the articles show how to do it but the install/compile actually happens only when the source-code is copied in to the container and \"go build\" is run in the dockerfile.</p><p>I see \"go download\" downloads all pkgs in go.mod to /go/mod/pkg. How do I install these?<p> I can give \"go install &lt;pkg&gt;\" but that would mean I need to update my Dockerfile each time a new pkg is added to go.mod.</p></p><p>What is the one-shot way of installing it in the dockerfile build?</p><p>Edit: The context is to build a dev container where deps are pre-built saving time when code is mounted on the container and built -- this is the main point to save time. The container wouldn't have the app itself. Only the dependencies fully installed and serve as a standard environment to run.</p>","contentLength":861,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"godoc.nvim - Golang docs inside Neovim!","url":"https://www.reddit.com/r/golang/comments/1ivfv16/godocnvim_golang_docs_inside_neovim/","date":1740220022,"author":"/u/ffredrikk","guid":9111,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Protobuf Should Dominate the Data Format Ecosystem","url":"https://dev.to/leapcell/why-protobuf-should-dominate-the-data-format-ecosystem-4ddd","date":1740217327,"author":"Leapcell","guid":9047,"unread":true,"content":"<p>Protobuf (Google Protocol Buffers), as defined in the official documentation: Protocol buffers is a language-independent, platform-independent, and extensible method for serializing structured data, which can be widely applied in scenarios such as data communication protocols and data storage. It is a tool library provided by Google with an efficient protocol data exchange format, possessing the characteristics of flexible, efficient, and automated structured data serialization mechanisms.</p><p>Compared with XML, the size of data encoded by Protobuf is smaller, and the encoding and decoding speed is faster. Compared with Json, Protobuf performs more excellently in conversion efficiency, with both its time efficiency and space efficiency reaching 3 to 5 times that of JSON.</p><p>As the official description states: ‚ÄúProtocol buffers are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data ‚Äì think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.‚Äù</p><h2>\n  \n  \n  Comparison of Data Formats\n</h2><p>Suppose we have a  object, represented by JSON, XML, and Protobuf respectively, and let's see their differences.</p><div><pre><code>John24</code></pre></div><p>Protobuf directly represents data in binary format, which is not as intuitive as XML and JSON formats. For example:</p><div><pre><code>[10 6 69 108 108 122 111 116 16 24]\n</code></pre></div><h3>\n  \n  \n  Good Performance/High Efficiency\n</h3><ul><li>: The overhead of XML formatting (serialization) is acceptable, but the overhead of XML parsing (deserialization) is relatively large. Protobuf has optimized this aspect and can significantly reduce the time overhead of serialization and deserialization.</li><li>: Protobuf also greatly reduces the space occupation.</li></ul><h3>\n  \n  \n  Code Generation Mechanism\n</h3><p>For example, write the following content similar to a structure:</p><div><pre><code></code></pre></div><p>Protobuf can automatically generate the corresponding  file and  file, and encapsulate the operations on the structure  into a class.</p><h3>\n  \n  \n  Support for Backward Compatibility and Forward Compatibility\n</h3><p>When the client and the server use a protocol simultaneously, if the client adds a byte in the protocol, it will not affect the normal use of the client.</p><h3>\n  \n  \n  Support for Multiple Programming Languages\n</h3><p>In the source code officially released by Google, it includes support for multiple programming languages, such as:</p><ul></ul><h2>\n  \n  \n  Disadvantages of Protobuf\n</h2><h3>\n  \n  \n  Poor Readability Due to Binary Format\n</h3><p>To improve performance, Protobuf uses a binary format for encoding, which makes the data less readable and will affect the efficiency during the development and testing phase. However, under normal circumstances, Protobuf performs very reliably, and serious problems generally do not occur.</p><p>Generally, XML is self-descriptive, while the Protobuf format is not. It is a piece of binary format protocol content, and it is difficult to know its function without matching it with a pre-written structure.</p><p>Although Protobuf supports serialization and deserialization in multiple languages, it is not a universal transmission standard across platforms and languages. In scenarios of multi-platform message passing, its compatibility with other projects is not good, and corresponding adaptation and transformation work is often required. Compared with json and XML, its universality is slightly insufficient.</p><p>Proto message type files generally end with . In a  file, one or more message types can be defined.</p><p>The following is an example of defining a message type for a search query. The  at the beginning of the file is used to describe the version information. Currently, there are two versions of proto, proto2 and proto3.</p><p>Explicitly set the syntax format to proto3. If the  is not set, it defaults to proto2.  represents the content to be queried,  represents the page number of the query, and  represents the number of items per page.  must be located on the first line of the  file excluding comments and blank lines.</p><p>The following message contains 3 fields (, , ), and each field has a corresponding type, field name, and field number. The field type can be , , , or a composite type.</p><div><pre><code></code></pre></div><p>Each field in the message type needs to be defined with a unique number, and this number is used to identify the field in the binary data. Numbers in the range of [1,15] can be encoded and represented with one byte; in the range of [16,2047], they need to be encoded and represented with two bytes. Therefore, leaving the numbers within 15 for frequently occurring fields can save space. The minimum value of the number is 1, and the maximum value is 2^29 - 1 = 536870911. Numbers in the range of [19000, 19999] cannot be used because these numbers are used internally by the proto compiler. Similarly, other pre-reserved numbers cannot be used either.</p><p>Each field can be modified by  or . In the proto3 syntax, if the modification type is not specified, the default value is .</p><ul><li>: It means that the modified field appears at most once, that is, it appears 0 or 1 time.</li><li>: It means that the modified field can appear any number of times, including 0 times. In the proto3 syntax, fields modified by  use the  encoding by default.</li></ul><p>You can add comments to the  file. The comment syntax is the same as the C/C++ style, using  or .</p><div><pre><code></code></pre></div><p>When deleting or commenting out a field in a , other developers in the future may reuse the previous field number when updating the  definition. If they accidentally load the old version of the  file, it may lead to serious problems, such as data corruption. To avoid such problems, you can specify the reserved field numbers and field names. If someone uses these field numbers in the future, an error will be generated when compiling the proto, thus reminding that there is a problem with the proto.</p><p>Note: Do not mix the use of field names and field numbers for the same field.</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Mapping between Field Types and Language Types\n</h3><p>The defined  file can generate Go language code through a generator. For example, the Go file generated from the  file is the  file.</p><p>The mapping between basic types in proto and Go language types is shown in the following table (here only the type mapping between Go and C/C++ is listed, and for other languages, refer to <a href=\"https://developers.google.com/protocol-buffers/docs/proto3):\" rel=\"noopener noreferrer\">https://developers.google.com/protocol-buffers/docs/proto3):</a>\n|.proto Type | Go Type | C++ Type |\n| double | float64 | double |<p>\n| float | float32 | float |</p>\n| int32 | int32 | int32 |<p>\n| int64 | int64 | int64 |</p>\n| uint32 | uint32 | uint32 |<p>\n| uint64 | uint64 | uint64 |</p>\n| sint32 | int32 | int32 |<p>\n| sint64 | int64 | int64 |</p>\n| fixed32 | uint32 | uint32 |<p>\n| fixed64 | uint64 | uint64 |</p>\n| sfixed32 | int32 | int32 |<p>\n| sfixed64 | int64 | int64 |</p>\n| bool | bool | bool |<p>\n| string | string | string |</p>\n| bytes | []byte | string |</p><div><table><tbody><tr></tr></tbody></table></div><p>When defining a message, if you want the value of a field to be only one of the expected values, you can use the enum type.</p><p>For example, now add the  field to , and its value can only be one of , , , , , , and . This can be achieved by adding an enum to the message definition and adding a constant for each possible enum value.</p><div><pre><code></code></pre></div><p>The first constant of the  enum must be mapped to 0, and all enum definitions need to include a constant mapped to 0, and this value is the first line content of the enum definition. This is because 0 is used as the default value of the enum. In the proto2 syntax, the enum value on the first line is always the default value. For the sake of compatibility, the value 0 must be the first line of the definition.</p><p>Other  files can be imported in a  file, so as to use the message types defined in the imported file.</p><div><pre><code></code></pre></div><p>By default, only the message types defined in the directly imported  file can be used. But sometimes it may be necessary to move the  file to a new location. At this time, a virtual  file can be placed in the old location, and the  syntax can be used to forward all imports to the new location, instead of directly moving the  file and updating all call points at once. Any place that imports a proto file containing the  statement can pass on the public dependencies of the imported dependencies.</p><p>For example, there are  and  files in the current folder, and  is imported in the  file, that is, the  file has the following content:</p><p>Suppose now we want to put the messages in  into the  file for use in other places. We can modify  and import  in it. Note that we need to use  because a single  can only use the messages defined in  and cannot use the message types in the proto file imported in .</p><div><pre><code></code></pre></div><p>When using  for compilation, the option  or  needs to be used to notify  where to find the imported files. If the search path is not specified,  will look for it in the current directory (the path where  is called).</p><p>Message types in the proto2 version can be imported into a proto3 file for use, and message types in the proto3 version can also be imported into a proto2 file. But the enum types in proto2 cannot be directly applied to the proto3 syntax.</p><p>Message types can be defined inside another message type, that is, nested definitions. For example, the  type is defined inside , and it supports multiple levels of nesting.</p><div><pre><code></code></pre></div><p>When an outer message type uses a message inside another message, such as the  type using , it can use .</p><div><pre><code></code></pre></div><p>Unknown fields are fields that the proto compiler cannot recognize. For example, when an old binary file parses the data sent by a new binary file with new fields, these new fields will become unknown fields in the old binary file. In the initial version of proto3, unknown fields were discarded when the message was parsed, but in version 3.5, the retention of unknown fields was reintroduced. Unknown fields are retained during parsing and are included in the serialized output.</p><p>The key to the high efficiency of Protobuf lies in its TLV (tag-length-value) encoding format. Each field has a unique  value as an identifier,  represents the length of the  data (for a  with a fixed length, there is no ), and  is the content of the data itself.</p><p>For the  value, it is composed of two parts:  and .  is the number given to each field in the  earlier, and  represents the type (fixed length or variable length). The  currently has 6 values from 0 to 5, and these 6 values can be represented by 3 bits.</p><p>The values of  are shown in the following table, where 3 and 4 have been deprecated, and we only need to pay attention to the remaining 4 types. For data encoded with Varint, there is no need to store the byte length , and at this time, the TLV encoding format degenerates into TV encoding. For 64-bit and 32-bit data, there is also no need for  because the  value already indicates whether the length is 8 bytes or 4 bytes.</p><div><table><thead><tr></tr></thead><tbody><tr><td>int32 int64 uint32 uint64 bool enum</td></tr><tr></tr><tr></tr><tr><td>string bytes packed repeated fields embedded</td></tr><tr></tr><tr></tr><tr></tr></tbody></table></div><h3>\n  \n  \n  Varint Encoding Principle\n</h3><p>Varint is a variable-length int, which is a variable-length encoding method. It can make smaller numbers use fewer bytes to represent, and achieve data compression by reducing the number of bytes used to represent numbers. For an int32 type number, it usually requires 4 bytes to represent, but with Varint encoding, an int32 type number less than 128 can be represented with 1 byte. For larger numbers, it may require 5 bytes to represent, but in most messages, very large numbers usually do not appear, so using Varint encoding can use fewer bytes to represent numbers.</p><p>Varint is a variable-length encoding, and it distinguishes each field through the highest bit of each byte. If the highest bit of a byte is 1, it means that the subsequent byte is also part of the number; if it is 0, it means that this is the last byte, and the remaining 7 bits are all used to represent the number. Although each byte will waste 1 bit of space (that is, 1/8 = 12.5% waste), if there are many numbers that do not need to be fixed as 4 bytes for representation, a large amount of space can still be saved.</p><p>For example, for an int32 type number 65, its Varint encoding process is as follows, and the 65 that originally occupied 4 bytes only occupies 1 byte after encoding.</p><p>For an int32 type number 128, it occupies 2 bytes after encoding.</p><p>Varint decoding is the reverse process of encoding, which is relatively simple, and no example is given here.</p><p>numbers to unsigned numbers, and then use Varint encoding to reduce the number of bytes after encoding.</p><p>Zigzag uses unsigned numbers to represent signed numbers, enabling numbers with smaller absolute values to be represented with fewer bytes. Before understanding Zigzag encoding, let's first understand a few concepts:</p><ul><li>: The highest bit is the sign bit, and the remaining bits represent the absolute value.</li><li>: Except for the sign bit, invert the remaining bits of the original code one by one.</li><li>: For positive numbers, the two's complement is itself; for negative numbers, except for the sign bit, invert the remaining bits of the original code one by one and then add 1.</li></ul><p>Take the int32 type number -2 as an example, and its encoding process is as follows.</p><p>In summary, for negative numbers, perform arithmetic operations on their two's complement. For a number , if it is of the  type, perform the operation ; if it is of the  type, perform the operation . Through this operation, the negative number is changed to a positive number, and this process is Zigzag encoding. Finally, use Varint encoding.</p><p>Since Varint and Zigzag encoding can self-parse the content length, the length item can be omitted, and the TLV storage is simplified to TV storage, without the need for the  item.</p><h3>\n  \n  \n  Calculation Methods of tag and value Values\n</h3><p>The  stores the identification information and data type information of the field, that is,  (field data type) +  (identification number). The field number can be obtained through the , corresponding to the defined message field. The calculation formula is <code>tag = field_number&lt;&lt;3 | wire_type</code>, and then perform Varint encoding on it.</p><p>The  is the value of the message field after Varint and Zigzag encoding.</p><h3>\n  \n  \n  string Encoding (continued)\n</h3><p>When the field type is the  type, the field value is encoded in UTF-8. For example, there is the following message definition:</p><div><pre><code></code></pre></div><p>In the Go language, the sample code for encoding this message is as follows:</p><div><pre><code></code></pre></div><p>The binary content after encoding is as follows:</p><div><pre><code>[10 14 67 104 105 110 97 228 184 173 144 155 189 228 120 186]\n</code></pre></div><p>Nested messages mean that the  is another field message. The outer message is stored using TLV storage, and its  is also a TLV storage structure. The schematic diagram of the entire encoding structure is as follows (it can be imagined as a tree structure, where the outer message is the root node, and the nested message inside it is used as a child node, and each node follows the TLV encoding rule):</p><ol><li>The outermost message has its corresponding ,  (if any), and .</li><li>When the  is a nested message, this nested message has its own independent ,  (if any), and .</li><li>By analogy, if there are nested messages within the nested message, continue to encode according to the TLV rule.</li></ol><h3>\n  \n  \n  repeated Fields with packed\n</h3><p>The fields modified by  can be with  or without it. For multiple field values of the same  field, their  values are all the same, that is, the data type and field sequence number are the same. If multiple  storages are used, there will be redundancy of the .</p><p>If  is set, the storage method of the  field will be optimized. That is, the same  is only stored once, and then the total length  of all values under the  field is added to form a  storage structure. This method can effectively compress the length of the serialized data and save transmission overhead. For example:</p><div><pre><code></code></pre></div><p>In the above example, the  field does not use , and each  value will have independent  and  storage; while the  field uses , and the  will only be stored once, followed by the total length  of all  values, and then all  values are arranged in sequence. In this way, when the data volume is large, the  field using  can significantly reduce the space occupied by the data and the bandwidth consumption during transmission. </p><p>With its efficiency (in terms of size) and professionalism (professional types), Protobuf should have a higher coverage in the future data transmission field.</p><p>Finally, I would like to introduce to you the most suitable platform for deploying services: </p><h3>\n  \n  \n  1. Multi-Language Support\n</h3><ul><li>Develop with JavaScript, Python, Go, or Rust.\n</li></ul><h3>\n  \n  \n  2. Deploy unlimited projects for free\n</h3><ul><li>pay only for usage ‚Äî no requests, no charges.</li></ul><h3>\n  \n  \n  3. Unbeatable Cost Efficiency\n</h3><ul><li>Pay-as-you-go with no idle charges.\n</li><li>Example: $25 supports 6.94M requests at a 60ms average response time.\n</li></ul><h3>\n  \n  \n  4. Streamlined Developer Experience\n</h3><ul><li>Intuitive UI for effortless setup.\n</li><li>Fully automated CI/CD pipelines and GitOps integration.\n</li><li>Real-time metrics and logging for actionable insights.\n</li></ul><h3>\n  \n  \n  5. Effortless Scalability and High Performance\n</h3><ul><li>Auto-scaling to handle high concurrency with ease.\n</li><li>Zero operational overhead ‚Äî just focus on building.\n</li></ul>","contentLength":16965,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Feature Flag Service: Experimenting with New Technologies and Architectures","url":"https://dev.to/palma99/feature-flag-service-experimenting-with-new-technologies-and-architectures-176p","date":1740217014,"author":"Palma99","guid":9046,"unread":true,"content":"<p>I am a junior frontend developer with two years of experience working with Vue.js, I wanted to broaden my knowledge by exploring backend development and experimenting with other frontend frameworks. I decided to create a project from scratch using Go for the backend and Angular 19 for the frontend. The project is a service for managing feature flags, inspired by great existing solutions. My primary focus was on implementing the principles of Clean Architecture while also improving my SQL skills by working directly with PostgreSQL without an ORM.</p><p>The source code can be found here:</p><p>The idea was to create a dashboard where users can sign in and manage their projects, environments and flags. Then, project's specific flags can be retrieved by user's app using a public api. The first thing that i wasn't sure about is how to implement this public interaction in a secure way, we will dive into that later, but the idea was to create some sort of library that handle this communication using a public key.</p><p>For the dashboard, I aimed to create an intuitive and simple UI for basic operations like creating new projects and flags. My main goal was to clearly display the status of the flags in each environment. This was the initial sketch of the UI.</p><p>I also wanted to implement collaboration, allowing multiple users to access the same project. This necessitates the implementation of a role/permission system, where, for example, only the owner can delete a project.</p><h2>\n  \n  \n  First step: Designing the database\n</h2><p>Let's dive into some technical details, starting with database design. I wanted to use a relational database, but at this stage, I didn‚Äôt really care which one to choose. So, as a first step, I started thinking about all the entities and the relationships between them:</p><ul><li>: a person that can sign up and have access to the dashboard</li><li>: represent a container of environment and flags</li><li>: each project can have one or more environments, this is useful for a real world project where multiple test environment can exist.</li><li>: represent a single feature that can be enabled or not</li></ul><p>I started creating many-to-many relationship between users and project, so we can easily implement collaboration as mentioned before.\nThe one-to-many relationship between  and  it's pretty straight forward as one project can have multiple environments.</p><p>Nothing special so far, but things started to get tricky when I encountered the flag table. </p><p>The first idea that came to mind was that each flag should be directly related to an environment. This seemed logical, given that we‚Äôre working in a multi-environment system where the end user needs to request flags for a specific environment. However, I quickly realized that this could introduce some introduce some complexities.</p><p>Imagine you're inside the dashboard for a specific project that has 3 environments (TEST, QA, PROD), and you want to create a new flag called 'dark_mode_experimental'. This means you would need to create 3 new rows in the  table, one for each environment. Then, if you want to update the flag name to 'dark_mode', you would need to update all the rows accordingly. The same applies if you want to delete a flag. Furthermore, if a project already has some flags and you want to add another environment (let's say 'DEV'), you would need to duplicate all the existing flags for this new environment, which can lead to increased complexity and potential maintenance issues.</p><p>The final solution is that flags belong to a project while maintaining a many-to-many relationship with environments through the  table. This table allows us to store the flag status for each specific environment. By doing so, we can easily manage flag updates and deletions without needing to duplicate or update rows across multiple environments.</p><p>What happens when a new environment is created within a project is quite simple: we just add a new row in the  table. The relations in the  table are not created immediately but only after a flag is updated. This ensures that we avoid unnecessary entries for environments where no flags have been modified yet. Once a flag is updated, the corresponding relation in the flag_environment table is established, allowing us to track the flag's status in the new environment. </p><h2>\n  \n  \n  Step two: Implementing Go backend\n</h2><p>As I mentioned, I'm more of a frontend person, but I have a strong interest in learning backend technologies. During my studies, I worked with several different languages, mostly C, Java, and Python. These are great languages, but I wanted to try something new. Recently, I heard a lot of positive things about Go, so I decided to give it a shot.</p><p>There are a couple of things I want to mention before diving into the code. My main goal here was to structure the code by following clean architecture principles. This approach helps ensure that the code remains modular, maintainable, and testable. Additionally, for handling data, I chose not to use any ORM because I believe that for a study project, writing raw SQL is more instructive and provides a deeper understanding of how data is managed at the database level.</p><p>Let's start with folder structure</p><p>In Go, it's common to have a folder called  that contains the entry point of the program, and a folder called  for all the application code. That's what I did ‚Äî I created two subfolders inside : one for the API version and one for the CLI version of the service.</p><p>There are some great articles about clean architecture, and the structure I implemented is quite standard, so I won't go into detail about what each folder represents. I just want to highlight some parts of the code that demonstrate how the principles are applied and how the different components interact with each other in the project.</p><p>As I mentioned, I'm new to the Go world and still getting familiar with the ecosystem. From what I've seen so far, there aren't any major frameworks like those in the .NET or Java ecosystems that handle dependency injection in such a clean way. Therefore, I decided to implement dependency injection in a very 'vanilla' way, without relying on any external frameworks. Here is an example</p><div><pre><code></code></pre></div><p>An interactor is a struct with some dependencies that has methods to fulfill some business use cases, e.g.</p><div><pre><code></code></pre></div><p>There are several aspects that can be improved, such as error handling or using a factory to create entities. However, the key idea is that the 'Create Environment' use case is managed within this method, which does not rely on any concrete implementation.</p><p>In this project, I implemented anemic entities, which is not ideal. For example, all fields are public so they can be serialized using Go's standard library, although I'm not fully convinced this is the best approach.</p><div><pre><code></code></pre></div><p>The infrastructure folder contains all the implementations related to external dependencies. In this case, it includes the repository implementation for PostgreSQL and the middleware used by the HTTP framework.</p><p>I decided to use PostgreSQL as the database for no particular reason (well, maybe because I already had a Docker image pulled). However, thanks to clean architecture, it's easy to swap the database by simply implementing a new repository that adheres to the same interface. For example:</p><div><pre><code></code></pre></div><p>In this case, interfaces refer to the components that allow external systems to interact with the application. For a web API, this typically consists of a function that, for example, extracts request parameters or body data, creates a DTO, and calls the interactor.</p><div><pre><code></code></pre></div><h4>\n  \n  \n  Authentication for the admin section\n</h4><p>When dealing with authentication in the real world, it's better to relay on well tested library to improve security. However this for this simple project i decided to implement a username and password authentication that works with JWT tokens from scratch, using this popular library 'github.com/golang-jwt/jwt/v5'.</p><h4>\n  \n  \n  Implementation of the \"public api\"\n</h4><p>To allow the end user to access flags for a certain environment, I decided to implement a public key pattern. Essentially, there is a public REST API protected by a middleware that checks for a specific header containing a key. If the key is valid, it grants read-only access to all the enabled flags for that environment. Even if the public key gets stolen, the impact is limited. Since it only grants read-only, the key cannot be used to modify any data or access sensitive information.</p><p>That's how i implemented the middleware</p><div><pre><code></code></pre></div><p>Then in the route definition</p><div><pre><code></code></pre></div><p>To interact with the public API I wrote a simple typescript SDK that allow to easily communicate with the service. It provides basic caching and types, and can be used by any javascript app.</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Admin dashboard in Angular 19\n</h3><p>Once I completed the backend, I wanted to interact with my service through a comfortable UI. Angular 19 had just come out with stable signals and other cool features, so I decided to use it for the frontend. I didn‚Äôt want to spend too much time designing UI components, hence I decided to use a component library that provides pre-built, customizable components. This allowed me to focus more on the core functionality and user experience. The library i choose is <a href=\"https://taiga-ui.dev\" rel=\"noopener noreferrer\">Taiga UI</a>.</p><p>The frontend is quite simple, a bit different from the initial sketch but it provides all the features i need.</p><p>List of user projects<a href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Frb0w8emw1cc77mmswnh9.png\"><img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Frb0w8emw1cc77mmswnh9.png\" alt=\"Ui project list\" width=\"800\" height=\"477\"></a></p><p>An interesting feature I added consists of a section where you can test the payload of the public api for the environment. It works by making an api call to public endpoint using the environment key of the selected environment, and then it shows the response.</p><ul><li>Unit testing: Clean architecture is great and makes things easier to test, but I haven‚Äôt written a single test for my business logic yet. This is definitely something to focus on moving forward.</li><li>Collaboration is supported, but there is currently no way to \"invite\" someone to join a project (just manually on db). In the future, it would be cool to implement an invitation system, allowing users to easily add collaborators and manage team access.</li></ul>","contentLength":9963,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Generic Bitfield I had fun implementing","url":"https://gist.github.com/oplanre/de0bba4f1e2f769458ca1adff7f12280","date":1740197539,"author":"/u/ln3ar","guid":9162,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iva8up/generic_bitfield_i_had_fun_implementing/"},{"title":"from nodejs want to move to golang","url":"https://www.reddit.com/r/golang/comments/1iv7ngg/from_nodejs_want_to_move_to_golang/","date":1740189188,"author":"/u/Spirited-Item1431","guid":8971,"unread":true,"content":"<p>I used to be a web developer who used Node.js as my daily programming language, but now I'm interested in switching to Golang. Aside from the usual fundamentals, what are the most important things to learn in Golang?</p>","contentLength":216,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Understanding Packages in Go: A Comprehensive Guide","url":"https://dev.to/abstractmusa/fsdfasdf-asfa-3fd1","date":1740188556,"author":"Md Abu Musa","guid":8929,"unread":true,"content":"<p>In Go, a package is a fundamental concept for organizing and reusing code. This guide explains everything you need to know about Go packages.</p><ul><li>A package is a collection of source files in the same directory.</li><li>All files in a package must declare the same package name at the top.</li><li>It provides modularity, encapsulation, and code reuse.</li></ul><ul><li>A special package that creates an executable program.</li><li>Must contain a  function.</li><li>Used only for executables.</li></ul><ul><li>Can have any name except .</li><li>Used to create reusable code.</li><li>Can be imported by other packages.</li></ul><h2>\n  \n  \n  3. Package Visibility Rules\n</h2><ul><li>Names starting with an  letter are .</li><li>Names starting with a  letter are .</li></ul><div><pre><code></code></pre></div><p>To use packages in Go, you import them:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  5. Package Organization Example\n</h2><div><pre><code>myapp/\n‚îú‚îÄ‚îÄ main.go              // package main\n‚îú‚îÄ‚îÄ utils/\n‚îÇ   ‚îú‚îÄ‚îÄ math.go         // package utils\n‚îÇ   ‚îî‚îÄ‚îÄ strings.go      // package utils\n‚îî‚îÄ‚îÄ models/\n    ‚îî‚îÄ‚îÄ user.go         // package models\n</code></pre></div><h2>\n  \n  \n  6. Benefits of Using Packages\n</h2><ul></ul><ul><li>All files in the same folder must have the same package name.</li><li>Package names usually match the directory name.</li><li>Standard library packages like , , etc., come with Go installation.</li><li>You can create custom packages for better code structure.</li><li>Use  to initialize a new module (which can contain multiple packages).</li></ul><p>By following these best practices, you can effectively manage code in Go using packages.</p>","contentLength":1373,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Comments on Executive Order 14168","url":"https://aphyr.com/posts/380-comments-on-executive-order-14168","date":1740179095,"author":"Aphyr","guid":8872,"unread":true,"content":"<p>Executive order 14168 is biologically incoherent and socially cruel. All passport applicants should be allowed to select whatever gender markers they feel best fit, including M, F, or X.</p><p>In humans, neither sex nor gender is binary at any level. There are several possible arrangements of sex chromosomes: X, XX, XY, XXY, XYY, XXX, tetrasomies, pentasomies, etc. A single person can contain a mosaic of cells with different genetics: some XX, some XYY. Chromosomes may not align with genitalia: people with XY chromosomes may have a vulva and internal testes. People with XY chromosomes and a small penis may be surgically and socially reassigned female at birth‚Äîand never told what happened. None of these biological dimensions necessarily align with one‚Äôs internal concept of gender, or one‚Äôs social presentation.</p><p>The executive order has no idea how biology works. It defines ‚Äúfemale‚Äù as ‚Äúa person belonging, at conception, to the sex that produces the large reproductive cell‚Äù. Zygotes do not produce reproductive cells at all: under this order none  of us have a sex. Oogenesis doesn‚Äôt start until over a month into embryo development. Even if people were karyotyping their zygotes immediately after conception so they could tell what ‚Äúlegal‚Äù sex they were going to be, they could be wrong: which gametes we produce depends on the formation of the genital ridge.</p><p>All this is to say that if people fill out these forms using this definition of sex, they‚Äôre guessing at a question which is both impossible to answer and socially irrelevant. You might be one of the roughly two percent of humans born with an uncommon sexual development and not even know it. Moreover, the proposed change fundamentally asks the wrong question: gender markers on passports are used by border control agents, and are expected to align with how those agents read the passport holder‚Äôs gender. A mismatch will create needless intimidation and hardship for travelers.</p><p>Of course most of us will not have our identities challenged under this order. That animus is reserved for trans people, for gender-non-conforming people, for anyone whose genetics, body, dress, voice, or mannerisms don‚Äôt quite fit the mold. Those are the people who will suffer under this order. That cruelty should be resisted.</p>","contentLength":2298,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tk9.0 canvas demo","url":"https://opu.peklo.biz/p/25/02/21/1740170028-43ac6.png","date":1740170311,"author":"/u/0xjnml","guid":8897,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iv11dh/tk90_canvas_demo/"},{"title":"Installing Golang on Windows WSL/WSL2","url":"https://dev.to/sonishivam10/installing-golang-on-windows-wslwsl2-3pn5","date":1740169411,"author":"ShivamS","guid":8810,"unread":true,"content":"<p>Official Go documentation might not provide the steps to install Go on WSL/WSL2. If you want to install GoLang and set up the development environment, follow these steps:</p><ul><li><p>Open your terminal and use the command to download the specific version.\nNote: Replace <strong>go1.24.0.linux-amd64.tar.gz</strong> with the latest version.<code>wget https://dl.google.com/go/go1.24.0.linux-amd64.tar.gz</code></p></li><li><p>Unzip:<code>sudo tar -xvf go1.24.0.linux-amd64.tar.gz</code></p></li><li><p>Move to the correct path.</p></li></ul><div><pre><code>echo \"export GOROOT=/usr/local/go\" &gt;&gt; ~/.bashrc\necho \"export GOPATH=\\$HOME/go\" &gt;&gt; ~/.bashrc\necho \"export PATH=\\$GOPATH/bin:\\$GOROOT/bin:\\$PATH\" &gt;&gt; ~/.bashrc\n</code></pre></div><ul><li><p>Refresh the terminal:</p></li><li><p>Verify the Go version.</p></li></ul>","contentLength":638,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learn how to set up and deploy apps to your own VPS or bare metal using Sidekick. Sidekick is an alternative to Kamal and Coolify, with over 6.5k GitHub stars","url":"https://dev.to/pmbanugo/learn-how-to-set-up-and-deploy-apps-to-your-own-vps-or-bare-metal-using-sidekick-sidekick-is-an-42od","date":1740166290,"author":"Peter Mbanugo","guid":8788,"unread":true,"content":"<h2>Self-hosting on bare metal and Cloud VM - Deploy like a Pro with Sidekick</h2>","contentLength":73,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Self-hosting on bare metal and Cloud VM - Deploy like a Pro with Sidekick","url":"https://dev.to/pmbanugo/self-hosting-on-bare-metal-and-cloud-vm-deploy-like-a-pro-with-sidekick-2b27","date":1740165668,"author":"Peter Mbanugo","guid":8787,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"list of decimal packages: fixed and big","url":"https://www.reddit.com/r/golang/comments/1iuunf1/list_of_decimal_packages_fixed_and_big/","date":1740154589,"author":"/u/kardianos","guid":8830,"unread":true,"content":"<p>I was updating a list of decimal packages. I thought I would share.</p><p>There are generally 2 varieties: fixed sized and arbitrary precision. The udecimal is interesting as it uses a fixed size for 128 bit precision with zero allocations, then uses an allocating \"*big.Int\" version for anything larger then that.</p><p>I currently use \"cockroachdb/apd\", which is a great package for frameworks or databases, but, it's a bit awkward to hold and lacks good formating. Realistically, I just need a fixed size decimal for my needs (financial/clinical). When I get a chance, I'll probably swap in for one of the fixed size packages.</p>","contentLength":615,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Talk me out of using Mongo","url":"https://www.reddit.com/r/golang/comments/1iutb24/talk_me_out_of_using_mongo/","date":1740151172,"author":"/u/grdevops","guid":8652,"unread":true,"content":"<p>Talk me out of using Mongo for a project I'm starting and intend to make a publicly available service. I  love how native Mongo feels for golang, specifically structs. I have a fair amount of utils written for it and it's basically at a copy and paste stage when I'm adding it to different structs and different types. </p><p>Undeniably, Mongo is what I'm comfortable with have spend the most time writing and the queries are dead simple in Go (to me at least) compared to Postgres where I have not had luck with embedded structs and getting them to easily insert or scanned when querying (especially many rows) using sqlx. Getting better at postgres is something I can do and am absolutely 100% willing to do if it's the right choice, I just haven't run into the issues with Mongo that I've seen other people have</p><p>As far as the data goes, there's not a ton of places where I would need to do joins, maybe 5% of the total DB calls or less and I know that's where Mongo gets most of its flak. </p>","contentLength":984,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go Panic and Recover: A Deep Dive into Error Handling","url":"https://dev.to/leapcell/go-panic-and-recover-a-deep-dive-into-error-handling-56be","date":1740150048,"author":"Leapcell","guid":8648,"unread":true,"content":"<p>In the Go language, there are two keywords that often appear in pairs ‚Äî panic and recover. These two keywords are closely related to defer. They are both built-in functions in the Go language and provide complementary functions.</p><h2>\n  \n  \n  I. Basic Functions of panic and recover\n</h2><ul><li>: It can change the control flow of the program. After calling panic, the remaining code of the current function will be immediately stopped from execution, and the defer of the caller will be recursively executed in the current Goroutine.</li><li>: It can stop the program crash caused by panic. It is a function that can only take effect in defer. Calling it in other scopes will not have any effect.</li></ul><h2>\n  \n  \n  II. Phenomena When Using panic and recover\n</h2><h3>\n  \n  \n  (I) panic Only Triggers the defer of the Current Goroutine\n</h3><p>The following code demonstrates this phenomenon:</p><div><pre><code></code></pre></div><p>The running result is as follows:</p><div><pre><code>$ go run main.go\nin goroutine\npanic:\n...\n</code></pre></div><p>When running this code, it will be found that the defer statement in the main function is not executed, and only the defer in the current Goroutine is executed. Because the runtime.deferproc corresponding to the defer keyword will associate the deferred call function with the Goroutine where the caller is located, so when the program crashes, only the deferred call function of the current Goroutine will be called.</p><h3>\n  \n  \n  (II) recover Only Takes Effect When Called in defer\n</h3><p>The following code reflects this feature:</p><div><pre><code></code></pre></div><div><pre><code>$ go run main.go\nin main\npanic: unknown err\ngoroutine 1 [running]:\nmain.main()\n ...\nexit status 2\n</code></pre></div><p>By carefully analyzing this process, it can be known that recover will only take effect when called after a panic occurs. However, in the above control flow, recover is called before panic, which does not meet the conditions for taking effect. Therefore, the recover keyword needs to be used in defer.</p><h3>\n  \n  \n  (III) panic Allows Multiple Nested Calls in defer\n</h3><p>The following code shows how to call panic multiple times in a defer function:</p><div><pre><code></code></pre></div><p>The running result is as follows:</p><div><pre><code>$ go run main.go\nin main\npanic: panic once\n  panic: panic again\n  panic: panic again and again\ngoroutine 1 [running]:\n...\nexit status 2\n</code></pre></div><p>From the output result of the above program, it can be determined that multiple calls to panic in the program will not affect the normal execution of the defer function. Therefore, it is generally safe to use defer for the finalization work.</p><h2>\n  \n  \n  III. Data Structure of panic\n</h2><p>The panic keyword in the source code of the Go language is represented by the data structure runtime._panic. Every time panic is called, a data structure like the following will be created to store relevant information:</p><div><pre><code></code></pre></div><ul><li>: It is a pointer to the parameter when defer is called.</li><li>: It is the parameter passed in when panic is called.</li><li>: It points to the earlier called runtime._panic structure.</li><li>: It indicates whether the current runtime._panic has been recovered by recover.</li><li>: It indicates whether the current panic has been forcibly terminated.</li></ul><p>From the link field in the data structure, it can be inferred that the panic function can be called continuously multiple times, and they can form a linked list through the link.</p><p>The three fields pc, sp, and goexit in the structure are all introduced to fix the problems brought by runtime.Goexit. runtime.Goexit can only end the Goroutine that calls this function without affecting other Goroutines. However, this function will be cancelled by the panic and recover in defer. The introduction of these three fields is to ensure that this function will definitely take effect.</p><h2>\n  \n  \n  IV. Principle of Program Crash\n</h2><p>The compiler will convert the keyword panic into runtime.gopanic. The execution process of this function includes the following steps:</p><ol><li>Create a new runtime._panic and add it to the front of the _panic linked list of the Goroutine where it is located.</li><li>Continuously obtain runtime._defer from the _defer linked list of the current Goroutine in a loop and call runtime.reflectcall to run the deferred call function.</li><li>Call runtime.fatalpanic to abort the entire program.\n</li></ol><div><pre><code></code></pre></div><p>It should be noted that three relatively important parts of code are omitted in the above function:</p><ol><li>The code in the recover branch for restoring the program.</li><li>The code for optimizing the performance of the defer call through inlining.</li><li>The code for fixing the abnormal situation of runtime.Goexit.</li></ol><p>In version 1.14, the Go language solved the conflict between recursive panic and recover and runtime.Goexit through the submission of runtime: ensure that Goexit cannot be aborted by a recursive panic/recover.</p><p>runtime.fatalpanic implements a program crash that cannot be recovered. Before aborting the program, it will print out all the panic messages and the parameters passed in during the call through runtime.printpanics:</p><div><pre><code></code></pre></div><p>After printing the crash message, it will call runtime.exit to exit the current program and return the error code 2. The normal exit of the program is also implemented through runtime.exit.</p><h2>\n  \n  \n  V. Principle of Crash Recovery\n</h2><p>The compiler will convert the keyword recover into runtime.gorecover:</p><div><pre><code></code></pre></div><p>The implementation of this function is very simple. If the current Goroutine has not called panic, then this function will directly return nil, which is also the reason why the crash recovery will fail when called in a non-defer. Under normal circumstances, it will modify the recovered field of runtime._panic, and the recovery of the program is handled by the runtime.gopanic function:</p><div><pre><code></code></pre></div><p>The above code omits the inlining optimization of defer. It takes out the program counter pc and stack pointer sp from runtime._defer and calls the runtime.recovery function to trigger the scheduling of the Goroutine. Before the scheduling, it will prepare the sp, pc, and the return value of the function:</p><div><pre><code></code></pre></div><p>When the defer keyword is called, the stack pointer sp and program counter pc at the time of the call have already been stored in the runtime._defer structure. The runtime.gogo function here will jump back to the position where the defer keyword was called.</p><p>runtime.recovery will set the return value of the function to 1 during the scheduling process. From the comments of runtime.deferproc, it can be found that when the return value of the runtime.deferproc function is 1, the code generated by the compiler will directly jump to before the return of the caller function and execute runtime.deferreturn:</p><div><pre><code></code></pre></div><p>After jumping to the runtime.deferreturn function, the program has been recovered from the panic and executes the normal logic, and the runtime.gorecover function can also take out the arg parameter passed in when calling panic from the runtime._panic structure and return it to the caller.</p><p>Analyzing the crash and recovery process of the program is rather tricky, and the code is not particularly easy to understand. Here is a simple summary of the program crash and recovery process:</p><ol><li>The compiler is responsible for the work of converting keywords. It converts panic and recover into runtime.gopanic and runtime.gorecover respectively, converts defer into the runtime.deferproc function, and calls the runtime.deferreturn function at the end of the function that calls defer.</li><li>When encountering the runtime.gopanic method during the running process, it will successively take out the runtime._defer structure from the linked list of the Goroutine and execute it.</li><li>If runtime.gorecover is encountered when calling the deferred execution function, it will mark _panic.recovered as true and return the parameter of the panic.</li><li>After this call ends, runtime.gopanic will take out the program counter pc and stack pointer sp from the runtime._defer structure and call the runtime.recovery function to restore the program.</li><li>runtime.recovery will jump back to runtime.deferproc according to the passed-in pc and sp.</li><li>The code automatically generated by the compiler will find that the return value of runtime.deferproc is not 0. At this time, it will jump back to runtime.deferreturn and restore to the normal execution flow.</li><li>If runtime.gorecover is not encountered, it will traverse all the runtime._defer in turn, and finally call runtime.fatalpanic to abort the program, print the parameters of the panic, and return the error code 2.</li></ol><p>The analysis process involves a lot of knowledge at the underlying level of the language, and the source code is also relatively obscure to read. It is full of unconventional control flows, jumping back and forth through the program counter. However, it is still very helpful for understanding the execution flow of the program. </p><p>Finally, I would like to recommend the most suitable deployment platform: </p><h3>\n  \n  \n  1. Multi-Language Support\n</h3><ul><li>Develop with JavaScript, Python, Go, or Rust.\n</li></ul><h3>\n  \n  \n  2. Deploy unlimited projects for free\n</h3><ul><li>pay only for usage ‚Äî no requests, no charges.</li></ul><h3>\n  \n  \n  3. Unbeatable Cost Efficiency\n</h3><ul><li>Pay-as-you-go with no idle charges.\n</li><li>Example: $25 supports 6.94M requests at a 60ms average response time.\n</li></ul><h3>\n  \n  \n  4. Streamlined Developer Experience\n</h3><ul><li>Intuitive UI for effortless setup.\n</li><li>Fully automated CI/CD pipelines and GitOps integration.\n</li><li>Real-time metrics and logging for actionable insights.\n</li></ul><h3>\n  \n  \n  5. Effortless Scalability and High Performance\n</h3><ul><li>Auto-scaling to handle high concurrency with ease.\n</li><li>Zero operational overhead ‚Äî just focus on building.\n</li></ul>","contentLength":9238,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"In-depth Guide to net/netip Prefix Methods 7/7","url":"https://dev.to/rezmoss/in-depth-guide-to-netnetip-prefix-methods-77-4b3c","date":1740150000,"author":"Rez Moss","guid":8657,"unread":true,"content":"<p>Hey there! We've made it to our final deep dive into net/netip's core types. Today we're focusing on the Prefix type and its methods. If you've worked with networks, you're familiar with CIDR notation (like 192.168.1.0/24). That's exactly what Prefix handles, and we're going to explore every method you can use with it.</p><p>Let's start by looking at all the ways to create and work with Prefix.</p><div><pre><code></code></pre></div><p>Let's explore the essential methods every Prefix provides:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  1. IPAM (IP Address Management) System\n</h3><p>A comprehensive IPAM system using Prefix:</p><div><pre><code></code></pre></div><p>A tool for network planning and analysis:</p><div><pre><code></code></pre></div><p>A system for managing network access control lists:</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><ol><li><strong>Handle IPv4 and IPv6 Appropriately</strong></li></ol><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>This concludes our deep dive into the net/netip package! We've covered:</p><ul><li>Addr type and its methods</li><li>AddrPort for handling IP:port combinations</li><li>Prefix for working with CIDR networks</li></ul><p>These types work together to provide a robust foundation for network programming in Go. The key benefits of using net/netip include:</p><ul><li>Comprehensive functionality</li></ul><p>Remember to check the Go documentation for updates and new features. The package continues to evolve with the language.</p><p>Keep exploring and building great networking applications with Go!</p>","contentLength":1182,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Relation with tpl and Html on VSCode?","url":"https://dev.to/skyhayato/how-relation-with-tpl-and-html-on-vscode-11a9","date":1740147550,"author":"SKY-HaYaTo","guid":8636,"unread":true,"content":"<p>Hi,Guys! \nI'm Kohei,a Software Engineer in Japan.</p><p>I am talking about a function of VSCode.</p><p>Now, The Topic is about Relationship with these extension  and  on Visual Studio Code(VSCode).</p><p>Extension  is often used in Web Framework of PHP.</p><p>Recently, I develop personal Web apps using  and  which is one of Web MVC Frameworks of Golang.</p><p> is generally used  as template engine.So, I need to make VSCode recognize  extension like .</p><p>In this article, you do'nt install any plugins with ,but revide  on VSCode.</p><p>VSCode is the most popular Free IDE and used in the world.\nAn one of nice functions on the IDE is to relation variaty of extension.</p><p>As my memorandom and shrering with you,I have decited to write the article.</p><p>Ok,Now,Let's explanation!</p><p>In conclution, only 3 steps is completed.</p><h2>\n  \n  \n  Start VSCode and Click Prompt Screen\n</h2><p>Top of the VSCode is set (as a below picture).\nYou click on cursor.</p><h2>\n  \n  \n  Input Value of  in the screen\n</h2><p>Next,You need to input the value .\nIf maybe you continue to type , key intellisence will start and display some canditates including .</p><p>When you see the word,click it!</p><p>Then target page will transition to .</p><h2>\n  \n  \n  Revision Settings.json File\n</h2><p>When display ,you will type String of sentense (below the capture).</p><p>You input the senetences,please save the revision.</p><p>From now, we can relationship with  and .</p>","contentLength":1315,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"6 New AI-Powered Tech Startups Reach Unicorn Status in January 2025","url":"https://dev.to/saad_hassan_8f937dc6fafc9/6-new-ai-powered-tech-startups-reach-unicorn-status-in-january-2025-pa3","date":1740145657,"author":"Saad Hassan","guid":8604,"unread":true,"content":"<p>Six cutting-edge AI startups have skyrocketed to unicorn status in January 2025, shaking up industries like healthcare, cybersecurity, automation, and defense. With billion-dollar valuations and massive investments, these companies‚ÄîTruveta, Codeium, Mercor, Augury, Neko Health, and Epirus‚Äîare redefining the future of tech. From AI-driven medical breakthroughs to next-gen coding assistants, the surge in AI funding signals a new era of innovation</p>","contentLength":452,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gofs - a file server written in go","url":"https://www.reddit.com/r/golang/comments/1iuqggw/gofs_a_file_server_written_in_go/","date":1740143207,"author":"/u/-dtdt-","guid":9077,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/-dtdt-\"> /u/-dtdt- </a>","contentLength":29,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I built a new playground for Go","url":"https://codiew.io/ide?t=go","date":1740140631,"author":"/u/Halabooda","guid":8597,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iupnrn/i_built_a_new_playground_for_go/"},{"title":"Junior, Trying to understand why startups use golang for backend","url":"https://www.reddit.com/r/golang/comments/1iup4di/junior_trying_to_understand_why_startups_use/","date":1740138781,"author":"/u/FriendshipOk6564","guid":8573,"unread":true,"content":"<p>Hello,i just took a look at the website 'who is hiring' and saw a lot of startups using ruby on rails and golang in their stack and i'm confuse, the path isn't normally mvp in rails and after some companies will rewrite their wall backend at some point in something like Java spring? it append for netflix but also a big company where i live. Why would they mixte ror and golang? Those it mean they are rewriting their ror in a microservice architecture in go?</p>","contentLength":460,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to properly prepare monorepos in Golang and is it worth it?","url":"https://www.reddit.com/r/golang/comments/1iuoppk/how_to_properly_prepare_monorepos_in_golang_and/","date":1740137237,"author":"/u/GoDuffer","guid":8780,"unread":true,"content":"<p>Hello everyone. At the moment I am writing a report on the topic of a monorepo in order to close my internship at the university.</p><p>Since I am a Go developer (or at least I aspire to be one), I decided to make a monorepo in Go.</p><p>The first thing I came across was an article from Uber about how they use Bazel and I started digging in this direction.</p><p>And then I realized that it was too complicated for small projects and I became interested.</p><p>Does it make sense to use a monorepo on small projects? If not, how to split the application into services? Or store each service in a separate repository.</p><p>In Java, everything is trivially simple with their modules and Gradle. Yes, Go has modules and a workspace, but let's be honest, this is not the level of Gradle.</p><p>As a result, we have that Bazel is too complicated for simple projects, and gowork seems somehow cut down after Gradle.</p><ol><li><p>Monorepo or polyrepo for Go?</p></li><li><p>Is there anything other than go work and Bazel?</p></li><li><p>What is the correct way to split a Go project so that it looks like a Solution in C#, or modules in Java/Gradle?</p></li></ol><p>It is quite possible that I really don't understand the architecture of Go projects, I will be glad if you point me in the right direction.</p>","contentLength":1196,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Deeper Love of Go (Go 1.24 early access edition)","url":"https://bitfieldconsulting.com/books/deeper","date":1740136216,"author":"/u/bitfieldconsulting","guid":8525,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iuogi4/the_deeper_love_of_go_go_124_early_access_edition/"},{"title":"My experience after switching from Java to Go","url":"https://www.reddit.com/r/golang/comments/1iuni44/my_experience_after_switching_from_java_to_go/","date":1740132223,"author":"/u/hosmanagic","guid":8498,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/hosmanagic\"> /u/hosmanagic </a>","contentLength":33,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"reddittui - A terminal browser for reddit","url":"https://github.com/tonymajestro/reddit-tui","date":1740124441,"author":"/u/tmajest","guid":8438,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iulout/reddittui_a_terminal_browser_for_reddit/"},{"title":"creating your own Docker like what a shiny title and hard work A year ago, I built a minimal container in Go. Now, it's time for a revisit! This time, I'm tackling network isolation, resource limits, and deeper container architecture.","url":"https://dev.to/micromax/creating-your-own-docker-like-what-a-shiny-title-and-hard-work-a-year-ago-i-built-a-minimal-53fc","date":1740101152,"author":"mohamed alaaeldin","guid":7546,"unread":true,"content":"<h2>Beyond Basics: Building a More Powerful Container in Go ‚Äî Network Isolation &amp; Advanced Features</h2><h3>mohamed alaaeldin „Éª Feb 21</h3>","contentLength":125,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Beyond Basics: Building a More Powerful Container in Go ‚Äî Network Isolation & Advanced Features","url":"https://dev.to/micromax/beyond-basics-building-a-more-powerful-container-in-go-network-isolation-advanced-features-3674","date":1740100901,"author":"mohamed alaaeldin","guid":7518,"unread":true,"content":"<p><em>Containers Uncovered: More Than Just Lightweight Virtual Machines!‚Äù</em></p><blockquote><p>If you‚Äôre like me ‚Äî always wondering how things work and eager to build them with your own mind and hands ‚Äî you‚Äôre in the right place!\n    In the first part of this <a href=\"https://dev.to/micromax/creating-a-minimal-container-in-go-a-step-by-step-guide-283b\">article (Part 1)</a>, I attempted to build a minimal container system using only Go, relying on Linux‚Äôs unshare and namespaces. It was purely a demonstration, and I wasn‚Äôt aiming to develop a fully functional container runtime tool. I intentionally left out many critical aspects, such as security, networking, and image management.\n    I initially thought it would be simple, but I quickly realized that even a basic container system involves thousands of concepts and implementations. However, my passion for understanding and building things kept me going.<p>\n    Now, after a year since my first article on Building a Minimal Container in Go, I‚Äôve realized that both my code and my original article need a fresh perspective. So, it‚Äôs time for a revisit!</p></p></blockquote><ol><li><p>Responsibilities:\nParse user commands (run, exec, ps, rm)<p>\nCommunicate with daemon via RPC or any other way</p>\nFormat and display output</p></li></ol><div><pre><code>Command completion\nOutput formatting (JSON/YAML)\nLog streaming\n</code></pre></div><div><pre><code>Manage container lifecycle\nMaintain container state database\nCoordinate between components\n</code></pre></div><div><pre><code>REST/gRPC API\nEvent logging\nResource tracking\n</code></pre></div><div><pre><code>Namespace Manager: CLONE_NEW* flags handling and more flags in real world .\nCgroups Manager: Resource constraints\nFilesystem Setup: RootFS preparation\n</code></pre></div><div><pre><code>OCI runtime spec compliance\nUser namespace remapping\nSeccomp/AppArmor profiles\n</code></pre></div><div><pre><code>Registry Client: Docker Hub integration or you own images services if you will go wiled\nLayer Manager: OverlayFS/BTRFS\nSnapshotter: Copy-on-write layers\n</code></pre></div><div><pre><code>Image caching\nSignature verification\nGarbage collection\n</code></pre></div><div><pre><code>CNI Plugins: Bridge, MACVLAN, IPVLAN\nIPAM: DHCP/Static allocation\nService Mesh: DNS, service discovery\n</code></pre></div><div><pre><code>Multi-host networking\nNetwork policies\nPort mapping\n</code></pre></div><div><pre><code>Volume Manager: Bind mounts\nSnapshot Manager: Incremental backups\nQuota Enforcer: Disk limits\n</code></pre></div><div><pre><code>Persistent storage\nTemporary filesystems\nEncryption support\n</code></pre></div><p>this schema will give you a bigger picture</p><div><pre><code>\n                           +---------------------+\n                           |      User CLI       |\n                           | (run, exec, ps, rm) |\n                           +----------+----------+\n                                      |\n                                      | (gRPC/HTTP)\n                                      v\n                           +---------------------+\n                           |   Container Daemon  |\n                           | (State Management)  |\n                           +----------+----------+\n                                      |\n                   +------------------+------------------+\n                   |                  |                  |\n         +----------+----------+ +-----+--------+ +-------+---------+\n         |   Container Runtime | | Image Service| | Network Manager |\n         | (namespace/cgroups) | | (OCI Images)  | | (CNI Plugins)   |\n         +----------+----------+ +-----+--------+ +-------+---------+\n                   |                  |                  |\n         +---------v---------+ +------v-------+ +--------v---------+\n         | Linux Kernel       | | Storage Driver| | Host Networking |\n         | - namespaces       | | (OverlayFS)   | | (iptables/bridge)|\n         | - cgroups v2       | +---------------+ +------------------+\n         | - capabilities     |\n         +--------------------+\n</code></pre></div><p>It has been a long journey for me to learn and think through every component. I encountered many challenges, especially with aspects like OverlayFS and networking.</p><p>My biggest issue in my first implementation was networking. It was really difficult to isolate the child container and set up its own bridged network.</p><p>To solve network isolation, you need to think clearly ü§î at this stage.</p><p>First, you need to create a bridge on the host with two virtual interfaces:</p><div><pre><code>The first interface remains on the host.\nThe second interface is moved to the child container ü´ô.\n</code></pre></div><p>The real challenge here is managing command signaling between the host and the child container.</p><p>In my approach, I will attempt to create a proof of concept implementation.\nUnderstanding Container Networking</p><p>When we create containers, one of the most crucial aspects is network isolation. Think of it like giving each container its own private network environment, complete with its own network interfaces, IP addresses, and routing rules. Let‚Äôs break down how we achieve this in our container implementation.\nThe Network Setup Process</p><ol><li>Creating the Network Namespace</li></ol><p>First, we create a separate network namespace for our container. This is like giving the container its own private networking room:</p><div><pre><code>const ContainerName = \"mycontainer\"\n\nfunc createNetworkNamespace(name string) error {\n    // Create directory for network namespaces\n    if err := os.MkdirAll(\"/var/run/netns\", 0755); err != nil {\n        return err\n    }\n\n    // Create the namespace file\n    nsFile := filepath.Join(\"/var/run/netns\", name)\n    fd, err := os.Create(nsFile)\n    if err != nil {\n        return err\n    }\n    fd.Close()\n\n    // Bind mount it to make it accessible\n    return syscall.Mount(\"/proc/self/ns/net\", nsFile, \"bind\", syscall.MS_BIND, \"\")\n}\n</code></pre></div><ol><li>Setting Up Virtual Network Interfaces</li></ol><p>We create a virtual network cable (veth pair) to connect our container to the host system:</p><div><pre><code>const (\n    VethHost      = \"veth0\"  // Host end of the cable\n    VethContainer = \"veth1\"  // Container end of the cable\n    ContainerIP   = \"10.0.0.2/24\"\n    HostIP        = \"10.0.0.1/24\"\n    Gateway       = \"10.0.0.1\"\n)\n</code></pre></div><p>The setup happens in two parts:\n1-On the host side:</p><div><pre><code>func setupHostNetwork(pid int) error {\n    // Create the virtual network cable (veth pair)\n    if err := exec.Command(\"ip\", \"link\", \"add\", VethHost, \"type\", \"veth\", \n        \"peer\", \"name\", VethContainer).Run(); err != nil {\n        return fmt.Errorf(\"failed to create veth pair: %v\", err)\n    }\n\n    // Move one end to the container\n    if err := exec.Command(\"ip\", \"link\", \"set\", VethContainer, \n        \"netns\", fmt.Sprintf(\"%d\", pid)).Run(); err != nil {\n        return fmt.Errorf(\"failed to move veth to container: %v\", err)\n    }\n\n    // Configure the host end\n    if err := exec.Command(\"ip\", \"link\", \"set\", VethHost, \"up\").Run(); err != nil {\n        return fmt.Errorf(\"failed to bring up host interface: %v\", err)\n    }\n    if err := exec.Command(\"ip\", \"addr\", \"add\", HostIP, \"dev\", VethHost).Run(); err != nil {\n        return fmt.Errorf(\"failed to assign IP to host interface: %v\", err)\n    }\n}\n</code></pre></div><p>2 ‚Äî Inside the container:</p><div><pre><code>func setupContainerNetwork() error {\n    // Enable the loopback interface\n    if err := exec.Command(\"ip\", \"link\", \"set\", \"lo\", \"up\").Run(); err != nil {\n        return fmt.Errorf(\"failed to bring up lo: %v\", err)\n    }\n\n    // Configure the container's network interface\n    if err := exec.Command(\"ip\", \"link\", \"set\", VethContainer, \"up\").Run(); err != nil {\n        return fmt.Errorf(\"failed to bring up veth: %v\", err)\n    }\n    if err := exec.Command(\"ip\", \"addr\", \"add\", ContainerIP, \n        \"dev\", VethContainer).Run(); err != nil {\n        return fmt.Errorf(\"failed to assign IP to veth: %v\", err)\n    }\n    if err := exec.Command(\"ip\", \"route\", \"add\", \"default\", \n        \"via\", Gateway).Run(); err != nil {\n        return fmt.Errorf(\"failed to add default route: %v\", err)\n    }\n}\n</code></pre></div><p>To allow our container to access the internet, we need to set up NAT (Network Address Translation) rules. This is like setting up a router for our container:</p><div><pre><code>func setupHostNetwork(pid int) error {\n    // Get the host's internet-connected interface\n    iface, err := getDefaultInterface()\n    if err != nil {\n        return fmt.Errorf(\"failed to get default interface: %v\", err)\n    }\n\n    // Set up NAT and forwarding rules\n    cmds := [][]string{\n        {\"sysctl\", \"-w\", \"net.ipv4.ip_forward=1\"},\n        {\"iptables\", \"-t\", \"nat\", \"-A\", \"POSTROUTING\", \n            \"-s\", \"10.0.0.0/24\", \"-o\", iface, \"-j\", \"MASQUERADE\"},\n        {\"iptables\", \"-A\", \"FORWARD\", \"-i\", iface, \n            \"-o\", VethHost, \"-j\", \"ACCEPT\"},\n        {\"iptables\", \"-A\", \"FORWARD\", \"-i\", VethHost, \n            \"-o\", iface, \"-j\", \"ACCEPT\"},\n    }\n\n    for _, cmd := range cmds {\n        if out, err := exec.Command(cmd[0], cmd[1:]...).CombinedOutput(); err != nil {\n            return fmt.Errorf(\"failed %v: %s\\n%s\", cmd, err, out)\n        }\n    }\n}\n</code></pre></div><p><strong>finally , Resource Cleanup</strong></p><p>One often overlooked but crucial aspect is cleaning up network resources when the container stops. Our implementation handles this through a ResourceManager:</p><div><pre><code>\ntype ResourceManager struct {\n    containerName string\n    vethHost      string\n    mounts        []string\n    namespaces    []string\n}\n\nfunc (rm *ResourceManager) cleanupNetwork() error {\n    // Clean up iptables rules\n    if err := rm.cleanupIptablesRules(); err != nil {\n        log.Printf(\"Warning: iptables cleanup failed: %v\", err)\n    }\n\n    // Remove the virtual network interface\n    if out, err := exec.Command(\"ip\", \"link\", \"delete\", \n        rm.vethHost).CombinedOutput(); err != nil {\n        log.Printf(\"Warning: failed to delete veth interface: %v (%s)\", err, out)\n    }\n\n    return nil\n}\n</code></pre></div><p>How It All Works Together</p><div><pre><code>When starting a container:\n\nCreate a new network namespace\nCreate virtual network interfaces (veth pair)\nConfigure IP addresses and routing\nSet up NAT for internet access\nMount necessary filesystems and set up devices\n</code></pre></div><p>2 .During container runtime:</p><div><pre><code>Container uses its virtual network interface for all network communication\nOutgoing traffic goes through NAT to reach the internet\nIncoming traffic is routed back to the container\n</code></pre></div><p>3 . When stopping a container:</p><div><pre><code>Clean up iptables rules\nRemove virtual interfaces\nUnmount network namespace\nRemove namespace files\n</code></pre></div><p>Common Issues and Debugging</p><p>When implementing container networking, you might encounter these common issues:</p><div><pre><code>DNS Resolution Problems\n\nOur implementation includes DNS setup:\n</code></pre></div><div><pre><code>// in most cases this will case error , still trying to solve it \nfunc setupDNS() error {\n    resolvHost := \"/etc/resolv.conf\"\n    resolvContainer := filepath.Join(RootFS, \"etc/resolv.conf\")\n    return syscall.Mount(resolvHost, resolvContainer, \"bind\", \n        syscall.MS_BIND|syscall.MS_RDONLY, \"\")\n}\n</code></pre></div><p>2.Network Interface Issues</p><div><pre><code>Always check interface status with ip link show\nVerify IP assignments with ip addr show\nCheck routing with ip route show\n</code></pre></div><div><pre><code>Verify iptables rules are correctly set\nCheck IP forwarding is enabled\nEnsure the host interface is up and working\n</code></pre></div><p>Our implementation includes several security features:</p><div><pre><code>Network Isolation\n\nEach container gets its own network namespace\nNetwork traffic is isolated between containers\n</code></pre></div><div><pre><code>Proper cleanup of network resources prevents resource leaks\nAutomatic cleanup on container exit\n</code></pre></div><p>This networking implementation provides a solid foundation for container isolation while maintaining internet connectivity. While it‚Äôs simpler than production container runtimes, it demonstrates the core concepts of container networking.</p><blockquote><p>this was the hard part for me and i have tryed so many implemention to achive that . you have to keep in main what and where your command executted . some times you find your self trying to create vath‚Äôs in continer or you cannot connect or move the continer interface from host to chiled</p></blockquote><p>you have to read my previeus articl to know what we are doing i had clean up my code and add every thing agine to test network isolation</p><p>do not forget to change RootFS to your root fs like ‚Äúubuntu or whatever image you will run‚Äù</p><div><pre><code>package main\n\nimport (\n \"fmt\"\n \"log\"\n \"os\"\n \"os/exec\"\n \"path/filepath\"\n \"strings\"\n \"syscall\"\n \"os/signal\" \n)\n\nconst (\n ContainerName = \"mycontainer\"\n VethHost      = \"veth0\"\n VethContainer = \"veth1\"\n ContainerIP   = \"10.0.0.2/24\"\n HostIP        = \"10.0.0.1/24\"\n Gateway       = \"10.0.0.1\"\n RootFS        = \"/mnt/drive/go-projects/lc-images-regs/ubuntu_fs\"\n)\n\n\n\ntype ResourceManager struct {\n    containerName string\n    vethHost      string\n    mounts        []string\n    namespaces    []string\n}\nfunc NewResourceManager(containerName string) *ResourceManager {\n    return &amp;ResourceManager{\n        containerName: containerName,\n        vethHost:     VethHost,\n        mounts: []string{\n            \"/proc\",\n            \"/dev/pts\",\n            \"/dev\",\n        },\n        namespaces: []string{\n            \"net\",\n            \"uts\",\n            \"pid\",\n            \"ipc\",\n        },\n    }\n}\n\nfunc (rm *ResourceManager) Setup() {\n    // Set up signal handling\n    sigChan := make(chan os.Signal, 1)\n    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)\n\n    go func() {\n        sig := &lt;-sigChan\n        log.Printf(\"Received signal %v, cleaning up...\", sig)\n        rm.Cleanup()\n        os.Exit(1)\n    }()\n}\n\nfunc (rm *ResourceManager) Cleanup() error {\n    var errors []string\n\n    // 1. Clean up network resources\n    if err := rm.cleanupNetwork(); err != nil {\n        errors = append(errors, fmt.Sprintf(\"network cleanup error: %v\", err))\n    }\n\n    // 2. Clean up mounts\n    if err := rm.cleanupMounts(); err != nil {\n        errors = append(errors, fmt.Sprintf(\"mount cleanup error: %v\", err))\n    }\n\n    // 3. Clean up namespaces\n    if err := rm.cleanupNamespaces(); err != nil {\n        errors = append(errors, fmt.Sprintf(\"namespace cleanup error: %v\", err))\n    }\n\n    if len(errors) &gt; 0 {\n        return fmt.Errorf(\"cleanup errors: %s\", strings.Join(errors, \"; \"))\n    }\n    return nil\n}\n\nfunc (rm *ResourceManager) cleanupNetwork() error {\n    // Clean up iptables rules first\n    if err := rm.cleanupIptablesRules(); err != nil {\n        log.Printf(\"Warning: iptables cleanup failed: %v\", err)\n    }\n\n    // Clean up veth interfaces\n    if out, err := exec.Command(\"ip\", \"link\", \"delete\", rm.vethHost).CombinedOutput(); err != nil {\n        log.Printf(\"Warning: failed to delete veth interface: %v (%s)\", err, out)\n    }\n\n    return nil\n}\n\nfunc (rm *ResourceManager) cleanupIptablesRules() error {\n    iface, err := getDefaultInterface()\n    if err != nil {\n        return fmt.Errorf(\"failed to get default interface: %v\", err)\n    }\n\n    rules := [][]string{\n        {\"iptables\", \"-D\", \"FORWARD\", \"-i\", iface, \"-o\", rm.vethHost, \"-j\", \"ACCEPT\"},\n        {\"iptables\", \"-D\", \"FORWARD\", \"-i\", rm.vethHost, \"-o\", iface, \"-j\", \"ACCEPT\"},\n        {\"iptables\", \"-t\", \"nat\", \"-D\", \"POSTROUTING\", \"-s\", \"10.0.0.0/24\", \"-o\", iface, \"-j\", \"MASQUERADE\"},\n    }\n\n    for _, rule := range rules {\n        if out, err := exec.Command(rule[0], rule[1:]...).CombinedOutput(); err != nil {\n            log.Printf(\"Warning: failed to remove iptables rule: %v (%s)\", err, out)\n        }\n    }\n\n    return nil\n}\n\nfunc (rm *ResourceManager) cleanupMounts() error {\n    for _, mount := range rm.mounts {\n        mountPath := filepath.Join(RootFS, mount)\n        if err := syscall.Unmount(mountPath, syscall.MNT_DETACH); err != nil {\n            log.Printf(\"Warning: failed to unmount %s: %v\", mountPath, err)\n        }\n    }\n    return nil\n}\n\nfunc (rm *ResourceManager) cleanupNamespaces() error {\n    for _, ns := range rm.namespaces {\n        nsPath := filepath.Join(\"/var/run/netns\", rm.containerName)\n        if err := syscall.Unmount(nsPath, syscall.MNT_DETACH); err != nil {\n            log.Printf(\"Warning: failed to unmount namespace %s: %v\", ns, err)\n        }\n        if err := os.Remove(nsPath); err != nil {\n            log.Printf(\"Warning: failed to remove namespace file %s: %v\", nsPath, err)\n        }\n    }\n    return nil\n}\n\nfunc cleanupExistingResources() error {\n // Cleanup network namespace\n if _, err := os.Stat(\"/var/run/netns/\" + ContainerName); err == nil {\n  if err := cleanupNetworkNamespace(ContainerName); err != nil {\n   return fmt.Errorf(\"failed to cleanup existing network namespace: %v\", err)\n  }\n }\n\n // Cleanup veth interfaces\n if _, err := exec.Command(\"ip\", \"link\", \"show\", VethHost).CombinedOutput(); err == nil {\n  if err := exec.Command(\"ip\", \"link\", \"delete\", VethHost).Run(); err != nil {\n   return fmt.Errorf(\"failed to delete existing veth interface: %v\", err)\n  }\n }\n\n // Cleanup iptables rules\n if err := cleanupIptablesRules(); err != nil {\n  return fmt.Errorf(\"failed to cleanup iptables rules: %v\", err)\n }\n\n return nil\n}\n\nfunc cleanupIptablesRules() error {\n iface, err := getDefaultInterface()\n if err != nil {\n  return fmt.Errorf(\"failed to get default interface: %v\", err)\n }\n\n cmds := [][]string{\n  {\"iptables\", \"-D\", \"FORWARD\", \"-i\", iface, \"-o\", VethHost, \"-j\", \"ACCEPT\"},\n  {\"iptables\", \"-D\", \"FORWARD\", \"-i\", VethHost, \"-o\", iface, \"-j\", \"ACCEPT\"},\n  {\"iptables\", \"-t\", \"nat\", \"-D\", \"POSTROUTING\", \"-s\", \"10.0.0.0/24\", \"-o\", iface, \"-j\", \"MASQUERADE\"},\n }\n\n for _, cmd := range cmds {\n  // Ignore errors since rules might not exist\n  exec.Command(cmd[0], cmd[1:]...).Run()\n }\n\n return nil\n}\nfunc getDefaultInterface() (string, error) {\n out, err := exec.Command(\"ip\", \"route\", \"show\", \"default\").CombinedOutput()\n if err != nil {\n  return \"\", err\n }\n\n fields := strings.Fields(string(out))\n for i, field := range fields {\n  if field == \"dev\" &amp;&amp; i+1 &lt; len(fields) {\n   return fields[i+1], nil\n  }\n }\n\n return \"\", fmt.Errorf(\"no default interface found\")\n}\n\nfunc main() {\n if len(os.Args) &lt; 2 {\n  log.Fatal(\"Usage: [run|child] command [args...]\")\n }\n\n switch os.Args[1] {\n case \"run\":\n  run()\n case \"child\":\n  child()\n default:\n  log.Fatalf(\"unknown command: %s\", os.Args[1])\n }\n}\nfunc setupCgroups(ContainerName string , pid int, cpuShares, memoryLimitMB int) error {\n    cgroupBase := \"/sys/fs/cgroup\"\n    containerID := ContainerName // fmt.Sprintf(\"container_%d\", pid)\n\n    // Create CPU cgroup\n    cpuPath := filepath.Join(cgroupBase, \"cpu\", containerID)\n    os.MkdirAll(cpuPath, 0755)\n    os.WriteFile(filepath.Join(cpuPath, \"cpu.shares\"), []byte(fmt.Sprintf(\"%d\", cpuShares)), 0644)\n    os.WriteFile(filepath.Join(cpuPath, \"tasks\"), []byte(fmt.Sprintf(\"%d\", pid)), 0644)\n\n    // Create memory cgroup\n    memoryPath := filepath.Join(cgroupBase, \"memory\", containerID)\n    os.MkdirAll(memoryPath, 0755)\n    os.WriteFile(filepath.Join(memoryPath, \"memory.limit_in_bytes\"), []byte(fmt.Sprintf(\"%d\", memoryLimitMB*1024*1024)), 0644)\n    os.WriteFile(filepath.Join(memoryPath, \"tasks\"), []byte(fmt.Sprintf(\"%d\", pid)), 0644)\n\n\n uidMap := fmt.Sprintf(\"0 %d 1\", os.Getuid())\n gidMap := fmt.Sprintf(\"0 %d 1\", os.Getgid())\n\n os.WriteFile(fmt.Sprintf(\"/proc/%d/uid_map\", pid), []byte(uidMap), 0644)\n os.WriteFile(fmt.Sprintf(\"/proc/%d/gid_map\", pid), []byte(gidMap), 0644)\n    return nil\n}\nfunc run() {\n rm := NewResourceManager(ContainerName)\n    rm.Setup()\n    defer rm.Cleanup()\n\n if err := cleanupExistingResources(); err != nil {\n  log.Printf(\"Cleanup warning: %v\", err)\n }\n\n // Create network namespace\n if err := createNetworkNamespace(ContainerName); err != nil {\n  log.Fatalf(\"Failed to create network namespace: %v\", err)\n }\n\n // Start container process\n cmd := exec.Command(\"/proc/self/exe\", append([]string{\"child\"}, os.Args[2:]...)...)\n cmd.Stdin = os.Stdin\n cmd.Stdout = os.Stdout\n cmd.Stderr = os.Stderr\n cmd.SysProcAttr = &amp;syscall.SysProcAttr{\n  Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS | syscall.CLONE_NEWNET |\n\n  syscall.CLONE_NEWIPC ,\n\n\n }\n\n if err := cmd.Start(); err != nil {\n  log.Fatalf(\"Failed to start container: %v\", err)\n }\n pid := cmd.Process.Pid\n if err :=setupCgroups(ContainerName , pid , 512 , 256  ); err != nil { // Example: 512 CPU shares, 256 MB memory limit\n  log.Fatalf(\"Failed to setup cgroups: %v\", err)\n }\n // Configure host-side networking\n if err := setupHostNetwork(cmd.Process.Pid); err != nil {\n  log.Fatalf(\"Failed to setup host network: %v\", err)\n }\n\n // Wait for container to exit\n if err := cmd.Wait(); err != nil {\n  log.Fatalf(\"Container failed: %v\", err)\n }\n\n // Cleanup\n if err := cleanupNetworkNamespace(ContainerName); err != nil {\n  log.Printf(\"Failed to cleanup network namespace: %v\", err)\n }\n}\n\nfunc child() {\n // Setup container environment\n if err := setupContainer(); err != nil {\n  log.Fatalf(\"Failed to setup container: %v\", err)\n }\n\n // Execute command\n if len(os.Args) &lt; 3 {\n  log.Fatal(\"No command specified\")\n }\n cmd := exec.Command(os.Args[2], os.Args[3:]...)\n cmd.Stdin = os.Stdin\n cmd.Stdout = os.Stdout\n cmd.Stderr = os.Stderr\n if err := cmd.Run(); err != nil {\n  log.Fatalf(\"Command failed: %v\", err)\n }\n}\n\nfunc createNetworkNamespace(name string) error {\n // Create bind mount for ip netns compatibility\n if err := os.MkdirAll(\"/var/run/netns\", 0755); err != nil {\n  return err\n }\n\n // Create namespace file\n nsFile := filepath.Join(\"/var/run/netns\", name)\n fd, err := os.Create(nsFile)\n if err != nil {\n  return err\n }\n fd.Close()\n\n // Bind mount\n return syscall.Mount(\"/proc/self/ns/net\", nsFile, \"bind\", syscall.MS_BIND, \"\")\n}\n\nfunc cleanupNetworkNamespace(name string) error {\n nsFile := filepath.Join(\"/var/run/netns\", name)\n if err := syscall.Unmount(nsFile, 0); err != nil {\n  return fmt.Errorf(\"failed to unmount network namespace: %v\", err)\n }\n // Remove the file to complete cleanup.\n if err := os.Remove(nsFile); err != nil {\n  return fmt.Errorf(\"failed to remove namespace file %s: %v\", nsFile, err)\n }\n return nil\n}\n\n\nfunc setupHostNetwork(pid int) error {\n // Get host's default interface\n iface, err := getDefaultInterface()\n if err != nil {\n  return fmt.Errorf(\"failed to get default interface: %v\", err)\n }\n\n // Create veth pair\n if err := exec.Command(\"ip\", \"link\", \"add\", VethHost, \"type\", \"veth\", \"peer\", \"name\", VethContainer).Run(); err != nil {\n  return fmt.Errorf(\"failed to create veth pair: %v\", err)\n }\n\n // Move container end to namespace\n if err := exec.Command(\"ip\", \"link\", \"set\", VethContainer, \"netns\", fmt.Sprintf(\"%d\", pid)).Run(); err != nil {\n  return fmt.Errorf(\"failed to move veth to container: %v\", err)\n }\n\n // Configure host interface\n if err := exec.Command(\"ip\", \"link\", \"set\", VethHost, \"up\").Run(); err != nil {\n  return fmt.Errorf(\"failed to bring up host interface: %v\", err)\n }\n if err := exec.Command(\"ip\", \"addr\", \"add\", HostIP, \"dev\", VethHost).Run(); err != nil {\n  return fmt.Errorf(\"failed to assign IP to host interface: %v\", err)\n }\n\n cmds := [][]string{\n\n  {\"sysctl\", \"-w\", \"net.ipv4.ip_forward=1\"},\n  {\"iptables\", \"-t\", \"nat\", \"-A\", \"POSTROUTING\", \"-s\", \"10.0.0.0/24\", \"-o\", iface, \"-j\", \"MASQUERADE\"},\n  {\"iptables\", \"-A\", \"FORWARD\", \"-i\", iface, \"-o\", VethHost, \"-j\", \"ACCEPT\"},\n  {\"iptables\", \"-A\", \"FORWARD\", \"-i\", VethHost, \"-o\", iface, \"-j\", \"ACCEPT\"},\n }\n\n for _, cmd := range cmds {\n  if out, err := exec.Command(cmd[0], cmd[1:]...).CombinedOutput(); err != nil {\n   return fmt.Errorf(\"failed %v: %s\\n%s\", cmd, err, out)\n  }\n }\n\n return nil\n}\n\nfunc setupContainer() error {\n // Setup root filesystem\n if err := syscall.Chroot(RootFS); err != nil {\n  return fmt.Errorf(\"chroot failed: %v\", err)\n }\n if err := os.Chdir(\"/\"); err != nil {\n  return fmt.Errorf(\"chdir failed: %v\", err)\n }\n\n // Mount proc\n if err := syscall.Mount(\"proc\", \"/proc\", \"proc\", 0, \"\"); err != nil {\n  return fmt.Errorf(\"failed to mount proc: %v\", err)\n }\n\n // Setup devices\n if err := setupDevices(); err != nil {\n  return fmt.Errorf(\"failed to setup devices: %v\", err)\n }\n\n // Configure network\n if err := setupContainerNetwork(); err != nil {\n  return fmt.Errorf(\"failed to setup network: %v\", err)\n }\n\n //if err := setupDNS(); err != nil {\n // return fmt.Errorf(\"DNS setup failed: %v\", err)\n //}\n\n return nil\n}\n\nfunc setupDNS() error {\n // Copy host's resolv.conf\n resolvHost := \"/etc/resolv.conf\"\n resolvContainer := filepath.Join(RootFS, \"etc/resolv.conf\")\n\n // Create container's /etc if missing\n if err := os.MkdirAll(filepath.Join(RootFS, \"etc\"), 0755); err != nil {\n  return err\n }\n\n // Bind mount host's resolv.conf\n return syscall.Mount(resolvHost, resolvContainer, \"bind\", syscall.MS_BIND|syscall.MS_RDONLY, \"\")\n}\n\nfunc setupDevices() error {\n // Mount tmpfs for /dev\n if err := syscall.Mount(\"tmpfs\", \"/dev\", \"tmpfs\", 0, \"size=64k,mode=755\"); err != nil {\n  return err\n }\n\n // Create /dev/pts directory if missing\n devPts := \"/dev/pts\"\n if err := os.MkdirAll(devPts, 0755); err != nil {\n  return fmt.Errorf(\"mkdir %s failed: %v\", devPts, err)\n }\n\n // Mount devpts on /dev/pts for pty support\n if err := syscall.Mount(\"devpts\", devPts, \"devpts\", 0, \"mode=0620,ptmxmode=0666\"); err != nil {\n  return fmt.Errorf(\"failed to mount devpts on %s: %v\", devPts, err)\n }\n // Create basic devices\n devices := []struct {\n  name  string\n  major uint32\n  minor uint32\n }{\n  {\"null\", 1, 3},\n  {\"zero\", 1, 5},\n  {\"random\", 1, 8},\n  {\"urandom\", 1, 9},\n }\n\n for _, dev := range devices {\n  path := filepath.Join(\"/dev\", dev.name)\n  if err := syscall.Mknod(path, syscall.S_IFCHR|0666, int(makedev(dev.major, dev.minor))); err != nil {\n   return err\n  }\n }\n\n return nil\n}\n\nfunc makedev(major, minor uint32) uint64 {\n return (uint64(major) &lt;&lt; 8) | uint64(minor)\n}\n\nfunc setupContainerNetwork() error {\n // Bring up loopback\n if err := exec.Command(\"ip\", \"link\", \"set\", \"lo\", \"up\").Run(); err != nil {\n  return fmt.Errorf(\"failed to bring up lo: %v\", err)\n }\n\n // Configure veth interface\n if err := exec.Command(\"ip\", \"link\", \"set\", VethContainer, \"up\").Run(); err != nil {\n  return fmt.Errorf(\"failed to bring up veth: %v\", err)\n }\n if err := exec.Command(\"ip\", \"addr\", \"add\", ContainerIP, \"dev\", VethContainer).Run(); err != nil {\n  return fmt.Errorf(\"failed to assign IP to veth: %v\", err)\n }\n if err := exec.Command(\"ip\", \"route\", \"add\", \"default\", \"via\", Gateway).Run(); err != nil {\n  return fmt.Errorf(\"failed to add default route: %v\", err)\n }\n\n return nil\n}\n</code></pre></div><p>Important point: You must mount and create essential virtual devices and establish communication (such as pipes or signals) between the host and child container .</p><div><pre><code>func setupDevices() error {\n // Mount tmpfs for /dev\n if err := syscall.Mount(\"tmpfs\", \"/dev\", \"tmpfs\", 0, \"size=64k,mode=755\"); err != nil {\n  return err\n }\n\n // Create /dev/pts directory if missing\n devPts := \"/dev/pts\"\n if err := os.MkdirAll(devPts, 0755); err != nil {\n  return fmt.Errorf(\"mkdir %s failed: %v\", devPts, err)\n }\n\n // Mount devpts on /dev/pts for pty support\n if err := syscall.Mount(\"devpts\", devPts, \"devpts\", 0, \"mode=0620,ptmxmode=0666\"); err != nil {\n  return fmt.Errorf(\"failed to mount devpts on %s: %v\", devPts, err)\n }\n // Create basic devices\n devices := []struct {\n  name  string\n  major uint32\n  minor uint32\n }{\n  {\"null\", 1, 3},\n  {\"zero\", 1, 5},\n  {\"random\", 1, 8},\n  {\"urandom\", 1, 9},\n }\n\n for _, dev := range devices {\n  path := filepath.Join(\"/dev\", dev.name)\n  if err := syscall.Mknod(path, syscall.S_IFCHR|0666, int(makedev(dev.major, dev.minor))); err != nil {\n   return err\n  }\n }\n\n return nil\n}\n</code></pre></div><div><pre><code>func NewResourceManager(containerName string) *ResourceManager {\n    return &amp;ResourceManager{\n        containerName: containerName,\n        vethHost:     VethHost,\n        mounts: []string{\n            \"/proc\",\n            \"/dev/pts\",\n            \"/dev\",\n        },\n        namespaces: []string{\n            \"net\",\n            \"uts\",\n            \"pid\",\n            \"ipc\",\n        },\n    }\n}\n\nfunc (rm *ResourceManager) Setup() {\n    // Set up signal handling\n    sigChan := make(chan os.Signal, 1)\n    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)\n\n    go func() {\n        sig := &lt;-sigChan\n        log.Printf(\"Received signal %v, cleaning up...\", sig)\n        rm.Cleanup()\n        os.Exit(1)\n    }()\n}\n</code></pre></div><p>Now you have a broad overview, but you still have a long journey ahead to achieve what production-ready container runtime systems offer.</p><p>If you need system file images to test your code, you can use Docker to download one.</p><div><pre><code>$ docker run -d --rm --name ubuntu_fs ubuntu:20.04 sleep 1000\n$ mkdir -p ./ubuntu_fs\n$ docker cp ubuntu_fs:/ ./ubuntu_fs\n$ docker stop ubuntu_fs\n</code></pre></div><p>Or use tool like debootstrap</p><div><pre><code>sudo apt-get update\nsudo apt-get install debootstrap\nsudo mkdir -p /path/to/rootfs\nsudo debootstrap stable /path/to/rootfs http://deb.debian.org/debian\n</code></pre></div><p>Sometimes, while testing, you may need to install software in your container image from the host if your child container struggles to access the internet.</p><div><pre><code>sudo chroot /path/to/rootfs /bin/sh -c \"apk add --no-cache iproute2\"\n</code></pre></div><div><pre><code>sudo chroot /mnt/drive/go-projects/lc-images-regs/ubuntu_fs /bin/sh -c \"apt-get update &amp;&amp; apt-get install -y iproute2\"\n</code></pre></div><p>Note: Sometimes, when you try to start the container by running the following command to start Bash as the entry point, you may encounter a bug:</p><div><pre><code>sudo go run Main.go run sudo /bin/bash\n</code></pre></div><div><pre><code>2025/02/21 00:26:28 Failed to setup container: failed to setup network: failed to bring up veth: exit status 1\n2025/02/21 01:26:28 Failed to setup host network: failed to assign IP to host interface: exit status 1\nexit status 1\n\n\n</code></pre></div><p>This happens due to resource cleanup errors. You can either ignore it and retry the command up to three times or fix the issue.</p><p>You still need to implement DNS to align with the original system design. What we built is just a proof of concept application.</p><p>My next step is to ensure resource limitations and create an image composer like Docker while utilizing OverlayFS. Until then, if you need any help, feel free to DM me.</p><p>this is discord channel for this topic only join me :</p>","contentLength":29110,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Creating a Minimal Container in Go: A Step-by-Step Guide ( part 1 )","url":"https://dev.to/micromax/creating-a-minimal-container-in-go-a-step-by-step-guide-283b","date":1740100117,"author":"mohamed alaaeldin","guid":7517,"unread":true,"content":"<p><strong>What is Containers any way!</strong>\nContainers are lightweight, portable, and efficient, making them a popular choice for deploying and running applications. In this tutorial, we‚Äôll guide you through the process of creating a minimal container using Go. The example code provided focuses on essential containerization concepts, including namespaces, chroot, and control groups (cgroups).</p><p>Before getting started, ensure you have the following installed:</p><div><pre><code>Go programming language: Install Go\nBasic understanding of Linux namespaces and control groups\n</code></pre></div><p>introduction\nSo what is Linux namespaces and control groups ?</p><p>Namespaces have been part of the Linux kernel since about 2002, and over time more tooling and namespace types have been added. Real container support was added to the Linux kernel only in 2013, however. This is what made namespaces really useful and brought them to the masses.</p><p>But what are namespaces exactly? Here‚Äôs a wordy definition from Wikipedia:</p><p>‚ÄúNamespaces are a feature of the Linux kernel that partitions kernel resources such that one set of processes sees one set of resources while another set of processes sees a different set of resources.‚Äù</p><p>In other words, the key feature of namespaces is that they isolate processes from each other. On a server where you are running many different services, isolating each service and its associated processes from other services means that there is a smaller blast radius for changes, as well as a smaller footprint for security‚Äërelated concerns. Mostly though, isolating services meets the architectural style of microservices as described by Martin Fowler.\nTypes of Namespaces</p><p>Within the Linux kernel, there are different types of namespaces. Each namespace has its own unique properties:</p><div><pre><code>A user namespace has its own set of user IDs and group IDs for assignment to processes. In particular, this means that a process can have root privilege within its user namespace without having it in other user namespaces.\nA process ID (PID) namespace assigns a set of PIDs to processes that are independent from the set of PIDs in other namespaces. The first process created in a new namespace has PID 1 and child processes are assigned subsequent PIDs. If a child process is created with its own PID namespace, it has PID 1 in that namespace as well as its PID in the parent process‚Äô namespace. See below for an example.\nA network namespace has an independent network stack: its own private routing table, set of IP addresses, socket listing, connection tracking table, firewall, and other network‚Äërelated resources.\nA mount namespace has an independent list of mount points seen by the processes in the namespace. This means that you can mount and unmount filesystems in a mount namespace without affecting the host filesystem.\nAn interprocess communication (IPC) namespace has its own IPC resources, for example POSIX message queues.\nA UNIX Time‚ÄëSharing (UTS) namespace allows a single system to appear to have different host and domain names to different processes.\n\nthe container are fast isolated environment , we will focus on this part many things are involved and my main goal is to Demystifying Containers\n\nassuming that you are on a linux machine (try Power shell Ubuntu image if you are on Windows :-)\n</code></pre></div><div><pre><code>host-machine $ id\n\nuid=1000(mohamed) gid=1000(mohamed) groups=1000(mohamed) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c.1023\n</code></pre></div><p>Now I run the following unshare command to create a new namespace with its own user and PID namespaces. I map the root user to the new namespace (in other words, I have root privilege within the new namespace), mount a new proc filesystem, and fork my process (in this case, bash) in the newly created namespace.</p><p>unshare --user --pid --map-root-user --mount-proc --fork bash</p><p>Congratulation , you are in isolated name space and some how you are on\nisolated PID in same file system and same network , your entry point /bin/bash</p><p>The ps -ef command shows there are two processes running ‚Äì bash and the ps command itself ‚Äì and the id command confirms that I‚Äôm root in the new namespace (which is also indicated by the changed command prompt):</p><div><pre><code>root # ps -ef\nUID         PID     PPID  C STIME TTY        TIME CMD\nroot          1        0  0 14:46 pts/0  00:00:00 bash\nroot         15        1  0 14:46 pts/0  00:00:00 ps -ef\nroot # id\nuid=0(root) gid=0(root) groups=0(root) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c.1023\n</code></pre></div><p><strong>Namespaces and Containers</strong></p><blockquote><p>Namespaces are one of the technologies that containers are built on, used to enforce segregation of resources. We‚Äôve shown how to create namespaces manually, but container runtimes like Docker, rkt, podman , runC , containerD , and many other container technology\n    one of most unique projects are <a href=\"https://katacontainers.io/\" rel=\"noopener noreferrer\">https://katacontainers.io/</a> they claim that they are mix between container and VM‚Äôs .\nWhat Are cgroups?</p></blockquote><p>cgroups, or control groups, are a Linux kernel feature that enables the management and limitation of system resources like CPU, memory, and network bandwidth, among others. We can use cgroups to set limits on these resources and distribute them among different groups of processes.</p><p>cgroups have a hierarchical structure with root and child, each with resource limits set by controllers ‚Äî for example, a CPU controller for CPU time or a memory controller for memory.</p><p>We can use cgroups for various purposes, such as controlling resource usage in a multi-tenant environment, providing Quality of Service (QoS) guarantees, and running containers.</p><p>Cgroups provide the following features:</p><div><pre><code>Resource limits ‚Äî You can configure a cgroup to limit how much of a particular resource (memory or CPU, for example) a process can use.\nPrioritization ‚Äî You can control how much of a resource (CPU, disk, or network) a process can use compared to processes in another cgroup when there is resource contention.\nAccounting ‚Äî Resource limits are monitored and reported at the cgroup level.\nControl ‚Äî You can change the status (frozen, stopped, or restarted) of all processes in a cgroup with a single command.\n</code></pre></div><p>The following command creates a v1 cgroup (you can tell by pathname format) called foo and sets the memory limit for it to 50,000,000 bytes (50 MB).</p><div><pre><code>root # mkdir -p /sys/fs/cgroup/memory/foo\nroot # echo 50000000 &gt; /sys/fs/cgroup/memory/foo/memory.limit_in_bytes\n</code></pre></div><p>Now I can assign a process to the cgroup, thus imposing the cgroup‚Äôs memory limit on it. I‚Äôve written a shell script called test.sh, which prints cgroup testing tool to the screen, and then waits doing nothing. For my purposes, it is a process that continues to run until I stop it.</p><p>I start test.sh in the background and its PID is reported as 2428. The script produces its output and then I assign the process to the cgroup by piping its PID into the cgroup file /sys/fs/cgroup/memory/foo/cgroup.procs.</p><div><pre><code>root # ./test.sh &amp;\n[1] 2428\nroot # cgroup testing tool\nroot # echo 2428 &gt; /sys/fs/cgroup/memory/foo/cgroup.procs\n</code></pre></div><p>To validate that my process is in fact subject to the memory limits that I defined for cgroup foo, I run the following ps command. The -o cgroup flag displays the cgroups to which the specified process (2428) belongs. The output confirms that its memory cgroup is foo.</p><div><pre><code>root # ps -o cgroup 2428\nCGROUP\n12:pids:/user.slice/user-0.slice/\\\nsession-13.scope,10:devices:/user.slice,6:memory:/foo,...\n\n</code></pre></div><p>By default, the operating system terminates a process when it exceeds a resource limit defined by its cgroup.</p><p>and this fair amount of information about namespace and cgroup\nyou can read full doc about it by Scott van Kalken of F5<p>\nat this link , also this post Demystifying Containers 101 and this one focus on Docker ecosystem ‚ÄúA Beginner-Friendly Introduction to Containers, VMs and Docker‚Äù</p>\npart 1 : Chroot<p>\ni will not use Namespaces , ‚Äúat this part‚Äù</p></p><p>this may surprise however i will achieve the isolation , we will use Chroot a simple UNIX tool</p><p>chroot, short for \"change root,\" is a Unix system call that changes the root directory of a process to a specified path, effectively creating a new root filesystem for the process and its children. This can be a powerful tool for creating isolated environments or \"chroot jails.\"\nHow Chroot Works:</p><div><pre><code>Setting a New Root Directory: When you execute the chroot system call or the chroot command in the shell, it changes the root directory for the process and its children. The new root directory becomes the / (root) directory for that process, isolating it from the actual root directory of the host system.\nIsolation: After the chroot operation, the process and its children can only access files and directories within the new root directory. They cannot access files outside this new root, providing a level of isolation and containment.\n</code></pre></div><div><pre><code>System Recovery: chroot is commonly used in system recovery scenarios. If your system becomes unbootable or experiences issues, you can boot from a live CD/USB, chroot into the broken system, and make necessary repairs without affecting the rest of the host system.\nEnvironment Isolation: Developers and system administrators may use chroot to create isolated environments for testing or building software. This is especially common in scenarios where different versions of libraries or dependencies are required.\nSecurity: Although chroot provides some level of isolation, it's not foolproof in terms of security. It was not designed as a security feature and should not be solely relied upon for containing malicious processes. Modern containerization technologies, like Docker, utilize more advanced mechanisms, such as Linux namespaces and cgroups, to provide stronger isolation.\n</code></pre></div><p>Consider the following example:</p><div><pre><code>\nmkdir mychroot\ncp -r /bin /lib /lib64 /usr /mychroot\nchroot /mychroot /bin/bash\n</code></pre></div><div><pre><code>We create a directory called mychroot and copy essential binaries and libraries into it.\nWe use chroot to change the root directory to /mychroot.\nAfter the chroot command, executing /bin/bash will run a Bash shell within the isolated environment.\n</code></pre></div><p>Keep in mind that chroot by itself does not provide complete isolation; it is often used in conjunction with other tools and techniques to create more secure and robust containerized environments.\nPrepare the Ubuntu Root Filesystem</p><p>now final this you will need before you start a filesystem .\nwe will use Docker to download Ubuntu filesystem</p><p>you will only need docker to download it , in your project root</p><div><pre><code>$ docker run -d --rm --name ubuntu_fs ubuntu:20.04 sleep 1000\n$ mkdir -p ./ubuntu_fs\n$ docker cp ubuntu_fs:/ ./ubuntu_fs\n$ docker stop ubuntu_fs\n</code></pre></div><p>now we have ubuntu_fs inside our project , inside your main package</p><div><pre><code>package main\n\nimport (\n \"io/ioutil\"\n \"log\"\n \"os\"\n \"os/exec\"\n \"path/filepath\"\n \"strconv\"\n \"syscall\"\n \"strings\"\n \"fmt\"\n \"github.com/vishvananda/netns\"\n\n)\n\n\n\nfunc main() {\n switch os.Args[1] {\n case \"run\":\n  run(os.Args[2:]...)\n case \"child\":\n  child(os.Args[2:]...)\n default:\n  log.Fatal(\"Unknown command. Use run &lt;command_name&gt;, like `run /bin/bash` or `run echo hello`\")\n }\n}\n\n\n\nfunc run(command ...string) {\n\n log.Println(\"Executing\", command, \"from run\")\n cmd := exec.Command(\"/proc/self/exe\", append([]string{\"child\"}, command[0:]...)...)\n cmd.Stdin = os.Stdin\n cmd.Stdout = os.Stdout\n cmd.Stderr = os.Stderr\n\n // Cloneflags is only available in Linux\n // CLONE_NEWUTS namespace isolates hostname\n // CLONE_NEWPID namespace isolates processes\n // CLONE_NEWNS namespace isolates mounts\n cmd.SysProcAttr = &amp;syscall.SysProcAttr{\n  Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS ,\n  Unshareflags: syscall.CLONE_NEWNS | syscall.CLONE_NEWNET, \n }\n\n // Run child using namespaces. The command provided will be executed inside that.\n  must(cmd.Run())\n}\n\n\n\n\nfunc child(command ...string) {\n\n // Create cgroup\n cg()\n\n\n\n\n\n cmd := exec.Command(command[0], command[1:]...)\n\n cmd.Stdin = os.Stdin\n cmd.Stdout = os.Stdout\n cmd.Stderr = os.Stderr\n\n\n must(syscall.Sethostname([]byte(\"container\")))\n\n\n must(syscall.Chroot(\"./ubuntu_fs\"))\n // Change directory after chroot\n must(os.Chdir(\"/\"))\n // Mount /proc inside container so that `ps` command works\n must(syscall.Mount(\"proc\", \"proc\", \"proc\", 0, \"\"))\n // Mount a temporary filesystem\n if _, err := os.Stat(\"mytemp\"); os.IsNotExist(err) {\n  must(os.Mkdir(\"mytemp\", os.ModePerm))\n }\n must(syscall.Mount(\"something\", \"mytemp\", \"tmpfs\", 0, \"\"))\n\n\n\n\n must(cmd.Run())\n\n // Cleanup mount\n must(syscall.Unmount(\"proc\", 0))\n must(syscall.Unmount(\"mytemp\", 0))\n}\n\n\n\n\nfunc cg() {\n // cgroup location in Ubuntu\n cgroups := \"/sys/fs/cgroup/\"\n\n pids := filepath.Join(cgroups, \"pids\")\n containers_mini := filepath.Join(pids, \"containers_mini\")\n os.Mkdir(containers_mini, 0755)\n // Limit to max 20 pids\n must(ioutil.WriteFile(filepath.Join(containers_mini, \"pids.max\"), []byte(\"20\"), 0700))\n // Cleanup cgroup when it is not being used\n must(ioutil.WriteFile(filepath.Join(containers_mini, \"notify_on_release\"), []byte(\"1\"), 0700))\n\n pid := strconv.Itoa(os.Getpid())\n // Apply this and any child process in this cgroup\n must(ioutil.WriteFile(filepath.Join(containers_mini, \"cgroup.procs\"), []byte(pid), 0700))\n}\n\nfunc must(err error) {\n if err != nil {\n  log.Printf(\"Error: %v\\n\", err)\n   panic(err)\n }\n}\n</code></pre></div><p>this code introduced by Liz Rice</p><p>Understanding the Code</p><p>The main function serves as the entry point of the program. It uses command-line arguments to determine whether to run a new container or act as a child process within an existing container.</p><div><pre><code>func main() {\n    switch os.Args[1] {\n    case \"run\":\n        run(os.Args[2:]...)\n    case \"child\":\n        child(os.Args[2:]...)\n    default:\n        log.Fatal(\"Unknown command. Use run &lt;command_name&gt;, like `run /bin/bash` or `run echo hello`\")\n    }\n}\n\n</code></pre></div><p>The run function sets up the container environment and executes a specified command inside it.</p><p><code>func run(command ...string) {\n   log.Println(\"Executing\", command, \"from run\")<p>\n   cmd := exec.Command(\"/proc/self/exe\", append([]string{\"child\"}, command[0:]...)...)</p>\n   cmd.Stdin = os.Stdin\n   cmd.Stderr = os.Stderr<p>\n    cmd.SysProcAttr = &amp;syscall.SysProcAttr{</p>\n        Cloneflags:    syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS,<p>\n        Unshareflags:  syscall.CLONE_NEWNS | syscall.CLONE_NEWNET,</p>\n    }\n}</code></p><div><pre><code>this command cmd := exec.Command(‚Äú/proc/self/exe‚Äù, append([]string{‚Äúchild‚Äù}, command[0:]‚Ä¶)‚Ä¶)\nmake sure that it‚Äôs append all command to same process\nThe Cloneflags specify the namespaces to be isolated (UTS, PID, and mount namespaces).\nThe Unshareflags further isolate the network namespace.\nThe cmd.Run() method runs the provided command within the created container.\n</code></pre></div><p>The child function is responsible for setting up the container filesystem and executing the specified command inside it.</p><div><pre><code>func child(command ...string) {\n    // ...\n    cg()\n    must(syscall.Sethostname([]byte(\"container\")))\n    must(syscall.Chroot(\"./ubuntu_fs\"))\n    must(os.Chdir(\"/\"))\n    must(syscall.Mount(\"proc\", \"proc\", \"proc\", 0, \"\"))\n    must(syscall.Mount(\"something\", \"mytemp\", \"tmpfs\", 0, \"\"))\n    must(cmd.Run())\n    must(syscall.Unmount(\"proc\", 0))\n    must(syscall.Unmount(\"mytemp\", 0))\n}\n</code></pre></div><div><pre><code>The cg function sets up a control group (cgroup) to limit resource usage for the container.\nSethostname sets the hostname inside the container.\nChroot changes the root directory for the container.\nMount is used to mount essential filesystems like /proc and a temporary filesystem.\nFinally, the command is executed within the container.\n</code></pre></div><p>The cg function creates and configures a cgroup for the container, limiting the number of processes.</p><div><pre><code>func cg() {\n // cgroup location in Ubuntu\n cgroups := \"/sys/fs/cgroup/\"\n\n pids := filepath.Join(cgroups, \"pids\")\n containers_mini := filepath.Join(pids, \"containers_mini\")\n os.Mkdir(containers_mini, 0755)\n // Limit to max 20 pids\n must(ioutil.WriteFile(filepath.Join(containers_mini, \"pids.max\"), []byte(\"20\"), 0700))\n // Cleanup cgroup when it is not being used\n must(ioutil.WriteFile(filepath.Join(containers_mini, \"notify_on_release\"), []byte(\"1\"), 0700))\n\n pid := strconv.Itoa(os.Getpid())\n // Apply this and any child process in this cgroup\n must(ioutil.WriteFile(filepath.Join(containers_mini, \"cgroup.procs\"), []byte(pid), 0700))\n}\n\n</code></pre></div><div><pre><code>Cgroups are used to control and limit resource usage for processes.\nIn this example, the cgroup limits the maximum number of processes to 20.\n</code></pre></div><p>The must function is a simple utility function for handling errors.</p><div><pre><code>func must(err error) {\n    if err != nil {\n        log.Printf(\"Error: %v\\n\", err)\n        panic(err)\n    }\n}\n</code></pre></div><p>If an error occurs, it is logged, and the program is terminated.\nBuilding and Running the Container</p><p>To run the minimal container, follow these steps:</p><div><pre><code>Build the executable: go build -o mycontainer main.go\nCreate a filesystem directory with an Ubuntu root filesystem, e.g., ubuntu_fs.\nRun the container: sudo ./mycontainer run /bin/bash\nremember you need to run it as sudo\nyour entry point is /bin/bash\n</code></pre></div><p>now you are in your own minimal container , and now you have a deep understanding , may be if i have more time in the future i will add isolation layer on network , our you can do it , thank you for your time i hopped it helped anyone .</p><div><pre><code>read this will help you more\n\nnamespace &amp; golang a series of article explains namespace with go examples\n\n‚ÄúCreating Network Stacks and Connecting with the Internet‚Äù by ‚ÄúShrikanta Mazumder‚Äù\n</code></pre></div><p>on next part we will create a network layer that give our container a virtual Ethernet in isolated subset that use host bridge as gateway . see you soon</p>","contentLength":17425,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to manage tool dependencies in Go 1.24+","url":"https://www.alexedwards.net/blog/how-to-manage-tool-dependencies-in-go-1.24-plus","date":1740083763,"author":"/u/alexedwards","guid":7465,"unread":true,"content":"<p>One of my favourite features of Go 1.24 is the new functionality for managing  dependencies.</p><p>By this, I mean tooling that you use to assist with development, testing, build, or deployment ‚Äì such as <a href=\"https://staticcheck.dev/\"></a> for static code analysis, <a href=\"https://pkg.go.dev/golang.org/x/vuln/cmd/govulncheck\"></a> for vulnerability scanning, or <a href=\"https://www.alexedwards.net/blog/github.com/air-verse/air\"></a> for live-reloading applications.</p><p>Historically, managing these dependencies ‚Äî especially in a team setting ‚Äî has been tricky. The previous solutions have been to use a <a href=\"https://marcofranssen.nl/manage-go-tools-via-go-modules\"></a> file or the <a href=\"https://www.alexedwards.net/blog/using-go-run-to-manage-tool-dependencies\"></a> pattern, but while these approaches work, they‚Äôve always felt like workarounds with some downsides.</p><p>With Go 1.24, there‚Äôs finally a better way. </p><p>To demonstrate the new functionality, let's scaffold a simple module and add some application code.</p><figure><code><pre>$ go mod init example.com\n<samp>go: creating new go.mod: module example.com</samp>\n$ touch main.go\n</pre></code></figure><figure><code><pre>package main\n\nimport (\n    \"fmt\"\n\n    \"github.com/kr/text\"\n)\n\nfunc main() {\n    wrapped := text.Wrap(\"This is an informational message that should be wrapped.\", 30)\n    fmt.Println(wrapped)\n}\n</pre></code></figure><p>Now fetch the  package and run the code. The output should look like this:</p><figure><code><pre>$ go get github.com/kr/text\n<samp>go: downloading github.com/kr/text v0.2.0\ngo: added github.com/kr/text v0.2.0</samp>\n$ go run .\n<samp>This is an informational\nmessage that should be\nwrapped.</samp></pre></code></figure><p>Go 1.24 introduces the  flag for , which you can use like this:</p><figure><code><pre>go get -tool import_path@version\n</pre></code></figure><p>This command will download the package specified by the import path (along with any child dependencies), store them in your module cache, and record them in your  file. The  part is optional ‚Äì if you omit it, the latest version will be downloaded.</p><p>Let's use this to add the latest versions of  and  to our module as developer tools, along with  version .</p><figure><code><pre>$ go get -tool golang.org/x/tools/cmd/stringer\n<samp>go: downloading golang.org/x/tools v0.30.0\ngo: downloading golang.org/x/sync v0.11.0\ngo: downloading golang.org/x/mod v0.23.0\ngo: added golang.org/x/mod v0.23.0\ngo: added golang.org/x/sync v0.11.0\ngo: added golang.org/x/tools v0.30.0</samp>\n\n$ go get -tool golang.org/x/vuln/cmd/govulncheck\n<samp>go: downloading golang.org/x/vuln v1.1.4\ngo: downloading golang.org/x/telemetry v0.0.0-20240522233618-39ace7a40ae7\ngo: downloading golang.org/x/sys v0.30.0\ngo: upgraded golang.org/x/telemetry v0.0.0-20240521205824-bda55230c457 =&gt; v0.0.0-20240522233618-39ace7a40ae7\ngo: added golang.org/x/vuln v1.1.4</samp>\n\n$ go get -tool honnef.co/go/tools/cmd/staticcheck@v0.5.1\n<samp>go: downloading honnef.co/go/tools v0.5.1\ngo: downloading golang.org/x/exp/typeparams v0.0.0-20231108232855-2478ac86f678\ngo: downloading github.com/BurntSushi/toml v1.4.1-0.20240526193622-a339e1f7089c\ngo: downloading golang.org/x/exp v0.0.0-20231110203233-9a3e6036ecaa\ngo: added github.com/BurntSushi/toml v1.4.1-0.20240526193622-a339e1f7089c\ngo: added golang.org/x/exp/typeparams v0.0.0-20231108232855-2478ac86f678\ngo: added honnef.co/go/tools v0.5.1</samp></pre></code></figure><p>After running these, your  file will now include a  section listing the tools you've added. The corresponding module paths and versions for all the dependencies will appear in the  section and be marked as indirect:</p><figure><code><pre>module example.com\n\ngo 1.24.0\n\nrequire (\n    github.com/BurntSushi/toml v1.4.1-0.20240526193622-a339e1f7089c // indirect\n    github.com/kr/text v0.2.0 // indirect\n    golang.org/x/exp/typeparams v0.0.0-20231108232855-2478ac86f678 // indirect\n    golang.org/x/mod v0.23.0 // indirect\n    golang.org/x/sync v0.11.0 // indirect\n    golang.org/x/sys v0.30.0 // indirect\n    golang.org/x/telemetry v0.0.0-20240522233618-39ace7a40ae7 // indirect\n    golang.org/x/tools v0.30.0 // indirect\n    golang.org/x/vuln v1.1.4 // indirect\n    honnef.co/go/tools v0.5.1 // indirect\n)\n\ntool (\n    golang.org/x/tools/cmd/stringer\n    golang.org/x/vuln/cmd/govulncheck\n    honnef.co/go/tools/cmd/staticcheck\n)\n</pre></code></figure><p>Once added, you can run tools using the  command.</p><p>To run a specific tool from the command line within your module, you can use  followed by the last non-major-version segment of the import path for the tool (which is, normally, just the name for the tool). For example:</p><figure><code><pre>$ go tool staticcheck -version\n<samp>staticcheck 2024.1.1 (0.5.1)</samp>\n\n$ go tool govulncheck\n<samp>No vulnerabilities found.</samp></pre></code></figure><p>The  command also works nicely if you want to execute tools from your scripts or Makefiles. To illustrate, let's create a Makefile with an  task that runs staticcheck and govulncheck on the codebase.</p><pre><code>.PHONY: audit\naudit:\n    go vet ./...\n    go tool staticcheck ./...\n    go tool govulncheck\n</code></pre><p>If you run , you should see that all the checks complete successfully.</p><figure><code><pre>$ make audit\n<samp>go vet ./...\ngo tool staticcheck ./...\ngo tool govulncheck\nNo vulnerabilities found.</samp></pre></code></figure><p>Let's also take a look at an example where we use the stringer tool in conjunction with  to generate  methods for some  constants.</p><figure><code><pre>package main\n\nimport (\n    \"fmt\"\n\n    \"github.com/kr/text\"\n)\n\n//go:generate go tool stringer -type=Level\n\ntype Level int\n\nconst (\n    Info Level = iota\n    Error\n    Fatal\n)\n\nfunc main() {\n    wrapped := text.Wrap(\"This is an informational message that should be wrapped.\", 30)\n\n    fmt.Printf(\"%s: %s\\n\", Info, wrapped)\n}\n</pre></code></figure><p>The important thing here is the  line. When you run  on this file, it will in turn use  to execute the version of the stringer tool listed in your  file.</p><figure><code><pre>$ go generate .\n$ ls \n<samp>go.mod  go.sum  level_string.go  main.go  Makefile</samp></pre></code></figure><p>You should see that a new  file is created, and running the application should result in some output that looks like this:</p><figure><code><pre>$ go run .\n<samp>Info: This is an informational\nmessage that should be\nwrapped.</samp></pre></code></figure><p>You can check which tools have been added to a module by running , like so:</p><figure><code><pre>$ go list tool\n<samp>honnef.co/go/tools/cmd/staticcheck\ngolang.org/x/tools/cmd/stringer\ngolang.org/x/vuln/cmd/govulncheck</samp></pre></code></figure><p>Because the tools are included in your  file as dependencies, if you want to check that the code for the tools stored in your module cache has not changed you can simply run :</p><figure><code><pre>$ go mod verify\n</pre></code></figure><p>This will check that the code in your module cache exactly matches the corresponding checksums in your  file.</p><p>If you run , the code for tooling dependencies will be included in the  folder and the  manifest alongside your non-tool dependencies.</p><figure><code><pre>$ go mod vendor\n$  tree  -L 3\n<samp>.\n‚îú‚îÄ‚îÄ go.mod\n‚îú‚îÄ‚îÄ go.sum\n‚îú‚îÄ‚îÄ main.go\n‚îú‚îÄ‚îÄ Makefile\n‚îî‚îÄ‚îÄ vendor\n        ‚îú‚îÄ‚îÄ github.com\n        ‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ BurntSushi\n        ‚îÇ&nbsp;&nbsp; ‚îî‚îÄ‚îÄ kr\n        ‚îú‚îÄ‚îÄ golang.org\n        ‚îÇ&nbsp;&nbsp; ‚îî‚îÄ‚îÄ x\n        ‚îú‚îÄ‚îÄ honnef.co\n        ‚îÇ&nbsp;&nbsp; ‚îî‚îÄ‚îÄ go\n        ‚îî‚îÄ‚îÄ modules.txt</samp></pre></code></figure><p>When tools are vendored in this way, running  will execute the corresponding code in the  directory. Note that  does not work on vendored code.</p><p>To upgrade or downgrade a specific tool to a specific version, you can use the same <code>go get -tool import_path@version</code> command that you did for adding the tool originally. For example:</p><figure><code><pre>$ go get -tool honnef.co/go/tools/cmd/staticcheck@v0.5.0\n</pre></code></figure><p>To upgrade to the latest version of a specific tool, omit the  suffix. </p><figure><code><pre>$ go get -tool honnef.co/go/tools/cmd/staticcheck\n</pre></code></figure><p>You can also upgrade  to their latest version by running . Note:  is a sub-command here, not a flag.</p><p>If your tool dependencies are vendored, you will need to re-run  after any upgrades or downgrades.</p><p>At the time of writing, I'm not aware of any easy way to specifically list the tools that have upgrades available ‚Äì if you know of one please let me know!</p><p>To remove the tool completely from your module, use  with the special version tag .</p><figure><code><pre>$ go get -tool honnef.co/go/tools/cmd/staticcheck@none\n</pre></code></figure><p>Again, if you're vendoring, make sure to run  after removing a tool.</p><p>A <a href=\"https://old.reddit.com/r/golang/comments/1iu8nkj/how_to_manage_tool_dependencies_in_go_124/mdzscsa/\">Reddit commenter</a> mentioned the potential for problems if your tools share dependencies with your application code. For example, let's say that your application code depends on  version , and is tested and known to work with that version. Then if you add a tool that relies on a  version of , the version number in your  file will be bumped to the newer version and your application code will use that newer version too.</p><p>In theory, this  be a problem so long as all your dependencies and their child dependencies are stable, follow strict semantic versioning, and don't make backwards-incompatible changes without a major version increment. But, of course, the real world is messy and backwards-incompatible changes  happen, which could unexpectedly break your application code.</p><p>It's worth noting that this issue isn't limited to tool dependencies ‚Äì the same thing can happen if your application code and a non-tool dependency both rely on the same package. However, including tools in  increases the risk.</p><p>To reduce this risk, you can use a separate modfile for tool dependencies instead of including them in your main . You can do this with the  flag, specifying an alternative file such as , like so:</p><figure><code><pre><samp># Initialize a go.tool.mod modfile</samp>\n$ go mod init -modfile=go.tool.mod example.com\n\n<samp># Add a tool to the module</samp>\n$ go get -tool -modfile=go.tool.mod golang.org/x/vuln/cmd/govulncheck\n\n<samp># Run the tool from the command line</samp>\n$ go tool -modfile=go.tool.mod govulncheck\n\n<samp># List all tools added to the module</samp>\n$ go list -modfile=go.tool.mod tool\n\n<samp># Verify the integrity of the tool dependencies</samp>\n$ go mod verify -modfile=go.tool.mod\n\n<samp># Upgrade or downgrade a tool to a specific version</samp>\n$ go get -tool -modfile=go.tool.mod golang.org/x/vuln/cmd/govulncheck@v1.1.2\n\n<samp># Upgrade all tools to their latest version</samp>\n$ go get -modfile=go.tool.mod tool\n\n<samp># Remove a tool from the module</samp>\n$ go get -tool -modfile=go.tool.mod golang.org/x/vuln/cmd/govulncheck@none\n</pre></code></figure>","contentLength":9405,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iu8nkj/how_to_manage_tool_dependencies_in_go_124/"},{"title":"Geoblocking the UK with Debian & Nginx","url":"https://aphyr.com/posts/379-geoblocking-the-uk-with-debian-nginx","date":1740080755,"author":"Aphyr","guid":7410,"unread":true,"content":"<p>A few quick notes for other folks who are <a href=\"https://geoblockthe.uk\">geoblocking the UK</a>. I just set up a basic geoblock with Nginx on Debian. This is all stuff you can piece together, but the Maxmind and Nginx docs are a little vague about the details, so I figure it‚Äôs worth an actual writeup. My Nginx expertise is ~15 years out of date, so this might not be The Best Way to do things. YMMV.</p><p>First, register for a free <a href=\"https://www.maxmind.com/en/geolite2/signup\">MaxMind account</a>; you‚Äôll need this to subscribe to their GeoIP database. Then set up a daemon to maintain a copy of the lookup file locally, and Nginx‚Äôs GeoIP2 module:</p><pre><code>apt install geoipupdate libnginx-mod-http-geoip2\n</code></pre><p>Create a license key on the MaxMind site, and download a copy of the config file you‚Äôll need. Drop that in . It‚Äôll look like:</p><pre><code>AccountID XXXX\nLicenseKey XXXX\nEditionIDs GeoLite2-Country\n</code></pre><p>The package sets up a cron job automatically, but we should grab an initial copy of the file. This takes a couple minutes, and writes out <code>/var/lib/GeoIP/GeoLite2-Country-mmdb</code>:</p><p>The GeoIP2 module should already be loaded via <code>/etc/nginx/modules-enabled/50-mod-http-geoip2.conf</code>. Add a new config snippet like <code>/etc/nginx/conf.d/geoblock.conf</code>. The first part tells Nginx where to find the GeoIP database file, and then extracts the two-letter ISO country code for each request as a variable. The  part sets up an  variable, which is set to  for GB, otherwise .</p><pre><code>geoip2 /var/lib/GeoIP/GeoLite2-Country.mmdb {\n  $geoip2_data_country_iso_code country iso_code;\n}\n\nmap $geoip2_data_country_iso_code $osa_geoblocked {\n  GB      1;\n  default 0;\n}\n</code></pre><p>Write an HTML file somewhere like <code>/var/www/custom_errors/osa.html</code>, explaining the block. Then serve that page for HTTP 451 status codes: in <code>/etc/nginx/sites-enabled/whatever</code>, add:</p><pre><code>server {\n  ...\n  # UK OSA error page\n  error_page 451 /osa.html;\n  location /osa.html {\n    internal;\n    root /var/www/custom_errors/;\n  }\n\n  # When geoblocked, return 451\n  location / {\n    if ($osa_geoblocked = 1) {\n      return 451;\n    }\n  }\n}\n</code></pre><p>Test your config with , and then . You can test how things look from the UK using a VPN service, or something like <a href=\"https://www.locabrowser.com/\">locabrowser</a>.</p><p>This is, to be clear, a bad solution. MaxMind‚Äôs free database is not particularly precise, and in general IP lookup tables are chasing a moving target. I know for a fact that there are people in non-UK countries (like Ireland!) who have been inadvertently blocked by these lookup tables. Making those people use Tor or a VPN , but I don‚Äôt know what else to do in the current regulatory environment.</p>","contentLength":2491,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rate my photo manipulation tool","url":"https://www.reddit.com/r/golang/comments/1iu6pch/rate_my_photo_manipulation_tool/","date":1740079001,"author":"/u/tunerhd","guid":7513,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/tunerhd\"> /u/tunerhd </a>","contentLength":30,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Call Center Wondr by BNI 0821-4448-0002","url":"https://dev.to/vanglevan/call-center-wondr-by-bni-0821-4448-0002-1pjn","date":1740067711,"author":"Vang LE","guid":7293,"unread":true,"content":"<p>Nomor Resmi Call Center Wondr BNI 0821-4448-0002. Untuk informasi lebih lanjut, nasabah dapat menghubungi BNI Call Center di 0821-4448-0002.</p><p>Untuk mendapatkan informasi lebih lanjut mengenai gangguan pada bni mobile atau wondr by bni, nasabah dapat menghubungi <a href=\"https://dev.to/jai2002/cs-wondr-by-bni-0821-4448-0002-2962\">CS Wondr BNI 0821-4448-0002</a>.</p>","contentLength":288,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"C equivalent of select() / poll() in go socket programming","url":"https://www.reddit.com/r/golang/comments/1iu1ugj/c_equivalent_of_select_poll_in_go_socket/","date":1740067219,"author":"/u/ChestPainGuy","guid":8416,"unread":true,"content":"<p>Hi, I'm fairly new to socket programming and go, so forgive my ignorance.</p><p>Recently, I have been reading up Beej's guide to network programming, where he explains the use of  and  to read and write to multiple sockets without blocking.</p><p>I have googled quite a bit, but almost every tutorial or go example on the basics of socket connections just spawn a new goroutine with something like .</p><ol><li>So whats' the equivalent of  in go?</li><li>Is spawning a goroutine for every connection an effective approach?</li></ol><p>Any good links to network programming in go would be appreciated if this question is too dumb. Thanks</p>","contentLength":588,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"ErrGroup: Unlocking Go's Concurrency Power","url":"https://dev.to/leapcell/errgroup-unlocking-gos-concurrency-power-3g2h","date":1740066210,"author":"Leapcell","guid":7266,"unread":true,"content":"<p> is a utility in the official Go library  used for concurrently executing multiple  and handling errors. It implements  based on , providing more powerful functions for concurrent programming.</p><p>Compared with ,  has the following advantages:</p><ol><li>:  is only responsible for waiting for the  to complete and does not handle return values or errors. While  cannot directly handle return values, it can immediately cancel other running  when a  encounters an error and return the first non- error in the  method.</li><li>:  can be used in conjunction with . When a  encounters an error, it can automatically cancel other , effectively controlling resources and avoiding unnecessary work.</li><li><strong>Simplifying Concurrent Programming</strong>: Using  can reduce the boilerplate code for error handling. Developers do not need to manually manage error states and synchronization logic, making concurrent programming simpler and more maintainable.</li><li><strong>Limiting the Number of Concurrency</strong>:  provides an interface to limit the number of concurrent  to avoid overloading, which is a feature that  does not have.</li></ol><h2>\n  \n  \n  Example of Using sync.WaitGroup\n</h2><p>Before introducing , let's first review the usage of .</p><div><pre><code></code></pre></div><div><pre><code>$ go run examples/main.go\nfetch url http://www.google.com/ status 200 OK\nfetch url http://www.golang.org/ status 200 OK\nError: Get \"http://www.somestupidname.com/\": dial tcp: lookup www.somestupidname.com: no such host\n</code></pre></div><p>Typical idiom of :</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Example of Using errgroup.Group\n</h2><p>The usage pattern of  is similar to that of .</p><div><pre><code></code></pre></div><div><pre><code>$ go run examples/main.go\nfetch url http://www.google.com/ status 200 OK\nfetch url http://www.golang.org/ status 200 OK\nError: Get \"http://www.somestupidname.com/\": dial tcp: lookup www.somestupidname.com: no such host\n</code></pre></div><p> provides  to add a cancellation function.</p><div><pre><code></code></pre></div><div><pre><code>$ go run examples/withcontext/main.go\nError:  Get \"http://www.somestupidname.com/\": dial tcp: lookup www.somestupidname.com: no such host\nfetch url http://www.google.com/ status 200 OK\n</code></pre></div><h3>\n  \n  \n  Limiting the Number of Concurrency\n</h3><p> provides  to limit the number of concurrently executing .</p><div><pre><code></code></pre></div><div><pre><code>$  go run examples/main.go\nGoroutine 3 is starting\nGoroutine 1 is starting\nGoroutine 2 is starting\nGoroutine 2 is done\nGoroutine 1 is done\nGoroutine 5 is starting\nGoroutine 3 is done\nGoroutine 6 is starting\nGoroutine 4 is starting\nGoroutine 6 is done\nGoroutine 5 is done\nGoroutine 8 is starting\nGoroutine 4 is done\nGoroutine 7 is starting\nGoroutine 9 is starting\nGoroutine 9 is done\nGoroutine 8 is done\nGoroutine 10 is starting\nGoroutine 7 is done\nGoroutine 10 is done\nAll goroutines complete.\n</code></pre></div><p> provides  to try to start a task, which needs to be used in conjunction with .</p><div><pre><code></code></pre></div><div><pre><code>$ go run examples/main.go\nGoroutine 1 started successfully\nGoroutine 1 is starting\nGoroutine 2 is starting\nGoroutine 2 started successfully\nGoroutine 3 started successfully\nGoroutine 4 could not start (limit reached)\nGoroutine 5 could not start (limit reached)\nGoroutine 6 could not start (limit reached)\nGoroutine 7 could not start (limit reached)\nGoroutine 8 could not start (limit reached)\nGoroutine 9 could not start (limit reached)\nGoroutine 10 could not start (limit reached)\nGoroutine 3 is starting\nGoroutine 2 is done\nGoroutine 3 is done\nGoroutine 1 is done\nAll goroutines complete.\n</code></pre></div><h2>\n  \n  \n  Source Code Interpretation\n</h2><p>The source code of  mainly consists of 3 files:</p><div><pre><code></code></pre></div><ul><li>: An empty structure used to pass signals to control the number of concurrency.</li><li>:\n\n<ul><li>: The function called when the context is cancelled.</li><li>: The internally used .</li><li>: The signal channel that controls the number of concurrent coroutines.</li><li>: Ensures that the error is handled only once.</li><li>: Records the first error.</li></ul></li></ul><ul><li>: Limits the number of concurrency.\n</li></ul><div><pre><code></code></pre></div><ul><li>: Starts a new coroutine to execute the task.\n</li></ul><div><pre><code></code></pre></div><ul><li>: Waits for all tasks to complete and returns the first error.\n</li></ul><div><pre><code></code></pre></div><ul><li>: Tries to start a task.\n</li></ul><div><pre><code></code></pre></div><p> is an official extended library that adds error handling capabilities on the basis of , providing functions such as synchronization, error propagation, and context cancellation. Its  method can add a cancellation function,  can limit the number of concurrency, and  can try to start a task. The source code is ingeniously designed and worthy of reference. </p><p>Finally, I would like to recommend the most suitable platform for deploying golang: </p><h3>\n  \n  \n  1. Multi-Language Support\n</h3><ul><li>Develop with JavaScript, Python, Go, or Rust.\n</li></ul><h3>\n  \n  \n  2. Deploy unlimited projects for free\n</h3><ul><li>pay only for usage ‚Äî no requests, no charges.</li></ul><h3>\n  \n  \n  3. Unbeatable Cost Efficiency\n</h3><ul><li>Pay-as-you-go with no idle charges.\n</li><li>Example: $25 supports 6.94M requests at a 60ms average response time.\n</li></ul><h3>\n  \n  \n  4. Streamlined Developer Experience\n</h3><ul><li>Intuitive UI for effortless setup.\n</li><li>Fully automated CI/CD pipelines and GitOps integration.\n</li><li>Real-time metrics and logging for actionable insights.\n</li></ul><h3>\n  \n  \n  5. Effortless Scalability and High Performance\n</h3><ul><li>Auto-scaling to handle high concurrency with ease.\n</li><li>Zero operational overhead ‚Äî just focus on building.\n</li></ul>","contentLength":4854,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Paginaci√≥n con cursor","url":"https://dev.to/gaston_duarte/paginacion-con-cursor-341d","date":1740066023,"author":"Gaston Duarte","guid":7268,"unread":true,"content":"<p>Al desarrollar aplicaciones que muestran grandes vol√∫menes de datos, es fundamental implementar t√©cnicas de paginaci√≥n para mejorar el rendimiento y la experiencia del usuario. En un e-commerce, por ejemplo, podr√≠a haber miles de productos en la base de datos, pero el frontend solo necesita mostrar 10 a la vez.</p><p>Enviar todos los registros al frontend para que los almacene en memoria no es una soluci√≥n eficiente. En su lugar, el backend debe gestionar la paginaci√≥n de manera efectiva.</p><p>Existen dos enfoques principales para paginar datos:  y .</p><p>Este m√©todo utiliza un  para determinar desde qu√© registro comenzar la consulta.</p><p>Veamos un ejemplo simple:</p><p>Supongamos que tenemos 25 registros en nuestra base de datos, y tenemos una vista que quiere mostrar esos registros de a 10.</p><p>Entonces el frontend nos enviara:</p><div><pre><code>{\n  \"limit\": 10,\n  \"offset\": 0\n}\n</code></pre></div><p>El backend har√° una consulta a la base de datos:</p><p><code>SELECT * FROM nombre_tabla LIMIT 10 OFFSET 0</code></p><p>Es decir, mostrar 10 registros desde el registro 0 (del 0..9). \nPara obtener los siguientes 10 registros:</p><div><pre><code>{\n  \"limit\": 10,\n  \"offset\": 10\n}\n</code></pre></div><p><code>SELECT * FROM nombre_tabla LIMIT 10 OFFSET 10</code></p><p>Eso mostrara desde el registro 10 al 19 y as√≠ sucesivamente.</p><h3>\n  \n  \n  Problemas de </h3><ol><li><p><strong>Baja eficiencia en grandes vol√∫menes de datos:</strong> Consultas con  grande pueden volverse costosas, ya que la base de datos debe recorrer muchos registros antes de devolver los deseados.</p></li><li><p><strong>Inconsistencias en datos din√°micos:</strong> Si se agregan o eliminan registros, la paginaci√≥n puede omitir o duplicar registros.</p></li></ol><p>Aqu√≠ es donde aparece la paginaci√≥n con cursor, la cual hace que nuestras consulta a la base de datos sean mucho mas performantes.</p><p>En vez de enviar el campo , utilizaremos un campo .</p><h4>\n  \n  \n  ¬øY como definimos cual es nuestro cursor?\n</h4><p>Bien, la respuesta es depende. Depende de qu√© datos tenemos guardados en nuestro registro, vayamos al caso mas simple, tener un identificador √∫nico auto-incremental.</p><p>Supongamos que nuestro registro tiene estos datos:</p><div><pre><code>{\n  \"id\": 1,\n  \"nombre\": \"Juan\"\n},\n{\n  \"id\": 2,\n  \"nombre\": \"Patricia\"\n},\n...\n</code></pre></div><p>El frontend solicita el primer registro con  (sin cursor) y el backend responder√° ademas del registro a mostrar cual es el cursor que debe enviar en la siguiente request:</p><div><pre><code>{\n  \"limit\": 1,\n  \"cursor\": 2\n  \"user\":{\n       \"id\": 1,\n       \"nombre\": \"Juan\"\n  }\n}\n</code></pre></div><p>Consulta a la base de datos:</p><p><code>SELECT * FROM nombre_tabla LIMIT 1</code></p><p>En la siguiente request que haga el frontend enviara,  y , entonces desde el backend podremos hacer una consulta a la base de datos de este estilo:</p><p><code>SELECT * FROM nombre_tabla WHERE id &gt;= 2 ORDER BY id LIMIT 1</code></p><p>Lo cual traer√° a partir del registro que contenta id &gt;= 2 y solamente 1.</p><h3>\n  \n  \n  ¬øCual es la ventaja sobre offset?\n</h3><ol><li><p>: No se recorren registros innecesarios. Simplemente lo limitamos en el .</p></li><li><p>: No se ven afectados registros por insert o delete.</p></li></ol><h3>\n  \n  \n  Ahora, ¬øQu√© sucede si no tenemos un id auto-incremental y ordenado?\n</h3><p>Si los registros tienen un  en lugar de un ID incremental, se puede utilizar otro campo como cursor, por ejemplo, :</p><p>Por ejemplo, supongamos registros de este estilo:</p><div><pre><code>{\n  \"uuid\": \"asdn1029nc\",\n  \"nombre\": \"Juan\",\n  \"fecha_nacimiento\": \"2003-02-21\"\n},\n{\n  \"uuid\": \"sap0238gh\",\n  \"nombre\": \"Patricia\",\n  \"fecha_nacimiento\": \"2002-11-04\"\n},\n...\n</code></pre></div><p>Para utilizar  debemos ordenar nuestros registros por alg√∫n campo, en este caso la fecha de nacimiento, entonces ahora si el frontend nos pide un registro en la primer request, desde el backend devolveremos:</p><div><pre><code>{\n  \"limit\": 1,\n  \"cursor\": \"2002-11-04\"\n  \"user\":{\n       \"uuid\": \"sap0238gh\",\n       \"nombre\": \"Patricia\",\n       \"fecha_nacimiento\": \"2002-11-04\"\n  }\n},\n...\n</code></pre></div><p>Nuestra consulta a la base de datos ser√°:</p><p><code>SELECT * FROM nombre_tabla WHERE fecha_nacimiento &gt; '2002-11-04' ORDER BY fecha_nacimiento LIMIT 1</code></p><h4>\n  \n  \n  ¬øY que sucede si hay dos registros con la misma fecha, vamos a perder registros?\n</h4><p>Bueno, ahi es donde podemos concatenar dos campos del registro para utilizarlo como cursor para asegurarnos de no perder registros, por ejemplo: <code>cursor=fecha_nacimiento+uuid</code>. Importante siempre en la consulta hacer un <code>order by cursor, fecha_nacimiento</code>.</p><h2>\n  \n  \n  Seguridad: Encodear el cursor\n</h2><p>Es importante utilizar un  en  de nuestro cursor para evitar un . \nEste puede ser un ejemplo de c√≥digo en Go para encodear el cursor:</p><div><pre><code>func DecodeCursor(encoded string) (string, string, error) {\n    data, err := base64.StdEncoding.DecodeString(encoded)\n    if err != nil {\n        return \"\", \"\", err\n    }\n    parts := strings.Split(string(data), \"|\")\n    if len(parts) != 2 {\n        return \"\", \"\", fmt.Errorf(\"cursor inv√°lido\")\n    }\n    return parts[0], parts[1], nil\n}\n\nfunc EncodeCursor(creationDate string, reportID string) string {\n    cursorData := fmt.Sprintf(\"%s|%s\", creationDate, reportID)\n    return base64.StdEncoding.EncodeToString([]byte(cursorData))\n}\n</code></pre></div><p>Si bien  es sencilla y funciona bien con pocos registros,  es mucho m√°s eficiente para grandes vol√∫menes de datos y evita inconsistencias. Dependiendo del caso, se puede utilizar un ID incremental o una combinaci√≥n de campos como cursor para garantizar un correcto orden y rendimiento.</p>","contentLength":5074,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Slice Internals in Go: How the Runtime Expands Slices Efficiently","url":"https://themsaid.com/slice-internals-in-go","date":1740064893,"author":"/u/themsaid","guid":7435,"unread":true,"content":"<p>The deeper you delve into Go‚Äôs internals, the more evident it becomes that its creators carefully engineered the language to strike a precise balance between performance and flexibility. This delicate equilibrium influences many of Go‚Äôs core features, including its approach to memory management and data structures. One standout example of this thoughtful design is the implementation of slice growth. Through this approach, Go ensures that slices expand seamlessly, optimizing both performance and memory usage without compromising ease of use.</p><p>In Go, a slice is a lightweight data structure that serves as a window into a contiguous block of memory where elements of a specific type are stored. At its core, a slice doesn‚Äôt directly contain the data itself but instead holds a pointer to an underlying array (know as the backing array.)</p><p>When the Go runtime creates a slice, as in this example, it constructs a small struct under the hood, defined in the runtime as :</p><div><pre> {\n\t unsafe.\n}</pre></div><p>The  type has the following fields:</p><ul><li> holds a pointer to the underlying array.</li><li> stores the number of elements in the slice.</li><li> stores the capacity of the array.</li></ul><p>The  type used for the  field is a generic pointer type that bypasses Go's type safety rules. Since the size of an array in Go is part of the type, the runtime uses  so it can replace the array with a larger one when needed.</p><p>The code in the example above creates a slice that has zero elements with a backing array that can hold 10 elements of type . We can later fill that array with elements by using the  function:</p><p>Here, we append a byte to the empty array represented by the unsigned 8-bit integer .</p><p>When appending elements to a slice, the Go runtime first checks whether the backing array has enough capacity to accommodate the new elements. If it does, the elements are simply added to the existing array. However, if the current array lacks sufficient space, the runtime allocates a larger backing array, copies the existing elements into it, and then appends the new elements.</p><div><pre>([], , )\n\n(, ) (, ) </pre></div><p>The capacity of the newly allocated array is determined by several factors, including the current array‚Äôs capacity, the type of elements it holds, and the number of new elements being appended. These factors influence how much the array grows, ensuring efficient memory usage while minimizing the need for frequent reallocations.</p><p>The runtime begins by attempting to double the existing capacity as the first step in determining the new array size:</p><div><pre></pre></div><p>If the total number of existing and newly appended elements exceeds the doubled capacity, the runtime sets the new capacity to match the required number of elements:</p><div><pre> {\n    \n}</pre></div><p>This ensures that the new capacity is larger than or equals to the number of elements after the appending operation.</p><div><pre>([], , )\n\n(, , , )\n\n.(()) </pre></div><p>In this example, the integer slice initially had a capacity of 1. After adding three elements, the runtime allocated a new backing array with a capacity of 3. This happened because doubling the original capacity (1 * 2) was insufficient to accommodate the new elements, prompting the runtime to adjust the capacity accordingly.</p><p>If doubling the capacity is sufficient, the runtime further evaluates whether allocating such a large array is efficient or merely a waste of memory.</p><p>For small slices, capacity less than 256, the runtime employs a simple doubling strategy (e.g., 2 to 4, 4 to 8, 8 to 16.) This makes sense for small workloads: doubling ensures plenty of headroom for future appends. However, as the slice‚Äôs capacity climbs into more than 256, or beyond, doubling becomes less practical. Doubling a capacity of, say, 10,000 to 20,000 allocates an extra 10,000 elements‚Äô worth of memory (potentially tens or hundreds of kilobytes, depending on the element size) which might sit unused for a long time.</p><p>To address this, the runtime adjusts its growth strategy for larger slices by reducing the growth factor gradually until it reaches 1.25. This slower growth means that if a slice already has a capacity of, say, 512, adding a few elements doesn‚Äôt balloon it to 1024; it might rise to 832 instead (a 62.5% increase). The key insight is that a larger slice can absorb more appends before hitting its capacity limit. For instance, a slice with a capacity of 512 has room for 512 more elements if empty, compared to just 8 for a capacity of 8. This naturally delays the need for reallocation.</p><p>This conservative approach aims to curb excessive memory usage. By growing incrementally rather than exponentially, the runtime avoids reserving vast swaths of memory that might remain idle, which is critical in applications handling large datasets or with limited resources (e.g., embedded systems). However, there‚Äôs a flip side: smaller growth steps mean the slice fills up sooner, triggering reallocation more often. Each reallocation involves CPU work (allocating memory, copying the existing elements, and updating the slice‚Äôs pointer) which can add up if appends are frequent.</p><p>The runtime‚Äôs strategy thus balances these two forces: memory footprint versus CPU overhead. It leans toward saving memory at the cost of potentially more frequent (but smaller) reallocations, betting that the trade-off pays off in most real-world scenarios where slices don‚Äôt grow indefinitely.</p><p>When determining how a slice should grow, the Go runtime takes into account the type of elements stored in the array, as this directly impacts memory allocation. On 64-bit systems, memory is generally allocated in chunks of 8 bytes. Any allocation that does not align with this rule is rounded up to the nearest multiple of 8 to ensure efficient memory usage and alignment.</p><p>Let's say we create a slice of bytes with capacity zero and then append an element to it:</p><div><pre>([], , )\n\n(, )\n\n.(()) </pre></div><p>After the growth, the capacity of the slice becomes 8 (8 bytes). If the element type was a 64-bit integer instead, the growth will increase the capacity to 1 (1 * 64 bits = 8 bytes):</p><div><pre>([], , )\n\n(, )\n\n.(()) </pre></div><p>If the element type was a 32-bit integer, the growth will increase the capacity to 2 (2 * 32 bits = 8 bytes):</p><div><pre>([], , )\n\n(, )\n\n.(()) </pre></div><p>The reason is that modern CPUs, particularly on 64-bit systems, operate most efficiently when data is aligned to their word size (the amount of data they can process in one cycle.) On a 64-bit system, the word size is 64 bits, or 8 bytes. If the runtime allocates, say, 5 bytes, the CPU  and masks off the unused portion. That means, allocating in 8-byte multiples ensures the entire chunk is usable without waste or extra work.</p><p>In addition, CPU caches fetch memory in 64-byte lines (8 words of 8 bytes each.) Multiples of 8 bytes fit neatly into these lines, reducing cache misses and improving locality when accessing sequential data, like a slice‚Äôs backing array.</p><p>In addition to the 8-byte chunk allocation rule, the Go runtime maintains a table of predefined constants to guide its memory allocation decisions. This table categorizes memory allocations into specific size classes, helping the runtime minimize fragmentation and efficiently reuse freed memory blocks.</p><p>The table looks like this:</p><div><pre>+---------+-------+\n| Class   | Value |\n+---------+-------+\n| Class  |      |\n| Class  |     |\n| Class  |     |\n| Class  |     |\n| Class  |     |\n| Class  |     |\n| Class  |     |\n| Class  |     |\n| Class  |    |\n| .     | .   |\n+---------+-------+</pre></div><p>This size class allocation table functions as an efficient lookup mechanism for managing memory allocation and deallocation. When a memory block belonging to a specific size class is freed, the runtime stores it in the table rather than immediately returning it to the operating system. Later, if a request is made for a memory block of the same size class, the system can quickly retrieve and reuse the previously freed block instead of performing an extensive search through physical memory to find a suitable allocation.</p><div><pre>+---------------------------------+\n|  Freed memory  size class X  |\n+---------------------------------+\n        ‚îÇ\n        ‚ñº\n+-------------------+  \n| Memory Block     |  &lt;-- Freed  (Stored in Table)\n+-------------------+  \n| Memory Block     |  &lt;-- Freed  (Stored in Table)\n+-------------------+  \n| Memory Block     |  &lt;-- Freed  (Stored in Table)\n+-------------------+  \n        ‚îÇ\n        ‚ñº\n+-------------------------------------+\n| Incoming Memory Allocation Request  |\n+-------------------------------------+\n        ‚îÇ\n          (Lookup in Table)\n+-------------------------------+\n| Matching Freed Block Found    |\n+-------------------------------+\n        ‚îÇ\n          (Reused Instead of )\n+----------------------------+\n|  Allocated to Application  |\n+----------------------------+</pre></div><p>With that in mind, the runtime not only rounds up to the nearest 8-byte boundary but also rounds up to the nearest size class in the allocation table.</p><p>Consider this slice operation:</p><div><pre>([], , )\n\n(, , , , , )</pre></div><p>Here, the slice starts with zero capacity and we add 5 elements of type . Without considering the size class allocation table, the runtime would allocate 40 bytes for the new backing array:</p><div><pre> *  bits =  bits /  =  bytes</pre></div><p>Instead, the runtime consults the class allocation table and rounds up to the nearest match (48 in this case). As a result, it allocates a backing array with a capacity of 6 (48 bytes / 64 bits), even though the new array would only need to hold 5 elements (that require only 40 bytes).</p><p>This approach significantly improves performance by reducing external fragmentation (where free memory is scattered in small, non-contiguous blocks, making larger allocations difficult.) It also minimizes allocation overhead and speeds up memory access by eliminating the need to repeatedly request new memory from the operating system.</p><p>In summary, the Go runtime takes several key factors into account when growing an array:</p><ol><li>: It starts with a doubling factor (2x) and then gradually winds down to 1.25x.</li><li>: The array is rounded up to the nearest 8-byte boundary.</li><li><strong>The Size Class Allocation Table</strong>: The runtime rounds up to the nearest available class in the table.</li></ol><p>I really admire the thoughtful work the Go team has put into making the language both efficient and flexible. It's clear that a lot of careful consideration went into optimizing performance while maintaining flexibility for developers.</p>","contentLength":10276,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iu0xjk/slice_internals_in_go_how_the_runtime_expands/"},{"title":"Building Mobile Apps Without a Backend: The Power of Database Gateway API","url":"https://dev.to/muhammetberdi_jepbarov/building-mobile-apps-without-a-backend-the-power-of-database-gateway-api-19m0","date":1740064863,"author":"Muhammetberdi Jepbarov","guid":7267,"unread":true,"content":"<h2>\n  \n  \n  The Pain of Backend Development\n</h2><p>If you've ever built a mobile or web app that interacts with a database, you know the struggle‚Äîdesigning API endpoints, handling authentication, writing business logic, and ensuring scalability. Sometimes, all you need is <strong>a simple way to query the database</strong> and retrieve structured JSON responses without going through the entire process of backend development.</p><p>That‚Äôs exactly why many years ago I built the ‚Äîa solution that allows developers to interact directly with <strong>PostgreSQL and MSSQL databases via a secure API</strong>, without writing a full-fledged backend.</p><h2>\n  \n  \n  The Idea Behind Database Gateway API\n</h2><p>The goal was simple: <strong>Why should you have to build an entire backend when all you need is an API for your database?</strong></p><p>I needed a lightweight yet powerful solution that could:</p><ul><li><strong>Eliminate the need for a dedicated backend</strong> in simple applications.</li><li><strong>Enable mobile and web apps to access database data seamlessly.</strong></li><li><strong>Provide an easy way to deploy APIs</strong> for database interactions with minimal setup.</li><li><strong>Integrate with any existing system</strong>, whether it‚Äôs an enterprise  or a <strong>retail point-of-sale (POS) system</strong>.</li></ul><p>This led to the creation of the ‚Äîa framework-agnostic API layer that acts as a bridge between your database and applications.</p><p>The  is a standalone service that connects to your  or  database and <strong>exposes SQL queries as API endpoints</strong>. It takes care of request parsing, security, and response formatting, allowing you to focus on building your application instead of writing backend logic.</p><p>‚úÖ <strong>Direct SQL Query Execution:</strong> Supports SELECT, INSERT, UPDATE, and DELETE operations via API requests.<strong>Automatic JSON Responses:</strong> Converts database query results into well-structured JSON.<strong>Easy Integration with Mobile &amp; Web Apps:</strong> No need for a complex backend‚Äîjust plug it into your frontend. Set up role-based access, API keys, and rate limiting.<strong>Supports Complex Queries &amp; Joins:</strong> Fetch relational data easily, just like using SQL directly.<strong>Minimal Deployment Overhead:</strong> Run it as a standalone service or containerized in Docker.  </p><h2>\n  \n  \n  Real-World Impact: 29 Deployments &amp; 150+ Devices\n</h2><p>This API has been successfully deployed across , powering over , primarily in . It integrates seamlessly with <strong>mobile apps and existing accounting systems</strong>, allowing businesses to:</p><ul><li><strong>Sync sales data in real-time</strong>, eliminating manual record-keeping.</li><li><strong>Improve customer experience</strong> by linking mobile apps to inventory and POS systems.</li><li><strong>Enable effortless data exchange between different applications</strong> without writing additional backend logic.</li></ul><p>If you‚Äôre a developer building a <strong>mobile app, web dashboard, or prototype</strong>, the  can save you <strong>weeks of development time</strong> by handling database queries and responses automatically.</p><p>Instead of spinning up a full backend, setting up ORM models, and writing CRUD endpoints, <strong>you simply install the gateway, configure it with your database, and start making API requests.</strong></p><p>‚úÖ Instant API ‚Äì Set up in minutes and start making SQL queries right away.\n‚úÖ Effortless Integration ‚Äì Works with mobile, web, and desktop apps.<p>\n‚úÖ JSON-Formatted Responses ‚Äì Your queries return well-structured JSON, ready to use.</p>\n‚úÖ Perfect for Prototyping ‚Äì Quickly test database interactions without a full backend.<p>\n‚úÖ Optimized for Performance ‚Äì Execute fast queries with minimal setup.</p></p><p>üöÄ How It Works\nüîç Querying Your Database</p><p>Need to fetch data? Just send a POST request with your SQL query:</p><p>POST 127.0.0.1:8000/api/v1/make-db-request\n{<p>\n  \"query_string\": \"SELECT * FROM tbl_mg_materials\",</p>\n  \"base64_columns\": [\"group_code\", \"image_pict\", \"firm_id_guid\"]</p><p>Pro tip: Use base64_columns to encode image BLOBs or sensitive data!\nüìä The Response</p><p>The API returns a structured JSON response:</p><p>{\n  \"data\": [...], \n  \"total\": 2, <p>\n  \"message\": \"db query result\"</p>\n}</p><p>‚ö†Ô∏è Important Considerations</p><p>üî¥ Security First! ‚Äì This API executes raw SQL, so make sure to restrict access and validate inputs.\nüî¥ Database Changes? ‚Äì Schema updates might require adjustments to your API queries.<p>\nüî¥ Use with Caution ‚Äì Best for internal tools, rapid prototyping, and trusted environments.</p></p><p>Want to try it out? The  is open-source and available for anyone to use and contribute to. You can integrate it into your next project and <strong>cut down on backend development time significantly</strong>.</p><p>Check out the repository: <p>\nLet me know if you have questions or ideas for improvements‚Äîhappy coding! üöÄ</p></p>","contentLength":4384,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"–ö–∞–∫ —è —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª –±–∏–±–ª–∏–æ—Ç–µ–∫—É Viewscount: –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –≤ Golang","url":"https://dev.to/muhammetberdi_jepbarov/kak-ia-razrabotal-bibliotieku-viewscount-rieshieniie-probliemy-orghanichieskogho-podschieta-prosmotrov-v-golang-1jn0","date":1740061078,"author":"Muhammetberdi Jepbarov","guid":7242,"unread":true,"content":"<p>–ö–∞–∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏, –º—ã —á–∞—Å—Ç–æ —Å—Ç–∞–ª–∫–∏–≤–∞–µ–º—Å—è —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å—é –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö. –ë—É–¥—å —Ç–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –¥–ª—è —Å—Ç–∞—Ç–µ–π, –≤–∏–¥–µ–æ –∏–ª–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤, –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –ø–æ–ª–∞–≥–∞—é—Ç—Å—è –Ω–∞ –ø—Ä–æ—Å—Ç—É—é –∫–æ–ª–æ–Ω–∫—É  –≤ —Å–≤–æ–∏—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–±–ª–µ–º–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç, –∫–æ–≥–¥–∞ –≤—ã –Ω–µ —Ö–æ—Ç–∏—Ç–µ –ø–∏—Å–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ–µ API –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã, –∫–æ—Ç–æ—Ä–∞—è –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ –ø–æ–¥—Å—á–µ—Ç–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, –∏ –ø—Ä–∏ —ç—Ç–æ–º –≤–∞–∂–Ω–æ –æ–±–µ—Å–ø–µ—á–∏—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –æ—Ç —Ç–∞–∫–∏—Ö –∞—Ç–∞–∫, –∫–∞–∫ DoS (Denial of Service). –≠—Ç–æ —Ç–∞ –ø—Ä–æ–±–ª–µ–º–∞, —Å –∫–æ—Ç–æ—Ä–æ–π —è —Å—Ç–æ–ª–∫–Ω—É–ª—Å—è, –∏ –ø—Ä–∏—á–∏–Ω–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–π —è —Å–æ–∑–¥–∞–ª –±–∏–±–ª–∏–æ—Ç–µ–∫—É .</p><p>–í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –æ—Ç—Å–ª–µ–∂–∏–≤–∞—é—Ç—Å—è –≤ —Ç–æ–π –∏–ª–∏ –∏–Ω–æ–π —Ñ–æ—Ä–º–µ ‚Äî –±—É–¥—å —Ç–æ –¥–ª—è –±–ª–æ–≥–∞, —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–¥—É–∫—Ç–∞ –∏–ª–∏ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –û–¥–Ω–∞–∫–æ —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –±—ã–ª–æ –±—ã –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—ã–º –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–º, –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–∂–Ω–æ–π –∑–∞–¥–∞—á–µ–π. –í—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ø—É—Ç—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö API –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ —ç—Ç–∏—Ö —Ç–∞–±–ª–∏—Ü, –Ω–æ —ç—Ç–æ –æ—Ç–Ω–∏–º–∞–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –Ω–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è. –ê —á—Ç–æ –µ—Å–ª–∏ –º–æ–∂–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä—ã, –Ω–µ –ø–∏—à–∞ API –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã? –ß—Ç–æ –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –≤ –ª—é–±–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ? –ò–º–µ–Ω–Ω–æ –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç —è –Ω–∞—á–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º .</p><h3>\n  \n  \n  –ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –µ–¥–∏–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è\n</h3><p>–ö–æ–≥–¥–∞ –≤—ã —Å—Ç—Ä–æ–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, –æ–¥–Ω–∏–º –∏–∑ –≤–∞–∂–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —è–≤–ª—è–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö. –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª—É—á–∞—è—Ö –∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫–∏ –º–æ–≥—É—Ç –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —Å—á–µ—Ç—á–∏–∫ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, –¥–µ–ª–∞—è –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã ‚Äî –∑–¥–µ—Å—å –≤–∞–∂–Ω–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å —Ç–∞–∫–∏–µ –∞—Ç–∞–∫–∏, –∫–∞–∫ DoS (Denial of Service). –ë–µ–∑ –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è –≤–∞—à–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —É—è–∑–≤–∏–º—ã–º –¥–ª—è –ø–æ–¥–æ–±–Ω—ã—Ö –∞—Ç–∞–∫, —á—Ç–æ –ø–æ–¥—Ä—ã–≤–∞–µ—Ç –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö.</p><p>–¢–∞–∫ –ø–æ—è–≤–∏–ª–∞—Å—å –∏–¥–µ—è —Å–æ–∑–¥–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ . –Ø —Ö–æ—Ç–µ–ª —Å–æ–∑–¥–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–∑–≤–æ–ª–∏–ª–æ –±—ã –ª–µ–≥–∫–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –¥–ª—è –ª—é–±—ã—Ö —Ç–∞–±–ª–∏—Ü, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞, –∏ –ø—Ä–∏ —ç—Ç–æ–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ—Å—Ç–æ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è —ç—Ç–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è –≤ –ª—é–±–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –∑–∞—â–∏—â–∞—è –æ—Ç –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã—Ö –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–æ–≤. –≠—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å –ª—é–±—ã–º Golang —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º, —Ç–∞–∫–∏–º –∫–∞–∫ ,  –∏–ª–∏ –¥–∞–∂–µ –±–∞–∑–æ–≤—ã–º , –∏ –±—ã—Ç—å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –æ—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—è PostgreSQL.</p><p>–ö–æ–≥–¥–∞ –≤—ã –¥–æ–±–∞–≤–ª—è–µ—Ç–µ  –≤ —Å–≤–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –≤—ã –º–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä—ã —Å—Ä–∞–∑—É ‚Äî –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–∏—Å–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ API –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã. –î–æ–ø—É—Å—Ç–∏–º, —É –≤–∞—Å –µ—Å—Ç—å —Ç–∞–±–ª–∏—Ü—ã, —Ç–∞–∫–∏–µ –∫–∞–∫  –∏–ª–∏ , –∫–∞–∂–¥–∞—è –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –∏–º–µ–µ—Ç –∫–æ–ª–æ–Ω–∫—É . –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã —Å–æ–∑–¥–∞–≤–∞—Ç—å API —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å—á–µ—Ç—á–∏–∫–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –∫–∞–∂–¥—ã–π —Ä–∞–∑, –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É, –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å  –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç—Ç–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞.</p><p>–í–æ—Ç –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ:</p><p>–í –≤–∞—à–µ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤—å—Ç–µ –∫–æ–ª–æ–Ω–∫—É  –≤ –≤–∞—à–∏ —Ç–∞–±–ª–∏—Ü—ã:</p><div><pre><code></code></pre></div><p>–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∏ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∞–±–ª–∏—Ü. –ù–µ –Ω—É–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏–ª–∏ API ‚Äî –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤—å—Ç–µ —ç—Ç—É –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤.</p><h3>\n  \n  \n  –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Viewscount –≤ –≤–∞—à–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ\n</h3><p>–°–∞–º–∞—è –ª—É—á—à–∞—è —á–∞—Å—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫–∏  –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–∞ —è–≤–ª—è–µ—Ç—Å—è <strong>–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –æ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤</strong>. –ù–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ª–∏ –≤—ã ,  –∏–ª–∏ –¥–∞–∂–µ , –≤—ã –º–æ–∂–µ—Ç–µ –ª–µ–≥–∫–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –µ–µ –≤ –≤–∞—à–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ. –í–æ—Ç –∫–∞–∫ –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –µ–µ –∫–∞–∫ middleware –≤ :</p><p>–°–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å view tracker –≤ –≤–∞—à–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏:</p><div><pre><code></code></pre></div><p>–ö–∞–∫ —Ç–æ–ª—å–∫–æ middleware –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ, –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –µ–≥–æ –∫ –≤–∞—à–∏–º –º–∞—Ä—à—Ä—É—Ç–∞–º. –í–æ—Ç –∫–∞–∫ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è:</p><div><pre><code></code></pre></div><p>–≠—Ç–∞ –ø—Ä–æ—Å—Ç–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫—É  –≤ –≤–∞—à–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ. Middleware –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ –∏ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫–æ–ª–æ–Ω–∫–µ  –ø–æ –º–µ—Ä–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –ø—Ä–∏ —ç—Ç–æ–º –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –∑–∞—â–∏—Ç—É –æ—Ç –∞—Ç–∞–∫.</p><ol><li>: –í—Å–µ–≥–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞ ‚Äî –∏ –≤—ã —É–∂–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –Ω–∞ –ª—é–±–æ–π –∏–∑ –≤–∞—à–∏—Ö —Ç–∞–±–ª–∏—Ü.</li><li><strong>–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤</strong>: –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ª—é–±—ã–º Golang —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Å—Ç–µ–∫–∞.</li><li>: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞—è –±—ã—Å—Ç—Ä—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —Å—á–µ—Ç—á–∏–∫ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤,  –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –æ—Å—Ç–∞—é—Ç—Å—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏ –∏ —Ç–æ—á–Ω—ã–º–∏.</li><li><strong>–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å</strong>: –ù–µ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–µ API –∏–ª–∏ —Å–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.</li></ol><p> —Ä–µ—à–∞–µ—Ç –æ–±—â—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏: –∫–∞–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –ø—Ä–∏ —ç—Ç–æ–º –Ω–µ –ø–∏—Å–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ API –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã. –õ–µ–≥–∫–æ—Å—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏, –∑–∞—â–∏—Ç–∞ –æ—Ç –∞—Ç–∞–∫ –∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤ –¥–µ–ª–∞—é—Ç –µ–µ –º–æ—â–Ω—ã–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤, —Å–æ–∑–¥–∞—é—â–∏—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ Golang-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.</p><p>–ù–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å –≤–Ω–µ—Å—Ç–∏ –≤–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç –∏ —Å–æ–æ–±—â–∞—Ç—å –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö —á–µ—Ä–µ–∑ <a href=\"https://github.com/mikebionic/viewscount\" rel=\"noopener noreferrer\">GitHub Viewscount</a>. –Ø –±—É–¥—É —Ä–∞–¥ —É–≤–∏–¥–µ—Ç—å, –∫–∞–∫ —ç—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø–æ–º–æ–∂–µ—Ç –¥—Ä—É–≥–∏–º –≤ –∏—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ!</p>","contentLength":8108,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How I Developed the Viewscount Library: Solving the Problem of Organic View Counting in Golang","url":"https://dev.to/muhammetberdi_jepbarov/how-i-developed-the-viewscount-library-solving-the-problem-of-organic-view-counting-in-golang-1684","date":1740061016,"author":"Muhammetberdi Jepbarov","guid":7241,"unread":true,"content":"<p>As developers, we often encounter the need to track views on content across various platforms. Whether it's tracking views for articles, videos, or products, most applications rely on a simple  column in their database tables. The challenge arises when you don‚Äôt want to go through the hassle of writing a separate API for each table that needs view tracking, while also ensuring that your system is secure from abuse like DoS (Denial of Service) attacks. This is the problem I encountered and the reason I created the  library.</p><p>In most applications, views are tracked in some form‚Äîwhether it‚Äôs for a blog post, a product listing, or even user profile pages. However, implementing a solution that is both scalable and secure can become cumbersome. You could go the route of writing custom APIs for each of these tables, but that‚Äôs time-consuming and doesn‚Äôt scale well. What if there was a way to track these views without rewriting APIs for every new table? What if there was a more efficient way to integrate this functionality into any app? That‚Äôs when I started working on .</p><h3>\n  \n  \n  The Need for a Unified Solution\n</h3><p>When building any system with views tracking, one of the critical concerns is ensuring that the view count remains authentic. In some cases, malicious users may attempt to artificially inflate the view count through repeated requests‚Äîthis is where preventing DOS (Denial of Service) type increments comes into play. Without a solid solution, your application becomes vulnerable to these types of attacks, undermining the integrity of your view count.</p><p>Thus, the idea for  was born. I wanted a way to seamlessly count organic views across any tables, regardless of the framework, while providing an easy-to-integrate middleware solution that prevents abusive increments. This library is designed to integrate with any Golang web framework, like , , or even basic , and is database-agnostic, supporting PostgreSQL seamlessly.</p><p>When you add  to your application, you can begin tracking views instantly‚Äîwithout having to write separate APIs for each table. Let‚Äôs say you have tables like  or , each with a  column. Instead of building an API specifically to increment the  each time a user views a page, you can use  to track this automatically.</p><p>Here‚Äôs how it works in practice:</p><p>In your database, you simply add the  column to your tables like so:</p><div><pre><code></code></pre></div><p>The same goes for your other tables. No need for complicated queries or APIs‚Äîjust a simple column to track views. </p><h3>\n  \n  \n  Integrating Viewscount into Your Application\n</h3><p>The best part of  is that it‚Äôs designed to be . Whether you're using , , or even , you can easily integrate it into your application. Here‚Äôs how you can add it as middleware in :</p><p>First, you‚Äôll need to initialize the view tracker in your app:</p><div><pre><code></code></pre></div><p>Once you‚Äôve set up the middleware, you can add it to your routes. Here‚Äôs how you do it:</p><div><pre><code></code></pre></div><p>This simple setup integrates the  library into your existing app. The middleware will automatically track views on the specified table and increment the  column as needed, while also providing protection against abuse.</p><h3>\n  \n  \n  The Benefits of Viewscount\n</h3><ol><li>: With just a few lines of code, you can integrate view counting into any of your existing tables.</li><li>: The library is designed to work with any Golang web framework, making it easy to use in your project regardless of the stack.</li><li><strong>Prevention of DOS Attacks</strong>: By limiting rapid requests that could artificially inflate view counts,  ensures that the data remains reliable and accurate.</li><li>: No need for custom APIs or complex queries‚Äîjust use the library and track views automatically in real time.</li></ol><p> solves a common problem in application development: how to track views across tables securely and efficiently without having to build a separate API for each table. Its easy integration, ability to prevent DOS-style attacks, and framework-agnostic design make it a powerful tool for developers building modern Golang applications.</p><p>Feel free to contribute to the project and raise issues or suggestions via <a href=\"https://github.com/mikebionic/viewscount\" rel=\"noopener noreferrer\">Viewscount GitHub</a>. I‚Äôd love to see how this library can help others in their development journey!</p>","contentLength":4129,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Found a profiling tool on GitHub: here‚Äôs what I learned testing it","url":"https://www.reddit.com/r/golang/comments/1itvpcl/found_a_profiling_tool_on_github_heres_what_i/","date":1740048221,"author":"/u/dergtersder","guid":7140,"unread":true,"content":"<p>I recently came across Perforator, an open-source profiler, while browsing GitHub. I decided to test it out on one of our Go services, which has been a bit sluggish lately.</p><p>- The real-time flame graphs are incredibly detailed and made it easy to spot inefficient function calls.</p><p>- Setup was simple. It worked out of the box with minimal configuration.</p><p>- One downside... it doesn‚Äôt yet have full Java support, which we also use heavily.</p><p>Overall, I‚Äôd say it‚Äôs great for projects in Go, Python, or C++. Curious if anyone else has tested it. What‚Äôs been your experience?</p>","contentLength":570,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"zns ‚Äî A CLI tool for querying DNS records with readable, colored output.","url":"https://github.com/znscli/zns","date":1740048103,"author":"/u/bschaatsbergen_","guid":7285,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1itvodu/zns_a_cli_tool_for_querying_dns_records_with/"},{"title":"Scaling gRPC With Kubernetes Using Go","url":"https://nyadgar.com/posts/scaling-grpc-with-kubernetes-using-go/","date":1740036838,"author":"/u/No-Bug-242","guid":7096,"unread":true,"content":"<a href=\"mailto:noam.g4@gmail.com\">By Noam Yadgar</a><p><a href=\"https://grpc.io/\" target=\"_blank\" rel=\"noopener\"></a>\n is a strong player in microservices-based systems.\nLeveraging <a href=\"https://protobuf.dev/\" target=\"_blank\" rel=\"noopener\">Protocol Buffers</a>\n for well-defined API contracts,\nfast serialization (about  faster than ), smaller payloads, and the use\nof streams (thanks to ). It‚Äôs easy to see why this technology for\nreal-time microservice communication is a good choice.</p><p>Unlike a typical REST API that‚Äôs built on top of ,  is built on top of\n. The most noticeable feature of  is the ability to perform .\nThis feature allows servers to asynchronously  data to the client before the client\nasks for it.  leverages  to support , a key feature that separates \nfrom any other -based API. Because of that, \nrequires a long-lasting  connection between the client and the server.</p><p>One thing that makes s exceptionally good at scaling is the notion of being .\nEvery single request is essentially a new  session that can be routed to any available replica\nof the server. This works perfectly with Kubernetes ‚Äôs load-balancing.</p><p>Things are a bit different when it comes to  because each client is keeping the \nconnection for its entire lifespan (if not configured otherwise), the load-balancer will try to\nsymmetrically spread the load across the clients and servers.</p><pre>flowchart LR\n    c1(client-1):::pod ==&gt; s[service/server]:::srv\n    c2(client-2):::pod ==&gt; s\n    c3(client-3):::pod ==&gt; s\n    c4(client-4):::pod ==&gt; s\n    s ==&gt; p1(server-1):::pod\n    s ==&gt; p2(server-2):::pod\n    s ==&gt; p3(server-3):::pod\nlinkStyle 0,3,4 stroke: orange;\nlinkStyle 1,5 stroke: blue;\nlinkStyle 6,2 stroke: red;\nclassDef srv fill: #a3e4d7, stroke:  #148f77 \nclassDef pod fill: #85c1e9, stroke: #2874a6\n</pre><p><small><i>Figure 1: The first three clients are symmetrically routed to the server‚Äôs three pods.\nThe 4th client starts the next cycle.</i></small></p><p>In Figure 1, we have more clients than servers, so even if we may not fully optimize\nthe resource utilization of the servers, at least all of them are kept busy. But what happens\nif we have fewer clients than servers? The answer is that some pods will stand idle\nwithout doing work but waste resources.</p><pre>flowchart LR\n    c1(client-1):::pod ==&gt; s[service/server]:::srv\n    s ==&gt; p1(server-1):::pod\n    s --&gt; p2(server-2):::pod\n    s --&gt; p3(server-3):::pod\nlinkStyle 0,1 stroke: orange;\nclassDef srv fill: #a3e4d7, stroke:  #148f77 \nclassDef pod fill: #85c1e9, stroke: #2874a6\n</pre><p><small><i>Figure 2: One client - Three servers.\nThe client is making requests only to one server.</i></small></p><p>Autoscaling the number of server replicas might be the solution.\nThe truth is - It‚Äôs not. Imagine a scenario where you‚Äôve set an autoscaling rule (with\na tool like <a href=\"https://keda.sh/\" target=\"_blank\" rel=\"noopener\">Keda</a>\n) that increases the number of replicas whenever a pod\nreaches 90% of its memory consumption.</p><p>Since there‚Äôs no link between the number of clients and the number of servers,\nwe can face a scenario in which one client is causing the autoscaling rule to be triggered,\nincreasing the number of servers by one; however, it doesn‚Äôt use the new replica.</p><p>It wouldn‚Äôt make sense to scale the number of servers based on the number of clients either.\nScaling based on resource utilization is a good rule, but we want to ensure that\nwhen a pod is too busy, it will share the load with new replicas that the autoscaling tool is adding.</p><p>To illustrate the problem, I wrote simple  apps in Go (a client and a server)\nbased on this :</p><div><pre tabindex=\"0\"><code data-lang=\"proto\"></code></pre></div><p>The client sends 3000 messages via the  method, and the server responds\nwith a pre-generated  to reflect its unique identity. The returned value is then\nprinted to  by the client. Here‚Äôs the client‚Äôs code:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>Using <a href=\"https://minikube.sigs.k8s.io/docs/\" target=\"_blank\" rel=\"noopener\">minikube</a>\n as my local Kubernetes cluster.\nI‚Äôve deployed three servers, pointed from a service called  and ran one client\nas a job:</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>As you can see, although we have three servers, the client sent all of its requests only to one of\nthese servers. Maybe because our single client is making synchronous\nrequests to the service. Let‚Äôs try to communicate concurrently:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>The same results. You‚Äôll still face the same results even if you try to create the connection on every iteration.\nAs mentioned above, the load-balancer is symmetrically spreading connections across pods,\nso a single client will always be connected to the same server.</p><p>In this experiment, we‚Äôre trying to make our single client spread its messages (preferably evenly)\nacross the different replicas of the server.</p><pre>flowchart LR\n    c1(client-1):::pod ==&gt; s[service/server]:::srv\n    s ==&gt; p1(server-1):::pod\n    s ==&gt; p2(server-2):::pod\n    s ==&gt; p3(server-3):::pod\nlinkStyle 0,1,2,3 stroke: orange;\nclassDef srv fill: #a3e4d7, stroke:  #148f77 \nclassDef pod fill: #85c1e9, stroke: #2874a6\n</pre><p><small><i>Figure 3: One client is sending requests to all server‚Äôs replicas.</i></small></p><p>The trick is to  Kubernetes‚Äô built-in load balancer. Kubernetes supports  services.\nThose services don‚Äôt have static IPs and, therefore, don‚Äôt have a single endpoint where they perform\nload-balancing. The purpose of  services is to expose pod IPs deployed under\nthe service via , allowing other load-balancing/service-discovery implementations to replace\nthe built-in one.</p><p>To turn a Kubernetes service into a  service, we should simply add to our service definition:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><h3>Client side load-balancing</h3><p>Now that our service is , we can set the client‚Äôs load-balancing policy\nto make request in a  fashion:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>If we run this version of the client against a  service:</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>Great! All 3000 messages were sent across all pods. The spread is not quite\neven. One pod received about 42% of messages, and the others about 29%. The reason is that our client\nsent all of its messages concurrently. If we send the messages synchronously:</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>The client has almost successfully cycled around all three servers with a nearly 100% even spread.</p><p>We‚Äôre not done yet. Our client doesn‚Äôt have a mechanism for knowing about new pods\nduring its runtime. When calling  with the load-balancing settings,\nour client retrieves the list of available IPs and will never try to fetch it again by default.</p><p>To illustrate this point, I throttled the client by adding 50 milliseconds to each iteration,\ngiving me 2.5 minutes to play with the number of replicas during the client‚Äôs runtime.</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>I removed one replica during runtime and gradually added up to 5 replicas.\nLet‚Äôs see the results:</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>Interestingly, we‚Äôve lost one pod forever after the first change (removing one replica).\nIn fact, it (coincidentally) failed to make its first request, and our client‚Äôs load balancer discarded it for good.\nNotice that our client wasn‚Äôt aware that I‚Äôd added more replicas (up to 5)  during its runtime.</p><p>To solve this, we need a  resolver that allows the client to periodically fetch new IPs.\nThe  module conveniently has a built-in  resolver.\nBy using its  package, we can globally register a  resolver as follows:</p><div><pre tabindex=\"0\"><code data-lang=\"go\"></code></pre></div><p>On this attempt, I started with three replicas, then dropped one, added one, and finally dropped one.\nLet‚Äôs look at the results:</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>Not a single miss. The last one, with the 150 messages, is probably the first pod dropped\nsince I dropped it closer to the start of the client‚Äôs job. Then, I‚Äôve added one, perhaps the\npod with the 512 messages. After I removed one replica again, I was left with two pods, running until\nthe job was finished, explaining the two pods with identical 1169 messages.</p><p>By understanding the benefits of  services in Kubernetes and combining client-side load-balancing\nwith a  resolver, we‚Äôve managed to make a  client in Go that knows how to spread its messages\nin a  manner while being aware of new available servers during runtime.</p>","contentLength":7458,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1itt1xh/scaling_grpc_with_kubernetes_using_go/"},{"title":"Analyzing and editing sections of an ELF executable","url":"https://www.reddit.com/r/golang/comments/1itsiws/analyzing_and_editing_sections_of_an_elf/","date":1740034718,"author":"/u/Astro_Z0mbie","guid":7512,"unread":true,"content":"<p>Hello everyone, I am taking a course in computer security, I am studying malware analysis with ghira. Since I know a bit about golang I wanted to write a program that modifies the .text section of an executable but I can't do it. \"debug/elf\" is extremely useful but does not allow modifications. What do you recommend? My purpose is simply to add a section to the end of the executable.</p>","contentLength":386,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go 1.24 uses Swiss Tables, what are they?","url":"https://dev.to/ocodista/go-124-uses-swiss-table-what-are-they-3c2l","date":1740014008,"author":"Caio Borghi","guid":6120,"unread":true,"content":"<ul><li>\nThe Old Map\n\n<ul><li>\nChaining\n\n</li></ul></li><li>\n\nSwiss Table\n\n<ul></ul></li><li>\n\nElastic Hashing\n\n</li></ul><p>In v1.24, Go replaced its  implementation with a new version of hash table called , or .</p><p>\nA Swiss Table is a map, that uses a cache-friendly, more efficient (with shorter memory footprint) approach that makes comparisons and insertions faster.</p><p>It also uses a different strategy for addressing collisions: <em>linear probing on steroids</em> over the previous strategy .</p><p>When working with hash-tables, one thing is certain: .</p><p>The previous implementation was highly tuned for memory efficiency and performance.</p><p> It pre-allocates memory in the form of , where each bucket can have up to 8  pairs. When a bucket is full (or half-full), the algorithm allocates a new  as a linked list, in a process known as .</p><p>As the table approaches a high rate of *, the runtime moves all entries to a new memory address block (usually twice as big as the previous one), this is known as . </p><p><code>* Load Factor = used positions / total capacity</code></p><p>In traditional chaining, whenever there is a conflict, the runtime allocates memory for a new / and stores it as a linked-list.</p><p>Imagine a hash function that, based on a string, returns an  (offset value) to a fixed memory address:</p><p>Usually, these functions try to produce an <a href=\"https://www.geeksforgeeks.org/avalanche-effect-in-cryptography/\" rel=\"noopener noreferrer\"></a> to distribute the results \"evenly\" over the map memory interval.</p><p>Our hashing function is more vulnerable to conflicts, as it only returns the size of the string to define the address.</p><p>Now, let's assume we add the following keys:</p><div><table><tbody></tbody></table></div><p>When we add a new \"Go\" key, we caused a conflict.</p><p>As the index of \"Go\" is 2 and there is already \"JS\" at position 2, the strategy will allocate a new  in the available memory and point the  prop of \"JS\" to \"Go\".</p><div><table><tbody></tbody></table></div><p>So we have keys, that are used as inputs in a , that generates an  (<em>or an offset for a fixed memory address/start of the list</em>) and the  or  or  are inserted as linked-lists.</p><p>As you can see, <strong>each new node is placed far from it's conflict key in the memory</strong>.</p><p>This means that, when searching for a key that has conflicts (, for example), the processor will fetch sparse addresses in memory.</p><p>Even though the Go previous implementation used a lot of performance improvement techniques (as using 8-sized buckets instead of single-nodes) and partially comparing keys (7 bits instead of 64), <strong>this chaining approach is not cache-friendly</strong>.</p><p>You can check the specific details <a href=\"https://github.com/golang/go/blob/master/src/runtime/map_noswiss.go#L365\" rel=\"noopener noreferrer\">here</a>.</p><p>It's a cleaver implementation that uses 1 byte metadata and  on steroids.</p><p>No more dynamic memory allocation for  with .</p><div><table><tbody></tbody></table></div><p>A better visualization in this case is to look at the has table as a, well, _flat_hash_map.</p><p>When a conflict occurs, the algorithm will  search for the next position, one by one.</p><p>For adding \"Go\", we have:</p><ul><li>See slot 1016 and realize it is filled.</li><li>See slot 1024 and realize it its filled.</li><li>See slot 1032 and realize it its filled.</li><li>Slot 1040 is open, use it.</li></ul><p>It's only on slot 1040 that will find an open spot, this is where the \"Go\" key goes.</p><p>The important thing to notice is that this time, collisions are located  each other, making them , which speeds things up a little bit.</p><p>Streaming <a href=\"https://en.wikipedia.org/wiki/Single_instruction,_multiple_data\" rel=\"noopener noreferrer\">SIMD</a> Extensions 3 is a kind of processor instruction that, combined with curated software engineering techniques such as , provides a way to perform parallel reads of memory addresses with a single instruction.</p><p>Which means that, when probing for collisions, the Swiss Table could perform up to 16 checks at once, <em>even though Golang seems to be using just 8</em>, it's way better than checking one by one!</p><p>Swiss Table uses a metadata byte to partially store the hashed key, enabling quick comparison (7 bit instead of 64).</p><p>With  (also known as ) +  + ,  and  are faster and consume less memory than the previous implementation.</p><ol><li>Create and populate a  items map </li><li>Performs  lookups using mod indexing.</li><li>Inserts  new entries into the map.</li><li>Removes the first  from the map.</li></ol><div><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr></tbody></table></div><p>Even though the Go Swiss Table uses buckets and a sparse hash function (for the avalanche effect) to distribute keys evenly over the pre-allocated memory block, as the table get's full, conflicts will generate  sections that will increase search time.</p><p>It's easy to see this happening with a 10 positions table:</p><div><pre><code>Table: [nil, C, JS, PHP, PERL, nil, nil, nil, nil, nil]\n\nAdding a new \"B\" key would cause:\n- len(B) = 1\n- position 1 is occupied by \"C\", look next\n- position 2 is occupied by \"JS\", look next\n- position 3 is occupied by \"PHP\", look next\n- position 4 is occupied by \"PRL\", look next\n- position 4 is free, add \"B\"\n\nTable: [nil, C, JS, PHP, PERL, B, nil, nil, nil, nil]\nIndex:   0,  1,  2,  3,   4,   5,   6,   7,   8,   9  \n</code></pre></div><p>Now, any  call that returned 1, 2, 3, 4 or 5 would require searching up to 4 positions, piece of cake for the , I recognize, but what if there was a </p><p>In January 2025, a new paper regarding  was launched suggesting a new approach, theoretically better than , called . </p><p>It claims to beat a 40-years old conjecture (<a href=\"https://en.wikipedia.org/wiki/Yau%27s_conjecture\" rel=\"noopener noreferrer\">Yao's conjecture</a>), that defends linear probing as a simple, with near-optimal efficiency, that doesn't degrade catastrophically as load increases.</p><p>Krapivin discovered the new strategy while being unaware of Yao's conjecture, which indicates we should challenge  more often.</p><p>Basically, instead of checking positions one by one, or 16 by 16 (as our beloved  do), it created a new bidimensional strategy to calculate the insert address using .</p><p>The idea is, there is a new function named  that returns a position of a node, where:</p><ol><li>i = Primary Bucket (Hash Result)</li></ol><p>So, using our previous hash function, both keys \"JS\" and \"Go\" would return 2 as their \"Primary Bucket\".</p><p>The insertion order would determine if the key would be placed at position œÜ(2, 1) = 2 or maybe œÜ(2, 2) = 7.</p><p>The magic lies in the  function, that is able to <em>virtually create overflow buckets</em> for collisions_. It outperforms the complexity algorithm for  for worst and average cases, with these  or , it probes less addresses, leading to a better  performance.</p><p>Will  be applied to Swiss Tables? \nMaybe. I hope so. Time will tell.</p><p>I still have open questions:</p><ul><li>Will elastic hashing prove itself faster than linear probing + SSE3?</li><li>Can Elastic Hash benefit itself from the parallel reads of SIMD?</li><li>Which language will be the first to implement this new algorithm?</li></ul><p>If you, by any chance, happens to cross some of these answers out there, leave it a comment!</p><p>It's nice to experience these latest improvements to Hash Table efficiency as they happen, in real time.</p><p>A  old paper improving the code complexity of one aspect of the core data structure algorithm is great news! </p><p>It shows that there are no boundaries for performance improvements, not even decade-old rules are safe, no matter where you are, <strong>there is always room for improvement</strong>.</p>","contentLength":6605,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"iter.Seq, iter.Seq2 and iter.Pull in practice","url":"https://www.reddit.com/r/golang/comments/1itly57/iterseq_iterseq2_and_iterpull_in_practice/","date":1740013085,"author":"/u/fuzzylollipop","guid":7381,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/fuzzylollipop\"> /u/fuzzylollipop </a>","contentLength":36,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go team is sneaking Monadish packages into the standard library","url":"https://www.reddit.com/r/golang/comments/1itlwvi/go_team_is_sneaking_monadish_packages_into_the/","date":1740012981,"author":"/u/fuzzylollipop","guid":6954,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/fuzzylollipop\"> /u/fuzzylollipop </a>","contentLength":36,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Concurrency, go routines","url":"https://www.reddit.com/r/golang/comments/1itfw9d/concurrency_go_routines/","date":1739997413,"author":"/u/Historical-Poetry871","guid":7380,"unread":true,"content":"<p>there is some core ideas of multi threading and goroutines individually i cant understand.</p><p>1- the fact that there is no guarantee about the code execution and which thread is going to read this value through a channel</p><p>2- how would this be faster than synchronous execution since we have to write and operate once per x time ?</p><p>3- dead locks and channels being a blocking at reading or writing</p><p>4- mutex and how they does work and how would i be sure that this thread is going to read right now and this would come after</p><p>all i have found is just some scratching of the surface so if there is any recommendations videos, articles, books, etc.. i would be thankful.</p>","contentLength":655,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go Pointers vs. Values: When to Use Them (and When Not To)","url":"https://dev.to/wycliffealphus/go-pointers-vs-values-when-to-use-them-and-when-not-to-1epn","date":1739995337,"author":"Wycliffe A. Onyango","guid":6024,"unread":true,"content":"<p>If you're new to Go, one thing you‚Äôll quickly notice is that Go doesn‚Äôt have  like some other languages‚Äîit has  instead. But what if you need to tell the difference between a field that was never set and one that was explicitly set to zero? This is where  can help‚Äîbut they can also introduce unnecessary complexity. Let‚Äôs break it down step by step.</p><h2>\n  \n  \n  The Problem: Missing vs. Zero Value\n</h2><p>Imagine you‚Äôre working with JSON data that represents a user:</p><p>If we define our Go struct like this:</p><div><pre><code></code></pre></div><p>Both of the JSON examples above will result in  in Go. This means we can‚Äôt tell whether the name was:</p><ol><li> to an empty string.</li><li> in the JSON at all.</li></ol><p>This can be a problem if missing values need special handling.</p><h2>\n  \n  \n  The Solution: Using Pointers for JSON\n</h2><div><pre><code></code></pre></div><p>Now, we can check if  is :</p><div><pre><code></code></pre></div><ul><li><p>If the  field is absent in the JSON, .</p></li><li><p>If the  field is present but empty (),  is , but its value is .</p></li></ul><p>This is useful when working with APIs, databases, or configurations where a missing value is different from an empty one.</p><p>Pointers can be , making code harder to read and more error-prone.</p><p><strong>Example: Configuration Settings</strong></p><p>Let‚Äôs say we need a configuration with a timeout value. A common mistake is using a pointer:</p><div><pre><code></code></pre></div><p>Now, every time we want to use it, we have to check if it‚Äôs :</p><div><pre><code></code></pre></div><p>This makes the code more complex than necessary. Instead, we can use a <strong>simple integer with a boolean flag:</strong></p><div><pre><code></code></pre></div><p>Now, we check if  is true:</p><div><pre><code></code></pre></div><ul><li>No extra memory allocations for pointers.</li><li>Simpler, more readable code.</li></ul><ul><li><p> when you need to distinguish between \"unset\" and \"zero value\" (especially in JSON and APIs).</p></li><li><p> when a zero value is enough and you don‚Äôt need to track missing data separately.</p></li><li><p><strong>Avoid unnecessary pointers</strong> to keep your Go code clean, efficient, and easy to maintain.</p></li></ul><p>By following these simple rules, you‚Äôll write  with fewer headaches! </p>","contentLength":1794,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learning how to use a debugger ( YouTube video )","url":"https://youtu.be/LuNeTTFIwpw?si=18Ikh0CskJjEM_-r","date":1739994289,"author":"/u/adelowo","guid":6082,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1itelqr/learning_how_to_use_a_debugger_youtube_video/"},{"title":"WAX ‚Äì JSX-based Server-Side Rendering for Go","url":"https://www.reddit.com/r/golang/comments/1itc26f/wax_jsxbased_serverside_rendering_for_go/","date":1739988285,"author":"/u/NoPeanut6044","guid":6110,"unread":true,"content":"<p>WAX is a Go library for server-side rendering (SSR) of JSX/TSX components, designed to provide a seamless, dynamic view layer without the need to regenerate templates after code changes.</p><p>Key Features: ‚úÖ Server-side rendering of JSX ‚Äì Render JSX/TSX views directly in Go.<p> üîÑ Hot reload for views ‚Äì Automatically refresh changes without restarting the server.</p> ‚úÖ TypeScript model generation ‚Äì Generate TypeScript typings from Go structs for type safety.<p> ‚úÖ Seamless integration ‚Äì Works with net/http, Echo, and other Go web frameworks.</p> üöÄ Single-file deployment ‚Äì Bundle JSX views into a Go binary using embed.FS.</p><p>Library is in active development but usable. I'd love to get your feedback and suggestions for improvement!</p>","contentLength":735,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GitHub - codeglyph/go-dotignore: go-dotignore is a Go library for parsing .gitignore-style files and matching paths against ignore patterns. It supports custom ignore files, negation patterns, directory/file matching, and advanced wildcards.","url":"https://github.com/codeglyph/go-dotignore","date":1739980393,"author":"/u/toxic2soul","guid":5961,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1it8pc7/github_codeglyphgodotignore_godotignore_is_a_go/"},{"title":"Building high-performance websites using htmx and Go","url":"https://dev.to/logrocket/building-high-performance-websites-using-htmx-and-go-2beb","date":1739977200,"author":"Megan Lee","guid":5886,"unread":true,"content":"<p>The web development landscape is shifting back toward server-side rendering and away from JavaScript-heavy client-side architectures. This trend has been fueled by tools like React Server Components and the  directory in frameworks like Next.js, which simplifies server-side routing and rendering. </p><p>In response to this shift, tools like htmx are gaining popularity for building interactive web experiences with minimal JavaScript. The HTML-based htmx allows for server-side rendering using AJAX. In this article, we‚Äôll explore how to build a high-performance website using htmx and Go, a backend language known for its speed and efficiency.</p><p><a href=\"https://blog.logrocket.com/using-htmx-modern-apps-classic-techniques/\" rel=\"noopener noreferrer\">htmx</a> is a lightweight JavaScript library that enables building large, dynamic sites with minimal reliance on client-side JavaScript. </p><p>htmx injects various AJAX-like attributes and is rendered to simple HTML on the server, which allows developers to achieve <a href=\"https://www.w3schools.com/xml/ajax_intro.asp\" rel=\"noopener noreferrer\">AJAX</a>-like updates and dynamic interactions on the pages. </p><div><pre><code>\n    Click Me!\n</code></pre></div><p>Here, a button element is given various attributes. When clicked, the  attribute sends an HTTP POST request to the  API. Afterward, the button click will swap the targeted div with an ID of  with the response received from the API. </p><p>This is how htmx handles typical dynamic interactions. As you can see, the page or the element in this case will be server-rendered, thus quite quick in terms of interactivity, while saving on client-side JavaScript bundles.</p><p><a href=\"https://go.dev/doc/\" rel=\"noopener noreferrer\">Golang</a>, or Go, is a high-performance, typed programming language. Its automatic garbage collection, efficient concurrency model, and rapid execution make it a popular choice for building scalable backends.</p><h2>\n  \n  \n  Building a simple dynamic app with htmx and Go\n</h2><p>Setting up a Go server is the first step in building a backend with Go. Go‚Äôs specification makes it easy to quickly spin up a server by using its built-in  package. Assuming you have Go set up in your system, you can create a Go project in a directory and start by creating a file called . </p><p>In this file, you have to import the  for string and log formatting and  for initiating the server:</p><div><pre><code></code></pre></div><p>This creates the  function with the following server code:</p><div><pre><code></code></pre></div><p>This will run your server at 8080 port and print \"Hello World!\" in your terminal. </p><p>You can go a step further and, instead of printing the log, you can render a simple UI by changing the  function:</p><div><pre><code></code></pre></div><p>Now, at the root , this HTML will be rendered instead. The key thing to note here is that <code>w.Header().Set(\"Content-Type\", \"text/html\")</code> sets the response header to indicate the content type is HTML. Finally, you can execute this file by running the command  where  is the filename.</p><h3>\n  \n  \n  Adding interactivity with htmx\n</h3><p>You can use htmx to render the same HTML snippet with htmx-specific attributes that will allow you to add interactions to the page. You can integrate htmx in this project by just using a CDN, and including it in your script wherever you are rendering:</p><div><pre><code></code></pre></div><p>In this example, you can update your  function to include the htmx syntax:</p><div><pre><code></code></pre></div><p>You can see the  tag that now allows you to write the htmx-specific syntax and hence the attributes. What is really happening here? </p><p>Well, as you have seen in the first section of this article, the  attribute will get a response from the  API and will swap the  due to . This new response will update the div with an ID of  due to the  attribute. </p><p>For all of this to happen, you need to have the  endpoint that will send a content response that is supposed to replace the existing HTML content. In Go, you can create such a handler like so:</p><div><pre><code></code></pre></div><p>This handler will send the HTML response of <code>&lt;p&gt;Content updated at: +r.RemoteAddr+&lt;/p&gt;</code>, i.e. printing the IP address of the user.</p><h2>\n  \n  \n  Advanced usage: Real-world examples\n</h2><p>Now that you understand the basic implementation with Go, we‚Äôre going to go a little deeper and build a small to-do list app.</p><h3>\n  \n  \n  Building a to-do list app\n</h3><p>First things first, create a directory/folder on your system and create a  file. Alternatively, you can run the following code:</p><p>Here, the todo-app will be your project name, which will create the  file where you will write all the backend logic. Now, you need something to store your entries to ensure data persistence. You can use SQL to store your creds and the items that your to-do app will contain. You‚Äôll need to import this library by running the following:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Define a task model in Go\n</h3><p>Now, you need to define the schema for your to-do items. Any to-do items will have an ID and a status to track if it is completed or not. In Go, you can have this schema typed in as follows:</p><div><pre><code></code></pre></div><p>With the schema set, you now need to have an  function that will render an HTML file to the browser, and with that, the rest of your backend logic will mutate the rendered HTML based on the new to-do items or its status of being completed:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  API endpoints to add, delete, and mark tasks as completed\n</h3><p>With  added, the next step is to define API endpoints and their corresponding functions:</p><ul><li>: Gets all the to-do items from the SQL backend</li><li>: Adds an input from the user by entering the HTML input field</li><li>: Deletes items by handling the  button click</li><li>: Toggles the item status and marks it as completed</li></ul><p>You can find the complete  backend logic here:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Building a database using SQL\n</h3><p>To make sure your to-do items are persisted, you have to save them to a local database. In this example, I‚Äôll use <a href=\"https://blog.logrocket.com/using-sql-database-golang/\" rel=\"noopener noreferrer\">SQL</a>. Just spin up a new terminal, assuming you have <a href=\"https://dev.mysql.com/downloads/installer/\" rel=\"noopener noreferrer\">SQL installed</a> on your system, you can create a new database by running:</p><p>Now create a schema on the database called  with the described types and keys:</p><div><pre><code></code></pre></div><p>Here, the  is our primary key. </p><p>To make sure your database has been created, you can run ; it will render all your databases as follows:</p><div><pre><code></code></pre></div><p>To check the entries in your app, run <code>SELECT id, title, details FROM todos;</code>, which will render all the to-do items entries.</p><h3>\n  \n  \n  Building frontend using htmx\n</h3><p>Now, with the  and the  logic set in, you can move over to the HTML part and create a file called . It will be responsible for rendering out and swapping items based on the mutation from the backend logic from the  file:</p><div><pre><code></code></pre></div><p>Notice that the CSS is being written in the same file, but you can move to a CSS file of its own based on your preference. You can move the styling part to its own file and import the file in HTML itself. Find the complete code in this <a href=\"https://github.com/abhinav-anshul/htmx-todo-app\" rel=\"noopener noreferrer\">GitHub repo</a><a href=\"https://github.com/abhinav-anshul/htmx-todo-app\" rel=\"noopener noreferrer\">sitory</a>. </p><p>Make sure you have SQL set up on your system for the application to work correctly. You can see the preview here: <a href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fblog.logrocket.com%2Fwp-content%2Fuploads%2F2025%2F02%2Fto-do-list-app-preview-scaled.gif\"><img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fblog.logrocket.com%2Fwp-content%2Fuploads%2F2025%2F02%2Fto-do-list-app-preview-scaled.gif\" alt=\"To-Do List App Preview\" width=\"800\" height=\"440\"></a></p><p>In a typical htmx and Go setup, you already have an application that is quite fast as it leverages server-side rendering, but you can still use a series of steps on both the frontend and backend as you scale up your application. Below are a few optimization methods I recommend.</p><h3>\n  \n  \n  Backend optimizations with Go\n</h3><p>Backend optimization ensures smooth API delivery and scales an application's performance. Go is built with optimal performance and scalability in mind.</p><h4>\n  \n  \n  Efficient database handling with Go: Use sqlx or native database drivers\n</h4><p>Go offers quick database interactions that result in fast performance. It provides both native database drivers and <a href=\"https://github.com/jmoiron/sqlx\" rel=\"noopener noreferrer\">sqlx</a> for simplified querying. As you have seen in this article, you have used native database driver, SQL just by importing a package straight from GitHub. Similarly, you can use sqlx to have reduced boilerplate and more built-in features like struct mapping.</p><h4>\n  \n  \n  Caching responses to reduce server load\n</h4><p>Go offers several approaches to caching to reduce computation and not overburden the database. You can use in-memory caching techniques such as  for lightweight, easy-to-use key-value pair-styled caching:</p><div><pre><code></code></pre></div><p>Similarly, for more advanced use cases, you can use <a href=\"https://blog.logrocket.com/guide-to-fully-understanding-redis/\" rel=\"noopener noreferrer\">Redis</a>. All you have to do is import the package from GitHub and get started:</p><div><pre><code></code></pre></div><h4>\n  \n  \n  Use goroutines for concurrent task execution\n</h4><p>It would be unfair to talk about Go and not mention concurrency. <a href=\"https://blog.logrocket.com/concurrency-patterns-golang-waitgroups-goroutines/\" rel=\"noopener noreferrer\">G</a><a href=\"https://blog.logrocket.com/concurrency-patterns-golang-waitgroups-goroutines/\" rel=\"noopener noreferrer\">oroutines</a>, when paired with concurrency, can be quite powerful. Goroutines are small lightweight threads that can be run programmatically to manage by Go's runtime:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Frontend optimizations with htmx\n</h3><p>In this application, you optimized HTML by using htmx, an external third-party library that relies heavily on server-side rendering. htmx not only makes it easier to develop applications with Go but it also minimizes the payload. </p><p>It uses some of the very smart and well-thought-out attributes, such as , to lazy load the content. If you are developing a scalable app with server-side rendering, htmx is probably the missing piece if not using any other server-rendering libraries.</p><h2>\n  \n  \n  Benefits, trade-offs, and best practices\n</h2><p>As web development trends shift toward optimizing performance and reducing JavaScript overhead, the htmx and Go stack provides an efficient alternative to traditional frontend-heavy frameworks. </p><p>When building an app with htmx and Go, you can maintain a clear separation between backend logic and UI updates, which can save you a lot of time when working across different teams. </p><p>While htmx is relatively new and may have a learning curve, developers with a solid Go background will find it a powerful choice for building fast, server-rendered applications.</p><h2>\n  \n  \n  Get set up with LogRocket's modern error tracking in minutes:\n</h2><ol><li>Install LogRocket via NPM or script tag.  must be called client-side, not server-side.</li></ol><div><pre><code>npm i  logrocket \n\n// Code:\n\nimport LogRocket from  \nLogRocket.init</code></pre></div><div><pre><code></code></pre></div><p>3.(Optional) Install plugins for deeper integrations with your stack:</p><ul></ul>","contentLength":9432,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introduce My Self !","url":"https://dev.to/skyhayato/introduce-my-self--3ail","date":1739975643,"author":"SKY-HaYaTo","guid":5854,"unread":true,"content":"<p>Hi, Guys!\nIt's Kouhei, a software engineer in Japan.</p><p>Now, this article is my first challenge, so I will introduce my career.</p><p>At this time, I work as an engineer.\nMy skills are divided into four sections, as listed below:</p><ol><li>Frontend Developer\nSkills:</li></ol><p>HTML, CSS, JavaScript, TypeScript\nReact (Next.js)</p><ol><li>Backend Developer\nSkills:</li></ol><p>Java (Spring Framework)\nC# (ASP.NET Core, Entity Framework)<p>\nPHP (Laravel, CakePHP, Symfony)</p>\nGolang (Echo, Beego)\nPython (Django)\nExcel VBA</p><p>PostgreSQL\nSQL Server</p><ol><li>Cloud\nAWS (Amazon Web Services) ‚Äì Currently a beginner, so I'm studying!\nI'm studying these skills every day. In addition, to enjoy talking about these topics with people around the world, I am also studying languages (English, French, Spanish, and Indonesian).</li></ol><p>Through this article, I hope to improve my language skills, not just in English but also in other languages.</p><p>Looking forward to your responses!</p>","contentLength":882,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Yet another article on sqlc","url":"https://www.reddit.com/r/golang/comments/1it50tc/yet_another_article_on_sqlc/","date":1739970356,"author":"/u/Medical-Age-6422","guid":6018,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/Medical-Age-6422\"> /u/Medical-Age-6422 </a>","contentLength":39,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Are you tired of APIs that crawl when they should fly?","url":"https://dev.to/architagr/are-you-tired-of-apis-that-crawl-when-they-should-fly-4ned","date":1739961900,"author":"Archit Agarwal","guid":5695,"unread":true,"content":"<p>You‚Äôre building a batch update API to process 1,000 tasks in a single request. Each task needs to go through these steps:</p><ul></ul><p>Sounds simple, right? Well, here‚Äôs the catch: each step takes 100 milliseconds per task. Multiply that by 1,000 tasks across 4 steps, and voil√†‚Äîyou‚Äôre staring at over 6 minutes to process a single batch.</p><p>What if I told you it could be done in ~400ms?</p><p>Check out my latest article on Concurrent Pipelines in Go. I‚Äôll walk you through building scalable APIs that are as fast as your users expect them to be.</p>","contentLength":534,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GopherCon Europe 2025 just got released","url":"https://www.reddit.com/r/golang/comments/1it2all/gophercon_europe_2025_just_got_released/","date":1739960425,"author":"/u/zetttaa","guid":5688,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/zetttaa\"> /u/zetttaa </a>","contentLength":30,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sponge vs Spring: A Comprehensive Comparison and Selection Guide","url":"https://dev.to/zhufuyi/sponge-vs-spring-a-comprehensive-comparison-and-selection-guide-490e","date":1739951435,"author":"zhuyasen","guid":5620,"unread":true,"content":"<h3>\n  \n  \n  Framework Comparison and Selection Guide\n</h3><p>In today's fast-evolving technological landscape, choosing the right development framework is crucial for the success of a project. This article provides a detailed comparison of two popular frameworks‚ÄîSponge and Spring‚Äîto help developers make an informed choice based on project requirements.</p><h4>\n  \n  \n  Framework Feature Comparison\n</h4><div><table><tbody><tr></tr><tr><td>Low-code, Code Generation, Modularization</td><td>IoC (Inversion of Control), DI (Dependency Injection), AOP (Aspect-Oriented Programming)</td></tr><tr><td>High performance, fast execution speed, excellent concurrency</td><td>Mature performance, requires JVM tuning, potentially long startup time</td></tr><tr><td>Relatively new, rapidly evolving</td><td>Highly mature, industry standard, high stability</td></tr><tr><td>RESTFul API, Backend Services, Microservices, Rapid Development</td><td>Enterprise applications, Web applications, Microservices, Backend systems, Broad applicability</td></tr><tr><td>Relatively low, low-code reduces development barriers</td><td>Steep learning curve, vast and complex ecosystem</td></tr><tr><td>Code generation (SQL, Protobuf, JSON, Custom Templates), Gin, gRPC, ORM, API Documentation, CRUD, Modularization</td><td>IoC container, DI, AOP, Spring MVC, Data Access, Transaction Management, Web Services, JDBC Abstraction, Testing Framework, Modularization</td></tr><tr><td>Spring MVC, Spring WebFlux (Reactive)</td></tr><tr><td>Natively designed for microservices, supports multiple microservice architectures</td><td>Excellent microservices support through Spring Boot and Spring Cloud</td></tr><tr><td><strong>Code Generation Capability</strong></td><td>Core feature, powerful, highly automated</td><td>Relatively weak, Spring Initializr provides project initialization and limited scaffolding</td></tr><tr><td>MySQL, MongoDB, PostgreSQL, SQLite</td><td>Extensive database support via Spring Data and JDBC</td></tr><tr><td>Service registration &amp; discovery (Consul, Etcd, Nacos), Load balancing, Circuit breaker, Rate limiting, Tracing, Monitoring, Configuration Center</td><td>Spring Cloud suite (e.g., Eureka, Consul, Nacos, Ribbon, Hystrix, Gateway, Sleuth, Zipkin), Service registration &amp; discovery, Load balancing, Circuit breaker, Rate limiting, API Gateway, Tracing, Configuration Center, Monitoring</td></tr><tr><td>Relatively small but growing</td><td>Large and highly active, with extensive resources and support</td></tr><tr><td>UI tools, Command-line tools</td><td>Spring Boot, Spring Initializr, Maven, Gradle, IDE support</td></tr></tbody></table></div><h4>\n  \n  \n  Summary &amp; Selection Recommendations\n</h4><p> is a mature and comprehensive Java enterprise application framework with a vast community and ecosystem. It is centered around IoC, DI, and AOP, offering numerous modules and functionalities needed to build complex applications. Spring is suitable for large-scale enterprise applications, particularly those requiring high scalability, reliability, and security. However, Spring has a steep learning curve, involves complex configurations, and has relatively long startup times.</p><p> is an emerging Go development framework focused on improving development efficiency and lowering entry barriers. It emphasizes code generation and integrates common components such as the Gin web framework, gRPC RPC framework, and microservice capabilities. It also provides a user-friendly UI interface and comprehensive documentation. Sponge is ideal for rapidly developing high-performance web services, API endpoints, and microservices, especially when quick delivery and low-code development are priorities. The learning curve for Sponge is relatively low, but its community and ecosystem are not as mature as Spring's.</p><ul><li><ul><li>  You need to build large, complex, enterprise-grade Java applications.</li><li>  Your team has extensive experience with Java and Spring.</li><li>  You require high maturity, stability, and strong community support.</li><li>  Application performance bottlenecks are primarily in business logic or database layers rather than the framework itself.</li></ul></li><li><ul><li>  You need to rapidly develop high-performance Go web services, RESTFul APIs, or microservices.</li><li>  You prioritize development efficiency and low-code development.</li><li>  Your team has solid Go development experience or wants to explore a new Go framework.</li><li>  Fast startup time and low resource consumption are critical.</li><li>  Suitable for small to large backend services with rapid iteration and scalability needs.</li></ul></li></ul><p>With this comparison and selection guide, developers can choose the most suitable framework based on their project requirements and team technology stack, ensuring successful and efficient development.</p>","contentLength":4277,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building Multi-language Support in Go: A Practical Guide with GoFrame","url":"https://dev.to/jones_charles_ad50858dbc0/building-multi-language-support-in-go-a-practical-guide-with-goframe-19oo","date":1739948795,"author":"Jones Charles","guid":5619,"unread":true,"content":"<p>Ever needed to make your Go application speak multiple languages? In this guide, I'll show you how to implement internationalization (i18n) in your Go applications using GoFrame. Whether you're building a small web app or a large-scale system, proper i18n support can help you reach users worldwide. Let's dive in!</p><ul><li>Setting up i18n in a GoFrame project</li><li>Managing translations efficiently</li><li>Hot reloading translations</li><li>Best practices and gotchas</li></ul><ul><li>Go 1.16 or later installed</li><li>Some familiarity with web development concepts</li></ul><p>First, let's install the required i18n module. GoFrame makes this super easy:</p><div><pre><code>go get  github.com/gogf/gf/v2/i18n/gi18n\n</code></pre></div><p>Create a configuration file in your project. I usually put it in <code>manifest/config/config.yaml</code>:</p><div><pre><code></code></pre></div><p>This tells GoFrame where to find our translation files and what our default language should be.</p><h2>\n  \n  \n  Creating Translation Files üìù\n</h2><p>Here's where the fun begins! Create a directory called  and add your translation files. Let's support English, Chinese, and Japanese:</p><div><pre><code></code></pre></div><p>Pro tip: Keep your translation keys organized and meaningful. It'll save you headaches later!</p><h2>\n  \n  \n  The Magic: Translation in Action ‚ú®\n</h2><p>Here's a simple example of how to use translations in your code:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Dynamic Content with Parameters üîÑ\n</h2><p>Need to include dynamic values in your translations? Got you covered:</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>One of my favorite features is the built-in plural support:</p><div><pre><code></code></pre></div><p>The system automatically chooses the right form based on the count. How cool is that?</p><h2>\n  \n  \n  Auto-Detection in Web Apps üåê\n</h2><p>In web applications, you'll want to detect the user's language automatically. Here's a practical example:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Hot Reload for Development üî•\n</h2><p>During development, you might want to see translation changes without restarting your app. Enable hot reload in your config:</p><div><pre><code></code></pre></div><p>Now you can update translations on the fly!</p><ol><li>: Keep your translation files modular. Split them by feature if you have many translations.</li><li>: Use dot notation (e.g., ) to organize your translation keys.</li><li>: Always test your app with different languages to catch any hardcoded strings.</li><li>: Set up a fallback language for missing translations.</li></ol><h2>\n  \n  \n  Common Pitfalls to Avoid ‚ö†Ô∏è\n</h2><ul><li>Don't forget to handle missing translations gracefully</li><li>Be careful with string concatenation in translations</li><li>Watch out for context-specific translations</li><li>Remember that some languages read right-to-left</li></ul><p>Internationalization doesn't have to be scary! With GoFrame's i18n support, you can create truly global applications with minimal fuss. The framework handles the complex parts, letting you focus on building great features.</p><ul><li>Try implementing i18n in your project</li><li>Explore more advanced features like custom translation loaders</li><li>Share your experiences in the comments!</li></ul><p>Have you implemented i18n in your Go projects? What challenges did you face? Let's discuss in the comments below! üëá</p><p><em>Found this helpful? Follow me for more Go tutorials and tips! Also, check out <a href=\"https://dev.to/jones_charles_ad50858dbc0/implementing-websocket-communication-and-heartbeat-mechanism-with-goframe-a-hands-on-guide-44df\">my other articles</a> on Go development.</em></p>","contentLength":2918,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"go-msquic: A new QUIC/HTTP3 library for Go that relies on msquic","url":"https://www.reddit.com/r/golang/comments/1isx99g/gomsquic_a_new_quichttp3_library_for_go_that/","date":1739940299,"author":"/u/noboruma","guid":5564,"unread":true,"content":"<p> is one of the most performant QUIC protocol library out there. is a wrapper around  so you can use it in your Go project.</p><p>The project is quite new, but we have seen good performance results with it so far. PRs are welcome!</p>","contentLength":222,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Please let me know if you are interested in Part 3","url":"https://dev.to/mohammad-reza-mahdiani/please-let-me-know-if-you-are-interested-in-part-3-1nm3","date":1739939814,"author":"Mohammad Reza Mahdiani","guid":5567,"unread":true,"content":"<h2>The Ultimate Guide to Programming Languages: Choosing the Right Tool for the Job - Part 2</h2><h3>Mohammad Reza Mahdiani „Éª Feb 1</h3>","contentLength":121,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Golang Application Instrumentation: A Different Approach?","url":"https://www.reddit.com/r/golang/comments/1isu2iv/golang_application_instrumentation_a_different/","date":1739930591,"author":"/u/colonel_whitebeard","guid":4525,"unread":true,"content":"<p>As a curious engineer, I rabbit-hole a lot. Today, I was thinking...which always turns out bad. And often leads to a new ridiculous project...</p><p>I've been working on an idea that aims to simplify how I trace and analyze Go applications during development. The core idea is to enable comprehensive tracing‚Äîcapturing function calls, execution times, and generating visual call graphs‚Äîwithout requiring any modifications to your existing source code. Instead of littering your project with tracing code, you simply drop in a YAML configuration file and let the tool do its \"magic\".</p><p><strong>Why This Project Came to Be:</strong> The goal was to create something that could offer deep insights into an application's runtime behavior‚Äîeverything from simple function calls to complex concurrent operations‚Äîwhile keeping the codebase untouched. I just don't want to write inline instrumentation code into my application while I'm prototyping.</p><ul><li><strong>Automatic Instrumentation:</strong> It wraps function calls automatically, capturing entry, exit, parameters, return values, and performance metrics.</li><li> Generates a DOT file that can be converted into a visual diagram (with Graphviz) to see how your functions interact.</li><li> All configuration is done through a simple YAML file, making it incredibly easy to add or remove instrumentation as needed.</li></ul><ul><li> You don‚Äôt have to change your code at all.</li><li> Just add a YAML file, and you're ready to gain insights.</li><li> It works across different types of Go applications‚Äîwhether it's handling concurrency, recursion, or typical sequential logic.</li><li><strong>Better Debugging &amp; Profiling:</strong> It helps you understand performance bottlenecks and the inner workings of your application without the overhead of traditional methods.</li></ul><p><em>Again, this is aimed at the development stage. It's not a replacement for existing production-ready telemetry packages. It's just meant to be a simple way to add some instrumentation to any application without modifying the codebase.</em></p><p><strong><em>Is this concept valid, or am I just reinventing the wheel?</em></strong></p><p>If there's enough interest, I'll certainly share the source code, but right now it's working, but a bit of a cluster-mess. I'll just need a day or two to clean it up and make it less embarrassing. ;)</p><p>Cheers, and thanks for the feedback!</p><p>EDIT: I realized that I should explain a few more details! The idea revolves around AST construction/deconstruction of the project code to build a new temp version of an existing application with instrumentation wrapped around the code. It then runs the instrumented version of your code in a temp area and provides analysis in the form of logs and call graphs, and other info. This can certainly be extended, but it was only a day-long rabbit hole. ;)</p>","contentLength":2675,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Testing concurrent code with testing/synctest","url":"https://go.dev/blog/synctest","date":1739923200,"author":"Damien Neil","guid":5901,"unread":true,"content":"<p>\n      Damien Neil\n      19 February 2025\n      </p><p>One of Go‚Äôs signature features is built-in support for concurrency.\nGoroutines and channels are simple and effective primitives for\nwriting concurrent programs.</p><p>However, testing concurrent programs can be difficult and error prone.</p><p>In Go 1.24, we are introducing a new, experimental\n<a href=\"https://go.dev/pkg/testing/synctest\"></a> package\nto support testing concurrent code. This post will explain the motivation behind\nthis experiment, demonstrate how to use the synctest package, and discuss its potential future.</p><p>In Go 1.24, the  package is experimental and\nnot subject to the Go compatibility promise.\nIt is not visible by default.\nTo use it, compile your code with  set in your environment.</p><h2>Testing concurrent programs is difficult</h2><p>To begin with, let us consider a simple example.</p><p>The <a href=\"https://go.dev/pkg/context#AfterFunc\"></a> function\narranges for a function to be called in its own goroutine after a context is canceled.\nHere is a possible test for :</p><pre><code>func TestAfterFunc(t *testing.T) {\n    ctx, cancel := context.WithCancel(context.Background())\n\n    calledCh := make(chan struct{}) // closed when AfterFunc is called\n    context.AfterFunc(ctx, func() {\n        close(calledCh)\n    })\n\n    // TODO: Assert that the AfterFunc has not been called.\n\n    cancel()\n\n    // TODO: Assert that the AfterFunc has been called.\n}\n</code></pre><p>We want to check two conditions in this test:\nThe function is not called before the context is canceled,\nand the function  called after the context is canceled.</p><p>Checking a negative in a concurrent system is difficult.\nWe can easily test that the function has not been called ,\nbut how do we check that it  be called?</p><p>A common approach is to wait for some amount of time before\nconcluding that an event will not happen.\nLet‚Äôs try introducing a helper function to our test which does this.</p><pre><code>// funcCalled reports whether the function was called.\nfuncCalled := func() bool {\n    select {\n    case &lt;-calledCh:\n        return true\n    case &lt;-time.After(10 * time.Millisecond):\n        return false\n    }\n}\n\nif funcCalled() {\n    t.Fatalf(\"AfterFunc function called before context is canceled\")\n}\n\ncancel()\n\nif !funcCalled() {\n    t.Fatalf(\"AfterFunc function not called after context is canceled\")\n}\n</code></pre><p>This test is slow:\n10 milliseconds isn‚Äôt a lot of time, but it adds up over many tests.</p><p>This test is also flaky:\n10 milliseconds is a long time on a fast computer,\nbut it isn‚Äôt unusual to see pauses lasting several seconds\non shared and overloaded\n<a href=\"https://en.wikipedia.org/wiki/Continuous_integration\" rel=\"noreferrer\" target=\"_blank\">CI</a>\nsystems.</p><p>We can make the test less flaky at the expense of making it slower,\nand we can make it less slow at the expense of making it flakier,\nbut we can‚Äôt make it both fast and reliable.</p><h2>Introducing the testing/synctest package</h2><p>The  package solves this problem.\nIt allows us to rewrite this test to be simple, fast, and reliable,\nwithout any changes to the code being tested.</p><p>The package contains only two functions:  and .</p><p> calls a function in a new goroutine.\nThis goroutine and any goroutines started by it\nexist in an isolated environment which we call a .\n waits for every goroutine in the current goroutine‚Äôs bubble\nto block on another goroutine in the bubble.</p><p>Let‚Äôs rewrite our test above using the  package.</p><pre><code>func TestAfterFunc(t *testing.T) {\n    synctest.Run(func() {\n        ctx, cancel := context.WithCancel(context.Background())\n\n        funcCalled := false\n        context.AfterFunc(ctx, func() {\n            funcCalled = true\n        })\n\n        synctest.Wait()\n        if funcCalled {\n            t.Fatalf(\"AfterFunc function called before context is canceled\")\n        }\n\n        cancel()\n\n        synctest.Wait()\n        if !funcCalled {\n            t.Fatalf(\"AfterFunc function not called after context is canceled\")\n        }\n    })\n}\n</code></pre><p>This is almost identical to our original test,\nbut we have wrapped the test in a  call\nand we call  before asserting that the function has been called or not.</p><p>The  function waits for every goroutine in the caller‚Äôs bubble to block.\nWhen it returns, we know that the context package has either called the function,\nor will not call it until we take some further action.</p><p>This test is now both fast and reliable.</p><p>The test is simpler, too:\nwe have replaced the  channel with a boolean.\nPreviously we needed to use a channel to avoid a data race between\nthe test goroutine and the  goroutine,\nbut the  function now provides that synchronization.</p><p>The race detector understands  calls,\nand this test passes when run with .\nIf we remove the second  call,\nthe race detector will correctly report a data race in the test.</p><p>Concurrent code often deals with time.</p><p>Testing code that works with time can be difficult.\nUsing real time in tests causes slow and flaky tests,\nas we have seen above.\nUsing fake time requires avoiding  package functions,\nand designing the code under test to work with\nan optional fake clock.</p><p>The  package makes it simpler to test code that uses time.</p><p>Goroutines in the bubble started by  use a fake clock.\nWithin the bubble, functions in the  package operate on the\nfake clock. Time advances in the bubble when all goroutines are\nblocked.</p><p>To demonstrate, let‚Äôs write a test for the\n<a href=\"https://go.dev/pkg/context#WithTimeout\"></a> function.\n creates a child of a context,\nwhich expires after a given timeout.</p><pre><code>func TestWithTimeout(t *testing.T) {\n    synctest.Run(func() {\n        const timeout = 5 * time.Second\n        ctx, cancel := context.WithTimeout(context.Background(), timeout)\n        defer cancel()\n\n        // Wait just less than the timeout.\n        time.Sleep(timeout - time.Nanosecond)\n        synctest.Wait()\n        if err := ctx.Err(); err != nil {\n            t.Fatalf(\"before timeout, ctx.Err() = %v; want nil\", err)\n        }\n\n        // Wait the rest of the way until the timeout.\n        time.Sleep(time.Nanosecond)\n        synctest.Wait()\n        if err := ctx.Err(); err != context.DeadlineExceeded {\n            t.Fatalf(\"after timeout, ctx.Err() = %v; want DeadlineExceeded\", err)\n        }\n    })\n}\n</code></pre><p>We write this test just as if we were working with real time.\nThe only difference is that we wrap the test function in ,\nand call  after each  call to wait for the context\npackage‚Äôs timers to finish running.</p><p>A key concept in  is the bubble becoming .\nThis happens when every goroutine in the bubble is blocked,\nand can only be unblocked by another goroutine in the bubble.</p><p>When a bubble is durably blocked:</p><ul><li>If there is an outstanding  call, it returns.</li><li>Otherwise, time advances to the next time that could unblock a goroutine, if any.</li><li>Otherwise, the bubble is deadlocked and  panics.</li></ul><p>A bubble is not durably blocked if any goroutine is blocked\nbut might be woken by some event from outside the bubble.</p><p>The complete list of operations which durably block a goroutine is:</p><ul><li>a send or receive on a nil channel</li><li>a send or receive blocked on a channel created within the same bubble</li><li>a select statement where every case is durably blocking</li></ul><p>Operations on a  are not durably blocking.</p><p>It is common for functions to acquire a global mutex.\nFor example, a number of functions in the reflect package\nuse a global cache guarded by a mutex.\nIf a goroutine in a synctest bubble blocks while acquiring\na mutex held by a goroutine outside the bubble,\nit is not durably blocked‚Äîit is blocked, but will be unblocked\nby a goroutine from outside its bubble.</p><p>Since mutexes are usually not held for long periods of time,\nwe simply exclude them from ‚Äôs consideration.</p><p>Channels created within a bubble behave differently from ones created outside.</p><p>Channel operations are durably blocking only if the channel is bubbled\n(created in the bubble).\nOperating on a bubbled channel from outside the bubble panics.</p><p>These rules ensure that a goroutine is durably blocked only when\ncommunicating with goroutines within its bubble.</p><p>External I/O operations, such as reading from a network connection,\nare not durably blocking.</p><p>Network reads may be unblocked by writes from outside the bubble,\npossibly even from other processes.\nEven if the only writer to a network connection is also in the same bubble,\nthe runtime cannot distinguish between a connection waiting for more data to arrive\nand one where the kernel has received data and is in the process of delivering it.</p><p>Testing a network server or client with synctest will generally\nrequire supplying a fake network implementation.\nFor example, the <a href=\"https://go.dev/pkg/net#Pipe\"></a> function\ncreates a pair of s that use an in-memory network connection\nand can be used in synctest tests.</p><p>The  function starts a goroutine in a new bubble.\nIt returns when every goroutine in the bubble has exited.\nIt panics if the bubble is durably blocked\nand cannot be unblocked by advancing time.</p><p>The requirement that every goroutine in the bubble exit before Run returns\nmeans that tests must be careful to clean up any background goroutines\nbefore completing.</p><p>Let‚Äôs look at another example, this time using the \npackage to test a networked program.\nFor this example, we‚Äôll test the  package‚Äôs handling of\nthe 100 Continue response.</p><p>An HTTP client sending a request can include an ‚ÄúExpect: 100-continue‚Äù\nheader to tell the server that the client has additional data to send.\nThe server may then respond with a 100 Continue informational response\nto request the rest of the request,\nor with some other status to tell the client that the content is not needed.\nFor example, a client uploading a large file might use this feature to\nconfirm that the server is willing to accept the file before sending it.</p><p>Our test will confirm that when sending an ‚ÄúExpect: 100-continue‚Äù header\nthe HTTP client does not send a request‚Äôs content before the server\nrequests it, and that it does send the content after receiving a\n100 Continue response.</p><p>Often tests of a communicating client and server can use a\nloopback network connection. When working with ,\nhowever, we will usually want to use a fake network connection\nto allow us to detect when all goroutines are blocked on the network.\nWe‚Äôll start this test by creating an  (an HTTP client) that uses\nan in-memory network connection created by <a href=\"https://go.dev/pkg/net#Pipe\"></a>.</p><pre><code>func Test(t *testing.T) {\n    synctest.Run(func() {\n        srvConn, cliConn := net.Pipe()\n        defer srvConn.Close()\n        defer cliConn.Close()\n        tr := &amp;http.Transport{\n            DialContext: func(ctx context.Context, network, address string) (net.Conn, error) {\n                return cliConn, nil\n            },\n            // Setting a non-zero timeout enables \"Expect: 100-continue\" handling.\n            // Since the following test does not sleep,\n            // we will never encounter this timeout,\n            // even if the test takes a long time to run on a slow machine.\n            ExpectContinueTimeout: 5 * time.Second,\n        }\n</code></pre><p>We send a request on this transport with the ‚ÄúExpect: 100-continue‚Äù header set.\nThe request is sent in a new goroutine, since it won‚Äôt complete until the end of the test.</p><pre><code>        body := \"request body\"\n        go func() {\n            req, _ := http.NewRequest(\"PUT\", \"http://test.tld/\", strings.NewReader(body))\n            req.Header.Set(\"Expect\", \"100-continue\")\n            resp, err := tr.RoundTrip(req)\n            if err != nil {\n                t.Errorf(\"RoundTrip: unexpected error %v\", err)\n            } else {\n                resp.Body.Close()\n            }\n        }()\n</code></pre><p>We read the request headers sent by the client.</p><pre><code>        req, err := http.ReadRequest(bufio.NewReader(srvConn))\n        if err != nil {\n            t.Fatalf(\"ReadRequest: %v\", err)\n        }\n</code></pre><p>Now we come to the heart of the test.\nWe want to assert that the client will not send the request body yet.</p><p>We start a new goroutine copying the body sent to the server into a ,\nwait for all goroutines in the bubble to block, and verify that we haven‚Äôt read anything\nfrom the body yet.</p><p>If we forget the  call, the race detector will correctly complain\nabout a data race, but with the  this is safe.</p><pre><code>        var gotBody strings.Builder\n        go io.Copy(&amp;gotBody, req.Body)\n        synctest.Wait()\n        if got := gotBody.String(); got != \"\" {\n            t.Fatalf(\"before sending 100 Continue, unexpectedly read body: %q\", got)\n        }\n</code></pre><p>We write a ‚Äú100 Continue‚Äù response to the client and verify that it now sends the\nrequest body.</p><pre><code>        srvConn.Write([]byte(\"HTTP/1.1 100 Continue\\r\\n\\r\\n\"))\n        synctest.Wait()\n        if got := gotBody.String(); got != body {\n            t.Fatalf(\"after sending 100 Continue, read body %q, want %q\", got, body)\n        }\n</code></pre><p>And finally, we finish up by sending the ‚Äú200 OK‚Äù response to conclude the request.</p><p>We have started several goroutines during this test.\nThe  call will wait for all of them to exit before returning.</p><pre><code>        srvConn.Write([]byte(\"HTTP/1.1 200 OK\\r\\n\\r\\n\"))\n    })\n}\n</code></pre><p>This test can be easily extended to test other behaviors,\nsuch as verifying that the request body is not sent if the server does not ask for it,\nor that it is sent if the server does not respond within a timeout.</p><p>We are introducing <a href=\"https://go.dev/pkg/testing/synctest\"></a>\nin Go 1.24 as an  package.\nDepending on feedback and experience\nwe may release it with or without amendments,\ncontinue the experiment,\nor remove it in a future version of Go.</p><p>The package is not visible by default.\nTo use it, compile your code with  set in your environment.</p><p>We want to hear your feedback!\nIf you try out ,\nplease report your experiences, positive or negative,\non <a href=\"https://go.dev/issue/67434\">go.dev/issue/67434</a>.</p>","contentLength":13215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Create a Server Driven CLI from your REST API","url":"https://dev.to/zuplo/create-a-server-driven-cli-from-your-rest-api-3p29","date":1739917825,"author":"Adrian Machado","guid":4457,"unread":true,"content":"<blockquote><p>This article is written by <a href=\"https://github.com/lispyclouds\" rel=\"noopener noreferrer\">Rahul D√©</a>, a VP of &gt; Site Reliability Engineering at Citi and creator/maintainer of popular tools &gt; like <a href=\"https://github.com/babashka/babashka\" rel=\"noopener noreferrer\">babashka</a>, &gt; <a href=\"https://github.com/bob-cd/bob\" rel=\"noopener noreferrer\">bob</a>, and now &gt; <a href=\"https://github.com/lispyclouds/climate\" rel=\"noopener noreferrer\">climate</a>. All opinions expressed are &gt; his own.</p></blockquote><p>APIs, specifically the REST APIs are everywhere and the <a href=\"https://swagger.io/specification/\" rel=\"noopener noreferrer\">OpenAPI</a> is pretty much a standard. Accessing them via various means is a fairly regular thing that a lot of us do often and when it comes to the CLI (Command Line Interface) languages like Go, Rust etc are quite popular choices when building. These languages are mostly of statically typed in nature, favouring a closed world approach of knowing all the types and paths at compile time to be able to produce lean and efficient binary for ease of deployment and use.</p><p>Like with every engineering choice, there are trade-offs. The one that's here is the loss of dynamism, namely we see a lot of bespoke tooling in these languages doing fundamentally the same thing: make HTTP calls and let users have a better experience than making those calls themselves. The need to know all the types and paths beforehand causes these perceived maintenance issues:</p><ul><li>Spec duplication: the paths, the schemas etc need to be replicated on the\nclient side again. eg when using the popular <a href=\"https://cobra.dev/\" rel=\"noopener noreferrer\">Cobra</a> lib for Go, one must tell it all the possible types beforehand.</li><li>Tighter coupling of client and server: As we have to know each of the paths\nand the methods that a server expects, we need to essentially replicate that same thing when making the requests making a tight coupling which is susceptible to breakage when the API changes. API is a product having its own versioning. eg kubectl only supports <a href=\"https://kubernetes.io/releases/version-skew-policy/\" rel=\"noopener noreferrer\">certain versions</a> of kubernetes. Similarly podman or docker CLIs.</li><li>Servers can't influence the client: Ironically to the previous point, as we\nnow have replicated the server spec on the client side we effectively have a split brain: changes on the server like needing a new parameter etc need to be copied over to the client.</li></ul><p>All of this put together increases the maintenance overhead and its specially true for complex tooling like kubectl.</p><p>I work primarily on the infra side of this, namely Platform and Site Reliability Engineering which involves me having other developers as my users and this cascading effect of an API breakage is quite painful. There are way to work around this issue and from my experience, being <a href=\"https://www.atlassian.com/blog/technology/spec-first-api-development\" rel=\"noopener noreferrer\">spec-first</a> seems to offer the best balance of development and maintenance velocities.</p><p>I am quite a big fan of being spec-first, mainly for the following reasons:</p><ul><li>The API spec is the single source of truth: This is what your users see and\nnot your code. Make this the first class citizen like your users and the code should use this and not the other way round.</li><li>This keeps all the servers and clients in sync automatically with less\nbreakage.</li><li>This keeps a nice separation between the business logic (the API handler code)\nand the infra thereby allowing developers to focus on what's important.</li></ul><p>Another project of mine <a href=\"https://bob-cd.github.io/\" rel=\"noopener noreferrer\">Bob</a> can be seen as an example of spec-first design. All its tooling follow that idea and its <a href=\"https://bob-cd.github.io/cli/\" rel=\"noopener noreferrer\">CLI</a> inspired Climate. A lot of Bob uses <a href=\"https://clojure.org/\" rel=\"noopener noreferrer\">Clojure</a> a language that I cherish and who's ideas make me think better in every other place too.</p><p>Although codegen is one of the ways to be spec-first, I personally don't subscribe to the approach of generating code:</p><ul><li>Introduces another build step adding complexity and more layers of debugging.</li><li>Makes the build more fragile in keeping up with tooling and language changes.</li><li>The generated code comes with its own opinions and is often harder to\nchange/mould to our needs.</li><li>It is static code at the end, can't do much at runtime.</li></ul><ul><li><a href=\"https://rest.sh/\" rel=\"noopener noreferrer\">restish</a>: Inspired some of the ideas behind this. This is a\nproject with different goals of being a fully automatic CLI for an OpenAPI REST API and is a bit hard to use as a lib.</li><li><a href=\"https://github.com/lispyclouds/navi\" rel=\"noopener noreferrer\">navi</a>: Server side spec-first library I\nwrote for Clojure which inspired the handler mechanism in Climate.</li></ul><p>Keeping all of the above into consideration and the fact that Go is one of the most widely used CLI languages, <a href=\"https://github.com/lispyclouds/climate\" rel=\"noopener noreferrer\">Climate</a> was built to address the issues.</p><p>As the name implies, its your mate or sidekick when building CLIs in Go with the intentions of:</p><ul><li>Keeping the REST API boilerplate away from you.</li><li>Keep the CLI code always in sync with the changes on the server.</li><li>Ability to bootstrap at runtime without any code changes.</li><li>Decoupling you from API machinery, allowing you to focus on just the handlers,\nbusiness logic and things that may not the part of the server calls.</li><li>It does just enough to take the machinery out and not more like making the\ncalls for you too; that's business logic.</li></ul><p>Every OpenAPI3 Schema consists of one or more <a href=\"https://swagger.io/docs/specification/v3_0/paths-and-operations/#operations\" rel=\"noopener noreferrer\">Operations</a> having an . An Operation is a combination of the HTTP path, the method and some parameters.</p><p>Overall, Climate works by with these operations at its core. It:</p><ul><li>Parses these from the YAML or JSON file.</li><li>Transforms each of these into a corresponding Cobra command by looking at\nhints from the server.</li><li>Transform each of the parameters into a Flag with the type.</li><li>Build a grouped Cobra command tree and attach it to the root command.</li></ul><h3>\n  \n  \n  Servers influencing the CLI\n</h3><p>Climate allows the server to influence the CLI behaviour by using OpenAPI's <a href=\"https://swagger.io/docs/specification/v3_0/openapi-extensions/\" rel=\"noopener noreferrer\">extensions</a>. This is the secret of Climate's dynamism. Influenced by some of the ideas behind <a href=\"https://rest.sh/\" rel=\"noopener noreferrer\">restish</a> it uses the following extensions as of now:</p><ul><li>: A list of strings which would be used as the alternate names\nfor an operation.</li><li>: A string to allow grouping subcommands together. All operations\nin the same group would become subcommands in that group name.</li><li>: A boolean to hide the operation from the CLI menu. Same\nbehaviour as a cobra command hide: it's present and expects a handler.</li><li>: A boolean to tell climate to omit the operation completely.</li><li>: A string to specify a different name. Applies to operations and\nrequest bodies as of now.</li></ul><p>As of now, only the primitive types are supported:</p><ul></ul><p>More support for <a href=\"https://swagger.io/docs/specification/v3_0/data-models/data-types/\" rel=\"noopener noreferrer\">types</a> like collections and composite types are planned. These are subject to limitations of what Cobra can do out of the box and what makes sense from a CLI perspective. There are sensible default behaviour like for request bodies its implicity  which handles most cases. These types are converted to Flags with the appropriate type checking functions and correctly coerced or the errors reported when invoked.</p><p>Checkout <a href=\"https://github.com/bob-cd/wendy\" rel=\"noopener noreferrer\">Wendy</a> as a proper example of a project built with Climate.</p><p>This assumes an installation of <a href=\"https://go.dev/doc/install\" rel=\"noopener noreferrer\">Go 1.23+</a> is available.</p><div><pre><code>go get github.com/lispyclouds/climate\n</code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>Define a cobra root command:</p><div><pre><code></code></pre></div><h4>\n  \n  \n  Handlers and Handler Data:\n</h4><p>Define one or more handler functions of the following signature:</p><div><pre><code></code></pre></div><p>As of now, each handler is called with the cobra command it was invoked with, the args and an extra , more info <a href=\"https://pkg.go.dev/github.com/lispyclouds/climate#pkg-types\" rel=\"noopener noreferrer\">here</a></p><p>This can be used to query the params from the command mostly in a type safe manner:</p><div><pre><code></code></pre></div><p>Define the handlers for the necessary operations. These map to the  field of each operation:</p><div><pre><code></code></pre></div><p>Bootstrap the root command:</p><div><pre><code></code></pre></div><p>Continue adding more commands and/or execute:</p><div><pre><code></code></pre></div><div><pre><code>go run main.go \nMy Calc powered by OpenAPI\n\nUsage:\n  calc \n\nAvailable Commands:\n  completion  Generate the autocompletion script the specified shell\n  Help about any info        Operations on info\n  ops         Operations on ops\n  ping        Returns Ok all is well\n\nFlags:\n  , calc\n\nUse more information about a command.\n\ngo run main.go ops \nOperations on ops\n\nUsage:\n  calc ops \n\nAvailable Commands:\n  add-get     Adds two numbers\n  add-post    Adds two numbers via POST\n\nFlags:\n  , ops\n\nUse more information about a command.\n\ngo run main.go ops add-get \nAdds two numbers\n\nUsage:\n  calc ops add-get flags]\n\nAliases:\n  add-get, ag\n\nFlags:\n  , add-get\n       int   The first number\n       int   The second number\n\ngo run main.go ops add-get  1  foo\nError: invalid argument  flag: strconv.ParseInt: parsing : invalid syntax\nUsage:\n  calc ops add-get flags]\n\nAliases:\n  add-get, ag\n\nFlags:\n  , add-get\n       int   The first number\n       int   The second number\n\ngo run main.go ops add-get  1  2\n2024/12/14 12:53:32 INFO called! </code></pre></div><p>Climate results from my experiences of being at the confluence of many teams developing various tools and proving the need to keep specifications at the centre of things. WIth this it hopefully inspires others to adopt such approaches and with static tooling like Go, its still possible to make flexible things which keep the users at the forefront.</p>","contentLength":8299,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Starskey - High performance embedded key-value database (LSM tree based)","url":"https://github.com/starskey-io/starskey","date":1739917759,"author":"/u/diagraphic","guid":4472,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1isp362/starskey_high_performance_embedded_keyvalue/"},{"title":"SQLC and multiple SQLite connections","url":"https://www.reddit.com/r/golang/comments/1isksmh/sqlc_and_multiple_sqlite_connections/","date":1739905824,"author":"/u/maekoos","guid":4430,"unread":true,"content":"<p>I've read a few times now that it's best to have one SQLite connection for writing and then one or more for reading to avoid database locking (I think that's why, at least).</p><p>But I'm not sure how you‚Äôd best handle this with SQLC?</p><p>I usually just create a single repo with a single sql.DB instance, which I then pass to my handlers. Should I create two repos and pass them both? I feel like I'd probably mix them up at some point. Or maybe one repo package with my read queries and another with only my write queries?</p><p>I'm really curious how you‚Äôd handle this in your applications!</p>","contentLength":578,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Double Entry: o que √©, quando usar e como fazer","url":"https://dev.to/lerian/double-entry-o-que-e-quando-usar-e-como-fazer-2594","date":1739899152,"author":"Jefferson Rodrigues","guid":4316,"unread":true,"content":"<p>Quem est√° come√ßando a trabalhar no setor financeiro pode se deparar com esse termo \"double-entry\", que √© um conceito fundamental para o gerenciamento de transa√ß√µes e registros financeiros. Neste post, quero explicar em detalhes como esse conceito funciona, quando ele deve ser utilizado e sua import√¢ncia para manter a integridade das transa√ß√µes financeiras.</p><p>A melhor maneira de explicar o que √© um double-entry √© com um exemplo. Ent√£o, considere que voc√™ fa√ßa uma transfer√™ncia Pix de R$ 1.000 para pagar uma conta; esse processo de transfer√™ncia, na verdade, realiza duas opera√ß√µes:</p><ul><li>A primeira opera√ß√£o √© a de d√©bito de R$ 1.000 na sua conta;</li><li>A segunda opera√ß√£o √© a de cr√©dito de R$ 1.000 na conta destino.</li></ul><p>√â imprescind√≠vel que, para a transa√ß√£o seja efetuada com sucesso, ambas as opera√ß√µes sejam registradas corretamente. Se uma das opera√ß√µes falhar, todo o processo precisa ser revertido para manter a integridade da conta. Esse conceito √© conhecido como double entry (entrada dupla) e √© fundamental para garantir a integridade das transa√ß√µes financeiras.</p><h2>\n  \n  \n  Import√¢ncia no Setor Financeiro\n</h2><p>O sistema de double entry √© crucial no setor financeiro por diversos motivos:</p><ul><li> Garante que todas as transa√ß√µes financeiras sejam registradas com exatid√£o, reduzindo erros e discrep√¢ncias nas contas.</li><li> Permite rastrear facilmente o hist√≥rico de transa√ß√µes e identificar poss√≠veis irregularidades ou fraudes.</li><li><strong>Conformidade regulat√≥ria:</strong> Atende aos requisitos legais e regulat√≥rios do setor financeiro, que exigem registros precisos e transparentes.</li><li> Simplifica o processo de reconcilia√ß√£o, permitindo a compara√ß√£o eficiente entre registros internos e extratos banc√°rios.</li></ul><h2>\n  \n  \n  Aplica√ß√µes al√©m dos sistemas financeiros\n</h2><p>O sistema de double entry, embora tradicionalmente associado a sistemas financeiros, pode ser aplicado em outros contextos tamb√©m, como em gest√£o de invent√°rio e log√≠stica em que √© preciso registrar a entrada e sa√≠da de produtos.</p><p>Em todos esses casos, o princ√≠pio fundamental do double entry ‚Äî onde cada transa√ß√£o afeta dois registros diferentes ‚Äî ajuda a manter a integridade e rastreabilidade dos dados.</p><p>Vamos criar um exemplo simples de implementa√ß√£o do sistema double entry em Go. Neste exemplo, vamos simular uma transfer√™ncia banc√°ria:</p><div><pre><code></code></pre></div><p>Neste exemplo, implementamos:</p><ul><li>Uma estrutura  para representar contas com ID e saldo</li><li>Uma estrutura  para registrar os detalhes das transa√ß√µes</li><li>M√©todos  e  para realizar as opera√ß√µes nas contas</li><li>Uma fun√ß√£o  que implementa o conceito de double entry, garantindo que ambas as opera√ß√µes sejam realizadas</li></ul><p>Quando executado, este c√≥digo demonstra uma transfer√™ncia de R$ 300,00 da conta A para a conta B, mostrando os saldos antes e depois da opera√ß√£o. Se houver qualquer erro durante o processo (como saldo insuficiente), a transa√ß√£o n√£o √© completada.</p><p>No exemplo que vimos anteriormente, criamos duas opera√ß√µes fundamentais que comp√µem uma transa√ß√£o:</p><ul><li>Uma opera√ß√£o de d√©bito (Debit) que remove o valor da conta de origem</li><li>Uma opera√ß√£o de cr√©dito (Credit) que adiciona o valor na conta de destino</li></ul><p>Essas opera√ß√µes s√£o as unidades b√°sicas de uma transa√ß√£o financeira e devem sempre ocorrer em pares para manter o princ√≠pio do double-entry. Cada opera√ß√£o √© at√¥mica, ou seja, ou ela acontece por completo ou n√£o acontece, n√£o existindo estados intermedi√°rios.</p><p>No c√≥digo, implementamos essas opera√ß√µes como m√©todos separados da estrutura Account, mas elas s√£o sempre chamadas juntas atrav√©s da fun√ß√£o Transfer para garantir que o princ√≠pio do double-entry seja respeitado.</p><h3>\n  \n  \n  Encapsulamento e Seguran√ßa\n</h3><p>Para garantir que o saldo s√≥ possa ser alterado atrav√©s da fun√ß√£o de transa√ß√£o, podemos utilizar encapsulamento e tornar o campo Balance privado na estrutura Account. Veja como podemos modificar o c√≥digo anterior:</p><div><pre><code></code></pre></div><p>Com essa implementa√ß√£o, o campo balance s√≥ pode ser modificado atrav√©s dos m√©todos do pr√≥prio pacote, garantindo que todas as altera√ß√µes de saldo passem pelo sistema de double entry.</p><p>Claro, h√° outras considera√ß√µes importantes ao implementar um sistema de double entry, como garantir a atomicidade das transa√ß√µes usando um banco de dados transacional e implementar logs detalhados de todas as opera√ß√µes para fins de auditoria. Essas pr√°ticas ajudam a manter a integridade e rastreabilidade do sistema.</p><p>Ao contr√°rio de basicamente todos os sistemas financeiros brasileiros que s√£o fechados, o Midaz nos permite examinar e discutir abertamente o uso de double entry e estudar como essa pr√°tica funciona em um ambiente de produ√ß√£o.</p><h3>\n  \n  \n  Como √© criada uma opera√ß√£o\n</h3><p>Vamos examinar como o Midaz cria uma opera√ß√£o individual dentro de uma transa√ß√£o. Dentro da cria√ß√£o de uma transa√ß√£o, √© chamado o m√©todo  que recebe os detalhes da transa√ß√£o e as contas envolvidas. Segue o c√≥digo da cria√ß√£o de uma opera√ß√£o, comentado:</p><div><pre><code></code></pre></div><p>Para facilitar a leitura, removi loggers e tracers e alguns outros detalhes, mas voc√™ pode analisar na √≠ntegra o c√≥digo no GitHub <a href=\"https://github.com/LerianStudio/midaz/blob/main/components/transaction/internal/adapters/http/in/transaction.go\" rel=\"noopener noreferrer\">da cria√ß√£o de uma transa√ß√£o</a> e da opera√ß√£o. Coloque nos coment√°rios caso queira um artigo destrinchando e explicando como √© feito o c√≥digo de uma transa√ß√£o financeira por completo.</p>","contentLength":5250,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Better GitHub Actions caching for Go","url":"https://danp.net/posts/github-actions-go-cache/","date":1739896962,"author":"/u/dpiddy","guid":4507,"unread":true,"content":"<p>I‚Äôve been spending some time on <a href=\"https://en.wikipedia.org/wiki/Continuous_integration\" target=\"_blank\">CI</a> improvements at <a href=\"https://www.grax.com/\" target=\"_blank\">work</a> recently, mostly around cutting down how long things take.</p><p>As I looked to see if anything about our overall process could be improved, a couple things bothered me:</p><p>Why, if we were using a pretty standard GitHub Actions setup, were there indications that modules were being downloaded as part of every run?\nShouldn‚Äôt that all be cached?</p><p>Why did it seem like there was always a delay before tests actually started running?\nShouldn‚Äôt the first few packages‚Äô fast tests complete quickly?</p><p>Before getting into what I ended up changing, let‚Äôs review the setup we had and break down the issues.</p><p>There are two main workflows I was concerned with: one for CI and another artifacts.</p><p>The CI workflow runs tests.\nThe artifacts workflow builds binaries for distribution.\nWe use <a href=\"https://docs.github.com/en/actions/sharing-automations/creating-actions/about-custom-actions\" target=\"_blank\">custom actions</a> to cut down on some repetition but they both end up having this step:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>Let‚Äôs look at the second one in more detail.</p><p>setup-go doesn‚Äôt use the <a href=\"https://github.com/actions/cache\" target=\"_blank\">cache action</a> directly but they both use the same implementation so we can describe what setup-go is doing in its terms.</p><p>If you were to put an explicit action/cache step in to replicate what setup-go does, it would look something like:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>(some items in  made static for brevity)</p><p>When saving to the cache, this step generates a key based on:</p><ul></ul><p>For example, if you <a href=\"https://go.dev/doc/devel/release#go1.23.minor\" target=\"_blank\">updated to use Go 1.23.4</a> around December 3rd when it came out and didn‚Äôt change anything else that influenced the key until Go 1.23.5 came out in January you would have been using the same cache item that whole time.\nA build that happened January 8th would have used the same cache item as one that started December 16th, regardless of how much your code had changed in the meantime.</p><p>For smaller projects that‚Äôs probably not a big deal but for larger ones it can add up.\nIt seemed to be for ours!</p><p>We were running into another issue related to cache item immutability.</p><p>When we did make a change that led to a cache item, our faster-running artifacts workflow was sneaking in and saving a cache item based on what it was doing.\nWhen the CI workflow finished it saw the cache key it wanted to save already existed and carried on.</p><p>The artifacts workflow for the most part runs .\nOur CI workflow runs something like <code>go test -race -count 1 ./...</code>.</p><p>That meant our cache was missing build output that could help build our tests, especially for the <a href=\"https://go.dev/doc/articles/race_detector\" target=\"_blank\">race detector</a> enabled by .\nThat explained the delay before our first few fast-testing packages produced any output.</p><p>The cache was also missing all the modules needed by everything CI does which explained every CI run starting with some download output.</p><p>Now that the issues were understood they could be fixed!</p><p>I wanted a new setup that would:</p><ul><li>Cache build output in a way that kept things fresh</li><li>Not let the cache grow too big</li><li>Ensure the more involved CI workflow saved cache items, not the artifacts workflow</li><li>Only save to the cache when running CI on the  branch</li><li>Let CI and artifacts runs on any branch use the cache</li></ul><p>Let‚Äôs start with cache saving.</p><p>Near the end of the CI workflow, we now have this:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>The  step gives us a  environment variable with the current date.\nThe  step saves a cache item to a key based on OS, the hash of , and .</p><p>That means whenever a cache item is saved it‚Äôll end with the  value, such as .\nBecause cache items are immutable, if a cache item already exists with the same , saving will be skipped.</p><p>If an existing cache was used for this run, before saving, the  step trims build output that was not created or used by the CI run that is completing.\nThere is <a href=\"https://go.dev/issue/69879\" target=\"_blank\">a proposal</a> around making the go command‚Äôs cache trimming configurable but this seems good enough for our purposes.</p><p>Finally, to ensure all needed modules end up in any saved cache items, we have this near the top of the CI workflow:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p><a href=\"https://go.dev/ref/mod#go-mod-download\" target=\"_blank\"></a> will pre-fill the module cache with everything the main module needs.\nIf everything is already present, it does nothing (and is fast).</p><p>Since only the CI action saves the cache that means the artifacts workflow can‚Äôt leave us with an ineffective cache item anymore.</p><p>All this leaves us with a cache that is:</p><ul><li>Pre-filled with all modules the main module needs</li><li>Updated every day or so with the use of </li><li>Trimmed before saving to only contain relevant build output, keeping size down</li><li>Only saved by CI runs on </li></ul><p>Now, restoring the cache.</p><p>Near the top of both the CI and artifacts workflows, we have:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><p>The trick here is that using  means restoring will always fall back to using <a href=\"https://github.com/actions/cache#inputs\" target=\"_blank\"></a>.\nThe  prefix contains everything before the  value that is used to save.</p><p>This means all both the CI and artifacts workflows, on any branch, can load a cache item that was saved by a recent CI run on .</p><p>For example, if the last CI run on  saved , any subsequent CI or artifacts run will use that item.</p><p>All this leaves us with a cache restore setup that:</p><ul><li>Both the CI and artifacts workflows, on any branch, can use</li><li>Prefers fresh cache entries saved by CI on </li></ul><h2>Conclusion and possible improvements</h2><p>All this together has helped our Go caching greatly.</p><p>Your results may vary, of course, but rolling these changes out cut about a minute and a half off our CI run time.\nAnd it was nice to see those initial fast tests report something almost instantly.</p><p>Perhaps this should be integrated into the setup-go action somehow.</p><p>Either way a possible improvement over  could be to judge cache churn by how many build output files are created/touched during a CI run.\nIf many are created and few are touched, it probably indicates a new cache item is warranted.</p>","contentLength":5471,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1ish19c/better_github_actions_caching_for_go/"},{"title":"Building a Goroutine Pool in Go","url":"https://dev.to/leapcell/building-a-goroutine-pool-in-go-38bk","date":1739894867,"author":"Leapcell","guid":4280,"unread":true,"content":"<p>Previously, it was mentioned that when the native HTTP server in Go handles client connections, it spawns a goroutine for each connection, which is a rather brute - force approach. To gain a deeper understanding, let's take a look at the Go source code. First, define the simplest HTTP server as follows:</p><div><pre><code></code></pre></div><p>Follow the entry point  function.</p><div><pre><code></code></pre></div><p>First,  is responsible for listening on the network port.  then retrieves the TCP connection from the network port, and  spawns a goroutine for each TCP connection to handle it. I also mentioned that the fasthttp network framework has better performance than the native  framework, and one of the reasons is the use of a goroutine pool. So, the question is, if we were to implement a goroutine pool ourselves, how would we do it? Let's start with the simplest implementation.</p><p>In Go, goroutines are launched using the  keyword. Goroutine resources are different from temporary object pools; they cannot be put back and retrieved again. So, goroutines should be running continuously. They run when needed and block when not needed, which has little impact on the scheduling of other goroutines. And the tasks of goroutines can be passed through channels. Here comes a simple weak version:</p><div><pre><code></code></pre></div><p>The above code also calculates the running time of the program. For comparison, here is a version without using a pool:</p><div><pre><code></code></pre></div><p>Finally, comparing the running times, the code using the goroutine pool runs in about 2/3 of the time of the code without using a pool. Of course, this test is still a bit rough. Next, we use the Go benchmark testing method introduced in the reflect article to test. The test code is as follows (many irrelevant codes are removed):</p><div><pre><code></code></pre></div><p>The final test results are as follows. The code using the goroutine pool indeed has a shorter execution time.</p><div><pre><code>$ go test -bench='.' gopool_test.go\nBenchmarkGopool-8            500       2696750 ns/op\nBenchmarkNopool-8            500       3204035 ns/op\nPASS\n</code></pre></div><p>For a good thread pool, we often have more requirements. One of the most urgent needs is to be able to customize the function that the goroutine runs. A function is nothing more than a function address and function parameters. What if the functions to be passed in have different forms (different parameters or return values)? A relatively simple method is to introduce reflection.</p><div><pre><code></code></pre></div><p>However, introducing reflection also brings performance issues. The goroutine pool was originally designed to solve performance problems, but now a new performance issue has been introduced. So, what should we do? Closures.</p><div><pre><code></code></pre></div><p>It is worth noting that in Go, closures can easily lead to problems if not used properly. A key point in understanding closures is the reference to an object rather than a copy. This is just a simplified version of the goroutine pool implementation. When actually implementing it, many details need to be considered, such as setting up a stop channel to stop the pool. But the core of the goroutine pool lies here.</p><p>So, is there a relationship between the number of goroutines in the goroutine pool and the number of CPU cores? This actually needs to be discussed in different cases.</p><h2>\n  \n  \n  1. Goroutine pool is not fully utilized\n</h2><p>This means that as soon as there is data in the , it will be taken away by the goroutine. In this case, of course, as long as the CPU can schedule it, that is, the number of goroutines in the pool and the number of CPU cores are optimal. Tests have confirmed this.</p><h2>\n  \n  \n  2. Data in  is blocked\n</h2><p>This means that there are not enough goroutines. If the running tasks of goroutines are not CPU - intensive (most cases are not) and are only blocked by I/O, then generally, the more goroutines within a certain range, the better. Of course, the specific range needs to be analyzed according to the specific situation.</p><p>Finally, I would like to recommend a platform  that is most suitable for deploying Golang services.</p><h2>\n  \n  \n  1. Multi - Language Support\n</h2><ul><li>Develop with JavaScript, Python, Go, or Rust.\n</li></ul><h2>\n  \n  \n  2. Deploy unlimited projects for free\n</h2><ul><li>Pay only for usage ‚Äî no requests, no charges.</li></ul><h2>\n  \n  \n  3. Unbeatable Cost Efficiency\n</h2><ul><li>Pay - as - you - go with no idle charges.\n</li><li>Example: $25 supports 6.94M requests at a 60ms average response time.\n</li></ul><h2>\n  \n  \n  4. Streamlined Developer Experience\n</h2><ul><li>Intuitive UI for effortless setup.\n</li><li>Fully automated CI/CD pipelines and GitOps integration.\n</li><li>Real - time metrics and logging for actionable insights.\n</li></ul><h2>\n  \n  \n  5. Effortless Scalability and High Performance\n</h2><ul><li>Auto - scaling to handle high concurrency with ease.\n</li><li>Zero operational overhead ‚Äî just focus on building.\n</li></ul>","contentLength":4558,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Websocket and Informer Implementation in Golang(Custom K8s Controller)","url":"https://dev.to/rahulxf/websocket-and-informer-implementation-in-golang-1hk","date":1739885745,"author":"Rahul Vishwakarma","guid":4191,"unread":true,"content":"<h2>\n  \n  \n  The Architecture of Controllers\n</h2><p>Since controllers are in charge of meeting the desired state of the resources in Kubernetes, they somehow need to be informed about the changes on the resources and perform certain operations if needed. For this, controllers follow a special architecture to</p><ul><li>inform any events (updating, deleting, adding) done on the resources,</li><li>keep a local cache to decrease the load on API Server,</li><li>keep a work queue to pick up events,</li><li>run workers to perform reconciliation on resources picked up from work queue.</li></ul><p>Informer monitors the changes of target resource. An informer is created for each of the target resources if you need to handle multiple resources (e.g. podInformer, deploymentInformer).</p><div><pre><code>1) Initialize the Controller\n The NewController function sets up the Kubernetes controller with a work queue, informer, and WebSocket connection.\n It listens for Deployment events (Add, Update, Delete) and enqueues them.\n\n2) Run the Controller\n The Run method waits for cache synchronization and starts the worker loop.\n It continuously processes events from the work queue.\n\n3) Process Deployment Events\n The processItem method retrieves Deployment events from the queue and determines the necessary action.\n It fetches the Deployment details and handles errors, deletions, and updates.\n\n4) Handle Deployment Changes\n, , and  respond to Deployment changes.\n Updates track Replica count and Image changes and send logs via WebSocket.\n\n5) Send Updates via WebSocket\n The updateLogs function logs and sends JSON messages about Deployment changes.\n The WebSocket connection ensures real-time updates for external systems.\n\n</code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code>Reference \n- https://github.com/kubernetes/community/blob/8cafef897a22026d42f5e5bb3f104febe7e29830/contributors/devel/controllers.md\n- Imp https://github.com/kubernetes/sample-controller/blob/master/controller.go#L110-L114 \n- Imp https://medium.com/speechmatics/how-to-write-kubernetes-custom-controllers-in-go-8014c4a04235\n- Youtube https://www.infracloud.io/kubernetes-school/writing-custom-k8s-controller/writing-a-kubernetes-custom-controller/\n- https://chishengliu.com/posts/kubernetes-operator-sample-controller/\n- https://www.nakamasato.com/kubernetes-training/kubernetes-operator/client-go/informer/#implementation-sharedinformerfactory\n- https://buraksekili.github.io/articles/controller-runtime-1/\n\n</code></pre></div>","contentLength":2349,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Nil channels in Go","url":"https://vishnubharathi.codes/blog/nil-channels-in-go/","date":1739885221,"author":"/u/scriptnull","guid":5667,"unread":true,"content":"<p>A friend from work messaged me today that they had a hard time because they had used  instead of  in their Go code.</p><p>I responded by saying that I usually have one rule of thumb i.e. to always use of  whenever I need a channel or map. That way I can be very sure that I can use those immediately.</p><p>They added that the surprising thing was it didn‚Äôt panic the program rather they ended up with an infinite loop that ran silently. I got more intrigued about the situation. So many questions started popping up in my mind. Why was I not able to catch it in the code review? Why was there no linter rule that could catch this? What is the point of having a nil channel in Go if I am brainwashing myself to always use ?</p><p>I went on to get some answers and here they are!</p><p>It is just a channel assigned to nil value.</p><p>When you try to send to a nil channel. </p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><h2>Receive from a nil channel</h2><p>When you try to receive a value from a nil channel</p><p>You again get a deadlock.</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>Now let us try doing both from a nil channel.</p><figure><table><tbody><tr><td><pre></pre></td><td><pre></pre></td></tr></tbody></table></figure><p>This ended up with deadlock too.</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>But my friend mentioned they ran into an infinite loop and not a deadlock. How so?</p><p>My immediate suspicion was a  construct instead of  construct in the above program.</p><figure><table><tbody><tr><td><pre></pre></td><td><pre></pre></td></tr></tbody></table></figure><p>Now that leads to an infinite loop without printing anything! Because  seems to not execute the  block when  is a nil channel. What can it do after all? It can‚Äôt really receive anything from an un-initialized nil channel, right? So it ignores the  block and always runs the  block again and again.</p><p>Now let us initialize the channel by using  instead of  to see how our dear friend  behaves.</p><figure><table><tbody><tr><td><pre></pre></td><td><pre></pre></td></tr></tbody></table></figure><p>It was again an infinite loop, but this time the output was different. </p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>The zeros took over the output. I had to pipe the output to  to stop the program from running infinitely and at the same time collect some sample output.</p><p>What are these zeros? Where are they coming from?</p><p>Those are arising from the  block of the select. When the channel is not nil, our select statement attempts to receive a value. That results in printing , the three values that were sent to the channel. When we close a channel, all we get is the zero value. Hence we are getting zeros after that.</p><p>Is there a way to check if a channel is closed? yes, there is.</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>We avoided printing zeros, but it is still leading to an infinite loop. Because the select is alternating between  and  blocks and continuously executes them.</p><p>Let us get rid of .</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>That didn‚Äôt prevent the infinite loop, our friend  is going on and on choose the  block and performing the if condition that evaluates to false always as the channel is closed after sending 3.</p><p>How do we avoid the infinite loop? Remember how the select statement ignored the  block when my friend accidentally used the nil channel instead of an initialized channel at the start of this post? That is exactly what we need to  the case in the  statement.</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>Now we are out of an infinite loop but are hitting a deadlock after the channel is closed.</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>Because after we  the case, the  statement essentially reduces to an empty  clause.</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>Makes the go routine sleep forever, there is no case statement that it can listen to for receiving a message.</p><p>The core lesson however is</p><blockquote><p>nil channels are useful for disabling  blocks of </p></blockquote><p>I kind of arrived at this lesson in a weird way, but <a target=\"_blank\" rel=\"noopener\" href=\"https://www.youtube.com/watch?v=t9bEg2A4jsw\">this just for func episode</a> teaches it in a beautiful way. (Thanks Campoy if you are reading this!)</p><p>This is particularly useful when you are dealing with multiple channels in different cases of a  and if you want to diable the case blocks one by one when those channels are no longer needed. Going to copy-paste the example from that justforfunc episode to capture the idea.</p><p>The problem is to merge values coming from two channels and output them in another channel.</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>Now the  routine could listen on both the channels and disable the case for a channel after it is closed to make sure that we don‚Äôt spend any more CPU time on that case.</p><figure><table><tbody><tr><td><pre></pre></td><td><pre></pre></td></tr></tbody></table></figure><p>Let me solve the rest of the problem just for closure.</p><p>One way would be to break to an  label as shown below. That way, </p><figure><table><tbody><tr><td><pre></pre></td><td><pre></pre></td></tr></tbody></table></figure><p>NOTE: this would work without the  statement also.</p><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>If the above is same as the previous solution, what is the point? We noticed that setting a channel to  is beneficial when we have multiple cases. In here, I could maybe use that as a check for the .</p><figure><table><tbody><tr><td><pre></pre></td><td><pre></pre></td></tr></tbody></table></figure><p>I should probably start brainwasing myself to make sure I set the channel to  after consuming it completely. That way I can avoid the weird break label syntax and disable select cases to get more throughput.</p><p>Anyhow I know of a simpler solution. So my recommended solution for my friend would be to</p><ul><li>initialize the channel with </li><li>use a  construct instead of  construct.</li></ul><figure><table><tbody><tr><td><pre></pre></td></tr></tbody></table></figure><p>The example that I gave was a very ‚Äútrimmed down‚Äù version of what my friend was trying to accomplish in a real-world system. He was trying to consume a channel and split the messages into two other channels. The miss was failing to  the channels where the split was occurring.</p><p>On the other end, we learned from the justforfunc example that, when we try to merge two channels into one, we could start setting the consumed channel(s) to nil.</p><p>This is provoking me to make up <a target=\"_blank\" rel=\"noopener\" href=\"https://go-proverbs.github.io/\">a Go proverb</a> of my own üòÖ Please excuse me if it sounds bad! You have come so far. So you can‚Äôt escape from it now - lol :D</p><p>‚ÄúInit when you split, Nil when you merge.‚Äù</p>","contentLength":5257,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1iscmld/nil_channels_in_go/"},{"title":"How Gost-DOM avoids making HTTP calls","url":"https://dev.to/stroiman/how-gost-dom-avoids-making-http-calls-4dka","date":1739883190,"author":"Peter Str√∏iman","guid":4153,"unread":true,"content":"<p>This article is about the implementation of <a href=\"https://github.com/gost-dom/browser\" rel=\"noopener noreferrer\">Gost-DOM</a>, the headless browser written in <a href=\"https://go.dev/\" rel=\"noopener noreferrer\">Go</a>.</p><p>Web applications written in Go are very easy to test. An web application serves HTTP requests from a single function, . Test code can just call this function to test the web application behaviour, but still express the test in terms of http requests, responses, headers, body, and status codes; rather than .</p><p>I wanted Gost-DOM to take advantage of this for two reasons:</p><ol><li>Performance - The test is just calling Go code, avoiding the overhead of a TCP stack</li><li>Isolation - By eliminating the need to manage TCP ports, it becomes much easier to run tests in isolation.</li></ol><p>Part 2 is really the most important part here. Although there is nothing preventing tests from running in isolation; the management of TCP ports increases complexity of the test setup.</p><p>I wanted to build this in a way that makes the core of the browser unaware of how HTTP requests are handled. Fortunately, Go's excellent standard library has the right tools out of the box.</p><p>Outgoing HTTP requests are handled by an <a href=\"https://pkg.go.dev/net/http#Client\" rel=\"noopener noreferrer\"></a> instance; which abstracts the transport layer through the <a href=\"https://dev.to/stroiman/how-gost-dom-avoids-making-http-calls-4dka\"></a> interface.</p><div><pre><code></code></pre></div><p>A great feature of Go is that many essential operations are abstracted by single-method interfaces. The  has just one method:</p><div><pre><code></code></pre></div><p>This means, I just need to create a type implementing the  interface, that calls .</p><h2>\n  \n  \n  Implementing the interface\n</h2><p>The http handler function receives an . This is not a concrete type, but an interface. </p><p>In addition to promoting a testable design of your production code, Go also supports great test tools in the <a href=\"https://pkg.go.dev/net/http/httptest\" rel=\"noopener noreferrer\"> package</a>. The <a href=\"https://pkg.go.dev/net/http/httptest#ResponseRecorder\" rel=\"noopener noreferrer\"></a> is a valid  that test code can pass to the implementation, and simplifies dealing with response body streams.</p><p>But the  is also so kind to actually generate a proper , that can be retrieved by calling, <code>ResponseRecorder.Result()</code>.</p><p>The type representing the request is the same in the  and the , so I made a copy, to avoid mutation in the tested server code affects the request object generated in the browser. The first version of the  looked like this:</p><div><pre><code></code></pre></div><p>This worked fine in the beginning, but had some issues.</p><h3>\n  \n  \n  A slightly odd design decision\n</h3><p>In the midst of the very well designed API is what I find to be a somewhat odd design decision. </p><p>The  passed to the , and the  passed to your http  is the same type, but they are really . The one is an  request, and the other is an  request.</p><p>While they share are similarities, they are not the entirely the same, and the type has properties that are only relevant for processing incoming requests, such as decoding form data. And there have different  determining if a request is valid. </p><p>First, the outgoing request is allowed to have a  request body, where the incoming request always have a body. </p><p>Then, the incoming request is a source of a <a href=\"https://pkg.go.dev/context\" rel=\"noopener noreferrer\"></a>, which I didn't initialise either.</p><p>Fixing the request was easy:</p><div><pre><code></code></pre></div><p>And now, the browser itself will create HTTP requests using an instance of the  provided. Test code can control the client, replacing default HTTP request behaviour with one that calls your HTTP handler, and an outgoing request from the browser is now just a simple function call.</p><p>Go also provides a cookie jar. So adding cookie support was so simple that giving it a headling was completely overkill.</p><p>The function that constructs an  communicating with a simple handler is as simple as:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Testing identity provider integration\n</h2><p>While this is not a feature yet, it is intended to extend this functionality to support multiple HTTP handlers, simulating different host names.</p><p>This could be valuable in testing an OAuth authentication flow, or sign in using external identity providers. You could create a test HTTP handler simulating the behaviour of an identity provider, and test the flow independently of the external provider.</p><p>In my previous experience, this is often accomplished with a  identity provider, configured with some test users. But this approach has some drawbacks:</p><ul><li>The tests may fail due to a temporary outage of an external service (in the worst case, preventing deployeing a critical)</li><li>Tests may fail due to account lockout.</li><li>Using \"real test users\" makes test code depend on an external context, i.e., there are factors affecting the outcome of the test that is not specified in the test.</li><li>Developers may not have privileges to administer test users, preventing them from writing the right test, waiting for an administrator to add new users.</li></ul><p>By mocking an IDP, you gain full control of test environment flow. Then you'd need to setup the round tripper to support two hostnames:</p><ul><li> Calls your application http handler</li><li> Calls your mock identity provider web app.</li></ul><p>And you'd still be able to run everything in parallel.</p><p>Intrigued? Check out <a href=\"https://github.com/gost-dom/browser\" rel=\"noopener noreferrer\">Gost-DOM</a>. And stay tuned for more nitty-gritty details about how I build a headless browser in Go.</p><p>And please, spread the word. üôè</p><ol><li><p>I want to emphasise that this tool is meant to support the majority of tests written to support a TDD flow. That doesn't mean there shouldn't be added more tests after the fact to find critical integration issues, and I certainly recommend having ONE automated tests exercise the login flow if your application integrates with an external identity provider. But I don't want that to be part of the normal development flow.&nbsp;‚Ü©</p></li></ol>","contentLength":5233,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Gost-DOM is implemented","url":"https://dev.to/stroiman/how-gost-dom-is-implemented-48o9","date":1739883151,"author":"Peter Str√∏iman","guid":4152,"unread":true,"content":"<p><a href=\"https://github.com/gost-dom/browser\" rel=\"noopener noreferrer\">Gost-DOM</a> is headless browser written in Go. It is written with the purpose of supporting a TDD feedback loop while building web applications in Go.</p><p>This article is a short introduction to the the series about the technical solutions. Future articles will go more into details of specific solutions.</p><p>It started as an experiment, but as I progressed I strongly felt that this could become an extremely valuable tool for web development in Go.</p><p>On February 6th, I released version 0.1, signifying that the project had reached a level that it could fulfil minimal use cases. But as the versioning scheme indicates:</p><ul><li>This is a very early prototype</li><li>The API may not be stable. I believe I have found a reasonably good structure, but I am still learning.</li></ul><p>In general, the browser now supports minimal HTMX apps, e.g., clicking elements with HTMX handlers, including boosted links, that update history, form submission using HTMX with content swapping.</p><p>Gost was specifically written with HTMX in mind, and it features a <a href=\"https://v8.dev/\" rel=\"noopener noreferrer\">V8</a> engine for JavaScript support. Work is in progress to also support <a href=\"https://github.com/dop251/goja\" rel=\"noopener noreferrer\">Goja</a>, a pure Go JavaScript engine. Gost has a cookie support, and Gost can bypass the TCP stack for extremely fast test execution. It supports full isolation of test cases with no fuzz, and parallel tests as a result (depending only on  code). The goal is \"ludicrous speed\" for web application TDD feedback loop.</p><p>In future articles, I will dive in to specific aspects and solution I have applied during the implementation of Gost-DOM.</p><p>But I invite you to try out <a href=\"https://github.com/gost-dom/browser\" rel=\"noopener noreferrer\">Gost-DOM</a>, and spread the word.</p>","contentLength":1562,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Map internals in Go 1.24","url":"https://themsaid.com/map-internals-go-1-24","date":1739870475,"author":"/u/themsaid","guid":4239,"unread":true,"content":"<p>Maps in Go 1.24 have undergone a complete rewrite, significantly improving their performance. The new implementation draws inspiration from Google's high-performance hash map design known as <a href=\"https://abseil.io/about/design/swisstables#swiss-tables-design-notes\" rel=\"nofollow\">Swiss Tables</a>.</p><p>Under the new implementation, a Map is a collection of groups of 8 key/value pairs. Each  contains 8 slots of data in addition to a metadata field that holds a . The control word is 64 bits in size, each byte representing one of the slots.</p><div><pre>+---------------------+\n|  Control  (b) |  &lt;-  ( byte per slot)\n+---------------------+\n|  Key   |  Value   |  \n|  Key   |  Value   |  \n|  Key   |  Value   |  \n|  Key   |  Value   |  \n|  Key   |  Value   |  \n|  Key   |  Value   |  \n|  Key   |  Value   |  \n|  Key   |  Value   |  \n+---------------------+</pre></div><p>These groups are distributed across multiple tables, with each  containing a number of groups that is always a power of two. A power of two is a number that can be written as (2^n), such as 1, 2, 4, 8, etc...</p><div><pre>+---------------------+\n|       Table        |  \n+---------------------+\n+---------------------+\n|  Control  (b) |  &lt;- Group \n+---------------------+\n|  Key   |  Value   |   \n.\n|  Key   |  Value   |  \n+---------------------+\n+---------------------+\n|  Control  (b) |  &lt;- Group \n+---------------------+\n|  Key   |  Value   |  \n.\n|  Key   |  Value   |  \n+---------------------+</pre></div><p>The map holds a pointer to the array of tables it manages and replaces the array with another when the number of tables change.</p><p>When you lookup or insert/update a key. A hashing function is used to generate a 64 bit hash code. This code is then divided into two parts:</p><ol><li>The first 57 bits: referred to as .</li><li>The last 7 bits: referred to as .</li></ol><p>The full hash code is used to determine which table stores a given key in a multi-table map. Within each table, the h1 portion of the code identifies the potential groups that may contain the key. Once a group is selected, the h2 portion is utilized in the control word to enable fast key lookups within that group.</p><p>The hash code of a key is used to determine which table the key belongs to. This selection process is done by using a portion of the hash code, specifically a number of bits, based on how many tables are available. For example, if there's only a single table, the hash code is not considered and all keys go straight to the table. If there are two tables, the first bit in the code is used to determine which table the key belongs to:</p><div><pre>Hash:     : \nFirst bit : \nTable     : </pre></div><div><pre>Hash:     : \nFirst bit : \nTable     : </pre></div><p>Now let's say there are 4 tables. In that case, two bits are used:</p><div><pre>Hash:        : \nFirst  bits : \nTable        : </pre></div><div><pre>Hash:        : \nFirst  bits : \nTable        : </pre></div><div><pre>Hash:        : \nFirst  bits : \nTable        : </pre></div><p>Using the first 57 bits of the hash (), an internal function calculates the index of the group where a key should be stored. If that group is full (i.e., all 8 slots are occupied), quadratic probing is used to find the next group to check. Instead of simply checking the groups one after another (as in linear probing), quadratic probing uses a mathematical formula to determine the next group, with the step size increasing as the number of groups grows. This ensures that keys are distributed across as many groups as possible, reducing congestion and leading to faster lookups.</p><p>If linear probing were used instead, the runtime would just check the next group in line each time it encounters a full group. For example:</p><div><pre> group  =&gt; (full).\n group  =&gt; (also full).\n group  =&gt; (available slot).</pre></div><p>This could cause congestion in the groups at the beginning of the table, and lookups would become slower because the runtime would have to check more and more groups to find the desired key.</p><p>In contrast, with quadratic probing, the steps spread out across the table, reducing congestion and making lookups faster. Even when groups are full, the formula guarantees the next probe is further away in a way that distributes keys more evenly.</p><p>As mentioned earlier, the control word is 64 bits in size and each byte represents one of the slots. The last 7 bits of the hash () are used to fill the last 7 bits of the byte representing the slot. The one extra bit is used to flag the slot as empty, deleted, or occupied.</p><div><pre>Empty   : \nDeleted : \nOccupied: ******* (where * is a bit of h2)</pre></div><p>When looking up a key in a group, the control word is scanned to find potential slots in which the control byte matches h2 of the key. Once a slot is located, the runtime compares the input key with the key occupying the slot. If there's a match, the value is returned. If not, the next possible slot is checked.</p><p>In this example, occupied slots where the h2 value matches  appear twice in the control word. This means there are two slots where the key could potentially be stored:</p><div><pre>[][]</pre></div><p>When updating a key, the control word is first used to find if the key already exists in the group. If it doesn't exist in the group, or any other group in the probe sequence, the first available slot is used to insert the new key.</p><p>The process for looking up a key in a map follows these steps:</p><ol><li>Use the hash to determine the table.</li><li>Create a probe sequence for potential groups that may house the key (using h1).</li><li>Go over the groups one by one.</li><li>Scan the group's control word to find possible slots that match h2.</li><li>Check the key stored in each matching slot to verify it matches the input key.</li></ol><p>While traversing the groups, the search will stop immediately if the runtime encounters a group with an empty slot. This optimization improves the lookup process by allowing the search to return early, rather than continuing to probe all the groups in the sequence unnecessarily.</p><p>For this to work effectively, it is important that a slot which previously held a deleted key is not marked as empty. Instead, it is marked as \"deleted.\" This ensures that the search process can differentiate between truly empty slots and those that were once occupied but now deleted, allowing the lookup to behave correctly without mistakenly stopping prematurely.</p><p>The optimizations in this process stem from the following factors:</p><ol><li>The runtime only needs to scan a single table in a large map.</li><li>It only checks a subset of groups within that table.</li><li>It uses the control word first to verify the key's existence, rather than iterating through each key-value pair individually.</li><li>It returns early if an empty slot is found.</li></ol><p>When inserting a value into a map , the runtime first attempts to find a slot that is occupied by the same key, using the same probing sequence as in key lookups.</p><p>If the runtime encounters a group that contains an empty slot during the search, it concludes that the key does not exist in the map. The empty slot is then used to store the new key-value pair.</p><p>If no empty slots are found, the runtime proceeds to look for the first slot that is marked as \"deleted.\" This slot is available for reuse, and the new key-value pair is inserted into this deleted slot, ensuring that the table's capacity is efficiently used.</p><p>When deleting a key from a map, the runtime searches for the key using the same probing sequence as in key lookups. For each group, the runtime checks for the key using the control word and then inspects the actual key stored in each matching slot.</p><p>If the key was found, the runtime checks if there are empty slots in the group. If yes, the key is marked as empty. Otherwise, it's marked as deleted to avoid interrupting lookups prematurely as explained in a previous section.</p><p>If the key wasn't found in a group while the group had empty slots. The search stops as this means the key doesn't exist in the map.</p><p>When you make a small map, size &lt;= 8, the runtime creates a map with no tables and a single group. Inside that single group, all slots are either empty or occupied (no slots are marked as \"deleted\"). This is because a small map doesn't use the probing sequence for lookups, it simply iterates over the 8 slots of the single group until it finds a match.</p><p>As the map grows in size, or if you make a large map, the tables concept is introduced to speed up lookups by distributing the keys on multiple groups.</p><p>When a table is first created, it is allocated a capacity that allows it to hold between 16 and 1024 slots (equivalent to 2 to 128 groups). As the number of occupied slots approaches ~87% of the table capacity, the table undergoes a growth operation in which the runtime multiplies the current capacity by 2. If the new value is 1024 slots or less, the table is simply replaced with a new one that has double the old capacity. However, if expanding the table would push its capacity beyond 1024 slots, the table is instead split into two separate tables to manage the growing data efficiently.</p><p>When a table is split into two, the tables array in the map data structure is replaced with a larger array, whose size is always a power of two (1, 2, 4, 8, ‚Ä¶). For example, imagine a scenario where a map initially has two tables (Table 0 and Table 1). If Table 0 needs to be split, the total number of tables increases to three. However, to maintain a power-of-two-sized array, the tables array grows to size 4 and multiple entries in the new array can point to the same table:</p><div><pre> ()\n ()\n</pre></div><p>Using the key hash, what used to map to table 0 before the split, may now map to table  or . And what used to map to table 1 before the growth, will keep pointing to table 1 (represented by index 2 and 3 in the array.):</p><pre lang=\"math\"><code>Before Growth:\n\nSelection bit = 0  --&gt;  [index 0] --&gt;  Table 0\nSelection bit = 1  --&gt;  [index 1] --&gt;  Table 1\n</code></pre><pre lang=\"math\"><code>After Growth:\n\nSelection bits = 00  --&gt;  [index 0]  --&gt;  Table 0a\nSelection bits = 01  --&gt;  [index 1]  --&gt;  Table 0b\nSelection bits = 10  --&gt;  [index 2]  --&gt;  Table 1\nSelection bits = 11  --&gt;  [index 3]  --&gt;  Table 1\n</code></pre><p>This techniques avoids rehashing the entire map and allows for individual tables to grow separately.</p><p>Reading the source code of Go 1.24's map implementation was a fascinating experience. One of the things I truly admire about Go is that its core functionality is implemented in the language itself. This makes it possible to dive deep into the internals, understand exactly how things work behind the scenes, and learn from the incredibly talented contributors who have shaped the language.</p><p>If you're curious and want to explore the source code yourself, you can start <a href=\"https://github.com/golang/go/blob/master/src/internal/runtime/maps/map.go\">here</a>.</p>","contentLength":10240,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/golang/comments/1is8rwa/map_internals_in_go_124/"},{"title":"Monitor Kubernetes API Versions","url":"https://dev.to/binyam/monitor-kubernetes-api-versions-1d40","date":1739860312,"author":"binyam","guid":3979,"unread":true,"content":"<p>üöÄ Building a Simple Kubernetes API Monitor in Go</p><p>Kubernetes moves fast, and deprecated APIs can break your workloads without warning. What if you had a lightweight tool that keeps track of these changes?</p><p>In this post, I‚Äôll walk you through building a Kubernetes API monitoring tool using Go, exposing metrics via Prometheus, and packaging it with a Helm chart.</p><p>üõ†Ô∏è What This Tool Does\n    ‚Ä¢ Scans for deprecated/removed Kubernetes APIs in a cluster<p>\n    ‚Ä¢ Exposes findings via a Prometheus metrics endpoint</p>\n    ‚Ä¢ Ships with a Helm chart for easy deployment<p>\n    ‚Ä¢ Includes Prometheus alert rules to notify you of risky APIs</p></p><p>While tools like kubectl deprecations exist, they often require manual execution. A Kubernetes-native monitoring solution ensures continuous tracking and alerting, integrating directly with Prometheus.</p><p>üìú Getting Started\n    1.  Write a Go script using client-go to list API versions.<p>\n    2.  Compare them with Kubernetes‚Äô deprecation policy.</p>\n    3.  Serve findings as Prometheus metrics (/metrics endpoint).<p>\n    4.  Package the tool with a Helm chart (Deployment + ServiceMonitor).</p></p><p>üí° Next Steps\n    ‚Ä¢ Add a Grafana dashboard for visual insights<p>\n    ‚Ä¢ Extend functionality to check for feature gates</p>\n    ‚Ä¢ Implement a webhook notifier for Slack &amp; Teams</p><p>This is just a sneak peek‚ÄîI‚Äôll be sharing the full codebase and Helm chart in a follow-up post. Stay tuned!</p><p>üöÄ What‚Äôs your favorite way to track Kubernetes API changes? Drop your thoughts below!</p><p>Would you like me to tweak the tone or add anything before you publish? üöÄ</p>","contentLength":1575,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Every time I build my Golang project, I get Microsoft Defender warnings","url":"https://www.reddit.com/r/golang/comments/1is61jy/every_time_i_build_my_golang_project_i_get/","date":1739858974,"author":"/u/freewheel1466","guid":4307,"unread":true,"content":"<p>Every time I build my Golang project, I get this message:</p><p><code>bash Threats found Microsoft Defender Antivirus found threats. Get details. </code></p><p>This wouldn't have been a problem if my binary was meant to run on a server. However, I'm building a desktop application which will run on customers' end devices (Windows 10/11 PCs).</p><p>If the binaries I build get flagged by Windows Defender, I don't see how I could get people to run it.</p>","contentLength":417,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is this book still applicable ?","url":"https://www.reddit.com/r/golang/comments/1is2dlm/is_this_book_still_applicable/","date":1739846680,"author":"/u/United-Nebula3793","guid":4118,"unread":true,"content":"   submitted by   <a href=\"https://www.reddit.com/user/United-Nebula3793\"> /u/United-Nebula3793 </a>","contentLength":40,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sync all of your LeetCode solutions to Github using glsync","url":"https://dev.to/ahmedabdulaziz/sync-all-of-your-leetcode-solutions-to-github-using-glsync-2jg","date":1739838024,"author":"Ahmed Ehab Abdul-Aziz","guid":2115,"unread":true,"content":"<p>I developed <a href=\"https://github.com/ahmed-e-abdulaziz/glsync\" rel=\"noopener noreferrer\">glsync</a>, a CLI tool to sync all your LeetCode submissions to Github (and possibly any other Git client). Each solution will be committed based on its submission date on LeetCode.</p><p>You can create a custom repo on GitHub, and glsync will get all of your submissions from LeetCode and push it into this custom repo. It can also work with Gitlab and other Git repos.</p><p>I found a lack of similar tools that sync ALL of your submissions, not one at a time.</p><p>I created it because companies judge interviewees by how frequently they commit to Github. This can make time spent in LeetCode feel invisible to them, as it won't be visible on your GitHub profile.</p><p>I did this in about a week, so if you want more features, support other platforms, or encounter bugs, feel free to send me a message.</p>","contentLength":787,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Can anyone explain to me in simple terms what vCPU means? I have been scratching my head over this.","url":"https://www.reddit.com/r/golang/comments/1irz945/can_anyone_explain_to_me_in_simple_terms_what/","date":1739837593,"author":"/u/gwwsc","guid":4406,"unread":true,"content":"<div><p>If I run a go app on an EC2 server, does it matter if it has 1vCPU or 2vCPU? How should I determine the hardware specifications of the system on which my app should run?</p></div>   submitted by   <a href=\"https://www.reddit.com/user/gwwsc\"> /u/gwwsc </a>","contentLength":197,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Deploy Hugo With Cloudflare Pages","url":"https://dev.to/mlem_dev/how-to-deploy-hugo-with-cloudflare-pages-6h9","date":1739835465,"author":"mlem_dev","guid":2096,"unread":true,"content":"<p>According to wise sages (aka the internet), the best way to learn something is by teaching it to others. So, why not embark on the noble quest of starting a blog today?</p><h3>\n  \n  \n  What's a Static Site Generator?\n</h3><p>In a world of bloated websites and laggy load times, Static Site Generators (SSGs) stand as the knights in shining armor. They create a site all at once and then deliver it in a flash‚Äîno lag, just pure performance.</p><ul><li>: Like a perfectly timed dodge in , static site generators pre-build the entire website and deliver it to the user all at once‚Äîno waiting around for things to load.</li><li>: You‚Äôre no longer chained to the whims of a CMS. With SSGs, you're free to craft whatever template your heart desires</li><li>: These frameworks are lighter than a cat‚Äôs nap, so your website won‚Äôt require a ton of resources.</li><li>: If you love the power of Markdown (like the freedom of the  open world), you‚Äôre in for a treat.</li></ul><ul><li>: Imagine trying to navigate the Lands Between without a map‚Äîyep, that's what working with an SSG feels like at first. You‚Äôll need to read the documentation to figure out how things work, but once you get the hang of it, you will feel right at home.</li><li><strong>Lack of Default Templates</strong>: Out of the box, SSGs don't come with many templates. You'll either need to create your own or  of GitHub to find something to use.</li></ul><p><em>SSGs are powerful tools! If you want to learn more, check out this detailed breakdown from <a href=\"https://www.cloudflare.com/learning/performance/static-site-generator/\" rel=\"noopener noreferrer\">Cloudflare</a>.</em></p><h3>\n  \n  \n  What's Out There in the Land of Static Site Generators?\n</h3><p>The world of Static Site Generators is vast, filled with many frameworks and options.\nHere's the good news: you‚Äôve got plenty of paths to explore. I‚Äôve chosen <a href=\"https://gohugo.io/\" rel=\"noopener noreferrer\">Hugo</a>, which seems to be one of the most popular choices (even  uses it, so that‚Äôs like the  of validation). At work, we've dabbled in a few other options, like WordPress, Google Pages, and Nextra. Each has its strengths, but in the end, it's all about finding the right fit for your .</p><p>One of my personal quests in 2025 is to learn Go, and since Hugo is written in Go, it felt like the perfect opportunity to level up those skills in the real world. Bonus points: it's fully open-source (you know, like that sword you find in the middle of nowhere that no one tells you about).</p><p>Oh, and let's not forget the . I went with the <a href=\"https://github.com/adityatelange/hugo-PaperMod/\" rel=\"noopener noreferrer\">PaperMod</a> theme, which I absolutely love. It‚Äôs simple, clean, and lets my content shine.</p><h3>\n  \n  \n  Setting Up Your Hugo Website with Cloudflare Pages\n</h3><p>Ready to embark on the setup journey? Here‚Äôs your guide to creating your Hugo-powered website using Cloudflare Pages.</p><ol><li>Before diving in, check the theme‚Äôs documentation for any specific requirements. For me, this meant heading over to the <a href=\"https://github.com/adityatelange/hugo-PaperMod/wiki/Installation\" rel=\"noopener noreferrer\">PaperMod GitHub page</a> to make sure I wasn‚Äôt missing anything important.</li><li>Create a GitHub repository and link it to your local files. If you‚Äôre not familiar with Git yet, don't worry‚Äîlearn it now. You‚Äôll need it, trust me. Here‚Äôs a  in the form of a Git course by <a href=\"https://www.youtube.com/watch?v=rH3zE7VlIMs\" rel=\"noopener noreferrer\">thePrimeagen</a>‚Äîgo complete it before you continue. </li><li>Once your repo is all set up, take a moment to look at the  file and make any customizations. This is your chance to tweak the theme to fit your personal aesthetic. </li></ol><ol><li>Select  from the framework preset options. You can stick with the default settings unless your theme docs say otherwise. \n \nSome themes may require a specific Hugo version, higher or lower than what Cloudflare Pages uses. You can manually set the Hugo version with . For PaperMod, I needed version 0.143.1 or higher, so that‚Äôs what I picked.</li></ol><ol><li>Once everything is set up, click .</li></ol><p>And voil√†‚Äîyour website is now live! Every time you push to the master branch, Cloudflare Pages will automatically rebuild your site and serve it under the URL <code>{your_project_name}.pages.dev</code>, or any custom domain you set up.</p><p>If you run into any issues along the way, don‚Äôt panic. Check the build logs for all the clues you need to debug any CI/CD problems. </p><p>Now you‚Äôre ready to explore the vast world of static site generators and embrace your role as a blog creator. May your markdown be clean, your deployments swift, and may you never get stuck in an endless loop of errors (unless it's a fun one) :3</p>","contentLength":4135,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Worker pool with some extras","url":"https://www.reddit.com/r/golang/comments/1irxsfw/worker_pool_with_some_extras/","date":1739833608,"author":"/u/umputun","guid":4446,"unread":true,"content":"<p>Created this package out of necessity after dealing with many concurrent and parallel data processing tasks. While building worker pools manually is perfectly fine for simple cases, some scenarios can get quite tricky to handle correctly.</p><p>This package gives you a clean API with some neat features - you can batch tasks for better performance, keep worker state, route related tasks to the same worker, collect metrics, and handle errors the way you want. It comes with middleware for common needs like retries with backoff, timeouts, panic recovery and validation, plus you can add any custom middleware you need to address any cross-cutting concerns.</p><p>You can even chain multiple pools together to build complex processing pipelines. All type-safe with generics. The pool is fast enough and even outperforms many manual implementations.</p>","contentLength":835,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Minecraft from scratch with only modern openGL","url":"https://www.reddit.com/r/golang/comments/1irwit1/minecraft_from_scratch_with_only_modern_opengl/","date":1739830424,"author":"/u/One_Mess_1093","guid":2083,"unread":true,"content":"<table> <tr><td> <a href=\"https://www.reddit.com/r/golang/comments/1irwit1/minecraft_from_scratch_with_only_modern_opengl/\"> <img src=\"https://external-preview.redd.it/MoadT5xBO4ujN4IJxeK687Yka2borosJ0cF4_zWoSj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=692e4a1041c21b00f7d0c804c056ce4366b2e2d4\" alt=\"Minecraft from scratch with only modern openGL\" title=\"Minecraft from scratch with only modern openGL\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/One_Mess_1093\"> /u/One_Mess_1093 </a> <br/> <span><a href=\"https://github.com/GianlucaP106/minecraft\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1irwit1/minecraft_from_scratch_with_only_modern_opengl/\">[comments]</a></span> </td></tr></table>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Being fluent in Go can give you greater returns in the long-run","url":"https://www.reddit.com/r/golang/comments/1irw2jj/being_fluent_in_go_can_give_you_greater_returns/","date":1739829322,"author":"/u/narenarya","guid":3954,"unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>Here&#39;s what I observed after programming in Go, Python, and JavaScript for quite a bit of time now (&gt; 10 years)</p> <p>Both Python &amp; JavaScript provide better initial returns despite less fluency, whereas Go will be very productive once you feel comfortable.</p> <p>So, if you are already in Go learning path, keep pushing! It will soon pay you back in hefty amounts.</p> <p>I made a chart to show this:</p> <p><a href=\"https://imgur.com/a/i4ZwdcK\">Go learning curve &amp; returns</a></p> <p>I would like to hear your opinions about working with other programming languages &amp; Go in terms of productivity.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/narenarya\"> /u/narenarya </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1irw2jj/being_fluent_in_go_can_give_you_greater_returns/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1irw2jj/being_fluent_in_go_can_give_you_greater_returns/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"go version -m","url":"https://www.reddit.com/r/golang/comments/1irus4i/go_version_m/","date":1739826191,"author":"/u/der_gopher","guid":2036,"unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>Did you know that you can inspect any Go binary and find the Go version it was built with? <code>go version -m &lt;file&gt;</code> does just that, plus shows other helpful build info. Comes very handy when debugging binaries shipped to prod.</p> <p>``` $ go version -m ./ultrafocus</p> <p>ultrafocus: go1.24.0 path github.com/plutov/ultrafocus mod github.com/plutov/ultrafocus v0.3.1 build GOARCH=amd64 build GOOS=darwin build GOAMD64=v1 build vcs=git build vcs.revision=4f9ebaee5de88c9fa3ea27d5327edb5283e624f0 build vcs.time=2024-10-11T11:23:07Z build vcs.modified=false ```</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/der_gopher\"> /u/der_gopher </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1irus4i/go_version_m/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1irus4i/go_version_m/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Don't Waste Time‚ÄîLearn Golang Now!","url":"https://dev.to/holasoymalva/dont-waste-time-learn-golang-now-4f5p","date":1739819481,"author":"Leon Martin","guid":2000,"unread":true,"content":"<p>If you're a developer and you're still not dabbling in Golang, you're missing out. Over the past few years, I've seen the industry shift dramatically‚Äîcompanies are looking for faster, leaner, and more reliable code. While languages like JavaScript, Java, and Python have their merits, Golang (or Go) offers a unique combination of speed, simplicity, and concurrency that can really set you apart.</p><p>I've worked on projects in various languages, and here‚Äôs what I've learned: when performance and simplicity matter, Golang wins hands down.</p><h2>\n  \n  \n  What Makes Golang Special?\n</h2><p>Golang was designed with one goal in mind‚Äîsimplicity. Unlike some languages that try to do everything and end up bloated, Go takes a minimalistic approach. It's statically typed, compiled, and comes with a built-in garbage collector, which means you get performance without the pain of manual memory management.</p><p>One of the standout features of Go is its native support for concurrency. Go routines make it incredibly easy to write concurrent code that scales with modern multi-core processors. This is a game changer compared to, say, JavaScript's event loop or Python's Global Interpreter Lock (GIL), which can sometimes be a bottleneck.</p><p>Here's a simple example of how Go handles concurrency:</p><div><pre><code></code></pre></div><p>In this example, two goroutines run concurrently without the complex callbacks or promises you might see in JavaScript. It's straightforward, and it just works.</p><p>Let's take a look at a basic \"Hello, World!\" program across three languages: Go, Python, and JavaScript.</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>While the \"Hello, World!\" example is trivial, the real difference shows up in how each language handles performance and scalability. Python, with its dynamic nature, can be slower for CPU-bound tasks. JavaScript, though fast in many scenarios, relies on an event loop and often struggles with heavy concurrent processing. Go, on the other hand, is compiled to native code and excels in performance-critical, concurrent applications.</p><h2>\n  \n  \n  Why You Should Jump on the Golang Bandwagon\n</h2><p>The tech landscape is changing fast. In the last few years, we've seen massive shifts‚Äîmass layoffs, startups pivoting, and companies rethinking their entire tech stacks. What does this mean for you? Adaptability. You need a language that's not only powerful but also flexible enough to handle the demands of modern systems.</p><p>Golang is used by giants like Google, Dropbox, and Uber. It‚Äôs becoming the de facto language for cloud services and microservices. If you're looking to future-proof your career, learning Go is a smart move. It's not just about writing code; it's about building systems that can handle millions of requests per second without breaking a sweat.</p><h2>\n  \n  \n  When to Use Golang‚Äîand When Not To\n</h2><p>While Golang is fantastic, it's not a silver bullet. There are cases where other languages might be a better fit:</p><ul><li><strong>Web Frontend Development:</strong> Golang isn't built for browser-based apps. If you're working on a rich client-side experience, JavaScript (or TypeScript) is still your best bet.</li><li> If you need to whip together a quick prototype, Python's simplicity and vast ecosystem might be more convenient.</li><li><strong>Data Science &amp; Machine Learning:</strong> Python dominates this field due to its extensive libraries like TensorFlow, NumPy, and Pandas.</li></ul><p>However, if your focus is on building robust backend services, scalable APIs, or high-performance systems, Golang shines.</p><p>Time is precious, and in a rapidly evolving tech world, you don‚Äôt want to be stuck with outdated tools. Golang offers a blend of simplicity, performance, and modern concurrency that can supercharge your development process. Whether you're building microservices, cloud applications, or high-performance systems, learning Go is a smart investment in your future.</p><p>So, don't waste time‚Äîdive into Golang, experiment with it, and see how it can transform the way you build software. What are your thoughts on Go? Have you tried it yet? Drop a comment below, and let's chat about it!</p>","contentLength":3957,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Today I learned something new about Go's slices","url":"https://www.reddit.com/r/golang/comments/1irpsb0/today_i_learned_something_new_about_gos_slices/","date":1739814408,"author":"/u/andres2142","guid":1995,"unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>Go really cares about performance, cares about not wasting any resources.</p> <p>Given this example:</p> <pre><code>var s []int s = append(s, 0) //[0] len(1) cap(1) s = append(s, 1) //[0 1] len(2) cap(2) s = append(s, 2, 3, 4) //[0 1 2 3 4] len(5) cap(6) </code></pre> <p>The capacity after adding multiple values to <code>s</code> is 6, not 8. This blew my mind because I thought it should&#39;ve doubled the capacity from 4 to 8, but instead, Go knows that 8 should have been a waste and instead sets it as 6, as long as you append multiple values to a slice.</p> <p>This is different if I would&#39;ve done individually like this:</p> <pre><code>var s []int s = append(s, 0) //[0] len(1) cap(1) s = append(s, 1) //[0 1] len(2) cap(2) s = append(s, 2) //[0 1 2] len(3) cap(4) s = append(s, 3) //[0 1 2 3] len(4) cap(4) s = append(s, 4) //[0 1 2 3 4] len(5) cap(8) </code></pre> <p><code>s</code> ends up with a capacity of 8 because it doubled it, like usual</p> <p>I was not aware of this amazing feature.</p> <p>Go is really an amazing language. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/andres2142\"> /u/andres2142 </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1irpsb0/today_i_learned_something_new_about_gos_slices/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1irpsb0/today_i_learned_something_new_about_gos_slices/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Muscle up your Go templates experience","url":"https://www.reddit.com/r/golang/comments/1irnum2/muscle_up_your_go_templates_experience/","date":1739809759,"author":"/u/begoon","guid":2035,"unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://github.com/Masterminds/sprig\">https://github.com/Masterminds/sprig</a></p> <p>This brings go templates experience to another level just with one import.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/begoon\"> /u/begoon </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1irnum2/muscle_up_your_go_templates_experience/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1irnum2/muscle_up_your_go_templates_experience/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Data Processing Pipeline in Go (Golang)","url":"https://dev.to/saleh_rahimzadeh/data-processing-pipeline-in-go-golang-1098","date":1739808307,"author":"Saleh Rahimzadeh","guid":1926,"unread":true,"content":"<p>A  is a series of stages or steps where data is processed sequentially. \nEach stage performs a specific operation on the data, and the output of one stage becomes the input of the next. <p>\nThis pattern is commonly used in scenarios like ETL (Extract, Transform, Load), stream processing, or batch processing.</p></p><p>In Go (Golang), pipelines are often implemented using  and , which are core features of the language for concurrent programming. \nChannels allow you to pass data between stages, and goroutines enable concurrent execution of each stage.</p><h2>\n  \n  \n  Key Concepts of a Data Processing Pipeline in Go\n</h2><ol><li><ul><li>Each stage is a function that takes input data, processes it, and produces output data.</li><li>Stages are connected via channels.</li></ul></li><li><ul><li>Channels are used to pass data between stages.</li><li>They ensure safe communication between goroutines.</li></ul></li><li><ul><li>Each stage can run concurrently as a goroutine.</li><li>This allows for efficient utilization of CPU and I/O resources.</li></ul></li><li><ul><li>: Distributing work across multiple goroutines (parallelism).</li><li>: Combining results from multiple goroutines into a single channel.</li></ul></li></ol><h2>\n  \n  \n  Simple Data Processing Pipeline\n</h2><p>Let‚Äôs build a simple pipeline that:</p><ol><li>Prints the squared numbers.\n</li></ol><div><pre><code></code></pre></div><ol><li><ul><li>Takes a counter integer, range over it and sends them into a channel.</li><li>Runs in a goroutine to avoid blocking the main program.</li></ul></li><li><ul><li>Reads numbers from the input channel, squares them, and sends the result to the output channel.</li><li>Also runs in a goroutine.</li></ul></li><li><ul><li>Reads squared numbers from the input channel and prints them.</li></ul></li><li><ul><li>The  function produces numbers.</li><li>The  function processes them.</li><li>The  function consumes the final output.</li></ul></li></ol><h2>\n  \n  \n  Adding Concurrency with Fan-Out and Fan-In\n</h2><p>To make the pipeline more efficient, you can introduce  (multiple goroutines processing data in parallel) and  (combining results back into a single channel) patterns.</p><p>Example: Fan-Out and Fan-In</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Key Points in the Fan-Out/Fan-In Example\n</h3><ol><li><ul><li>Multiple goroutines () are started to process data concurrently.</li><li>This is useful when the processing stage is CPU-intensive or involves I/O operations.</li></ul></li><li><ul><li>The  ensures that the output channel is closed only after all workers are done.</li><li>This combines the results from multiple goroutines into a single channel.</li></ul></li><li><ul><li>You can adjust the number of workers based on the available resources (e.g., CPU cores).</li></ul></li></ol><h2>\n  \n  \n  Best Practices for Data Processing Pipelines in Go\n</h2><ol><li><p>:\nIf one stage is slower than others, use buffered channels to avoid blocking.</p></li><li><p>:\nUse  to handle cancellation and timeouts gracefully.</p></li><li><p>:\nPropagate errors through channels or use a separate error channel.</p></li><li><p>:\nEnsure channels are properly closed to avoid goroutine leaks.</p></li><li><p>:\nTest each stage independently to ensure correctness.</p></li></ol><p>Example with Error Handling and Context:</p><div><pre><code></code></pre></div><p>This example adds  and  to ensure the pipeline can handle errors and timeouts gracefully.</p>","contentLength":2756,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go 1.24 is here üôå","url":"https://www.reddit.com/r/golang/comments/1irm5qm/go_124_is_here/","date":1739805479,"author":"/u/danielwetan","guid":1891,"unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>This release brings performance boosts, better tooling, and improved WebAssembly support.</p> <p>Highlights: - Generics: Full support for generic type aliases. - Faster Go: New runtime optimizations cut CPU overhead by ~2‚Äì3%. - Tooling: Easier tool dependency tracking (go get -tool), smarter go vet for tests. - WebAssembly: Export Go functions to the WASM host. - Standard library: FIPS 140-3 compliance, better benchmarking, new os.Root for isolated filesystem access.</p> <p>Full details: <a href=\"https://go.dev/blog/go1.24\">https://go.dev/blog/go1.24</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/danielwetan\"> /u/danielwetan </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1irm5qm/go_124_is_here/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1irm5qm/go_124_is_here/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google OAuth 2.0 Flow in Golang and React.js","url":"https://dev.to/the-arcade-01/google-oauth-20-flow-in-golang-and-reactjs-536a","date":1739796865,"author":"Aashish Koshti","guid":1815,"unread":true,"content":"<p>In this blog I've shared my approach on integrating Google OAuth in my app (Golang for backend and React.js for frontend).</p><ol><li>User requests for login from the client app</li><li>The client app hits login endpoint on the backend</li><li>The backend server generates the unqiue url of auth provider consent page and redirects the request</li><li>The consent page opens directly to the user requesting for granting permission</li><li>The user gives access to the permission, then auth provider calls the callback url of the backend server</li><li>The backend server then generates the access and refresh tokens and sets them in http only cookies</li><li>The backend server then redirects to the success page of the client app</li></ol><ul><li>Access &amp; Refresh token Flow</li></ul><ol><li>Backend sets access and refresh token to http only cookie</li><li>Client calls protected routes using the access token</li><li>If the access token expires, the client then calls  API using the refresh token from cookies</li><li>Backend then issues new access token and sets it in the cookie</li></ol><p>Here I won't put all the code from repo, I will just explain few code snippets so that you can implement it in your own way.</p><div><pre><code></code></pre></div><ul><li>Calling the auth provider for consent page\n</li></ul><div><pre><code></code></pre></div><ul><li>Handling callback function from auth provider\n</li></ul><div><pre><code></code></pre></div><ul><li>Setting the tokens in cookie\n</li></ul><div><pre><code></code></pre></div><div><pre><code></code></pre></div><ul><li><p>Creating request interceptors using axios, interceptors are functions which are triggered before an api request or on its response or both.<p>\nHere on the response, we are checking if its 401 then we need to refresh the access token again.</p><p>\nWe will use this api client for calling our apis.</p></p></li></ul><div><pre><code></code></pre></div><ul><li>Creating a AuthProvider context\n</li></ul><div><pre><code></code></pre></div><ul><li>Protected Route component, using the context isAuthenticated bool to check user auth\n</li></ul><div><pre><code></code></pre></div><p>In App.tsx, making Profile page as protected route</p><div><pre><code></code></pre></div><ol><li>Storing the refresh token in DB\n\n<ul><li>Since the refresh token is only returned on the first consent, its ideal to store it in DB as if it gets lost on the client app we can set it again after fetching it from the DB.</li><li>Second, if in case we need to revoke the refresh token, we can delete it from DB, and revoke it from auth provider and then issue it again from login flow</li><li>The refresh token has to be send on each login request (whether fetching it from DB if its not expired, or generating new one if its expired)</li></ul></li></ol><p>Some more learning resources which you can refer</p>","contentLength":2203,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"searchcode.com‚Äôs SQLite database is probably 6 terabytes bigger than yours","url":"https://www.reddit.com/r/golang/comments/1irhw56/searchcodecoms_sqlite_database_is_probably_6/","date":1739792175,"author":"/u/FoxInTheRedBox","guid":1805,"unread":true,"content":"&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/FoxInTheRedBox\"> /u/FoxInTheRedBox </a> <br/> <span><a href=\"https://boyter.org/posts/searchcode-bigger-sqlite-than-you/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1irhw56/searchcodecoms_sqlite_database_is_probably_6/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Efficiently Filling Arrays and Slices in Go: A Performance Guide","url":"https://dev.to/vishalj32/efficiently-filling-arrays-and-slices-in-go-a-performance-guide-41bi","date":1739790584,"author":"Vishal Jain","guid":1779,"unread":true,"content":"<h2>\n  \n  \n  Efficiently Filling Arrays and Slices in Go: A Performance Guide\n</h2><p>When working on a Go project, you might need to fill a slice or array with a repeating pattern. Recently, I explored different approaches to achieve this efficiently and discovered a powerful way to boost performance. In this article, I‚Äôll walk through various techniques to fill a slice in Go, highlight their performance differences, and explain why one method stands out as significantly faster.</p><h3>\n  \n  \n  Why Slice Filling Matters\n</h3><p>For my toy project, I needed to fill a background buffer with a specific RGB color pattern. Optimizing this operation significantly improved my achievable frame rate. The insights I gained could be useful for anyone working with large datasets, graphics programming, or high-performance applications.</p><p>All tests were performed on a buffer of 73,437 bytes, allocated as:</p><div><pre><code></code></pre></div><p>Let‚Äôs compare three common ways to fill this slice.</p><p>The simplest way is to iterate through each index and set the value.</p><div><pre><code></code></pre></div><div><table><thead><tr></tr></thead><tbody><tr><td>Benchmark_FillsliceIndex-10</td></tr></tbody></table></div><p>This approach is straightforward but relatively slow due to the per-element indexing and bounds checking.</p><p>Using a  loop provides a slight performance improvement:</p><div><pre><code></code></pre></div><div><table><thead><tr></tr></thead><tbody><tr><td>Benchmark_FillsliceRange-10</td></tr></tbody></table></div><p>This is faster than the index-based approach but still not optimal.</p><h2>\n  \n  \n  3. The Copy Trick (Efficient Method)\n</h2><p>The most efficient approach leverages Go's built-in  function to fill the slice incrementally:</p><div><pre><code></code></pre></div><div><table><thead><tr></tr></thead><tbody><tr><td>Benchmark_FillsliceCopyTrick-10</td></tr></tbody></table></div><p>The improvement here is dramatic‚Äîabout 30x faster than the basic loop!</p><h2>\n  \n  \n  4. Filling with a Multi-Element Pattern\n</h2><p>If you need to fill the slice with a repeating multi-byte pattern, you can adapt the copy trick easily:</p><div><pre><code></code></pre></div><div><table><thead><tr></tr></thead><tbody><tr><td>Benchmark_FillslicePatternCopyTrick-10</td></tr></tbody></table></div><h2>\n  \n  \n  Summary of Benchmark Results\n</h2><div><table><thead><tr></tr></thead><tbody><tr><td>Benchmark_FillsliceIndex-10</td></tr><tr><td>Benchmark_FillsliceRange-10</td></tr><tr><td>Benchmark_FillsliceCopyTrick-10</td></tr><tr><td>Benchmark_FillslicePatternCopyTrick-10</td></tr></tbody></table></div><h2>\n  \n  \n  How and Why the Copy Trick Works\n</h2><p>The  function avoids the overhead of indexing and bounds checking each element. Here‚Äôs how it works:</p><ul><li>The first value (or pattern) is loaded into the slice.</li><li>Each call to  duplicates twice the amount of data as the previous iteration.</li><li>This exponential growth reduces the number of copy operations required, amortizing the cost.</li><li>The final copy naturally stops when the slice is filled‚Äîno bounds checks are needed.</li></ul><p>For the complete source code and more details, check out the GitHub repository: <a href=\"https://github.com/Vishalj32/sliceFillExample.git\" rel=\"noopener noreferrer\">sliceFillExample</a></p><p>If you ever need to efficiently fill a slice or array in Go, especially for large datasets, the copy trick is a powerful and elegant solution. It‚Äôs faster, avoids unnecessary allocations, and leverages built-in optimizations for block memory operations.</p><p>I hope this guide helps you optimize your Go code and improve your application‚Äôs performance. Let me know if you discover any other cool slice-filling techniques!</p>","contentLength":2840,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Golang Data Compression Guide: Optimizing Performance with gzip and zlib","url":"https://dev.to/aaravjoshi/golang-data-compression-guide-optimizing-performance-with-gzip-and-zlib-2ml3","date":1739783012,"author":"Aarav Joshi","guid":1720,"unread":true,"content":"<blockquote><p>As a best-selling author, I invite you to explore my books on <a href=\"https://www.amazon.com/stores/Aarav-Joshi/author/B0DQYNVXZ7?ref=ap_rdr&amp;isDramIntegrated=true&amp;shoppingPortalEnabled=true&amp;ccs_id=738636bd-0ca1-4d7b-8efa-481bfc222571\" rel=\"noopener noreferrer\">Amazon</a>. Don't forget to follow me on <a href=\"https://medium.com/@aarav-joshi\" rel=\"noopener noreferrer\">Medium</a> and show your support. Thank you! Your support means the world! </p></blockquote><p>Data compression is a critical aspect of modern software development, particularly when dealing with large-scale applications that process substantial amounts of data. In Golang, we have several powerful tools and libraries that make implementing compression both efficient and straightforward.</p><p>I've worked extensively with data compression in Go, and I've found that choosing the right compression algorithm and implementation strategy can significantly impact application performance. The standard library provides excellent compression packages, including gzip, zlib, and the more recent lz4 implementations.</p><p>The most common compression algorithms in Go applications are gzip and zlib. Each has its advantages, with gzip typically offering better compression ratios while zlib provides faster compression speeds. Let's examine a robust implementation that leverages both.</p><div><pre><code></code></pre></div><p>Memory management is crucial when implementing compression. Using sync.Pool helps reduce garbage collection pressure by reusing buffers. This is particularly important in high-throughput scenarios where many compression operations occur simultaneously.</p><p>Streaming compression is another important consideration. When dealing with large files or network transfers, we don't want to load entire datasets into memory. Here's an implementation of streaming compression:</p><div><pre><code></code></pre></div><p>For optimal performance, it's essential to consider compression levels. Golang's compression packages typically offer compression levels from 1 (fastest) to 9 (best compression). The default level (6) provides a good balance between speed and compression ratio.</p><p>Here's a practical example of implementing a file compressor with progress monitoring:</p><div><pre><code></code></pre></div><p>To optimize compression performance in concurrent scenarios, we can implement a worker pool pattern:</p><div><pre><code></code></pre></div><p>When implementing compression in production applications, it's crucial to handle edge cases and implement proper error handling. Here's an example of a robust compression service:</p><div><pre><code></code></pre></div><p>For applications dealing with different types of data, implementing a smart compression strategy that selects the most appropriate algorithm based on data characteristics can be beneficial:</p><div><pre><code></code></pre></div><p>The effectiveness of compression varies significantly based on the type of data being compressed. Text-based data typically achieves higher compression ratios compared to already-compressed formats like images or videos. It's important to profile your specific use case to determine the optimal compression strategy.</p><p>Remember to implement proper monitoring and metrics collection for compression operations in production environments. This helps identify bottlenecks and optimize performance:</p><div><pre><code></code></pre></div><p>When implementing compression in Go applications, always consider the trade-offs between compression ratio, speed, and memory usage. The right balance depends on your specific requirements and constraints.</p><p> is an AI-driven publishing company co-founded by author . By leveraging advanced AI technology, we keep our publishing costs incredibly low‚Äîsome books are priced as low as ‚Äîmaking quality knowledge accessible to everyone.</p><p>Stay tuned for updates and exciting news. When shopping for books, search for  to find more of our titles. Use the provided link to enjoy !</p><p>Be sure to check out our creations:</p>","contentLength":3416,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Is Go a good language for beginners?","url":"https://www.reddit.com/r/golang/comments/1irfdsh/is_go_a_good_language_for_beginners/","date":1739781521,"author":"/u/Locyain","guid":1741,"unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>I know a bit of Lua, HTML, and CSS, and I&#39;ve also considered learning JavaScript, but it seems like a lot of content, so I thought I might learn it later. What I like about Go is its simplicity, and what I enjoy the most is the ability to create TUI applications. What do you think about that?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/Locyain\"> /u/Locyain </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1irfdsh/is_go_a_good_language_for_beginners/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1irfdsh/is_go_a_good_language_for_beginners/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Use the New tool Directive in Go 1.24","url":"https://www.reddit.com/r/golang/comments/1ir2q9q/how_to_use_the_new_tool_directive_in_go_124/","date":1739740319,"author":"/u/zakariachahboun","guid":794,"unread":true,"content":"&#32; submitted by &#32; <a href=\"https://www.reddit.com/user/zakariachahboun\"> /u/zakariachahboun </a> <br/> <span><a href=\"https://www.bytesizego.com/blog/go-124-tool-directive\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1ir2q9q/how_to_use_the_new_tool_directive_in_go_124/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"I wrote a Go Game in the Go Language","url":"https://www.reddit.com/r/golang/comments/1ir2kz3/i_wrote_a_go_game_in_the_go_language/","date":1739739934,"author":"/u/ExistingStrawberry25","guid":1861,"unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>I&#39;m a long-time professional Java developer, and I was curious about both the Go language and the Go board game, so I started a conversation with ChatGPT about both. At certain point, I quite innocently asked if there was a way to use the language to simulate the game. It turned out there was. It&#39;s an amateur effort, not ready for prime time, but it works. If you want to check it out, I&#39;d be interested to know what people in the know about Go think. <a href=\"https://github.com/eGantry/go-repo\">Here&#39;s the game project.</a> To run it from the project folder, enter <code>go run main.go ko-rule.go</code></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/ExistingStrawberry25\"> /u/ExistingStrawberry25 </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1ir2kz3/i_wrote_a_go_game_in_the_go_language/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1ir2kz3/i_wrote_a_go_game_in_the_go_language/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why did they decide not to have union ?","url":"https://www.reddit.com/r/golang/comments/1iqzofv/why_did_they_decide_not_to_have_union/","date":1739732626,"author":"/u/D4kzy","guid":765,"unread":true,"content":"<!-- SC_OFF --><div class=\"md\"><p>I know life is simpler without union but sometimes you cannot get around it easily. For example when calling the windows API or interfacing with C.</p> <p>Do they plan to add union type in the future ? Or was it a design choice ?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/D4kzy\"> /u/D4kzy </a> <br/> <span><a href=\"https://www.reddit.com/r/golang/comments/1iqzofv/why_did_they_decide_not_to_have_union/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1iqzofv/why_did_they_decide_not_to_have_union/\">[comments]</a></span>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"mongotui - A MongoDB client with a terminal user interface","url":"https://www.reddit.com/r/golang/comments/1iqv3kc/mongotui_a_mongodb_client_with_a_terminal_user/","date":1739721100,"author":"/u/gopher_256","guid":717,"unread":true,"content":"<table> <tr><td> <a href=\"https://www.reddit.com/r/golang/comments/1iqv3kc/mongotui_a_mongodb_client_with_a_terminal_user/\"> <img src=\"https://external-preview.redd.it/55ok8qa12rwU9Jc0kdib_vxlpdVHi8KxFJlw-e3iA1g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=736beebd3df0fa9ed868209e58cd6f5a2480f176\" alt=\"mongotui - A MongoDB client with a terminal user interface\" title=\"mongotui - A MongoDB client with a terminal user interface\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/gopher_256\"> /u/gopher_256 </a> <br/> <span><a href=\"https://github.com/kreulenk/mongotui\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1iqv3kc/mongotui_a_mongodb_client_with_a_terminal_user/\">[comments]</a></span> </td></tr></table>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Writing LLM prompts in Go with type-safety","url":"https://www.reddit.com/r/golang/comments/1iqtugn/writing_llm_prompts_in_go_with_typesafety/","date":1739717626,"author":"/u/shared_ptr","guid":690,"unread":true,"content":"<table> <tr><td> <a href=\"https://www.reddit.com/r/golang/comments/1iqtugn/writing_llm_prompts_in_go_with_typesafety/\"> <img src=\"https://external-preview.redd.it/M_AtZ_KMWH0EvoBdkj5ejjLtytl99FrbaFjeBLdIYZA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1dd424ef52b065c3c52ecee76a707f34466b88e\" alt=\"Writing LLM prompts in Go with type-safety\" title=\"Writing LLM prompts in Go with type-safety\" /> </a> </td><td> &#32; submitted by &#32; <a href=\"https://www.reddit.com/user/shared_ptr\"> /u/shared_ptr </a> <br/> <span><a href=\"https://blog.lawrencejones.dev/ai-dont-need-python/\">[link]</a></span> &#32; <span><a href=\"https://www.reddit.com/r/golang/comments/1iqtugn/writing_llm_prompts_in_go_with_typesafety/\">[comments]</a></span> </td></tr></table>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["go"]}