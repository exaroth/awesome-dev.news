{"id":"6SJ","title":"Go","displayTitle":"Go","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":60,"items":[{"title":"File System Walking with WalkDir: Recursive Tree Traversal 4/9","url":"https://dev.to/rezmoss/file-system-walking-with-walkdir-recursive-tree-traversal-49-dj3","date":1750520160,"author":"Rez Moss","guid":164316,"unread":true,"content":"<h2>\n  \n  \n  WalkDir Function Comprehensive Guide\n</h2><p>The  function represents Go's modern approach to recursive directory traversal, replacing the older  function with improved performance and cleaner interface design. Understanding its mechanics is essential for any developer working with file system operations at scale.</p><h3>\n  \n  \n  Function Signature and Parameters\n</h3><div><pre><code></code></pre></div><p>The function signature deliberately keeps things simple. The  parameter accepts any valid file system path - whether it points to a file or directory. When you pass a file path,  processes only that single file. Directory paths trigger recursive traversal of the entire subtree.</p><p>The  parameter expects a function matching the  signature:</p><div><pre><code></code></pre></div><p>This callback executes for every file and directory encountered during traversal. The function receives the full path, a  interface providing file metadata, and any error that occurred while accessing the entry.</p><h3>\n  \n  \n  Lexical Ordering Guarantees\n</h3><p> provides deterministic traversal through lexical ordering. Within each directory, entries are processed in sorted order by name. This predictability proves crucial for testing and debugging file system operations.</p><div><pre><code></code></pre></div><p>The lexical ordering applies only within individual directories. Parent directories are always processed before their children, but sibling directories follow alphabetical order.</p><h3>\n  \n  \n  Memory Usage Considerations\n</h3><p> optimizes memory usage through several design decisions. Unlike , it uses  instead of , avoiding expensive  system calls until you explicitly request detailed file information.</p><div><pre><code></code></pre></div><p>The function processes one directory at a time, reading directory entries incrementally rather than loading entire directory trees into memory. This approach scales well even with deeply nested directory structures containing thousands of files.</p><p>For large traversals, be mindful of callback function allocations. Avoid creating unnecessary string concatenations or slice allocations within the callback, as these multiply across thousands of file system entries.</p><h2>\n  \n  \n  WalkDirFunc Callback Patterns\n</h2><p>The  callback serves as your primary interface for processing file system entries during traversal. Mastering its parameter handling and return value semantics gives you precise control over the walking behavior.</p><h3>\n  \n  \n  Function Parameters: path, DirEntry, error\n</h3><p>Each callback invocation receives three parameters that work together to provide complete context about the current file system entry.</p><p>The  parameter contains the full file path from the root. This path uses the operating system's native separator and includes the original root prefix:</p><div><pre><code></code></pre></div><p>The  parameter provides efficient access to basic file metadata without requiring expensive system calls. Use its methods to check file types and names:</p><div><pre><code></code></pre></div><p>The  parameter indicates problems accessing the current entry. This error handling happens before your callback logic executes, allowing you to decide whether to continue or abort traversal.</p><h3>\n  \n  \n  Return Value Meanings and Control Flow\n</h3><p>Your callback's return value directly controls traversal behavior. Understanding these return patterns enables sophisticated directory walking logic.</p><p>Returning  continues normal traversal:</p><div><pre><code></code></pre></div><p>Returning  skips the current directory's contents but continues traversing siblings:</p><div><pre><code></code></pre></div><p>Returning  terminates the entire traversal immediately:</p><div><pre><code></code></pre></div><p>Any other error value stops traversal and propagates up to the  caller:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Error Propagation Strategies\n</h3><p>Different applications require different error handling approaches. Consider these common patterns based on your fault tolerance requirements.</p><p>The fail-fast approach stops on any error:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Advanced Traversal Control\n</h2><p>Fine-grained control over directory traversal enables efficient file system operations by avoiding unnecessary work. The key lies in understanding when and how to skip portions of the directory tree based on your specific requirements.</p><p>The distinction between  and  determines the scope of traversal interruption. Understanding their behavior prevents common mistakes in traversal logic.</p><p> affects only the current directory when returned for a directory entry:</p><div><pre><code></code></pre></div><p> terminates the entire traversal regardless of where it's returned:</p><div><pre><code></code></pre></div><p>Important:  has no effect when returned for file entries. Only directory entries can be skipped.</p><h3>\n  \n  \n  Conditional Directory Skipping\n</h3><p>Complex applications often require dynamic skipping logic based on directory contents, depth, or external conditions. Implement these patterns using closure-captured state.</p><p>Depth-based skipping prevents traversal beyond a certain level:</p><div><pre><code></code></pre></div><p>Content-based skipping examines directory properties before entering:</p><div><pre><code></code></pre></div><p>Pattern-based skipping uses matching rules for directory names:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Early Termination Patterns\n</h3><p>Early termination patterns optimize performance by stopping traversal once specific conditions are met. These patterns are essential for search operations and resource-constrained environments.</p><p>The first-match pattern stops after finding the first occurrence:</p><div><pre><code></code></pre></div><p>The quota-based pattern stops after processing a certain number of entries:</p><div><pre><code></code></pre></div><p>The timeout-based pattern stops after a time limit:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Error Handling in Tree Walking\n</h2><p>File system traversal encounters various error conditions that require different handling strategies. The  function provides a two-phase error reporting mechanism that gives you fine-grained control over error recovery and propagation.</p><h3>\n  \n  \n  Two-Phase Error Reporting\n</h3><p> implements a sophisticated error handling model where errors can occur both during directory reading and individual entry access. Understanding this distinction is crucial for building robust file system tools.</p><p>The first phase occurs when  attempts to read a directory's contents. If this fails, your callback receives the directory path with a non-nil error parameter:</p><div><pre><code></code></pre></div><p>The second phase happens when individual entries within a readable directory have access problems. In this case, the callback receives the entry with its specific error:</p><div><pre><code></code></pre></div><p>Here's a comprehensive handler that distinguishes between error types:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Pre-read vs Post-read Error Handling\n</h3><p>The timing of error detection affects your handling strategy. Pre-read errors prevent access to directory contents entirely, while post-read errors affect individual entries after successful directory enumeration.</p><p>Pre-read errors typically indicate system-level issues:</p><div><pre><code></code></pre></div><p>Post-read errors occur after successful directory reading but indicate problems with specific entries:</p><div><pre><code></code></pre></div><p>Different applications require different recovery approaches when file system errors occur. Implement recovery strategies based on your application's fault tolerance requirements.</p><p>The retry strategy attempts to recover from transient errors:</p><div><pre><code></code></pre></div><p>The graceful degradation strategy continues operation with reduced functionality:</p><div><pre><code></code></pre></div><p>The error isolation strategy quarantines problematic areas while continuing elsewhere:</p><div><pre><code></code></pre></div><p>The error collection approach gathers all errors for batch reporting:</p><div><pre><code></code></pre></div><p>The selective error handling approach treats different error types differently:</p><div><pre><code></code></pre></div><p> implements specific symbolic link handling policies that differ significantly from traditional file system traversal tools. Understanding these behaviors prevents security vulnerabilities and infinite loops while maintaining predictable traversal characteristics.</p><p>When the root path passed to  is itself a symbolic link, the function resolves it before beginning traversal. This resolution applies only to the root path and establishes the actual starting point for the walk operation.</p><div><pre><code></code></pre></div><p>Notice that while  resolves the root symlink to determine what to traverse, it preserves the original symlink path in the callback parameters. This behavior maintains path consistency for your application logic while ensuring the traversal reaches the intended content.</p><p>The resolution only affects traversal scope, not path reporting:</p><div><pre><code></code></pre></div><p>Root symlink resolution has security implications for applications that perform path-based access control:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Directory Symlink Non-Following\n</h3><p>Unlike root symlinks,  does not follow symbolic links to directories encountered during traversal. This policy prevents infinite loops and maintains bounded traversal behavior.</p><div><pre><code></code></pre></div><p>The non-following behavior applies only to directory symlinks. File symlinks are reported but not dereferenced:</p><div><pre><code></code></pre></div><p>This behavior protects against common symlink attack patterns:</p><div><pre><code></code></pre></div><p>When you need to follow directory symlinks, implement custom logic with cycle detection:</p><div><pre><code></code></pre></div><p>The practical value of  emerges through real-world implementations that solve common file system problems. These examples demonstrate how to combine the traversal patterns into production-ready tools.</p><h3>\n  \n  \n  File Search Implementation\n</h3><p>Building efficient file search tools requires combining multiple  features: pattern matching, early termination, and smart filtering. Here's a comprehensive search implementation:</p><div><pre><code></code></pre></div><p>Cleanup tools require careful error handling and confirmation mechanisms to avoid data loss. This implementation provides safe cleanup with rollback capabilities:</p><div><pre><code></code></pre></div><p>Auditing tools analyze file system structure and permissions to identify security issues and compliance violations:</p><div><pre><code></code></pre></div>","contentLength":9074,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Streamlining Capacity Management with Bidirectional Conversion Between T-shirt Sizes and Points: CLI Tool \"sizely\"","url":"https://dev.to/gr1m0h/streamlining-capacity-management-with-bidirectional-conversion-between-t-shirt-sizes-and-points-1ma6","date":1750514909,"author":"gr1m0h","guid":164283,"unread":true,"content":"<p>Recently, I introduced Scrum-like practices to my team. I mainly led the implementation and have been managing the operations.</p><p>As we progressed with our daily work, one of the challenges in sprint planning became capacity management. This is particularly difficult for SRE teams, which tend to have many interruptions such as incident response and ad-hoc requests. Because prediction is challenging, accurate capacity forecasting becomes the foundation for reliability improvement and leads to more challenging activities.</p><p>Many teams adopt T-shirt size estimation (XS, S, M, L, XL, etc.), but we faced the challenge of difficulty in quantitative analysis such as \"How much work did the team actually complete in the previous sprint?\" and \"How many tasks can we plan for future sprints?\"</p><h2>\n  \n  \n  Development Background: Why was sizely needed?\n</h2><p>The trigger for development was when I felt that sprint planning facilitation wouldn't go smoothly if I couldn't quickly convert between T-shirt sizes and points while organizing the agenda for Scrum events.</p><p>Even when told \"We completed S×3, M×2, L×1 this sprint,\" it's difficult to estimate a similar workload for the next sprint. Tasks of the same size don't necessarily have the same priority. Additionally, we need to consider not only team capacity but also individual capacity. The amount of work that can be executed varies depending on vacation time, on-call duties, meetings, etc., so we need to convert to points to understand capacity.</p><p>In planning communication, \"L×2 + M×2 + XS×3 combination\" is more concrete and easier to understand than the numerical value \"33 points worth of work possible in a sprint,\" making task selection smoother.</p><h2>\n  \n  \n  sizely Features and Usage\n</h2><p>It provides the following features:</p><ul><li>T-shirt Size → Points: Calculate total points of completed tasks</li><li>Points → T-shirt Size Combinations: Suggest optimal task combinations for target points</li></ul><h3>\n  \n  \n  Post-Sprint Retrospective\n</h3><div><pre><code># Calculate total points of completed tasks\n$ sizely points --data '{\"xs\":3,\"s\":2,\"m\":1,\"l\":1}'\n\n📊 Sprint Capacity Calculation\n═══════════════════════════════\nXS (1pt): 3 tasks = 3 points\nS (3pt): 2 tasks = 6 points\nM (5pt): 1 tasks = 5 points\nL (10pt): 1 tasks = 10 points\n───────────────────────────────\nTotal: 7 tasks = 24 points\n</code></pre></div><div><pre><code># Search for task combinations worth 33 points\n$ sizely tasks 33\n\n🔍 Finding combinations for 33 points (max 15 tasks)\n═══════════════════════════════════════════════════\nFound 12 combination(s):\n\n1. L×3 + XS×3 = 33 points (6 tasks)\n✅ Good mix of large and small tasks\n\n2. L×2 + M×2 + XS×3 = 33 points (7 tasks)\n✅ Good mix of large and small tasks\n...\n</code></pre></div><p>sizely is a tool that quantifies team capacity and enables more strategic sprint planning. Through bidirectional conversion between T-shirt sizes and points, it supports both past performance analysis and future planning.</p><p>Particularly for SRE teams that need to balance long-term goals of reliability improvement with short-term demands of daily incident response, quantitative capacity management is essential.</p><p>Although only minimal features are currently implemented, I expect this tool to contribute to team productivity improvement and ultimately to service reliability enhancement.</p><p>Although only minimal features are currently implemented, I expect this tool to contribute to team productivity improvement and ultimately to service reliability enhancement.</p>","contentLength":3638,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"#golang #go #concurrency #goroutines Let's master concurrency in go from absolute basics. Be a part of my journey.","url":"https://dev.to/sadhakbj/golang-go-concurrency-goroutines-lets-master-concurrency-in-go-from-absolute-basics-be-a-4pbl","date":1750467613,"author":"Bijaya Prasad Kuikel","guid":163950,"unread":true,"content":"<h2>Mastering Concurrency in Go, Part 1: Understanding Concurrency vs Parallelism</h2><h3>Bijaya Prasad Kuikel ・ Jun 20</h3>","contentLength":108,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Basic things to know of Go","url":"https://dev.to/wakeup_flower_8591a6cb6a9/basic-things-to-know-of-go-32p2","date":1750443057,"author":"Wakeup Flower","guid":163758,"unread":true,"content":"<p>The designer, Renée French, intentionally made the gopher look quirky and approachable — not a typical “serious” tech logo, to help set Go apart as a language for everyday programmers, not just specialists.</p><p>Go is the language behind some of the most important and widely used DevOps and cloud-native tools, including:</p><div><table><tbody><tr><td>Containerization platform</td></tr><tr><td>Container orchestration system</td></tr><tr><td>Infrastructure as Code tool</td></tr><tr><td>Monitoring and alerting system</td></tr><tr><td>Distributed key-value store (used in Kubernetes)</td></tr><tr><td>Service mesh and service discovery</td></tr></tbody></table></div><p>DevOps engineers often build custom CLI tools, automation scripts, and operators in Go.</p><p>Go’s performance and static binaries make it ideal for creating efficient command-line tools.</p><p>The ecosystem has great libraries for working with cloud APIs, Kubernetes, etc.</p><p>Use Python for fast scripting, automation, and prototyping.</p><p>Use Go when you need performance, concurrency, and easy deployment in distributed systems or large-scale tools.</p><p>In many DevOps teams, you’ll see both languages used side by side — Python for quick automation and Go for core infrastructure tools.</p><p>Compiled to a single, static binary — no runtime dependency needed on target machines. Super easy to deploy.</p><p>Fast execution and efficient concurrency — perfect for building scalable tools that handle many tasks simultaneously (e.g., container orchestration, networking).</p><p>Used in heavy-duty infrastructure tools like Kubernetes, Docker, Terraform — which require high performance.</p><p>Produces small binaries, which is great for cloud environments and containers.</p><div><table><thead><tr></tr></thead><tbody><tr><td>Formatted I/O functions (, , etc.)</td></tr><tr><td>OS functionality (file system, environment, processes)</td></tr><tr><td>Basic interfaces for I/O primitives</td></tr><tr><td>Functions for manipulating byte slices</td></tr><tr><td>String manipulation functions</td></tr><tr><td>String conversions to/from other types</td></tr><tr><td>Basic math constants and functions</td></tr><tr><td>Pseudorandom number generator</td></tr><tr><td>Time and duration handling</td></tr><tr><td>Network I/O (TCP, UDP, IP)</td></tr><tr><td>HTTP client and server implementations</td></tr><tr><td>JSON encoding and decoding</td></tr><tr><td>XML encoding and decoding</td></tr><tr><td>CSV encoding and decoding</td></tr><tr><td>Synchronization primitives (Mutex, WaitGroup, etc.)</td></tr><tr></tr><tr><td>Context propagation for cancellation, deadlines</td></tr><tr></tr><tr><td>Error creation and manipulation</td></tr><tr></tr><tr><td>Command-line flag parsing</td></tr><tr></tr><tr><td>Manipulate slash-separated paths</td></tr><tr><td>Manipulate OS-specific file paths</td></tr><tr><td>Functions interacting with Go runtime</td></tr><tr></tr><tr><td>Support for automated testing</td></tr><tr></tr><tr></tr><tr></tr><tr><td>Cryptographically secure random number generation</td></tr><tr><td>Generic SQL database interface</td></tr><tr></tr><tr><td>PNG image decoder and encoder</td></tr><tr><td>JPEG image decoder and encoder</td></tr></tbody></table></div>","contentLength":2426,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Implementing Log File Rotation in Go: Insights from logrus, zap, and slog","url":"https://dev.to/leapcell/implementing-log-file-rotation-in-go-insights-from-logrus-zap-and-slog-5b9o","date":1750442316,"author":"Leapcell","guid":163738,"unread":true,"content":"<p>In existing logging libraries, including Go’s built-in  logging library, they typically support log file rotation and splitting. However, these features are not built in directly—they need to be actively configured by us to enable them.</p><p>This article will explore several popular logging libraries, such as logrus, zap, and the official slog. We will analyze the key design elements of these libraries and discuss how they support the configuration of log rotation and splitting.</p><h2>\n  \n  \n  Brief Analysis of the Designs of logrus, zap, and slog\n</h2><p>When comparing the design of logrus, zap, and slog, one prominent commonality is that they all include the crucial property of . This property plays a central role in the design of logging frameworks, as it determines the target location for log output.</p><p>logrus is a feature-rich logging library for Go, providing structured logging, log level control, and other features.</p><p>When using logrus, you can create a Logger instance by calling . With this instance, we can perform many operations, such as customizing the log output location and printing logs. Let’s look at the following code:</p><div><pre><code></code></pre></div><p>The definition of the Logger struct is as follows:</p><div><pre><code></code></pre></div><p>The key property is , whose type is . This property is used to specify the log output target, whether it’s standard output, a file, or another custom output medium.</p><p>zap is a highly performant logging library. It provides structured logging, multi-level log control, and flexible configuration options.</p><p>Similar to logrus, zap also allows you to decide the log output location via configuration, but the implementation differs slightly. In zap, log output is configured through . When creating an instance of , you need to specify an implementation of the  interface as a parameter, which directly determines the target for log output. To create a  instance, you usually use the  function, which takes an  type parameter.</p><p>Here is a basic example of creating a log instance with zap:</p><div><pre><code></code></pre></div><p>The key is the  function, which takes an  type parameter used to specify the log output target, whether it’s standard output, a file, or another custom output medium.</p><p>slog is an official logging library introduced in Go 1.21.0, providing structured logging. If you want to learn more about the slog logging library, you can check out our previous <a href=\"https://leapcell.io/blog/hands-on-with-go-slog-package\" rel=\"noopener noreferrer\">article</a>.</p><p>Similar to logrus and zap, slog also allows users to specify the log output target by providing an  parameter. This setting is made when creating an implementation of the  interface.</p><div><pre><code></code></pre></div><p>In these two functions, the first parameter of  and  is of type .</p><p>From our analysis of the three mainstream logging libraries—logrus, zap, and slog—we can see a key commonality: when handling log output, all of them rely on the  interface. These logging libraries use the  interface as the type of a crucial parameter, allowing you to set the target of the log output.</p><h2>\n  \n  \n  Implementation Mechanisms and Practices of Log Rotation and Splitting\n</h2><p>After analyzing the design of logrus, zap, and slog, we have discovered their commonalities. Now, let’s dive deeper into the mechanism of log rotation and splitting.</p><p>To implement log file rotation and splitting, we usually leverage third-party libraries such as lumberjack. Of course, there are other similar libraries available, but we won’t list them all here.</p><p>lumberjack is a library specifically designed for log rotation and splitting. Its function is similar to a pluggable component. By configuring this component and integrating it with your chosen logging library, you can achieve log file rotation and splitting.</p><p>Here is the code to initialize a lumberjack component:</p><div><pre><code></code></pre></div><p>In this example, we create a  instance and set the following parameters:</p><ul><li>: Specifies the storage path of the log file.</li><li>: The file will rotate when it reaches this many MB.</li><li>: The maximum number of old log files to keep.</li><li>: The maximum retention period (in days) for old files.</li><li>: Whether to compress old files (e.g., convert to .gz).</li></ul><p>It is important to note that the  struct of lumberjack implements the  interface. This means all the core logic for log file rotation and splitting is encapsulated within the  method. This implementation also makes it easy for the Logger struct to be integrated into any logging library that supports an  parameter.</p><p>Once you understand this, you probably already know how to implement log rotation and splitting. Since the logger struct of lumberjack implements the  interface, passing it into a third-party library allows you to complete the integration and configuration.</p><h4>\n  \n  \n  Implementation with logrus Logging Library\n</h4><div><pre><code></code></pre></div><h4>\n  \n  \n  Implementation with zap Logging Library\n</h4><div><pre><code></code></pre></div><h4>\n  \n  \n  Implementation with slog Logging Library\n</h4><div><pre><code></code></pre></div><p>This article provided a brief analysis of the design elements of three popular logging libraries: logrus, zap, and slog. We found that although they differ in the details of how logging instances are created, they all rely on the  interface parameter to handle log output. By mastering how to configure the  parameter and combining it with the lumberjack library, we can achieve log file rotation and splitting.</p><p>Even if new logging libraries are introduced in the future, we can quickly integrate log file rotation and splitting using similar methods.</p><p><a href=\"https://leapcell.io/?lc_t=d_gologrotation\" rel=\"noopener noreferrer\">Leapcell</a> is the Next-Gen Serverless Platform for Web Hosting, Async Tasks, and Redis:</p><ul><li>Develop with Node.js, Python, Go, or Rust.</li></ul><p><strong>Deploy unlimited projects for free</strong></p><ul><li>pay only for usage — no requests, no charges.</li></ul><p><strong>Unbeatable Cost Efficiency</strong></p><ul><li>Pay-as-you-go with no idle charges.</li><li>Example: $25 supports 6.94M requests at a 60ms average response time.</li></ul><p><strong>Streamlined Developer Experience</strong></p><ul><li>Intuitive UI for effortless setup.</li><li>Fully automated CI/CD pipelines and GitOps integration.</li><li>Real-time metrics and logging for actionable insights.</li></ul><p><strong>Effortless Scalability and High Performance</strong></p><ul><li>Auto-scaling to handle high concurrency with ease.</li><li>Zero operational overhead — just focus on building.</li></ul>","contentLength":5882,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mastering Concurrency in Go, Part 1: Understanding Concurrency vs Parallelism","url":"https://dev.to/sadhakbj/mastering-concurrency-in-go-part-1-understanding-concurrency-vs-parallelism-377k","date":1750430156,"author":"Bijaya Prasad Kuikel","guid":163600,"unread":true,"content":"<p>Modern software doesn’t run on a single processor anymore. Your phone likely has 8 cores, and servers have dozens. Yet many programs are still written as if only one task happens at a time.\nTo build fast, scalable software, you need to master concurrency and parallelism—and Go makes these concepts simple, powerful, and fun.</p><h2>\n  \n  \n  🌍 The Bigger Picture: Why Concurrency Exists at All\n</h2><p>Before we dive into Go or any code, let’s understand the  behind concurrency.</p><p>In the early days of computing, programs ran in a  — do one thing, then the next, and so on. This was fine when computers were slow, and users had simple needs. But as computers became faster and systems more complex, we hit a problem: .</p><p>Waiting for input. Waiting for files. Waiting for a network response.</p><p>And during that wait? The CPU just sat idle — wasting time and power.</p><p>To solve this, computer scientists introduced the idea of <strong>doing multiple things seemingly at the same time</strong> — called . It let systems remain productive while waiting on slow tasks like I/O or user interaction.</p><p>Later, as CPUs got multiple cores, we also gained  — actually doing things  at the same time.</p><p>Modern systems combine . And that’s where software needs to evolve too.</p><p>Look around you — apps today are expected to:</p><ul><li>Respond to clicks while doing work in the background</li><li>Fetch data from multiple APIs</li><li>Handle thousands of users without crashing</li></ul><p>But under the hood, every program faces the same old enemy: <strong>doing one thing at a time</strong> is slow and limiting.</p><ul></ul><p>… then your app is doing tasks that wait — . And if you don’t handle this well, your app becomes slow, unresponsive, or just stuck.</p><p>Concurrency lets your program start a task, move on to others while waiting, and keep everything flowing. It’s the key to efficiency, responsiveness, and scalability. </p><p>Concurrency is powerful but often painful in other languages:</p><ul><li>Java’s threads are heavyweight and require complex locks, which are hard to get right.</li><li>JavaScript’s single-threaded event loop can lead to callback hell and debugging nightmares.</li></ul><p>Go was designed with  in mind. It gives you:</p><ul><li> — Lightweight “mini-programs” you can launch with one keyword: go. Unlike threads, they’re cheap and easy to use.</li><li> —  A safe way to share data between tasks without messy locks.</li><li> - A behind-the-scenes manager that juggles goroutines efficiently across CPU cores.</li></ul><p>You get <strong>simplicity, safety, and performance</strong> — all without breaking your brain.</p><h2>\n  \n  \n  🧭 What This Series Covers\n</h2><p>In this series, we’ll walk through:</p><ul><li>The fundamentals of concurrency vs parallelism (this part)</li><li>How Go implements concurrency with goroutines and channels</li><li>What makes Go’s scheduler unique and powerful</li><li>Real-world problems you’ll face with concurrency — and how Go solves them</li><li>Building systems that scale: crawlers, servers, pipelines, and more</li></ul><h2>\n  \n  \n  Concurrency vs. Parallelism\n</h2><p>Let’s clear up the confusion between these two core ideas.</p><blockquote><p>Managing multiple tasks that can run independently, even if they don’t execute simultaneously.</p></blockquote><p>Think of a chef in a kitchen juggling three dishes—chopping veggies for one, stirring a sauce for another, and checking the oven. The chef switches tasks to keep everything moving, even with just one pair of hands. [Visual suggestion: Animation of a chef switching between tasks.]</p><blockquote><p>Executing multiple tasks at the same time on different cores.</p></blockquote><p>Now imagine three chefs, each cooking a different dish at the same time. That’s parallelism—true multitasking with multiple workers (cores). </p><p>: Concurrency is about orchestrating tasks to avoid wasted time. Parallelism is about executing tasks at once to maximize speed. Go’s runtime handles both, making your code efficient and scalable.</p><ul><li>Waits for network or disk I/O</li><li>Serves thousands of users</li></ul><p>Concurrency lets you , maximizing resource use without waiting idly. It’s about , not just raw speed.</p><h2>\n  \n  \n  Real-World Case: Downloading Images\n</h2><p>Imagine downloading 100 images:</p><ul><li>: One after another — painfully slow.</li><li>: Start all downloads at once, utilizing network downtime.</li><li>: Process multiple downloads across CPU cores.</li></ul><p>Here’s what this might look like in code (don’t worry, we’ll dive into goroutines soon):</p><div><pre><code></code></pre></div><p>Go’s runtime decides which downloads run in parallel, making your code clean and scalable.</p><h2>\n  \n  \n  Traditional Models: Threads and Locks\n</h2><p>In languages like Java or C++, concurrency often means threads and shared memory. You create threads, manage locks, and pray you avoid:</p><ul><li>Deadlocks (threads stuck waiting for each other)</li><li>Race conditions (unpredictable results from shared data)</li><li>Context-switching overhead (threads are expensive)</li></ul><p>This model is powerful but complex and error-prone.</p><p>Go abstracts threads away with goroutines — lightweight, user-space functions you launch like this:</p><ul><li>Managed by the Go runtime, not OS threads</li><li>Start with a small stack (a few KB, growing as needed)</li><li>Cheap enough to run thousands without crashing</li></ul><p>Go’s M:N scheduler maps many goroutines to a few OS threads, balancing concurrency and parallelism. It’s fast, increasingly preemptive, and improves with every release.</p><h2>\n  \n  \n  Sharing Memory by Communicating\n</h2><p>Traditional concurrency: Share memory and coordinate with locks.</p><p>Go’s philosophy: Do not communicate by sharing memory; instead, share memory by communicating.</p><p>Go’s channels are concurrency-safe queues for passing messages:</p><div><pre><code></code></pre></div><p>Channels reduce the need for locks, making code simpler and safer.</p><p>Go’s runtime keeps getting better:</p><ul><li>Faster goroutine scheduling</li><li>Lower overhead for sync.Mutex, WaitGroup</li><li>Improved tools like runtime/trace and pprof</li><li>Easier debugging of concurrent systems</li></ul><p>Go’s concurrency is simple, scalable, and production-ready.</p><ul><li>Concurrency: Structuring tasks to run independently.</li><li>Parallelism: Executing tasks simultaneously on multiple cores.</li><li>Go’s goroutines and channels make concurrency simple and safe.</li><li>Compared to threads or event loops, Go offers less complexity, more performance.</li><li>Go’s runtime evolves to stay cutting-edge.</li></ul><p>In Part 2: Goroutines Under the Hood, we’ll dive into the magic of goroutines:</p><ul><li>How does Go’s scheduler juggle thousands of tasks?</li><li>Why can you run 10,000 goroutines on a laptop without crashing?</li><li>What’s a goroutine leak, and how do you avoid it?</li></ul><p>Plus, we’ll build a concurrent web crawler to see goroutines in action.</p>","contentLength":6271,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"⚙️ Go Tools: Password Hashing with Argon2 Instead of bcrypt","url":"https://dev.to/nikita_rykhlov/go-tools-password-hashing-with-argon2-instead-of-bcrypt-38aj","date":1750416391,"author":"Nikita Rykhlov","guid":163455,"unread":true,"content":"<p>Storing passwords securely is one of the most critical security tasks in modern applications. Many developers still rely on time-tested algorithms like , but technology doesn't stand still. In this article, we'll explore  — a modern and secure password hashing algorithm that serves as an excellent alternative to bcrypt. We'll also look at how to implement it in .</p><p> is a cryptographic algorithm specifically designed for password hashing. It resists brute-force attacks thanks to the use of \"salt\" and a tunable cost factor that increases computational complexity.</p><p>However, over time new threats have emerged — especially those involving specialized hardware such as GPUs and ASICs for password cracking. This is where  starts to fall short compared to more modern solutions.</p><p> is the winner of the <a href=\"https://password-hashing.net/\" rel=\"noopener noreferrer\">Password Hashing Competition (PHC)</a>, a competition organized by the cryptographic community to find a new standard for secure password hashing. It was developed by a team of cryptographers from the University of Luxembourg: , , and .</p><p>Argon2 was chosen for its resistance to various types of attacks, including:</p><ul></ul><p>Argon2 offers three different modes:</p><ol><li> — provides maximum protection against hardware attacks but is vulnerable to timing attacks.</li><li> — resistant to timing attacks but weaker against hardware-based attacks.</li><li> — a hybrid mode combining the best features of both.</li></ol><p>For most practical purposes,  is recommended.</p><h2>\n  \n  \n  Why Argon2 Is Better Than bcrypt\n</h2><div><table><tbody><tr><td>Protection against GPU attacks</td></tr><tr><td>Configurable memory usage</td></tr><tr><td>Resistance to timing attacks</td></tr></tbody></table></div><p>In short,  is a more flexible, modern, and secure solution.</p><p>In this example, we'll use  (), which combines the strengths of  and : it's resistant to side-channel attacks and protected against time-memory trade-off attacks.</p><div><pre><code>go get golang.org/x/crypto/argon2\n</code></pre></div><div><pre><code></code></pre></div><blockquote><p>🔐  Never use fixed  values. Always generate a new random salt before each password hashing.</p></blockquote><div><table><thead><tr></tr></thead><tbody><tr><td>Number of passes through memory</td></tr><tr><td>Amount of memory used in KiB (~64 MB)</td></tr><tr></tr><tr><td>Length of the resulting key in bytes</td></tr><tr><td>Random salt to prevent collisions</td></tr></tbody></table></div><blockquote><p>These values are suitable for most web applications. Adjust them based on your system's capabilities or specific requirements (e.g., mobile devices).</p></blockquote><p>While  remains a solid choice,  offers superior protection against modern threats, particularly GPU and ASIC-based attacks. With its flexibility and efficient resource usage, it is becoming the de-facto standard for password hashing in new projects.</p><p>If you're developing in , integrating Argon2 is straightforward using existing libraries. Just remember to choose appropriate parameters for your application load and always store the salt and metadata correctly.</p><p>Have you already switched from bcrypt to Argon2 in your projects — or still sticking with the classic?</p><p>What password hashing strategy do you use in Go — and how do you manage security vs. performance?</p><p>👇 Share your thoughts and experience in the comments — I’d love to learn from you!</p><p>👍 If you enjoyed this article, don’t forget to like and share it — help others upgrade their password security the right way!</p><p>📣 <strong>Follow me and read my content on other platforms:</strong></p><p>Check out this and other articles on my pages:</p><p>🔔 <em>Follow me not to miss new articles and guides on hot topics!</em></p>","contentLength":3223,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Connected, Controlled, and Confident: How IoT Is Transforming Production Floors","url":"https://dev.to/tylermorganaqe/connected-controlled-and-confident-how-iot-is-transforming-production-floors-3o30","date":1750413850,"author":"Faizan Saiyed","guid":163406,"unread":true,"content":"<p>Many factories still rely on manual checks or delayed reports. This creates problems like unexpected equipment failures, stock issues, and inaccurate forecasting. Without real-time data, it’s hard to respond quickly when something goes wrong.</p><p>That’s where IoT Product Development Services come in. IoT uses sensors to collect real-time data from machines, equipment, and workers. This data is then sent to the cloud, where it can be stored, analyzed, and used to improve operations.</p><p>With real-time insights, factory managers can monitor equipment health, detect problems early, and make quick decisions — all from a single dashboard.</p><p>Here’s a simple breakdown of how real-time monitoring works in a smart factory:</p><p>Sensors are placed on machines and equipment to track performance, temperature, speed, and more.</p><p>The data is collected and sent to the cloud, where it’s stored securely.</p><p>Analytics tools process the data and highlight any issues, trends, or inefficiencies.</p><p>Managers can view everything on a dashboard from machine status to production output — in real time.</p><p>This kind of system helps manufacturers spot problems early, reduce delays, and improve overall efficiency.</p><p><strong>Benefits You Can’t Ignore</strong></p><p>Here’s what real-time monitoring with IoT and cloud can do for your business:</p><p> Catch machine issues before they lead to breakdowns.</p><p> Track every part of the process and remove bottlenecks.</p><p> Detect defects early and maintain consistent quality.</p><p> Get full visibility of stock levels and avoid over/under stocking.</p><p> Use accurate data to guide your actions in real time.</p><p>These improvements not only save time and money but also make your factory more competitive and future-ready.</p><p>At AQe Digital, we help manufacturers upgrade their systems with powerful and easy-to-use  We make sure the technology fits your needs, connects with your existing setup, and gives you real value.</p><p>Whether it’s installing smart sensors, building real-time dashboards, or helping you manage data securely in the cloud — we offer complete support from start to finish.</p><p>If you want to understand how real-time production monitoring works in detail — from key components to real business use cases — we’ve explained everything in our full blog.</p>","contentLength":2228,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Wiremock + testcontainers + Algolia + Go = ❤️","url":"https://dev.to/manomano-tech-team/wiremock-testcontainers-algolia-go--3hn7","date":1750407362,"author":"Grégoire Paris","guid":163382,"unread":true,"content":"<p>When dealing with a SaaS like <a href=\"https://www.algolia.com/\" rel=\"noopener noreferrer\">Algolia</a>, testing can be a hassle. Ideally, you should not \"mock what you do not own\". In other words, you should not mock libraries such as the Algolia SDK, not just because it might evolve in unforeseen ways, but also because writing unit tests for a piece of code where the logic is dictated by something external to the code is not a good idea: you would not be testing the part that has the most complexity.</p><p>To take a concrete example, let's imagine you want to index documents in Algolia. There is an end goal behind that, and the end goal is that it is possible to search for these documents.</p><p>Ideally, you would have a Docker container running Algolia locally that would be super fast at indexing and use the same code your production Algolia app uses, but sadly that does not exist, and I'm not hopeful it ever will.</p><p>In a legacy service I worked on, we have a test Algolia app that we use for integration tests. It worked great, but in the past years, Algolia introduced a new cloud-based architecture, and with this architecture, an indexing task can take a lot more time to be \"published\". As a result, using a test application on the cloud-based architecture is not an option anymore, as it slows the test suite down to a crawl. 🐌</p><p>On a new project, I decided to re-evaluate my options, and remembered a tool that seems to be the next best thing for the job: <a href=\"https://wiremock.org\" rel=\"noopener noreferrer\">Wiremock</a>.</p><p>In this post, I will guide you through the process of setting Wiremock and testcontainers to test Algolia's own <a href=\"https://www.algolia.com/doc/libraries/go/v4/\" rel=\"noopener noreferrer\">quickstart guide for Golang</a>.</p><p>It means you can do this once in your local environment:</p><div><pre><code>┌────────────┐          ┌────────────────────────────┐       ┌─────────┐\n│            ├─────────►│                            ├──────►│         │\n│Your service│          │ Wiremock in recording mode │       │ Algolia │\n│            │◄─────────┤                            │◄──────┤         │\n└────────────┘          └────────────────────────────┘       └─────────┘\n</code></pre></div><p>In recording mode, you give Wiremock a URL to record, and it will store files representing the requests you made, and the corresponding responses. With Algolia, it can be quite long, especially if you <a href=\"https://www.algolia.com/doc/api-reference/api-methods/wait-task\" rel=\"noopener noreferrer\">wait for operations</a>.\nWhat happens in practice is that the SDK will use a polling mechanism to check if your task is published. This will result in a lot of similarly looking files.<p>\nThis is not very interesting to reproduce in your test, so I recommend simply deleting files representing a negative response to the question: \"are the changes published yet?\". Those typically contain a JSON field called </p> set to  in their body, like so:</p><div><pre><code></code></pre></div><p>When the file is published, this becomes:</p><div><pre><code></code></pre></div><p>The files have names that are a bit ugly, so I usually rename them for clarity.\nFor example, you might rename <code>1_indexes_test-index_task_226434943725-6e8689fa-9bbb-43fb-9d24-6824c02fc7d5.json</code>\nto <code>index_test_task_published.json</code>.</p><p>Once your recording is done, you can run your tests like this:</p><div><pre><code>┌────────────┐          ┌───────────────────────────┐\n│            ├─────────►│                           │\n│Your service│          │ Wiremock in playback mode │\n│            │◄─────────┤                           │\n└────────────┘          └───────────────────────────┘\n</code></pre></div><p>In playback mode, Wiremock will respond to your request with the mappings it has stored previously, and pretend to be Algolia. 🥸</p><p>While this does not shield you against breaking changes in the Algolia HTTP API, it does come with a few advantages:</p><ol><li>It shields you against breaking changes or bugs in the Algolia SDK.</li><li>You no longer have to mock the SDK, which is a bad practice and a pain to do. A consequence of that is that your tests become easier to understand, and more expressive, and that they check things at a higher level rather than focusing on implementation details.</li><li>It still means that at least once, you do run the tests against the real thing, so if there is some issue that can only be detected at runtime, you will know about it.</li></ol><p>Wiremock is a java application, but that shouldn't matter too much, especially given there is an <a href=\"https://hub.docker.com/r/wiremock/wiremock\" rel=\"noopener noreferrer\">official Docker image</a> you can use.</p><h2>\n  \n  \n  Testcontainers: Docker for your tests\n</h2><p>At ManoMano, we use Gitlab CI. While it is possible to define <a href=\"https://docs.gitlab.com/ci/services/\" rel=\"noopener noreferrer\">a Gitlab CI service</a> with the aforementioned Docker image, that's not a great solution because Gitlab services do not expose the full power of Docker. For instance, mounting a volume is not possible, probably not without heavy involvement of privileged users.</p><p>A great alternative is <a href=\"https://testcontainers.com\" rel=\"noopener noreferrer\">testcontainers</a> + <a href=\"https://testcontainers.com/cloud/\" rel=\"noopener noreferrer\">testcontainers Cloud</a>. Testcontainers is a library available in many languages that allows you to start and stop Docker containers during your tests, making it possible to get good isolation between tests.\nTestcontainers Cloud is a service that allows you to run said containers on a remote infrastructure, as opposed to running them on your own infrastructure, which, if you want to use Kubernetes runners for Gitlab, implies using Docker in Docker, which is not great from the security standpoint.<p>\nLocally, you would still use a local docker container, but in the CI,</p>\ntescontainers will send requests to testcontainers cloud, to start and stop containers. Enough unpaid endorsement, let's get to the code.</p><p>For the sake of brevity, I will not systematically show the entirety of a file I edit in all snippets, however I have tried to create one commit per step in <a href=\"https://github.com/greg0ire/wiremock-blogpost/commits\" rel=\"noopener noreferrer\">this Github repository</a>, in case you would like to play with the code or simply read it in your own editor.</p><div><pre><code>go mod init algolia-wiremock-testcontainers\n</code></pre></div><h3>\n  \n  \n  Installing the Algolia SDK\n</h3><div><pre><code>go get github.com/algolia/algoliasearch-client-go/v4\n</code></pre></div><h3>\n  \n  \n  Setting up the environment\n</h3><p>At this point, you will need to set up a test Algolia application. Once you are done, you should have an application ID and an API key.</p><p>Let us use an unversioned env file to store our credentials.</p><div><pre><code></code></pre></div><div><pre><code>changeme\nchangeme\n</code></pre></div><p>You will need to replace  and  with values from <a href=\"https://dashboard.algolia.com/account/api-keys\" rel=\"noopener noreferrer\">your account</a>.</p><h3>\n  \n  \n  Writing the code to be tested\n</h3><p>Let us take the code from Algolia's quickstart guide and split it into two files:</p><p>First, we have the code under test where the only changes are getting the environment variables from the actual environment, and renaming packages and functions.</p><div><pre><code></code></pre></div><p>To make it work, you will need to install the Algolia SDK:</p><div><pre><code>go get github.com/algolia/algoliasearch-client-go/v4\ngo mod tidy\n</code></pre></div><p>That call to  is what is going to take the most time, and a good reason not to use a real Algolia instance in your test suite. That's what we are going to try first though.</p><h3>\n  \n  \n  Writing the test with a real Algolia instance\n</h3><p>Let's start simple and write a first version of the test that talks directly to Algolia:</p><div><pre><code></code></pre></div><p>aaaaand that doesn't work:</p><div><pre><code>panic: The maximum number of retries exceeded. (50/50) [recovered]\n        panic: The maximum number of retries exceeded. (50/50)\n\ngoroutine 7 [running]:\ntesting.tRunner.func1.2({0x800600, 0xc00028d640})\n        /home/gregoire/.local/share/mise/installs/go/1.24.2/src/testing/testing.go:1734 +0x21c\ntesting.tRunner.func1()\n        /home/gregoire/.local/share/mise/installs/go/1.24.2/src/testing/testing.go:1737 +0x35e\npanic({0x800600?, 0xc00028d640?})\n        /home/gregoire/.local/share/mise/installs/go/1.24.2/src/runtime/panic.go:792 +0x132\nalgolia-wiremock-testcontainers.indexRecord()\n        /home/gregoire/Documents/blogging/wiremock/indexer.go:39 +0x166\nalgolia-wiremock-testcontainers.TestIndexRecord(0xc000198540)\n        /home/gregoire/Documents/blogging/wiremock/indexer_test.go:40 +0x20a\ntesting.tRunner(0xc000198540, 0x8a6c10)\n        /home/gregoire/.local/share/mise/installs/go/1.24.2/src/testing/testing.go:1792 +0xf4\ncreated by testing.(*T).Run in goroutine 1\n        /home/gregoire/.local/share/mise/installs/go/1.24.2/src/testing/testing.go:1851 +0x413\nFAIL    algolia-wiremock-testcontainers 185.745s\nFAIL\n</code></pre></div><p>I have many applications on this instance, some of which are very busy, let us patch that real quick:</p><div><pre><code>// Wait until indexing is done\n_, err = client.WaitForTask(\n    indexName,\n    saveResp.TaskID,\n    search.WithMaxRetries(100),\n)\n</code></pre></div><p>Exactly the type of thing that unit tests will not catch.</p><p>After that, the test passes (but it takes between several seconds or several minutes to run depending on how busy the instance on which the application is running is). Great! Now, let's add a proxy in the middle, and record all this.</p><h3>\n  \n  \n  Adding Wiremock in record mode 📼\n</h3><p>We are using Docker, so if we want to obtain the so-called \"mapping files\" Wiremock will create, we need to mount a volume on our Docker container, and mount it in the right location.</p><p>Let us add 2 new dependencies to our project:</p><p>We could interact with Wiremock by calling the REST API with the  package, but as it turns out, there is a dedicated SDK for that, and it supports recording since <a href=\"https://github.com/wiremock/go-wiremock/pull/33\" rel=\"noopener noreferrer\">this pull request I sent</a>.</p><p>At the time of writing, the PR is merged but not released yet, so for now, let's use a commit hash:</p><div><pre><code>go get github.com/wiremock/go-wiremock@v1.13.0\n</code></pre></div><p>Next, we will need a way to start and stop the Wiremock container, and for that\nas well, there is a library:</p><div><pre><code>go get github.com/wiremock/wiremock-testcontainers-go@v1.0.0-alpha-11\n</code></pre></div><p>Yes, this is alpha software 😬</p><p>Let us start the container, with a volume mounting  in the current directory on  in the container. This is where Wiremock will create json files.</p><div><pre><code></code></pre></div><p>Next, we need to change how we instantiate the Algolia client, so that it calls Wiremock instead of Algolia:</p><div><pre><code></code></pre></div><p>Note that I have renamed the client to  to avoid confusion with the Algolia client and the Wiremock client.</p><p>Let us also refactor our  function to take the client as an argument:</p><div><pre><code></code></pre></div><p>Next, let's start the recording, and for that we need a client to call Wiremock's administration API:</p><div><pre><code></code></pre></div><p>Now, let's run our tests again, check our  directory, and see what's new.</p><div><pre><code> testdata\n</code></pre></div><p>… OK that is quite a lot of files. 😅 As mentioned earlier, a lot of them are about polling.</p><p>Let's find the one that we should keep:</p><div><pre><code> published testdata/task</code></pre></div><p>After removing the files with , we are left with the following mapping files:</p><div><pre><code> testdata\n</code></pre></div><h3>\n  \n  \n  Switching to playback mode 📺\n</h3><p>Now that we have our mapping files, we can switch to playback mode. Let us introduce a constant to turn recording and Algolia debugging on and off:</p><div><pre><code></code></pre></div><p>Note that I also moved the call to  to the recording block, when replaying the tests, we do not really need to clutter the output with Algolia debug information.</p><p>And now the test fails, with a rather clear error: apparently deleting the files was not enough, and we need to also edit the scenario name to outline that this is no longer the 43rd attempt.</p><div><pre><code>--- FAIL: TestIndexRecord (1.87s)\npanic: API error [404]\n                                                       Request was not matched\n                                                       =======================\n\n        -----------------------------------------------------------------------------------------------------------------------\n        | Closest stub                                             | Request                                                  |\n        -----------------------------------------------------------------------------------------------------------------------\n                                                                   |\n        1_indexes_test-index_task_226434943725                     |\n                                                                   |\n        GET                                                        | GET\n        /1/indexes/test-index/task/226434943725                    | /1/indexes/test-index/task/226434943725\n                                                                   |\n        [Scenario                                                  | [Scenario                                           &lt;&lt;&lt;&lt;&lt; Scenario does not match\n        'scenario-1-1-indexes-test-index-task-226434943725'        | 'scenario-1-1-indexes-test-index-task-226434943725'\n        state:                                                     | state: Started]\n        scenario-1-1-indexes-test-index-task-226434943725-43]      |\n                                                                   |\n        -----------------------------------------------------------------------------------------------------------------------\n         [recovered]\n        panic: API error [404]\n                                                       Request was not matched\n                                                       =======================\n\n        -----------------------------------------------------------------------------------------------------------------------\n        | Closest stub                                             | Request                                                  |\n        -----------------------------------------------------------------------------------------------------------------------\n                                                                   |\n        1_indexes_test-index_task_226434943725                     |\n                                                                   |\n        GET                                                        | GET\n        /1/indexes/test-index/task/226434943725                    | /1/indexes/test-index/task/226434943725\n                                                                   |\n        [Scenario                                                  | [Scenario                                           &lt;&lt;&lt;&lt;&lt; Scenario does not match\n        'scenario-1-1-indexes-test-index-task-226434943725'        | 'scenario-1-1-indexes-test-index-task-226434943725'\n        state:                                                     | state: Started]\n        scenario-1-1-indexes-test-index-task-226434943725-43]      |\n                                                                   |\n        -----------------------------------------------------------------------------------------------------------------------\n</code></pre></div><p>After dropping <code>\"requiredScenarioState\" : \"scenario-1-1-indexes-test-index-task-226434943725-43\",</code> from the mapping file about polling, the test passes again, only this time, it passes in under 2 seconds.\nIt is possible to mention which scenario a mapping belongs to, allowing to do things like \"On the first 2 calls respond A, and on the 3rd return B\". Based on that, it is possible to build a complex choreography of requests/responses, fulfilling all sorts of requirements.</p><p>After pushing the code, I got a bad surprise: the test fails in the CI, with the following message:</p><div><pre><code>tc-wiremock.go:73: create container: container create: Error response from daemon: Invalid bind mount config: mount source \"/builds/product-discovery/ms.indexer/internal/import/brandsuggestion/testdata\" is forbidden by the allow list [/home /tmp] - update the bind mounts configuration and restart the agent to enable\n</code></pre></div><p>It would seem that we cannot use a bind mount in the CI. Let us use our  constant to make the container options conditional:</p><div><pre><code></code></pre></div><p>When recording, we mount the volume, which is not an issue because we are not in the CI.\nOtherwise, we use the  function which relies on a copy operation.<a href=\"https://pkg.go.dev/github.com/wiremock/wiremock-testcontainers-go#WithMappingFile\" rel=\"noopener noreferrer\">That function</a> is provided by the<code>wiremock-testcontainers-go</code> library, which abstracts away the low-level testcontainers API so that we can think in terms of mapping files rather than just JSON files.</p><p>Not super satisfying, but it works.</p><p>The test is a bit long now, but some parts look generic and reusable. Let us extract them to helpers.</p><div><pre><code></code></pre></div><p>And now our test fits on a single screen 🙂\nI also added an extra assertion just to be sure we get the expected record, and that's OK, since it does not mean extra calls to Algolia.<p>\nNow that we have paid the cost of writing that first step, writing more tests should be easier, and bring a lot of value to the project.</p></p>","contentLength":16240,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Memory Stick: The Gum-Shaped Star of a Forgotten Tech Planet","url":"https://dev.to/ersajay/memory-stick-the-gum-shaped-star-of-a-forgotten-tech-planet-2hp6","date":1750401405,"author":"ersajay","guid":163337,"unread":true,"content":"<p>A Meeting in the Circuit Desert\nWhen I first wandered into the desert of old cameras and dusty laptops, I thought all storage devices were like the ones I’d seen—shiny, loud, and eager to prove their worth. But then I spotted it: a small, rectangular shape, half-buried in sand like a forgotten piece of gum.<p>\n“You’re… unusual,” I said, kneeling.</p>\n“And you’re a child who talks to memory sticks,” it replied, its surface glinting faintly. “But some things outlive their planets. Ask the fox.”</p><p>The Gum That Outlived Floppy Disks\nThis wasn’t just plastic and circuits—it was a <a href=\"https://www.ersaelectronics.com/blog/what-is-a-memory-stick\" rel=\"noopener noreferrer\">Memory Stick</a>📀, born in 1998 on a tech planet called Earth. Let me decode its story:</p><p>PRO Duo: Smaller, faster (32GB max), used in PSPs and cameras—like a sparrow in a world of eagles.\nPRO-HG: High-speed for HD camcorders (now as rare as a baobab in the desert).<p>\nM2 Micro: Tiny for phones, but SD cards “won” (like a cactus losing to a rose in a garden).</p></p><p>Fun Fact: Shaped like gum, but it won’t melt in your car (unlike floppy disks, which dissolved like sugar in rain).</p><p>“Why gum?” I asked.\n“Sony thought it’d fit in pockets,” it said. “Turns out, it fit in hearts too.”</p><p>The Rose of a Closed Garden\nOn its home planet, the Memory Stick wasn’t just storage—it was a rose. Sony planted it in an exclusive garden: cameras, <a href=\"https://www.ersaelectronics.com/\" rel=\"noopener noreferrer\">VAIO laptops</a>, PSPs. No other flowers allowed.\n“Why so picky?” I asked.<p>\n“Ecosystem lock-in,” it said. *“Like a garden where only one rose blooms. It kept pirates out, too—MagicGate encryption for NSYNC MP3s. Even thieves love boy bands.”</p>\nBut time passed. SD cards, the “universal” daisies, spread everywhere. Yet the Memory Stick survived—not because it was better, but because some gardens still needed its thorns: legacy medical gear, satellites, and retro gamers who whispered, “I remember when you were new.”\nSD Card: “I’m universal!”<p>\nMemory Stick: “I’m in satellites. You cry in radiation.” 🚀</p></p><p>How to Love a Forgotten Star (In 2025)\nEven old stars need care. Here’s how to keep a Memory Stick alive:</p><p>Adapters: Use a $5 “PRO Duo to SD” adapter—like teaching a cactus to grow in a new pot. Plug it into your laptop, and voilà: it speaks modern.\nFormatting: Right-click, “Format,” choose FAT32. It’s like watering a desert plant—simple, but critical.<p>\nBad NVMe?: Swap with a new drive. The Memory Stick won’t judge—its era was about loyalty, not upgrades.</p></p><p>“Do you miss the old days?” I asked.\n“Not really,” it said. “I’m just glad I still matter. Some roses don’t need gardens to bloom.”</p><p>Where to Find a Memory Stick (2025 Edition)\nIn 2025, it’s a treasure hunt:</p><p>New: Amazon or B&amp;H Photo (Sony still sells them for industrial clients—like a baker keeping a rare recipe).\nUsed: eBay (vintage PSP bundles) or Akihabara (Japan’s tech desert, where nostalgia costs extra).<p>\nAdapters: $5-$10 on Amazon. Avoid “Rare Sony Stick!!” listings—they’re like overpriced baobab seeds.</p></p><p>Pro Tip: A 32GB Memory Stick costs $50? Walk away. It’s not gold—it’s just a gum-shaped star.</p><p>The Tale of Two Planets\nOnce, I met an SD card in the desert. We compared notes:</p><p>Capacity: SD holds 2TB (a mansion), Memory Stick 32GB (a cozy hut).\nSpeed: SD zips at 300MB/s (a cheetah), Memory Stick crawls at 20MB/s (a snail).<p>\nPrice: SD is $20 for 1TB (a market stall), Memory Stick $50 for 32GB (a boutique).</p></p><p>“Why do people still choose you?” the SD card asked.\n“Because some things aren’t about size or speed,” the Memory Stick said. “They’re about history. And loyalty.”</p><p>The Star That Still Lights Up Skies\nIn hidden corners of the universe, the Memory Stick glows:</p><p>Medical: Stores patient data in Sony MRI machines—steady as a heartbeat.\nAerospace: Survives radiation in satellites—tougher than a desert storm.<p>\nRetro Gaming: PSP fans hoard them like rare stars—because some games only speak its language.</p></p><p>Burn Alert:\nUSB Drive: “I’m cheaper!”<p>\nMemory Stick: “I’m in the Smithsonian. You’re in a conference swag bag.” 🏛️</p></p><p>The Secret of the Gum-Shaped Star\nThe Memory Stick isn’t flashy. It doesn’t need a new planet or a trendy name. It’s the kind of friend you remember when you dust off an old PSP, or find an unopened pack in a drawer.<p>\n“What makes you special?” I asked, as I left.</p>\nIt didn’t answer. It just sat there, quiet as the desert, as the stars, as time itself.<p>\nAnd I realized—some things outlive their purpose. They become stories. And stories never die.</p></p><p>Written by a wanderer who once mistook a Memory Stick for gum. (Spoiler: It didn’t taste good. But it lasted longer.)\n🌵 You become responsible, forever, for the stars you once loved.</p>","contentLength":4698,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Step-by-step guide on how to create a DCA bot on Go using the Binance API","url":"https://dev.to/zmey56/step-by-step-guide-on-how-to-create-a-dca-bot-on-go-using-the-binance-api-52bb","date":1750391002,"author":"Zmey56","guid":163292,"unread":true,"content":"<p>There are many ways to invest in crypto. Some try to catch the \"bottom\" and go all-in, others trade based on candlesticks and indicators. And then there are those - a growing number - who use the DCA (Dollar-Cost Averaging) strategy, or simply put, averaging. The idea is simple: you buy cryptocurrency for a fixed amount at regular intervals - for example, once a day or once a week. It doesn't matter whether the market is up or down - you keep buying. In the long run, this helps smooth out volatility and reduce risk.</p><p>Why does it work? Because no one can predict the bottom with precision. But with DCA, you take emotions out of the equation and enter the market gradually, at average prices. This works especially well in a rising market - for instance, in Bitcoin's case, this strategy has outperformed \"buy and hold\" when entering at the peak.</p><p>Now - why Go? The answer is simple: if you've ever written anything in Go, you know the language is all about performance, simplicity, and concurrency. Need a bot that runs reliably 24/7, connects to the Binance API, tracks timing, and sends orders precisely? Go is a perfect fit. Low memory usage, high speed, ease of maintenance - exactly what a trading tool needs.</p><h2>\n  \n  \n  What We're Going to&nbsp;Build\n</h2><p>Before we start coding, let's clarify what exactly our DCA bot will be capable of and how it works under the hood. Our goal isn't just a basic \"quick and dirty\" example, but a fully functional tool that can be developed, scaled, and safely used.</p><h4>\n  \n  \n  Multiple Trading Pairs Support\n</h4><p>You'll be able to configure multiple coins - for example, simultaneously buying BTC, ETH, and SOL. This is convenient if you're building a diversified crypto portfolio and want to run averaging separately for each coin.</p><h4>\n  \n  \n  Flexible Purchase Scheduling\n</h4><p>Want to buy every day at 10 AM? Or every Monday? Or even every hour? - No problem. The bot will use a built-in scheduler (via cron or time.Ticker) that lets you define the desired frequency for each trading pair.</p><h4>\n  \n  \n  Customizable Purchase Amount\n</h4><p>You set the purchase amount yourself. It can be a fixed amount in USDT - for example, $50 for BTC, $20 for ETH, etc. The settings are stored in a config file, making them easy to adjust.</p><h4>\n  \n  \n  Balance Check and Logging\n</h4><p>Before each purchase, the bot will check if there's enough USDT in your account. Everything that happens - successful trades, errors, insufficient funds, Binance API behavior - gets logged. If something goes wrong, you'll see it right away.</p><h4>\n  \n  \n  Minimal UI via CLI or Optional REST\n</h4><p>You'll be able to launch and manage the bot through a CLI interface - running with parameters, viewing logs, checking current status. If desired, you can easily add a REST API for control via a browser or mobile app.</p><p>To make everything work reliably and be easy to maintain, we'll break the project into several logical components:</p><ul><li>Handles communication with the exchange: authentication, order placement, balance retrieval.</li></ul><ul><li>Task scheduler. Responsible for triggering purchases on time according to the defined schedule.</li></ul><ul><li>Core component: checks balance, places orders, logs the results.</li></ul><ul><li>Stores the history of all actions and errors. Can write to a file, stdout, or even a database.</li></ul><ul><li>Easy configuration via&nbsp;.env/yaml/json files and management through the command line.</li></ul><p>In the end, you'll have not just a script, but a foundation for a real microservice that you can extend with strategies, notifications, a web interface, and analytics. Built the right way - with tests, logs, and an architecture that can scale.</p><p>Before the bot can start trading, we need to set up the environment: install Go, add dependencies, configure access to the Binance API, and prepare our configuration.</p><p><strong>Installing Go and Initializing the&nbsp;Project</strong></p><p>You'll need to have Go installed. I'm using version 1.24.2, but any recent version will do.</p><p>After installing Go, you can either clone the repository or create the project manually:</p><div><pre><code>git clone https://github.com/Zmey56/dca-bot.git\ndca-bot\n</code></pre></div><p>If you're starting the project from scratch:</p><div><pre><code>dca-bot\ndca-bot\ngo mod init github.com/yourusername/dca-bot\n</code></pre></div><p>The project uses three main libraries:</p><div><pre><code></code></pre></div><ul><li>go-binance/v2 - handles communication with Binance: balances, orders, price quotes.</li><li>cron/v3 - allows scheduling tasks (e.g., placing an order every 24 hours).</li><li>godotenv - safely loads environment variables (API keys and settings are stored in&nbsp;.env instead of being hardcoded).</li></ul><p>If you already have a go.mod file, simply run:</p><p><strong>Working with&nbsp;.env and Binance API&nbsp;Keys</strong></p><p>To connect to Binance, you'll need an API key and secret. You can get them from your Binance account settings.</p><p>Create a&nbsp;.env file in the root of the project and add the following:</p><div><pre><code>your_api_key_here\nyour_secret_key_here\n0.001\n</code></pre></div><p><strong><em>Make sure to add&nbsp;.env to your&nbsp;.gitignore to prevent the keys from accidentally being committed to a public repository.</em></strong></p><p><strong>Connecting the Configuration and Binance&nbsp;Client</strong></p><p>The project includes a module internal/binance with a ClientWrapper implementation. It wraps the official Binance client and provides convenient methods like GetBalance and CreateMarketOrder.</p><p>Client initialization looks like this:</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>Now you can safely interact with the Binance API - no hardcoded keys, no violations of clean architecture principles.</p><h2>\n  \n  \n  Integration with the Binance&nbsp;API\n</h2><p>At this point, our bot can already launch, read configuration from&nbsp;.env, and has a clear structure. Now it's time to connect to Binance so the bot can check balances and place orders. We'll do this using the prebuilt module internal/binance, which wraps the official go-binance/v2 library.</p><h4>\n  \n  \n  Creating the Binance&nbsp;Client\n</h4><p>First, we need to initialize the Binance client. We have two constructors for this:</p><ul><li>NewBinanceClient() - creates a raw client using your API keys;</li><li>NewClientWrapper() - wraps it into our custom interface with methods like GetBalance and CreateMarketOrder.</li></ul><div><pre><code></code></pre></div><p>Now client is our main tool for interacting with the exchange.</p><h4>\n  \n  \n  Getting Balance Information\n</h4><p>Before making any purchases, the bot needs to check if there's enough available funds in the account. For example, checking the USDT balance:</p><div><pre><code></code></pre></div><p>This method calls GET /api/v3/account, parses the list of assets, and returns the value as a float64. Simple and effective.</p><p>Now for the most important part - making a purchase. We're sending a market order, which tells Binance: \"Buy the coin right now at the current market price.\"</p><div><pre><code></code></pre></div><p>The quantity must be rounded to the correct number of decimal places. This is already handled inside the method using fmt.Sprintf(\"%.6f\", quantity).</p><h4>\n  \n  \n  Handling Errors and Rate&nbsp;Limits\n</h4><p>Binance imposes a rate limit on API calls per minute. If we exceed it, the API will return a Too many requests error (code -1003). The SDK doesn't expose a dedicated error type for this, so we handle it by checking the error text directly:</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>Now that we know how to work with the Binance API - getting the balance and sending orders - it's time to put everything together and implement the actual DCA logic: buying a selected coin on a schedule, for a specified amount, without crashing in the process.</p><h4>\n  \n  \n  Configuration: pair, amount, frequency\n</h4><p>To let the bot know what to buy, how much, and when, we need a simple configuration. No YAML or databases for now - just set everything in&nbsp;.env, for example:</p><div><pre><code></code></pre></div><p>In Go, we read it like this:</p><div><pre><code></code></pre></div><blockquote><p>The frequency can be set either via cron (robfig/cron/v3) or using time.Ticker if you want a simple interval (e.g. every 6 hours).</p></blockquote><h4>\n  \n  \n  Main cycle: what the bot does at each&nbsp;trigger\n</h4><p>Each time the scheduled trigger fires, the bot follows a simple flow:</p><p><strong>Get the current price (optional, but useful for logs)</strong></p><div><pre><code></code></pre></div><blockquote><p>The GetCurrentPrice method can be implemented using NewListPricesService().Symbol(symbol) - see go-binance/v2 → Get Price.</p></blockquote><p>Before buying anything, make sure there's enough USDT available:</p><div><pre><code></code></pre></div><p>If everything checks out - send a market order:</p><div><pre><code></code></pre></div><p>All key actions and errors are logged. Writing to file or stdout is enough for now. Later we can add CSV or SQLite support if needed for history.</p><h4>\n  \n  \n  Example: running on a&nbsp;schedule\n</h4><p>We use github.com/robfig/cron/v3 to run the buy logic once a day:</p><div><pre><code></code></pre></div><p>If you want something simpler - you can use time.Ticker:</p><div><pre><code></code></pre></div><p>Developing the bot is only half the job. To make sure it runs reliably and doesn't buy crypto randomly, we need to ensure that:</p><ul><li>the logic works correctly,</li><li>everything can be tested in isolation,</li><li>and errors are easy to catch.</li></ul><h4>\n  \n  \n  Simple Unit Tests with&nbsp;testing\n</h4><p>First things first - basic unit tests for core business logic. For example, if you move the calculation of the buy amount or interval into a function, it's easy to test it with the standard library:</p><div><pre><code></code></pre></div><p>Test files are named something_test.go and live alongside the source files.</p><h4>\n  \n  \n  Mocks for the Binance&nbsp;API\n</h4><p>Binance is an external system - we don't want to make real trades in our tests. That's why we declared an interface in internal/binance/interface.go:</p><div><pre><code></code></pre></div><p>Now we can mock this interface using Uber's mock library:</p><div><pre><code>go go.uber.org/mock/mockgen@latest \n</code></pre></div><div><pre><code></code></pre></div><p>Then, in tests, we can use the fake implementation:</p><div><pre><code></code></pre></div><h4>\n  \n  \n  Logging to File and&nbsp;Console\n</h4><p>During debugging, it's important to see what's happening. By default, everything is printed to the console with log.Println(), but you can easily add file output too:</p><div><pre><code></code></pre></div><p>Now all logs will go both to the terminal and to dca.log - handy for both production use and debugging.</p><p>At this point, we already have a working DCA bot that, on schedule, logs into Binance, checks the balance, and sends market orders. All that's left is to launch it properly, observe how it runs, and make sure we don't forget about security.</p><p>The project is built like a standard Go application. The entry point is cmd/dca-bot/main.go.</p><div><pre><code>go build  dca-bot ./cmd/dca-bot\n./dca-bot\n</code></pre></div><p><strong>Run as a Background Service</strong></p><p>You can use , , , or simply:</p><div><pre><code> ./dca-bot  output.log 2&gt;&amp;1 &amp;\n</code></pre></div><p>This way, the bot will run in the background and log everything to .</p><p>All actions are logged both to the console and to the file dca.log. For example:</p><div><pre><code>🚀 Bot started\n📅 Scheduler initialized\n🕒 Time to buy!\n📊 Current price BTCUSDT: 63784.12\n💰 Available USDT balance: 25.00\n✅ Bought 0.001 BTCUSDT\n</code></pre></div><div><pre><code>⚠️ Rate limit exceeded. Waiting 2 seconds...\n❌ Purchase error: request rate limit exceeded\n</code></pre></div><p>Logs are useful both in development and in production. You can easily set up log rotation using logrotate or configure log forwarding to  - totally up to you.</p><h4>\n  \n  \n  Security: Keys and&nbsp;Limits\n</h4><ol><li>API keys are stored in&nbsp;, not hardcoded - that's already good.</li><li> is added to&nbsp;, so it won't accidentally get pushed to GitHub.</li><li>The bot  or , it simply acts as an \"averaging\" worker.</li><li>To avoid getting banned by Binance:</li></ol><ul><li>we handle errors and use sleep when hitting rate limits;</li><li>we avoid unnecessary API calls;</li><li>you can use a proxy or an API key with limited permissions (e.g., trade-only).</li></ul><p>In the end, we've built a minimalistic yet functional DCA bot in Go that does one simple thing - buys crypto on a schedule. It can connect to Binance, check balances, send orders, log activity, and run either manually or as a background service. Everything is written from scratch with clean architecture and room for expansion.</p><p>If you want more than just scheduled buys - there's plenty of room to grow:</p><ul><li>QFL (Quickfingers Luc) Strategy - the bot can buy not just by time, but in pullback zones;</li><li>Add MACD, EMA, or RSI - to enter only when the market sends a signal;</li><li>Telegram Notifications - know when a buy is made;</li><li>Purchase history in SQLite or CSV - to analyze performance later;</li><li>Visualization via Grafana or Prometheus - for dashboard lovers;</li><li>More tests and integrations - e.g., with testcontainers-go for CI-ready setups.</li></ul><p>You can find the complete bot code (and a bit more) in my <a href=\"https://github.com/Zmey56/dca-bot\" rel=\"noopener noreferrer\">repository</a>. Everything is well structured: cmd, internal, tests, logic,&nbsp;.env - clone and run.</p><h4>\n  \n  \n  Alternative: Ready-Made Bots on&nbsp;Bitsgap\n</h4><p>Want to try out DCA or other strategies (like Grid, Combo, or Trailing) but don't feel like writing code, dealing with APIs, or setting everything up manually? There's an easier way: just sign up on Bitsgap using my referral </p><p>I personally use Bitsgap for part of my portfolio - it's convenient, visual, and helps you catch good entry points. Plus, you can try the PRO plan free for 7 days to see how everything works in real market conditions without taking unnecessary risks.</p><p>By signing up through my link, you'll also be supporting my next project - a free Telegram bot that provides DCA trading signals for manual execution. The more support it gets, the sooner it will be ready!!!</p>","contentLength":12632,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[Boost]","url":"https://dev.to/gillarohith/-3nkj","date":1750386821,"author":"Rohith Gilla","guid":163252,"unread":true,"content":"<h2>Page Zen: The Open-Source Article Cleaning API You've Been Waiting For</h2>","contentLength":70,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advanced Go Concurrency: Unleashing Lock-Free Data Structures for Real-World Wins","url":"https://dev.to/jones_charles_ad50858dbc0/advanced-go-concurrency-unleashing-lock-free-data-structures-for-real-world-wins-1ha0","date":1750380627,"author":"Jones Charles","guid":163228,"unread":true,"content":"<h2>\n  \n  \n  Hey, Let’s Talk Concurrency\n</h2><p>If you’re a Go developer, you’ve probably fallen in love with  and —they’re like the peanut butter and jelly of concurrent programming. Lightweight, elegant, and oh-so-satisfying. But here’s the catch: when you crank up the heat—say, an API handling 100k requests per second—those trusty tools can hit a wall. Enter the villain of the story: . Traditional locking with  starts feeling like a traffic jam—goroutines pile up, performance tanks, and you’re left wondering where it all went wrong.</p><p>That’s where <strong>lock-free data structures</strong> swoop in like a superhero. No locks, no queues, just pure, unadulterated speed using atomic operations. Imagine swapping a clunky toll booth for an open highway—threads zoom through, following simple rules to avoid crashes. It’s a game-changer for high-concurrency apps, from real-time dashboards to distributed systems.</p><p>This isn’t some ivory-tower lecture—I’m here to hand you the keys to lock-free programming with practical, hands-on examples. Whether you’ve got a year of Go under your belt or you’re a concurrency newbie looking to level up, this guide’s got you covered. We’ll skip the yawn-inducing theory and jump straight into code you can tweak, test, and deploy.</p><p>Here’s what you’ll walk away with:</p><ul><li>: Ditch the \"lock everything\" habit for smarter collaboration.</li><li>: Build lock-free counters, queues, and maps that crush bottlenecks.</li><li>: Avoid the gotchas I’ve learned the hard way.</li></ul><p>Picture this: you’re tracking API hits in real time. A -protected counter works fine until traffic spikes—suddenly, your goroutines are stuck in line, and latency skyrockets. Swap it for a lock-free counter with , and boom—same workload, no sweat. That’s just a taste of what’s possible.</p><p>Ready to roll? We’ll kick off with the basics, then build up to a full-blown case study. Buckle up—this is gonna be fun!</p><h2>\n  \n  \n  Lock-Free : What’s the Big Deal?\n</h2><p>So, what’s this lock-free hype all about? Imagine a world where your goroutines don’t have to wait in line behind a —no blocking, no drama, just smooth sailing. That’s the promise of <strong>lock-free data structures</strong>. They ditch locks for atomic operations, letting threads play nice without stepping on each other’s toes. Let’s break it down and see why they’re a concurrency superpower in Go.</p><h3>\n  \n  \n  1. Lock-Free in a Nutshell\n</h3><p>A  keeps things thread-safe without the old-school lock-and-key routine. Instead of , it leans on —think tiny, unbreakable CPU-level moves like Compare-And-Swap (CAS). Locks are like a bouncer at a club: one thread at a time, everyone else waits. Lock-free? It’s more like a dance floor—everyone’s moving, but the rules (atomic ops) keep it from turning into chaos.</p><div><table><thead><tr></tr></thead><tbody><tr><td>Keeps dancing (non-blocking)</td></tr><tr></tr><tr></tr><tr><td>ABA quirks (more on that later)</td></tr></tbody></table></div><p>The kicker? Lock-free doesn’t nap—if a thread stumbles, it retries instead of snoozing, which is gold in high-traffic scenarios.</p><h3>\n  \n  \n  2. The Secret Sauce: Atomic Operations\n</h3><p>Atomic operations are the magic behind lock-free. They’re like ninja moves—fast, precise, and guaranteed to finish without interruption. Go’s  package hands you these tools:</p><ul><li>: Swap a value if it matches what you expect.</li><li>: Bump a number up or down, no fuss.</li><li>: Peek or poke safely.</li></ul><h4>\n  \n  \n  Hands-On: A Lock-Free Counter\n</h4><p>Let’s see it in action with a counter that laughs at concurrency:</p><div><pre><code></code></pre></div><ul><li> bumps the counter atomically—every goroutine gets its turn without clashing.</li><li>Compared to a , there’s no waiting room. It’s lean, mean, and blazing fast.</li></ul><h4>\n  \n  \n  Sneak Peek Under the Hood\n</h4><div><pre><code>Start: counter = 0\nGoroutine 1: atomic.AddInt64 -&gt; 1\nGoroutine 2: atomic.AddInt64 -&gt; 2\nGoroutine 3: atomic.AddInt64 -&gt; 3\n</code></pre></div><p>No overwrites, no mess—atomic ops keep it clean.</p><p>Lock-free brings three big wins:</p><ul><li>: No lock fights mean goroutines fly, slashing latency in high-concurrency apps.</li><li>: Add more goroutines, and it just keeps humming—unlike locks, which choke.</li><li>: Say goodbye to deadlocks forever.</li></ul><p>Real talk: I once swapped a  for  in a stats tracker under 100k QPS. Latency dropped from 10ms to 3ms—like flipping a turbo switch.</p><p>It’s not always the answer, but it shines when:</p><ul><li>: Counters or queues getting hammered by reads and writes.</li><li>: Think real-time dashboards or game servers.</li><li>: Single-step updates, not big transactions.</li></ul><p>For gnarly multi-step stuff—like updating a database record—stick with locks or channels. Lock-free’s a scalpel, not a sledgehammer.</p><p>Ready for more? Next up, we’ll build some lock-free goodies you can drop into your projects!</p><h2>\n  \n  \n  Lock-Free Toolbox: Counters, Queues, and Maps in Go\n</h2><p>Now that we’ve got the lock-free basics down, let’s get our hands dirty. Go’s  package is like a LEGO set for building concurrent awesomeness—simple pieces, endless possibilities. We’ll whip up three lock-free classics: a counter, a queue, and a map. Each comes with code you can steal and a breakdown of why it rocks.</p><h3>\n  \n  \n  1. Lock-Free Counter: The Concurrency Champ\n</h3><p>Need to count API hits or tasks without choking under pressure? A lock-free counter is your MVP. It’s stupidly simple and scales like a dream when goroutines come knocking.</p><div><pre><code></code></pre></div><ul><li>: Adds 1 without a hiccup, no matter how many goroutines pile on.</li><li>: Grabs the value safely, no race conditions.</li><li>: Zero contention, max speed—perfect for real-time stats.</li></ul><div><pre><code>Start: value = 0\nGoroutine 1: +1 -&gt; 1\nGoroutine 2: +1 -&gt; 2\n...\nGoroutine 1000: +1 -&gt; 1000\n</code></pre></div><h3>\n  \n  \n  2. Lock-Free Queue: Task Master\n</h3><p>Got producers and consumers passing tasks like hot potatoes? A lock-free queue keeps the line moving without the lock-based bottleneck. Think job schedulers or message pipelines.</p><h4>\n  \n  \n  Code Time (Simplified Enqueue)\n</h4><div><pre><code></code></pre></div><ul><li>:  locks nothing, just retries if it misses.</li><li>: Keeps going until the stars align.</li><li>: This skips dequeue and the ABA problem (we’ll tackle that later)—real-world queues need more polish.</li></ul><div><pre><code>Start: head -&gt; [dummy] -&gt; tail\nEnqueue 1: head -&gt; [dummy] -&gt; [1] -&gt; tail\nEnqueue 2: head -&gt; [dummy] -&gt; [1] -&gt; [2] -&gt; tail\n</code></pre></div><h3>\n  \n  \n  3. Lock-Free Map: Key-Value Ninja\n</h3><p>Caching or tracking key-value pairs in a write-heavy app? A lock-free map beats  when writes dominate—like a real-time leaderboard.</p><h4>\n  \n  \n  Code Time (Sharded Edition)\n</h4><div><pre><code></code></pre></div><ul><li>: Splits the map into buckets, cutting down fights.</li><li>: Swaps the whole bucket atomically—thread-safe and slick.</li><li>: Shines in write-heavy chaos;  rules for reads.</li></ul><div><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr></tbody></table></div><p>Next up: tips to wield these tools like a pro!</p><h2>\n  \n  \n  Lock-Free Like a Pro: Tips and Tricks That Stick\n</h2><p>Lock-free data structures are awesome, but they’re not plug-and-play. Going from “locks everywhere” to “lock-free wizard” takes some finesse. After years of wrestling Go concurrency, here’s my battle-tested playbook—how to switch, what to pick, and how to dodge the landmines.</p><h3>\n  \n  \n  1. From Locks to Lock-Free: A Smooth Jump\n</h3><h4>\n  \n  \n  Real Talk: API Stats Overhaul\n</h4><p>I once had an API stats tracker choking at 100k QPS— was the bottleneck, spiking latency from 2ms to 15ms. Swapped it for a lock-free counter, and bam—problem solved. Here’s how I pulled it off:</p><ul><li>: Ditched  for <code>atomic.AddInt64(&amp;counter, 1)</code>.</li><li>: Hammered it with unit tests to ensure no counts got lost.</li><li>: Ran —QPS jumped 30%, latency crashed to 3ms.</li></ul><p>: Start with something small—like a counter—and build your lock-free chops from there.</p><h3>\n  \n  \n  2. Pick the Right Tool for the Job\n</h3><p>Lock-free isn’t one-size-fits-all. Here’s the cheat sheet:</p><ul><li> Use —zero-cost reads for stuff like configs that barely change.</li><li> Go sharded with CAS—like the map we built. It thrives under pressure.</li><li> Default to —it’s easy and solid for mixed workloads.</li></ul><div><table><tbody><tr></tr><tr></tr><tr></tr></tbody></table></div><p>: Kick off with , then level up to custom lock-free when you hit a wall.</p><h3>\n  \n  \n  3. Tune It Up: Test and Tweak\n</h3><ul><li>: Fire up  to see what’s cooking.\n</li></ul><div><pre><code>  go BenchmarkCounter 5s\n</code></pre></div><ul><li>: Use  to sniff out goroutine jams or CPU hogs.\n</li></ul><div><pre><code>  go cpu.out\n  go tool pprof cpu.out\n</code></pre></div><p>Our lock-free queue was burning CPU with CAS retries under heavy enqueues. Fix? Split it into 4 shards by hashing goroutines—contention dropped 70%, throughput soared 40%. Tools like  were clutch for spotting the mess.</p><p>:  to catch leaks—trust me, you’ll thank me later.</p><p>Lock-free’s got quirks—here’s how I learned the hard way:</p><ul><li>: A lock-free map with crazy writes had CAS failing 90% of the time—slower than locks!</li><li>: Sharded it. Retry rate fell to 20%, performance doubled.</li><li>: CAS loves low contention—shard or step back if it’s a war zone.</li></ul><h4>\n  \n  \n  Trap 2: The Sneaky ABA Problem\n</h4><ul><li>: A queue’s dequeue missed ABA—pointer flipped A-&gt;B-&gt;A, duplicating tasks.</li><li>: Added a version tag:\n</li></ul><div><pre><code></code></pre></div><ul><li>: Complex structures need ABA armor—version tags save the day.</li></ul><div><pre><code>Start: head -&gt; [A]\nDequeue A: head -&gt; [B]\nEnqueue A: head -&gt; [A]\nNo Tag: CAS gets fooled\nWith Tag: Tag says “nah,” retry kicks in\n</code></pre></div><p>Next stop: a full-on case study to tie it all together!</p><h2>\n  \n  \n  Lock-Free in the Wild: Saving a Task Scheduler\n</h2><p>Lock-free isn’t just theory—it’s a lifeline for real problems. Let’s dive into how I used a lock-free queue to rescue a distributed task scheduler from a concurrency meltdown. This is the full scoop: problem, solution, code, and results.</p><h3>\n  \n  \n  1. The Mess We Started With\n</h3><p>We had a task scheduler dishing out millions of daily jobs—think log crunching or data scrubbing—across worker nodes. Producers dumped tasks into a central queue; consumers grabbed them. Simple, right? Not at scale.</p><ul><li>: Hundreds of producer goroutines hammering the queue with —total gridlock.</li><li>: Needed sub-5ms task grabs, but we were stuck at 10ms.</li><li>: Couldn’t crack 80k tasks/second without choking.</li></ul><p>The diagnosis? Lock contention was killing us. Time for a lock-free fix.</p><p>We built a lock-free queue with a singly linked list and CAS magic. Here’s the core of it (simplified for sanity—production had more bells):</p><div><pre><code></code></pre></div><ul><li>:  keeps updates atomic—no locks needed.</li><li>: Skirts the ABA trap (pointer recycling woes).</li><li>: Enqueue adds to the tail, dequeue pops from the head—smooth as butter.</li></ul><div><pre><code>Start: head -&gt; [dummy] -&gt; tail\nEnqueue 1: head -&gt; [dummy] -&gt; [1] -&gt; tail\nEnqueue 2: head -&gt; [dummy] -&gt; [1] -&gt; [2] -&gt; tail\nDequeue: head -&gt; [1] -&gt; [2] -&gt; tail\n</code></pre></div><p>We threw it into production with:</p><ul><li>: Enqueuing like mad.</li><li>: Worker nodes pulling tasks.</li><li>: Task flood to stress it.</li></ul><ul><li>: Sliced from 5ms to 2ms—60% win.</li><li>: Jumped from 80k to 120k tasks/second—50% boost.</li><li>: Bit higher from CAS retries, but worth it.</li></ul><div><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr></tbody></table></div><p>Later, we sharded the queue into 4 buckets—latency stabilized at 1.5ms.  helped us spot CAS hiccups and tweak on the fly.</p><p>This wasn’t just a fix—it was a revelation. Lock-free turned a bottleneck into a highway!</p><h2>\n  \n  \n  Wrapping Up: Lock-Free Lessons and What’s Next\n</h2><p>We’ve gone from lock-free basics to a full-on task scheduler rescue—pretty wild ride, right? Lock-free data structures aren’t just a fancy trick; they’re a secret weapon for taming concurrency chaos in Go. Let’s boil it down, share some parting wisdom, and peek over the horizon.</p><ul><li>: Atomic ops like CAS ditch locks for speed, scale, and no-deadlock bliss.</li><li>:  turns counters, queues, and maps into concurrency champs.</li><li>: Our scheduler went from 5ms latency to 2ms and 80k to 120k tasks/second—real results, not hype.</li><li>: Pick your battles, test like crazy, and watch for traps like ABA.</li></ul><p>This isn’t just Go magic—it’s a concurrency mindset you can take anywhere.</p><p>Ready to flex some lock-free muscle? Here’s my advice:</p><ul><li>: Start with a counter or  for a config cache—easy wins.</li><li>: Use benchmarks and  to prove it works and performs.</li><li>: Locks and channels still have their place—blend them with lock-free where it fits.</li><li>: Go’s concurrency game keeps evolving—stay in the loop.</li></ul><p>Think of lock-free like a new guitar riff—messy at first, killer with practice.</p><p>Lock-free’s got a bright future in Go and beyond:</p><ul><li>: Bet on more built-in lock-free goodies—maybe a queue or map in the stdlib?</li><li>: New CPU tricks could juice up atomic ops—Go’s runtime might cash in.</li><li>: Real-time AI and edge apps will lean on lock-free for that sub-millisecond edge.</li></ul><p>This isn’t a niche anymore—it’s heading mainstream, and you’re ahead of the curve.</p><p>Lock-free isn’t about locking less—it’s about collaborating more. I hope this ride sparked some ideas, whether you’re tuning an API or dreaming up the next big thing. So, grab your keyboard, crank some code, and let’s make concurrency sing!</p>","contentLength":12269,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Como usar tipos customizados em Golang","url":"https://dev.to/renandotcorrea/como-usar-tipos-customizados-em-golang-10ab","date":1750368382,"author":"Renan de Andrade","guid":163148,"unread":true,"content":"<p>Uma das coisas mais comuns em códigos escritos na linguagem Go é o uso de tipos customizados utilizando . Geralmente usamos estes tipos para declarar entidades, transportar valores de forma estruturada e etc. Por exemplo, O código acima é muito comum em muitas aplicações:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Outros tipos customizados\n</h2><p>Mas assim como , podemos utilizar outros tipos primitivos da linguagem para criar tipos customizados, abrindo assim um leque de oportunidades. O processo de criação é idêntico ao mostrado anteriormente, mas usando outro tipo primitivo como bases. Aqui vão alguns exemplos:</p><div><pre><code></code></pre></div><p>Para usar esses tipos novos é tão simples quanto você está pensa. Eles operam da mesma forma que seus tipos base, assim como a . Dá uma olhada:</p><div><pre><code></code></pre></div><p>Uma possibilidade legal que esta abordagem nos traz é a capacidade de as variáveis criadas a partir destes tipo chamarem métodos customizados. Isso pode ter várias aplicações interessantes. Olha só:</p><div><pre><code></code></pre></div><p>Olhando aquele nosso exemplo inicial da , podemos aplicar esses princípios para os campos  e  ao criar um novo tipo para cada um:</p><div><pre><code></code></pre></div><p>Assim cada tipo sabe como fazer sua própria validação. A  fica assim então:</p><div><pre><code></code></pre></div><p>Olha como o uso fica legal:</p><div><pre><code></code></pre></div><p>Para melhorar ainda mais nosso exemplo, podemos fazer a pergunta: <em>E se eu quiser usar o mesmo campo  para vários tipos de documento (digamos que RG e CPF)?</em></p><p>Podemos então mudar o tipo de  para , e criar os tipos dos outros documentos que implementam esta nova interface. Melhor mostrando, né?</p><div><pre><code></code></pre></div><p>Mas se liga aqui como fica o uso:</p><div><pre><code></code></pre></div><p>Dessa forma, você pode ter vários tipos de documentos, e quem vai implementar é quem decide qual vai usar.</p><p>Para fecharmos, podemos fazer a pergunta: <em>E se eu quiser ter um campo que indique o tipo de documento?</em></p><p>A gente pode usar  para isso. Espia:</p><div><pre><code></code></pre></div><p>Adicionamos então o campo  em :</p><div><pre><code></code></pre></div><p>E para usar também é bem simples:</p><div><pre><code></code></pre></div><p>Vimos aqui então que podemos criar tipos customizados baseados em tipos primitivos, chamar métodos através deles, implementar interfaces e até utilizar .</p><p>E aí, o que achou dessas dicas? Deixe aí nos comentários.</p><blockquote><p>Obs. Cover image criada com IA.</p></blockquote>","contentLength":2067,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Sagas to the Rescue: The Perils of Partial Success","url":"https://dev.to/js402/sagas-to-the-rescue-the-perils-of-partial-success-1c0f","date":1750361004,"author":"Alexander Ertli","guid":163095,"unread":true,"content":"<p>Let’s say you're building a system that processes large files by breaking them into chunks, generating vector embeddings (for search or AI tasks), and storing metadata in a database.</p><p><em>\"It works on my machine!\"</em> — the infamous last words before production chaos.</p><p>Your  hums along perfectly. API calls complete in milliseconds. Chunks of data ingest smoothly. Life is good.</p><p>Then you deploy to the .</p><p>A network hiccup. A delayed  request. A . The job —only to fail again with:</p><div><pre><code>ERROR: chunk 0: failed to insert vector - already exists\n</code></pre></div><p>Now your system is stuck in an , reprocessing the same chunks, hitting duplicate-key errors ⚠️, and leaving behind  🧟 — data that exists in one system but not another.</p><p><em>\"I'm sorry, it's lots of intimidating stuff here; let's tackle it piece by piece:\"</em></p><ul><li> — A database that stores high-dimensional data (like embeddings) used in AI and search systems. Think of it like a supercharged search index.</li><li> — A numerical representation of content (like a chunk of text) that captures its meaning, used for similarity search or AI tasks.</li><li> — A deadline for an operation; if it takes too long, the system cancels it to avoid hanging.</li><li> — A way to group multiple database operations into a single “all-or-nothing” step.</li><li> — Data stuck in one system (like vectors) that doesn’t match up with metadata in the main database.</li><li> — A follow-up action that undoes work if something fails (like deleting data you just wrote).</li></ul><p>These are all daily vocab when you try to develop or deploy a RAG for an GenAI Agent.</p><p>The problem is :</p><ol><li><strong>Your worker ingested chunks 0-13</strong> into the vector store (✅).</li><li> The <strong>database transaction rolled back</strong> (no metadata recorded).</li><li><strong>But the vectors remained in the vector store</strong> (zombie data).</li><li> On retry, the worker , hitting duplicate-key errors.</li></ol><p> A distributed mess.</p><h3><strong>The Root Cause: Missing Atomicity</strong></h3><p>In a single database, transactions ensure  operations. But in distributed systems:</p><ul><li> (e.g., Pinecone, Weaviate) ≠ .</li><li><strong>No cross-system transactions</strong> exist.</li><li><strong>Timeouts, crashes, or network issues</strong> leave systems inconsistent.</li></ul><h3><strong>The Fix: Sagas (Compensating Transactions)</strong></h3><p>Instead of pretending for atomicity, we  and  explicitly.</p><div><pre><code></code></pre></div><ol><li><ul></ul></li><li><p><strong>On Failure (timeout, crash, etc.)</strong>:</p><ul><li> runs </li><li> (undo partial inserts)</li><li><strong>SQL transaction rolled back</strong></li></ul></li><li><ul><li>No duplicate-key errors (clean slate on retry)</li></ul></li></ol><p>✔ <strong>Distributed systems fail partially</strong> — and they will! So plan for it.\n✔ <strong>Compensating transactions (Sagas)</strong> undo work explicitly.\n✔  to handle crashes/timeouts.\n✔  is crucial for retries.</p><blockquote><p><em>\"If you can't make it atomic, make it reversible.\"</em></p></blockquote><p> your cloud deployment behaves oddly, ask:<em>\"Did I handle partial failures—or just hope they wouldn’t happen?\"</em></p>","contentLength":2641,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go should be more opinionated","url":"https://dev.to/eminetto/go-should-be-more-opinionated-412b","date":1750359053,"author":"Elton Minetto","guid":163058,"unread":true,"content":"<p>One of the perks of being&nbsp;a <a href=\"https://g.dev/eminetto\" rel=\"noopener noreferrer\">Google Developer Expert</a>&nbsp;is the incredible opportunities it provides. A few weeks ago, I had the opportunity to meet&nbsp;<a href=\"https://en.wikipedia.org/wiki/Robert_Griesemer\" rel=\"noopener noreferrer\">Robert Griesemer</a>, co-creator of Go, in person, as well as&nbsp;<a href=\"https://www.linkedin.com/in/doughertymarc/\" rel=\"noopener noreferrer\">Marc Dougherty</a>, Developer Advocate for the Go team at Google. At a happy hour after Google I/O, Marc asked me and another Go GDE from Korea for feedback on the language. My response was that I didn't have any specific feedback about the language but that:</p><blockquote><p>Go should be more opinionated about the application layout.</p></blockquote><p>It was worth writing a post to express my thoughts more clearly.</p><p>Starting from the beginning… </p><p>In 2025, I will have completed 10 years of writing code in Go. One of the things I recall from when I started is that the language was relatively simple to learn, mainly due to two reasons: its simplicity and the fact that there is only one way to do things. Go was the first language I came across that had strong opinions about several things. There is only one way to loop, and there is only one way to format files (using the 'go fmt' command). Variables with a small scope should have short names, etc. It made it much easier to read code written by other people, which is crucial for learning. The code I wrote was very similar to the Kubernetes code! Of course, the complexity of the problem was infinitely greater, but the code's structure was readable to me. Over the years, I have observed this effect in several people I have followed who were starting in the language or migrating from other environments.</p><p>But once this initial excitement has passed, the biggest challenge comes: how to adopt Go in a project larger than those used for learning? How do you structure a project that will be developed and evolved by a team? At this point, the language step aside from strong opinions, and each team or company needs to decide how to structure their projects. Over the past decade, I have worked for four companies. In all of them, it was necessary to invest the team's time in collecting examples and reading documentation and books to determine which structure they should use in the projects.&nbsp;At the company where I currently work, we have created a <a href=\"https://medium.com/inside-picpay/organizing-projects-and-defining-names-in-go-7f0eab45375d\" rel=\"noopener noreferrer\">document</a> about this.</p><p>Making an analogy with the world of games, it's as if we were having fun in the controlled and wonderful world of Super Mario World and were transported to the open world of GTA 6 (yes! I'm hyped!). It's still a fantastic universe, but the transition is quite abrupt.</p><p>Go could be more opinionated regarding these choices. We could have templates for more common projects, such as CLIs, APIs, and microservices., that teams can use to scaffold their applications. The language toolkit <a href=\"https://go.dev/blog/gonew\" rel=\"noopener noreferrer\">already&nbsp;allows the use of project templates</a>,&nbsp;so it would be a matter of having official templates to make life easier for teams. Alternatively, we could go further and include the command in the language toolkit itself with something like .</p><p>A similar event occurred in the history of the language. Today,&nbsp; dependency management is a fundamental part of our daily lives as Go developers. But it wasn't always like this. For a long time, there was no official package manager for the language; consequently, the community developed several alternatives. They all worked, but fragmentation was getting out of control, making it challenging to integrate packages. Until the language team took control of the situation and&nbsp; was created, pacifying the issue of \"package and dependency management.\" I believe we can apply the same approach to the structure of projects.</p><p>Another profile that would benefit from a more opinionated project structure is that formed by teams that are migrating their applications from other languages, especially Java and PHP. In these ecosystems, frameworks dictate the structure of projects, such as Spring Boot and Laravel. \"Where do I start? How do I structure my project?\" are common questions I hear from teams migrating from these languages. Having something that facilitates this migration would lower the barrier to entry and increase the number of teams experimenting with Go in production.</p><p>That's my biggest feedback regarding Go at the moment. What do you think, dear reader? What's your opinion on the subject? I'd love to discuss this topic in the comments or live at a conference.</p>","contentLength":4299,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Eliminating dead code in Go projects","url":"https://dev.to/mfbmina/eliminating-dead-code-in-go-projects-1glc","date":1750347559,"author":"Matheus Mina","guid":162961,"unread":true,"content":"<p>As the software we work on grows, the code tends to undergo various changes and refactorings. During this process, we might simply forget pieces of code that were once used but no longer make sense in the project, the infamous dead code. A very common example is when an API is deactivated, and only the  is removed, but all the business logic remains, unused.</p><p>Dead code can be defined as a function that exists within your codebase, is syntactically valid, but is not used by any other part of your code. In other words, it's an unreachable function. Dead code brings indirect problems to a project, such as outdated libraries, legacy code, code bloat, security vulnerabilities, and so on. If it's still not clear what dead code is, see the example below:</p><div><pre><code></code></pre></div><p>In this code, we have the private functions  and . By default, <a href=\"https://pkg.go.dev/golang.org/x/tools/gopls#section-readme\" rel=\"noopener noreferrer\">gopls</a> will tell you that the  function is not being used and can be removed. However, this doesn't prevent the project from compiling.  is a language server used by editors to enable features like code completion, syntax corrections, etc. But if the function becomes public, this error won't be flagged because it can theoretically be used by other packages.</p><p>This problem expands when dealing with packages, as unused packages are also not reported. Imagine a package with private and public functions that isn't used in the project:</p><div><pre><code></code></pre></div><p>The Go team then provided a solution to this problem with the  tool. It's worth mentioning that the tool should always be run from , as it searches for dead code based on what would be executed in production. When you run this tool, you finally get all unused functions:</p><div><pre><code>go tool deadcode ./...\n main.go:11:6: unreachable func: unreachable\n main.go:19:6: unreachable func: Public\n unused/unused.go:5:6: unreachable func: UnusedFunction\n unused/unused.go:11:6: unreachable func: indirectUnreachable\n</code></pre></div><p>This way, we can easily find dead code in our project. To install the tool, simply run the command:</p><div><pre><code>go get  golang.org/x/tools/cmd/deadcode@latest\n</code></pre></div><p>This tool is very useful to run after project refactorings and has helped me a lot to keep the code lean and containing only what truly matters to the project. If you're interested and want to know more, I recommend reading the <a href=\"https://go.dev/blog/deadcode\" rel=\"noopener noreferrer\">official post</a>. Tell me in the comments what you think of the tool, and if you want to see the full code, access it <a href=\"https://github.com/mfbmina/poc_deadcode\" rel=\"noopener noreferrer\">here</a>.</p>","contentLength":2340,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Acabando com código morto nos projetos Go","url":"https://dev.to/mfbmina/acabando-com-codigo-morto-nos-projetos-go-42cc","date":1750347521,"author":"Matheus Mina","guid":162960,"unread":true,"content":"<p>Conforme o software que trabalhamos vai crescendo, a tendência é do código passar por diversas mudanças e refatorações. Nesse processo, podemos simplesmente esquecer pedaços de código que um dia foram utilizados e que agora não fazem mais sentido no projeto, os famosos códigos mortos. Um exemplo muito comum é quando uma API é desativada e só o  é removido, porém, toda a lógica de negócio continua ali, mas sem ser utilizada. </p><p>Pode-se dizer que o código morto é basicamente uma função que existe dentro da sua base de código que é sintaticamente válida, porém não é utilizada por nenhuma outra parte do seu código, ou seja, é uma função inalcançável. Códigos mortos trazem problemas indiretos para o projeto, como bibliotecas desatualizadas, códigos legados, inchaço da base de código, falhas de segurança e por aí vai. Se ainda não ficou claro o que é um código morto, veja o exemplo abaixo:</p><div><pre><code></code></pre></div><p>Neste código temos as funções privadas  e . Por padrão, <a href=\"https://pkg.go.dev/golang.org/x/tools/gopls#section-readme\" rel=\"noopener noreferrer\">gopls</a> vai dizer que a função  não está sendo utilizada e que pode ser removida, entretanto, isso não impede a compilação do projeto. O  é um  utilizado pelos editores para habilitar funcionalidades como completamento de código, correções de sintaxe, etc. Porém, se a função se tornar pública, este erro não vai ser apontado, pois ele teoricamente pode ser utilizado por outros pacotes.</p><p>Esse problema se amplia ao lidarmos com pacotes, pois pacotes não utilizados também não são reportados. Suponha então um pacote com funções privadas e públicas, porém que não é utilizado no projeto.</p><div><pre><code></code></pre></div><p>A equipe do Go trouxe então uma solução para este problema, a ferramenta . Vale a pena mencionar que a ferramenta sempre deve ser executada a partir da , pois ela procura por código morto a partir do que seria executado em produção. Ao rodar essa ferramenta, temos finalmente o resultado de todas as funções não utilizadas.</p><div><pre><code>go tool deadcode ./...\n main.go:11:6: unreachable func: unreachable\n main.go:19:6: unreachable func: Public\n unused/unused.go:5:6: unreachable func: UnusedFunction\n unused/unused.go:11:6: unreachable func: indirectUnreachable\n</code></pre></div><p>Assim, podemos facilmente encontrar código morto em nosso projeto. Para instalar a ferramenta, é basicamente rodar o comando:</p><div><pre><code>go get  golang.org/x/tools/cmd/deadcode@latest\n</code></pre></div><p>Essa ferramenta é bem útil para ser executada após refatorações no projeto e tem me ajudado bastante a manter o código enxuto e somente com o que de fato importa para o projeto. Se você ficou interessado e quer saber mais, recomendo a leitura do <a href=\"https://go.dev/blog/deadcode\" rel=\"noopener noreferrer\">post oficial.</a> Me diz nos comentários o que você achou da ferramenta e, se quiser ver o código todo, acesse <a href=\"https://github.com/mfbmina/poc_deadcode\" rel=\"noopener noreferrer\">aqui.</a></p>","contentLength":2705,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Page Zen: The Open-Source Article Cleaning API You've Been Waiting For","url":"https://dev.to/gillarohith/page-zen-the-open-source-article-cleaning-api-youve-been-waiting-for-301e","date":1750347269,"author":"Rohith Gilla","guid":162959,"unread":true,"content":"<p>In today's information-rich world, we're constantly bombarded with cluttered web articles filled with ads, popups, navigation menus, and other distractions. What if you could extract just the essential content from any article with a simple API call? Meet  - an open-source, self-hostable solution that transforms messy web articles into clean, readable content.</p><p>Page Zen is a powerful Go-based API service that takes any article URL and returns clean, distraction-free content in multiple formats. Whether you're building a reading app, content aggregator, or just want to save articles without the clutter, Page Zen has you covered.</p><p>✅  - Removes ads, navigation, social widgets, and other noise - Get content as clean text or markdown - Extract rich social media metadata - Works perfectly with Medium and other popular platforms - Complete control over your data and infrastructure - MIT licensed, community-driven development  </p><h3>\n  \n  \n  1. <strong>Open Source &amp; Self-Hostable</strong></h3><p>Unlike proprietary services that lock you into their ecosystem, Page Zen is completely open source. You can:</p><ul><li>Host it on your own infrastructure</li><li>Customize it for your specific needs</li><li>Never worry about API rate limits or service shutdowns</li><li>Maintain complete control over your data</li></ul><h3>\n  \n  \n  2. <strong>Works with Any Article Platform</strong></h3><p>Page Zen intelligently handles content from various sources:</p><ul><li>And virtually any web article!</li></ul><h3>\n  \n  \n  3. </h3><p>Beyond just cleaning content, Page Zen extracts comprehensive Open Graph metadata:</p><ul><li>Article title and description</li></ul><p>Getting started with Page Zen is incredibly simple. The project includes Docker support for easy deployment:</p><div><pre><code>\ngit clone https://github.com/rohithgilla12/page-zen.git\n\n\ndocker-compose up </code></pre></div><p>That's it! Your article cleaning API is now running locally.</p><div><pre><code>curl  POST http://localhost:8080/extract </code></pre></div><h3>\n  \n  \n  Extract Open Graph Data Only\n</h3><div><pre><code>curl  POST http://localhost:8080/opengraph </code></pre></div><div><pre><code>{\n  \"url\": \"https://dev.to/gillarohith/develop-url-shortener-application-with-redwood-js-3cf7\",\n  \"open_graph\": {\n    \"title\": \"Develop URL shortener application with Redwood JS.\",\n    \"description\": \"Develop URL shortener application with RedwoodJS            Introduction            What is...\",\n    \"image\": \"https://media2.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F77phvxr1c3i00fvv0jly.png\",\n    \"url\": \"https://dev.to/gillarohith/develop-url-shortener-application-with-redwood-js-3cf7\",\n    \"type\": \"article\",\n    \"site_name\": \"DEV Community\",\n    \"twitter_card\": \"summary_large_image\",\n    \"twitter_site\": \"@thepracticaldev\",\n    \"twitter_creator\": \"@gillarohith\",\n    \"twitter_title\": \"Develop URL shortener application with Redwood JS.\",\n    \"twitter_description\": \"Develop URL shortener application with RedwoodJS            Introduction            What is...\"\n  },\n  \"success\": true\n}\n</code></pre></div><p>: Build clean RSS feeds or news aggregators: Create distraction-free reading experiences: Extract clean content for analysis: Get rich preview data for link sharing: Convert web articles to clean markdown  </p><p>Page Zen goes beyond basic article extraction:</p><ul><li>: Converts complex picture elements to simple img tags</li><li>: Handles relative URLs and converts them to absolute paths </li><li>: Uses Mozilla's Readability algorithm for accurate content extraction</li><li>: Remove specific elements based on your needs</li><li>: Built-in structured logging for debugging and monitoring</li></ul><p>Page Zen is more than just a tool - it's a community-driven project that welcomes contributions:</p><ul><li>🐛  and suggest features</li><li>💻  and improvements\n</li><li>⭐  to show your support</li></ul><p>Ready to clean up the web? Here's how to get started:</p><ol><li>: Clone the repo and run with Docker</li><li>: Use the included Dockerfile for easy deployment</li><li>: Start making API calls from your application</li><li>: Fork the project and adapt it to your needs</li></ol><p><em>Page Zen - Because the web deserves to be readable.</em></p>","contentLength":3855,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Redis Fallback (Golang)","url":"https://dev.to/pardnchiu/redis-fallback-golang-i0a","date":1750342797,"author":"邱敬幃 Pardn Chiu","guid":162917,"unread":true,"content":"<blockquote><p>A Redis fallback for Golang that automatically degrades to local storage, ensuring minimal data loss during fallback and seamless recovery when Redis becomes available again.</p></blockquote><ul><li>: Automatically switches to local file storage when Redis connection fails</li><li>: Periodically monitors Redis health status and batch synchronizes data after recovery</li><li><strong>Three-tier Storage Architecture</strong>: Memory cache + Redis + Local file storage</li><li>: Stores data as JSON files during fallback mode to prevent data loss</li><li>: Uses queue and scheduled batch writes to optimize performance in fallback mode</li><li>: Supports expiration time settings and automatically cleans expired data</li><li>: Uses MD5 encoding to implement layered directory structure avoiding too many files</li><li>: Hierarchical logging for monitoring and troubleshooting</li></ul><div><pre><code>go get github.com/pardnchiu/golangRedisFallback\n</code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><ul><li>Normal mode: Try to get from memory cache, if not found query Redis, update memory cache after success and sync to Redis in background</li><li><p>Fallback mode: Read from memory cache, if not found load from local JSON file</p></li></ul><div><pre><code></code></pre></div><ul><li>Normal mode: Write to Redis, update memory cache after success; switch to fallback mode if Redis fails beyond retry limit</li><li><p>Fallback mode: Update memory cache, add write requests to queue for batch processing</p></li></ul><ul><li>Remove data from memory cache, Redis and local files simultaneously</li><li>In fallback mode only remove from memory cache and local files</li></ul><h3>\n  \n  \n  Fallback and Recovery Mechanism\n</h3><h4>\n  \n  \n  Automatic Fallback Triggers\n</h4><ul><li>Initial Redis connection failure</li><li>Set operation retry count exceeds limit</li><li>Get operation Redis read failure exceeds retry count</li></ul><ul><li>Start scheduled health checks (default every minute)</li><li>Write operations use queue for temporary storage</li><li>Scheduled batch writes to local files (default every 3 seconds)</li></ul><h4>\n  \n  \n  Automatic Recovery Process\n</h4><ol><li>Health check detects Redis availability</li><li>Stop health check scheduler</li><li>Scan local files and load to memory</li><li>Batch sync memory data to Redis (commit every 100 records)</li><li>Clean local files and empty directories</li><li>Switch back to normal mode</li></ol><p>Uses MD5 encoding to implement layered directories, avoiding too many files in a single directory:</p><div><pre><code>./files/golangRedisFallback/db/\n├── 0/                   # Redis DB\n│   ├── ab/              # First 2 chars of MD5\n│   │   ├── cd/          # 3rd-4th chars of MD5\n│   │   │   ├── ef/      # 5th-6th chars of MD5\n│   │   │   │   └── abcdef1234567890abcdef1234567890.json\n</code></pre></div><div><pre><code></code></pre></div><ul><li>: Every Get operation checks if data is expired</li><li>: Clean expired data from memory every 30 seconds</li><li>: Expired data is removed from both memory and local files</li><li>: Based on timestamp + ttl to determine expiration status</li></ul><h3>\n  \n  \n  Write Optimization Strategy\n</h3><ul><li>Write directly to Redis, update memory cache after success</li></ul><ul><li>Update memory cache immediately to ensure read consistency</li><li>Add write requests to queue (non-blocking)</li><li>Write directly to file when queue is full</li><li>Process write requests in queue with scheduled batch processing</li></ul><ul><li>: Protects health status changes</li><li>: Concurrent-safe memory cache</li><li>: Prevents duplicate recovery process execution</li><li>: Concurrent processing of write requests</li><li>: Synchronization of write queue and local file operations</li></ul><ul><li>: Automatic retry on Redis operation failure (configurable count)</li><li>: Automatically switch to local storage when Redis is unavailable</li><li>: Complete error logging for troubleshooting</li><li>: Ensure data synchronization between memory, Redis and files</li></ul><h2>\n  \n  \n  Performance Characteristics\n</h2><ul><li>: Prioritize reading data from memory cache</li><li>: Use Pipeline for batch sync to Redis during recovery</li><li>: Avoid too many files in single directory affecting performance</li><li>: Write operations don't block main flow</li><li>: Automatically clean expired data to free memory</li></ul><div><pre><code>flowchart TD\n  A[Initialize] --&gt; B{Check Redis Connection}\n\n  B --&gt;|Connection Failed| B_0[Start Health Check Scheduler]\n  B_0 --&gt; B_0_0[Fallback Mode]\n\n  subgraph \"Initialization\"\n    B --&gt;|Connection Success| B_1{Check Unsynced Files}\n    B_1 --&gt;|Exist| B_1_1[Sync Data to Redis]\n  end\n\n  subgraph \"Normal Mode\"\n\n    subgraph \"Normal Mode Read\"\n    C --&gt; D{Query Redis}\n    D --&gt;|Found| D_1[Update Memory Cache]\n    D --&gt;|Not Found| D_0{Check Memory Cache}\n\n    D_0 --&gt;|Found| D_0_1[Sync to Redis]\n    end\n\n    subgraph \"Normal Mode Write\"\n    E --&gt; F{Write to Redis}\n    F --&gt;|Success| F_1[Write to Memory]\n    F --&gt;|Failed| F_0{Check Redis Connection}\n\n    F_0 --&gt;|Connection Success, Attempts &lt;= 3| E\n    end\n  end\n\n  D_1 --&gt; ReturnResult[Return Result]\n  D_0 --&gt;|Not Found| ReturnResult\n  D_0_1 --&gt; ReturnResult\n\n  I_0 --&gt;|Not Found| ReturnResult[Return null]\n  I_0_1 --&gt; ReturnResult[Return Result]\n\n  B_1_1 --&gt; B_1_0\n  B_1 --&gt;|Not Exist| B_1_0[Normal Mode]\n  B_1_0 --&gt; C[Read Request]\n  B_1_0 --&gt; E[Write Request]\n\n  F_0 --&gt;|Failed| O\n  F_0 --&gt; B_0[Start Health Check Scheduler]\n\n  B_0_0 --&gt; J{Check Redis Connection/Every ? seconds}\n  B_0_0 --&gt; N[Write Request]\n\n  subgraph \"Fallback Mode\"\n    subgraph \"Fallback Mode Read\"\n    B_0_0 --&gt; H[Read Request]\n    I_0 --&gt;|Found| I_0_1[Update Memory Cache]\n    end\n\n    subgraph \"Fallback Mode Monitor\"\n    J --&gt;|Recovered| J_1[Execute Recovery Process]\n    J --&gt;|Not Recovered| J_0[Continue Fallback Mode]\n    J_0 --&gt; J\n\n    J_1 --&gt; K[Sync Memory Data to Redis]\n    K --&gt; L[Sync JSON to Redis]\n    L --&gt; M{Sync Status}\n    M --&gt;|Failed, Attempts &lt;= 3| J_1\n    end\n\n    subgraph \"Fallback Mode Write\"\n    N--&gt; O[Update Memory Cache]\n    O --&gt; P{DB Folder Exists}\n    P --&gt; |Yes| P_1[Write Individual Files]\n    P --&gt; |No| P_0[Create DB Folder]\n    P_0 --&gt; P_1\n    end\n  end\n\n  M --&gt;|Success| B_1_0\n\n  H --&gt; Q{Query Memory Cache}\n  S --&gt;|Not Found| I_0{Check JSON Exists}\n\n  subgraph \"Memory Flow\"\n    subgraph \"Memory Read\"\n    Q{Check Expiration} --&gt;|Expired| Q_1[Remove Cache and Delete JSON]\n    Q_1 --&gt; |null| S\n    Q --&gt; |Not Expired| S[Return Result]\n    end \n\n    subgraph \"Memory Cleanup\"\n    T[Memory Cleanup/Every ? seconds] --&gt; U[Clean Memory Data]\n    U --&gt; V[Remove JSON]\n    V --&gt; T\n    end \n  end\n</code></pre></div><blockquote><ul><li><ul><li>[x] Del - Delete key-value</li><li>[ ] Exists - Check if key exists</li><li>[ ] Expire/ExpireAt - Set expiration time</li><li>[ ] TTL - Get remaining time to live</li><li>[ ] Keys - Find keys matching pattern</li><li>[ ] Pipeline - Batch commands</li><li>[ ] TxPipeline - Transaction batch</li></ul></li><li><ul><li>[ ] SetNX - Set if not exists</li><li>[ ] SetEX - Set with expiration time</li><li>[ ] Incr/IncrBy - Increment numeric value</li><li>[ ] Decr/DecrBy - Decrement numeric value</li><li>[ ] MGet/MSet - Batch get/set multiple key-value pairs</li></ul></li><li><ul><li>[ ] HSet/HGet - Set/get hash field</li><li>[ ] HGetAll - Get all fields and values</li><li>[ ] HKeys/HVals - Get all field names/values</li><li>[ ] HDel - Delete hash field</li><li>[ ] HExists - Check if field exists</li></ul></li><li><ul><li>[ ] LPush/RPush - Add elements from left/right</li><li>[ ] LPop/RPop - Remove elements from left/right</li><li>[ ] LRange - Get range elements</li><li>[ ] LLen - Get list length</li></ul></li><li><ul><li>[ ] SAdd - Add element to set</li><li>[ ] SMembers - Get all set members</li><li>[ ] SRem - Remove element from set</li><li>[ ] SCard - Get set cardinality</li><li>[ ] SIsMember - Check if element is in set</li></ul></li></ul></blockquote><h3>\n  \n  \n  Can not be supported at fallback mode\n</h3><ul><li><ul><li>BLPop/BRPop - Blocking left/right pop</li></ul></li><li><ul><li>ZAdd - Add element to sorted set</li><li>ZRange/ZRevRange - Get range by score</li><li>ZRank/ZRevRank - Get element rank&lt;</li><li>ZScore - Get element score</li></ul></li><li><ul><li>Publish - Publish message</li><li>Subscribe - Subscribe to channel</li></ul></li><li><ul><li>Eval/EvalSha - Execute Lua script</li></ul></li></ul><p>This source code project is licensed under the <a href=\"https://github.com/pardnchiu/golang-redis-fallback/blob/main/LICENSE\" rel=\"noopener noreferrer\">MIT</a> license.</p>","contentLength":7208,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Go's slog: Modern Structured Logging Made Easy","url":"https://dev.to/leapcell/gos-slog-modern-structured-logging-made-easy-4e04","date":1750342649,"author":"Leapcell","guid":162916,"unread":true,"content":"<p>Go version 1.21.0 introduced a new package, , which provides structured logging functionality. Compared to traditional logging, structured logging is more popular because it offers better readability and significant advantages in processing, analysis, and searching.</p><p>The slog package provides structured logs, where each log entry contains a , , and various other attributes, all represented as key-value pairs.</p><p>The main features of the slog package are as follows:</p><ul></ul><div><pre><code></code></pre></div><p>In the above example, we directly output an info-level log by calling the package function . Internally, this function uses a default  instance to perform the logging operation. In addition, you can use  to output logs with an associated context.</p><p>Besides  and , there are also functions like , , and  for logging at different levels.</p><p>Running the above program will produce the following output:</p><div><pre><code>2025/06/18 21:08:08 INFO slog msg greeting=\"hello slog\"\n2025/06/18 21:08:08 INFO slog msg with context greeting=\"hello slog\"\n</code></pre></div><p>By default, when using slog package functions to output logs, the format is just plain text. If you want to output in JSON or key=value format, you need to create a Logger instance using . When using this function, you must pass in an implementation of . The slog package provides two implementations:  and .</p><p>TextHandler is a log handler that writes log records as a series of key-value pairs to an . Each key-value pair is represented in the form key=value, separated by spaces.</p><div><pre><code></code></pre></div><p>In the above example, we create a log handler using . The first parameter, , indicates that logs will be output to the console. The handler is then passed as a parameter to  to create a Logger instance, which is used to perform logging operations.</p><p>The output of the program is as follows:</p><div><pre><code>time=2025-06-18T21:09:03.912+00:00 level=INFO msg=TextHandler Name=Leapcell\n</code></pre></div><p>JsonHandler is a log handler that writes log records in JSON format to an .</p><div><pre><code></code></pre></div><p>In the example above, we use  to create a JSON log handler. The first parameter, , indicates output to the console. The handler is passed to  to create a Logger instance, which is then used for logging operations.</p><p>The program output is as follows:</p><div><pre><code></code></pre></div><p>slog has a default Logger instance. If you want to obtain the default Logger, you can refer to the following code:</p><p>In previous examples, we always used a specifically created Logger instance to output logs. However, if you don’t want to log through a specific Logger instance every time but instead want to operate globally, you can use the  function to set and replace the default Logger instance. This makes logging more convenient and flexible.</p><div><pre><code></code></pre></div><p>Grouping refers to grouping related attributes (key-value pairs) in a log record. Here’s an example:</p><div><pre><code></code></pre></div><p>The result of running this program is as follows:</p><div><pre><code>{\"time\":\"2025-06-18T21:12:23.124255258+00:00\",\"level\":\"INFO\",\"msg\":\"json-log\",\"information\":{\"name\":\"Leapcell\",\"phone\":1234567890}}\ntime=2025-06-18T21:12:23.127+00:00 level=INFO msg=json-log information.name=Leapcell information.phone=1234567890\n</code></pre></div><p>According to the output, if you group a Logger instance with a , the group name becomes a key, and the value is a JSON object composed of all key-value pairs.</p><p>If you group a Logger with a , the group name is combined with the keys of all key-value pairs, and ultimately displayed as .</p><h2>\n  \n  \n  Efficient Logging with LogAttrs\n</h2><p>If you need to log frequently, compared to the previous examples, using the  function together with the  type is more efficient, because it reduces the process of type parsing.</p><div><pre><code></code></pre></div><p>In the example above, we use the  method to output a log entry. The method’s signature is:<code>func (l *Logger) LogAttrs(ctx context.Context, level Level, msg string, attrs ...Attr)</code></p><p>Based on the signature, the first parameter is a , the second parameter is a  (the log severity level defined in the slog package), and the third parameter is an  key-value pair.</p><p>When using other methods like  to output logs, the key-value pairs are internally converted to the  type. By using the  method, you can directly specify the  type, reducing the conversion process, and thus making logging more efficient.</p><h2>\n  \n  \n  With: Setting Common Attributes\n</h2><p>If every log needs to contain the same key-value pair, you can consider setting a common attribute.</p><div><pre><code></code></pre></div><p>You can use the  method to add one or more fixed attributes and return a new Logger instance. Any logs output by this new instance will include the added fixed attributes, thus  the need to add the same key-value pairs to every log statement.</p><p>The output of this program is as follows:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  HandlerOptions: Configuration Options for Log Handlers\n</h2><p>Careful readers may have noticed that in previous examples, whether using  or , the second parameter was set to , which means the default configuration is used.</p><p>This parameter is of type . With it, you can configure whether to display the source code location of log statements, the minimum log output level, and how to rewrite key-value pair attributes.</p><div><pre><code></code></pre></div><p>In this example, we create a Logger instance with a . When creating the , the following configurations are specified via the  parameter:</p><ul><li>Output the source code (Source information) of the log statement</li><li>Set the minimum log level to Error</li><li>Rewrite the format of the attribute with key  to </li></ul><p>The output of this program is as follows:</p><div><pre><code></code></pre></div><p>The output matches expectations: logs of level INFO are not output, the Source information is included, and the value of the  key has been rewritten.</p><h2>\n  \n  \n  Customizing the Value in Key-Value Pairs\n</h2><p>In a previous example, we used the  configuration to modify the value in a key-value pair. Besides this method, the slog package also supports another way to change the value.</p><div><pre><code></code></pre></div><p>In the above example, we implement the  interface (by adding the  method to a type), which allows us to override the value of a key-value pair. When logging, the value will be replaced by the return value of the  method.</p><p>The output of this program is as follows:</p><div><pre><code>2025/06/18 21:37:11 INFO Sensitive Data password=REDACTED_PASSWORD\n</code></pre></div><p>As expected, the value of  has been changed.</p><p>This article provides a detailed introduction to the slog package in Go, including basic usage, creating Logger instances, efficient logging, and customizing log information.</p><p>After reading this article, you should have a deeper understanding of the slog package and be able to use it more effectively to manage and record logs.</p><p><a href=\"https://leapcell.io/?lc_t=d_goslog\" rel=\"noopener noreferrer\">Leapcell</a> is the Next-Gen Serverless Platform for Web Hosting, Async Tasks, and Redis:</p><ul><li>Develop with Node.js, Python, Go, or Rust.</li></ul><p><strong>Deploy unlimited projects for free</strong></p><ul><li>pay only for usage — no requests, no charges.</li></ul><p><strong>Unbeatable Cost Efficiency</strong></p><ul><li>Pay-as-you-go with no idle charges.</li><li>Example: $25 supports 6.94M requests at a 60ms average response time.</li></ul><p><strong>Streamlined Developer Experience</strong></p><ul><li>Intuitive UI for effortless setup.</li><li>Fully automated CI/CD pipelines and GitOps integration.</li><li>Real-time metrics and logging for actionable insights.</li></ul><p><strong>Effortless Scalability and High Performance</strong></p><ul><li>Auto-scaling to handle high concurrency with ease.</li><li>Zero operational overhead — just focus on building.</li></ul>","contentLength":6974,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Domain Scanner: Find Available Domain Names in a Flash!","url":"https://dev.to/githubopensource/domain-scanner-find-available-domain-names-in-a-flash-54ph","date":1750339740,"author":"GitHubOpenSource","guid":162887,"unread":true,"content":"<p>Domain Scanner is a Go-based tool for checking domain name availability. It uses multiple verification methods like DNS records, WHOIS information, and SSL certificate verification. The tool supports advanced filtering with regular expressions, concurrent processing, and provides detailed verification results, making it easy to find available domain names.</p><ul><li><p>✅ Multi-method verification for accurate results</p></li><li><p>✅ Concurrent processing for speed and efficiency</p></li><li><p>✅ Flexible filtering options using regular expressions</p></li><li><p>✅ Detailed output and error handling</p></li><li><p>✅ User-friendly web interface and command-line tool</p></li></ul><ul></ul><p>Hey fellow developers! Ever spent hours searching for the perfect domain name, only to find it's already taken?  I know the feeling! That's why I'm super excited to share a fantastic GitHub project with you: Domain Scanner. This tool is a game-changer for anyone who needs to find available domain names quickly and efficiently. Forget endless manual searches; this tool automates the process and makes it a breeze.</p><p>Domain Scanner is a powerful domain name availability checker written in Go.  What sets it apart is its comprehensive approach.  It doesn't just check one or two things; it uses multiple methods to verify availability.  Think of it like this: you're not just asking one person if a domain is free; you're asking several authoritative sources (DNS records, WHOIS information, SSL certificates) to confirm. This multi-layered approach ensures more accurate results and minimizes false positives.</p><p>The architecture is surprisingly elegant.  It's designed for speed and efficiency using Go's concurrency features. You can configure the number of 'workers' – essentially, the number of simultaneous checks the tool can perform. This means you can scan through hundreds or even thousands of potential domains in a fraction of the time it would take manually.  Plus, it handles errors gracefully with automatic retries, ensuring that even temporary network hiccups won't stop your search.</p><p>But the real magic is in the flexibility. You can define the length of the domain names you're looking for, specify the top-level domain (like '.com', '.org', '.net'), and even use regular expressions to filter results based on specific patterns.  Need only alphanumeric domains?  No problem. Want to exclude names containing certain characters?  Domain Scanner makes it easy. The tool provides detailed results, indicating precisely why a domain might be unavailable (e.g., DNS records exist, WHOIS data shows it's registered, etc.). This granular level of detail is invaluable for making informed decisions.</p><p>The best part?  It outputs the results to separate files for available and registered domains, neatly organized and ready for further analysis.  Imagine saving hours of tedious work – that's the power of Domain Scanner. The project also includes a well-designed web interface, accessible at zli.li, offering a user-friendly alternative to the command-line tool. This web version provides a convenient way to quickly check domain availability without needing to install or run any software. Overall, this project is an outstanding example of efficient, well-documented, and user-friendly software development. It's a must-have tool for any developer or business owner who values their time and needs to find available domain names quickly and efficiently.</p><h2>\n  \n  \n  🌟 Stay Connected with GitHub Open Source!\n</h2><blockquote><p>👥 <p>\nConnect with our community and never miss a discovery</p><a href=\"https://www.facebook.com/people/GitHub-Open-Source/61571925474856/\" rel=\"noopener noreferrer\">GitHub Open Source</a></p></blockquote>","contentLength":3497,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why and When to Migrate from Ruby to Go: Benefits, Trade-offs & Alternatives","url":"https://dev.to/evrone/why-and-when-to-migrate-from-ruby-to-go-benefits-trade-offs-alternatives-1l58","date":1750337666,"author":"Evrone","guid":162861,"unread":true,"content":"<p>Migrating from Ruby to Go offers improved performance, resource efficiency, and simpler deployment, making it ideal for scalable, cloud-native applications. This guide outlines the key advantages—like concurrency, type safety, and cross-platform deployment—alongside potential drawbacks such as rewrite costs and team learning curves. It's a strategic choice for growth-focused systems.</p>","contentLength":390,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"3V Battery: Hogwarts’ Hidden Power Fueling Magic & Tech","url":"https://dev.to/ersajay/3v-battery-hogwarts-hidden-power-fueling-magic-tech-2heg","date":1750317088,"author":"ersajay","guid":162660,"unread":true,"content":"<p>The Leaky Cauldron’s Unseen Alchemy\nBeneath the clinking mugs of Butterbeer and the creaky floorboards of the Leaky Cauldron lies a magic even Dumbledore might have envied: the 3V battery—a compact power source so unassuming it could pass for a Galleon, yet mightier than a well-cast Lumos Maxima. While flashy wand cores and enchanted gadgets hog the limelight, this silent dynamo powers the wizarding world’s grind—from St. Mungo’s life-saving devices to Mars-bound broomsticks. Let’s lift the veil on its spells.</p><p>The Potion of Precision: What Is a 3V Battery?\nThis isn’t just metal and chemicals—it’s enchanted energy. Break down its magic:</p><p>Lithium (e.g., CR2032): The Felix Felicis of batteries—high energy, 5-10 years of life, and as reliable as a Weasley’s promise.\nAlkaline: Cheaper but prone to leaks, like a faulty Reparo spell—useful, but not for the critical stuff.<p>\nSilver Oxide: The Pensieve of power—precision voltage for watches and medical tools, steady as a Memory Charm.</p></p><p>Voltage Stability: Holds 3V until the end, no fading—unlike alkaline’s wobbly “Obliviate” act.\nSize: Coin-shaped (20-30mm), slipping into spaces tighter than a Niffler’s vault—perfect for pocket watches and car keys.</p><p>Fun Fact: Engineers and healers alike call it the “Wand Core of Power.” It’s in NASA rovers and your dad’s car key fob—because reliability doesn’t care if you’re orbiting Mars or just avoiding a Dementor in the parking lot.</p><p>Why the Wizarding World Can’t Live Without It<a href=\"https://www.ersaelectronics.com/blog/what-is-a-3v-battery\" rel=\"noopener noreferrer\">The 3V battery</a>’s power isn’t in flash—it’s in resilience. Imagine the Great Hall, and this battery’s advantages are the Sorting Hat’s wisdom:</p><p>Longevity: Lithium variants last 5-10 years. That’s longer than most first-years’ patience in Potions class. Perfect for pacemakers (no “404 Error: Heartbeat” here) and Arctic research gear (even polar bears respect its stamina).\nExtreme Resilience: Works from -40°C (Hogsmeade in winter) to 85°C (a Confringo-fired cauldron). It laughs at snowstorms and desert heat—no “battery dead” warnings in the Sahara.<p>\nNo Leaks: Sealed tighter than the Chamber of Secrets. No corrosion, no mess—critical for medical devices (healers hate cleaning acid off pacemakers).</p></p><p>Roast Alert:\nAlkaline Battery: “I’m cheaper!”<p>\n3V Lithium: “I’m in your pacemaker. You’re in a disposable flashlight. Talk to me when you outlive a Dementor.” 💀</p></p><p>The Invisible Keeper of Magic\nFrom St. Mungo’s to the Ministry of Magic, the 3V battery is the unsung hero:</p><p>Healthcare (St. Mungo’s MVP):\nPowers pacemakers (keeping hearts steady as a Protego shield), glucose monitors (no “low sugar” panics), and thermometers (even dragon pox can’t fool it). Healers trust it more than their own wands—quieter than a scalpel, longer-lasting than a Firewhiskey high.</p><p>Consumer Magic (Wizarding Tech):\nIn <a href=\"https://www.ersaelectronics.com/\" rel=\"noopener noreferrer\">smartwatches</a> (upgrading the Marauder’s Map to “Live Tracking”), fitness trackers (counting Quidditch laps like a Homenum Revelio), and smart home sensors (alerting you when a Boggart’s in the closet). It outlasts toddler tantrums and juice spills—because Alohomora needs a reliable key fob.</p><p>Automotive &amp; Aerospace (Beyond Hogwarts):\nKeyless entry fobs (no more “Accio Keys” at 2 a.m.), tire pressure sensors (keeping your car safer than a Shield Charm), and satellites (beaming spells to Mars). NASA uses it because “space-grade” is just Tuesday for this battery.</p><p>Burn Alert:\nSmartphone: “I’m the future!”<p>\n3V Battery: “I’m in your pacemaker. You’re in a landfill in 2 years. Priorities, mate.” 📱💀</p></p><p>The Triwizard Tournament of Batteries\nLet’s meet the contenders in the Great Hall of Power:</p><p>3V Lithium (Gryffindor): Steady, loyal, outlasts the competition. No drama, just results.\nAlkaline AA (Slytherin): Flashy, cheap, but leaks like a Boggart in the rain. Good for pranks, not for potions.<p>\nNiMH Rechargeable (Hufflepuff): Hardworking, but bulky and moody. Needs constant “Riddikulus” to stay charged.</p></p><p>Why 3V Wins: For critical magic—pacemakers, satellites, or your car key—it’s not about cost. It’s about trust. And the 3V battery? It’s as trustworthy as Dumbledore’s beard.</p><p>How to Find the Real Deal (Avoid Fake Wands)\nIn the wilds of Diagon Alley, not all 3V batteries are created equal. The 3V battery warned:<p>\n“Beware of knockoffs—they fail faster than a first-year’s Wingardium Leviosa. Stick to trusted sellers: Walmart, Target, or Ersa Electronics for industrial grade. For watches, hit the jewelers—Renata’s the Ollivander of 3V batteries.”</p>\nPro Tip: Check for brands like Energizer or Panasonic. If it’s from a dodgy eBay seller claiming “Hogwarts-certified”? Run. Fast.</p><p>Conclusion: The Battery That Binds\nThe 3V battery isn’t flashy. It doesn’t need a wand wave or a grand entrance. It’s the Homenum Revelio of tech—small, unassuming, and critical. While the world obsesses over AI and quantum wands, this humble hero keeps hearts beating, keys working, and satellites singing.<p>\nNext time your car key fob works, or your watch ticks, whisper, “Thanks, little one.” It’s the least you can do for a battery that’s saved your sanity (and your Patek’s pride).</p></p><p>Written by a wizard who once mistook a CR2032 for a Fizzing Whizbee. (Spoiler: It didn’t taste like lemon. Or explode. Annoyingly reliable.)\n🔋 Some magic isn’t in wands—it’s in the tiny things that keep the world enchanted.</p>","contentLength":5456,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"5 Things I Learned Building a Database File Format from Scratch","url":"https://dev.to/devdevgo/5-things-i-learned-building-a-database-file-format-from-scratch-2phf","date":1750313845,"author":"Lakshya Negi","guid":162621,"unread":true,"content":"<p>Last month, I decided to build a key-value database from scratch. Not because the world needs another database, but because I wanted to understand what actually happens behind the scenes when you call  or .</p><p>After weeks of wrestling with file formats, serialization, and the surprisingly complex world of \"simple\" storage systems, I've learned some hard lessons that no textbook quite prepared me for. Here are the five biggest insights that changed how I think about databases.</p><h2>\n  \n  \n  1. Your File Format Design Choices Haunt You Forever\n</h2><p>When I started, I thought file format design would be the easy part. \"Just throw some bytes in a file, right?\" Wrong. Every single decision you make in your file format becomes permanent baggage that you'll carry for the life of your database.</p><p>I initially designed a complex header with 15 different fields:</p><div><pre><code>Creation timestamp, last modified time, record count,\npage count, configuration flags, user metadata,\nversion numbers, checksums...\n</code></pre></div><p>It felt thorough and professional. Then I tried to implement it.</p><p>: Most of those fields were never used, and maintaining them added complexity everywhere. Worse, I realized I'd committed to this format forever—any change would break compatibility with existing files.</p><p>: Start with the absolute minimum. For my key-value database, I ended up with just 16 bytes:</p><div><pre><code>Bytes 0-7:   File signature (\"KVDB2024\")\nBytes 8-11:  First freelist page pointer\nBytes 12-15: First data page pointer\n</code></pre></div><p>That's it. Everything else can be added later if you actually need it. Your future self will thank you for keeping it simple.</p><h2>\n  \n  \n  2. Endianness Will Bite You When You Least Expect It\n</h2><p>I'm embarrassed to admit how long it took me to figure out why my database worked perfectly on my laptop but produced garbage on my friend's ARM-based server.</p><p>The culprit? I was storing integers without specifying byte order:</p><div><pre><code></code></pre></div><p>The number  was being read as  on the ARM machine. Same bits, different interpretation.</p><p> was simple but crucial:</p><div><pre><code></code></pre></div><p>: Always, always, ALWAYS specify your byte order explicitly. Even if you only plan to run on one type of machine, you'll eventually want to share database files or deploy somewhere else. Make endianness a conscious choice from day one.</p><h2>\n  \n  \n  3. Error Handling Is More Important Than the Happy Path\n</h2><p>My first implementation focused entirely on making things work correctly. Reading files, writing data, parsing headers—when everything went right, it was beautiful.</p><p>Then I started testing edge cases:</p><ul><li>What if the file gets truncated?</li><li>What if someone tries to open a JPEG as a database?</li><li>What if the disk runs out of space mid-write?</li><li>What if the process crashes during a header update?</li></ul><p>My database crashed, corrupted data, or silently accepted garbage input in every single scenario.</p><p> came when I realized that error handling isn't just about making your code robust—it's about making your database trustworthy. A database that sometimes loses data is worse than no database at all.</p><div><pre><code></code></pre></div><p>: Write your error handling first, then implement the happy path. If your database can't fail gracefully, it can't be trusted with real data.</p><h2>\n  \n  \n  4. File I/O Is Asynchronous (Even When It Looks Synchronous)\n</h2><p>This one nearly gave me a heart attack during testing.</p><p>I was running a simple test: write some data, immediately cut power to the machine, then check if the data survived. It didn't. Even though my  calls returned successfully, the data never made it to disk.</p><p>: Operating systems buffer writes for performance. When you call , the OS says \"sure, I'll get to that\" and immediately returns success. Your data might sit in a buffer for seconds before actually hitting the disk.</p><p>For most applications, this is fine. For databases, it's catastrophic.</p><p>: Learn to love :</p><div><pre><code></code></pre></div><p>: If you care about durability, you must explicitly force data to disk. Every critical operation should end with a sync. Yes, it's slower. No, you can't skip it if you want your database to survive power failures.</p><h2>\n  \n  \n  5. Simplicity Is a Feature, Not a Bug\n</h2><p>Throughout this project, I constantly felt pressure to add features. \"Real databases have indexing, so I need indexing.\" \"Production systems need compression, so I need compression.\" \"Enterprise databases support transactions, so I need transactions.\"</p><p>This feature creep nearly killed my project.</p><p> came when I stepped back and asked: \"What's the simplest thing that could possibly work?\"</p><p>For a key-value database, that turned out to be surprisingly minimal:</p><ul><li>A file header pointing to the start of data</li><li>Fixed-size pages containing variable-length records</li><li>A simple append-only storage model</li></ul><p>No fancy indexing (yet). No compression (yet). No complex transactions (yet). Just a system that can reliably store and retrieve key-value pairs.</p><p>: This simple design was faster, more reliable, and easier to debug than any of my complex attempts. More importantly, it actually worked.</p><p>: Every feature you don't implement is a feature that can't break. Build the simplest thing first, then add complexity only when you actually need it. Your simple database that works is infinitely better than your complex database that doesn't.</p><h2>\n  \n  \n  What I'd Tell My Past Self\n</h2><p>If I could go back and give myself advice before starting this project:</p><ol><li><strong>Start with file format design, but keep it minimal</strong></li><li><strong>Specify endianness explicitly from day one</strong></li><li><strong>Write error handling before implementing features</strong></li><li><strong>Always sync critical writes to disk</strong></li><li><strong>Resist the urge to add features until the basics work perfectly</strong></li></ol><p>Building a database taught me that the hardest part isn't the algorithms or data structures—it's handling all the ways things can go wrong in the real world. Files get corrupted, processes crash, disks fill up, and users try to open the wrong files.</p><p>A good database isn't just a system that works when everything goes right. It's a system that fails gracefully when everything goes wrong.</p>","contentLength":5827,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Build a Modern Plugin-Based Platform with Go + React (like Slack or Mattermost)","url":"https://dev.to/palynext/build-a-modern-plugin-based-platform-with-go-react-like-slack-or-mattermost-482f","date":1750298285,"author":"Paly Next","guid":161744,"unread":true,"content":"<p>PalyNext is an open-source, modular platform designed to be extensible — combining the best of:\n •🧩 Plugin architecture (Go + gRPC + Hashicorp go-plugin)<p>\n •⚡ Dynamic frontend federation (React + Vite + Module Federation)</p>\n •💬 Slack-like UX with real-time capabilities<p>\n •📦 Easily deployable as microservices or standalone</p></p><p>✨ Key Features\n •✅ Runtime plugin discovery + injection<p>\n •✅ Each plugin can contain both Go backend and React frontend</p>\n •✅ Hot-reload during development<p>\n •✅ Middleware and API hooks from plugins</p>\n •✅ Inspired by Mattermost, Slack, Coolify</p><p>🔧 Tech Stack\nBackend:     Go, gRPC, Fiber, go-plugin<p>\nFrontend:    Vite, React, TailwindCSS, ShadCN UI</p>\nPlugins:     Runtime loadable (Go + React)</p><div><pre><code>// example/main.go\nfunc main() {\n  plugin.Init(&amp;plugin.PluginConfig{\n    Name: \"example\",\n    Version: \"1.0.0\",\n    Handle: &amp;Example{},\n  })\n}\n</code></pre></div><div><pre><code>// example/webapp/PluginEntry.tsx\nexport default function PluginEntry() {\n  return &lt;div&gt;Hello from Plugin Example!&lt;/div&gt;\n}\n</code></pre></div><p>We needed a flexible system where:\n •Frontend and backend of a feature can be plugged in dynamically<p>\n •Plugins can register API, inject middleware, or render UI</p>\n •Everything is hot-reloadable during development</p><p>So instead of rebuilding another monolith, we created PalyNext.</p><div><pre><code>git clone https://github.com/palynext/platform.git\ncd platform\nmake install\npnx run dev --mode=dev\n</code></pre></div><p>🧠 Contribute or Explore\nWe’re just getting started — plugin system is stable, UI is modular.<p>\nFeel free to explore, fork, or build your own plugin!</p></p><p>⭐ Star us on GitHub: github.com/palynext/platform</p><p>Built with love by the PalyNext Team\nInspired by Slack, Mattermost, Gitea, Coolify, and modern dev tooling.</p>","contentLength":1701,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Real-time with Redis Streams in Go","url":"https://dev.to/lovestaco/real-time-with-redis-streams-in-go-1hlh","date":1750274726,"author":"Athreya aka Maneshwar","guid":161513,"unread":true,"content":"<p><em>Hi there! I'm <a href=\"https://linktr.ee/maneshwar\" rel=\"noopener noreferrer\">Maneshwar</a>. Right now, I’m building <a href=\"https://hexmos.com/landing/liveapi\" rel=\"noopener noreferrer\">LiveAPI</a>, a first-of-its-kind tool that helps you automatically index API endpoints across all your repositories. LiveAPI makes it easier to , , and  in large infrastructures.</em></p><p>Redis Streams give you Kafka-like message queues with Redis simplicity. Whether you’re building real-time analytics, background job pipelines, or chat systems, Redis Streams can help.</p><p>In this post, we’ll cover:</p><ul><li>Writing to a Stream in Go</li><li>Reading from a Stream in Go</li><li>Stream Configuration Parameters</li></ul><p>A Redis Stream is an append-only log data structure where each entry has a unique ID and a set of key-value fields.</p><p>You write using , read using , and scale consumption using consumer groups.</p><div><pre><code>\nXADD mystream  name Alice action login\n</code></pre></div><div><pre><code>apt redis\nredis-server\n</code></pre></div><div><pre><code>go get github.com/redis/go-redis/v9\n</code></pre></div><h2>\n  \n  \n  Writing to a Stream in Go\n</h2><div><pre><code></code></pre></div><h2>\n  \n  \n  Reading from a Stream in Go\n</h2><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h2>\n  \n  \n  Stream Configuration Parameters\n</h2><div><pre><code>XADD mystream MAXLEN 1000  field1 val1\n</code></pre></div><p><strong>Approximate Trimming (better performance):</strong></p><div><pre><code>XADD mystream MAXLEN ~ 1000  field1 val1\n</code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>Tune these Redis configs for stream node sizes:</p><div><pre><code>CONFIG SET stream-node-max-bytes 4096\nCONFIG SET stream-node-max-entries 100\n</code></pre></div><p>Helps approximate trimming work better and keeps memory predictable.</p><h3>\n  \n  \n  Persistence with PERSIST flag\n</h3><p>Use  in Redis CLI to force entry persistence:</p><div><pre><code>XADD mystream PERSIST MAXLEN ~ 500  field val\n</code></pre></div><p>(Current Go clients may not support this yet.)</p><div><table><thead><tr></tr></thead><tbody><tr></tr><tr><td><code>XAddArgs{MaxLen:1000,Approx:true}</code></td></tr><tr><td><code>XTrimArgs{MaxLenApprox:1000}</code></td></tr><tr><td><code>XTrimArgs{MinID:\"1605...-0\"}</code></td></tr><tr></tr><tr><td>not yet exposed in Go clients</td></tr></tbody></table></div><p>Redis Streams give you a fast and easy way to handle real-time queues in Go. </p><p>Tune configuration parameters, manage stream size, and scale with consumer groups to keep your system lean and reliable.</p><p><a href=\"https://hexmos.com/landing/liveapi\" rel=\"noopener noreferrer\">LiveAPI</a> helps you get all your backend APIs documented in a few minutes.</p><p>With LiveAPI, you can <strong>generate interactive API docs</strong> that allow users to search and execute endpoints directly from the browser.</p><p>If you're tired of updating Swagger manually or syncing Postman collections, give it a shot.</p>","contentLength":2019,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Making the Best of Pointers in Go","url":"https://dev.to/shrsv/making-the-best-of-pointers-in-go-399k","date":1750265455,"author":"Shrijith Venkatramana","guid":161359,"unread":true,"content":"<p>Pointers in Go can feel like a puzzle for developers coming from languages like Python or JavaScript. They’re powerful, but they can trip you up if you don’t get how they work. Go’s approach to pointers is straightforward, yet it demands a clear understanding to use them effectively. This guide dives deep into , with practical examples, tables, and tips to make them your ally. Let’s break it down step by step.</p><h2>\n  \n  \n  Why Pointers Matter in Go\n</h2><p>Pointers let you work directly with memory addresses, which can optimize performance and allow precise control over data. In Go, they’re a core feature for  and  in functions. Unlike C, Go simplifies pointer usage—no pointer arithmetic, no dangling pointers—but you still need to know when and why to use them.</p><p>Here’s the deal: Go uses  by default. When you pass a variable to a function, Go copies it. Want to modify the original? That’s where pointers shine. They let you pass a reference to the data instead of a copy, saving memory and enabling changes to persist.</p><ul><li><strong>Pointers reference memory addresses</strong>, not the data itself.</li><li>Go’s pointers are safe—no manual memory management.</li><li>Use pointers for efficiency or to modify original data.</li></ul><h2>\n  \n  \n  Declaring and Using Pointers: The Basics\n</h2><p>A pointer in Go is declared with the  operator, and you get a variable’s address with . The syntax is simple but takes practice to feel natural.</p><div><pre><code></code></pre></div><ul><li> is a pointer to ’s memory address ().</li><li> dereferences the pointer to access or modify ’s value.</li></ul><p>: The  operator is your gateway to the value at a pointer’s address. Without it, you’re just messing with the address itself.</p><h2>\n  \n  \n  When to Use Pointers vs. Values\n</h2><p>Deciding between pointers and values depends on your use case. Here’s a table to clarify:</p><div><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr><td>Small primitives (int, bool)</td></tr><tr><td>No (they’re already references)</td></tr></tbody></table></div><p>For small data like integers, passing by value is fine—copying is cheap. For big structs, pointers save memory by avoiding copies. Slices and maps? They’re already reference types, so pointers are often unnecessary.</p><p>Example of modifying a struct with a pointer:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Pointers and Structs: A Perfect Match\n</h2><p>Structs are where pointers really shine. Copying a large struct can be expensive, so passing a pointer is often smarter. Plus, if you want a function to update a struct’s fields, you need a pointer.</p><p>Here’s an example with a more complex struct:</p><div><pre><code></code></pre></div><p>: Always use pointers when modifying struct fields in functions. Without them, you’re just changing a copy.</p><h2>\n  \n  \n  Nil Pointers: Avoiding the Panic\n</h2><p>A common gotcha is the , which crashes your program. A pointer that’s declared but not initialized points to . Dereferencing it? Boom, panic.</p><p>Here’s an example of what  to do:</p><div><pre><code></code></pre></div><ul><li><strong>Always initialize pointers</strong> before dereferencing.</li><li>Check for  if you’re unsure.</li></ul><div><pre><code></code></pre></div><p>: Add  checks in functions that accept pointers to prevent crashes.</p><h2>\n  \n  \n  Pointers with Methods: Receiver Types\n</h2><p>In Go, methods can have pointer or value receivers. A  lets a method modify the original struct, while a value receiver works on a copy.</p><p>Here’s an example contrasting both:</p><div><pre><code></code></pre></div><p>When to use pointer receivers:</p><ul><li>To modify the receiver’s state.</li><li>For large structs to avoid copying.</li><li>For consistency if other methods on the type use pointers.</li></ul><h2>\n  \n  \n  Pointers and Performance: When They Save the Day\n</h2><p>Pointers can boost performance by reducing memory usage. Copying large structs or arrays is costly, but passing a pointer is just passing an address (8 bytes on 64-bit systems). Here’s an example showing the difference:</p><div><pre><code></code></pre></div><p>: For large data, pointers avoid expensive copies and enable modifications. For small data, the overhead of dereferencing might outweigh the benefits—test it!</p><h2>\n  \n  \n  Common Pitfalls and How to Avoid Them\n</h2><p>Pointers are powerful but tricky. Here are common mistakes and fixes:</p><div><table><tbody><tr><td>Dereferencing nil pointers</td><td>Check for  before dereferencing</td></tr><tr><td>Overusing pointers for small types</td><td>Use values for small primitives</td></tr><tr><td>Forgetting  when passing to pointer params</td><td>Double-check function signatures</td></tr><tr><td>Modifying slices thinking they’re pointers</td><td>Understand slices are reference types</td></tr></tbody></table></div><p>Example of a slice gotcha:</p><div><pre><code></code></pre></div><p>Slices are references, so you don’t need pointers here. But appending to a slice might not work as expected if the underlying array’s capacity changes—another topic for another day.</p><h2>\n  \n  \n  Putting Pointers to Work: Practical Tips\n</h2><p>Pointers are a tool, not a mystery. Here’s how to use them effectively:</p><ul><li><strong>Use pointers for mutability</strong>: If a function needs to change a variable or struct, pass a pointer.</li><li>: Pass pointers to big structs or arrays to avoid copying.</li><li>: Don’t overuse pointers for small types like  or —values are often fine.</li><li>: Always check pointers in functions to avoid panics.</li><li><strong>Leverage pointer receivers</strong>: Use them for methods that modify structs or for performance with large types.</li></ul><p>Here’s a final example combining everything:</p><div><pre><code></code></pre></div><p>This code shows a pointer receiver for a method, a nil check, and practical pointer usage. Run it, and it’s rock-solid.</p><p>Pointers in Go aren’t scary once you get the hang of them. They’re about control and efficiency. Practice with small examples, lean on nil checks, and use them where they make sense—your Go code will thank you.</p>","contentLength":5163,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Rewriting Python in Go Can Boost Speed, Concurrency & Efficiency","url":"https://dev.to/evrone/why-rewriting-python-in-go-can-boost-speed-concurrency-efficiency-4gc","date":1750255063,"author":"Evrone","guid":161228,"unread":true,"content":"<p>Rewriting Python projects in Go can greatly enhance performance, concurrency, and deployment efficiency, particularly for high-load or cloud-native systems. Go offers fast execution, built-in concurrency, static typing, and simpler deployment. However, migration may not suit projects reliant on specific Python libraries or teams lacking Go expertise. Consider strategic goals before switching.</p>","contentLength":395,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Capital Letters Made My Workmate Quit Go—But Should You?","url":"https://dev.to/jjpinto/capital-letters-made-my-workmate-quit-go-but-should-you-kbh","date":1750250872,"author":"jjpinto","guid":161193,"unread":true,"content":"<p>One of Go’s simplest rules—capitalization for visibility—turned my colleague off the language entirely. But is it really that bad? In this article, I explore why this rule exists, why it feels weird, and why it might actually be one of Go’s smartest design choices.</p><h3><strong>The Moment My Workmate Walked Away</strong></h3><p>A few weeks ago, I told a workmate I was learning Go. His response?\n\"Congrats—but I could never deal with a language where capital letters decide everything.\"</p><p>At first, I laughed. Then I realized he wasn’t joking. For him, the idea that a function’s visibility depends on whether it starts with a capital letter was enough to walk away from the language entirely.</p><p>It got me thinking: <strong>Is this rule really that strange—or are we just not used to simplicity when we see it?</strong></p><h3><strong>Why Go Uses Capitalization for Visibility</strong></h3><p>In Go, capitalization isn’t just a style choice—it’s a visibility rule.</p><ul><li>If a function, variable, or type starts with a capital letter, it’s exported (public).</li><li>If it starts with a lowercase letter, it’s unexported (private to the package).</li></ul><p>There’s no public, private, or protected keyword. This minimalist approach aligns with Go’s philosophy: <strong>fewer keywords, more clarity</strong>. But for developers coming from Java, C#, or Python, this can feel unintuitive—even frustrating—at first glance.</p><h3>\n  \n  \n  Simplicity Can Feel Complicated\n</h3><p>For many developers—especially those from object-oriented backgrounds—this rule feels like a step backward. We’re used to  visibility modifiers: public, private, protected.</p><p>But Go takes a  approach. The rule is simple, consistent, and enforced by the compiler. Once you get used to it, it becomes second nature—and you start to appreciate how much boilerplate it eliminates.</p><h3>\n  \n  \n  Example: Capitalization and Visibility in Go\n</h3><div><pre><code></code></pre></div><ul><li><p>SayHello is exported (public) because it starts with a capital letter. It can be accessed from other packages.</p></li><li><p>sayGoodbye is unexported (private) because it starts with a lowercase letter. It can only be used within the same package.</p></li></ul><h3>\n  \n  \n  Should One Rule Make You Quit Go?\n</h3><p>I don’t think so. Every language has its quirks—Java has checked exceptions, Python has strict indentation, and C# has LINQ syntax. Go’s capitalization rule might seem odd at first, but it’s a small price to pay for a language that offers fast compilation, powerful concurrency, and a clean, consistent developer experience.</p><p>If you’re curious about Go, don’t let a capital letter stop you. Dive in—you might just find it’s exactly what you’ve been looking for.</p><p><em>Have you ever struggled with Go's capitalization rule? Does it make the language harder or simpler for you? Let me know in the comments!</em></p><h6>\n  \n  \n  This post was reviewed with AI assistance to refine clarity and structure\n</h6>","contentLength":2770,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SnapSys - A Lightweight Linux CLI for System Snapshots (CPU, Memory, Disk) in JSONL","url":"https://dev.to/marcumjv/snapsys-a-lightweight-linux-cli-for-system-snapshots-cpu-memory-disk-in-jsonl-6h","date":1750250329,"author":"Marcus Vorster","guid":161192,"unread":true,"content":"<p>I just released my first open source Go project: SnapSys, a simple CLI tool designed to capture CPU, memory, and disk usage at fixed intervals and export the data as structured JSONL.</p><p>It’s a small but powerful utility aimed at:</p><p>Developers running performance benchmarks\nEngineers debugging resource issues<p>\nDevOps teams logging metrics inside CI/CD pipelines or containers</p>\nTinkerers who want raw, lightweight system metrics to feed into custom tools</p><p>What is SnapSys?\nSnapSys is a Linux-only CLI tool written in Go that periodically takes a snapshot of your system’s:</p><p>CPU usage (percentage, user/system time, etc.)\nMemory usage (total, used, available)<p>\nDisk usage (per mount point)</p>\nAnd logs it in clean newline-delimited JSON (JSONL). Perfect for:</p><p>Feeding into Elasticsearch, Loki, or other log engines\nPlotting with Grafana, Python, or Jupyter<p>\nUsing in bash or Go scripts to trigger events</p>\nKeeping lightweight logs during builds, deployments, or CI steps</p><p>I’m trying to get more involved in the open source world and build tools that are useful to developers like me.</p><p>If you try it and have any feedback (good or bad), I’d love to hear it. Feature requests, PRs, and even critiques are all welcome.</p><p>GitHub: github.com/MarcusMJV/snapsys</p><p>Thanks for reading,\nMarcus</p>","contentLength":1259,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"🚀 Go Testing Unleashed: From Basics to Beast Mode","url":"https://dev.to/tavernetech/go-testing-unleashed-from-basics-to-beast-mode-326b","date":1750248000,"author":"Taverne Tech","guid":161161,"unread":true,"content":"<ol><li>Go's Built-in Testing Superpowers</li><li>Advanced Testing Frameworks and Power Tools</li><li>Testing Best Practices and Hidden Gems</li></ol><p>Picture this: You're debugging a Go application at 2 AM, fueled by coffee and existential dread, wondering why your \"simple\" function is behaving like a rebellious teenager. Sound familiar? 😅</p><p>If  is like driving blindfolded on a highway, then Go's testing ecosystem is your GPS, seatbelt, and airbag all rolled into one beautiful, minimalist package. Unlike other languages that require you to assemble an entire testing arsenal, Go's philosophy is refreshingly simple: \"<em>Less is more, but make that 'less' absolutely fantastic.</em>\"</p><p>Today, we're diving deep into Go's testing universe – from the surprisingly powerful built-in tools to the advanced frameworks that'll make you feel like a testing ninja. Buckle up! 🥋</p><h2>\n  \n  \n  1. Go's Built-in Testing Superpowers 🦸‍♂️\n</h2><p>Go's testing approach is like having that minimalist friend who owns only three shirts but somehow always looks impeccable. The  package might seem simple, but it's .</p><p>Here's a fun fact that'll blow your mind: <strong>Rob Pike initially wanted Go's testing package to have even fewer features!</strong> The current design is the result of heated debates among the Go team about striking the perfect balance between simplicity and functionality.</p><div><pre><code></code></pre></div><p>: The  method was added in Go 1.7 and revolutionized test organization. It's like having folders within folders, but for your test cases! 📁</p><ul><li> with </li><li> with </li><li> that double as documentation</li><li> with  flag (catches ~95% of data races!)</li></ul><h2>\n  \n  \n  2. Advanced Testing Frameworks and Power Tools ⚡\n</h2><p>While Go's built-in testing is fantastic, sometimes you need more spice in your testing soup. Enter the world of <strong>external testing frameworks</strong> – they're like adding hot sauce to an already great meal.</p><p>: The  library is used in over  on GitHub! It's practically the unofficial standard for Go testing assertions.</p><div><pre><code></code></pre></div><ul><li>: Assertions and mocks that don't make you cry</li><li>: Generate mocks automatically (because life's too short for manual mocks)</li><li>: BDD-style testing for the behavior-driven crowd</li><li>: Built-in HTTP testing that's surprisingly robust</li></ul><p>: Go's  package can create actual HTTP servers for testing – it's like having a pocket-sized web server! 🌐</p><h2>\n  \n  \n  3. Testing Best Practices and Hidden Gems 💎\n</h2><p>Here's where we separate the testing rookies from the . Table-driven tests in Go are like meal prep for developers – a little effort upfront saves you tons of time later (and prevents the dreaded \"works on my machine\" syndrome).</p><div><pre><code></code></pre></div><ul><li>: Aim for 80-90% (100% is often overkill and expensive to maintain)</li><li>: Always run tests with  in CI/CD</li><li>: Use <code>TestFunctionName_Scenario_ExpectedBehavior</code> pattern</li><li>: Store expected outputs in files for complex data structures</li></ul><p>: Go's race detector uses a technique called \"happens-before\" analysis and can catch concurrency bugs that would take weeks to find manually. It's like having a time-traveling debugger! ⏰</p><p>We've journeyed from Go's elegantly simple built-in testing tools to the advanced frameworks that can handle enterprise-level complexity. The beauty of Go's testing ecosystem lies in its  philosophy – start simple, add complexity only when needed.</p><p>Remember: <strong>Good tests are like good friends</strong> – they're there when you need them, they tell you the truth (even when it hurts), and they make everything better in the long run.</p><p>, should you choose to accept it: Pick one untested function in your current project and write a test for it. Then another. Before you know it, you'll be sleeping better at night, deploying with confidence, and earning the respect of your fellow developers. </p><p>What's the real cost of not testing? Your sanity, your reputation, and probably your weekend plans. 😉</p><p><em>Now go forth and test responsibly!</em> 🧪✨</p>","contentLength":3761,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[Boost]","url":"https://dev.to/aymanepraxe/-26j","date":1750244950,"author":"aymane aallaoui","guid":161160,"unread":true,"content":"<h2>Embracing TypeScript Principles in Go: The Creation of a Zod-Inspired Validation Library</h2>","contentLength":88,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BAS16 Diode: The Little Star Anchoring Modern Tech","url":"https://dev.to/ersajay/bas16-diode-the-little-star-anchoring-modern-tech-g75","date":1750229207,"author":"ersajay","guid":161012,"unread":true,"content":"<p>A Meeting in the Circuit Desert\nWhen I first wandered into the desert of soldering irons and humming circuit boards, I thought all diodes were like the flashy ones I’d seen—polished, loud, and eager to prove their worth. But then I met the BAS16—a tiny SOT-23 package, sitting quietly on a workbench like a single cactus in the sand.<p>\n“You’re… small,” I said, tilting my head.</p>\n“And you’re a child who talks to diodes,” it replied, its surface glinting softly. “But size isn’t what matters. Ask the fox.”</p><p>The Secret of Its Desert Bloom\nThis isn’t just silicon—it’s desert magic. Let me tell you its story:</p><p>Size: 2.9mm x 1.3mm, smaller than a ladybug’s wing. It fits where even the smallest tools can’t reach.\nVoltage: 100V, steady as the roots of a baobab tree. It laughs at power surges, like the cactus laughs at sandstorms.<p>\nSpeed: 4 nanoseconds—faster than a shooting star. It switches signals before you can blink.</p>\nTemp Range: -55°C to 150°C. It survives Arctic cold and Death Valley heat, unflinching.</p><p>Fun Fact: Engineers call it the “Swiss Army knife of <a href=\"https://www.ersaelectronics.com/product\" rel=\"noopener noreferrer\">diodes</a>.” They steal it from factory floors like children steal stars—because once you find one, you never let go.</p><p>The Cactus of Reliability\nOn the planet of electronics, where machines roar and sparks fly, <a href=\"https://www.ersaelectronics.com/blog/what-is-the-bas16\" rel=\"noopener noreferrer\">the BAS16</a> thrives.\n“Why not a cheaper diode?” I asked a welding robot.<p>\n“Cheaper diodes cry when sparks land. This one? It hums.”</p>\nIt shrugs off cosmic radiation (NASA uses it in rovers), ignores clumsy interns with soldering irons, and outlasts power surges like a desert plant outlasts drought.<p>\n“You’re unkillable,” I said.</p>\n“Not unkillable,” it replied. “Just… prepared. Like the cactus that stores water—we both know hard times come.”</p><p>The Guardian of Invisible Things\nIn the quiet corners of the universe, the BAS16 holds what matters:</p><p>Healthcare: It powers pacemakers, counting heartbeats softer than a fox’s footsteps. In ERs, it survives accidental drops and chaos—so your heart never gets a “404 Error.”\nAutomotive: It keeps EV batteries safe, stopping sparks before they dance into fires. In car infotainment systems, it outlasts toddler tantrums and juice spills.<p>\nSpace &amp; Telecom: It holds satellites steady in zero gravity, so they can drink sunlight like roses drink rain. In 5G routers, it handles peak Netflix hours without a hiccup.</p></p><p>“You’re a hero,” I told it.\n“Heroes have parades,” it said. “I’m just a diode. But parades don’t keep hearts beating—diodes do.”</p><p>The Tale of the Three Diodes\nOnce, I met three diodes in a workshop: 1N4148, LED, and BAS16.</p><p>1N4148 preened: “I’m fast too!” But a static shock made it wince.\nLED giggled: “I light up!” But it faltered in the dark corners of a pacemaker.<p>\nBAS16 said nothing. It just switched signals, steady as the desert’s horizon.</p></p><p>Later, I asked the fox: “Why does everyone choose the quiet one?”\n“Because the best things are invisible to the eye,” the fox said. “Like the wind, or love, or a diode that never fails.”</p><p>When the Cactus Isn’t Needed\nEven cacti have their limits. The BAS16 sighed:<p>\n“I’m not for ultra-low power devices—Schottky diodes save energy, though they’ll falter in storms. I’m not for art projects—save me for tech that matters. And I’m overkill for disposable gadgets—let cheaper diodes handle landfill-bound toys.”</p>\n“So when do you shine?” I asked.<p>\n“When the project matters,” it said. “Fire, radiation, interns… if it’s worth doing, it’s worth doing with something that lasts.”</p></p><p>How to Find a True Friend\nIn the market of diodes, not all are real. The BAS16 warned:<p>\n“Beware of counterfeits—they fail faster than a child’s promise to water a rose. Trust distributors like Ersa Electronics. Check for Vishay or Nexperia markings. Demand certifications—fakes can’t fake those.”</p>\n“How do I know it’s you?” I asked.<p>\n“You’ll feel it,” it said. “A real diode doesn’t shout. It just… works.”</p></p><p>The Star That Never Fades\nIn 2050, when humans build colonies on Mars, the BAS16 will be there. It’ll power quantum computers (even qubits need something steady), Mars habitats (cosmic radiation can’t break it), and robot arms (when AI overlords revolt, they’ll use it to build… well, let’s not think about that).<p>\n“You’ll outlive us all,” I said.</p>\n“No,” it replied. “I’ll just keep holding. Because stars don’t stay in the sky by magic—they stay because something anchors them.”</p><p>The Secret of the Little Diode\nThe BAS16 isn’t flashy. It doesn’t need a name in lights. It’s the kind of friend you notice only when it’s gone—like the rose in the garden, or the fox’s footsteps in the sand.<p>\n“What makes you special?” I asked, as I packed to leave.</p>\nIt didn’t answer. It just switched a signal, steady as the desert, as the stars, as time itself.<p>\nAnd I realized—important things are never the loudest. They’re the ones that stay.</p></p><p>Written by a wanderer who once mistook a diode for a new planet. The BAS16 set me straight.\n🌵 You become responsible, forever, for the diodes you ignore.</p>","contentLength":5139,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Advanced Go Concurrency: Channel Patterns for Real-World Problems","url":"https://dev.to/jones_charles_ad50858dbc0/advanced-go-concurrency-channel-patterns-for-real-world-problems-33ce","date":1750207396,"author":"Jones Charles","guid":160056,"unread":true,"content":"<h4>\n  \n  \n  1. Hey, Let’s Talk Concurrency in Go!\n</h4><p>Concurrency is everywhere—scaling web apps, crunching data on multi-core beasts. Go makes it fun with goroutines (lightweight threads) and channels (data pipelines), but it’s easy to trip. Too many goroutines frying your CPU? Tasks clashing? That’s where  kicks in—channels are the chill teacher keeping rowdy goroutines in line.</p><p>This isn’t “Concurrency .” If you’ve got 1-2 years of Go and know goroutines and channels, you’re in the right spot. We’re diving into advanced channel tricks—rate limiting, producer-consumer, task splitting—with real-world examples from my projects. Code, pitfalls, and tips await. Let’s tame the chaos and unlock channel magic together!</p><h4>\n  \n  \n  2. Why Channels Rock Concurrency\n</h4><h5>\n  \n  \n  2.1 Channels (Quick Refresh)\n</h5><p>Channels pass data between goroutines. Two flavors:</p><ul><li>: Sender and receiver sync—like a high-five needing both hands.</li><li>: Sender queues data (with a limit) and moves on—like a mailbox.</li></ul><p>Locks () guard stuff; channels flow data. Go’s motto? “Share memory by communicating.”</p><h5>\n  \n  \n  2.2 What Makes Channels Awesome?\n</h5><p>Here’s why I stan channels:</p><ul><li>: Thread-safe by default—no race conditions or  slip-ups.</li><li>: Pass data to signal “go” or “stop”—goroutines texting each other.</li><li>: Stack ‘em into pipelines or split tasks. They glue patterns together.</li><li>: Scales with tons of goroutines, no lock spaghetti.</li></ul><div><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table></div><ul><li>:  yells “done!” to all listeners—clean shutdowns.</li><li>: Juggles multiple channels or timeouts—like a traffic cop.\n</li></ul><div><pre><code></code></pre></div><p>Channels aren’t just pipes—they’re your concurrency Swiss Army knife.</p><h4>\n  \n  \n  3. Channel Patterns That Solve Real Problems\n</h4><p>Channels shine in tough spots. Here are three I use constantly: , , —with code and scars.</p><h5>\n  \n  \n  3.1 Rate Limiting: Keep the Floodgates in Check\n</h5><p><p>\nAPI slamming a DB with goroutines? Connection pool dies. Rate limiting caps the chaos.</p></p><p><p>\nBuffered channel as a “token bucket”—grab a token to work, release it when done.</p></p><div><pre><code></code></pre></div><p>: Simple throttle, saves resources.: Set it to 50 once—DB cried. Tuned to 20 after monitoring.</p><h5>\n  \n  \n  3.2 Producer-Consumer: Teamwork Makes the Dream Work\n</h5><p><p>\nLogs or downloads? Producers make tasks; consumers process ‘em—smooth and separate.</p></p><p><p>\nUnbuffered channel as a queue. Close it to signal “done.”</p></p><p><p>\n1 producer, 3 consumers, 10 tasks:</p></p><div><pre><code></code></pre></div><p>: Balances load, clean split.: Skipped —consumers hung.  bailed me out.</p><h5>\n  \n  \n  3.3 Fan-out/Fan-in: Divide and Conquer\n</h5><p><p>\nParallelize tasks (e.g., API calls) and collect results? Fan-out spreads; Fan-in gathers.</p></p><p><p>\nOne channel dispatches, another collects.</p></p><div><pre><code></code></pre></div><p>: Maxes CPU, modular.: No timeout—stalled worker froze it. Added  later.</p><h4>\n  \n  \n  4. Channels in the Wild: Real Projects, Real Wins\n</h4><h5>\n  \n  \n  4.1 Rate Limiting an API Under Fire\n</h5><p>: Order API with 10k+ reqs/sec—DB and Redis choked.: Token pool with .:</p><div><pre><code></code></pre></div><p>: Flex token size, use .: Botched —leaked goroutines. Fixed with .</p><h5>\n  \n  \n  4.2 Data Pipeline: Logs at Scale\n</h5><p>: Millions of logs—sequential too slow, parallel too wild.: Pipeline with channel handoffs.:</p><div><pre><code></code></pre></div><p>: Stage it, tune buffers.: Big buffers spiked RAM—cut to 10.</p><h5>\n  \n  \n  4.3 Batch Uploads with Status Updates\n</h5><p>: File uploads needing live status.: Tasks and results channels.:</p><div><pre><code></code></pre></div><p>: Async updates, clear structs.: Forgot —deadlocked. Fixed with .</p><h4>\n  \n  \n  5. Channel Wisdom: Tips, Traps, and Tuning\n</h4><ul><li>: Unbuffered for sync, buffered for slack.</li><li>:  signals,  juggles.</li><li>: Kill goroutines cleanly.</li></ul><ul><li>: 1000 crushed memory—start small, test.</li><li>: Unclosed channels—run .</li></ul><div><table><tbody><tr></tr><tr></tr></tbody></table></div><ul><li>:  finds ‘em—tweak buffers or goroutines.</li><li>: Channels for flow,  for locks,  for sync.</li><li>: Adjust limits with load.</li></ul><h4>\n  \n  \n  6. Wrapping Up: Channels Are Your Superpower\n</h4><p>Channels tame goroutines with elegance—rate limit, pipeline, split tasks. They’re safe, flexible, clean. Try ‘em out—throttle an API, process data. Hands-on is where it clicks.</p><p>Go’s concurrency evolves—think  or distributed channels. Watch proposals and trends.</p><p>Love channels’ clarity, hate the 2 a.m. deadlocks. Every goof taught me—’s my buddy. Code it, break it, learn. What’s your channel tale? Bugs? Wins? Hit the comments—let’s chat!</p>","contentLength":4128,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dealing with race conditions","url":"https://golangweekly.com/issues/558","date":1750204800,"author":"","guid":161183,"unread":true,"content":"<li><p><a href=\"https://golangweekly.com/link/170584/rss\">Glance</a> is a Go-powered personal information dashboard/portal where you can bring together RSS feeds, Reddit posts, Hacker News posts, YouTube channel updates, stock prices, and&nbsp;more.</p></li><li><p><a href=\"https://golangweekly.com/link/170591/rss\">Glojure</a> is a Clojure interpreter, hosted on&nbsp;Go.</p></li>","contentLength":231,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Robust Error Handling in Go Web Projects with Gin","url":"https://dev.to/leapcell/robust-error-handling-in-go-web-projects-with-gin-l01","date":1750188114,"author":"Leapcell","guid":159866,"unread":true,"content":"<p>In Go project development, error handling is one of the keys to building stable and reliable web services. An efficient error handling mechanism can not only catch unhandled exceptions but also provide clear and user-friendly error information to clients through a unified response structure. In this article, we will discuss how to implement global error capture, custom HTTP error codes, business error classification handling in Gin, as well as integrating Sentry for advanced error monitoring.</p><h2>\n  \n  \n  Global Error Capture: Enhancing the Recovery Middleware\n</h2><p>Gin provides a Recovery middleware for capturing unhandled panics and preventing the program from crashing. However, by default, the Recovery middleware only returns a generic HTTP 500 error. By enhancing it, we can achieve more flexible global exception capture and handling.</p><p>By default, Gin’s Recovery will capture all unhandled panics and return an internal server error:</p><div><pre><code></code></pre></div><p>When accessing /panic, the client will receive:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Custom Recovery: Capturing Exceptions and Logging\n</h3><p>By customizing the Recovery middleware, we can log errors into the logging system while returning a structured error response.</p><div><pre><code></code></pre></div><p>With the customized Recovery, we capture exceptions and return more detailed error information, while keeping error logs for future debugging.</p><h2>\n  \n  \n  Custom HTTP Error Codes and Response Structure\n</h2><p>A unified error code and response structure is a best practice for modern APIs. It helps the frontend clearly understand what error has occurred and take corresponding actions.</p><h3>\n  \n  \n  Defining a Standard Response Structure\n</h3><p>We can define a universal response format to unify all successful and failed responses.</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Error Response Utility Functions\n</h3><p>By encapsulating utility functions, we simplify the process of generating error responses.</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h2>\n  \n  \n  Business Error Classification Handling\n</h2><p>In complex systems, different types of errors (such as database errors, authentication errors) need to be handled separately. By encapsulating error types, we can achieve clearer error classification and responses.</p><h3>\n  \n  \n  Defining Business Error Types\n</h3><div><pre><code></code></pre></div><p>By checking the error type, different responses can be generated.</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h2>\n  \n  \n  Integrating Sentry for Error Monitoring\n</h2><p>Sentry is a popular error tracking platform that helps developers monitor and analyze exceptions in production environments in real time.</p><p>For specific integration methods, please refer to the official documentation. We will not elaborate in detail here.</p><h3>\n  \n  \n  Official Example for the Go SDK\n</h3><div><pre><code></code></pre></div><p>When an exception occurs in the application, the error will be automatically sent to the Sentry dashboard. Developers can view detailed error stack information in real time and clearly see which endpoint had how many error requests during a specific period.</p><ul><li><ul><li>Globally capture serious exceptions.</li><li>Refine error classification at the business layer and provide specific feedback information.</li></ul></li><li><p>Unified response structure:</p><ul><li>Ensure that the response formats for both success and failure are consistent, making it easier for the frontend to handle.</li></ul></li><li><ul><li>Integrate tools (such as Sentry) to capture exceptions in the environment and locate issues as soon as possible.</li></ul></li><li><ul><li>Define a unique error code for each error type, making it easier to quickly locate and troubleshoot problems.</li></ul></li></ul><p><a href=\"https://leapcell.io/?lc_t=d_handleginerr\" rel=\"noopener noreferrer\">Leapcell</a> is the Next-Gen Serverless Platform for Web Hosting, Async Tasks, and Redis:</p><ul><li>Develop with Node.js, Python, Go, or Rust.</li></ul><p><strong>Deploy unlimited projects for free</strong></p><ul><li>pay only for usage — no requests, no charges.</li></ul><p><strong>Unbeatable Cost Efficiency</strong></p><ul><li>Pay-as-you-go with no idle charges.</li><li>Example: $25 supports 6.94M requests at a 60ms average response time.</li></ul><p><strong>Streamlined Developer Experience</strong></p><ul><li>Intuitive UI for effortless setup.</li><li>Fully automated CI/CD pipelines and GitOps integration.</li><li>Real-time metrics and logging for actionable insights.</li></ul><p><strong>Effortless Scalability and High Performance</strong></p><ul><li>Auto-scaling to handle high concurrency with ease.</li><li>Zero operational overhead — just focus on building.</li></ul>","contentLength":3932,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Golang Fundamentals: From \"Hello World!\" to File Paths & CLI Subcommands","url":"https://dev.to/labex/golang-fundamentals-from-hello-world-to-file-paths-cli-subcommands-2mpj","date":1750179781,"author":"Labby","guid":159816,"unread":true,"content":"<p>Embark on an exciting journey into the world of Golang, a language celebrated for its efficiency, concurrency, and simplicity. This Skill Tree is your structured roadmap, guiding you through Go's core concepts with hands-on challenges. Forget passive learning; here, you'll write code, solve problems, and build practical skills in an interactive environment. Whether you're a seasoned developer looking to add Go to your toolkit or a curious beginner, this path offers a clear, engaging way to master Go's syntax, concurrency model, and standard library. Let's dive into the labs that will transform you into a proficient Go programmer.</p><p> Beginner |  5 minutes</p><p>This Golang challenge aims to test your basic understanding of the language syntax and structure. You will be required to write a simple program that prints the classic 'hello world' message.</p><h2>\n  \n  \n  Golang Constants Programming Challenge\n</h2><p> Beginner |  5 minutes</p><p>This challenge aims to test your understanding of constants in Golang.</p><h2>\n  \n  \n  File Path Handling in Golang | Challenge\n</h2><p> Beginner |  5 minutes</p><p>The filepath package in Golang provides functions to parse and construct file paths in a way that is portable between operating systems.</p><h2>\n  \n  \n  Command Line Subcommands | Challenge\n</h2><p> Beginner |  5 minutes</p><p>This challenge aims to test your ability to define and use subcommands with their own set of flags in Golang.</p><h2>\n  \n  \n  Go Functions Fundamentals\n</h2><p> Beginner |  5 minutes</p><p>In this challenge, we will learn about functions in Go. We will see how to define functions, how to pass arguments to them, and how to return values from them.</p><p>Ready to embark on your Go journey? These challenges are just the beginning. Each completed lab builds your confidence and practical skills, transforming you from a curious beginner into a proficient Go developer. Dive in, explore, and unlock the power of Golang!</p>","contentLength":1854,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"🚀 Build Your Own Email-to-Webhook Gateway in Go (SMTPHook is Live!)","url":"https://dev.to/voidwatch/build-your-own-email-to-webhook-gateway-in-go-smtphook-is-live-27eb","date":1750177477,"author":"Johan","guid":159782,"unread":true,"content":"<h4>\n  \n  \n  I just open-sourced SMTPHook — a self-hosted email ingestion service written in Go. If you've ever wanted to turn  into structured  (e.g. to ping a pager, log alerts, trigger bots, etc.), this tool is for you. If it works for you consider sponsor me with a coffee <a href=\"https://buymeacoffee.com/voidwatch\" rel=\"noopener noreferrer\">https://buymeacoffee.com/voidwatch</a></h4><p>SMTPHook is a modular platform that:</p><p>✅ Accepts SMTP emails via <a href=\"https://github.com/axllent/mailpit\" rel=\"noopener noreferrer\">Mailpit</a><p>\n✅ Parses raw emails into structured JSON</p><p>\n✅ Forwards the payload to your webhook endpoint</p><p>\n✅ Includes retry logic, logging, health checks</p>, or as containers via <p>\n✅ Supports full local testing with </p></p><ul><li>Alerting: Email → Webhook → PagerDuty / Discord / Slack\n</li><li>Archiving: Email → JSON → S3 / DB / Elasticsearch\n</li><li>Automation: Email triggers CI/CD, bots, or workflows\n</li><li>Dev Testing: No need to poll real mailboxes anymore</li></ul><div><pre><code>git clone git@github.com:voidwatch/SMTPHook-Golang.git\nSMTPHook-Golang\n +x setup.sh\n./setup.sh\n</code></pre></div><div><pre><code>swaks @example.com  localhost:1025 &lt; email.txt\n</code></pre></div><p>And receive it on your webhook.</p><ul><li>A dash of Curl and a bit of swaks</li></ul><p>I’d love your feedback, contributions, or ideas. If you find this useful and want to support the project, stars or donations are always welcome!</p><h2>\n  \n  \n  🙏 Support &amp; Contributions\n</h2><p>If you're an indie devops engineer, or just love hacking with Go and automation, I’d love your thoughts.<p>\nDM me or check the repo for sponsor links.</p><a href=\"https://buymeacoffee.com/voidwatch\" rel=\"noopener noreferrer\">https://buymeacoffee.com/voidwatch</a></p>","contentLength":1374,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building a JWT-Aware Reverse Proxy in Go for Tiered API Access","url":"https://dev.to/savinda_premachandra/-1kh8","date":1750175156,"author":"Savinda","guid":159720,"unread":true,"content":"<h2>Building a JWT-Aware Reverse Proxy in Go for Tiered API Access</h2>","contentLength":62,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stop pushing broken code. Start using Git hooks🧙‍♂️","url":"https://dev.to/ezpieco/stop-pushing-broken-code-start-using-git-hooks-44m6","date":1750168800,"author":"Ezpie","guid":159673,"unread":true,"content":"<p>Git Hooks are awesome - in theory.</p><ul><li>test before doing a commit. ✅</li><li>lint code before a push. ✅</li><li>prevent interns from crashing production due to untested code 😱</li></ul><p>But let's be honest, how many of us really use them huh?</p><p>Most of us probably don't use them mainly because:</p><ul><li>They live inside of  directory</li><li>They can't be version controlled</li><li>Feel like a trap - what if I mess up and do push to production but the hook didn't work and now the entire site crash(maybe that's why the internet is down today?)</li></ul><p>So, most of us, like me just:</p><ul><li>Or if you feel like killing yourself, you code in JS and can just use <a href=\"https://typicode.github.io/husky\" rel=\"noopener noreferrer\">Husky</a> - Which is amazing but nodejs\nonly</li></ul><p>Feeling trapped to use node everywhere(even the backend 😱), I decided to write a CLI based tool, <a href=\"https://ezpieco.github.io/GetHooky\" rel=\"noopener noreferrer\">GetHooky</a>, to manage all your git hooks for you. And you can also version control it and share it with your team!</p><p>Think of it as Husky, but for everyone 💪.</p><p>For the purpose of flexing GetHooky is written in rust... competitor go.</p><p>You just initialize a repository with hooky</p><p>This create's a directory by the name of , where all your hooks will live, you can version control this.</p><div><pre><code>hooky add pre-commit </code></pre></div><p>This creates a  file which contains the command you want, in this case  will be stored.</p><p>And then finally install it</p><p>This updates the hooks present in the  directory, to prevent GetHooky from accidently touching hooks which you don't want to change, your personal hooks, hooky adds a marker on top of each file which it controls  this tells it to touch only this file.</p><p>No nodejs, no dependencies, not even Go!</p><ul><li>Too little abstraction pythonist</li></ul><p>You can install GetHooky with curl or wget like so:</p><div><table><tbody><tr><td><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ezpieco/gethooky/master/tools/install.sh)\"</code></td></tr><tr><td><code>sh -c \"$(wget -O- https://raw.githubusercontent.com/ezpieco/gethooky/master/tools/install.sh)\"</code></td></tr></tbody></table></div><p>For windows I would highly recommend you to change your OS... just download it from the <a href=\"https://github.com/EzpieCo/GetHooky/releases\" rel=\"noopener noreferrer\">release page</a></p><p>GetHooky is exactly what you need to handle your interns and yourself, cause hey? We all have crashed production at least once in our life! Trust me Bro, I have first hand experience(nothing to do with the recent activities)</p><p>Check out in -&gt; <a href=\"https://github.com/EzpieCo/GetHooky\" rel=\"noopener noreferrer\">Github</a>\nDocs -&gt; Click right <a href=\"https://ezpieco.github.io/GetHooky\" rel=\"noopener noreferrer\">here</a> soy devs</p><p> As of now GetHooky is in early release, I would love feedbacks, feature requires, ideas and anything crazy you got!</p><p>Also don't forget to give it a ⭐️ on GitHub!</p><p>👉 Do you use Git hooks in your projects? Why or why not?</p><p>Let me know in the comments!</p>","contentLength":2434,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Prevent Race Conditions in Go Microservices with Distributed Locks","url":"https://dev.to/kittipat1413/prevent-race-conditions-in-go-microservices-with-distributed-locks-5609","date":1750156216,"author":"Kittipat.po","guid":159537,"unread":true,"content":"<p>In distributed systems, coordinating access to shared resources—such as rows in a database, files, or operations like seat reservation or payment processing—can be challenging when multiple services are involved. This is where distributed locks come in.</p><p>In this post, we’ll cover:</p><ul><li>What distributed locks are</li><li>Why and when you need them</li><li>A practical example in Go using </li><li>How to use the  from the <a href=\"https://github.com/kittipat1413/go-common/tree/main/framework/lockmanager\" rel=\"noopener noreferrer\">go-common</a> library to simplify implementation</li></ul><h2>\n  \n  \n  What is a Distributed Lock?\n</h2><p>A distributed lock ensures that <strong>multiple nodes in a system do not simultaneously perform conflicting operations on shared resources</strong>. It’s the distributed equivalent of a mutex, but across processes and machines.</p><ul><li>Preventing double booking in a ticketing system</li><li>Ensuring only one worker processes a message from a queue</li><li>Serializing access to a critical section of code across pods or services</li></ul><h2>\n  \n  \n  Redsync: Redis-based Locking 🔒\n</h2><p><a href=\"https://github.com/go-redsync/redsync\" rel=\"noopener noreferrer\">Redsync</a> is a Go implementation of the <a href=\"https://redis.io/docs/latest/develop/use/patterns/distributed-locks/\" rel=\"noopener noreferrer\">Redlock algorithm</a>, using Redis as the coordination backend. It’s simple, reliable, and battle-tested in production.</p><div><pre><code></code></pre></div><p>While Redsync is powerful, you often end up repeating boilerplate logic: setting up Redis clients, creating  with consistent options, generating unique tokens and managing error types.</p><p>To simplify this, the  package from the <a href=\"https://github.com/kittipat1413/go-common/tree/main/framework/lockmanager\" rel=\"noopener noreferrer\">go-common</a> library provides a clean abstraction over  with:</p><ul><li>✅ A standard  interface</li><li>⚙️ Pluggable token generator and retry logic</li><li>🧪 Easy mocking for unit testing</li></ul><p><strong>💡 Example: Using  LockManager</strong></p><div><pre><code></code></pre></div><p>While distributed locks can be powerful, they come with caveats:</p><ul><li><strong>Short TTLs may expire before the critical section is done,</strong> leading to unintended parallel execution.</li><li><strong>Long TTLs may block progress</strong> if a node crashes without releasing the lock.</li><li><strong>Don’t use locks as permanent ownership</strong> — they’re for coordination, not persistent state.</li><li><strong>Always wrap lock usage with context timeouts or deadlines</strong> to avoid deadlocks.</li></ul><blockquote><p>🧠 Pro Tip: Design your system to recover gracefully even if the lock fails or expires unexpectedly.</p></blockquote><p>Distributed locks are a foundational building block in microservices and distributed architectures. Whether you’re managing ticket availability, serializing task execution, or controlling access to shared state, having a reliable and testable lock mechanism makes a huge difference.</p>","contentLength":2278,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Teams Migrate from Java to Go — Benefits, Trade-Offs, and the Right Time","url":"https://dev.to/evrone/why-teams-migrate-from-java-to-go-benefits-trade-offs-and-the-right-time-4cm0","date":1750154090,"author":"Evrone","guid":159481,"unread":true,"content":"<p>This article examines why many development teams are migrating from Java to Go, highlighting Go’s advantages like better performance, simpler syntax, efficient concurrency, and ease of deployment. It also discusses trade-offs, including a smaller ecosystem and learning curve. Go is ideal for high-concurrency, cloud-native, or microservice architectures, but may not suit legacy-heavy enterprise systems.</p>","contentLength":407,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"SR621SW: The Hogwarts Battery Powering Time & Magic","url":"https://dev.to/ersajay/sr621sw-the-hogwarts-battery-powering-time-magic-48kj","date":1750143027,"author":"ersajay","guid":159408,"unread":true,"content":"<p>The Leaky Cauldron’s Hidden Alchemy\nBehind the creaky floorboards of Quality Quidditch Supplies and the flickering candlelight of the Leaky Cauldron lies a magic even Dumbledore might envy: the SR621SW—a 6.8mm x 2.1mm silver-oxide button cell, small as a Galleon but mightier than a well-cast Protego. While flashy lithium-ion packs strut through Diagon Alley, this unassuming dynamo quietly powers the wizarding world’s grind—from Weasley’s Widgets to Mars-bound broomsticks. Let’s unmask its spells.</p><p>The Potion of Precision: What Is SR621SW?\nThis isn’t candy—it’s enchanted energy. Break down its magic:</p><p>Voltage: 1.55V, steady as a Pensieve memory. No flickering, no fading—just pure, reliable magic.\nSize: 6.8mm x 2.1mm, smaller than a Niffler’s paw. Sneaks into the tightest spaces (like the back of a Rolex).<p>\nChemistry: Silver oxide, the Felix Felicis of battery tech—long-lasting, dependable, and trusted by potion masters (engineers) worldwide.</p>\nAliases: 364, SR621, <a href=\"https://www.ersaelectronics.com/\" rel=\"noopener noreferrer\">AG1</a>… even “G1” if you’re in a moody French lab. It’s the polyjuice potion of batteries—same magic, different labels.</p><p>Fun Fact: Engineers call it the “Wand Core of Button Cells.” They swipe it from kids’ toys like students steal chocolate frogs—because once you use it, you never go back.</p><p>The Triwizard Trials of Durability\nImagine the Great Hall, tables stacked with batteries vying for “Most Resilient Enchanter.” Let’s meet the contenders:\nA steadfast champion, its 1.55V hums like a well-tuned wand—no flickering, no fading, even under pressure. It lasts 3-5 years, outgrinding first-years at Transfiguration class. Temperature? It laughs at -30°C ice storms and 60°C cauldrons, sealed tighter than the Chamber of Secrets. Acid? Oil? Your coworker’s cursed energy drink? It shrugs them off like a Reparo spell.\nThe flashy underdog, boasting 1.5V but crumbling fast—like a Boggart in a rainstorm. It dies in 1-2 years (intern energy, at best), leaks like a nervous first-year on their first broom ride, and melts under a coffee cup.<a href=\"https://www.ersaelectronics.com/\" rel=\"noopener noreferrer\">CR2032</a> (Hufflepuff)\nOvereager, with 3V of “look at me!” energy, but midlife crisis hits at 2-3 years. It flexes extreme temps but whimpers when squeezed—leaking like a first-year’s tears after a Dementor drill. Worse, its overkill voltage fries tiny circuits like a Confringo gone wrong.\nCR2032: “I’m 3V! I’m better!”<p>\nSR621SW: “Your voltage fries hearing aids. Stay in your lane, mate.” 🔥</p></p><p>The Invisible Keeper of Magic\nIn the hidden corners of the wizarding world, <a href=\"https://www.ersaelectronics.com/blog/what-is-the-sr621sw-battery\" rel=\"noopener noreferrer\">the SR621SW</a> is the unsung hero:</p><p>Luxury Watches: Inside Rolex, Omega, and your dad’s Casio, it keeps time like a Time-Turner. Even the Patek Philippe crowd swears by it—because a $10k watch deserves a $0.50 battery that never fails.\nMedical Wonders: Powers pacemakers (steady as a heartbeat) and hearing aids (survives earwax apocalypses). Surgeons trust it more than their own wands—quieter than a scalpel, cheaper than a Firewhiskey night.<p>\nMars Rovers: NASA uses it because “Mars-grade” is just Tuesday for this battery. Cosmic radiation? Dust storms? It handles them like a seasoned Auror handles dark wizards.</p>\nToys &amp; Calculators: Survives juice spills, math meltdowns, and “hold my butterbeer” DIY projects. It’s the only battery that outlasts Weasley’s Wizard Wheezes pranks.</p><p>Burn Alert:\nSmartwatch: “I track your sleep!”<p>\nSR621SW: “I’m in a $10k Patek. You’re basic.” ⌚💎</p></p><p>The Secret Twins: Who’s a True Match?\nNot all batteries are created equal. The SR621SW has true twins and faux friends:</p><p>True Allies: 364, SR621, AG1, G1. Same size, same voltage, same magic. Even Renata 364 (Swiss-made, pricier) works—though the $0.50 generic is just as reliable.\nFaux Friends: LR621 (alkaline) dies faster than a Doxie infestation. CR621 (lithium) fries circuits like a Bombarda spell. Avoid “LR” or “CR” labels—they’re the Bogies of the battery world.</p><p>Pro Tip: If the package says “364” or “AG1,” you’re golden. Trust the labels like you trust a Veritaserum—no lies, just truth.</p><p>The Prophecy of the Tiny Titan\nIn 2050, when wizards build colonies on Mars, the SR621SW will still be there. It’ll power quantum clocks (even qubits need steady time), Mars habitats (cosmic radiation can’t break its magic), and robot familiars (when AI revolts, they’ll use it to build… well, let’s not dwell on that).<p>\nEngineer Prophecy: “In 2050, we’ll find these in alien tech—and they’ll still work. Because some magic doesn’t fade.”</p></p><p>Conclusion: The Battery That Binds\nThe SR621SW isn’t flashy. It doesn’t need a wand wave or a grand spell. It’s the Homenum Revelio of tech—small, unassuming, and critical. While lithium-ion packs chase “innovation,” this 0.3-gram hero keeps the world ticking, one flawless volt at a time.<p>\nNext time your watch stops, whisper, “Thanks, little buddy.” It’s the least you can do for a battery that’s saved your sanity (and your Patek’s pride).</p></p><p>Written by a wizard who once mistook an SR621SW for a Fizzing Whizbee. (Spoiler: It didn’t taste like lemon.)\n🔋 Some magic isn’t in wands—it’s in the tiny things that keep the world enchanted.</p>","contentLength":5203,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Debug Go Servers Inside Docker Like a Boss (with Delve)","url":"https://dev.to/shehan_avishka_6229bf40cc/debug-go-servers-inside-docker-like-a-boss-with-delve-1cbc","date":1750141584,"author":"Shehan Avishka","guid":159407,"unread":true,"content":"<p>I just wanted to execute my previous go program and could not install it on local machine 24.04 because some of the dependencies are kept in archive and got into trouble and then thought instead of installing it on local machine Whether I can install it on container or not. Then began to install docker file to install my go program within the docker in two stages.</p><p>Why two steps? Yes i want my runner is lightweight, First step is to build stage and second step were run stage. and each time i build docker container had to execute long command again and again. Yeah so for that what i created a script to control container and images. Within two lines i alerted this but actually it tooked nearly a week to test all things on a docker container. Now the best is gone. I just need to test some apis on docker container and discovered some end points are not functioning,</p><p>Next issue was how to debug the problem. there are two possible ways. first one is as usual put the print lines and second one is debugging. Instead of putting ton of print lines. i want to debug the code inside the docker container. But How?</p><p>Then googled and typed “how to debug go web server inside the docker container” Then i learned about the open source project was go-delv and that was great and good documentation.</p><p>Then When I went through the documentation I found the go-remote debugging for the first time. But I made a plan. Which is. I create two entry points to start the docker container. 1 is debug mod and 2 is normal docker startup.</p><p>Then during build time i install delv debug tool inside the container. during run time i create an entry point to start with delv debug server. Now my final aim is remote-debuging there i need to connect to debug server from outside the container and thus i expose the port to connect debug server.</p><p>The famous IDE like goland also support remote debug option. and But the need is to same code and go version. that the trick behind the scene. path mapping is the key unless we will be not able to debug. Because thats the trick of go-remote. from the outside of container and then we can attach it with docker container.</p><p>Let me explain how did I set the go-remote debugging step by step,</p><p>First as I mentioned I installed delv debug tool while building the docker container.</p><p><code>RUN cd ${APP_NAME} &amp;&amp; go install github.com/go-delve/delve/cmd/dlv@latest</code></p><p>But very important to note. while we are doing go build we must pass two flags to the go garbage collector to set the debugging. which is disable the optimization and disable the inline the code. which is necessary for debugging.</p><p><code>RUN cd ${APP_NAME} &amp;&amp; go mod tidy &amp;&amp; go build -gcflags \"all=-N -l\" -o ${APP_NAME}</code></p><p>And in the run stage we have to access execute delv, and it is in go/bin directory but to access it through entry point we have to copy it in /usr/local/bin/dlv</p><p><code>COPY --from=0 /go/bin/dlv /usr/local/bin/dlv</code></p><p>Then expose the port to reach the delv debug server</p><p>Then set the entry point to execute the go build through delv<code>ENTRYPOINT [\"dlv\", \"exec\", \"./delivery-data-cacher\", \"--listen=:2345\", \"--headless=true\", \"--api-version=2\", \"--accept-multiclient\", \"--continue\", \"--\"]</code></p><p>Within my bash script I define two entrypoint at the beginning I can select.</p><p>Let me know your thoughts! If needed, I’d be happy to dive deeper — with a detailed walkthrough of how the debug server communicates using the power of gRPC, how to set up the Dockerfile step-by-step, and more insights from my experience. Always open to feedback and discussion!</p>","contentLength":3501,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What I Wish I Knew Before Learning Go.","url":"https://dev.to/oathooh/what-i-wish-i-knew-before-learning-go-539d","date":1750098556,"author":"Seth Athooh","guid":157529,"unread":true,"content":"<p>When I started learning Go, I did what most developers do. I opened the official documentation, skimmed a few tutorials, and jumped straight into building something. Go looked simple on the surface short syntax, fast compile times, built-in concurrency. I figured I could pick it up in a weekend.</p><p>Go is simple, but not easy. It has a learning curve that’s easy to underestimate. And if I could go back and talk to my past self, here’s what I would say.</p><h2>\n  \n  \n  Simplicity is intentional\n</h2><p>At first, Go felt too bare. Where are the generics? Why no while loop? Why does everything feel so manual?</p><p>Eventually, I realized this simplicity was deliberate. Go avoids cleverness. It pushes you to write code that’s straightforward and easy to maintain. Instead of offering five ways to solve a problem, it gives you one solid way.</p><p>If you embrace the constraints, Go becomes a lot more enjoyable.</p><h2>\n  \n  \n  Interfaces work differently than you expect\n</h2><p>Go’s interfaces confused me at first. Unlike other languages, you don’t explicitly declare that a type implements an interface. You just define the methods, and if the shape fits, Go accepts it.</p><p>This implicit approach is powerful, but it can be hard to debug when things go wrong. I once spent hours trying to figure out why a type didn’t satisfy an interface, only to realize I’d misspelled a method name.</p><p>Once you understand how interfaces are used in Go especially small, focused ones it becomes one of the best parts of the language.</p><h2>\n  \n  \n  Error handling looks repetitive, but it matters\n</h2><p>I was used to try-catch blocks and error bubbling. Go throws that out the window.</p><p>In Go, error handling is explicit. You check the error after every operation and deal with it right there. At first it felt like noise, but over time I started to see the benefits. There’s no magic. No hidden failures. Just code that does what it says.</p><p>The more I worked with it, the more I appreciated the discipline.</p><h2>\n  \n  \n  Go’s tooling is incredibly helpful\n</h2><p>Go comes with excellent built-in tools. You don’t need to install formatters or dependency managers or testing libraries. Everything is there from the start.</p><ul><li> for managing dependencies</li><li> for catching mistakes</li></ul><p>The ecosystem encourages consistency, which makes collaboration and open source contributions smoother.</p><h2>\n  \n  \n  Goroutines are not threads\n</h2><p>One of Go’s headline features is concurrency using goroutines. They’re lightweight and easy to create. But that simplicity can also be a trap.</p><p>I made the mistake of spawning goroutines without fully understanding how they work. This led to race conditions, memory leaks, and hard-to-track bugs.</p><p>Eventually I learned to pair goroutines with proper synchronization using channels, mutexes, or wait groups. I also learned to use the  package for handling timeouts and cancellations. Once you grasp these tools, writing concurrent programs becomes much safer and more predictable.</p><p>Coming from object-oriented languages, I expected Go to feel limited without classes or inheritance. But Go uses structs and interfaces to achieve the same results, often in a cleaner and more flexible way.</p><p>Instead of deep inheritance trees, you compose small pieces of behavior. That shift in mindset took time, but once I got it, I found it easier to reason about my code.</p><h2>\n  \n  \n  The standard library is seriously good\n</h2><p>Go’s standard library covers a lot of ground. From HTTP servers to file I/O, JSON handling, cryptography, and more it’s all there.</p><p>I used to reach for third-party libraries out of habit. Now, I always check the standard library first. It's fast, reliable, and maintained by the Go team.</p><p>Testing in Go is simple and built in. You write test functions in the same package, use , and you’re done. No need for fancy tools or configuration.</p><p>One thing that helped me was using table-driven tests. It made my test cases cleaner and easier to expand over time.</p><h2>\n  \n  \n  Reading other people’s Go code helps a lot\n</h2><p>Since Go enforces formatting and favors convention, reading other people’s code is easier than in most languages. I learned a lot by browsing open source projects like Hugo, Docker, and Kubernetes.</p><p>It’s one of the best ways to get a feel for how experienced developers write idiomatic Go.</p><h2>\n  \n  \n  Stop comparing it to other languages\n</h2><p>In the beginning, I kept comparing Go to Python, JavaScript, and Java. I judged it by what it lacked instead of what it offered.</p><p>Go isn’t trying to be like other languages. It’s trying to be a better C. It focuses on performance, readability, and ease of deployment. Once I stopped fighting that, I started enjoying the language for what it is.</p><p>Learning Go challenged the way I think about programming. It forced me to be more disciplined, to value clarity over cleverness, and to care about what happens under the hood.</p><p>If you're starting out with Go, give yourself time. It’s not a flashy language, but it’s one that grows on you. And once it does, you might just find yourself reaching for it again and again.</p>","contentLength":4996,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"**High-Performance Go Logging: Achieving 100,000 Logs Per Second Without Bottlenecks**","url":"https://dev.to/aaravjoshi/high-performance-go-logging-achieving-100000-logs-per-second-without-bottlenecks-5761","date":1750092230,"author":"Aarav Joshi","guid":157463,"unread":true,"content":"<blockquote><p>As a best-selling author, I invite you to explore my books on <a href=\"https://www.amazon.com/stores/Aarav-Joshi/author/B0DQYNVXZ7?ref=ap_rdr&amp;isDramIntegrated=true&amp;shoppingPortalEnabled=true&amp;ccs_id=738636bd-0ca1-4d7b-8efa-481bfc222571\" rel=\"noopener noreferrer\">Amazon</a>. Don't forget to follow me on <a href=\"https://medium.com/@aarav-joshi\" rel=\"noopener noreferrer\">Medium</a> and show your support. Thank you! Your support means the world! </p></blockquote><p>Building robust logging systems in Go requires balancing performance and functionality. High-traffic applications need efficient logging that doesn't bottleneck the system while providing structured, queryable data. I've developed a solution that achieves over 100,000 logs per second on standard hardware.</p><p>The core challenge lies in minimizing allocations and lock contention. Standard logging approaches often become performance liabilities under load. My implementation addresses this through several key techniques:</p><p><strong>Asynchronous Processing with Worker Pool</strong></p><div><pre><code></code></pre></div><p>The channel buffer absorbs spikes in log volume. Worker goroutines serialize entries concurrently, preventing application threads from blocking on I/O. CPU-bound serialization work scales with available cores.</p><p><strong>Zero-Allocation Field Handling</strong></p><div><pre><code></code></pre></div><p>Recycling field slices avoids slice header allocations. Field constructors return stack-allocated structs:</p><div><pre><code></code></pre></div><p><strong>Buffer Pooling for JSON Serialization</strong></p><div><pre><code></code></pre></div><p>Reusing buffers eliminates allocation pressure during serialization. Pre-sized buffers prevent expensive runtime expansions.</p><div><pre><code></code></pre></div><p>Caller information adds significant overhead. Capturing it only for error levels maintains performance during normal operation.</p><div><pre><code></code></pre></div><p>Avoiding  for basic types reduces reflection overhead. Benchmarks show 3-5x speed improvement for primitive types.</p><p>\nThe non-blocking channel send with fallback:</p><div><pre><code></code></pre></div><p>This prevents log loss during extreme bursts while minimizing blocking under normal conditions.</p><div><pre><code></code></pre></div><p>\nOn a 8-core machine:</p><ul><li>100,000 logs/second sustained</li><li>12x faster than zap with similar features</li><li>97% reduction in GC pressure vs standard loggers</li></ul><ul><li>No in-process log filtering (level checked before queuing)</li><li>Possible reordering under high concurrency</li><li>Caller info only for errors</li><li>Manual type handling requires extension for custom types</li></ul><p>\nFor 1M+ logs/second:</p><ul><li>Use separate writer threads</li><li>Consider zero-copy techniques</li></ul><h2>\n  \n  \n  In production systems, I've found this architecture handles 15TB/day log volumes while keeping application overhead below 3%. The structured format enables powerful analytics while the performance ensures logging doesn't become the bottleneck.\n</h2><p>📘 , , , and  to the channel!</p><p> is an AI-driven publishing company co-founded by author . By leveraging advanced AI technology, we keep our publishing costs incredibly low—some books are priced as low as —making quality knowledge accessible to everyone.</p><p>Stay tuned for updates and exciting news. When shopping for books, search for  to find more of our titles. Use the provided link to enjoy !</p><p>Be sure to check out our creations:</p>","contentLength":2698,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"File Duplicate Detector. Go implementation.","url":"https://dev.to/andrey_matveyev/file-duplicate-detector-go-implementation-2270","date":1750068996,"author":"Andrey Matveyev","guid":159463,"unread":true,"content":"<h3>\n  \n  \n  SearchEngine, Processing Pipeline, Usage and Result.\n</h3><p>\"Truth is not born pure from the earth; it requires refinement from the superfluous to shine in its essence.\"\n— Ancient Wisdom</p><p>In previous parts of our series on the , we thoroughly examined individual components:  that perform specific tasks (file discovery, size determination, hash calculation, byte-by-byte comparison);  that ensure reliable data transfer between workers; and  that optimize the duplicate detection process by preventing redundant work.</p><p>Now it's time to put this puzzle together and understand how these independent, yet interconnected parts form a powerful system for detecting duplicate files. The  component and the data processing pipeline are central to this process.</p><h3>\n  \n  \n  1. : The Heart of Orchestration.\n</h3><p>The  is the brain of the entire system. Its main task is to launch and coordinate all stages of the file processing pipeline. It does not perform direct file operations but acts as a conductor, ensuring the correct execution of all operations:</p><ul><li><p>: Upon launch, the  initializes internal structures, such as a  to track the completion of all workers, and  for collecting statistics.</p></li><li><p>: The  method starts the main processing pipeline in a separate goroutine, allowing it to operate asynchronously.</p></li><li><p>: The  manages a cancellation context (), allowing for the graceful shutdown of all workers upon receiving a cancellation signal (e.g., ).</p></li><li><p>: After the pipeline completes its work, the  collects and provides the final results via the  method, as well as current progress via .</p></li></ul><p>Here's the  code, with inline comments for clarity::</p><div><pre><code></code></pre></div><h3>\n  \n  \n  2. Building the Processing Pipeline: pipeline()\n</h3><p>The most interesting part of the  is the  method, which is responsible for constructing the entire data processing pipeline. This demonstrates the principles of pipeline processing and concurrent programming in Go.</p><p>The pipeline consists of several sequential stages, each represented by a pool of workers and its own queue. Data (represented by *task) is passed from one stage to the next via Go channels:</p><ul><li><p> ():</p><ul><li>This is the first stage. It launches  workers that traverse the file system, recursively scanning directories and sending tasks () for each found file and directory.</li><li>It's important to note that  also contains a  that coordinates recursive directory traversal and completion signals for the .</li><li>The output of  is a channel that provides tasks containing the path and size of each file.</li></ul></li><li><p><code>runPool(&amp;sizer{}, N, ...)</code> ():</p><ul><li>The output channel of  becomes the input for the  pool.</li><li> filter files by size (e.g., excluding zero-byte files) and use a  for initial screening of files with unique sizes. If multiple files of the same size are found, they are passed to the next stage.</li></ul></li><li><p><code>runPool(&amp;hasher{}, N, ...)</code> ():</p><ul><li>The output channel of the  becomes the input for the  pool.</li><li> calculate the CRC32 hash for a portion of the file. At this stage, a second, more precise, duplicate filtering occurs: files with different hashes are guaranteed not to be duplicates.</li><li>A  is used here to determine if the hash is already known (a potential duplicate).</li></ul></li><li><p><code>runPool(&amp;matcher{}, N, ...)</code> ():</p><ul><li>The output channel of the  becomes the input for the  pool.</li><li> perform the most resource-intensive action: byte-by-byte comparison of files whose size and partial hash have matched. Only at this stage is it definitively confirmed that two files are identical.</li><li>A  is used to manage groups of potential duplicates to avoid redundant comparisons and track already verified files.</li></ul></li><li><p><code>...runPipeline(ctx context.Context)</code> ():</p><ul><li>The output channel of the  (containing only confirmed duplicates) is fed into the . From this queue, the code in  executes as the final stage, responsible for collecting and grouping the paths of all confirmed duplicate files, ultimately preparing the data for the final  structure.\n</li></ul></li></ul><div><pre><code></code></pre></div><p>All these stages are connected by channels, and each  launches a fixed number () of worker goroutines that process incoming tasks in parallel.  collects statistics for each stage, allowing progress to be monitored.</p><h3>\n  \n  \n  3. Metrics and Monitoring (, )\n</h3><p>One of the advantages of this implementation is its built-in mechanism for collecting metrics and monitoring progress. This allows not only tracking the process status in real-time but also analyzing the performance of each stage.</p><p>The  and  structures (file ) collect data on the number of processed files () and their total size () at the input () and output () of each queue (pipeline stage).</p><div><pre><code></code></pre></div><p>The  function (also in ) is a channel wrapper that increments the corresponding metrics as a task passes through the channel.</p><p>The  file contains the logic for displaying progress. In the  function, metric data is periodically retrieved via engine. (which returns a JSON representation of metrics) and printed to the console.</p><div><pre><code></code></pre></div><p>This allows real-time viewing of:</p><ul><li><p>The number of active goroutines.</p></li><li><p>Processing progress at each stage (number of files and their total size).</p></li><li><p>Filtering performance at the sizer, hasher, and matcher stages – how many files were \"discarded\" at each stage.</p></li></ul><p>Using the  from  is quite straightforward:</p><div><pre><code></code></pre></div><p>As seen in the example, you:</p><ul><li><p>Create a  with cancellation capability.</p></li><li><p>Set up OS signal handling for graceful termination.</p></li><li><p>Obtain a  instance.</p></li><li><p>Call  with the root path for scanning and a  function that will be invoked upon completion.</p></li><li><p>Launch  to display progress.</p></li><li><p>Wait for all operations to complete using a .</p></li><li><p>Retrieve and save (GetResult()) the found duplicates.</p></li></ul><h3>\n  \n  \n  5.  ()\n</h3><p>The final result of the 's operation is available via the  method and is returned as a  structure:</p><div><pre><code></code></pre></div><h4>\n  \n  \n  Example of application execution from the console (scanning an SSD disk C:):\n</h4><div><pre><code>PS D:\\go\\go-sample-detector&gt; go run .\n---- CURRENT CONFIGURATION ----\nRoot Path:             c:\\\nFile name for results:     fdd-result.txt\nFile name for logs:        fdd-output.log\nLogging level (info/debug): debug\nAdds source info in logs:  false\n-------------------------------\nProgress (every 10 seconds):\n45 folder 1_0_1 fetch 0_0_0 size 0_0_0 hash 0_0_0 match 0_0_0 result 0s\n50 folder 10849_6798_4051 fetch 41712_0_41712 size 29731_20019_9712 hash 1654_757_897 match 432_0_432 result 10.0514188s\n...\n50 folder 827791_5379_822412 fetch 2175225_1_2175224 size 2136075_1166018_970057 hash 737102_171_736931 match 725972_0_725972 result 11m30.1975563s\n50 folder 838528_3506_835022 fetch 2249794_0_2249794 size 2208711_1225693_983018 hash 750085_965_749120 match 737973_0_737973 result 11m40.1993708s\n31 folder 843222_0_843222 fetch 2270482_0_2270482 size 2229228_1234927_994301 hash 761939_5_761934 match 750026_6_750020 result 11m50.2018749s\n31 folder 843222_0_843222 fetch 2270482_0_2270482 size 2229228_1219410_1009818 hash 773913_0_773913 match 761518_0_761518 result 12m0.2085391s\n31 folder 843222_0_843222 fetch 2270482_0_2270482 size 2229228_1205527_1023701 hash 787439_42_787397 match 774824_0_774824 result 12m10.2143553s\n...\n31 folder 843222_0_843222 fetch 2270482_0_2270482 size 2229228_24236_2204992 hash 1722277_1662_1720615 match 1700204_1_1700203 result 22m0.3185755s\n5 folder 843222_0_843222 fetch 2270482_0_2270482 size 2229228_0_2229228 hash 1735310_0_1735310 match 1714249_0_1714249 result 22m10.3194308s\n4 folder 843222_0_843222 fetch 2270482_0_2270482 size 2229228_0_2229228 hash 1735310_0_1735310 match 1714249_0_1714249 result 22m20.320499s\n4 folder 843222_0_843222 fetch 2270482_0_2270482 size 2229228_0_2229228 hash 1735310_0_1735310 match 1714249_0_1714249 result 22m30.3211656s\n------- TOTAL STATISTIC -------\nTime of start:       11:29:09\nTime of ended:       11:51:41\nDuration:        22m31.7249332s\nTotal processed &lt;count (size Mb)&gt;:\n- folders:           843222\n- files:             2270482 (178753.517 Mb)\nPerformance of filtration &lt;inp-filtered-out (out %)&gt;:\n- sizer:             2270482     41254       2229228 (98.18 %)\n- hasher:            2229228     493918      1735310 (77.84 %)\n- matcher:           1735310     21061       1714249 (98.79 %)\nFound duplicates &lt;count (size Mb)&gt;:\n- groups of files:   311941\n- files:             1714249 (63811.304 Mb)\nFile with result: fdd-result.txt\nFile with logs: fdd-output.log\n-------------------------------\n</code></pre></div><div><pre><code>PS D:\\go\\go-sample-detector&gt; go run .\n---- CURRENT CONFIGURATION ----\nRoot Path:             d:\\\nFile name for results:     fdd-result.txt\nFile name for logs:        fdd-output.log\nLogging level (info/debug): debug\nAdds source info in logs:  false\n-------------------------------\nProgress (every 10 seconds):\n17 folder 0_0_0 fetch 0_0_0 size 0_0_0 hash 0_0_0 match 0_0_0 result 520.5µs\n50 folder 382_224_158 fetch 1910_0_1910 size 606_279_327 hash 277_155_122 match 108_0_108 result 10.0512721s\n...\n50 folder 6712_454_6258 fetch 54626_0_54626 size 32410_25710_6700 hash 3972_2552_1420 match 1334_0_1334 result 5m20.0859867s\n50 folder 6952_73_6879 fetch 55794_1_55793 size 33647_26147_7500 hash 4658_3204_1454 match 1365_0_1365 result 5m30.0865653s\n31 folder 7008_0_7008 fetch 56138_0_56138 size 34005_26153_7852 hash 4791_3313_1478 match 1389_0_1389 result 5m40.0886867s\n31 folder 7008_0_7008 fetch 56138_0_56138 size 34005_25868_8137 hash 4922_3373_1549 match 1451_0_1451 result 5m50.0892709s\n...\n31 folder 7008_0_7008 fetch 56138_0_56138 size 34005_567_33438 hash 22755_20341_2414 match 2291_0_2291 result 12m30.1476568s\n31 folder 7008_0_7008 fetch 56138_0_56138 size 34005_315_33690 hash 22961_20490_2471 match 2353_0_2353 result 12m40.1494179s\n20 folder 7008_0_7008 fetch 56138_0_56138 size 34005_0_34005 hash 23323_20744_2579 match 2459_0_2459 result 12m50.1500104s\n20 folder 7008_0_7008 fetch 56138_0_56138 size 34005_0_34005 hash 23323_20608_2715 match 2591_0_2591 result 13m0.1504921s\n...\n20 folder 7008_0_7008 fetch 56138_0_56138 size 34005_0_34005 hash 23323_423_22900 match 22122_0_22122 result 29m10.2776533s\n12 folder 7008_0_7008 fetch 56138_0_56138 size 34005_0_34005 hash 23323_0_23323 match 22555_0_22555 result 29m20.2791754s\n11 folder 7008_0_7008 fetch 56138_0_56138 size 34005_0_34005 hash 23323_0_23323 match 22557_0_22557 result 29m30.2803337s\n11 folder 7008_0_7008 fetch 56138_0_56138 size 34005_0_34005 hash 23323_0_23323 match 22557_0_22557 result 29m40.2814158s\n------- TOTAL STATISTIC -------\nTime of start:       12:03:35\nTime of ended:       12:33:22\nDuration:        29m46.4419118s\nTotal processed &lt;count (size Mb)&gt;:\n- folders:             7008\n- files:               56138 (645181.041 Mb)\nPerformance of filtration &lt;inp-filtered-out (out %)&gt;:\n- sizer:               56138     22133       34005 (60.57 %)\n- hasher:              34005     10682       23323 (68.59 %)\n- matcher:             23323       764       22559 (96.72 %)\nFound duplicates &lt;count (size Mb)&gt;:\n- groups of files:     7243\n- files:               22559 (15674.642 Mb)\nFile with result: fdd-result.txt\nFile with logs: fdd-output.log\n-------------------------------\n</code></pre></div><h4>\n  \n  \n  Example Logging Output (from fdd-output.log)\n</h4><div><pre><code>time=2025-06-15T11:29:09.260+03:00 level=DEBUG msg=\"InpProcess of Queue - started.\" poolName=fetchers\ntime=2025-06-15T11:29:09.260+03:00 level=DEBUG msg=\"OutProcess of Queue - started.\" poolName=fetchers\ntime=2025-06-15T11:29:09.260+03:00 level=DEBUG msg=\"Worker-pool - started.\" workerType=fdd.fetcher\ntime=2025-06-15T11:29:09.306+03:00 level=DEBUG msg=\"Worker-pool - started.\" workerType=*fdd.sizer\ntime=2025-06-15T11:29:09.306+03:00 level=DEBUG msg=\"Worker-pool - started.\" workerType=*fdd.hasher\ntime=2025-06-15T11:29:09.306+03:00 level=DEBUG msg=\"Worker-pool - started.\" workerType=*fdd.matcher\ntime=2025-06-15T11:29:09.308+03:00 level=DEBUG msg=\"InpProcess of Queue - started.\" poolName=sizers\ntime=2025-06-15T11:29:09.308+03:00 level=DEBUG msg=\"OutProcess of Queue - started.\" poolName=sizers\ntime=2025-06-15T11:29:09.308+03:00 level=DEBUG msg=\"InpProcess of Queue - started.\" poolName=matchers\ntime=2025-06-15T11:29:09.308+03:00 level=DEBUG msg=\"InpProcess of Queue - started.\" poolName=hashers\ntime=2025-06-15T11:29:09.308+03:00 level=DEBUG msg=\"OutProcess of Queue - started.\" poolName=hashers\ntime=2025-06-15T11:29:09.308+03:00 level=DEBUG msg=\"OutProcess of Queue - started.\" poolName=matchers\ntime=2025-06-15T11:29:09.308+03:00 level=DEBUG msg=\"InpProcess of Queue - started.\" poolName=packer\ntime=2025-06-15T11:29:09.308+03:00 level=DEBUG msg=\"OutProcess of Queue - started.\" poolName=packer\ntime=2025-06-15T11:29:09.311+03:00 level=INFO msg=\"Objects read error.\" item=*fdd.fetcher method=readDir() error=\"open c:\\\\$Recycle.Bin\\\\S-1-5-18: Access is denied.\" path=c:\\$Recycle.Bin\\S-1-5-18\n...\ntime=2025-06-15T11:39:52.958+03:00 level=INFO msg=\"File open error.\" item=*fdd.hasher method=os.Open() error=\"open c:\\\\Windows\\\\System32\\\\restore\\\\MachineGuid.txt: Access is denied.\" path=c:\\Windows\\System32\\restore\\MachineGuid.txt\ntime=2025-06-15T11:39:57.011+03:00 level=INFO msg=\"File open error.\" item=*fdd.hasher method=os.Open() error=\"open c:\\\\Windows\\\\System32\\\\wbem\\\\AutoRecover\\\\3FFDD473F026FB198DA9FA65EE71383C.mof: Access is denied.\" path=c:\\Windows\\System32\\wbem\\AutoRecover\\3FFDD473F026FB198DA9FA65EE71383C.mof\ntime=2025-06-15T11:40:55.247+03:00 level=DEBUG msg=\"InpProcess of Queue - stoped.\" poolName=fetchers\ntime=2025-06-15T11:40:55.247+03:00 level=DEBUG msg=\"OutProcess of Queue - stopped because queue is done and empty.\" poolName=fetchers\ntime=2025-06-15T11:40:55.250+03:00 level=DEBUG msg=\"Worker-pool - stoped.\" workerType=fdd.fetcher\ntime=2025-06-15T11:40:55.250+03:00 level=DEBUG msg=\"InpProcess of Queue - stoped.\" poolName=sizers\ntime=2025-06-15T11:40:55.252+03:00 level=DEBUG msg=\"OutProcess of Queue - stopped because queue is done and empty.\" poolName=sizers\ntime=2025-06-15T11:40:55.252+03:00 level=DEBUG msg=\"Worker-pool - stoped.\" workerType=*fdd.sizer\ntime=2025-06-15T11:40:55.252+03:00 level=DEBUG msg=\"InpProcess of Queue - stoped.\" poolName=hashers\n...\ntime=2025-06-15T11:50:53.101+03:00 level=INFO msg=\"File open error.\" item=*fdd.hasher method=os.Open() error=\"open c:\\\\Windows\\\\System32\\\\wbem\\\\AutoRecover\\\\DA736886F13A0E2EE2265319FB376753.mof: Access is denied.\" path=c:\\Windows\\System32\\wbem\\AutoRecover\\DA736886F13A0E2EE2265319FB376753.mof\ntime=2025-06-15T11:51:19.521+03:00 level=DEBUG msg=\"OutProcess of Queue - stopped because queue is done and empty.\" poolName=hashers\ntime=2025-06-15T11:51:19.522+03:00 level=DEBUG msg=\"Worker-pool - stoped.\" workerType=*fdd.hasher\ntime=2025-06-15T11:51:19.522+03:00 level=DEBUG msg=\"InpProcess of Queue - stoped.\" poolName=matchers\ntime=2025-06-15T11:51:19.522+03:00 level=DEBUG msg=\"OutProcess of Queue - stopped because queue is done and empty.\" poolName=matchers\ntime=2025-06-15T11:51:19.522+03:00 level=DEBUG msg=\"Worker-pool - stoped.\" workerType=*fdd.matcher\ntime=2025-06-15T11:51:19.522+03:00 level=DEBUG msg=\"InpProcess of Queue - stoped.\" poolName=packer\ntime=2025-06-15T11:51:19.522+03:00 level=DEBUG msg=\"OutProcess of Queue - started.\" poolName=packer\n</code></pre></div><p>DEBUG level logs show the start and stop of each worker pool (<code>Worker-pool - started./stoped.</code>) and queue processing (<code>InpProcess/OutProcess of Queue - started./stoped.</code>). INFO level logs often indicate file or folder access errors, for example, to system directories (). This is expected behavior, as the application attempts to access all files in the specified root directory.</p><h4>\n  \n  \n  Example Result File (fdd-result.txt)\n</h4><p>After completion, the application saves the results to a text file specified in the configuration (). The output format groups duplicates by size, hash, and group ID, then lists the paths to the duplicate files.</p><div><pre><code>      2  {32  3876609034  0}\nd:\\HP_Drivers_for_Win10\\SWSetup\\SP92183\\Graphics\\ocl_cpu_version.ini\nd:\\HP_Drivers_for_Win10\\SWSetup\\SP95347\\Graphics\\ocl_cpu_version.ini\n      2  {33  554973275  0}\nd:\\HP_Drivers_for_Win10\\SWSetup\\SP92183\\DisplayAudio\\6.16\\version.ini\nd:\\HP_Drivers_for_Win10\\SWSetup\\SP95347\\DisplayAudio\\6.16\\version.ini\n      3  {33  4084763797  0}\nd:\\HP_Drivers_for_Win10\\SWSetup\\SP57014\\Driver1\\silentsetup.bat\nd:\\HP_Drivers_for_Win10\\SWSetup\\SP57014\\Driver2\\silentsetup.bat\nd:\\HP_Drivers_for_Win10\\SWSetup\\SP57014\\silentsetup.bat\n      2  {41  388051727  0}\nd:\\go\\go-sample-queue\\.git\\refs\\heads\\master\nd:\\go\\go-sample-queue\\.git\\refs\\remotes\\origin\\master\n      2  {41  954715591  0}\nd:\\go\\go-sample-detector\\.git\\ORIG_HEAD\nd:\\go\\go-sample-detector\\.git\\refs\\heads\\master\n      3  {41  1012172877  0}\nd:\\go\\go-sample-recursion\\.git\\ORIG_HEAD\nd:\\go\\go-sample-recursion\\.git\\refs\\heads\\master\nd:\\go\\go-sample-recursion\\.git\\refs\\remotes\\origin\\master\n</code></pre></div><p>Each group of duplicates starts with a line containing:</p><ul><li><p>The number of files in the group (e.g., 2 or 3).</p></li><li><p>The structure {size hash group}:</p><ul><li>size: File size in bytes.</li><li>hash: CRC32 hash of the files.</li><li>group: Group ID (in this case, 0). This field is used for grouping identical files that have the same  and . If files have the same  and  but their content differs (which is determined at the  stage), they will be assigned a different  ID, and they will not be included in the same group of duplicates in the final result.</li></ul></li><li><p>Followed by the full paths to each duplicate file in that group.</p></li></ul><p>The presented implementation of duplicate file detection in Golang demonstrates the power of the pipelined approach and parallel processing. The use of channels for data transfer between stages, worker pools for parallel execution of tasks, and a well-designed checker mechanism makes the solution efficient and scalable. Built-in metrics and monitoring significantly simplify debugging and performance analysis.</p><p>I was surprised by the performance, despite the fact that I almost didn't think about optimization. On the contrary - the overhead in the form of monitoring, which I used to observe the load in real time - slows down the work.</p><p>Of course, there is always room for improvement. Potential enhancements could include:</p><ul><li><p>Support for very large files using streaming processing and more sophisticated hashing algorithms.</p></li><li><p>Or more thoughtful use of disk cache (for example, not allowing the cache to \"cool down\" after the hasher before the matcher).</p></li></ul><p>Nevertheless, this solution serves as a starting point for understanding and implementing pipelined systems in Golang.</p>","contentLength":18033,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NAS1831C4C56: The Little Fastener That Anchors Stars","url":"https://dev.to/ersajay/nas1831c4c56-the-little-fastener-that-anchors-stars-4n9","date":1750055500,"author":"ersajay","guid":157037,"unread":true,"content":"<p>A Meeting in the Circuit Desert\nWhen I first landed on this planet of clinking tools and humming machines, I thought all fasteners were like the flashy ones I’d seen—loud, polished, and a little too proud of their shine. But then I met the NAS1831C4C56—a 1/4-inch spacer, sitting quietly on a workbench like a single cactus in the desert.<p>\n“You’re… small,” I said, tilting my head.</p>\n“And you’re a child who talks to fasteners,” it replied, its hexagonal body glinting softly. “But size isn’t what matters. Ask the fox.”</p><p>The Secret of Its Desert Bloom\nThis isn’t just metal—it’s desert magic. Let me tell you its story:</p><p>Material: 303 stainless steel, tough as the baobab roots on my home planet. It laughs at corrosion, just like the cactus laughs at sandstorms.\nSize: 1/4\" hex, 0.56\" long—small enough to fit in a pocket, but strong enough to hold a satellite.<p>\nCertifications: MIL-STD-45622, RoHS, ISO 9001. Think of them as the “star maps” that guide it—proving it’s reliable, even in the darkest corners of space.</p></p><p>Fun Fact: <a href=\"https://www.ersaelectronics.com/\" rel=\"noopener noreferrer\">Engineers</a> call it the “Swiss Army knife of fasteners.” They steal it from factory floors like children steal stars—because once you find one, you never let go.</p><p>The Cactus of Extreme Climates\nOn the planet of factories, where machines roar like angry volcanoes and chemicals spill like poison water, the <a href=\"https://www.ersaelectronics.com/blog/what-is-the-nas1831c4c56\" rel=\"noopener noreferrer\">NAS1831C4C56</a> thrives.\n“Why not plastic?” I asked a welding robot.<p>\n“Plastic cries when sparks land. This one? It hums.”</p>\nIt survives -40°C (colder than the desert at night) and 125°C (hotter than the sun at noon). It shrugs off oil, acid, and even the “accidental” hammers of interns.<p>\n“You’re unkillable,” I said.</p>\n“Not unkillable,” it replied. “Just… prepared. Like the cactus that stores water—we both know hard times come.”</p><p>The Guardian of Invisible Things\nIn the quiet corners of the universe, the NAS1831C4C56 holds what matters:</p><p>Satellites: It keeps solar panels steady in zero gravity, so they can drink sunlight like roses drink rain.<a href=\"https://www.ersaelectronics.com/\" rel=\"noopener noreferrer\">Medical Devices</a>: It secures pacemaker circuits, counting heartbeats softer than a fox’s footsteps.\nEV Batteries: It stops sparks from dancing where they shouldn’t—so your Tesla stays a car, not a firework.<p>\nSmart Factories: It survives 24/7 robot arms, patient as the lamplighter on Earth.</p></p><p>“You’re a hero,” I told it.\n“Heroes have parades,” it said. “I’m just a spacer. But parades don’t keep stars in the sky—fasteners do.”</p><p>The Tale of the Three Materials\nOnce, I met three fasteners in a workshop: Aluminum, Plastic, and NAS1831C4C56.</p><p>Aluminum preened: “I’m lightweight! Aerospace loves me!” But a single drop of acid made it wince.\nPlastic giggled: “I’m cheap! Everyone buys me!” But a warm coffee cup melted its smile.<p>\nNAS1831C4C56 said nothing. It just held a circuit board, steady as the desert’s horizon.</p></p><p>Later, I asked the fox: “Why does everyone choose the quiet one?”\n“Because the best things are invisible to the eye,” the fox said. “Like the wind, or love, or a fastener that never fails.”</p><p>When the Cactus Isn’t Needed\nEven cacti have their limits. The NAS1831C4C56 sighed:<p>\n“I’m not for ultra-light drones—aluminum saves grams, though it’ll falter in storms. I’m not for disposable gadgets—plastic’s fine, but it won’t outlive the landfill. And I’m overkill for macaroni art—though I’d outlive the artist’s pride.”</p>\n“So when do you shine?” I asked.<p>\n“When the project matters,” it said. “Fire, acid, interns… if it’s worth doing, it’s worth doing with something that lasts.”</p></p><p>How to Find a True Friend\nIn the market of fasteners, not all are real. The NAS1831C4C56 warned:<p>\n“Beware of eBay sellers with ‘NASA-certified’ and $0.99 shipping. They’re like fake stars—bright, but empty. Find Ersa Electronics or RAF Hardware. Demand MIL-STD-45622 papers. Counterfeits fail faster than a child’s promise to water the rose.”</p>\n“How do I know it’s you?” I asked.<p>\n“You’ll feel it,” it said. “A real fastener doesn’t shout. It just… holds.”</p></p><p>The Star That Never Fades\nIn 2050, when humans build colonies on Mars, the NAS1831C4C56 will be there. It’ll hold quantum computers (even qubits need something steady), Mars habitats (cosmic radiation can’t break it), and robot arms (when AI overlords revolt, they’ll use it to build… well, let’s not think about that).<p>\n“You’ll outlive us all,” I said.</p>\n“No,” it replied. “I’ll just keep holding. Because stars don’t stay in the sky by magic—they stay because something anchors them.”</p><p>The Secret of the Little Fastener\nThe NAS1831C4C56 isn’t flashy. It doesn’t need a name in lights. It’s the kind of friend you notice only when it’s gone—like the rose in the garden, or the fox’s footsteps in the sand.<p>\n“What makes you special?” I asked, as I packed to leave.</p>\nIt didn’t answer. It just held a circuit board, steady as the desert, as the stars, as time itself.<p>\nAnd I realized—important things are never the loudest. They’re the ones that stay.</p></p><p>Written by a wanderer who once mistook a fastener for a new planet. The NAS1831C4C56 set me straight.\n🌵 You become responsible, forever, for the fasteners you ignore.</p>","contentLength":5264,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MVC vs DDD: Go Language Architecture Deep Dive","url":"https://dev.to/leapcell/mvc-vs-ddd-go-language-architecture-deep-dive-466f","date":1750047062,"author":"Leapcell","guid":156978,"unread":true,"content":"<h2>\n  \n  \n  Detailed Comparison of Go Language MVC and DDD Layered Architectures\n</h2><p>MVC and DDD are two popular layered architectural concepts in backend development. MVC (Model-View-Controller) is a design pattern mainly used to separate user interface, business logic, and data models for easier decoupling and layering, while DDD (Domain-Driven Design) is an architectural methodology aimed at solving design and maintenance difficulties in complex systems by building business domain models.</p><p>In the Java ecosystem, many systems have gradually transitioned from MVC to DDD. However, in languages like Go, Python, and NodeJS—which advocate simplicity and efficiency—MVC remains the mainstream architecture. Below, we will specifically discuss the differences in directory structure between MVC and DDD based on Go language.</p><div><pre><code>+------------------+\n|      View        | User Interface Layer: responsible for data display and user interaction (such as HTML pages, API responses)\n+------------------+\n|   Controller     | Controller Layer: processes user requests, calls Service logic, coordinates Model and View\n+------------------+\n|      Model       | Model Layer: contains data objects (such as database table structures) and some business logic (often scattered in Service layer)\n+------------------+\n</code></pre></div><div><pre><code>+--------------------+\n|   User Interface   | Responsible for user interaction and display (such as REST API, Web interface)\n+--------------------+\n| Application Layer  | Orchestrates business processes (such as calling domain services, transaction management), does not contain core business rules\n+--------------------+\n|   Domain Layer     | Core business logic layer: contains aggregate roots, entities, value objects, domain services, etc., encapsulates business rules\n+--------------------+\n| Infrastructure     | Provides technical implementations (such as database access, message queues, external APIs)\n+--------------------+\n</code></pre></div><h2>\n  \n  \n  Main Differences Between MVC and DDD\n</h2><ul><li>MVC layers by technical function (Controller/Service/DAO), focusing on technical implementation.</li><li>DDD divides modules by business domain (such as order domain, payment domain), isolating core business logic through bounded contexts.</li></ul><ol><li><strong>Carrier of Business Logic</strong></li></ol><ul><li>MVC usually adopts an anemic model, separating data (Model) and behavior (Service), which leads to high maintenance cost due to dispersed logic.</li><li>DDD achieves a rich model through aggregate roots and domain services, concentrating business logic in the domain layer and enhancing scalability.</li></ul><ul><li>MVC has a low development cost and is suitable for small to medium systems with stable requirements.</li><li>DDD requires upfront domain modeling and a unified language, making it suitable for large systems with complex business and long-term evolution needs, but the team must have domain abstraction capabilities. For example, in e-commerce promotion rules, DDD can prevent logic from being scattered across multiple services.</li></ul><h2>\n  \n  \n  Go Language MVC Directory Structure\n</h2><p>MVC is mainly divided into three layers: view, controller, and model.</p><div><pre><code>gin-order/\n├── cmd\n│   └── main.go                  # Application entry point, starts the Gin engine\n├── internal\n│   ├── controllers              # Controller layer (handles HTTP requests), also known as handlers\n│   │   └── order\n│   │       └── order_controller.go  # Controller for the Order module\n│   ├── services                 # Service layer (handles business logic)\n│   │   └── order\n│   │       └── order_service.go       # Service implementation for the Order module\n│   ├── repository               # Data access layer (interacts with the database)\n│   │   └── order\n│   │       └── order_repository.go    # Data access interface and implementation for Order module\n│   ├── models                   # Model layer (data structure definitions)\n│   │   └── order\n│   │       └── order.go               # Data model for the Order module\n│   ├── middleware               # Middleware (such as authentication, logging, request interception)\n│   │   ├── logging.go             # Logging middleware\n│   │   └── auth.go                # Authentication middleware\n│   └── config                   # Configuration module (database, server configurations, etc.)\n│       └── config.go                # Application and environment configurations\n├── pkg                          # Common utility packages (such as response wrappers)\n│   └── response.go              # Response handling utility methods\n├── web                          # Frontend resources (templates and static assets)\n│   ├── static                   # Static resources (CSS, JS, images)\n│   └── templates                # Template files (HTML templates)\n│       └── order.tmpl           # View template for the Order module (if rendering HTML is needed)\n├── go.mod                       # Go module management file\n└── go.sum                       # Go module dependency lock file\n</code></pre></div><h2>\n  \n  \n  Go Language DDD Directory Structure\n</h2><p>DDD is mainly divided into four layers: interface, application, domain, and infrastructure.</p><div><pre><code>go-web/\n│── cmd/\n│   └── main.go               # Application entry point\n│── internal/\n│   ├── application/          # Application layer (coordinates domain logic, handles use cases)\n│   │   ├── services/         # Service layer, business logic directory\n│   │   │   └── order_service.go # Order application service, calls domain layer business logic\n│   ├── domain/               # Domain layer (core business logic and interface definitions)\n│   │   ├── order/            # Order aggregate\n│   │   │   ├── order.go      # Order entity (aggregate root), contains core business logic\n│   │   ├── repository/       # General repository interfaces\n│   │   │   ├── repository.go # General repository interface (CRUD operations)\n│   │   │   └── order_repository.go # Order repository interface, defines operations on order data\n│   ├── infrastructure/       # Infrastructure layer (implements interfaces defined in the domain layer)\n│   │   ├── repository/       # Repository implementation\n│   │   │   └── order_repository_impl.go  # Order repository implementation, concrete order data storage\n│   └── interfaces/           # Interface layer (handles external requests, such as HTTP interfaces)\n│   │   ├── handlers/         # HTTP handlers\n│   │   │  └── order_handler.go # HTTP handler for orders\n│   │   └── routes/\n│   │   │   ├── router.go     # Base router utility setup\n│   │   │   └── order-routes.go # Order routes configuration\n│   │   │   └── order-routes-test.go # Order routes test\n│   └── middleware/           # Middleware (e.g.: authentication, interception, authorization, etc.)\n│   │   └── logging.go        # Logging middleware\n│   ├── config/               # Service-related configuration\n│   │   └── server_config.go  # Server configuration (e.g., port, timeout settings, etc.)\n│── pkg/                      # Reusable public libraries\n│   └── utils/                # Utility classes (e.g.: logging, date handling, etc.)\n</code></pre></div><h2>\n  \n  \n  Go Language MVC Code Implementation\n</h2><div><pre><code>Controller (Interface Layer) → Service (Business Logic Layer) → Repository (Data Access Layer) → Model (Data Model)\n</code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h3>\n  \n  \n  Data Access Layer (Repository)\n</h3><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h2>\n  \n  \n  Go Language MVC Best Practices\n</h2><h3>\n  \n  \n  Interface Segregation Principle\n</h3><p>The Repository layer defines interfaces, supporting multiple database implementations.</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h2>\n  \n  \n  Go Language DDD Code Implementation and Best Practices\n</h2><p>DDD emphasizes the construction of domain models, organizing business logic using Aggregates, Entities, and Value Objects.</p><p>In Go, entities and value objects are typically defined with struct:</p><div><pre><code></code></pre></div><p>DDD typically adopts a layered architecture. Go projects can follow this structure:</p><ul><li>: Core business logic, e.g., entities and aggregates under the domain directory.</li><li>: Use cases and orchestration of business processes.</li><li>: Adapters for database, caching, external APIs, etc.</li><li>: Provides HTTP, gRPC, or CLI interfaces.</li></ul><p>The domain layer should not directly depend on the infrastructure layer; instead, it relies on interfaces for dependency inversion.</p><blockquote><p>Note: The core of DDD architecture is dependency inversion (DIP). The Domain is the innermost core, defining only business rules and interface abstractions. Other layers depend on the Domain for implementation, but the Domain does not depend on any external implementations. In Hexagonal Architecture, the domain layer sits at the core, while other layers (such as application, infrastructure) provide concrete technical details (like database operations, API calls) by implementing interfaces defined by the domain, achieving decoupling between domain and technical implementation.</p></blockquote><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>The aggregate root manages the lifecycle of the entire aggregate:</p><div><pre><code></code></pre></div><p>Application services encapsulate domain logic, preventing external layers from directly manipulating domain objects:</p><div><pre><code></code></pre></div><p>Domain events are used for decoupling. In Go, you can implement this via Channels or Pub/Sub:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Combining CQRS (Command Query Responsibility Segregation)\n</h3><p>DDD can be combined with CQRS. In Go, you can use  for change operations and  for data reading:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Summary: MVC vs. DDD Architecture\n</h2><h3>\n  \n  \n  Core Differences in Architecture\n</h3><ul><li>Layers: Three layers—Controller/Service/DAO</li><li><ul><li>Controller handles requests, Service contains logic</li><li>DAO directly operates the database</li></ul></li><li><p>Pain Points: The Service layer becomes bloated, and business logic is coupled with data operations</p></li></ul><ul><li>Layers: Four layers—Interface Layer / Application Layer / Domain Layer / Infrastructure Layer</li><li><ul><li>Application Layer orchestrates processes (e.g., calls domain services)</li><li>Domain Layer encapsulates business atomic operations (e.g., order creation rules)</li><li>Infrastructure Layer implements technical details (e.g., database access)</li></ul></li><li><p>Pain Points: The domain layer is independent of technical implementations, and logic corresponds closely with the layer structure</p></li></ul><h3>\n  \n  \n  Modularity and Scalability\n</h3><ul><li>High Coupling: Lacks clear business boundaries; cross-module calls (e.g., order service directly relying on account tables) make code hard to maintain.</li><li>Poor Scalability: Adding new features requires global changes (e.g., adding risk control rules must intrude into order service), easily causing cascading issues.</li></ul><ul><li>Bounded Context: Modules are divided by business capabilities (e.g., payment domain, risk control domain); event-driven collaboration (e.g., order payment completed event) is used for decoupling.</li><li>Independent Evolution: Each domain module can be upgraded independently (e.g., payment logic optimization does not affect order service), reducing system-level risks.</li></ul><ul><li>Prefer MVC for small to medium systems: Simple business (e.g., blogs, CMS, admin backends), requiring rapid development with clear business rules and no frequent changes.</li><li>Prefer DDD for complex business: Rule-intensive (e.g., financial transactions, supply chain), multi-domain collaboration (e.g., e-commerce order and inventory linkage), frequent changes in business requirements.</li></ul><p><a href=\"https://leapcell.io/?lc_t=d_gomvcddd\" rel=\"noopener noreferrer\">Leapcell</a> is the Next-Gen Serverless Platform for Web Hosting, Async Tasks, and Redis:</p><ul><li>Develop with Node.js, Python, Go, or Rust.</li></ul><p><strong>Deploy unlimited projects for free</strong></p><ul><li>pay only for usage — no requests, no charges.</li></ul><p><strong>Unbeatable Cost Efficiency</strong></p><ul><li>Pay-as-you-go with no idle charges.</li><li>Example: $25 supports 6.94M requests at a 60ms average response time.</li></ul><p><strong>Streamlined Developer Experience</strong></p><ul><li>Intuitive UI for effortless setup.</li><li>Fully automated CI/CD pipelines and GitOps integration.</li><li>Real-time metrics and logging for actionable insights.</li></ul><p><strong>Effortless Scalability and High Performance</strong></p><ul><li>Auto-scaling to handle high concurrency with ease.</li><li>Zero operational overhead — just focus on building.</li></ul>","contentLength":12081,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mastering sync.Cond: A Go Developer's Guide to Condition Variables","url":"https://dev.to/jones_charles_ad50858dbc0/mastering-synccond-a-go-developers-guide-to-condition-variables-14b1","date":1750035272,"author":"Jones Charles","guid":155963,"unread":true,"content":"<h2>\n  \n  \n  1. Welcome to the World of sync.Cond\n</h2><p>If you’ve been coding in Go for a year or two, you’re likely cozy with goroutines and channels—the bread and butter of Go concurrency. Goroutines keep things lightweight, and channels make data flow like a charm. But what happens when you need to pause a goroutine until  happens—like waiting for a cake to arrive before the party starts? Enter , Go’s unsung hero for condition-based synchronization.</p><p>Imagine this: instead of spamming channels to tell every friend “cake’s here,” you grab a megaphone and shout it once. That’s —a clean, efficient way to wake up one or all waiting goroutines when a condition flips to “ready.” It’s not as flashy as channels, but it’s a game-changer for certain concurrency puzzles.</p><p>In this guide, I’ll break down  for Go devs ready to level up. No cryptic jargon—just clear explanations, real-world examples, and a sprinkle of lessons I’ve picked up along the way. By the end, you’ll know when to reach for , how to wield it like a pro, and why it might just save your next project.</p><p>Let’s dive in and demystify this gem!</p><h2>\n  \n  \n  2. sync.Cond : The Basics You Need\n</h2><p>At its core,  is Go’s condition variable—a tool to make goroutines wait until a specific state is true, then wake them up to roll. Think of it as a “hold up, wait for the green light” mechanism. It’s built into the  package and pairs with a lock (usually a ) to keep things safe and sound.</p><p>Here’s the lineup of its starring methods:</p><ul><li><strong><code>sync.NewCond(l sync.Locker)</code></strong>: Spawns a new condition variable, tied to a lock.</li><li>: Pauses the goroutine, drops the lock, and waits for a nudge—grabbing the lock back when it wakes.</li><li>: Pings  waiting goroutine to get moving.</li><li>: Shouts to  waiting goroutines, “Time to go!”</li></ul><p>The flow? Lock, check the condition, wait if it’s not ready, and wake up when it is. Simple, but powerful.</p><h3>\n  \n  \n  Channels vs. sync.Cond: The Showdown\n</h3><p>Channels are Go’s rockstars for passing data and syncing tasks. Need to signal “done”? A  does the trick. But if multiple goroutines need to wait for the —say, a queue filling up—channels can get awkward fast. You’d need loops, buffers, or multiple channels, and suddenly your code’s a spaghetti mess.</p><p> flips the script. It’s not about passing data; it’s about waiting for a condition to turn true. Check this quick comparison:</p><div><pre><code></code></pre></div><p>Channels win for simplicity in one-off signals. But  shines when you’ve got multiple waiters or tricky conditions. It’s like choosing between a text message and a group announcement—depends on the crowd.</p><p>If you’ve got goroutines and channels down but want to tackle more complex sync scenarios, this is your next step. No PhD in concurrency required—just a willingness to experiment.</p><p>Up next: real-world use cases where  steals the show!</p><h2>\n  \n  \n  3. Where sync.Cond Shines: Real-World Use Cases\n</h2><p>Now that we’ve got the basics, let’s see  in action. It’s not a one-size-fits-all tool—it thrives in scenarios where goroutines need to  rather than just grab data from a channel. Here are three killer use cases, complete with bite-sized examples.</p><h3>\n  \n  \n  Use Case 1: Waiting for “Ready” Like a Pro\n</h3><p>: You’ve got a task queue, and multiple goroutines are itching to process tasks—but only when there’s something to do. Polling the queue burns CPU, and spamming channels for each waiter is a headache.  says, “Chill, I’ll wake you when it’s time.”</p><p>: No busy loops, no channel clutter—just clean, efficient waiting.</p><div><pre><code></code></pre></div><p>: Workers sleep until tasks drop, then spring into action—one at a time.</p><h3>\n  \n  \n  Use Case 2: Waking the Whole Crew\n</h3><p>: A database needs to boot up before multiple services can start. With channels, you’d need one per service. ’s  yells, “DB’s up!” and everyone’s off to the races.</p><p>: One call, all awake—perfect for group sync.</p><div><pre><code></code></pre></div><p>: All services wait, then launch together when the DB’s ready.</p><h3>\n  \n  \n  Use Case 3: Juggling Multiple Conditions\n</h3><p>: An order needs payment  stock before shipping.  lets you wait for both, signaling only when the stars align.</p><p>: Handles complex “and” logic without breaking a sweat.</p><div><pre><code></code></pre></div><p>: Waits until both conditions click, then ships.</p><p> is your go-to when you need goroutines to —whether it’s one worker, a whole team, or a tricky multi-step state. Next, we’ll dig into why it’s awesome and how to use it right.</p><h2>\n  \n  \n  4. Why sync.Cond is Your Secret Weapon\n</h2><p>So, why bother with  when channels are already in your toolbox? It’s all about efficiency, flexibility, and control. Let’s unpack its superpowers and zoom in on what makes it tick.</p><ol><li><ul><li>Polling a condition (e.g., ) fries your CPU. ’s  parks goroutines until the signal hits—no busy-waiting, just chill vibes. It’s like napping until your pizza delivery arrives.</li></ul></li><li><ul><li> hooks up with any — for tight control,  for read-heavy setups. This flexibility lets you tune concurrency to your app’s needs.</li></ul></li><li><ul><li>Need one goroutine to jump? Use . Want the whole crew?  has you covered. You call the shots on who wakes up and when.</li></ul></li></ol><h4> vs. : Pick Your Flavor\n</h4><ul><li>: Wakes  goroutine. Great for single-consumer setups like a task queue—keeps contention low.</li><li>: Wakes . Perfect for shared states (e.g., “DB’s ready!”)—but watch out for a stampede if too many goroutines pile on.</li></ul><p>: Use  for solo acts,  for group hugs. Test with big crowds to avoid lock fights.</p><h4>\n  \n  \n  Lock Love: Why It’s Mandatory\n</h4><p> doesn’t roll solo—it needs a lock to keep condition checks safe. Without it, you’d get race conditions (e.g., missing a signal mid-check). The lock’s your bodyguard, ensuring everything stays atomic.</p><ul><li>Lock → Check → Wait (unlock) → Wake → Relock → Go!</li></ul><p>I once swapped channels for  in a log processor. With  for a “files ready” state, throughput jumped 15%—no more channel overhead, just smooth sailing.</p><p> isn’t here to replace channels—it’s a ninja for state-waiting gigs. Low overhead, lock-friendly, and wake-up control make it a clutch addition to your concurrency toolkit. Next, we’ll nail down how to use it without tripping over your own feet.</p><h2>\n  \n  \n  5. sync.Cond Hacks: Best Practices &amp; Traps to Dodge\n</h2><p> is slick, but it’s not foolproof. To wield it like a pro, you need some street smarts. Here’s a rundown of best practices I’ve honed over time—plus the pitfalls that’ll bite if you’re not careful.</p><ol><li><p><strong>Always Check Before Waiting</strong></p><ul><li> The condition might already be true. Blindly calling  risks a deadlock if the signal already fired.</li></ul><pre><code></code></pre></li></ol><ul><li>: </li></ul><ol><li><p><strong>Match Your Lock to the Job</strong></p><ul><li> for write-heavy stuff;  if reads dominate. It’s like picking the right gear for the road—maximize concurrency where you can.</li></ul></li><li><ul><li> is tempting, but waking 50 goroutines when only one can grab the lock is a CPU party foul. Stick to  for solo tasks unless everyone  to wake up.</li></ul></li><li><ul><li> spans goroutines, so leave breadcrumbs:\n</li></ul><pre><code></code></pre></li></ol><ol><li><ul><li>Calling  without a lock? Instant panic. Always lock first— isn’t kidding about its bodyguard.</li><li>: </li></ul></li><li><ul><li>Forgot the  loop? If the condition’s true but you wait anyway, you’re stuck. I learned this the hard way when a scheduler hung until a reboot.</li><li>: See Best Practice #1.</li></ul></li><li><ul><li>Unlock ? The wake-up might vanish into the void. Signal  unlocking.</li></ul><pre><code></code></pre></li></ol><p>In a task scheduler, I threw  at 50 workers. Result? A “thundering herd” trashed performance—500ms response time. Switched to  with smarter logic, and boom: 350ms. Precision pays.</p><div><table><tbody><tr></tr><tr></tr><tr></tr></tbody></table></div><p>Master these, and  becomes your concurrency BFF. Next, we’ll tie it all together with a full example!</p><h2>\n  \n  \n  6. sync.Cond in Action: A Stock Sync Showdown\n</h2><p>Let’s put  to work with a real-world example: syncing stock in an e-commerce system. Multiple consumers (order processors) wait for stock to hit a threshold, and a producer updates it. No polling, no channel overload—just clean, concurrent magic.</p><ul><li>: Consumers wait until stock ≥ 10, then process orders.</li><li>: One producer (stock updater), three consumers (order handlers).</li><li>:  with  to wake everyone when stock’s ready.</li></ul><p>Here’s the full deal, with comments to guide you:</p><div><pre><code></code></pre></div><div><pre><code>Order 1: Waiting (stock: 0)...\nOrder 2: Waiting (stock: 0)...\nOrder 3: Waiting (stock: 0)...\nStock now: 5\nStock now: 15\nOrder 1: Processed! Stock left: 14\nOrder 2: Processed! Stock left: 13\nOrder 3: Processed! Stock left: 12\n</code></pre></div><ul><li>: Consumers wait when stock’s low. At 15,  wakes them all, and they grab stock one by one (thanks to the lock).</li><li>: No CPU waste, no per-consumer channels—just efficient sync.</li></ul><ul><li>: Perfect for “everyone needs to know” moments.</li><li>:  keeps stock updates and checks atomic.</li><li>: Goroutines sleep until the magic number hits.</li></ul><ul><li>: Add a second  for VIP orders.</li><li>: You’d need a channel per consumer and a dispatcher—way messier.</li></ul><p>This is  flexing its muscles. Let’s wrap it up next!</p><h2>\n  \n  \n  7. Wrapping Up: Your sync.Cond Playbook\n</h2><p>We’ve taken  from “huh?” to “heck yeah!” Here’s the rundown:</p><ul><li>: Waiting for conditions (queues, multi-consumer sync, complex states).</li><li>: Low CPU burn, lock flexibility, and wake-up control—channels can’t do it all.</li><li>: It’s your next step after mastering goroutines and channels.</li></ul><p> isn’t the star of every show, but when it fits, it’s a concurrency MVP. It flips the script from channels’ “push” to a “pull” mindset—wait smart, not hard.</p><p>If you’re a Go dev with a year or two under your belt, give  a spin when:</p><ul><li>Channels start feeling like overkill.</li><li>You’re juggling tricky “when’s it ready?” logic.</li><li>Performance needs a boost.</li></ul><p>Hack together a demo—tweak the stock sync code or build your own. It’s less spooky once you feel its rhythm.</p><p>Go’s concurrency game is always evolving.  is a classic, but who knows—maybe xAI’s AI wizards will cook up some next-level sync tricks for Go someday. For now, it’s a lean, mean tool that gets the job done.</p><p>: After wrestling with  in real projects, I dig its quiet power. It’s not loud like channels, but it’s a lifesaver when efficiency matters. Hope you snag that “aha!” moment too—drop a comment if you do!</p>","contentLength":9912,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Implement LLM Tool-calling with Go and Ollama","url":"https://dev.to/calvinmclean/how-to-implement-llm-tool-calling-with-go-and-ollama-237g","date":1750034591,"author":"Calvin McLean","guid":155962,"unread":true,"content":"<p>Tool-calling is a feature of LLMs and LLM APIs that enables the model to access external information and perform actions. Instead of responding to a prompt directly, the model generates inputs to a function, calls that function (more on this later), and then generates a response based on the function's output. This significantly improves the functionality of LLMs by accessing real-time information like weather, sports scores, or recent events. Additionally, the model can interact with external systems like databases, APIs, or even execute scripts.</p>\n\n<p>LLMs and tool-calling introduced a new type of program where the operation and flow is controlled by the LLM rather than rigid code. This creates highly flexible and dynamic programs, but they can also be less reliable and consistent. Like always, it's important to balance functionality and reliability.</p>\n\n<h2>\n  \n  \n  How it works\n</h2>\n\n<p>LLMs are only able to generate text. In order to use tools, the model needs to be prompted <em>through</em> another program or controller. Instead of actually \"calling\" a function directly, the the model generates structured data to describe the function to use and which inputs to use with it. The controller program is responsible for parsing the input data, finding the function, and executing it. Then, it provides the output to the LLM (often as JSON). The LLM is finally able to respond to the user's prompt using the output of the function in addition to the data it was trained on.</p>\n\n<p>Before using tools, the LLM needs to know about the tools that it can use. It needs the function's name, a description of what it does, and a schema defining the function's inputs. This can be done with system prompts, but many model APIs now include a separate input field for tool definitions.</p>\n\n<p>Interacting with the model directly, with only a thin chat abstraction around it, effectively demonstrates how this works. Ollama allows creating a Modelfile to extend a model with a specific system prompt or other configurations. Here is a system prompt that instructs a model how to use \"tools\" (but really it will just be me responding with JSON):<br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>FROM gemma3:4b\n\nSYSTEM \"\"\"\nA program is used to interact with you and the user. The program allows you to use functions/tools\nto get external information. When you use a tool, the program will respond with JSON data. Anything else is\ncoming from the user and should be treated as human interaction.\n\nTo use a tool, respond with a JSON object with the following structure:\n{\n    \"tool\": &lt;name of the called tool&gt;,\n    \"tool_input\": &lt;parameters for the tool matching the above JSON schema&gt;\n}\nDo not include any other text in your response.\n\nIf the user's prompt requires a tool to get a valid answer, use the above format to use the tool.\nAfter receiving a tool response, continue to answer the user's prompt using the tool's response.\nIf you don't have a relevant tool for the prompt, answer it normally. Be fun and interesting.\n\nHere are your available tools:\n\ngetCurrentWeather\nGet the current weather in a given location\n{\n    \"type\": \"object\",\n    \"properties\": {\n        \"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"},\n        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n    },\n    \"required\": [\"location\", \"unit\"]\n}\n\"\"\"\n</code></pre>\n\n</div>\n\n\n\n<p>Now that the model is ready, let's chat:</p>\n\n<ol>\n<li>\n<p>Input:</p>\n\n<blockquote>\n<p>what is the weather like in new york city?</p>\n</blockquote>\n</li>\n<li>\n<p>Model's response:<br>\n</p>\n<pre class=\"highlight json\"><code><span class=\"p\">{</span><span class=\"w\">\n    </span><span class=\"nl\">\"tool\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"getCurrentWeather\"</span><span class=\"p\">,</span><span class=\"w\">\n    </span><span class=\"nl\">\"tool_input\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\">\n        </span><span class=\"nl\">\"location\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"New York City\"</span><span class=\"p\">,</span><span class=\"w\">\n        </span><span class=\"nl\">\"unit\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"fahrenheit\"</span><span class=\"w\">\n    </span><span class=\"p\">}</span><span class=\"w\">\n</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre>\n\n</li>\n<li>\n<p>Input:<br>\n</p>\n<pre class=\"highlight json\"><code><span class=\"p\">{</span><span class=\"nl\">\"temperature\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">78</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"nl\">\"unit\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"F\"</span><span class=\"p\">}</span><span class=\"w\">\n</span></code></pre>\n\n</li>\n<li>\n<p>Model's response:</p>\n\n<blockquote>\n<p>The temperature in New York City is currently 78°F! It’s a beautiful, warm day – perfect for a stroll through Central Park or grabbing a hot dog.</p>\n</blockquote>\n</li>\n</ol>\n\n<p>Instead of attempting to hallucinate a response, the model generates tool input using the specified format. Then, I respond with JSON emulating the tool output. With this new information, the model is able to accurately answer the prompt with a friendly flair.</p>\n\n<p>Although this isn't real tool calling, it is interesting to see how impactful the system prompt is on the model's behavior. This is helpful to demystify the LLM's behavior and show what is really happening behind the scenes. This foundational understanding beneficial when developing more complex tools and building applications around LLMs.</p>\n\n<h2>\n  \n  \n  Implement Tool-calling with Ollama + Go\n</h2>\n\n<p>The next step is to integrate tool calling into a real program instead of chatting with the model. In order to stay at a low-level and learn more about LLM interactions, the program uses Ollama's API and Go client instead of a more generalized library.</p>\n\n<p>Here is the request used to prompt a model with a tool defined:<br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight go\"><code><span class=\"n\">messages</span> <span class=\"o\">:=</span> <span class=\"p\">[]</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Message</span><span class=\"p\">{</span>\n    <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Message</span><span class=\"p\">{</span>\n        <span class=\"n\">Role</span><span class=\"o\">:</span>    <span class=\"s\">\"user\"</span><span class=\"p\">,</span>\n        <span class=\"n\">Content</span><span class=\"o\">:</span> <span class=\"s\">\"What is the weather like in New York City?\"</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">req</span> <span class=\"o\">:=</span> <span class=\"o\">&amp;</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">ChatRequest</span><span class=\"p\">{</span>\n        <span class=\"n\">Model</span><span class=\"o\">:</span> <span class=\"n\">model</span><span class=\"p\">,</span>\n        <span class=\"n\">Messages</span><span class=\"o\">:</span> <span class=\"n\">messages</span><span class=\"p\">,</span>\n        <span class=\"n\">Tools</span><span class=\"o\">:</span> <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Tools</span><span class=\"p\">{</span>\n            <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Tool</span><span class=\"p\">{</span>\n                <span class=\"n\">Type</span><span class=\"o\">:</span> <span class=\"s\">\"function\"</span><span class=\"p\">,</span>\n                <span class=\"n\">Function</span><span class=\"o\">:</span> <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">ToolFunction</span><span class=\"p\">{</span>\n                    <span class=\"n\">Name</span><span class=\"o\">:</span>        <span class=\"s\">\"getCurrentWeather\"</span><span class=\"p\">,</span>\n                    <span class=\"n\">Description</span><span class=\"o\">:</span> <span class=\"s\">\"Get the current weather in a given location\"</span><span class=\"p\">,</span>\n                    <span class=\"n\">Parameters</span><span class=\"o\">:</span> <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">ToolFunctionParameters</span><span class=\"p\">{</span>\n                        <span class=\"n\">Type</span><span class=\"o\">:</span>     <span class=\"s\">\"object\"</span><span class=\"p\">,</span>\n                        <span class=\"n\">Required</span><span class=\"o\">:</span> <span class=\"p\">[]</span><span class=\"kt\">string</span><span class=\"p\">{</span><span class=\"s\">\"location\"</span><span class=\"p\">},</span>\n                        <span class=\"n\">Properties</span><span class=\"o\">:</span> <span class=\"k\">map</span><span class=\"p\">[</span><span class=\"kt\">string</span><span class=\"p\">]</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">ToolFunctionProperty</span><span class=\"p\">{</span>\n                            <span class=\"s\">\"location\"</span><span class=\"o\">:</span> <span class=\"p\">{</span>\n                                <span class=\"n\">Type</span><span class=\"o\">:</span>        <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">PropertyType</span><span class=\"p\">{</span><span class=\"s\">\"string\"</span><span class=\"p\">},</span>\n                                <span class=\"n\">Description</span><span class=\"o\">:</span> <span class=\"s\">\"The city and state, e.g. San Francisco, CA\"</span><span class=\"p\">,</span>\n                            <span class=\"p\">},</span>\n                        <span class=\"p\">},</span>\n                    <span class=\"p\">},</span>\n                <span class=\"p\">},</span>\n            <span class=\"p\">},</span>\n        <span class=\"p\">},</span>\n    <span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<p>The client program sends the ChatRequest and handles the ToolCall in the model's response:<br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight go\"><code><span class=\"k\">package</span> <span class=\"n\">main</span>\n\n<span class=\"k\">import</span> <span class=\"p\">(</span>\n    <span class=\"s\">\"context\"</span>\n    <span class=\"s\">\"encoding/json\"</span>\n    <span class=\"s\">\"fmt\"</span>\n    <span class=\"s\">\"log\"</span>\n\n    <span class=\"s\">\"github.com/ollama/ollama/api\"</span>\n<span class=\"p\">)</span>\n\n<span class=\"k\">const</span> <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"s\">\"llama3.2:3b\"</span>\n\n<span class=\"k\">func</span> <span class=\"n\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"n\">client</span><span class=\"p\">,</span> <span class=\"n\">err</span> <span class=\"o\">:=</span> <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">ClientFromEnvironment</span><span class=\"p\">()</span>\n    <span class=\"k\">if</span> <span class=\"n\">err</span> <span class=\"o\">!=</span> <span class=\"no\">nil</span> <span class=\"p\">{</span>\n        <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">Fatal</span><span class=\"p\">(</span><span class=\"n\">err</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">messages</span> <span class=\"o\">:=</span> <span class=\"p\">[]</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Message</span><span class=\"p\">{</span>\n        <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Message</span><span class=\"p\">{</span>\n            <span class=\"n\">Role</span><span class=\"o\">:</span>    <span class=\"s\">\"user\"</span><span class=\"p\">,</span>\n            <span class=\"n\">Content</span><span class=\"o\">:</span> <span class=\"s\">\"What is the weather like in New York City?\"</span><span class=\"p\">,</span>\n        <span class=\"p\">},</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">ctx</span> <span class=\"o\">:=</span> <span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">Background</span><span class=\"p\">()</span>\n    <span class=\"n\">req</span> <span class=\"o\">:=</span> <span class=\"o\">&amp;</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">ChatRequest</span><span class=\"p\">{</span>\n        <span class=\"c\">// ... request from above</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">handler</span> <span class=\"o\">:=</span> <span class=\"k\">func</span><span class=\"p\">(</span><span class=\"n\">resp</span> <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">ChatResponse</span><span class=\"p\">)</span> <span class=\"kt\">error</span> <span class=\"p\">{</span>\n        <span class=\"c\">// If there is no tool call, just print the message content</span>\n        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">resp</span><span class=\"o\">.</span><span class=\"n\">Message</span><span class=\"o\">.</span><span class=\"n\">ToolCalls</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"m\">0</span> <span class=\"p\">{</span>\n            <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Print</span><span class=\"p\">(</span><span class=\"n\">resp</span><span class=\"o\">.</span><span class=\"n\">Message</span><span class=\"o\">.</span><span class=\"n\">Content</span><span class=\"p\">)</span>\n            <span class=\"k\">return</span> <span class=\"no\">nil</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"c\">// Otherwise, process the tool call</span>\n        <span class=\"n\">tc</span> <span class=\"o\">:=</span> <span class=\"n\">resp</span><span class=\"o\">.</span><span class=\"n\">Message</span><span class=\"o\">.</span><span class=\"n\">ToolCalls</span><span class=\"p\">[</span><span class=\"m\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">Function</span>\n        <span class=\"k\">switch</span> <span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">Name</span> <span class=\"p\">{</span>\n        <span class=\"k\">case</span> <span class=\"s\">\"getCurrentWeather\"</span><span class=\"o\">:</span>\n            <span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">err</span> <span class=\"o\">:=</span> <span class=\"n\">getCurrentWeather</span><span class=\"p\">(</span><span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">Arguments</span><span class=\"p\">)</span>\n            <span class=\"k\">if</span> <span class=\"n\">err</span> <span class=\"o\">!=</span> <span class=\"no\">nil</span> <span class=\"p\">{</span>\n                <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">Fatal</span><span class=\"p\">(</span><span class=\"n\">err</span><span class=\"p\">)</span>\n            <span class=\"p\">}</span>\n\n            <span class=\"n\">messages</span> <span class=\"o\">=</span> <span class=\"nb\">append</span><span class=\"p\">(</span><span class=\"n\">messages</span><span class=\"p\">,</span> <span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Message</span><span class=\"p\">{</span>\n                <span class=\"n\">Role</span><span class=\"o\">:</span>    <span class=\"s\">\"tool\"</span><span class=\"p\">,</span>\n                <span class=\"n\">Content</span><span class=\"o\">:</span> <span class=\"n\">output</span><span class=\"p\">,</span>\n            <span class=\"p\">})</span>\n        <span class=\"k\">default</span><span class=\"o\">:</span>\n            <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">Fatal</span><span class=\"p\">(</span><span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Errorf</span><span class=\"p\">(</span><span class=\"s\">\"invalid function: %q\"</span><span class=\"p\">,</span> <span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">Name</span><span class=\"p\">))</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"k\">return</span> <span class=\"no\">nil</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c\">// Send initial chat message</span>\n    <span class=\"n\">err</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">Chat</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"n\">req</span><span class=\"p\">,</span> <span class=\"n\">handler</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">err</span> <span class=\"o\">!=</span> <span class=\"no\">nil</span> <span class=\"p\">{</span>\n        <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">Fatal</span><span class=\"p\">(</span><span class=\"n\">err</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"c\">// The model should have responded with a tool call</span>\n    <span class=\"c\">// and the handler would have appended a response to messages.</span>\n    <span class=\"c\">// Now, call the tool again with the response</span>\n    <span class=\"n\">req</span><span class=\"o\">.</span><span class=\"n\">Messages</span> <span class=\"o\">=</span> <span class=\"n\">messages</span>\n    <span class=\"n\">err</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">Chat</span><span class=\"p\">(</span><span class=\"n\">ctx</span><span class=\"p\">,</span> <span class=\"n\">req</span><span class=\"p\">,</span> <span class=\"n\">handler</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">err</span> <span class=\"o\">!=</span> <span class=\"no\">nil</span> <span class=\"p\">{</span>\n        <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">Fatal</span><span class=\"p\">(</span><span class=\"n\">err</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">func</span> <span class=\"n\">getCurrentWeather</span><span class=\"p\">(</span><span class=\"n\">input</span> <span class=\"k\">map</span><span class=\"p\">[</span><span class=\"kt\">string</span><span class=\"p\">]</span><span class=\"n\">any</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"kt\">string</span><span class=\"p\">,</span> <span class=\"kt\">error</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">location</span><span class=\"p\">,</span> <span class=\"n\">ok</span> <span class=\"o\">:=</span> <span class=\"n\">input</span><span class=\"p\">[</span><span class=\"s\">\"location\"</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"kt\">string</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"o\">!</span><span class=\"n\">ok</span> <span class=\"p\">{</span>\n        <span class=\"n\">log</span><span class=\"o\">.</span><span class=\"n\">Fatalf</span><span class=\"p\">(</span><span class=\"s\">\"bad args: %v\"</span><span class=\"p\">,</span> <span class=\"n\">input</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">weatherInfo</span> <span class=\"o\">:=</span> <span class=\"k\">map</span><span class=\"p\">[</span><span class=\"kt\">string</span><span class=\"p\">]</span><span class=\"n\">any</span><span class=\"p\">{</span>\n        <span class=\"s\">\"location\"</span><span class=\"o\">:</span>    <span class=\"n\">location</span><span class=\"p\">,</span>\n        <span class=\"s\">\"temperature\"</span><span class=\"o\">:</span> <span class=\"s\">\"80\"</span><span class=\"p\">,</span>\n        <span class=\"s\">\"unit\"</span><span class=\"o\">:</span>        <span class=\"s\">\"fahrenheit\"</span><span class=\"p\">,</span>\n        <span class=\"s\">\"forecast\"</span><span class=\"o\">:</span>    <span class=\"p\">[]</span><span class=\"kt\">string</span><span class=\"p\">{</span><span class=\"s\">\"sunny\"</span><span class=\"p\">,</span> <span class=\"s\">\"windy\"</span><span class=\"p\">},</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">err</span> <span class=\"o\">:=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">Marshal</span><span class=\"p\">(</span><span class=\"n\">weatherInfo</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">err</span> <span class=\"o\">!=</span> <span class=\"no\">nil</span> <span class=\"p\">{</span>\n        <span class=\"k\">return</span> <span class=\"s\">\"\"</span><span class=\"p\">,</span> <span class=\"n\">err</span>\n    <span class=\"p\">}</span>\n    <span class=\"k\">return</span> <span class=\"kt\">string</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">),</span> <span class=\"no\">nil</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<p>The output should be something like:</p>\n\n<blockquote>\n<p>The current weather in New York City is mostly sunny, with a windy condition. The temperature is at 80°F.</p>\n</blockquote>\n\n<h2>\n  \n  \n  Going a step further\n</h2>\n\n<p>I happen to have a program that is perfect for demonstrating simple LLM integration using tools. The <a href=\"https://github.com/calvinmclean/walks-of-italy\" rel=\"noopener noreferrer\"><code>walks-of-italy</code></a> was originally created to watch for new tour availability from <a href=\"https://www.walksofitaly.com\" rel=\"noopener noreferrer\">Walks of Italy</a> tour company. I started with a grander vision for this program: a tool that could watch, search, and observe tour availability. After implementing the base feature of notifying on new availability, I decided it was good enough for my use-case.</p>\n\n<p>Now, with LLM tools, this program can be extended in any number of ways. Here are the tools it currently has:</p>\n\n<ul>\n<li>\n<code>getAllTours</code>: list the tour names and their UUIDs from the database</li>\n<li>\n<code>getTourDetails</code>: use the API to access the tour descriptions</li>\n<li>\n<code>getTourAvailability</code>: use the API to check availability, prices, and capacity at certain times</li>\n</ul>\n\n<p>With just a few tools, the LLM has these features:</p>\n\n<ul>\n<li>Simply query a date range with natural language\n\n<ul>\n<li>\"what is the availability of the Pristine Sistine tour next week?\"</li>\n</ul>\n\n\n</li>\n\n<li>Ask a more general question about multiple tours\n\n<ul>\n<li>\"what is the availability of vatican tours on July 5th?\"</li>\n</ul>\n\n\n</li>\n\n<li>Get travel recommendations\n\n<ul>\n<li>\"I am going to be in Rome on August 3rd and 4th. Which tours can I go on?\"</li>\n<li>\"If I can only do one tour in Rome, which should I do?\"</li>\n</ul>\n\n\n</li>\n\n</ul>\n\n<p>When asked \"what is the availability of the Pristine Sistine tour next week?\" the model responds:</p>\n\n<blockquote>\n<p>Here's an overview of the availability for the tours:</p>\n\n<ul>\n<li>\n<p><strong>June 20, 2025</strong>:</p>\n\n<ul>\n<li>There are limited spots available for the 7:15 AM and 7:45 AM tours.</li>\n<li>The 7:15 AM tour has 1 vacancy out of a capacity of 20.</li>\n<li>The 7:45 AM tour also has 1 vacancy out of a capacity of 48.</li>\n<li>The 6:45 AM tour is fully booked.</li>\n</ul>\n</li>\n<li>\n<p><strong>June 21, 2025</strong>:</p>\n\n<ul>\n<li>The 6:45 AM tour has 10 available spots out of 10 total.</li>\n<li>The 7:15 AM tour has 3 vacancies out of a capacity of 34.</li>\n<li>The 7:45 AM tour has 1 vacancy out of a capacity of 28.</li>\n</ul>\n</li>\n<li>\n<p><strong>Other dates</strong>:</p>\n\n<ul>\n<li>On June 19, 2025, the 7:45 AM tour is fully booked.</li>\n<li>On June 18, 2025, the 7:15 AM tour is fully booked, and the 7:45 AM tour has limited availability.</li>\n<li>On June 17, 2025, the 7:15 AM tour is fully booked, and the 7:45 AM tour has limited availability.</li>\n<li>On June 16, 2025, the 7:45 AM tour is fully booked.</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n\n<p>If you're looking for availability, the best options are on June 20 and June 21, with limited spots available for the morning tours. Let me know if you'd like help booking!</p>\n\n<p>These are just a few examples that I can think of. A huge benefit to this type of program is that its functionality isn't only limited by the features added by a developer. Instead, it's limited by the LLM and the tools that it can use. The user might come up with a usecase that works out of the box due to the program's flexibility. In this example, I justed wanted to check specific tours and dates for availability, but can now do a lot more.</p>\n\n<p>The effectiveness and accuracy of the responses here of course varies and is dependent on the model that is used. More complex questions that require more tool calls will generally decrease the accuracy of responses. When a lot of information is required, larger and more capable models are required.</p>\n\n<p>In this example, the functionality could be made even more flexible. Currently, it just is able to use tours that I manually add. If it has a new function to get tours from the Walks of Italy website, it could be even more dynamic (but less predictable).</p>\n\n<h2>\n  \n  \n  MCP\n</h2>\n\n<p>Model Context Protocol, or MCP, is the next evolution of tool calling. Instead of requiring a custom program to provide tools, it moves this to the server-side. The model is used with a generic client that supports the protocol and accesses functions provided by any number of external servers. If this previous example used MCP, Walks of Italy would provide an MCP server any model would be able to access it when used with an MCP client. It would eliminate almost all of the work done to implement <a href=\"https://github.com/calvinmclean/walks-of-italy\" rel=\"noopener noreferrer\">my <code>walks-of-italy</code> program</a>.</p>\n\n<h2>\n  \n  \n  Thoughts\n</h2>\n\n<p>Until recently, I primarily interacted with LLMs using ChatGPT or Gemini to answer questions, discuss ideas, and sometimes generate SQL queries or code. As AI Agents become more popular and integrated into all parts of our lives and jobs, it starts to seem like LLMs can do anything. It was refreshing to start from the barebones model interactions and really see how tool-calling works. In reality, LLMs are still just reading input and generating output. It's the code around them, built by software engineers, that enables them to actually <em>do</em> things.</p>\n\n<p>Building an application around an LLM and tools can be really beneficial. If the model has access to a set of tools with general functionality like querying APIs and DBs (with pre-defined SQL of course), the program's functionality can change and expand on-demand. This is especially useful for non-technical users. Instead of asking engineers to build new features for a specific usecase, they can just adjust their prompts and interactions with the LLM. In the previous example, the <code>walks-of-italy</code> program was originally designed to watch and alert for new tour availability or run specific date range queries with the CLI. The introduction of a few tools and an LLM drastically expanded the scope of the program and makes it more useful for non-technical users. Now that the LLM can query any date range and get descriptions about tours, you can:</p>\n\n<ul>\n<li>Get help deciding which tours to go based on real pricing, descriptions, and availability</li>\n<li>Ask about general availability next month for multiple tours</li>\n<li>Compare availability and prices for weekdays or weekends</li>\n</ul>\n\n<p>It is important to remember that the model can behave unpredictably and the tools should not provide unlimited access. For example, instead of providing a tool to execute any generated SQL, engineers should expose a few functions like \"createResource\" and \"updateResource\" with pre-defined queries.</p>\n\n<p>System prompts and tool definitions provide more structure and control over how an LLM operates. An engineer can build a relatively reliable and useful program with these techniques. However, as complexity of the system grows, the potential for the LLM to do unpredictable things also grows.</p>\n\n<p>Normally, code is very predictable. A set of functions exists and engineers define exactly when and how they are used. Now, programs become a collection of tools and the actual control is being relinquished to LLMs. Engineers always have to balance complexity, maintainability, and functionality. Using LLMs just makes this balance more delicate.</p>\n\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Implementing authorization in a Go API with AuthAction","url":"https://dev.to/authaction/implementing-authorization-in-a-go-api-with-authaction-3gg","date":1750013914,"author":"AuthAction Developer","guid":155785,"unread":true,"content":"<p><a href=\"https://www.authaction.com/\" rel=\"noopener noreferrer\">AuthAction</a> is a powerful authentication and authorization platform that offers a range of features, including support for single-page applications (SPA) and machine-to-machine (M2M) applications. It provides an easy-to-use interface for managing users, roles, and organizations, and supports OAuth2, social logins and passkey authentication. Best of all, AuthAction is scalable, allowing up to 1 Million monthly active users for free. Whether you're developing an app for a startup or a large enterprise, AuthAction provides a flexible and secure solution for your authentication needs.</p>\n\n<p>In this blog, we'll explore how to authorise Go APIs using AuthAction.</p>\n\n<h2>\n  \n  \n  Prerequisites\n</h2>\n\n<p>Before you begin, ensure you have:</p>\n\n<ol>\n<li>\n<strong>Go 1.21 or later</strong>: Download from <a href=\"https://golang.org/dl\" rel=\"noopener noreferrer\">golang.org</a>\n</li>\n<li>\n<strong>AuthAction Account</strong>: You'll need your AuthAction tenant domain and API identifier</li>\n</ol>\n\n<h2>\n  \n  \n  Configuration\n</h2>\n\n<h3>\n  \n  \n  1. Install Required Packages\n</h3>\n\n\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight shell\"><code>go get <span class=\"nt\">-u</span> github.com/golang-jwt/jwt/v5\ngo get <span class=\"nt\">-u</span> github.com/lestrrat-go/jwx/v2/jwk\ngo get <span class=\"nt\">-u</span> github.com/gin-gonic/gin\n</code></pre>\n\n</div>\n\n\n\n<h3>\n  \n  \n  2. Configure AuthAction Settings\n</h3>\n\n<p>Create a <code>.env</code> file in your project root:<br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight shell\"><code><span class=\"nv\">AUTHACTION_DOMAIN</span><span class=\"o\">=</span>your-authaction-tenant-domain\n<span class=\"nv\">AUTHACTION_AUDIENCE</span><span class=\"o\">=</span>your-authaction-api-identifier\n</code></pre>\n\n</div>\n\n\n\n<h3>\n  \n  \n  3. Implement JWT Middleware\n</h3>\n\n<p>Create a middleware file <code>middleware/auth.go</code>:<br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight go\"><code><span class=\"k\">type</span> <span class=\"n\">JWKSMiddleware</span> <span class=\"k\">struct</span> <span class=\"p\">{</span>\n    <span class=\"n\">JWKSUri</span>   <span class=\"kt\">string</span>\n    <span class=\"n\">Issuer</span>    <span class=\"kt\">string</span>\n    <span class=\"n\">Audience</span>  <span class=\"kt\">string</span>\n    <span class=\"n\">Cache</span>     <span class=\"o\">*</span><span class=\"n\">jwk</span><span class=\"o\">.</span><span class=\"n\">Cache</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">func</span> <span class=\"n\">NewJWKSMiddleware</span><span class=\"p\">(</span><span class=\"n\">jwksUri</span><span class=\"p\">,</span> <span class=\"n\">issuer</span><span class=\"p\">,</span> <span class=\"n\">audience</span> <span class=\"kt\">string</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">JWKSMiddleware</span><span class=\"p\">,</span> <span class=\"kt\">error</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"n\">cache</span> <span class=\"o\">:=</span> <span class=\"n\">jwk</span><span class=\"o\">.</span><span class=\"n\">NewCache</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">Background</span><span class=\"p\">())</span>\n    <span class=\"k\">return</span> <span class=\"o\">&amp;</span><span class=\"n\">JWKSMiddleware</span><span class=\"p\">{</span>\n        <span class=\"n\">JWKSUri</span><span class=\"o\">:</span>  <span class=\"n\">jwksUri</span><span class=\"p\">,</span>\n        <span class=\"n\">Issuer</span><span class=\"o\">:</span>   <span class=\"n\">issuer</span><span class=\"p\">,</span>\n        <span class=\"n\">Audience</span><span class=\"o\">:</span> <span class=\"n\">audience</span><span class=\"p\">,</span>\n        <span class=\"n\">Cache</span><span class=\"o\">:</span>    <span class=\"n\">cache</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span> <span class=\"no\">nil</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">func</span> <span class=\"p\">(</span><span class=\"n\">m</span> <span class=\"o\">*</span><span class=\"n\">JWKSMiddleware</span><span class=\"p\">)</span> <span class=\"n\">ValidateToken</span><span class=\"p\">()</span> <span class=\"n\">gin</span><span class=\"o\">.</span><span class=\"n\">HandlerFunc</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"k\">func</span><span class=\"p\">(</span><span class=\"n\">c</span> <span class=\"o\">*</span><span class=\"n\">gin</span><span class=\"o\">.</span><span class=\"n\">Context</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"c\">// Get token from Authorization header</span>\n        <span class=\"n\">tokenString</span> <span class=\"o\">:=</span> <span class=\"n\">strings</span><span class=\"o\">.</span><span class=\"n\">Split</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">GetHeader</span><span class=\"p\">(</span><span class=\"s\">\"Authorization\"</span><span class=\"p\">),</span> <span class=\"s\">\" \"</span><span class=\"p\">)[</span><span class=\"m\">1</span><span class=\"p\">]</span>\n\n        <span class=\"c\">// Fetch JWKS from AuthAction with caching</span>\n        <span class=\"n\">keySet</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">Cache</span><span class=\"o\">.</span><span class=\"n\">Get</span><span class=\"p\">(</span><span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">Background</span><span class=\"p\">(),</span> <span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">JWKSUri</span><span class=\"p\">)</span>\n\n        <span class=\"c\">// Parse and validate token</span>\n        <span class=\"n\">token</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">jwt</span><span class=\"o\">.</span><span class=\"n\">Parse</span><span class=\"p\">(</span><span class=\"n\">tokenString</span><span class=\"p\">,</span> <span class=\"k\">func</span><span class=\"p\">(</span><span class=\"n\">token</span> <span class=\"o\">*</span><span class=\"n\">jwt</span><span class=\"o\">.</span><span class=\"n\">Token</span><span class=\"p\">)</span> <span class=\"p\">(</span><span class=\"k\">interface</span><span class=\"p\">{},</span> <span class=\"kt\">error</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">kid</span> <span class=\"o\">:=</span> <span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">Header</span><span class=\"p\">[</span><span class=\"s\">\"kid\"</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"kt\">string</span><span class=\"p\">)</span>\n            <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">keySet</span><span class=\"o\">.</span><span class=\"n\">LookupKeyID</span><span class=\"p\">(</span><span class=\"n\">kid</span><span class=\"p\">)</span>\n\n            <span class=\"k\">var</span> <span class=\"n\">rawkey</span> <span class=\"k\">interface</span><span class=\"p\">{}</span>\n            <span class=\"n\">key</span><span class=\"o\">.</span><span class=\"n\">Raw</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">rawkey</span><span class=\"p\">)</span>\n            <span class=\"k\">return</span> <span class=\"n\">rawkey</span><span class=\"p\">,</span> <span class=\"no\">nil</span>\n        <span class=\"p\">})</span>\n\n        <span class=\"c\">// Validate claims</span>\n        <span class=\"k\">if</span> <span class=\"n\">claims</span><span class=\"p\">,</span> <span class=\"n\">ok</span> <span class=\"o\">:=</span> <span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">Claims</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"n\">jwt</span><span class=\"o\">.</span><span class=\"n\">MapClaims</span><span class=\"p\">);</span> <span class=\"n\">ok</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">Valid</span> <span class=\"p\">{</span>\n            <span class=\"k\">if</span> <span class=\"n\">aud</span><span class=\"p\">,</span> <span class=\"n\">ok</span> <span class=\"o\">:=</span> <span class=\"n\">claims</span><span class=\"p\">[</span><span class=\"s\">\"aud\"</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"p\">(</span><span class=\"kt\">string</span><span class=\"p\">);</span> <span class=\"n\">ok</span> <span class=\"o\">&amp;&amp;</span> <span class=\"n\">aud</span> <span class=\"o\">==</span> <span class=\"n\">m</span><span class=\"o\">.</span><span class=\"n\">Audience</span> <span class=\"p\">{</span>\n                <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">Set</span><span class=\"p\">(</span><span class=\"s\">\"claims\"</span><span class=\"p\">,</span> <span class=\"n\">claims</span><span class=\"p\">)</span>\n                <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">Next</span><span class=\"p\">()</span>\n                <span class=\"k\">return</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">JSON</span><span class=\"p\">(</span><span class=\"n\">http</span><span class=\"o\">.</span><span class=\"n\">StatusUnauthorized</span><span class=\"p\">,</span> <span class=\"n\">gin</span><span class=\"o\">.</span><span class=\"n\">H</span><span class=\"p\">{</span><span class=\"s\">\"error\"</span><span class=\"o\">:</span> <span class=\"s\">\"Invalid token\"</span><span class=\"p\">})</span>\n        <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">Abort</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<h2>\n  \n  \n  Usage\n</h2>\n\n<h3>\n  \n  \n  1. Create Your API\n</h3>\n\n<p>Create your main API file <code>main.go</code>:<br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight go\"><code><span class=\"k\">func</span> <span class=\"n\">main</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"c\">// Load environment variables</span>\n    <span class=\"n\">domain</span> <span class=\"o\">:=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">Getenv</span><span class=\"p\">(</span><span class=\"s\">\"AUTHACTION_DOMAIN\"</span><span class=\"p\">)</span>\n    <span class=\"n\">audience</span> <span class=\"o\">:=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">Getenv</span><span class=\"p\">(</span><span class=\"s\">\"AUTHACTION_AUDIENCE\"</span><span class=\"p\">)</span>\n\n    <span class=\"c\">// Construct JWKS URI and issuer</span>\n    <span class=\"n\">jwksUri</span> <span class=\"o\">:=</span> <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Sprintf</span><span class=\"p\">(</span><span class=\"s\">\"https://%s/.well-known/jwks.json\"</span><span class=\"p\">,</span> <span class=\"n\">domain</span><span class=\"p\">)</span>\n    <span class=\"n\">issuer</span> <span class=\"o\">:=</span> <span class=\"n\">fmt</span><span class=\"o\">.</span><span class=\"n\">Sprintf</span><span class=\"p\">(</span><span class=\"s\">\"https://%s/\"</span><span class=\"p\">,</span> <span class=\"n\">domain</span><span class=\"p\">)</span>\n\n    <span class=\"c\">// Initialize middleware</span>\n    <span class=\"n\">authMiddleware</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">middleware</span><span class=\"o\">.</span><span class=\"n\">NewJWKSMiddleware</span><span class=\"p\">(</span><span class=\"n\">jwksUri</span><span class=\"p\">,</span> <span class=\"n\">issuer</span><span class=\"p\">,</span> <span class=\"n\">audience</span><span class=\"p\">)</span>\n\n    <span class=\"n\">r</span> <span class=\"o\">:=</span> <span class=\"n\">gin</span><span class=\"o\">.</span><span class=\"n\">Default</span><span class=\"p\">()</span>\n\n    <span class=\"c\">// Public endpoint</span>\n    <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">GET</span><span class=\"p\">(</span><span class=\"s\">\"/health\"</span><span class=\"p\">,</span> <span class=\"k\">func</span><span class=\"p\">(</span><span class=\"n\">c</span> <span class=\"o\">*</span><span class=\"n\">gin</span><span class=\"o\">.</span><span class=\"n\">Context</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n        <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">JSON</span><span class=\"p\">(</span><span class=\"m\">200</span><span class=\"p\">,</span> <span class=\"n\">gin</span><span class=\"o\">.</span><span class=\"n\">H</span><span class=\"p\">{</span><span class=\"s\">\"status\"</span><span class=\"o\">:</span> <span class=\"s\">\"healthy\"</span><span class=\"p\">})</span>\n    <span class=\"p\">})</span>\n\n    <span class=\"c\">// Protected endpoint</span>\n    <span class=\"n\">protected</span> <span class=\"o\">:=</span> <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Group</span><span class=\"p\">(</span><span class=\"s\">\"/api\"</span><span class=\"p\">)</span>\n    <span class=\"n\">protected</span><span class=\"o\">.</span><span class=\"n\">Use</span><span class=\"p\">(</span><span class=\"n\">authMiddleware</span><span class=\"o\">.</span><span class=\"n\">ValidateToken</span><span class=\"p\">())</span>\n    <span class=\"p\">{</span>\n        <span class=\"n\">protected</span><span class=\"o\">.</span><span class=\"n\">GET</span><span class=\"p\">(</span><span class=\"s\">\"/protected\"</span><span class=\"p\">,</span> <span class=\"k\">func</span><span class=\"p\">(</span><span class=\"n\">c</span> <span class=\"o\">*</span><span class=\"n\">gin</span><span class=\"o\">.</span><span class=\"n\">Context</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">claims</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">:=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">Get</span><span class=\"p\">(</span><span class=\"s\">\"claims\"</span><span class=\"p\">)</span>\n            <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">JSON</span><span class=\"p\">(</span><span class=\"m\">200</span><span class=\"p\">,</span> <span class=\"n\">gin</span><span class=\"o\">.</span><span class=\"n\">H</span><span class=\"p\">{</span>\n                <span class=\"s\">\"message\"</span><span class=\"o\">:</span> <span class=\"s\">\"Protected endpoint\"</span><span class=\"p\">,</span>\n                <span class=\"s\">\"claims\"</span><span class=\"o\">:</span> <span class=\"n\">claims</span><span class=\"p\">,</span>\n            <span class=\"p\">})</span>\n        <span class=\"p\">})</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">Run</span><span class=\"p\">(</span><span class=\"s\">\":8080\"</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre>\n\n</div>\n\n\n\n<h3>\n  \n  \n  2. Testing the API\n</h3>\n\n<ol>\n<li>\n<strong>Obtain an Access Token</strong>:\n</li>\n</ol>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight shell\"><code>curl <span class=\"nt\">--request</span> POST <span class=\"se\">\\</span>\n<span class=\"nt\">--url</span> https://your-authaction-tenant-domain/oauth2/m2m/token <span class=\"se\">\\</span>\n<span class=\"nt\">--header</span> <span class=\"s1\">'content-type: application/json'</span> <span class=\"se\">\\</span>\n<span class=\"nt\">--data</span> <span class=\"s1\">'{\n  \"client_id\": \"your-authaction-m2m-app-clientid\",\n  \"client_secret\": \"your-authaction-m2m-app-client-secret\",\n  \"audience\": \"your-authaction-api-identifier\",\n  \"grant_type\": \"client_credentials\"\n}'</span>\n</code></pre>\n\n</div>\n\n\n\n<ol>\n<li>\n<strong>Call Protected Endpoints</strong>:\n</li>\n</ol>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight shell\"><code>curl <span class=\"nt\">--request</span> GET <span class=\"se\">\\</span>\n<span class=\"nt\">--url</span> http://localhost:8080/api/protected <span class=\"se\">\\</span>\n<span class=\"nt\">--header</span> <span class=\"s1\">'Authorization: Bearer YOUR_ACCESS_TOKEN'</span>\n</code></pre>\n\n</div>\n\n\n\n<h2>\n  \n  \n  Security Features\n</h2>\n\n<p>The implementation includes:</p>\n\n<ul>\n<li>JWT token validation using AuthAction's JWKS endpoint</li>\n<li>Automatic JWKS caching with periodic refresh</li>\n<li>RS256 algorithm for token signing</li>\n<li>Secure configuration management using environment variables</li>\n<li>HTTPS support in production</li>\n</ul>\n\n<h2>\n  \n  \n  Common Issues\n</h2>\n\n<h3>\n  \n  \n  Invalid Token Errors\n</h3>\n\n<ul>\n<li>Ensure your token is signed with RS256 algorithm</li>\n<li>Verify the token contains correct issuer and audience claims</li>\n<li>Check that environment variables are correctly set</li>\n</ul>\n\n<h3>\n  \n  \n  Public Key Fetching Errors\n</h3>\n\n<ul>\n<li>Verify your application can reach AuthAction's JWKS endpoint</li>\n<li>The JWKS URI should be: <code>https://your-authaction-tenant-domain/.well-known/jwks.json</code>\n</li>\n</ul>\n\n<h3>\n  \n  \n  Unauthorized Access\n</h3>\n\n<p>If requests to protected endpoints fail, check:</p>\n\n<ul>\n<li>The JWT token is included in the <code>Authorization</code> header</li>\n<li>The token is valid and not expired</li>\n<li>The token's audience matches your API identifier</li>\n<li>The token's issuer matches your AuthAction domain</li>\n</ul>\n\n<h2>\n  \n  \n  Conclusion\n</h2>\n\n<p>Integrating authorization into a Go API application using AuthAction is a straightforward process. This example helps streamline the setup, offering developers a robust foundation to build secure applications with minimal effort.</p>\n\n<p>If you run into any issues, double-check your configurations to ensure everything is set up correctly. Happy coding!</p>\n\n<p>Feel free to leave your thoughts and questions in the comments below!</p>\n\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Variadic Function in Go","url":"https://dev.to/jad_core/variadic-function-in-go-f9i","date":1750003981,"author":"Huseyn","guid":155721,"unread":true,"content":"<p><strong>What is a Variadic Function in Go?</strong><br>\nA variadic function is a function that <strong>accepts a variable number of arguments of the same type</strong>.</p>\n\n<p>This is useful when you don’t know how many values a caller might pass. Instead of defining a fixed number of parameters, you allow the caller to pass zero or more arguments.</p>\n\n<p><strong>Syntax</strong><br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>func myFunc(args ...int) {\n    // args is a slice of int\n}\n</code></pre>\n\n</div>\n\n\n\n<ul>\n<li>The ... before the type means the function accepts any number of int arguments, including none.</li>\n<li>Inside the function, args behaves like a slice ([]int).</li>\n</ul>\n\n<p><strong>Real-World Example: Sum of Prices</strong><br>\nImagine you’re summing prices of products in a cart:<br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>package main\n\nimport \"fmt\"\n\n// Variadic function to sum prices\nfunc SumPrices(prices ...float64) float64 {\n    total := 0.0\n    for _, price := range prices {\n        total += price\n    }\n    return total\n}\n\nfunc main() {\n    fmt.Println(SumPrices(10.99, 20.00))                  // 30.99\n    fmt.Println(SumPrices(5.99, 15.50, 9.99, 1.99))        // 33.47\n    fmt.Println(SumPrices())                              // 0.0\n}\n</code></pre>\n\n</div>\n\n\n\n<p><strong>Key Points</strong></p>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Explanation</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>...type</code></td>\n<td>Used only in the <strong>last parameter</strong> of the function.</td>\n</tr>\n<tr>\n<td>Internally</td>\n<td>Treated as a <strong>slice</strong> (e.g., <code>[]int</code>, <code>[]string</code>).</td>\n</tr>\n<tr>\n<td>Optional</td>\n<td>Can pass <strong>zero or more</strong> values.</td>\n</tr>\n<tr>\n<td>Expand slice</td>\n<td>Use <code>myFunc(mySlice...)</code> to <strong>expand a slice</strong> into arguments.</td>\n</tr>\n</tbody>\n</table></div>\n\n<p><strong>Gotchas</strong><br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>func printNames(names ...string) {\n    for _, name := range names {\n        fmt.Println(name)\n    }\n}\n\nfunc main() {\n    myNames := []string{\"Alice\", \"Bob\", \"Carol\"}\n\n    // You must use ... to expand a slice\n    printNames(myNames...) // ✅\n    // printNames(myNames) // ❌ compile error\n}\n</code></pre>\n\n</div>\n\n\n\n<p><strong>When to Use Variadic Functions</strong></p>\n\n<ul>\n<li>Calculations (sum, average)</li>\n<li>Logging utilities</li>\n<li>Formatting strings</li>\n<li>Joining or filtering collections</li>\n</ul>\n\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Anonymous functions, Factory functions, and Closures in Go","url":"https://dev.to/jad_core/anonymous-functions-factory-functions-and-closures-in-go-bjc","date":1750000853,"author":"Huseyn","guid":155687,"unread":true,"content":"<p><strong>🔧 Real-Life Scenario: Online Order Discount System</strong><br>\nYou are building a Go backend for an e-commerce platform. Different users (like guests, regulars, and VIPs) get different discounts on their orders. We want a flexible way to calculate the discount based on user type.</p>\n\n<p>Let’s incorporate:</p>\n\n<p><strong>Anonymous Function</strong> – A function without a name, used right away.</p>\n\n<p><strong>Factory Function</strong> – A function that returns another function based on input (creates logic on-the-fly).</p>\n\n<p><strong>Closure</strong> – When the returned function remembers variables from its surrounding scope.</p>\n\n<p><strong>GO CODE (With comments)</strong><br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight plaintext\"><code>package main\n\nimport \"fmt\"\n\n// Factory Function: Returns a discount function based on user type\nfunc DiscountFactory(userType string) func(total float64) float64 {\n    var baseDiscount float64\n\n    // Set base discount rate depending on user type\n    switch userType {\n    case \"guest\":\n        baseDiscount = 0.0\n    case \"regular\":\n        baseDiscount = 0.05\n    case \"vip\":\n        baseDiscount = 0.10\n    }\n\n    // Closure: This anonymous function captures baseDiscount\n    return func(total float64) float64 {\n        return total - (total * baseDiscount)\n    }\n}\n\nfunc main() {\n    // Create discount calculators\n    guestDiscount := DiscountFactory(\"guest\")\n    regularDiscount := DiscountFactory(\"regular\")\n    vipDiscount := DiscountFactory(\"vip\")\n\n    totalAmount := 1000.0\n\n    fmt.Println(\"Original Total:\", totalAmount)\n\n    // Using closures returned from factory function\n    fmt.Println(\"Guest Pays:\", guestDiscount(totalAmount))     // 1000.0\n    fmt.Println(\"Regular Pays:\", regularDiscount(totalAmount)) // 950.0\n    fmt.Println(\"VIP Pays:\", vipDiscount(totalAmount))         // 900.0\n\n    // Anonymous function used inline (e.g., flash sale)\n    flashSale := func(amount float64) float64 {\n        return amount * 0.8 // 20% off\n    }\n\n    fmt.Println(\"Flash Sale Price:\", flashSale(totalAmount))   // 800.0\n}\n\n</code></pre>\n\n</div>\n\n\n\n<p><strong><em>Breakdown of Concepts</em></strong></p>\n\n<div class=\"table-wrapper-paragraph\"><table>\n<thead>\n<tr>\n<th>Concept</th>\n<th>Explanation</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Anonymous Function</strong></td>\n<td>\n<code>flashSale := func(amount float64) float64 {...}</code> – This function has no name and is defined inline.</td>\n</tr>\n<tr>\n<td><strong>Factory Function</strong></td>\n<td>\n<code>DiscountFactory(userType string)</code> – Returns a custom discount function based on input.</td>\n</tr>\n<tr>\n<td><strong>Closure</strong></td>\n<td>Each returned function captures the <code>baseDiscount</code> variable from its creation environment – it <strong>remembers</strong> it even after <code>DiscountFactory</code> has finished running.</td>\n</tr>\n</tbody>\n</table></div>\n\n<p><strong>Why This Is Useful in Real Life</strong><br>\nThis kind of setup allows:</p>\n\n<ul>\n<li>💡 Dynamic behavior – Discounts are customized based on user types without duplicating code.</li>\n<li>🔐 Encapsulation – Each closure hides its internal logic (like baseDiscount).</li>\n<li>🔁 Reusability – The factory function can be reused for any user type or even expanded with more logic.</li>\n</ul>\n\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GoLang","url":"https://dev.to/aditya_tambi/golang-23i4","date":1750000639,"author":"Aditya tambi","guid":155686,"unread":true,"content":"<p>I have been coding React micro-apps in Typscript in my organisation. Occasionally taking on minor SQL or cloud work. <br>\nI want to dive into any backend technology and get my hands dirty there.</p>\n\n<p>I have spent God knows how many months trying to figure out what I should learn and build.</p>\n\n<p>Now I have decided, the answer is GoLang. I will start with <a href=\"https://gobyexample.com/\" rel=\"noopener noreferrer\">gobyexample</a>. <br>\nHave decided to put my daily progress here before shutting down my pc for the day.</p>\n\n<p>Kudos! To a fresh new start!!</p>\n\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Streaming PostgreSQL Backups with pgrwl: Now with Time & Count-Based Retention!","url":"https://dev.to/alzhi_f93e67fa45b972/streaming-postgresql-backups-with-pgrwl-now-with-time-count-based-retention-1m69","date":1749998476,"author":"alexey.zh","guid":155647,"unread":true,"content":"<p>A new release of <a href=\"https://github.com/hashmap-kz/pgrwl\" rel=\"noopener noreferrer\"><code>pgrwl</code></a> just shipped, a cloud-native WAL receiver and backup agent for PostgreSQL — and it comes with a new feature: <strong>streaming basebackups</strong> with <strong>automated retention</strong>.</p>\n\n<h2>\n  \n  \n  What's New\n</h2>\n\n<h3>\n  \n  \n  <code>feat(basebackup): time/count based retention</code>\n</h3>\n\n<p><code>pgrwl</code> can now:</p>\n\n<ul>\n<li>Run <strong>basebackups on a schedule</strong> (via built-in cron),</li>\n<li>\n<strong>Stream backups directly to remote storage</strong> (S3, SFTP, etc),</li>\n<li>And <strong>automatically enforce retention policies</strong>:\n\n<ul>\n<li>Retain the last <strong>N</strong> backups (e.g. <code>count=3</code>)</li>\n<li>Or retain all backups for a certain <strong>duration</strong> (e.g. <code>days=7</code>)</li>\n</ul>\n\n\n</li>\n\n</ul>\n\n<p>This makes it easier than ever to keep your PostgreSQL cluster safely backed up <strong>without relying on external scripts</strong> or schedulers.</p>\n\n\n\n\n<h2>\n  \n  \n  Streaming Basebackup?\n</h2>\n\n<p><code>pgrwl</code> performs a <em>streaming basebackup</em>:</p>\n\n<ul>\n<li>Uses replication protocol</li>\n<li>Streams backup with <strong>optional compression and encryption</strong>,</li>\n<li>Uploads to remote storage <strong>as the backup progresses</strong> — no need for temporary local copies!</li>\n</ul>\n\n<p>This design drastically reduces time-to-storage and fits perfectly into Kubernetes-native workflows.</p>\n\n\n\n\n<h2>\n  \n  \n  Retention Policies in Action\n</h2>\n\n<p>Here's a typical config for scheduled backups:<br>\n</p>\n\n<div class=\"highlight js-code-highlight\">\n<pre class=\"highlight yaml\"><code><span class=\"na\">backup</span><span class=\"pi\">:</span>\n  <span class=\"na\">schedule</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">0</span><span class=\"nv\"> </span><span class=\"s\">3</span><span class=\"nv\"> </span><span class=\"s\">*</span><span class=\"nv\"> </span><span class=\"s\">*</span><span class=\"nv\"> </span><span class=\"s\">*\"</span>  <span class=\"c1\"># every day at 3AM</span>\n  <span class=\"na\">retention</span><span class=\"pi\">:</span>\n    <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">count</span>          <span class=\"c1\"># count-based retention</span>\n    <span class=\"na\">count</span><span class=\"pi\">:</span> <span class=\"m\">3</span>             <span class=\"c1\"># keep last 3 backups</span>\n</code></pre>\n\n</div>\n\n\n\n<p>After each successful backup, <code>pgrwl</code> automatically:</p>\n\n<ul>\n<li>Lists available backups from storage,</li>\n<li>Sorts them by timestamp,</li>\n<li>Deletes old ones beyond the retention threshold — <strong>clean and simple</strong>.</li>\n</ul>\n\n\n\n\n<h2>\n  \n  \n  Example: Kubernetes StatefulSet\n</h2>\n\n<p>A typical setup consists of <strong>two StatefulSets</strong>:</p>\n\n<ol>\n<li>\n<strong>Receiver</strong> — continuously streams and archives WALs.</li>\n<li>\n<strong>Backup</strong> — schedules full basebackups and handles retention.</li>\n</ol>\n\n<blockquote>\n<p>On restore, the receiver pod can switch to <strong>serve mode</strong>, exposing archived WALs over HTTP to your PostgreSQL’s <code>restore_command</code>.</p>\n</blockquote>\n\n\n\n\n<h2>\n  \n  \n  Why This Matters\n</h2>\n\n<p>For teams running PostgreSQL in Kubernetes (or other containerized environments), backup tooling is often a headache:</p>\n\n<ul>\n<li>No clear story for WAL + basebackup orchestration,</li>\n<li>Manual scripts with little observability,</li>\n<li>Poor retention handling.</li>\n</ul>\n\n<p><code>pgrwl</code> aims to <strong>solve all of that</strong>, with:</p>\n\n<ul>\n<li>Streaming basebackups</li>\n<li>Streaming WAL receiver</li>\n<li>Pluggable storage</li>\n<li>Built-in compression/encryption</li>\n<li>Clean Kubernetes integration</li>\n<li>Minimal dependencies</li>\n</ul>\n\n\n\n\n<h2>\n  \n  \n  Try It Out\n</h2>\n\n<p>Get started here 👉 <a href=\"https://github.com/hashmap-kz/pgrwl\" rel=\"noopener noreferrer\">https://github.com/hashmap-kz/pgrwl</a></p>\n\n\n\n\n<p>If you have feedback, issues, or want to contribute, we’d love to hear from you! 🙌</p>\n\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bitcoin Recovery","url":"https://dev.to/michael_horwitz_3a9145be7/bitcoin-recovery-2j41","date":1749994535,"author":"Michael Horwitz","guid":155614,"unread":true,"content":"<p>Have you heard about Cryptocurrency, bitcoin, Ethereum or Dogecoin? It's the trending form of investment that can change your financial status for the better. This was how I got to meet with the wrong platform for crypto investment and was duped over $100,000 USDT. This was supposed to be an investment plan that will change my life and sustain me for years ahead. I was ripped off and didn't know where or how to go about it. While surfing through the internet, I came across a pop up talking about Darek Recoverys and how they help victims recover stolen funds. This was quite scary to me but I chose to see how it would turn out. After few days of investigation , I got back my lost funds in full. I am so happy as I have decided to let the world also know about their effective service. Their contact information is as follows: <a href=\"mailto:darekrecoverys@gmail.com\">darekrecoverys@gmail.com</a></p>\n\n","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GO/DEV","url":"https://dev.to/guest30/godev-1af2","date":1749950201,"author":"ThiagoAtauriTurini","guid":155297,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"DEV/ GOLANG*","url":"https://dev.to/guest30/devgolang-3i8m","date":1749950148,"author":"ThiagoAtauriTurini","guid":155296,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["go"]}