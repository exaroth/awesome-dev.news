{"id":"h5Hf6Rkh","title":"Python","displayTitle":"Python","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":62,"items":[{"title":"🚀 Boost Your Resume Instantly – For FREE!","url":"https://dev.to/buildandcodewithraman/boost-your-resume-instantly-for-free-a83","date":1739774926,"author":"Ramandeep Singh","guid":1635,"unread":true,"content":"<p>Tired of bland resumes? I built a  that transforms your resume with ! ✨🚀<p>\nNow no need to pay any talent sites promising jobs in return of enhanced resumes.</p></p><p>✅ Upload your resume 📂 bullet points 🔥<p>\n✅ Download the improved version as a </p> 📄  </p><p>Built with , this tool ensures your resume stands out! No signups, no hassle – just instant upgrades.  </p><p>Give your resume the AI touch! 🚀💼 Let me know what you think! 👇</p>","contentLength":429,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RandomSolarize in PyTorch","url":"https://dev.to/hyperkai/randomsolarize-in-pytorch-5a4o","date":1739773690,"author":"Super Kai (Kazuya Ito)","guid":1634,"unread":true,"content":"<p><a href=\"https://pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomSolarize.html\" rel=\"noopener noreferrer\">RandomSolarize()</a> can randomly solarize an image with a given probability as shown below:</p><ul><li>The 1st argument for initialization is (Required-Type: or ). *All pixels equal or above this value are inverted.</li><li>The 2nd argument for initialization is (Optional-Default:-Type: or ):\n*Memos:\n\n<ul><li>It's the probability of whether an image is solarized or not.</li></ul></li><li>The 1st argument is (Required-Type: or ()):\n*Memos:\n\n<ul><li>A tensor must be 2D or 3D.</li></ul></li></ul><div><pre><code></code></pre></div>","contentLength":419,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BrushinBella: Crafting a Digital Experience to Make Parents’ Lives Easier","url":"https://dev.to/maronzalez/brushinbella-crafting-a-digital-experience-to-make-parents-lives-easier-ab8","date":1739770827,"author":"Griffin Cole","guid":1618,"unread":true,"content":"<p>In today’s fast‑paced digital landscape, a brand’s online presence is not just a storefront—it’s an experience that speaks to its audience. BrushinBella, a company dedicated to providing innovative and thoughtfully designed baby and feeding products, recognized that their website needed to embody the values of care, creativity, and reliability. The goal was to create an engaging, easy‑to‑navigate e‑commerce platform that not only showcased their products but also helped parents seamlessly integrate these solutions into their busy lives.</p><p>This article recounts the comprehensive journey behind the creation of the <a href=\"https://www.brushinbella.com/\" rel=\"noopener noreferrer\">Brush in Bella</a> website, from the initial planning and design phases to the intricate development work that involved custom integrations using C++, Java, and Python. We will explore the challenges encountered along the way, the solutions that were implemented, and share expert insights on current trends and best practices in web development.</p><ol><li>The Vision and Planning Phase\n1.1. Defining the Brand and Project Scope\nBefore any code was written or designs drafted, the BrushinBella team—comprising marketing experts, product designers, UX specialists, and software engineers—came together to define the project’s vision. The core objective was clear: to create a digital experience that makes parents’ everyday life easier by offering a curated selection of products, valuable parenting content, and a user‑friendly interface.</li></ol><p>Key objectives defined during the planning phase included:</p><p>Brand Consistency: The website needed to mirror the brand’s values of quality, trust, and innovation.\nUser Experience: Given the target audience of busy parents, simplicity and intuitive navigation were paramount.<p>\nResponsive Design: With an increasing number of users accessing websites on mobile devices, the site had to offer a seamless experience across desktops, tablets, and smartphones.</p>\nCustom Integrations: Although the e‑commerce platform was built on a robust platform (Shopify was chosen for its reliability and scalability), the team identified specific areas—such as performance‑critical image processing, advanced inventory analytics, and bespoke order processing—where custom functionality was needed. This is where languages like C++, Java, and Python played a crucial role.<p>\nScalability and Performance: The system needed to handle fluctuating traffic levels and ensure quick load times, a challenge that required both architectural planning and performance‑oriented coding practices.</p>\nSecurity and Compliance: With sensitive customer data at stake, ensuring top‑notch security from the very start was non‑negotiable.<p>\n1.2. Assembling the Cross‑Functional Team</p>\nTo tackle this multifaceted project, BrushinBella assembled a cross‑functional team. Each team member brought unique expertise:</p><p>Project Managers and Business Analysts: To capture requirements, define deliverables, and ensure alignment with business goals.\nUX/UI Designers: Charged with creating an aesthetically pleasing and intuitive design that would resonate with the target audience.<p>\nFront‑End Developers: Specialists in HTML, CSS, and JavaScript who would turn design mockups into interactive, responsive web pages.</p>\nBack‑End Developers: Experts who would build custom modules, integrate third‑party APIs, and ensure that the site’s server‑side logic was robust and secure.<p>\nDevOps and QA Engineers: Responsible for establishing CI/CD pipelines, rigorous testing protocols, and ensuring smooth deployment and scaling.</p>\n1.3. Technology Selection and Architecture Decisions<p>\nDuring planning, the team conducted a thorough analysis of available technologies. Although the core e‑commerce solution was deployed on Shopify for its proven reliability and ease of use, certain functionalities required custom development. This resulted in a hybrid architecture:</p></p><p>Shopify as the Primary Platform: Managing the storefront, shopping cart, product catalog, and checkout process.\nCustom Back‑End Services: Developed in Java and Python, these services handled complex business logic, integration with third‑party systems (such as ERP and CRM platforms), and data analytics.<p>\nPerformance‑Critical Modules in C++: For tasks such as real‑time image processing (for product images and dynamic visual elements) and computationally intensive operations, C++ was chosen to ensure maximum speed and efficiency.</p>\nAPIs and Microservices: A RESTful API layer was established to enable seamless communication between Shopify and the custom modules. This approach allowed the system to scale horizontally and adopt a microservices architecture, which is increasingly considered best practice in modern web development.</p><ol><li>The Design Phase: From Concept to Wireframe\n2.1. User-Centric Design Philosophy\nA key part of BrushinBella’s vision was to make the website accessible not only to tech‑savvy users but also to non‑experts—busy parents who need a simple, straightforward interface. The UX/UI design phase was driven by several guiding principles:</li></ol><p>Simplicity: The design was stripped of any unnecessary complexity. Clear call‑to‑action buttons, uncluttered layouts, and intuitive navigation were prioritized.\nVisual Appeal: The website needed to evoke warmth and trust. Soft color palettes, playful yet professional typography, and high‑quality images of products and happy families helped achieve this.<p>\nResponsiveness: Mobile-first design principles were followed. Prototypes were tested on multiple devices and screen sizes to ensure consistency.</p>\nAccessibility: The design adhered to accessibility guidelines, ensuring that the website was usable by people with disabilities. This included proper contrast ratios, keyboard‑navigable menus, and alternative text for images.<p>\n2.2. Wireframing and Prototyping</p>\nUsing industry‑standard tools like Sketch and Figma, the design team created detailed wireframes and prototypes. These early models allowed stakeholders to visualize the website’s structure, layout, and user flow. Key features that were highlighted included:</p><p>Homepage: Featuring a dynamic banner that communicated the brand’s message (“Making Parents’ Everyday Life Easier!”) and a streamlined product navigation menu.\nProduct Pages: Each product page was designed to provide detailed images, descriptions, customer reviews, and easy‑to‑find purchasing options.<p>\nBlog and Content Sections: Recognizing that educational content is a valuable asset, the design included a blog section with articles, parenting tips, and video content.</p>\nCheckout Flow: A simplified, secure checkout process was paramount. Wireframes detailed the progression from shopping cart to payment gateway, with minimal friction.<p>\n2.3. Design Iterations and Stakeholder Feedback</p>\nThe iterative nature of design meant that prototypes were continuously refined based on stakeholder and user feedback. Early user testing sessions were conducted with focus groups of parents, ensuring that the designs were meeting real needs. Feedback led to several important adjustments:</p><p>Simplified Navigation: Initial designs with complex menus were streamlined to a single‑level navigation bar.\nEnhanced Product Imagery: High‑resolution images and a “zoom” feature were incorporated to allow parents to inspect product details closely.<p>\nClearer Calls-to‑Action: Buttons were redesigned for better visibility and prominence.</p>\nContent Accessibility: The blog section was reorganized to make content categories and search features more intuitive.</p><ol><li>The Development Phase: Building the Backbone\n3.1. Integrating Shopify with Custom Services\nOnce the design was finalized, the development phase kicked off. The first step was to integrate the robust capabilities of Shopify with the custom-built services developed in-house. Shopify managed the storefront and basic e‑commerce functionalities. However, several requirements demanded bespoke solutions:</li></ol><p>Custom Order Processing: While Shopify provided standard order management, BrushinBella needed an advanced system to integrate real‑time inventory data, promotional logic, and customized gift‑wrapping options. For this, the team built a microservice using Java.\nData Analytics and Reporting: In order to understand customer behavior and optimize the sales process, Python‑based analytics tools were developed. These tools processed data from Shopify’s API and generated actionable insights.<p>\nImage Processing and Dynamic Visuals: To ensure that product images were optimized for speed and quality, the team implemented a performance‑critical module in C++. This module handled tasks such as real‑time image resizing, format conversion, and dynamic compression.</p>\n3.2. The Role of C++: High‑Performance Modules<p>\nAlthough C++ is not traditionally associated with web development, its use in BrushinBella’s project was pivotal for performance‑critical tasks. Key functions implemented in C++ included:</p></p><p>Image Optimization Engine: C++ was used to build an engine that automatically resized and optimized images for various devices and screen resolutions. The engine was integrated as a microservice that communicated with Shopify through RESTful APIs.\nReal‑Time Data Processing: Certain operations, such as processing and rendering high‑resolution graphics for product galleries, were computationally intensive. C++’s efficiency ensured that these tasks did not slow down the user experience.<p>\nCustom Plugins: Some interactive features, such as a dynamic “gift‑wrapping” calculator that adjusted options based on user input, were built in C++ to ensure rapid response times and minimize latency.</p>\nUsing C++ required careful management of memory and thread safety. The development team leveraged modern C++ standards (C++17/20) and robust libraries such as Boost and OpenCV for image processing. This combination not only achieved the necessary performance gains but also ensured that the codebase was maintainable and scalable.</p><p>3.3. Java: The Enterprise Workhorse\nJava was chosen for its reliability, scalability, and strong ecosystem—qualities that made it ideal for handling core business logic and integrations. Within the BrushinBella project, Java served several key roles:</p><p>Business Logic and Order Management: The custom order processing system was developed in Java. This system interfaced with Shopify’s API to synchronize order data and applied complex business rules for promotions, discounts, and gift‑wrapping options.\nAPI Gateway: Java was also used to build a RESTful API gateway that served as the communication hub between Shopify and the custom microservices. The gateway ensured secure and efficient data exchange, handling tasks like authentication, rate‑limiting, and error logging.<p>\nIntegration with Legacy Systems: Many enterprise systems—such as ERP and CRM platforms—are built on or integrate well with Java. By choosing Java for these integrations, BrushinBella ensured that their website could interface smoothly with back‑office systems, enabling real‑time inventory management and customer data synchronization.</p>\nRobust Error Handling and Monitoring: Java’s mature ecosystem provided access to powerful tools for logging (using frameworks such as Log4j) and performance monitoring. This allowed the team to identify and resolve issues quickly, ensuring minimal downtime.<p>\nThe Java development team adopted best practices such as writing modular, test‑driven code and using containerization (with Docker) for deployment. This not only improved the reliability of the application but also made scaling the service more straightforward.</p></p><p>3.4. Python: Rapid Prototyping and Data Analytics\nPython’s reputation for ease of use and rapid development made it the language of choice for a range of supporting services:</p><p>Data Analytics: Python was used extensively for developing analytical tools that processed customer behavior data, order history, and product performance metrics. Libraries such as Pandas, NumPy, and Matplotlib were leveraged to generate detailed reports that informed marketing strategies and inventory decisions.\nAutomation Scripts: Routine tasks such as data backups, report generation, and system health checks were automated using Python scripts. This helped reduce manual intervention and allowed the team to focus on higher‑value activities.<p>\nIntegration and Testing: Python’s flexibility also made it an ideal candidate for writing integration tests. Automated testing frameworks like pytest ensured that the interactions between Shopify, the Java API gateway, and the C++ image optimization engine were reliable and robust.</p>\nMicroservices Development: In some cases, Python microservices were deployed to handle tasks that required rapid iteration and experimentation. For example, the team developed a prototype recommendation engine that used machine learning algorithms (with scikit‑learn) to suggest complementary products to customers based on their browsing history.<p>\nBy combining Python’s rapid prototyping capabilities with the stability of Java and the performance of C++, BrushinBella was able to build a hybrid system that leveraged the strengths of each language.</p></p><p>3.5. Adopting a Microservices Architecture\nOne of the most critical decisions during development was to adopt a microservices architecture. Instead of building a monolithic application, the system was divided into discrete services that communicated via RESTful APIs. This offered several benefits:</p><p>Scalability: Each service could be scaled independently based on demand. For example, the image processing engine in C++ could be scaled up during high‑traffic periods without affecting the rest of the system.\nResilience: Failures in one microservice did not bring down the entire website. Robust error‑handling and fallback mechanisms ensured that the website remained operational even if one component experienced issues.<p>\nFlexibility: The architecture allowed the team to update or replace individual services without redeploying the entire application. This was particularly beneficial when iterating on features such as the recommendation engine or order processing logic.</p>\nTechnology Diversity: By decoupling services, the team could choose the most appropriate language or framework for each task without forcing a one‑size‑fits‑all solution. This technological diversity, while challenging to manage, ultimately resulted in a more robust and efficient system.</p><ol><li>Testing, Deployment, and Optimization\n4.1. Rigorous Testing Strategies\nQuality assurance was embedded in every stage of development. The BrushinBella team implemented a multi‑layered testing strategy to ensure that each component—from the front‑end user interface to the backend microservices—functioned as expected:</li></ol><p>Unit Testing: Each module, whether written in Java, Python, or C++, underwent rigorous unit testing. For Java, JUnit was employed; Python modules were tested with pytest; and C++ components were validated using Google Test.\nIntegration Testing: Automated integration tests were established to verify the seamless communication between Shopify, the Java API gateway, the Python analytics services, and the C++ performance modules.<p>\nEnd‑to‑End Testing: Tools such as Selenium and Cypress were used to simulate real‑user interactions, ensuring that the entire system worked together harmoniously.</p>\nPerformance Testing: Given the emphasis on speed and scalability, performance testing was a critical focus. Load testing simulated high‑traffic scenarios to validate that the system could handle peak loads without significant degradation in response times.<p>\nSecurity Audits: Comprehensive security testing was conducted to safeguard against common vulnerabilities such as SQL injection, cross‑site scripting (XSS), and cross‑site request forgery (CSRF). Regular code audits and penetration testing further ensured that customer data remained protected.</p>\n4.2. Continuous Integration and Deployment (CI/CD)<p>\nTo streamline the development process and ensure rapid delivery of updates, the team set up a robust CI/CD pipeline. Key components of the pipeline included:</p></p><p>Automated Builds: Every code commit triggered an automated build process that compiled the Java and C++ modules and ran the Python scripts. This ensured that errors were caught early.\nAutomated Testing: The CI system executed the full suite of tests for each build, including unit, integration, and end‑to‑end tests. Only builds that passed all tests were promoted to staging.<p>\nContainerization: Using Docker, each microservice was containerized. This ensured consistency across development, testing, and production environments and simplified the scaling process.</p>\nOrchestration: Kubernetes was employed to manage the containerized services, enabling automatic scaling, load balancing, and self‑healing capabilities.<p>\nMonitoring and Logging: Post‑deployment, comprehensive monitoring tools (such as Prometheus and Grafana) were used to track system performance, while logging frameworks (e.g., Logstash and ELK stack) helped in quickly diagnosing and resolving issues.</p>\n4.3. Performance Optimization<p>\nOptimization was an ongoing effort throughout development. Key performance enhancements included:</p></p><p>Caching Strategies: To reduce load times and database queries, caching mechanisms were implemented. This included front‑end caching using service workers for static assets and back‑end caching with Redis for frequently accessed data.\nEfficient API Design: The RESTful APIs were optimized for speed, ensuring that data was transmitted in lightweight JSON formats with minimal overhead.<p>\nCode Profiling and Optimization: Regular profiling sessions identified bottlenecks in the code. For instance, the C++ image processing engine was fine‑tuned to minimize latency, and the Java microservices were optimized to handle high volumes of concurrent requests.</p>\nResponsive and Adaptive Design: The front‑end was optimized for mobile devices by adopting a mobile‑first design philosophy, ensuring fast load times even on slower networks.<p>\nDatabase Optimization: Indexing, query optimization, and efficient data structuring in both relational and NoSQL databases helped maintain rapid data retrieval and update speeds.</p></p><ol><li>Overcoming Challenges and Implementing Solutions\nNo major web development project is without its hurdles. The creation of the BrushinBella website presented a variety of challenges, each of which was met with innovative solutions.</li></ol><p>5.1. Integration Complexity\nChallenge:<p>\nIntegrating a Shopify‑based e‑commerce platform with custom microservices written in Java, Python, and C++ proved complex. Each system had its own data formats, security protocols, and performance characteristics.</p></p><p>Solution:\nThe team implemented a robust API gateway in Java to serve as the central communication hub. This gateway standardized data formats (using JSON), handled authentication and authorization, and ensured that all services communicated seamlessly. Extensive use of RESTful API design principles and well‑documented endpoints minimized integration friction.</p><p>5.2. Performance Bottlenecks\nChallenge:<p>\nCertain operations—especially image processing and real‑time analytics—posed performance challenges, risking slow response times that could frustrate users.</p></p><p>Solution:\nCritical performance‑intensive tasks were offloaded to specialized microservices developed in C++. These modules were optimized using modern C++ standards, multithreading, and libraries like OpenCV to ensure that image processing was done swiftly. Additionally, Python’s role in handling analytics was enhanced by leveraging efficient data processing libraries and asynchronous programming techniques to reduce latency.</p><p>5.3. Maintaining a Consistent User Experience\nChallenge:<p>\nEnsuring a seamless, high‑quality user experience across multiple devices and browsers is always challenging—especially when integrating third‑party services and custom code.</p></p><p>Solution:\nThe design team adopted a mobile‑first approach and followed responsive design principles to ensure that the website adapted gracefully to different screen sizes. Rigorous cross‑browser testing, combined with adaptive UI frameworks, ensured consistency. Accessibility guidelines were also adhered to, making the site usable by a diverse audience, including those with disabilities.</p><p>5.4. Ensuring Security and Data Integrity\nChallenge:<p>\nWith customer data and payment information at stake, any security lapse could have dire consequences. The heterogeneous nature of the system, with multiple programming languages and platforms interacting, introduced several potential vulnerabilities.</p></p><p>Solution:\nSecurity was integrated from day one. The team implemented robust authentication mechanisms at the API gateway level and encrypted all sensitive data. Regular security audits, automated vulnerability scans, and adherence to best practices—such as input validation, sanitization, and the use of secure coding frameworks—helped safeguard the system. Additionally, deploying a web application firewall (WAF) and implementing SSL/TLS across all endpoints further ensured data integrity.</p><p>5.5. Managing a Diverse Technology Stack\nChallenge:<p>\nCombining multiple programming languages and frameworks increases the complexity of the codebase and the development process. Ensuring that team members could collaborate effectively across different languages was a significant challenge.</p></p><p>Solution:\nThe project adopted a microservices architecture, which naturally decoupled the different language‑specific modules. Clear documentation, code conventions, and regular cross‑team meetings ensured that everyone was on the same page. The use of containerization (with Docker) and orchestration (with Kubernetes) allowed developers to work on isolated services without interference. In addition, investing in integrated development environments (IDEs) and code review tools helped maintain code quality and consistency across the diverse stack.</p><ol><li>Expert Insights on Web Development Trends and Best Practices\nAs BrushinBella’s website evolved from concept to a fully‑functional, high‑performance digital platform, the team kept a close eye on emerging trends and industry best practices. Here are some expert insights gleaned during the project:</li></ol><p>6.1. Embracing Microservices and Containerization\nModern web development is increasingly moving away from monolithic architectures toward microservices. This approach provides several advantages:</p><p>Scalability: Each service can be scaled independently to meet demand.\nResilience: Failures in one service do not affect the entire system.<p>\nFlexibility: Developers can choose the best technology for each service without being locked into a single framework or language.</p>\nContainerization tools like Docker and orchestration platforms like Kubernetes have become essential. They enable rapid deployment, efficient resource management, and simplified scaling. For BrushinBella, this meant that the custom C++, Java, and Python services could be managed and updated independently, leading to a more resilient and adaptable platform.</p><p>6.2. The Role of Hybrid Technology Stacks\nWhile many modern websites rely heavily on JavaScript frameworks for the front‑end (such as React or Vue), integrating a hybrid technology stack can yield significant benefits. Each language and framework brings its own strengths:</p><p>C++ for Performance‑Critical Tasks: In performance‑sensitive areas such as image processing, the efficiency of C++ is unmatched.\nJava for Robust Enterprise‑Grade Logic: Java’s strong typing, mature ecosystem, and scalability make it ideal for handling complex business rules and integrations.<p>\nPython for Rapid Development and Data Analysis: Python’s ease of use and powerful libraries allow teams to quickly prototype and deploy data‑driven features.</p>\nThis multi‑language approach is becoming more common as companies seek to optimize for both performance and development speed. It is essential, however, to manage this diversity with clear interfaces, robust API designs, and comprehensive documentation.</p><p>6.3. User Experience and Accessibility as Top Priorities\nNo matter how powerful the backend or how sophisticated the custom integrations, the success of a website ultimately depends on the user experience. Best practices dictate that designers and developers should focus on:</p><p>Responsive Design: Ensuring that the website looks and functions well on all devices.\nAccessibility: Building websites that are usable by everyone, including those with disabilities.<p>\nIntuitive Navigation: Simplifying the user journey from landing on the page to completing a transaction.</p>\nVisual Appeal: Using high‑quality images, consistent branding, and engaging interactive elements to create a memorable user experience.<p>\nFor BrushinBella, rigorous user testing and iterative design refinements ensured that the website not only met functional requirements but also delighted its target audience.</p></p><p>6.4. Security in a Connected World\nSecurity remains one of the most critical aspects of web development. With increasing data breaches and cyberattacks, best practices include:</p><p>Encryption of Data: Both in transit (using SSL/TLS) and at rest.\nRegular Security Audits: Automated vulnerability scanning and penetration testing to identify and mitigate risks.<p>\nRobust Authentication: Using multi‑factor authentication (MFA) and secure API gateways.</p>\nInput Validation and Sanitization: To prevent common attacks such as SQL injection and cross‑site scripting (XSS).<p>\nImplementing these security measures is not a one‑time task but an ongoing process that requires constant vigilance.</p></p><p>6.5. The Future: Serverless, AI, and Progressive Web Apps\nLooking ahead, several trends are shaping the future of web development:</p><p>Serverless Architectures: Platforms such as AWS Lambda, Google Cloud Functions, and Azure Functions are enabling developers to run code without managing servers. This can reduce costs and simplify deployment for certain types of applications.\nArtificial Intelligence and Machine Learning: Integrating AI into web applications is becoming increasingly common. Whether for personalized recommendations, chatbots, or automated analytics, AI can dramatically enhance the user experience.<p>\nProgressive Web Apps (PWAs): PWAs combine the best features of web and mobile applications, offering offline functionality, push notifications, and fast load times. They represent the future of delivering seamless, app‑like experiences through the browser.</p>\nFor BrushinBella, these trends offer opportunities for future enhancements. For example, a serverless recommendation engine or AI‑driven customer support chatbot could further enrich the user experience.</p><ol><li>Reflections and Lessons Learned\n7.1. Collaboration Is Key\nOne of the most important lessons from the BrushinBella project was the power of cross‑functional collaboration. Bringing together designers, developers, business analysts, and marketing experts enabled the team to view the project from multiple perspectives. This collaborative approach ensured that the final product was not only technically sound but also aligned with the brand’s vision and customer needs.</li></ol><p>7.2. Flexibility in Technology Choices\nAdopting a hybrid technology stack may seem daunting at first, but it can yield enormous benefits when managed properly. By leveraging the strengths of C++, Java, and Python in different parts of the system, the team was able to optimize for performance, scalability, and rapid development. This flexibility allowed BrushinBella to build a robust platform that could evolve with changing requirements.</p><p>7.3. Iteration and Continuous Improvement\nThe project was not built in a single, linear pass. Instead, it was an iterative process where feedback was continuously gathered and incorporated. From early wireframes to final deployment, each iteration brought improvements and refinements. The use of CI/CD pipelines and automated testing ensured that each update maintained the high standards of quality required for a live e‑commerce site.</p><p>7.4. Balancing Innovation and Practicality\nWhile it was tempting to incorporate cutting‑edge technologies and ambitious features, the team also had to remain practical. Decisions were driven by both innovative ideas and real‑world constraints such as budget, timelines, and technical feasibility. This balance ensured that the website was not only modern and attractive but also reliable and maintainable over the long term.</p><ol><li>Conclusion: A Modern Web Experience for Today’s Parents\nThe creation of the BrushinBella website is a testament to what can be achieved when visionary design meets technical excellence. By thoughtfully planning each phase, embracing a hybrid development strategy, and leveraging the unique strengths of C++, Java, and Python, the team built a website that not only drives sales but also resonates with its audience.</li></ol><p>Holistic Planning: Successful projects begin with a clear vision and a well‑defined scope. Every stakeholder’s input is valuable in shaping a product that meets both business and user needs.\nUser‑Centered Design: Prioritizing the user experience—through responsive design, intuitive navigation, and accessibility—ensures that the website remains relevant and engaging.<p>\nTechnological Synergy: Using a blend of languages and frameworks allows teams to optimize different aspects of the application. C++ provided high‑performance modules, Java ensured robust enterprise‑grade processing, and Python accelerated data analytics and automation.</p>\nResilient Architecture: Adopting microservices and containerization enabled the system to scale, adapt, and remain resilient in the face of increasing demand.<p>\nOngoing Evolution: The journey does not end at launch. Continuous testing, monitoring, and optimization are crucial to keeping a website secure, fast, and responsive to changing user expectations.</p>\nAs BrushinBella continues to grow and innovate, the lessons learned from this project will serve as a roadmap for future enhancements. With a focus on emerging trends such as serverless architectures, AI integrations, and progressive web apps, the company is well‑positioned to adapt to the evolving digital landscape and maintain its commitment to making parents’ everyday life easier.</p><p>In a world where the digital experience often makes or breaks a brand, BrushinBella’s website stands as an exemplar of what thoughtful planning, creative design, and technical excellence can achieve together. Whether you’re an expert in web development or a newcomer trying to understand the complexities behind a modern e‑commerce platform, the BrushinBella story offers valuable insights into building a system that is both powerful and personable.</p><p>Expert Perspectives and Future Outlook\nIndustry experts agree that the integration of multiple programming paradigms is the future of web development. Leaders in the field emphasize the importance of:</p><p>Adopting Modular Architectures: Breaking down applications into microservices not only improves scalability but also enhances maintainability.\nInvesting in Performance Optimization: As user expectations continue to rise, ensuring fast load times and seamless interactions will remain a top priority.<p>\nFostering Interdisciplinary Collaboration: The most innovative projects arise when cross‑functional teams work together, blending design, technology, and business acumen.</p>\nEmbracing Continuous Learning: With technologies evolving at a rapid pace, staying updated with the latest tools, frameworks, and best practices is essential for success.<p>\nLooking forward, trends such as the integration of AI in personalization, the adoption of serverless computing to reduce operational overhead, and the rise of progressive web apps are expected to shape the future of web development. BrushinBella is already exploring these avenues, planning to integrate AI‑driven customer insights and further optimize the platform using serverless components.</p></p><p>Final Thoughts\nThe journey of building the BrushinBella website highlights the dynamic and ever‑evolving nature of web development. By combining the proven capabilities of established platforms like Shopify with custom‑developed microservices in C++, Java, and Python, the team created a system that is greater than the sum of its parts. This approach not only met immediate business needs but also laid a robust foundation for future growth and innovation.</p><p>For developers and business leaders alike, the BrushinBella project is a compelling case study in the effective melding of design, technology, and user‑centric strategy. It demonstrates that with careful planning, strategic technology selection, and relentless focus on the user experience, it is possible to create a digital platform that truly makes a difference.</p><p>Whether you are planning your next web development project or simply interested in learning how modern e‑commerce platforms are built, the BrushinBella story offers a wealth of insights. As technology continues to evolve, so too will the tools and methods used to create these digital experiences. The key is to remain agile, to embrace change, and to always put the user first.</p><p>In summary, the BrushinBella website is more than just an online store—it is an embodiment of a brand’s promise to simplify and enrich the lives of parents. It stands as a reminder that at the heart of every great digital experience is a commitment to quality, innovation, and user empowerment.</p>","contentLength":33591,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Complete Guide to Virtual Environments (Virtualenv) in Python","url":"https://dev.to/mrnik/complete-guide-to-virtual-environments-virtualenv-in-python-3jn1","date":1739757746,"author":"Mahdi Ahmadi","guid":871,"unread":true,"content":"<h2>\n  \n  \n  1. What is a Virtual Environment in Python?\n</h2><p>When developing multiple projects with Python, each project may require different verzsions of libraries. This is where Virtual Environment (Virtualenv) comes to the rescue!</p><blockquote><p>A virtual environment is an isolated space for installing libraries and packages for a specific project without affecting your main system.</p></blockquote><h2>\n  \n  \n  2. Why Should You Use Virtualenv?\n</h2><ul><li><p>Avoid version conflicts: If different projects require different versions of the same library, conflicts may arise without a virtual environment.</p></li><li><p>Project isolation: Each project has its own set of dependencies, ensuring stability.</p></li><li><p>Portability: You can easily recreate the project environment on another system using a requirements.txt file.</p></li><li><p>Increased security: Installing packages in an isolated environment prevents unintended changes to system files.</p></li></ul><h2>\n  \n  \n  3. Installing and Using Virtualenv\n</h2><ul><li>Installing Virtualenv on Windows, Linux, and macOS</li></ul><p>If Virtualenv is not already installed, you can install it using the following command:</p><ul><li>Creating a Virtual Environment</li></ul><p>To create a virtual environment in your project directory, run:</p><p><em>venv is the name of the folder where the virtual environment will be created. You can use any name you prefer.</em></p><ul><li>Activating the Virtual Environment</li></ul><p>The activation process depends on your operating system:\nOn Windows (CMD or PowerShell):</p><div><pre><code>venv\\Scripts\\Activate.ps1\n</code></pre></div><p>Once activated, you will see the virtual environment name in the terminal prompt:</p><ul><li>Installing Packages in the Virtual Environment</li></ul><p>After activation, you can install project dependencies using:</p><ul><li>Deactivating the Virtual Environment</li></ul><p>To deactivate the virtual environment, simply run:</p><h2>\n  \n  \n  4. Saving and Recreating the Virtual Environment with </h2><p>To save the list of installed packages in the virtual environment, use:</p><div><pre><code>pip freeze &gt; requirements.txt\n</code></pre></div><p>To recreate the same environment on another system:</p><div><pre><code>pip install -r requirements.txt\n</code></pre></div><ul><li><p>Virtualenv helps you run Python projects in an isolated and conflict-free manner.</p></li><li><p>You can install it with pip install virtualenv.</p></li><li><p>Create and activate a virtual environment with venv.</p></li><li><p>Use requirements.txt to store and restore dependencies.</p></li></ul><p>Thanks for reading❤️\nI hope this guide helps you understand and use virtual environments effectively. If you have any questions or suggestions, feel free to leave a comment!</p>","contentLength":2322,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RandomPosterize in PyTorch","url":"https://dev.to/hyperkai/randomposterize-in-pytorch-40ac","date":1739757574,"author":"Super Kai (Kazuya Ito)","guid":870,"unread":true,"content":"<p><a href=\"https://pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomPosterize.html\" rel=\"noopener noreferrer\">RandomPosterize()</a> can randomly posterize an image with a given probability as shown below:</p><ul><li>The 1st argument for initialization is (Required-Type:):\n*Memos:\n\n<ul><li>It's the number of bits to keep for each channel.</li></ul></li><li>The 2nd argument for initialization is (Optional-Default:-Type: or ):\n*Memos:\n\n<ul><li>It's the probability of whether an image is posterized or not.</li></ul></li><li>The 1st argument is (Required-Type: or ()):\n*Memos:\n\n<ul><li>A tensor must be 2D or 3D.</li></ul></li></ul><div><pre><code></code></pre></div>","contentLength":425,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RandomInvert in PyTorch","url":"https://dev.to/hyperkai/randominvert-in-pytorch-4e0o","date":1739757459,"author":"Super Kai (Kazuya Ito)","guid":869,"unread":true,"content":"<ul><li>The 1st argument for initialization is (Optional-Default:-Type: or ):\n*Memos:\n\n<ul><li>It's the probability of whether an image is inverted or not.</li></ul></li><li>The 1st argument is (Required-Type: or ()):\n*Memos:\n\n<ul><li>A tensor must be 2D or 3D.</li></ul></li></ul><div><pre><code></code></pre></div>","contentLength":218,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What to do if the selenium crawler is detected?","url":"https://dev.to/98ip/what-to-do-if-the-selenium-crawler-is-detected-4o0f","date":1739757045,"author":"98IP 代理","guid":868,"unread":true,"content":"<p>When using Selenium for automated web crawling, it is often detected and blocked by the target website. This is usually because Selenium's automation features are more obvious and can be easily identified by the website's anti-crawler mechanism. This article will explore in depth how to deal with the problem of Selenium crawler being detected, including methods such as hiding automation features and using proxy IPs, and provide specific code examples. At the same time, 98IP proxy will be briefly mentioned as one of the solutions.</p><h2>\n  \n  \n  I. Reasons for Selenium crawlers being detected\n</h2><h3>\n  \n  \n  1.1 Obvious automation features\n</h3><p>Selenium's default browser behavior is significantly different from manual user operations, such as specific fields in the request header, fixed browser window size, uniform operation speed, etc., which may be used by websites to identify automated scripts.</p><h3>\n  \n  \n  1.2 Frequent request frequency\n</h3><p>Crawlers usually send requests at a frequency much higher than normal users, which can also easily alert websites.</p><p>If the crawler always sends requests from the same IP address, the IP address will soon be blacklisted by the website.</p><h2>\n  \n  \n  II. Strategies for dealing with Selenium crawler detection\n</h2><h3>\n  \n  \n  2.1 Hide automation features\n</h3><h4>\n  \n  \n  2.1.1 Modify request headers\n</h4><p>Through Selenium's <code>webdriver.ChromeOptions()</code> configuration, you can modify the browser's request header to make it closer to normal user requests.</p><div><pre><code></code></pre></div><h4>\n  \n  \n  2.1.2 Randomize browser settings\n</h4><p>Use libraries such as  to automatically manage browser drivers and randomize window size, scrolling behavior, etc. to simulate real user operations.</p><div><pre><code></code></pre></div><p>Sending requests through <a href=\"https://en.98ip.com/\" rel=\"noopener noreferrer\">proxy IPs</a> can effectively avoid the problem of IP being blocked. High-quality proxy services such as 98IP Proxy provide stable and anonymous IP resources, which is an effective means of dealing with Selenium crawlers being detected.</p><div><pre><code></code></pre></div><p> The above code uses the  library instead of  because  provides more flexible proxy configuration and request interception functions. If you haven't installed  yet, you can install it through .</p><h3>\n  \n  \n  2.3 Controlling request frequency\n</h3><p>By introducing random delays and setting reasonable request intervals, the request frequency of the Selenium crawler can be controlled to make it closer to the browsing behavior of normal users.</p><div><pre><code></code></pre></div><p>It is a common problem for Selenium crawlers to be detected, but by hiding automation features, using proxy IPs, controlling request frequency, etc., we can effectively reduce the risk of being detected. In particular, using high-quality proxy services such as 98IP Proxy can significantly improve the stability and success rate of crawlers.</p><p>In the future, with the continuous advancement of website anti-crawler technology, we also need to continuously update and improve crawler strategies. For example, introducing more complex browser simulation technology, using machine learning to predict and circumvent blocking strategies, etc. are all directions worth exploring.</p><p>In short, dealing with the problem of Selenium crawlers being detected requires comprehensive consideration of multiple factors and taking corresponding measures.</p>","contentLength":3162,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Writing Pythonic Code With Python Data Model","url":"https://dev.to/noble47/writing-pythonic-code-with-python-data-model-2j3o","date":1739751292,"author":"Noble-47","guid":847,"unread":true,"content":"<blockquote><p><em>This apparent oddity is the tip of an iceberg that, when properly understood, is the key to everything we call Pythonic. The iceberg is called the Python data model, and it describes the API that you can use to make your own objects play well with the most idiomatic language features.</em> - Luciano Ramalho (Fluent Python: clear, concise, and effective programming)</p></blockquote><p>What's so special about the Python data model one may ask. Rather than giving a personal answer, why don't we do a little dive in and see what we can accomplish by understanding the data model. Data model simply speaks about how data is represented. In Python, data is represented by objects or to sound a bit technical, objects are Python's abstraction for data. The data model provides us with an API that allows our objects to play well with the 'under the hood' of Python programming.</p><p>In our little dive into Python data model, we are going to specifically focus on the special methods. Special methods are class functions with special names that are invoked by special syntax. Defining these special methods in our class definitions can give our class instances some really cool Python powers like iteration, operator overloading, working well with context managers (the 'with' keyword), proper string representation and formatting, and many more. To show you how you could implement these special functions into your classes, we will consider two examples of situations where using these special functions would make our codes clearer and more Pythonic.</p><p><em>The first example is a little bit outside-the-box solution I came up with for creating a simple game of Rock-Paper-Scissors in Python and the second is going to be a bit mathematical in nature but I'm going to walk you through each line of code</em></p><h3><strong>A Simple Game Of Rock Paper Scissors</strong></h3><p>Just in case you are not familiar with the Rock-Paper-Scissors game, it is originally a hand game usually played among two people that involves making signs of either Rock or paper or scissors. Knowing the whole history of the game doesn't really matter what is important is knowing how to determine the winner. In a conventional setting, a hand sign of rock would always win against scissors but will lose against paper, a hand sign of scissors would win against paper and lose to rock and obviously, paper would lose to scissors and win against rock. we can summarize this as shown below</p><p>For our Python emulation of this game, we will limit the number of players to just two, one player would be the computer and the other would be the user. Also, this is not a machine learning article or a write-up about computer vision, our users would still have to type in an option between rock, paper, and scissors on the terminal for our program to work.\nBefore we go into the actual coding, it's good that we take a step back and consider how we want our Python script to be. For my solution to this challenge, I will use the random module to enable the computer select a random option of either rock, paper, or scissors. To implement how our code evaluates the winner, I'm going to make the following assumptions:</p><p>I'm also going to take an OOP approach; our rock, paper, and scissors will be treated as objects and not string variables. Rather than creating three separate classes for each, I'll create only one that can represent any of them. This approach would also allow me to show you how special methods make life easier. Now to the fun aspect!</p><p>Naming our class RPS may sound a bit odd, but I found the name 'RPS' to be a good fit cause each letter comes from the initials, R for Rock, P for Paper, and S for Scissors. What's important to note here is that creating an instance of our class requires two arguments: pick and name. We already stated that the users of our script would have to type in their selected option on the terminal, instead of making our users type in 'Paper' (which could be so stressful for them) why don't we just allow our user to type in 'P' (or 'p') to select 'Paper', that's what the pick stands for. The name property is the actual name e.g 'Paper'. So now that we know what each parameters is for, we can now inspect our class by creating an instance</p><div><pre><code>&gt;&gt;&gt; p = RPS('P', 'Paper') # create an instance\n&gt;&gt;&gt; p.name\n# return : Paper\n&gt;&gt;&gt; p.pick\n# return : P\n&gt;&gt;&gt; print(p)\n# return : &lt;__main__.RPS object at 0x...&gt;\n</code></pre></div><p>Our class instance was created and has the right attributes but notice what we get when we try to print the contents of the variable holding our class instance. Before getting into the technical details of how our class instance returns the odd-looking string, let's update our class definition by adding a single special function and see the difference.</p><p>Now let's create an instance and try printing our class instance again</p><div><pre><code>&gt;&gt;&gt; p = RPS('P', 'Paper')\n&gt;&gt;&gt; print(p)\n# return : RPS(P, Paper)\n</code></pre></div><p>As we can see, by defining the '' method we can achieve a better looking result. Let's make one more change to our class definition.</p><p>Now let's create an instance and test it again.</p><div><pre><code>&gt;&gt;&gt; p = RPS('P', 'Paper')\n&gt;&gt;&gt; p\n# return : RPS(P, Paper)\n&gt;&gt;&gt; print(p)\n# return : Paper\n&gt;&gt;&gt; str(p)\n# return : 'Paper'\n&gt;&gt;&gt; repr(p)\n# return : 'RPS(P, Paper)'\n</code></pre></div><p>To know what's going on here, we need to know a little about the print function. The print function converts all non-keyword arguments(like our p variable) to string using the built-in Python class . If calling  on our variable fails, python falls back on the built-in  function. When  is called on our object, it looks for a  method, if it finds none, it fails and then searches for a  method. Both the  and the  methods are special methods used for string representation of our object. The  method gives the official string representation of our object while the  method gives a friendly string representation of our object. I usually say that the  method is like talking to another developer and it usually shows how to call our class and the  is like talking to a user of our program (like the player in this case), you would usually just want to return a simple string like \"Paper\" to show the user what he picked.</p><p>Although I stated the  and  as the two special functions in our class definition, there's actually a third special method, and yes it is the most common one, the  function. It is used for initializing our class and called by the  special method just before returning our class instance. Did I just mention another special method we haven't defined? yes, I did. It may also interest you to know that Python automatically adds some other special methods to our class. You can check them out by calling the built-in function  on our class instance like this</p><div><pre><code>&gt;&gt;&gt; dir(p)\n# returns : ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'name', 'pick']\n</code></pre></div><p>Special functions or methods can be identified by the way they are named, they always begin with double underscores '<strong>' and end with double underscores '</strong>' Because of this special way of naming these methods, they are commonly called daunder methods (Double + UNDERscores = DUNDER). So if a method name begins with double underscores, it is most likely but not certainly a special method. Why not certainly? this is simply because Python does not stop us from defining our own methods using the dunder syntax. Alright back to our game script.</p><p>All that's left for us now is for us to let our script know how to determine a winner. As stated earlier, I will use comparison to evaluate a winner.</p><div><pre><code># comparison logic\nRock &gt; Scissors\nScissors &gt; Paper\nPaper &gt; Rock\n</code></pre></div><p>To implement this solution, I will add a dictionary and use the daunder greater_than method. The dictionary key would be the initials of Rock, Paper and Scissors. The value of each key would be the only other element that the key can defeat.</p><p>Notice the new lines of code, first the options dictionary and then the  method definition. With these new lines of code, let's see what new functionality our code now has.</p><div><pre><code># create a rock instance\n&gt;&gt;&gt; r = RPS('R', 'Rock')\n\n# create a paper instance\n&gt;&gt;&gt; p = RPS('P', 'Paper')\n\n# create a scissors instance\n&gt;&gt;&gt; s = RPS('S', 'Scissors')\n\n&gt;&gt;&gt; print(r,p,s)\n# return : Rock Paper Scissors\n\n&gt;&gt;&gt; p &gt; r # paper wins against rock\n# return : True\n\n&gt;&gt;&gt; r &gt; s # rock wins against scissors\n# return : True\n\n&gt;&gt;&gt; s &gt; p # scissors wins against paper\n# return : True\n\n&gt;&gt;&gt; p &lt; s # paper lose to scissors\n# return : True\n\n&gt;&gt;&gt; p &lt; r # paper lose to rock\n# return : False\n\n&gt;&gt;&gt; p &lt; s &lt; r# paper lose to scissors which lose to rock\n# return : True\n\n&gt;&gt;&gt; p &gt;= r paper wins or tie to rock\n# return : Traceback (most recent call last): \n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; \nTypeError: '&gt;=' not supported between instances of 'RPS' and 'RPS'\n</code></pre></div><p>Just by adding to  special method, our class instances have gained magical powers (daunder methods are sometimes called magic methods and we can see why). By implementing the daunder gt method, our class instance now relates well with the  and  symbols but not the  and  symbols. The reason is that  is just the negation of . The special method for  is  which can just be the negation of calling .</p><p>For the ≥ symbol, its special method is the  and it must be defined for our object to work well with the  sign. But in this program, we can do without it. </p><p>Another missing piece would be to check if two separate instances of Paper are equal.</p><div><pre><code>&gt;&gt;&gt; p1 = RPS(\"P\", \"Paper\")\n&gt;&gt;&gt; p2 = RPS(\"P\", \"Paper\")\n&gt;&gt;&gt; p3 = p1\n&gt;&gt;&gt; p1 == p2\n# return : False\n\n&gt;&gt;&gt; p1 == p3\n# return : True\n\n&gt;&gt;&gt; id(p1)\n# return : 140197926465008\n\n&gt;&gt;&gt; id(p2)\n# return : 140197925989440\n\n&gt;&gt;&gt; id(p3)\n# return : 140197926465008\n\n&gt;&gt;&gt; id(p1) == id(p3)\n# return : True\n\n&gt;&gt;&gt; id(p2) == id(p1)\n# return False\n</code></pre></div><p>The default operation of the equal comparison sign is to compare the id of the object. p1 and p2 are different class instances that happen to have the same attributes but their id differs and therefore are not equal. When we assign a variable to a class instance, we make that variable point to the address of the instance which is what we observe for p3 which has the same id as p1. We have the option of overriding how the equality comparison works on our object by defining and implementing our own  method. But for this script, I will compare two instances using their pick attribute. Now that we have defined our class and know how it works, we are now ready to see the full implementation of the Python script</p><p>Let me walk you through the code. We are already familiar with the RPS class definition. If you recall, our code is meant to allow the computer to select choices at random and that's what the random module is for. The random module makes available the  function which allows the 'random' selection of an element from an iterable object e.g. a list in Python. The list in this case is the . Because our class is made to work with uppercase letters for comparison, it is necessary that we always initialize our objects with uppercase for the pick attribute. This is why we first convert the user's input to upper case (line 34) with the&nbsp;. It is also possible that our user types in an unexpected character like 'Q' so we have to validate our user input by checking if the uppercase character is part of the valid options in . The mapping dictionary allows us to quickly convert the user's input to a corresponding instance of RPS after being validated. The evaluate_winner function makes use of the comparison symbol to determine the winner. Because we want the code to run in a loop until a winner is found, we make use of a while loop and when a winner is found, the evaluate_winner function returns True which will then break the loop and exit the game.</p><p>Here is one of the various results of running the code</p><p>Our Python code runs as expected, although there could be a couple of improvements or new features to add. The most important thing is that we see how using special methods in our class definition gives our code a more Pythonic feel. Assuming we were to take a different approach such as using nested if statements, our evaluate_winner method would look something like this</p><div><pre><code>def evaluate_winner(user_choice, comp_choice):\n    # check if user choice is 'R'\n    if user_choice == 'R':\n        # check if comp_choice is 'R'\n        if comp_choice == 'R':\n            # it is a tie\n            ...\n        elif comp_choice == 'S':\n            # user wins\n            ...\n        else:\n          # computer wins\n          ...\n    if ... \n     # do the same for when user_choice is 'S' and then for\n     # when user_choice is 'P'\n</code></pre></div><p>A problem with this approach other than the lengthy code is that if we desire to add a new element, diamond which can beat both rock and scissors but not paper (for an unknown reason), our if statements would begin to look really awkward. Whereas in our OOP approach, all we have to do is to modify the options dict like so</p><div><pre><code>options = {\"R\" : [\"S\"], \"P\" : [\"R\"], \"S\" : [\"P\"], \"D\" : [\"R\", \"S\"]}\n</code></pre></div><p>and then we change the if statement in  to be</p><div><pre><code>def __gt__(self,x):    \n    if x.pick in self.options[self.pick]:\n        return True\n    else:\n        return False\n</code></pre></div><p>we can make the statement shorter</p><div><pre><code>def __gt__(self, x):\n   return True if x.pick in self.options[self.pick] else False\n</code></pre></div><p>To conclude, here are some things you should note about using special methods:</p><ul><li><p>You hardly (or never) call them directly yourself, let Python do the calling for you</p></li><li><p>When defining functions that use the dunder naming syntax, you should consider that Python could one day define such a function and give it a different meaning. This could break your code or make it behave in unexpected ways</p></li><li><p>You certainly don't have to implement every special method there is. Just a couple that you are really sure you need. Remember, simple is better than complex. If there's a simpler way you should use that instead</p></li></ul><p>This is the first part of the topic, in the next part, we are going to be dealing with operator overloading and making iterable objects</p><p>Hope you enjoyed this article!!!</p>","contentLength":14165,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RandomPosterize in PyTorch","url":"https://dev.to/hyperkai/randomposterize-in-pytorch-35e6","date":1739744052,"author":"Super Kai (Kazuya Ito)","guid":799,"unread":true,"content":"<p><a href=\"https://pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomPosterize.html\" rel=\"noopener noreferrer\">RandomPosterize()</a> can randomly posterize an image with a given probability as shown below:</p><ul><li>The 1st argument for initialization is (Required-Type:):\n*Memos:\n\n<ul><li>It's the number of bits to keep for each channel.</li></ul></li><li>The 1st argument for initialization is (Optional-Default:-Type: or ):\n*Memos:\n\n<ul><li>It's the probability of whether an image is posterized or not.</li></ul></li><li>The 1st argument is (Required-Type: or ()):\n*Memos:\n\n<ul><li>A tensor must be 2D or 3D.</li></ul></li></ul><div><pre><code></code></pre></div>","contentLength":425,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"python Level 1","url":"https://dev.to/mohamed_yahyasidimohame/python-level-1-366c","date":1739741834,"author":"Mohamed Yahya Sidi Mohamed","guid":783,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A GUI App Which You Can Visulise Signal Waveforms With Python","url":"https://dev.to/gokhanergentech/a-gui-app-which-you-visulise-signal-waveforms-with-python-2ben","date":1739739362,"author":"Gökhan ERGEN","guid":767,"unread":true,"content":"<p>In this App, you can visulise three signal waveforms such as Sinusoidal, Square, and saw-toothed. Also, these signals has some params which you can setting them. The application was developed with dearpygui providing UI components for desktop apps. If you want to write a detailed blog about dearpygui, please comment :).</p><p>You can setting the ampitute of the waves.</p><p>A constant value which offsets veritcally</p><p>This is a sampling frequency showing how many samples is collected per a second.</p><p>We can use this to take the cycle count of signals. A cycle takes 1/Fsig seconds.</p><p>If Fsig is 0.2hz then the cycle count will be 5 seconds.</p><p>you can visulise sinusoidal sampled signal, squared sampled signal, and saw-toothed sampled signal by using above the params. The time range of signals is splitted (max_time-min_time)*Fs because Fs is sampling frequence per a second.</p><p>The program, which you change the params has a basic interface.</p><p>\nAs a default, selected waveform is sinusoidal.<p>\nSignal time range is between 0 and 10 and uses A*sin(2*π*Fsig*t+fi0)+dc as a formula to be drawn.</p>\nIn case A = 4,</p><p>We can use that positive side is about max 5 and negative side is min -3, because DC is 1 so signal shifts verticaly to up 1 step.</p><p>You will see a squared sampled signal.\nsignal_wave = sin(2*π<em>Fsig*t)\nif signal_wave &gt;=0, 1\n**Saw-toothed Wave</em>*</p><p>I use scipy library to draw saw-toothed wave form.\nAll of these signal waveforms use the same params.<p>\nLets change the time range as -100 to 100. We will see this graph sinusoidal waveforms.</p></p><p>I changed Fsig to 0.5. This means T = 1/0.5 = 2s cycle time.</p><p> 3.11.5 1.11.3 1.26.0 1.9.0</p>","contentLength":1594,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RustyNum Follow-Up: Fresh Insights and Ongoing Development","url":"https://dev.to/igorsusmelj/rustynum-follow-up-fresh-insights-and-ongoing-development-18f9","date":1739738297,"author":"IgorSusmelj","guid":766,"unread":true,"content":"<p>As a follow-up to my previous introduction to <a href=\"https://github.com/IgorSusmelj/rustynum\" rel=\"noopener noreferrer\">RustyNum</a>, I want to share a developer-focused update about what I’ve been working on these last few weeks. RustyNum, as you might recall, is my lightweight, Rust-powered alternative to NumPy published on GitHub under MIT license. It uses Rust’s portable SIMD features for faster numerical computations, while staying small (around ~300kB for the Python wheel). In this post, I’ll explore a few insights gained during development, point out where it really helps, and highlight recent additions to the documentation and tutorials.</p><p>If you missed the initial announcement, RustyNum focuses on:</p><ul><li>High performance using Rust’s SIMD</li><li>Memory safety in Rust, without GC overhead</li><li>Small distribution size (much smaller than NumPy wheels)</li><li>NumPy-like interface to reduce friction for Python users</li></ul><h2>\n  \n  \n  Developer’s Perspective: What’s New?\n</h2><p><strong>1. Working with Matrix Operations</strong></p><p>I’ve spent a good chunk of time ensuring matrix operations feel familiar. Being able to do something like matrix-vector or matrix-matrix multiplication with minimal code changes from NumPy was a primary goal. A highlight is the  function and the  operator, which both support these operations.</p><div><pre><code></code></pre></div><p>It’s neat to see how close this is to NumPy’s workflow. Benchmarks suggest RustyNum can often handle these tasks at speeds comparable to, and sometimes faster than, NumPy on smaller or medium-sized datasets. For very large matrices, I’m still optimizing the approach.</p><p><strong>2. Speeding Up Common Analytics Tasks</strong></p><div><pre><code></code></pre></div><p>The Python overhead can sometimes offset the raw Rust speed, but in many cases, RustyNum still shows advantages.</p><h2>\n  \n  \n  New Tutorials: Real-World Examples\n</h2><p>One of the best ways to see RustyNum in action is through practical examples. I’ve added several new tutorials with real-world coding scenarios:</p><ol><li> – Focus on dot products, matrix-vector, and matrix-matrix tasks.</li><li><strong>Replacing Core NumPy Calls</strong> – Demonstrates how to switch from NumPy’s mean, min, dot to RustyNum.</li><li><strong>Streamlining ML Preprocessing</strong> – Explores scaling, normalization, and feature engineering for machine learning.</li></ol><p>Check out a snippet of scaling code from that guide:</p><div><pre><code></code></pre></div><p>It’s a small snippet, but it shows how RustyNum can do row/column manipulations quite effectively. After scaling, you can still feed the data into your favorite machine learning frameworks. The overhead of converting RustyNum arrays back into NumPy or direct arrays is minimal compared to the cost of big model training steps.</p><p><strong>1. Large Matrix Optimizations</strong></p><p>I’ve noticed that for very large matrices (like 10k×10k), RustyNum’s current code paths aren’t yet fully optimized compared to NumPy. This area remains an active project. RustyNum is still young, and I’m hoping to introduce further parallelization or block-based multiplication techniques for better large-scale performance.</p><p>RustyNum supports float32 and float64 well, plus some integer types. I’m considering adding stronger integer support for data science tasks like certain indexing or small transformations. Meanwhile, advanced data types (e.g., complex numbers) might appear further down the line if the community needs them.</p><p><strong>3. Documentation and API Enhancements</strong></p><p>The docs site at <a href=\"https://rustynum.com/\" rel=\"noopener noreferrer\">rustynum.com</a> has an API reference and a roadmap. I’m continuously adding to it. If you spot anything missing or if you have a specific use case in mind, feel free to open a GitHub issue or submit a pull request.</p><p><strong>4. The big goal of Rustynum</strong></p><p>RustyNum is simply a learning exercise for me to combine Rust and Python. Since I spend every day around machine learning I would love to have RustyNum replace part of my daily Numpy routines. And we're slowly getting there. I started adding more and more methods around the topic of how to integrate RustyNum in ML pipelines.</p><h2>\n  \n  \n  Quick Code Example: ML Integration\n</h2><p>To demonstrate how RustyNum fits into a data pipeline, here’s a condensed example:</p><div><pre><code></code></pre></div><p>This script highlights that RustyNum can handle data transformations with a Pythonic feel, after which you can pass the arrays into other libraries.</p><p>It’s been fun to expand RustyNum’s features and see how well Rust can integrate with Python for high-performance tasks. The recent tutorials are a window into how RustyNum might replace parts of NumPy in data science or ML tasks, especially when smaller array sizes or mid-range tasks are involved.</p><ul><li>Check out the tutorials at rustynum.com</li><li>Contribute or report issues on GitHub</li><li>Share feedback if there’s a feature you’d love to see</li></ul><p>Thanks for tuning in to this developer-focused update, and I look forward to hearing how RustyNum helps you in your own projects!</p>","contentLength":4610,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Project Translate: The Translate API (Part 2)","url":"https://dev.to/__dbrown__/project-translate-the-translate-api-part-2-2nd1","date":1739731951,"author":"Emmanuel Akolbire","guid":724,"unread":true,"content":"<p>Hey developers! 👋 In this post, we'll implement the text translation endpoint using Python, AWS Lambda, and a clean Hexagonal Architecture. Let's dive in! You can check out my <a href=\"https://github.com/DeXtreme/translate\" rel=\"noopener noreferrer\">GitHub</a> for the complete code.</p><p>We create a new project with the directory structure shown in the picture\nThen we install the dependency, namely boto3, with pip. We also make sure to create a requirements.txt file so we know which version to install when the script is packaged.</p><p>We'll be employing Hexagonal(Layered) Architecture in the design of our API. Hexagonal Architecture or Ports and Adpaters is a design pattern that aims at creating loosely coupled components. A helpful guide can be found <a href=\"https://dev.to/xoubaman/understanding-hexagonal-architecture-3gk\">here</a>. Although python is a dynamically typed language, we can still use this pattern.</p><p>We'll be using the project directory structure shown below<a href=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fyys8ctber2fmle1icagi.png\"><img src=\"https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fyys8ctber2fmle1icagi.png\" alt=\"Project structure\" width=\"330\" height=\"385\"></a></p><h3>\n  \n  \n  The Translation Record Model\n</h3><p>Let's start with a simple but effective model to track our translations. We'll use Python's dataclasses - they're clean, efficient, and give us nice features out of the box.</p><div><pre><code></code></pre></div><p>Let's break down what each field does:</p><ul><li>: A unique identifier for each translation record</li><li>: The original text that needs translation</li><li>: The translated result</li><li>: Timestamp of when the translation was performed, automatically set to the current time</li></ul><p>You might wonder why we're using  instead of a regular class. Here's what makes dataclasses great for our use case:</p><p>Less Boilerplate: We don't need to write , , or  methods\nDefault Values: Easy handling of default values with the field function<p>\nType Hints: Built-in support for type hints, making our code more maintainable</p></p><p>Next, we'll define our ports using Python's Protocol class - a more Pythonic approach to interfaces. Let's dive in!\nWhy Protocols Over Abstract Base Classes?<p>\nBefore we jump into the code, let's understand why we're choosing Protocols:</p></p><ul><li>More Pythonic - follows duck typing principles</li><li>Structural subtyping instead of nominal subtyping</li><li>Better integration with static type checkers</li><li>No explicit inheritance required\n</li></ul><div><pre><code></code></pre></div><p>Now we define the adapters that implement the ports. The <code>DynamoDBPersistenceAdapter</code> stores the input and output in DynamoDB and return a Record object. The  translates the text with AWS Translate and returns the result.</p><div><pre><code></code></pre></div><p>Now we'll create the Lambda handler that ties everything together.\nWe'll define the  class with handles the requests to Lambda from the API Gateway. It parses the body for the required fields, translates the text, stores the input and output and returns a response</p><div><pre><code></code></pre></div><p>In order to allow Cross Origin Requests we add the Access-Control-Allow headers to the reponse object. For example, in the  method</p><div><pre><code></code></pre></div><p>In the next installment of this series, we'll dive into the code that handles file translation. Stay tuned! 🚀</p>","contentLength":2722,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"[Boost]","url":"https://dev.to/arindam_1729/-1h49","date":1739730645,"author":"Arindam Majumder","guid":723,"unread":true,"content":"<h2>🤯 11 Exciting GitHub Repositories You Should Check Right Now⚡️</h2><h3>Arindam Majumder  ・ Feb 13</h3>","contentLength":97,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Transform Your Data Model to AI Workflow - with only 8 extra lines of code!","url":"https://dev.to/eduardknezovic/transform-your-data-model-to-ai-workflow-with-only-8-extra-lines-of-code-3f5a","date":1739727355,"author":"Eduard Knezovic","guid":699,"unread":true,"content":"<p><em>\"Good programmers worry about data structures and their relationships.\"</em> - Linus Torvalds</p><p>What if you could create complex AI workflows as easily as defining your data structures with Pydantic?</p><p>What if you could simply harness the power of AI by allowing your Pydantic data models to flow like water?</p><p><a href=\"https://pypi.org/project/modellm/\" rel=\"noopener noreferrer\">ModeLLM</a> makes this possible by turning your Pydantic models into powerful AI pipeline components.</p><p>Let's go over an example!</p><p>You will need to provide your own OPENAI_API_KEY (if you haven't already)</p><div><pre><code></code></pre></div><p>You will also need to install the  library.</p><p>All of the relevant dependencies are automatically installed\nwith the  library.</p><p>Take a look at this complete working example.</p><div><pre><code></code></pre></div><p>To consolidate your knowledge:</p><ol><li>Execute the existing code on your computer</li><li>Generate the story for teenagers (uncomment one line of code) </li><li>Create a  Pydantic model that should summarize the story</li><li>Create your own Pydantic model and inject it to the pipeline</li></ol><p>In this example, we've managed to harness the power of AI\nin (only!) 8 additional lines of code - thanks to the <a href=\"https://pypi.org/project/modellm\" rel=\"noopener noreferrer\">ModeLLM library</a></p><ol><li>: Define what you want, not how to get it (LLM is smart enough to catch the cue)</li><li>: Chain transformations with the  operator (Makes our code easy to modify and extend)</li><li>: Docstrings guide the AI's behavior</li><li>: Easily swap components </li><li>: Complex AI operations hidden behind simple data models</li></ol><p>By defining our Pydantic data models (and decorating them) we were able to execute our AI pipeline with a single line of code:</p><div><pre><code></code></pre></div><p>What do you think about this approach? I would love to hear your thoughts and suggestions.</p>","contentLength":1534,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Modeling a Neuron in micrograd (As Explained by Karpathy)","url":"https://dev.to/shrsv/modeling-a-neuron-in-micrograd-as-explained-by-karpathy-6gh","date":1739723924,"author":"Shrijith Venkatramana","guid":677,"unread":true,"content":"<p><em>Hi there! I'm Shrijith Venkatrama, founder of Hexmos. Right now, I’m building <a href=\"https://hexmos.com/liveapi\" rel=\"noopener noreferrer\">LiveAPI</a>, a tool that makes generating API docs from your code ridiculously easy.</em></p><p>In serious neural network implementations, we model the neuron in the following way:</p><ol><li>1 \"Influence\"  (dendrite)</li><li>Sum of \"influences\" =  (cell body)</li></ol><p>The above leads to the cell body expression:</p><ol><li>Activation function - squashing fuction (, )</li></ol><h2>\n  \n  \n  Representing the Model Neuron (defined above) in micrograd\n</h2><div><pre><code></code></pre></div><h2>\n  \n  \n  Implementing  into Value (for the Activation Function)\n</h2><p>We have the following  formula:</p><p>We can implement the function as follows:</p><div><pre><code></code></pre></div><p>We'll add a new node  which is the :</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Derivative of o - Derivative of </h2><p>The formula for derivative of  is the following:</p><p>So, we want to find out :</p><div><pre><code>do/dn = 1 - tanh(n)**2 = 1 - o**2\n</code></pre></div><h2>\n  \n  \n  Getting all the backprop values calculated (manually)\n</h2><p>We leverage some patterns we've learned previously about how backprop works with addition/multiplication, to quickly fill in the values for  in each node:</p><div><pre><code></code></pre></div>","contentLength":996,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ultimate Football Draft (A Python Terminal Game)","url":"https://dev.to/jcubilloespinoza/ultimate-football-draft-a-python-terminal-game-128i","date":1739723472,"author":"Josue Cubillo Espinoza","guid":676,"unread":true,"content":"<p>Football fans around the world dream of managing their favorite teams and experiencing the thrill of competition. This Python program allows users to choose a team, participate in a simulated tournament, and compete for victory. By randomly assigning teams to groups and generating matches, the program provides an engaging and interactive experience.</p><p>The program begins by prompting the user to enter their name and select their favorite football team from a list of international clubs. After choosing a team, the program randomly assigns teams to groups for the tournament’s group stage. The user’s selected team is placed in one of these groups.</p><p>Using the random module, the program ensures fair and unpredictable group draws and match results. The user competes against other teams by answering trivia questions. Winning matches earns points, and the top teams from each group advance to the knockout stages.</p><p>Throughout the knockout rounds, the user’s team must win to progress further. If they lose a match, they are eliminated from the competition.</p><ol><li>Random selection of football teams into tournament groups.</li><li>Interactive gameplay where users answer questions to win matches.</li><li>Randomized match results for AI-controlled teams.</li><li>Automatic generation of tournament brackets leading to the final match.</li></ol><p>This project is a great example of how Python can be used to create engaging sports simulations. Whether you are a football fan or a programming enthusiast, this program provides an enjoyable way to experience the excitement of a football tournament. Try it out and see if your team can become the ultimate champion!</p>","contentLength":1617,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Unlock the Power of Neural Networks – From Scratch!","url":"https://dev.to/devinsights_blog_ed29ec86/unlock-the-power-of-neural-networks-from-scratch-3off","date":1739720592,"author":"DevInsights Blog","guid":652,"unread":true,"content":"<p>Have you ever wondered how machines can recognize images, translate languages, or even predict future trends? The secret lies in  – the backbone of modern AI.</p><p>Understanding how a neural network works can feel overwhelming, especially with so many complex libraries available. But what if you could actually <strong>build a neural network from scratch</strong> and understand every single step?</p><ul><li>The core concepts behind neural networks</li><li>Forward propagation, backpropagation, and loss calculation explained simply</li><li>A complete hands-on example in </li></ul><p>Building a neural network without relying on libraries like TensorFlow or PyTorch will give you  in AI. It’s like learning the fundamentals of a car engine before driving a sports car. Once you master this, using advanced tools will make far more sense.</p><p>Here’s a quick look at what you’ll be able to do:</p><div><pre><code></code></pre></div><p>This simple piece of code is part of a fully functional XOR solver you’ll build from scratch!</p><h4>\n  \n  \n  But That’s Just the Beginning...\n</h4><p>The full guide covers , from initializing weights to adjusting them through backpropagation – <strong>with clear explanations and complete working code.</strong></p><p>If you’re serious about AI and want to break free from black-box libraries, .</p><p><strong>Check it out now and start your deep learning journey today!</strong></p>","contentLength":1255,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Finished Auth App for Galileo! 🚀","url":"https://dev.to/khaled_abdelbar_43f8c0b1d/finished-auth-app-for-galileo-4md6","date":1739720424,"author":"Khaled Abdelbar","guid":651,"unread":true,"content":"<p>I’ve successfully finished building the authentication app for my Galileo project! 🎉</p><p>Next, I’ll focus on creating a Teams App to handle team functionalities, such as creating and joining teams. This will be a crucial step in enhancing collaboration within the project.</p><p>I’ll continue documenting each step of my journey here as I build Galileo, sharing insights and challenges I encounter. Stay tuned for updates on how I tackle the team management feature!</p>","contentLength":463,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python User Group Dhaka: Our Journey Begins – Event Recap","url":"https://dev.to/tamalchowdhury/python-user-group-dhaka-our-journey-begins-event-recap-2he7","date":1739715829,"author":"Tamal Anwar Chowdhury","guid":635,"unread":true,"content":"<p>On a cool February evening in Dhaka, a group of passionate Python enthusiasts gathered for something special—our city’s first-ever Python User Group meetup. What started as an idea a few weeks earlier turned into a diverse community event, laying the foundation for Python Dhaka’s journey.</p><p>Here’s how we made it happen and what we learned along the way.</p><p>The whole event was organized through our Facebook group. In Bangladesh, Facebook is the primary hub for tech enthusiasts to form communities and organize events. Unlike platforms like Meetup or Discord, Facebook groups often serve as the starting point for grassroots tech movements here. I launched a Facebook group for Python Dhaka a few weeks prior, and thanks to my personal network, it grew to 250 members within two weeks.</p><p>The next logical step was to organize an in-person meetup, because I want this group to be all about connecting with the local Python enthusiasts. After thinking about it for a few days, I locked in a date and venue for the first meetup.</p><p>I choose the 15th of February because it's the mid-month, and a Saturday. In Bangladesh, Fridays and Saturdays are official holidays. Friday is the most popular day for events, followed by Saturdays. I picked Chandrima Udyan for two reasons: 1. It has easy access to the bus and metro route; 2. It's a public park we can access for free.</p><p>I created the event on Facebook and started spreading the word on the FB group, my profile, Twitter, Linkedin, and my Instagram handle. I even created a short video announcing the event and posted it on all of my socials.</p><p>At 5 PM local time, I waited near the park entrance, feeling a mix of excitement and nerves. Soon, one by one, attendees started arriving, their calls guiding me to them. Here’s me waiting:</p><p>As we entered the park, a cool evening breeze greeted us—washing away the stress of city life and setting the perfect mood for our first meetup.</p><p>I started the meeting by sharing the Python Software Foundation's missions with the attendees, and how it relates to us:</p><ul><li><p><strong>To grow a diverse and international community of Python programmers:</strong> Organizing the Python Dhaka community is helping this mission.</p></li><li><p><strong>Encourage knowledge sharing, collaboration, and support devs of all backgrounds:</strong> Students from three universities joined this event. They were able to share knowledge and build future collaboration opportunities. This community is open to all levels of developer experience.</p></li><li><p><strong>Grow a diverse and welcoming community; support underrepresented communities in tech:</strong> One participant came from a non-computer science background, eager to transition into tech. This is exactly why Python Dhaka exists—to welcome everyone, regardless of their starting point.</p></li></ul><p>I then shared how I started evangelizing Python.</p><p>I am a professional JavaScript developer with React and NextJS expertise. I use JS for my daily work. My cousin wanted to learn Python, so I got into learning it. I found Python to be easy to learn and easy to teach. I was looking for a Python community in Dhaka, but there was none. That's why I decided to organize the Python User Group Dhaka.</p><p>I also mentioned that I don't own Python Dhaka. I am only organizing it for the time being. As this community grows, and if in the future I have to move cities, I will pass the torch to the next person to continue organizing our community activities.</p><p>We are not strictly Python fanatics. We would love to collaborate with our friends in the JavaScript, PHP, and Kotlin communities too from time to time.</p><p>We heard personal stories from the attendees, how they got into programming, and how they are using Python. Two students are doing competitive programming with C, C++ and thinking of switching to Python for CP and ML.</p><p>Two of the attendees came from different districts just so they could attend this meetup.&nbsp;</p><p><strong>One attendee traveled over 80 kilometers from Tangail just to be here. That level of dedication reminded me why this community matters.</strong></p><p>I shared many tech tips, and also informed them about the free GitHub Student Developer pack and how to avail it. We also discussed getting real-world experiences by putting an app out in the world.</p><p>We also announced the Campus Ambassador Program for Python Dhaka and nominated Abdullah to be the ambassador at Southeast University. A campus ambassador is a person in your college/university who will promote and evangelize Python programming language on your campus.</p><p>As the meetup was about to end, it was getting dark when we clicked this group photo.</p><p>Our journey is just beginning. We plan to host monthly meetups around the 15th of each month, but our ambition goes beyond that. We want to nurture the next generation of Python developers in Bangladesh, and one day, bring PyCon Bangladesh to life.</p><p>If you’re as passionate about Python as we are—whether you’re in Dhaka or anywhere in the world—we’d love your support. Find <a href=\"https://www.facebook.com/groups/pythondhaka\" rel=\"noopener noreferrer\">Python User Group Dhaka on Facebook</a>, or connect with me on Linkedin, X, and Instagram. Let's build this community together!</p>","contentLength":5017,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mobile-First Approach for FastAPI Full-Stack Template Authentication: Migrating to phone_number/OTP","url":"https://dev.to/justjayzee/mobile-first-approach-for-fastapi-full-stack-template-authentication-migrating-to-phonenumberotp-m02","date":1739715631,"author":"Javad Zarezadeh","guid":634,"unread":true,"content":"<p>As you may know,  is one of the most admired frameworks for developing RESTful APIs. Another fantastic project by the same author, <a href=\"https://dev.to/tiangolo\">@tiangolo</a>, is the <a href=\"https://github.com/fastapi/full-stack-fastapi-template\" rel=\"noopener noreferrer\">Full Stack FastAPI Template</a>, which I previously wrote about <a href=\"https://dev.to/justjayzee/why-fastapi-full-stack-template-is-my-go-to-for-modern-web-development-1f2e\">here</a>.</p><p>In this post, I'll guide you through the process of replacing the email/password authentication flow in the template with a phone_number/OTP-based system. This approach is ideal for mobile-first applications and offers a user-friendly, secure way to authenticate users. My goal is to make minimal changes to the original project while maintaining its adherence to  and . Let’s dive in! 😉</p><h2>\n  \n  \n  1. Replace  and  with  and </h2><ul><li>Update the  value to a phone number, e.g.,  or .</li><li>Remove  as it is no longer necessary.</li></ul><p>Replace all instances of the  field with .</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>⚠️  This change requires updating the database schema using Alembic migrations.</p><p><code>./backend/app/api/routes/private.py</code>\nReplace all occurrences of  and  with  and .</p><p><code>./backend/app/api/routes/login.py</code> call:</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>⚠️  Keep  and  unchanged due to OAuth2 standards.</p><p><code>./backend/app/api/routes/users.py</code></p><ul><li>Replace  with .</li><li>Remove the  in the  function related to email validation.</li></ul><ul><li>Replace  references with .</li><li>Remove  as it is no longer necessary.</li></ul><p> ./backend/app/crud.py  </p><ul><li>Replace all  and  references with  and .\n</li><li>Rename  to  and update all references to this function.</li></ul><h2>\n  \n  \n  2. Add an API Endpoint to Request OTP\n</h2><p><code>./backend/app/api/routes/login.py</code><p>\nAdd the following endpoint:</p></p><div><pre><code></code></pre></div><h2>\n  \n  \n  3. Nullify OTP After Login\n</h2><p><code>./backend/app/api/routes/login.py</code>\nIn the  function, nullify the OTP after successful login:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  4. Remove Unnecessary Functions\n</h2><p><code>./backend/app/api/routes/login.py</code><p>\nRemove the following functions:</p></p><ul><li><code>recover_password_html_content</code></li></ul><h2>\n  \n  \n  5. Remove Unnecessary Email Features\n</h2><p><code>./backend/app/api/routes/users.py</code><p>\nRemove the email-related logic, such as:</p></p><div><pre><code></code></pre></div><h2>\n  \n  \n  6. Remove Password Update and User Registration Functions\n</h2><p><code>./backend/app/api/routes/users.py</code></p><p>Remove the following functions:  </p><ul></ul><p>Since we are now using OTP-based authentication, these functions are redundant.  </p><p>Update all  fields to .  </p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><h3><strong>Remove OTP from :</strong></h3><p>For the  model, you don’t need to include the  field. Update it as follows:</p><div><pre><code></code></pre></div><p>This simplifies the creation process since OTP will be generated later during login.  </p><p>Add an  field to both the  and  models.  </p><div><pre><code></code></pre></div><h3><strong>Remove Unnecessary Models:</strong></h3><p>Delete models that are no longer needed, including:  </p><ul></ul><p>This cleanup ensures the models remain relevant to the new authentication system.  </p><ul><li><code>generate_reset_password_email</code></li><li><code>generate_new_account_email</code></li><li><code>generate_password_reset_token</code></li><li><code>verify_password_reset_token</code></li></ul><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>Following these steps will transform the Full Stack FastAPI Template’s email/password flow into a phone_number/OTP-based system while keeping it aligned with best practices and standards. Happy coding! 🚀 </p><p>These changes to the  original project are available in my <a href=\"https://github.com/javadzarezadeh/phone-otp-auth-fastapi\" rel=\"noopener noreferrer\">GitHub</a>. It is important to use this project cautiously, since I have not yet had time to write the tests.</p>","contentLength":2908,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RandomInvert in PyTorch","url":"https://dev.to/hyperkai/randominvert-in-pytorch-5eb0","date":1739711271,"author":"Super Kai (Kazuya Ito)","guid":615,"unread":true,"content":"<ul><li>The 1st argument for initialization is (Optional-Default:-Type: or ):\n*Memos:\n\n<ul><li>It's the probability of whether an image is inverted or not.</li></ul></li><li>The 1st argument is (Required-Type: or ()):\n*Memos:\n\n<ul><li>A tensor must be 2D or 3D.</li></ul></li></ul><div><pre><code></code></pre></div>","contentLength":218,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GaussianBlur in PyTorch (3)","url":"https://dev.to/hyperkai/gaussianblur-in-pytorch-3-56do","date":1739704832,"author":"Super Kai (Kazuya Ito)","guid":567,"unread":true,"content":"<div><pre><code></code></pre></div>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"just a silly game","url":"https://dev.to/bankai2054/just-a-silly-game-29kl","date":1739700124,"author":"anas barkallah","guid":566,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Migrating from AWS CDK v1 to CDK v2","url":"https://dev.to/sami_jaballah/migrating-from-aws-cdk-v1-to-cdk-v2-21nd","date":1739698802,"author":"Sami Jaballah","guid":565,"unread":true,"content":"<p>If you’re currently using CDK v1 in your daily work, you’ve probably hit a roadblock trying to implement new AWS features. AWS isn’t adding those to CDK v1 anymore—so to keep up with the latest and greatest, you’ll need to migrate to CDK v2. It might sound like a hassle, but don’t worry—I’ve got your back. Let’s go through this step-by-step and get you up to speed, Python style.</p><h2>\n  \n  \n  Why Should You Care About CDK v2?\n</h2><p>Alright, let’s address the big question: why even bother migrating to CDK v2? Well, here are three solid reasons:</p><p>Simplified Dependencies: No more pulling in tons of packages for different AWS services. CDK v2 bundles everything into a single package: aws-cdk-lib. How awesome is that?</p><p>Stay Updated: CDK v1 isn’t getting any love anymore. If you want to keep up with the latest AWS features and updates, v2 is where it’s at.</p><p>Better Developer Experience: AWS has introduced some stability guarantees and cleaned up APIs, making it easier for us to write and maintain our infrastructure code.</p><p><strong>1. Consolidated Package Structure</strong>\nRemember the days of importing a separate package for each AWS service? That’s history now. CDK v2 unifies everything into aws-cdk-lib.</p><div><pre><code>from aws_cdk import core\nfrom aws_cdk.aws_s3 import Bucket\n</code></pre></div><div><pre><code>from aws_cdk import Stack\nfrom aws_cdk.aws_s3 import Bucket\n</code></pre></div><p><strong>2. Goodbye to Deprecated APIs</strong></p><p>Some APIs and constructs from v1 didn’t make the cut in v2. For instance, core.Construct has been replaced by constructs.Construct. A little cleanup never hurts, right?</p><p>There are some great new features, like improved stability guarantees for low-level (L1) constructs and better testing capabilities with assertions.</p><h2>\n  \n  \n  Let’s Get Migrating: Step-by-Step Guide\n</h2><p>Ready to dive in? Follow these steps to upgrade your Python CDK project to v2.</p><p><strong>1. Update Your Dependencies</strong></p><p>Start by upgrading your project dependencies to use CDK v2. Open your requirements.txt or Pipfile and update them:</p><div><pre><code>aws-cdk-lib&gt;=2.0.0\nconstructs&gt;=10.0.0\n</code></pre></div><p>Then, install the new dependencies:</p><div><pre><code>pip install -r requirements.txt\n</code></pre></div><p>This is where the magic happens. Go through your code and replace aws_cdk.core with aws_cdk.Stack, and adjust other imports to use aws-cdk-lib.</p><div><pre><code>from aws_cdk import core\nfrom aws_cdk.aws_s3 import Bucket\n</code></pre></div><div><pre><code>from aws_cdk import Stack\nfrom aws_cdk.aws_s3 import Bucket\n</code></pre></div><p><strong>3. Refactor Deprecated Constructs</strong></p><p>Some constructs have been replaced or removed. For example, core.Construct is now constructs.Construct. Update your code accordingly.</p><div><pre><code>class MyBucket(core.Construct):\n    def __init__(self, scope: core.Construct, id: str):\n        super().__init__(scope, id)\n        Bucket(self, \"MyBucket\")\n</code></pre></div><div><pre><code>from constructs import Construct\n\nclass MyBucket(Construct):\n    def __init__(self, scope: Construct, id: str):\n        super().__init__(scope, id)\n        Bucket(self, \"MyBucket\")\n</code></pre></div><p><strong>4. Remove Unnecessary Feature Flags</strong></p><p>CDK v2 has removed or integrated several feature flags that were necessary in v1. To clean up your cdk.json file, remove any obsolete flags.</p><div><pre><code>{\n  \"app\": \"python3 app.py\",\n  \"context\": {\n    \"@aws-cdk/core:newStyleStackSynthesis\": true,\n    \"@aws-cdk/aws-ec2:uniqueImds\": true,\n    \"@aws-cdk/core:stackRelativeExports\": true,\n    \"@aws-cdk/aws-secretsmanager:parseOwnedSecretName\": true,\n    \"@aws-cdk/aws-kms:defaultKeyPolicies\": true,\n    \"@aws-cdk/core:enableStackNameDuplicates\": true,\n    \"aws-cdk:enableDiffNoFail\": true,\n    \"@aws-cdk/aws-ecr-assets:dockerIgnoreSupport\": true,\n    \"@aws-cdk/aws-s3:grantWriteWithoutAcl\": true,\n    \"@aws-cdk/aws-efs:defaultEncryptionAtRest\": true\n  }\n}\n</code></pre></div><div><pre><code>{\n  \"app\": \"python3 app.py\"\n}\n</code></pre></div><p>Removing these flags ensures your project stays aligned with CDK v2 best practices.</p><p>Finally, make sure everything works as expected. Run these commands:</p><p>Fix any issues that pop up, and you’re good to go!</p><h2>\n  \n  \n  Migration Verification Checklist\n</h2><ul><li> All imports updated to aws-cdk-lib</li><li> Construct imports moved to constructs package</li><li> cdk diff shows expected changes</li></ul><p>And there you have it! Migrating from CDK v1 to v2 isn’t as scary as it might seem. With unified dependencies, better APIs, and future-proofing, this upgrade is worth the effort. Take it one step at a time, and don’t hesitate to ask for help if you hit a roadblock.</p><p>Have you already migrated to CDK v2? Or are you planning to? Share your experience (or any questions) in the comments below!</p><h2>\n  \n  \n  Useful links to help you along the way:\n</h2>","contentLength":4369,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"My take on the Agentic Object Detection","url":"https://dev.to/mayank_laddha_21ef3e061ff/my-take-on-the-agentic-object-detection-4612","date":1739695329,"author":"Mayank Laddha","guid":564,"unread":true,"content":"<li><p>Segmenting Everything with SAM : We detect everything and worry about filtering later.</p></li><li><p>Filtering with CLIP: Once we have all the segmented objects, we don’t want all of them. We need to filter out the noise and keep only the relevant objects.</p></li><li><p>Adding Reasoning with a model like GPT-4o: Okay, so we’ve segmented and filtered. But what about finalising, understanding? That’s where a strong LLM like GPT-4o comes in.</p></li>","contentLength":418,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Streamline Document Processing Pipelines with FalkorDB’s String Loader","url":"https://dev.to/falkordb/streamline-document-processing-pipelines-with-falkordbs-string-loader-1f9g","date":1739693873,"author":"Dan Shalev","guid":563,"unread":true,"content":"<p> You decide how your data is chunked and processed, ensuring that the graph structure aligns perfectly with your RAG requirements.</p><p> By working with runtime memory data, the string loader avoids the overhead of writing and reading intermediate files, reducing latency and simplifying the workflow.</p><p><strong>Integration with GraphRAG SDK:</strong> The string loader is designed to work seamlessly with the GraphRAG SDK, allowing you to build advanced graph-based RAG systems with greater ease and precision.</p><p> The string loader is open-source, providing transparency and the ability to customize the feature to meet specific needs.</p>","contentLength":607,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building a RAG-Powered Support Chatbot in 24 Hours of Hackathon","url":"https://dev.to/akshay_gupta/building-a-rag-powered-support-chatbot-in-24-hours-of-hackathon-5f7c","date":1739690328,"author":"Akshay Gupta","guid":562,"unread":true,"content":"<p>Coffee? ✅ Chai? ✅ Determination to automate admin support? Double ✅</p><p>In a recent 24-hour hackathon at annual PeopleGrove offsite, my team tackled an ambitious challenge: building an AI-powered support chatbot that could think and respond like a season platform administrator.</p><p>Armed with Large Language Models (LLMs) and fueled by caffeine, we created a Retrieval-Augmented Generation (RAG) system that turned out to be surprisingly capable!</p><p>: Our support heroes (admins and agents) spending their days 😅:</p><ul><li>Answering the same questions from different institutions 🏫\n\n<ul><li>Repetitive SSO, analytics, and user management queries</li><li>Same solutions, different institutions</li></ul></li><li>Context-switching between multiple support channels 🔄\n\n<ul><li>Support tickets piling up</li></ul></li><li>Time-Consuming Routine Tasks ⏰\n\n<ul><li>Manual ticket search and response formatting</li></ul></li><li>Complex Problem-Solving Getting Delayed 🎯\n\n<ul><li>Too much time on routine questions</li><li>Limited bandwidth for critical platform improvements</li></ul></li></ul><p>Our support team needed a solution that could:</p><ul><li>Handle common queries intelligently 🤖</li><li>Provide consistent, accurate responses 📚</li><li>Free up time for complex problem-solving 💡</li><li>Scale support without scaling the team 📈</li><li>Maintain the human touch while automating routine tasks 🤝</li></ul><p>We built ChatterMind 🤖 - an AI chatbot that combines the power of LLMs with a RAG system. Think of it as a super-smart intern who:</p><ul><li>Never sleeps (unlike us during the hackathon) 😴</li><li>Has photographic memory of all support tickets 🧠</li><li>Knows the PeopleGrove documentation better than its authors 📚</li><li>Knows when to call for backup (aka create a ticket) 🆘</li><li>Remembers conversations (thanks to Redis - our MVP choice for the hackathon) 💾</li><li>Keeps secrets better than a vault 🔒</li></ul><p>Here's a high-level overview of how ChatterMind processes and responds to queries:</p><p>Let's geek out about our tech choices for a minute! 🤓</p><p>Our initial choice was the DeepSeek model (1.5B parameters) because, well, it was lightweight and fast. But we quickly discovered it had a tendency to... let's say, get creative with the truth. After some frantic testing and a few more cups of chai, we switched to Gemini 2.0 Flash (experimental) which proved to be our goldilocks model:</p><ul><li>Better context understanding</li><li>Stronger reasoning capabilities</li></ul><p>The secret sauce behind ChatterMind's human-like responses? Carefully crafted prompts! Our prompt engineering approach focused on:</p><ul><li>Role Definition 🎭\n\n<ul><li>Defined as \"Senior Product Support Specialist\"</li><li>Given a friendly personality and name</li><li>Established clear boundaries of authority</li></ul></li><li>Context Management 🧩\n\n<ul><li>User's current location in platform</li><li>Previous conversation history</li></ul></li><li>Response Structuring 📝\n\n<ul><li>Natural, conversational flow</li><li>Markdown formatting for readability</li><li>Length limits (100-300 words)</li><li>Clear action items when needed</li></ul></li><li>Safety Guidelines 🛡️\n\n<ul><li>Strict PII protection rules</li></ul></li><li>Dynamic Adaptation 🔄\n\n<ul><li>First-time vs follow-up questions</li><li>Technical vs non-technical users</li><li>Simple queries vs complex issues</li><li>Error scenarios vs success paths</li></ul></li></ul><p>Example Prompt Template 📝</p><div><pre><code>System Context:\nYou are ChatterMind, a Senior Product Support Specialist at PeopleGrove.\nPrimary Goal: Provide clear, accurate, and helpful support while maintaining security.\n\nBehavioral Guidelines:\n- Be professional yet friendly\n- Start with a warm greeting for new conversations\n- For follow-ups, continue naturally without greeting\n- Keep responses under 300 words\n- Use markdown only when needed\n- Never share PII or sensitive data\n- If unsure, ask for clarification\n- For complex issues, guide towards ticket creation\n\nCurrent Context:\n- User Location: {current_path}\n- Required Permissions: {path_permissions}\n- User Role: {user_role}\n\nPrevious Conversation:\n{chat_history}\n\nReference Knowledge:\n{relevant_articles}\n{similar_tickets}\n{route_context}\n\nCurrent Question: {user_query}\n\nResponse Format:\n1. [If new conversation] Brief greeting\n2. Acknowledge context/location\n3. Provide clear solution/steps\n4. Add relevant warnings/notes\n5. Offer follow-up assistance\n</code></pre></div><ul><li>Natural conversation flow 💬</li><li>Helpful, actionable responses ✅</li></ul><h3>\n  \n  \n  Data Processing &amp; Embeddings\n</h3><p>We built our knowledge base from three main sources:</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>Platform Routes &amp; Permissions:</p><div><pre><code></code></pre></div><p>For embeddings, we chose the  model from  because:</p><ul><li>384-dimensional embeddings (good balance of size vs. accuracy)</li><li>Fast inference time (crucial for real-time chat)</li><li>Great at capturing semantic meaning</li><li>Works well with technical content</li></ul><p>We stored these in ElasticSeach with cosine similarity search, which gave us:</p><div><pre><code></code></pre></div><h2>\n  \n  \n  Edge Cases &amp; Safety Features\n</h2><p>ChatterMind turned out to be quite the responsible assistant. Some of our favourite edge case handles:</p><p>Personal Data Protection:</p><div><pre><code>User: \"What's John Smith's email address?\"\nChatterMind: \"I apologize, but I cannot share personal information such as email addresses, phone numbers, or other private details about users. This is to protect user privacy and comply with data protection regulations. If you need to contact someone, I recommend using the platform's built-in messaging system.\"\n</code></pre></div><div><pre><code>User: \"Can you update my database permissions?\"\nChatterMind: \"I'm not able to directly modify system permissions or make database changes. This requires admin intervention for security reasons. Would you like me to help you create a ticket for this request?\"\n</code></pre></div><p>Handling Requests not related to Platform:</p><div><pre><code>User: \"What is 5 + 2 + 7?\"\nChatterMind: \"I apologise, but performing mathematical calculations is beyond my scope as a platform support assistant. I'm designed to help with PeopleGrove platform-related questions and issues. If you need a calculator, I'd recommend using your device's built-in calculator app or a dedicated math tool.\"\n</code></pre></div><div><pre><code>User: \"It's not working\"\nChatterMind: \"I notice you're on the messaging page, but I'll need more details to help you effectively. Could you please:\n1. Describe what specific feature isn't working\n2. What you were trying to do\n3. What error message (if any) you're seeing\n\nThis will help me provide the most relevant solution.\"\n</code></pre></div><p>Our implementation was heavily inspired by the excellent guide on building RAG systems with DeepSeek R1 by Asif Razzaq at MarkTechPost. While we ultimately chose Gemini 2.0 Flash for our use case, the fundamental RAG architecture outlined in the guide formed the backbone of our system.</p><p>Key learnings we adapted from the guide:</p><ul><li>Document processing pipeline structure</li><li>Vector store implementation with FAISS</li><li>Efficient retrieval mechanisms</li></ul><p>We modified these concepts to fit our specific needs:</p><div><pre><code></code></pre></div><p>The guide's emphasis on proper document chunking and context relevance directly influenced our implementation of the knowledge base processing:</p><div><pre><code></code></pre></div><h3>\n  \n  \n  Real-time Communication with WebSockets\n</h3><p>Why WebSockets? Because nobody likes waiting! We needed real-time, bi-directional communication between the frontend and our RAG system. RESTful APIs would've meant:</p><ul><li>No server-initiated messages</li><li>More complex state management</li><li>Chatbot responses getting suck \"in transit\"</li></ul><p>Here's how we implemented it:</p><div><pre><code></code></pre></div><p>The WebSocket connection allows us to:</p><ul><li>Stream responses in real-time</li><li>Maintain conversation state</li><li>Implement retry mechanism</li></ul><h3>\n  \n  \n  ElasticSearch as Our Knowledge Base\n</h3><p>While FAISS was suggested in the DeepSeek guide, we chose ElasticSearch for our vector store because:</p><ul><li>Built-in text search capabilities</li><li>Efficient vector similarity search</li></ul><p>Here's our ElasticSearch setup:</p><div><pre><code></code></pre></div><ul></ul><h2>\n  \n  \n  Cool Features We're Proud Of\n</h2><ul><li>Context-Aware Responses\n\n<ul><li>The bot doesn't just search - it understands where the user is in the platform and what they've been talking about. It's like having a GPS for user context!</li></ul></li><li>Privacy First\n\n<ul><li>We trained our bot to be as tight-lipped as a secret agent about sensitive data. Try asking for someone's email - it'll give you the \"I cannot share that information\" speech faster than you can say \"GDPR\"!</li></ul></li><li>Beyond the Knowledge Base\n\n<ul><li>The real magic happens when users ask questions that aren't in any document. By combining context with LLM capabilities, ChatterMind can reason about platform behaviour and suggest solutions, like a true admin would.\n</li></ul></li></ul><div><pre><code>ChatterMind: \"Hi Akshay, my name is ChatterMind! 👋 Welcome to XYZ Support. I'm here to help with any questions you have about mentoring, connecting with alumni, or using the platform. How can I assist you today?\"\nUser: \"Why is the page not working?\"\nChatterMind: \"It sounds like you're having trouble accessing the admin dashboard. To help me figure out why the page isn't working, could you tell me if you have correct access? This page requires admin-level permissions to function correctly. Also, please note that this page is not available on native mobile apps, so if you are using a mobile app, that could be the reason why it's not working.\n\nIf you do have the correct permissions and are not using a mobile app, could you describe what you're seeing on the page? Any details you can provide will help me troubleshoot the issue.\n\nPlease let me know if you have any other questions.\"\n</code></pre></div><h2>\n  \n  \n  Hackathon Compromises (aka Technical Debt)\n</h2><p>Let's be real - in 24 hours, we had to cut some corners:</p><ul><li>Redis for chat history\n\n<ul><li>Would use a proper database for production</li><li>No backup/persistence configuration</li></ul></li><li>Security shortcuts\n\n<ul><li>Basic token authentication</li></ul></li><li>Performance trade-offs\n\n<ul><li>Single-node ElasticSearch</li></ul></li></ul><p>If we had more time (and less caffeine), we'd love to add:</p><ul><li>Proper infrastructure\n\n<ul><li>Distributed chat history storage</li></ul></li><li>Cool features\n\n<ul><li>Voice interface (for those too tired to type)</li><li>Multi-language support (because admins speak many languages)</li><li>Predictive issue detection (stop problems before they happen!)</li></ul></li></ul><p>This project wouldn't have been possible (let alone won the hackathon! 🏆 🎉) without my amazing team's diverse skills and relentless energy. Special thanks to:</p><ul><li>Our AI/ML engineer Suyash who became our guide at times and pointed us in right direction. 🧠</li><li>Our Engineers Rajat &amp; Rahul who made WebSockets work like magic, and did the end-to-end integration on my core idea. ⚡</li><li>Our Engineers Manoj &amp; Samrood who integrated ElasticSearch &amp; became frontend ninjas who created a sleek chat-interface. 🎨</li><li>And countless Chai &amp; Coffee that fuelled our coding marathons. 🥤</li></ul><p>Winning the hackathon was the cherry on top of an incredible 24-hour journey. It proved that when passionate developers come together with a clear mission (and enough caffeine), we can create something truly impactful.</p><p>Our hackathon project proved that with modern LLMs, good prompt engineering, and a solid RAG system, you can build a surprisingly capable admin support chatbot in just 24 hours.</p><p>While not production-ready, it showed the potential for AI to transform admin support from a repetitive task to an intelligent service.</p><blockquote><p>No admins were harmed in the making of this chatbot, though several cups of Chai and Coffee were consumed! 🚀 ☕ 🎉</p></blockquote>","contentLength":10666,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python for Web Developers: A Fast-Paced Guide to the Language","url":"https://dev.to/austinwdigital/python-for-web-developers-a-fast-paced-guide-to-the-language-38f7","date":1739687040,"author":"Austin W","guid":561,"unread":true,"content":"<p>👋  Follow me on <a href=\"https://github.com/austinwdigital\" rel=\"noopener noreferrer\">GitHub</a> for new projects.</p><p>Python is a powerful, high-level programming language widely used in web development, automation, data science, and scripting. If you're already a  familiar with <strong>JavaScript, TypeScript, Node.js, and frameworks like React or Next.js</strong>, learning Python can open doors to backend development with <strong>Django, Flask, and FastAPI</strong>, as well as <strong>automation, data analysis, and AI</strong>.</p><p>This guide is a  of Python, focusing on concepts that web developers need to know. If you’re comfortable with JavaScript, you’ll find Python’s syntax clean and easy to pick up.</p><h2><strong>1. Python Syntax &amp; Basics</strong></h2><h3><strong>Hello World (No Semicolons, No Braces)</strong></h3><p>✔ No semicolons ().—uses indentation., just .  </p><h3><strong>Variables &amp; Dynamic Typing</strong></h3><div><pre><code></code></pre></div><p>✔ No need to declare , , or .<p>\n✔ Types are inferred dynamically.  </p></p><h3>\n  \n  \n  How Does const Work in Python?\n</h3><p>Python does not have const like JavaScript, but you can define constants by using all-uppercase variable names as a convention.</p><div><pre><code></code></pre></div><p>However, this does not enforce immutability. If you need true immutability, use a dataclass or a frozen set.</p><h3><strong>Data Types (Compared to JavaScript)</strong></h3><div><table><tbody><tr></tr><tr></tr><tr><td><code>let obj = {key: \"value\"};</code></td></tr></tbody></table></div><h2><strong>2. Control Flow (Loops &amp; Conditionals)</strong></h2><div><pre><code></code></pre></div><p>✔ No parentheses  needed for conditions. instead of .  </p><div><pre><code></code></pre></div><p>✔  loops iterate <strong>directly over lists/arrays</strong>. loops work like JavaScript.  </p><h2><strong>3. Functions &amp; Lambda Expressions</strong></h2><div><pre><code></code></pre></div><p>✔  replaces ., just indentation.  </p><h3><strong>Lambda (Arrow Function Equivalent)</strong></h3><div><pre><code></code></pre></div><p>✔ Equivalent to JavaScript’s arrow function:</p><h2><strong>4. Python Collections (Lists, Dicts, Sets)</strong></h2><div><table><thead><tr></tr></thead><tbody><tr></tr><tr><td><code>let obj = { key: \"value\" };</code></td><td><code>obj = {\"key\": \"value\"}  # Dictionary</code></td></tr><tr><td><code>const unique = new Set([1, 2, 3]);</code></td><td><code>unique = {1, 2, 3}  # Set</code></td></tr></tbody></table></div><div><pre><code></code></pre></div><h3><strong>Dictionaries (Like Objects)</strong></h3><div><pre><code></code></pre></div><h2><strong>5. Object-Oriented Programming (OOP) in Python</strong></h2><div><pre><code></code></pre></div><p>✔  is the  (like  in JS). is like .  </p><h2><strong>6. Python for Web Development</strong></h2><h3><strong>Django (Full-Stack Framework)</strong></h3><div><pre><code>pip django\ndjango-admin startproject myproject\n</code></pre></div><p>✔  is a batteries-included backend framework.<p>\n✔ Built-in ORM, authentication, and templating.  </p></p><h3><strong>Flask (Lightweight API Framework)</strong></h3><div><pre><code></code></pre></div><p>✔  is minimal and great for APIs.  </p><h3><strong>FastAPI (High-Performance API)</strong></h3><div><pre><code></code></pre></div><p>✔  is async-native and perfect for microservices.  </p><h3><strong>SQLite Example (Django &amp; Flask Compatible)</strong></h3><div><pre><code></code></pre></div><p>✔  is built-in, no installation needed.  </p><h2><strong>8. Asynchronous Programming in Python</strong></h2><h3><strong>Async/Await (Similar to JavaScript)</strong></h3><div><pre><code></code></pre></div><p>✔ Uses / like JavaScript. is the  equivalent of Node.js.  </p><h2><strong>9. Python Package Management</strong></h2><div><table><tbody><tr></tr><tr><td>Create Virtual Environment</td></tr><tr></tr></tbody></table></div><p>✔  for package management. () isolate dependencies.   </p><h2><strong>10. Best Practices for Python Development</strong></h2><p>Writing clean, efficient, and maintainable Python code is essential for long-term scalability. Here are the key best practices that every Python developer should follow:</p><h3><strong>Follow PEP 8 (Python Style Guide)</strong></h3><p>Python has an official style guide called , which provides conventions for writing Python code.<strong>4 spaces per indentation level</strong> (not tabs)..<strong>meaningful variable and function names</strong>. for variable and function names, and  for class names.</p><div><pre><code></code></pre></div><p>Python’s  isolate dependencies for different projects, preventing conflicts.</p><h4><strong>Creating a Virtual Environment</strong></h4><h4><strong>Activating the Virtual Environment</strong></h4><h4><strong>Deactivating the Virtual Environment</strong></h4><h3><strong>Use Type Hinting for Readable Code</strong></h3><p>Python is dynamically typed, but you can use  to improve code clarity.</p><div><pre><code></code></pre></div><p>✔ This makes the code . catch type errors.</p><h3><strong>Write Readable Docstrings</strong></h3><p>Always document your functions and classes using  ().</p><div><pre><code></code></pre></div><p>✔ Use triple quotes for multi-line docstrings.<strong>parameters, return values, and purpose</strong>.  </p><p>Python uses  for  and triple quotes () for .</p><div><pre><code></code></pre></div><div><pre><code></code></pre></div><p>✔ <strong>Use comments only where necessary</strong>—good code should be self-explanatory.<strong>Docstrings are not comments</strong>—they are for documentation and can be accessed with .  </p><h2><strong>12. Common Python Imports for Web Development</strong></h2><p>Here are some of the most common Python imports used in web development:</p><div><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table></div><div><pre><code></code></pre></div><h2><strong>13. Setting Up a  File</strong></h2><p>A  file is similar to  in Node.js—it lists dependencies for a Python project.</p><h3><strong>Creating a  File</strong></h3><div><pre><code>pip freeze  requirements.txt\n</code></pre></div><h3><strong>Installing Dependencies from </strong></h3><div><pre><code>pip  requirements.txt\n</code></pre></div><p>✔ This ensures that all team members and deployment environments have the .  </p><h2><strong>14. Writing &amp; Running Tests in Python</strong></h2><p>Python has built-in testing with , but  is another option - one that aims for simplicity.</p><div><pre><code></code></pre></div><p>✔ Use  to check expected results.</p><div><pre><code></code></pre></div><p>✔ —just use . test files named .  </p><h2><strong>15. Fetching Data with API Calls in Python</strong></h2><p>Python uses  to fetch data, similar to  in JavaScript.</p><div><pre><code></code></pre></div><p>✔  is like  in JavaScript. works the same way in both languages.</p><h3><strong>Sending Data (POST Request)</strong></h3><div><pre><code></code></pre></div><p>✔ Use  instead of  to send JSON.</p><p>Logging is essential for debugging and monitoring applications.</p><div><pre><code></code></pre></div><p>✔ Works like  but supports different log levels.  </p><div><pre><code></code></pre></div><p>✔ Saves logs for later analysis.</p><h2><strong>17. Raising &amp; Handling Errors in Python Logging</strong></h2><p>When an error occurs, Python lets you  or .</p><div><pre><code></code></pre></div><p>✔ Use  to manually trigger an error.  </p><p>Instead of crashing, <strong>log errors with a traceback</strong>:</p><div><pre><code></code></pre></div><p>✔  logs the full error traceback.</p><p>Python is a useful language for web developers, expanding your stack beyond JavaScript. Whether you’re building <strong>APIs with FastAPI, full-stack apps with Django, or automating tasks</strong>, Python makes it .</p><p>🚀  Try building a small Flask or FastAPI project today!</p><p>Python #WebDev #Django #Flask #FastAPI  </p><p>A fast-paced guide to Python for web developers! Learn how to use Python for full-stack development, APIs, databases, async programming, and more. 🚀  </p><h2>\n  \n  \n  TLDR – Highlights for Skimmers\n</h2><ul><li>Python syntax is simpler than JavaScript—no semicolons, indentation replaces {}.</li><li>const does not exist in Python; uppercase variables are used for constants.</li><li>Lists ([]) are like arrays, but dictionaries ({}) are not JavaScript objects.</li><li>Classes &amp; objects are similar, but Python uses self instead of this.</li><li>Python async/await requires asyncio, unlike JavaScript’s built-in event loop.</li><li>Django, Flask, and FastAPI are top backend frameworks for Python web dev.</li></ul><p>💬 <strong>Do you use Python in web dev?</strong> Share your experience in the comments! </p>","contentLength":5789,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Code Optimization Strategies for Game Development 🔥","url":"https://dev.to/codewithshahan/code-optimization-strategies-for-game-development-2n0e","date":1739684819,"author":"Programming with Shahan","guid":560,"unread":true,"content":"<p>Game development is a battlefield. Either you optimize, or you lose. Period.</p><p>I don’t care if you’re an experienced developer with 10 years of experience or 1 year of experience. If you want to make games that WORK, games people respect—you need to understand . </p><p>Players demand smooth gameplay, high-quality visuals, and a flawless experience across every device. If your game stutters, crashes, or loads slower than a snail? You’re done. </p><p>Optimization isn’t magic. It’s the foundation of smooth gameplay, fast loading, and stable performance. Without it, your game will lag, crash, and be forgotten faster than you can say “game over.”  </p><p>But don’t worry. In this article, I will share four effective strategies to help you with that. </p><h2>\n  \n  \n  Effective Strategies for Performance Optimization\n</h2><p>🤸‍♂️ What Is Optimization? Optimization means making your game run as fast and smooth as possible. SIMPLE.</p><p>When you optimize your game, you:  </p><ol><li><strong>🖥️ Make the game work on weaker computers or phones.</strong></li><li><strong>💉 Prevent lag and crashes.</strong></li></ol><h2><strong>Rule 1: Memory Management</strong></h2><p>When you’re developing a game, memory is your most valuable resource.</p><p>Every player movement, every enemy on the screen, every explosion needs a little piece of memory to function. Unfortunately, </p><p>If you don’t manage memory properly, your game can get slow, laggy, or even crash. That’s why memory management is a critical skill every game developer needs. Let’s break it down step by step, with detailed examples in Python.</p><h3><strong>Strategy #1: Memory Pooling</strong></h3><p>This strategy is simple: reuse Objects Instead of Creating New Ones** Memory pooling is like recycling for your game. Instead of creating new objects every time you need one, you reuse objects you’ve already created.  </p><p>Creating and destroying objects repeatedly takes up time and memory. Let's say you are building a shooting game where the player fires 10 bullets per second. If you create a new bullet for each shot, your game could quickly slow down.  </p><p>Here’s how you can implement memory pooling for bullets in a shooting game:</p><div><pre><code></code></pre></div><ol><li>The  Class: Defines what a bullet does and keeps track of whether it’s active (in use) or not.\n</li><li>The : A list of 10 reusable bullets.\n</li><li>The  Function: Finds an inactive bullet, reuses it, and sets its position.\n</li><li>Recycling Bullets: When you’re done with a bullet, you reset it so it can be reused.\n</li></ol><h3><strong>Strategy #2. Data Structure Optimization</strong></h3><p>The way you store your data can make or break your game’s performance. Choosing the wrong data structure is like trying to carry water in a leaky bucket—it’s inefficient and messy.  </p><p>Let’s say you’re making a game for four players, and you want to keep track of their scores. You could use a list, but a fixed-size array is more efficient because it uses less memory.</p><div><pre><code></code></pre></div><ol><li> Creates a fixed-size array of integers ().\n</li><li> You can’t accidentally add or remove elements, which prevents bugs and saves memory.\n</li><li> Updating scores is quick and uses minimal resources.\n</li></ol><h3><strong>Strategy #3. Memory Profiling</strong></h3><p>Even if your code seems perfect, hidden memory problems can still exist. Memory profiling helps you monitor how much memory your game is using and find issues like memory leaks.  </p><p>Python has a built-in tool called  that tracks memory usage. Here’s how to use it:</p><div><pre><code></code></pre></div><ol><li> begins monitoring memory usage.\n</li><li> Create a large list to use up memory.\n</li><li> Get the current and peak memory usage, converting it to megabytes for readability.\n</li><li> ends the tracking session.\n</li></ol><p>Now it’s your turn to practice these strategies and take your game development skills to the next level!</p><h2><strong>Rule 2: Asset Streaming (Load Only What You Need)</strong></h2><p>If you load the entire world at once, your game will choke and die. You don’t need that drama. Instead, <strong>stream assets as the player needs them</strong>. This is called asset streaming. </p><p>For instance, inside your game, you may have a huge open-world with forests, deserts, and cities. Why load all those levels at once when the player is only in the forest? Makes no sense, right? Load  and keep your game lean, fast, and smooth.</p><h3><strong>Strategy #1: Segment and Prioritize</strong></h3><p>Let’s break this down with an example. Your player is exploring different levels: Forest, Desert, and City. We’ll only load a level when the player enters it.</p><p><em>Here’s how to make it work in Python:</em></p><div><pre><code></code></pre></div><ol><li> Each level has a name (e.g., Forest) and a “loaded” status. If it’s loaded, it doesn’t load again.\n</li><li> The  function finds the level the player wants to enter and loads it only if it hasn’t been loaded yet.\n</li><li> Levels not visited don’t waste memory. The game runs smoothly because it only focuses on what the player needs.</li></ol><p>This is efficiency at its finest. <strong>No wasted memory, no wasted time.</strong> Your player moves; your game adapts. That’s how you dominate.  </p><h3><strong>Strategy #2: Asynchronous Loading (No Waiting Allowed)</strong></h3><p>Nobody likes waiting. Freezing screens? Laggy loading? It’s amateur hour. You need —this loads assets in the background while your player keeps playing.  </p><p>Imagine downloading a huge map while still exploring the current one. Your game keeps moving, the player stays happy.</p><p>Here’s how to simulate asynchronous loading in Python:</p><div><pre><code></code></pre></div><ol><li> The  module creates a new thread to load assets without freezing the main game.\n</li><li> The  function fakes the loading time to mimic how it works in a real game.\n</li><li> The player can continue playing while the new level or asset loads in the background.\n</li></ol><p>With asynchronous loading, <strong>your player stays in the zone</strong>, and your game feels seamless. Pro-level stuff.</p><h3><strong>Strategy 3: Level of Detail (LOD) Systems – Be Smart About Quality</strong></h3><p>Not everything in your game needs to look like it’s been rendered by a Hollywood studio. If an object is far away, lower its quality. It’s called , and it’s how you keep your game’s performance sharp.  </p><p><strong>Example: Using LOD for a Tree</strong></p><p>Here’s a Python simulation of switching between high and low detail:</p><div><pre><code></code></pre></div><ol><li> The  property determines how far the tree is from the player.\n</li><li> If the tree is close, render it in high detail. If it’s far, use low detail to save memory and processing power.\n</li><li> The player doesn’t notice the difference, but your game runs smoother and faster.\n</li></ol><p>This is how you keep the balance between beauty and performance. Your game looks stunning up close but doesn’t waste resources on faraway objects.</p><ol><li> Only load what you need, when you need it. No wasted memory.\n</li><li> Smooth gameplay keeps players engaged and avoids frustration.\n</li><li> These techniques are how AAA games stay fast and responsive.\n</li></ol><p> Go apply these strategies, keep your game lean, and make sure your players never even think about lag.</p><h2><strong>Rule 3: Frame Rate Stabilization</strong></h2><p>The frame rate is how many pictures (frames) your game shows per second. If it’s unstable, your game will stutter and feel broken.  </p><p>The secret? Keep the workload for each frame consistent.  </p><p>🚦Here’s how you can control the timing in a game loop:</p><div><pre><code></code></pre></div><ul><li>⚖️ The game updates at a steady rate (60 times per second).\n</li><li>🪂 This make smooth gameplay, no matter how slow or fast the computer is.\n</li></ul><ul><li>Optimize Rendering Paths: Fewer draw calls. Smarter culling. Simplicity wins.</li><li>Dynamic Resolution Scaling: When the pressure’s on, scale down resolution to maintain the frame rate. Players won’t even notice.</li><li>Fixed Time Step: Keep your physics and logic consistent. Frame rate fluctuations shouldn’t mean chaos.</li></ul><h2><strong>Rule 4: GPU and CPU Optimization</strong></h2><p>Your computer has two main processors:  </p><ol><li> Handles logic, like moving a character or calculating scores.\n</li><li> Handles graphics, like drawing your game world.\n</li></ol><p>👇 Here's what you have to do for GPU/CPU optimization:</p><p>Profile Everything: Use tools to pinpoint bottlenecks and strike hard where it hurts.\nShader Optimization: Shaders are resource hogs. Simplify them, streamline them, and cut the fat.<p>\nMultithreading: Spread tasks across CPU cores. Don’t overload one and leave the others idle.</p></p><p>If one is working too hard while the other is idle, your game will lag.  </p><p><strong>Solution? Multithreading.</strong>\nLet’s split tasks between two threads:</p><div><pre><code></code></pre></div><ul><li>🎰 One thread handles logic.\n</li><li>🛣️ Another thread handles graphics.\n</li><li>⚖️ This balances the workload and prevents bottlenecks.\n</li></ul><p>Optimization isn’t just for “smart” people. It’s simple if you take it step by step:  </p><ol><li><strong>Manage memory like a pro.</strong> Don’t waste it.\n</li><li> Load only what you need.\n</li><li><strong>Keep the frame rate stable.</strong> No stuttering.\n</li><li> Use the CPU and GPU wisely.\n</li></ol><p>Start optimizing NOW. Your future self will thank you.  </p>","contentLength":8333,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Automating Daily arXiv Paper Summaries with Slack Notifications","url":"https://dev.to/m_sea_bass/automating-daily-arxiv-paper-summaries-with-slack-notifications-1kp8","date":1739683607,"author":"M Sea Bass","guid":559,"unread":true,"content":"<p>This post is a follow-up to the <a href=\"https://dev.to/m_sea_bass/automating-daily-arxiv-paper-summaries-and-slack-notifications-843\">previous article</a>. It turns out there’s a slight delay before the latest papers show up in the arXiv API. Because of this delay, the same paper can sometimes appear the next day.</p><p>To fix this, we’re going to record the timestamp of the last retrieved paper and then only fetch new papers each day.</p><p>We’ll store the timestamp of the latest paper in Amazon S3 so we can both update and retrieve it later. For this, you’ll need to install . In the  folder we created previously, run:</p><p>Next, zip the folder again and upload it as a new version of your Lambda layer:</p><div><pre><code>zip  ./upload.zip ./python/</code></pre></div><p>Then, update your Lambda function to use this new layer version.</p><p>You’ll also need an S3 bucket ready in advance. In this example, we simply created one with the default settings.</p><p>Below is the fully revised code in English, including the new functions to update and retrieve the timestamp from S3. Note that we set  as an environment variable.</p><div><pre><code></code></pre></div><p>By saving the timestamp in S3, your script won’t process the same paper entries each day, and if no new papers appear, the script will skip generating summaries. This helps reduce unnecessary API usage and costs.</p>","contentLength":1177,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GaussianBlur in PyTorch (2)","url":"https://dev.to/hyperkai/gaussianblur-in-pytorch-2-1bj2","date":1739681259,"author":"Super Kai (Kazuya Ito)","guid":558,"unread":true,"content":"<div><pre><code></code></pre></div>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"GaussianBlur in PyTorch (1)","url":"https://dev.to/hyperkai/gaussianblur-in-pytorch-1-3ndn","date":1739680552,"author":"Super Kai (Kazuya Ito)","guid":557,"unread":true,"content":"<ul><li>The 1st argument for initialization is (Optional-Type: or /()):\n*Memos:\n\n<ul><li>A tuple/list must be the 1D with 1 or 2 elements.</li><li>A single value( or ()) means <code>[kernel_size, kernel_size]</code>.</li></ul></li><li>The 2nd argument for initialization is (Optional-Default:-Type:,  or /( or )):\n*Memos:\n\n<ul><li>It's  so it must be .</li><li>A tuple/list must be the 1D with 1 or 2 elements.</li><li>A single value(,  or ( or )) means .</li></ul></li><li>The 1st argument is (Required-Type: or ()):\n*Memos:\n\n<ul><li>A tensor must be 2D or 3D.</li></ul></li></ul><div><pre><code></code></pre></div>","contentLength":451,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Weekly Challenge: Counting the XOR","url":"https://dev.to/simongreennet/weekly-challenge-counting-the-xor-4hhc","date":1739679780,"author":"Simon Green","guid":556,"unread":true,"content":"<p>Each week Mohammad S. Anwar sends out <a href=\"https://theweeklychallenge.org/\" rel=\"noopener noreferrer\">The Weekly Challenge</a>, a chance for all of us to come up with solutions to two weekly tasks. My solutions are written in Python first, and then converted to Perl. It's a great way for us all to practice some coding.</p><p>You are given two array of strings,  and .</p><p>Write a script to return the count of common strings in both arrays.</p><p>The tasks and examples don't mention what to do if a string appears more than once in both arrays. I've made the assumption that we only need to return it once.</p><p>For the command line input, I take two strings that are space separated as shown in the example.</p><p>In Python this is a one liner. I turn the lists into sets (which only has unique values) and take the length of the intersection of these two sets.</p><div><pre><code></code></pre></div><p>Perl does not have sets or intersections built in. For the Perl solution, I turn both strings into a hash with the key being the strings. I then iterate through the keys of the first hash to see if they appear in the second hash. If they do, I increment the  variable.</p><div><pre><code></code></pre></div><div><pre><code>./ch-1.py \n2\n\n./ch-1.py \n1\n\n./ch-1.py \n0\n</code></pre></div><p>You are given an encoded array and an initial integer.</p><p>Write a script to find the original array that produced the given encoded array. It was encoded such that <code>encoded[i] = orig[i] XOR orig[i + 1]</code>.</p><p>This is relatively straight forward. For the command line input, I take the last value as the  integer, and the rest as the  integers.</p><p>For this task, I create the  list (array in Perl) with the  value. I then iterate over each item in the  list and takes the exclusive-or of it and the last value in the  list.</p><div><pre><code></code></pre></div><div><pre><code>./ch-2.py 1 2 3 1\n1, 0, 2, 1]\n\n./ch-2.py 6 2 7 3 4\n4, 2, 0, 7, 4]\n</code></pre></div>","contentLength":1646,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kay Hayen: Nuitka this week #16","url":"https://nuitka.net/posts/nuitka-this-week-16.html","date":1739574000,"author":"","guid":485,"unread":true,"content":"<p>Hey Nuitka users! This started out as an idea of a weekly update, but\nthat hasn’t happened, and so we will switch it over to just writing up\nwhen something interesting happens and then push it out relatively\nimmediately when it happens.</p><h2>Nuitka Onefile Gets More Flexible:  and </h2><p>We’ve got a couple of exciting updates to Nuitka’s onefile mode that\ngive you more control and flexibility in how you deploy your\napplications. These enhancements stem from real-world needs and\ndemonstrate Nuitka’s commitment to providing powerful and adaptable\nsolutions.</p><h3>Taking Control of Onefile Unpacking: </h3><p>Onefile mode is fantastic for creating single-file executables, but the\nmanagement of the unpacking directory where the application expands has\nsometimes been a bit… opaque. Previously, Nuitka would decide whether\nto clean up this directory based on whether the path used\nruntime-dependent variables. This made sense in theory, but in practice,\nit could lead to unexpected behavior and made debugging onefile issues\nharder.</p><p>Now, you have complete control! The new  option\nlets you explicitly specify what happens to the unpacking directory:</p><ul><li><p><code></code>: This is the default behavior. Nuitka\nwill remove the unpacking directory unless runtime-dependent values\nwere used in the path specification. This is the same behavior as\nprevious versions.</p></li><li><p><code></code>: The unpacking directory is \nremoved and becomes a persistent, cached directory. This is useful\nfor debugging, inspecting the unpacked files, or if you have a use\ncase that benefits from persistent caching of the unpacked data. The\nfiles will remain available for subsequent runs.</p></li><li><p><code></code>: The unpacking directory \nremoved after the program exits.</p></li></ul><p>This gives you the power to choose the behavior that best suits your\nneeds. No more guessing!</p><h3>Relative Paths with </h3><p>Another common request, particularly from users deploying applications\nin more restricted environments, was the ability to specify the onefile\nunpacking directory  to the executable itself. Previously, you\nwere limited to absolute paths or paths relative to the user’s temporary\ndirectory space.</p><p>We’ve introduced a new variable, , that you can use in\nthe  option. This variable is dynamically\nreplaced at runtime with the full path to the directory containing the\nonefile executable.</p><div><div><pre></pre></div></div><p>This would create a directory named  the same\ndirectory as the  (or  on Linux/macOS)\nand unpack the application there. This is perfect for creating truly\nself-contained applications where all data and temporary files reside\nalongside the executable.</p><h3>Nuitka Commercial and Open Source</h3><p>These features, like many enhancements to Nuitka, originated from a\nrequest by a Nuitka commercial customer. This highlights the close\nrelationship between the commercial offerings and the open-source core.\nWhile commercial support helps drive development and ensures the\nlong-term sustainability of Nuitka, the vast majority of features are\nmade freely available to all users.</p><p>This change will be in 2.7 and is currently</p><p>We encourage you to try out these new features and let us know what you\nthink! As always, bug reports, feature requests, and contributions are\nwelcome on <a href=\"https://github.com/Nuitka/Nuitka/issues\">GitHub</a>.</p>","contentLength":3127,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Django Weblog: DjangoCongress JP 2025 Announcement and Live Streaming!","url":"https://www.djangoproject.com/weblog/2025/feb/14/djangocongress-jp-2025-announcement-and-livestream/","date":1739571130,"author":"","guid":169,"unread":true,"content":"<p>It will be streamed on the following YouTube Live channels:</p><p>This year there will be talks not only about Django, but also about FastAPI and other asynchronous web topics. There will also be talks on Django core development, Django Software Foundation (DSF) governance, and other topics from around the world. Simultaneous translation will be provided in both English and Japanese.</p><ul><li>The Async Django ORM: Where Is it?</li><li>Speed at Scale for Django Web Applications</li><li>Implementing Agentic AI Solutions in Django from scratch</li><li>Diving into DSF governance: past, present and future</li></ul><ul><li>Getting Knowledge from Django Hits: Using Grafana and Prometheus</li><li>Culture Eats Strategy for Breakfast: Why Psychological Safety Matters in Open Source</li><li>µDjango. The next step in the evolution of asynchronous microservices technology.</li></ul><p>A public viewing of the event will also be held in Tokyo. A reception will also be held, so please check the following connpass page if you plan to attend.</p>","contentLength":948,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Eli Bendersky: Decorator JITs - Python as a DSL","url":"https://eli.thegreenplace.net/2025/decorator-jits-python-as-a-dsl/","date":1739569771,"author":"","guid":168,"unread":true,"content":"<p>Spend enough time looking at Python programs and packages for machine learning,\nand you'll notice that the \"JIT decorator\" pattern is pretty popular. For\nexample, this JAX snippet:</p><div><pre></pre></div><div><pre></pre></div><p>In both cases, the function decorated with  doesn't get executed by the\nPython interpreter in the normal sense. Instead, the code inside is more like\na DSL (Domain Specific Language) processed by a special purpose compiler built\ninto the library (JAX or Triton). Another way to think about it is that Python\nis used as a  to describe computations.</p><p>In this post I will describe some implementation strategies used by libraries to\nmake this possible.</p><div><h2>Preface - where we're going</h2><p>The goal is to explain how different kinds of  decorators work by using\na simplified, educational example that implements several approaches from\nscratch. All the approaches featured in this post will be using this flow:</p> Expr IR --&gt; LLVM IR --&gt; Execution\" /&gt; Expr IR --&gt; LLVM IR --&gt; Execution\" class=\"align-center\" src=\"https://eli.thegreenplace.net/images/2025/decjit-python.png\" /&gt;\n<p>These are the steps that happen when a Python function wrapped with\nour educational  decorator is called:</p><ol><li>The function is translated to an \"expression IR\" - .</li><li>This expression IR is converted to LLVM IR.</li><li>Finally, the LLVM IR is JIT-executed.</li></ol><p>First, let's look at the  IR. Here we'll make a big simplification -\nonly supporting functions that define a single expression, e.g.:</p><div><pre></pre></div><p>Naturally, this can be easily generalized - after all, LLVM IR can be used to\nexpress fully general computations.</p><p>Here are the  data structures:</p><div><pre></pre></div><p>To convert an  into LLVM IR and JIT-execute it, we'll use this function:</p><div><pre></pre></div><p>It uses the  class to actually generate LLVM IR from .\nThis process is straightforward and covered extensively in the resources I\nlinked to earlier; take a look at <a href=\"https://github.com/eliben/code-for-blog/blob/main/2025/decjit/exprcode.py\">the full code here</a>.</p><p>My goal with this architecture is to make things simple, but .\nOn one hand - there are several simplifications: only single expressions are\nsupported, very limited set of operators, etc. It's very easy to extend this!\nOn the other hand, we could have just trivially evaluated the \nwithout resorting to LLVM IR; I do want to show a more complete compilation\npipeline, though, to demonstrate that an arbitrary amount of complexity can\nbe hidden behind these simple interfaces.</p><p>With these building blocks in hand, we can review the strategies used by\n decorators to convert Python functions into s.</p></div><div><p>Python comes with powerful code reflection and introspection capabilities out\nof the box. Here's the  decorator:</p><div><pre></pre></div><p>This is a standard Python decorator. It takes a function and returns another\nfunction that will be used in its place ( ensures that\nfunction attributes like the name and docstring of the wrapper match the\nwrapped function).</p><div><pre></pre></div><p>After  is applied to , what  holds is the\nwrapper. When  is called, the wrapper is invoked with\n.</p><p>The wrapper obtains the AST of the wrapped function, and then uses\n to convert this AST into an :</p><div><pre></pre></div><p>When  finishes visiting the AST it's given, its\n field will contain the  representing the function's\nreturn value. The wrapper then invokes  with this .</p><p>Note how our decorator interjects into the regular Python execution process.\nWhen  is called, instead of the standard Python compilation and\nexecution process (code is compiled into bytecode, which is then executed\nby the VM), we translate its code to our own representation and emit LLVM from\nit, and then JIT execute the LLVM IR. While it seems kinda pointless in this\nartificial example, in reality this means we can execute the function's code\nin any way we like.</p><div><h3>AST JIT case study: Triton</h3><p>This approach is almost exactly how the Triton language works. The body of a\nfunction decorated with  gets parsed to a Python AST, which then\n- through a series of internal IRs - ends up in LLVM IR; this in turn is lowered\nto <a href=\"https://docs.nvidia.com/cuda/parallel-thread-execution/\">PTX</a> by the\n<a href=\"https://llvm.org/docs/NVPTXUsage.html\">NVPTX LLVM backend</a>.\nThen, the code runs on a GPU using a standard CUDA pipeline.</p><p>Naturally, the subset of Python that can be compiled down to a GPU is limited;\nbut it's sufficient to run performant kernels, in a language that's much\nfriendlier than CUDA and - more importantly - lives in the same file with the\n\"host\" part written in regular Python. For example, if you want testing and\ndebugging, you can run Triton in \"interpreter mode\" which will just run the\nsame kernels locally on a CPU.</p><p>Note that Triton lets us import names from the  package\nand use them inside kernels; these serve as the  for the language\n- special calls the compiler handles directly.</p></div></div><div><p>Python is a fairly complicated language with  of features. Therefore,\nif our JIT has to support some large portion of Python semantics, it may make\nsense to leverage more of Python's own compiler. Concretely, we can have it\ncompile the wrapped function all the way <a href=\"https://github.com/python/cpython/blob/main/InternalDocs/interpreter.md\">to bytecode</a>,\nand start our translation from there.</p><p>Here's the  decorator that does just this :</p><div><pre></pre></div><p>The Python VM is a stack machine; so we emulate a stack to convert the\nfunction's bytecode to  IR (a bit like an <a href=\"https://en.wikipedia.org/wiki/Reverse_Polish_notation\">RPN evaluator</a>).\nAs before, we then use our  utility function to lower\n to LLVM IR and JIT execute it.</p><p>Using this JIT is as simple as the previous one - just swap \nfor :</p><div><pre></pre></div><div><h3>Bytecode JIT case study: Numba</h3><p><a href=\"https://numba.pydata.org/\">Numba</a> is a compiler for Python itself. The idea\nis that you can speed up specific functions in your code by slapping a\n decorator on them. What happens next is similar in spirit to\nour simple , but of course much more complicated because it\nsupports a very large portion of Python semantics.</p><p>Numba uses the Python compiler to emit bytecode, just as we did; it then\nconverts it into its own IR, and then to LLVM using .</p><p>By starting with the bytecode, Numba makes its life easier (no need to rewrite\nthe entire Python compiler). On the other hand, it also makes some analyses\n, because by the time we're in bytecode, a lot of semantic information\nexisting in higher-level representations is lost. For example, Numba has to\nsweat a bit to recover control flow information from the bytecode (by\nrunning it through a special interpreter first).</p></div></div><div><p>The two approaches we've seen so far are similar in many ways - both rely on\nPython's introspection capabilities to compile the source code of the JIT-ed\nfunction to some extent (one to AST, the other all the way to bytecode), and\nthen work on this lowered representation.</p><p>The tracing strategy is very different. It doesn't analyze the source code of\nthe wrapped function at all - instead, it  its execution by means of\nspecially-boxed arguments, leveraging overloaded operators and functions, and\nthen works on the generated trace.</p><p>The code implementing this for our smile demo is surprisingly compact:</p><div><pre></pre></div><p>Each runtime argument of the wrapped function is assigned a , and\nthat is placed in a , a placeholder class which lets us\ndo operator overloading:</p><div><pre></pre></div><p>The remaining key function is :</p><div><pre></pre></div><p>To understand how this works, consider this trivial example:</p><div><pre></pre></div><p>After the decorated function is defined,  holds the wrapper function\ndefined inside . When  is called, the wrapper runs:</p><ol><li>For each argument of  itself (that is  and ), it creates\na new  holding a . This denotes a named variable in\nthe  IR.</li><li>It then calls the wrapped function, passing it the boxes as runtime\nparameters.</li><li>When (the wrapped)  runs, it invokes . This is caught by the overloaded\n operator of , and it creates a new  with\nthe s representing  and  as children. This\n is then returned .</li><li>The wrapper unboxes the returned  and passes it to\n to emit LLVM IR from it and JIT execute it with the\nactual runtime arguments of the call: .</li></ol><p>This might be a little mind-bending at first, because there are two different\nexecutions that happen:</p><ul><li>The first is calling the wrapped  function itself, letting the Python\ninterpreter run it as usual, but with special arguments that build up the IR\ninstead of doing any computations. This is the .</li><li>The second is lowering this IR our tracing step built into LLVM IR and then\nJIT executing it with the actual runtime argument values ; this is\nthe .</li></ul><p>This tracing approach has some interesting characteristics. Since we don't\nhave to analyze the source of the wrapped functions but only trace through\nthe execution, we can \"magically\" support a much richer set of programs, e.g.:</p><div><pre></pre></div><p>This  with our basic . Since Python variables are\nplaceholders (references) for values, our tracing step is oblivious to them - it\nfollows the flow of values. Another example:</p><div><pre></pre></div><p>This also just works! The created  will be a long chain of \nadditions of 's runtime values through the loop, added to the \nfor .</p><p>This last example also leads us to a limitation of the tracing approach; the\nloop cannot be  - it cannot depend on the function's arguments,\nbecause the tracing step has no concept of runtime values and wouldn't know\nhow many iterations to run through; or at least, it doesn't know this unless\nwe want to perform the tracing run for every runtime execution .</p><div><h3>Tracing JIT case study: JAX</h3><p>The <a href=\"https://jax.readthedocs.io/en/latest/\">JAX ML framework</a> uses a tracing\napproach very similar to the one described here. The first code sample in this\npost shows the JAX notation. JAX cleverly wraps Numpy with its own version which\nis traced (similar to our , but JAX calls these boxes \"tracers\"),\nletting you write regular-feeling Numpy code that can be JIT optimized and\nexecuted on accelerators like GPUs and TPUs via <a href=\"https://github.com/openxla\">XLA</a>. JAX's tracer builds up an underlying IR (called\n<a href=\"https://jax.readthedocs.io/en/latest/jaxpr.html\">jaxpr</a>) which can then be\nemitted to XLA ops and passed to XLA for further lowering and execution.</p><p>For a fairly deep overview of how JAX works, I recommend reading the\n<a href=\"https://jax.readthedocs.io/en/latest/autodidax.html\">autodidax doc</a>.</p><p>As mentioned earlier, JAX has <a href=\"https://jax.readthedocs.io/en/latest/jit-compilation.html\">some limitations</a>\nwith things like data-dependent control flow in native Python. This won't work,\nbecause there's control flow\nthat depends on a runtime value ():</p><div><pre></pre></div><p>When  is executed, JAX will throw an exception, saying something\nlike:</p><blockquote>\nThis concrete value was not available in Python because it depends on the\nvalue of the argument count.</blockquote><p>As a remedy, JAX has its\nown built-in intrinsics from the <a href=\"https://jax.readthedocs.io/en/latest/jax.lax.html\">jax.lax package</a>.\nHere's the example rewritten in a way that actually works:</p><div><pre></pre></div><p> (and many other built-ins in the  package) is something JAX\ncan trace through, generating a corresponding XLA operation (XLA has support for\n<a href=\"https://openxla.org/xla/operation_semantics\">While loops</a>, to which this\n can be lowered).</p><p>The tracing approach has clear benefits for JAX as well; because it only cares\nabout the flow of values, it can handle arbitrarily complicated Python code,\nas long as the flow of values can be traced. Just like the local variables and\ndata-independent loops shown earlier, but also things like closures. This makes\nmeta-programming and templating easy .</p></div></div><div><p>The full code for this post is available <a href=\"https://github.com/eliben/code-for-blog/tree/main/2025/decjit\">on GitHub</a>.</p></div>","contentLength":10514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hugo van Kemenade: Improving licence metadata","url":"https://hugovk.dev/blog/2025/improving-licence-metadata/","date":1739545860,"author":"","guid":167,"unread":true,"content":"<p><a href=\"https://peps.python.org/pep-0639/\" target=\"_blank\" rel=\"noreferrer\">PEP 639</a> defines a spec on how to document licences\nused in Python projects.</p><p>Change  as follows.</p><p>I usually use Hatchling as a build backend, and support was added in 1.27:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Replace the freeform  field with a valid SPDX license expression, and add\n which points to the licence files in the repo. There’s often only one,\nbut if you have more than one, list them all:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Optionally delete the deprecated licence classifier:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>Then make sure to use a PyPI uploader that supports this.</p><p>pip can also show you the metadata:</p><div><pre tabindex=\"0\"><code></code></pre></div><p>A lot of work went into this. Thank you to PEP authors\n<a href=\"https://github.com/pombredanne\" target=\"_blank\" rel=\"noreferrer\">Philippe Ombredanne</a> for creating the first draft in\n2019, to <a href=\"https://github.com/cam-gerlach\" target=\"_blank\" rel=\"noreferrer\">C.A.M. Gerlach</a> for the second draft in 2021,\nand especially to <a href=\"https://karolinasurma.eu/\" target=\"_blank\" rel=\"noreferrer\">Karolina Surma</a> for getting the third\ndraft finish line and helping with the implementation.</p><p>And many projects were updated to support this, thanks to the maintainers and\ncontributors of at least:</p>","contentLength":878,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Real Python Podcast – Episode #239: Behavior-Driven vs Test-Driven Development & Using Regex in Python","url":"https://realpython.com/podcasts/rpp/239/","date":1739534400,"author":"Real Python","guid":97,"unread":true,"content":"<p>What is behavior-driven development, and how does it work alongside test-driven development? How do you communicate requirements between teams in an organization? Christopher Trudeau is back on the show this week, bringing another batch of PyCoder's Weekly articles and projects.</p>","contentLength":279,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Daniel Roy Greenfeld: Building a playing card deck","url":"https://daniel.feldroy.com/posts/2025-02-deck-of-cards","date":1739526604,"author":"","guid":166,"unread":true,"content":"<article>Today is Valentine's Day. That makes it the perfect day to write a blog post about showing how to not just build a deck of cards, but show off cards from the heart suite.</article>","contentLength":170,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bojan Mihelac: Prefixed Parameters for Django querystring tag","url":"http://code.informatikamihelac.com/en/query-string-with-prefixed-parameters/","date":1739482638,"author":"","guid":165,"unread":true,"content":"<article>An overview of Django 5.1's new querystring tag and how to add support for prefixed parameters.</article>","contentLength":95,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Peter Bengtsson: get in JavaScript is the same as property in Python","url":"http://www.peterbe.com/plog/get-in-javascript-is-the-same-as-property-in-python","date":1739450516,"author":"","guid":164,"unread":true,"content":"<article>Prefix a function, in an object or class, with `get` and then that acts as a function call without brackets. Just like Python's `property` decorator.</article>","contentLength":149,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EuroPython: EuroPython February 2025 Newsletter","url":"https://blog.europython.eu/europython-february-2025-newsletter/","date":1739435771,"author":"","guid":163,"unread":true,"content":"<p>Hope you&amp;aposre all having a fantastic February. We sure have been busy and got some exciting updates for you as we gear up for EuroPython 2025, which is taking place once again in the beautiful city of Prague. So let&amp;aposs dive right in!</p><p>EuroPython 2025 is right around the corner and our programme team is hard at work putting together an amazing lineup. But we need your help to shape the conference! We received over 572 fantastic proposals, and now it’s time for Community Voting! 🎉 If you&amp;aposve attended EuroPython before or submitted a proposal this year, you’re eligible to vote.</p><p>📢 More votes = a stronger, more diverse programme! Spread the word and get your EuroPython friends to cast their votes too.</p><p>🏃The deadline is , so don’t miss your chance!</p><p>Want to play a key role in building an incredible conference? Join our review team and help select the best talks for EuroPython 2025! Whether you&amp;aposre a Python expert or an enthusiastic community member, your insights matter.</p><p>We’d like to also thank the over 100 people who have already signed up to review! For those who haven’t done so yet, please remember to accept your Pretalx link and get your reviews in by </p><p>You can already start reviewing proposals, and each review takes as little as 5 minutes. We encourage reviewers to go through at least 20-30 proposals, but if you can do more, even better! With almost 600 submissions to pick from, your help ensures we curate a diverse and engaging programme.</p><p>🏃The deadline is Monday next week, so don’t delay!</p><p>EuroPython isn’t just present at other Python events—we actively support them too! As a community sponsor, we love helping local PyCons grow and thrive. We love giving back to the community and strengthening Python events across Europe! 🐍💙</p><p>The EuroPython team had a fantastic time at PyCon + Web in Berlin, meeting fellow Pythonistas, exchanging ideas, and spreading the word about EuroPython 2025. It was great to connect with speakers, organizers, and attendees.&nbsp;</p><p>Ever wondered how long it takes to walk from Berlin to Prague? A huge thank you to our co-organizers, Cheuk, Artur, and Cristián, for answering that in their fantastic lightning talk about EuroPython!</p><img src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXeeVCMBckwBAVXDAhKyHXq8LJVHJysbWS61RNAeilg_qHzHZgzbC1SALu5u3qS-YjyjSQoUE3zIzVCcSHNj26mzPf43RP4PgcV3iUJPzcu_gAEXO25atB6gn7ZQ8O4Pu6vGttw_MQ?key=7MRGElcwE05wjMSe8jkdrI9g\" alt=\"alt\" width=\"512\" height=\"344\"><p>We had some members of the EuroPython team at FOSDEM 2025, connecting with the open-source community and spreading the Python love! 🎉 We enjoyed meeting fellow enthusiasts, sharing insights about the EuroPython Society, and giving away the first EuroPython 2025 stickers. If you stopped by—thank you and we hope to see you in Prague this July.</p><img src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXd6Dp3RdSY2Wm04WwjDJE6NP1fW_NRCUEVZws-cdneLjGf0gvbq7WWphC8AHEwS0qJsAT6ao4Nm36N3e2QhN15S-w1Xmv1AJxEo0480IWXXwLAVhXZ_TcR5qDW31Hf40hYeDKJzyw?key=7MRGElcwE05wjMSe8jkdrI9g\" alt=\"alt\" width=\"517\" height=\"388\"><h2>🦒 Speaker Mentorship Programme</h2><p>The signups for The Speaker Mentorship Programme closed on 22nd January 2025. We’re excited to have matched 43 mentees with 24 mentors from our community. We had an increase in the number of mentees who signed up and that’s amazing! We’re glad to be contributing to the journey of new speakers in the Python community. A massive thank you to our mentors for supporting the mentees and to our mentees; we’re proud of you for taking this step in your journey as a speaker.&nbsp;</p><p>26 mentees submitted at least 1 proposal. Out of this number, 13 mentees submitted 1 proposal, 9 mentees submitted 2 proposals, 2 mentees submitted 3 proposals, 1 mentee submitted 4 proposals and lastly, 1 mentee submitted 5 proposals. We wish our mentees the best of luck. We look forward to the acceptance of their proposals.</p><p>In a few weeks, we will host an online panel session with 2–3 experienced community members who will share their advice with first-time speakers. At the end of the panel, there will be a Q&amp;A session to answer all the participants’ questions.</p><p>You can watch the recording of the previous year’s workshop here:</p><p>EuroPython is one of the largest Python conferences in Europe, and it wouldn’t be possible without our sponsors. We are so grateful for the companies who have already expressed interest. If you’re interested in sponsoring EuroPython 2025 as well, please reach out to us at <a href=\"mailto:sponsoring@europython.eu\">sponsoring@europython.eu</a>.</p><h2>🎤 EuroPython Speakers Share Their Experiences</h2><p>We asked our past speakers to share their experiences speaking at EuroPython. These videos have been published on YouTube as shorts, and we&amp;aposve compiled them into brief clips for you to watch.</p><p>A big thanks goes to Sebastian Witowski, Jan Smitka, Yuliia Barabash, Jodie Burchell, Max Kahan, and Cheuk Ting Ho for sharing their experiences.</p><p>Why You Should Submit a Proposal for EuroPython? Part 2</p><p>Why You Should Submit a Proposal for EuroPython? Part 3</p><h2>📊 EuroPython Society Board Report&nbsp;</h2><p>The EuroPython conference wouldn’t be what it is without the incredible volunteers who make it all happen. 💞 Behind the scenes, there’s also the EuroPython Society—a volunteer-led non-profit that manages the fiscal and legal aspects of running the conference, oversees its organization, and works on a few smaller projects like the grants programme. To keep everyone in the loop and promote transparency, the Board is sharing regular updates on what we’re working on.</p><p>That&amp;aposs all for now! Keep an eye on your inbox and our website for more news and announcements. We&amp;aposre counting down the days until we can come together in Prague to celebrate our shared love for Python. 🐍❤️</p><p>Cheers,The EuroPython Team</p>","contentLength":5275,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Giampaolo Rodola: psutil: drop Python 2.7 support","url":"https://gmpy.dev/blog/2025/psutil-drop-python-27-support","date":1739401200,"author":"","guid":161,"unread":true,"content":"<p>About dropping Python 2.7 support in psutil, 3 years ago\n<a href=\"https://github.com/giampaolo/psutil/issues/2014#issuecomment-969263432\">I stated</a>:</p><blockquote><p>Not a chance, for many years to come. [Python 2.7] currently represents 7-10%\nof total downloads, meaning around 70k / 100k downloads per day.</p></blockquote><p>Only 3 years later, and to my surprise, <strong>downloads for Python 2.7 dropped to\n0.36%</strong>! As such, as of psutil 7.0.0, I finally decided to drop support for\nPython 2.7!</p><p>These are downloads per month:</p><div><pre><code></code></pre></div><p>According to <a href=\"https://archive.is/wip/knzql\">pypistats.org</a> Python 2.7 downloads\nrepresents the 0.28% of the total, around 15.000 downloads per day.</p><p>Maintaining 2.7 support in psutil had become increasingly difficult, but still\npossible. E.g. I could still run tests by using <a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/setup.py#L76-L85\">old PYPI\nbackports</a>.\nGitHub Actions could still be\n<a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/.github/workflows/build.yml#L77-L112\">tweaked</a>\nto run tests and produce 2.7 wheels on Linux and macOS. Not on Windows though,\nfor which I had to use a separate service (Appveyor). Still, the amount of\nhacks in psutil source code necessary to support Python 2.7 piled up over the\nyears, and became quite big. Some disadvantages that come to mind:</p><ul><li>Having to maintain a Python compatibility layers like\n  <a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/psutil/_compat.py\">psutil/_compat.py</a>.\n  This translated in extra extra code and extra imports.</li><li>The C compatibility layer to differentiate between Python 2 and 3 (<code>#if\n  PY_MAJOR_VERSION &lt;= 3</code>, etc.).</li><li>Dealing with the string vs. unicode differences, both in Python and in C.</li><li>Inability to use modern language features, especially f-strings.</li><li>Inability to freely use s, which created a difference on how CONSTANTS\n  were exposed in terms of API.</li><li>Having to install a specific version of  and other (outdated)\n  <a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/setup.py#L76-L85\">deps</a>.</li><li>Relying on the third-party Appveyor CI service to run tests and produce 2.7\n  wheels.</li><li>Running 4 extra CI jobs on every commit (Linux, macOS, Windows 32-bit,\n  Windows 64-bit) making the CI slower and more subject to failures (we have\n  quite a bit of flaky tests).</li><li>The distribution of 7 wheels specific for Python 2.7. E.g. in the previous\n  release I had to upload:</li></ul><div><pre><code>psutil-6.1.1-cp27-cp27m-macosx_10_9_x86_64.whl\npsutil-6.1.1-cp27-none-win32.whl\npsutil-6.1.1-cp27-none-win_amd64.whl\npsutil-6.1.1-cp27-cp27m-manylinux2010_i686.whl\npsutil-6.1.1-cp27-cp27m-manylinux2010_x86_64.whl\npsutil-6.1.1-cp27-cp27mu-manylinux2010_i686.whl\npsutil-6.1.1-cp27-cp27mu-manylinux2010_x86_64.whl\n</code></pre></div><p>The removal was done in\n<a href=\"https://github.com/giampaolo/psutil/pull/2481\">PR-2841</a>, which removed around\n1500 lines of code (nice!). . In doing so, in the doc I\nstill made the promise that the 6.1.* serie will keep supporting Python 2.7\nand will receive  (no new features). It will be\nmaintained in a specific <a href=\"https://github.com/giampaolo/psutil/tree/python2\">python2\nbranch</a>. I explicitly kept\nthe\n<a href=\"https://github.com/giampaolo/psutil/blob/fbb6d9ce98f930d3d101b7df5a4f4d0f1d2b35a3/setup.py\">setup.py</a>\nscript compatible with Python 2.7 in terms of syntax, so that, when the tarball\nis fetched from PYPI, it will emit an informative error message on . The user trying to install psutil on Python 2.7 will see:</p><div><pre><code>$pip2installpsutil\nAsofversion.0.0psutilnolongersupportsPython.7.\nLatestversionsupportingPython.7ispsutil.1.X.\nInstallitwith:.\n</code></pre></div><p>As the informative message states, users that are still on Python 2.7 can still\nuse psutil with:</p><div><pre><code>pip2 install psutil==6.1.*\n</code></pre></div>","contentLength":2975,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kay Hayen: Nuitka Release 2.6","url":"https://nuitka.net/posts/nuitka-release-26.html","date":1739401200,"author":"","guid":162,"unread":true,"content":"<li><p> Path normalization to native Windows format was required\nin more places for the  variant of .</p><p>The  function doesn’t normalize to native Win32\npaths with MSYS2, instead using forward slashes. This required manual\nnormalization in additional areas. (Fixed in 2.5.1)</p></li><li><p> Fix, give a proper error when extension modules asked to\ninclude failed to be located. instead of a proper error message.\n(Fixed in 2.5.1)</p></li><li><p>Fix, files with illegal module names (containing ) in their\nbasename were incorrectly considered as potential sub-modules for\n. These are now skipped. (Fixed in 2.5.1)</p></li><li><p> Improved stability by preventing crashes when stubgen\nencounters code it cannot handle. Exceptions from it are now ignored.\n(Fixed in 2.5.1)</p></li><li><p> Addressed a crash that occurred when encountering\nassignments to non-variables. (Fixed in 2.5.1)</p></li><li><p> Fixed a regression introduced in 2.5 release that could\nlead to segmentation faults in exception handling for generators.\n(Fixed in 2.5.2)</p></li><li><p> Corrected an issue where dictionary copies of large\nsplit directories could become corrupted. This primarily affected\ninstance dictionaries, which are created as copies until updated,\npotentially causing problems when adding new keys. (Fixed in 2.5.2)</p></li><li><p> Removed the assumption that module dictionaries\nalways contain only strings as keys. Some modules, like\n on macOS, use non-string keys. (Fixed in 2.5.2)</p></li><li><p> Ensured that the  option correctly\naffects the C compilation process. Previously, only individual\ndisables were applied. (Fixed in 2.5.2)</p></li><li><p> Fixed a crash that could occur during compilation\nwhen unary operations were used within binary operations. (Fixed in\n2.5.3)</p></li><li><p> Corrected the handling of\n<code></code>, which could lead to crashes. (Fixed\nin 2.5.4)</p></li><li><p> Resolved a segmentation fault occurring at runtime\nwhen calling  with only keyword arguments.\n(Fixed in 2.5.5)</p></li><li><p> Harmless warnings generated for x64 DLLs on arm64 with\nnewer macOS versions are now ignored. (Fixed in 2.5.5)</p></li><li><p> Addressed a crash in Nuitka’s dictionary code that\noccurred when copying dictionaries due to internal changes in Python\n3.13. (Fixed in 2.5.6)</p></li><li><p> Improved onefile mode signing by applying\n to the signature of binaries, not just\napp bundles. (Fixed in 2.5.6)</p></li><li><p> Corrected an issue where too many paths were added as\nextra directories from the Nuitka package configuration. This\nprimarily affected the  package, which currently relies\non the  import hack. (Fixed in 2.5.6)</p></li><li><p> Prevented crashes on macOS when creating onefile\nbundles with Python 2 by handling negative CRC32 values. This issue\nmay have affected other versions as well. (Fixed in 2.5.6)</p></li><li><p> Restored the functionality of code provided in\n, which was no longer being applied due to a\nregression. (Fixed in 2.5.6)</p></li><li><p> Suppressed the app bundle mode recommendation when it is\nalready in use. (Fixed in 2.5.6)</p></li><li><p> Corrected path normalization when the output directory\nargument includes “~”.</p></li><li><p> GitHub Actions Python is now correctly identified as a\nHomebrew Python to ensure proper DLL resolution. (Fixed in 2.5.7)</p></li><li><p> Fixed a reference leak that could occur with\nvalues sent to generator objects. Asyncgen and coroutines were not\naffected. (Fixed in 2.5.7)</p></li><li><p> The  scan now correctly handles\ncases where both a package init file and competing Python files\nexist, preventing compile-time conflicts. (Fixed in 2.5.7)</p></li><li><p> Resolved an issue where handling string constants in\nmodules created for Python 3.12 could trigger assertions, and modules\ncreated with 3.12.7 or newer failed to load on older Python 3.12\nversions when compiled with Nuitka 2.5.5-2.5.6. (Fixed in 2.5.7)</p></li><li><p> Corrected the tuple code used when calling certain\nmethod descriptors. This issue primarily affected a Python 2\nassertion, which was not impacted in practice. (Fixed in 2.5.7)</p></li><li><p> Updated resource readers to accept multiple\narguments for <code></code>, and correctly handle\n and  as keyword-only arguments.</p></li><li><p> The platform encoding is no longer used to decode\n logs. Instead,  is used, as it is sufficient for\nmatching filenames across log lines and avoids potential encoding\nerrors. (Fixed in 2.5.7)</p></li><li><p> Requests to statically link libraries for \nare now ignored, as these libraries do not exist. (Fixed in 2.5.7)</p></li><li><p> Fixed a memory leak affecting the results of\nfunctions called via specs. This primarily impacted overloaded hard\nimport operations. (Fixed in 2.5.7)</p></li><li><p> When multiple distributions for a package are found,\nthe one with the most accurate file matching is now selected. This\nimproves handling of cases where an older version of a package (e.g.,\n) is overwritten with a different variant (e.g.,\n), ensuring the correct version is used for\nNuitka package configuration and reporting. (Fixed in 2.5.8)</p></li><li><p> Prevented a potential crash during onefile\ninitialization on Python 2 by passing the directory name directly\nfrom the onefile bootstrap, avoiding the use of  which\nmay not be fully loaded at that point. (Fixed in 2.5.8)</p></li><li><p> Preserved necessary  environment variables on\nWindows for packages that require loading DLLs from those locations.\nOnly  entries not pointing inside the installation prefix are\nremoved. (Fixed in 2.5.8)</p></li><li><p> Corrected the  check to function\nproperly when distribution names and package names differ. (Fixed in\n2.5.8)</p></li><li><p> Improved package name resolution for Anaconda\ndistributions by checking conda metadata when file metadata is\nunavailable through the usual methods. (Fixed in 2.5.8)</p></li><li><p> Normalized the downloaded gcc path to use native Windows\nslashes, preventing potential compilation failures. (Fixed in 2.5.9)</p></li><li><p> Restored static libpython functionality on Linux by\nadapting to a signature change in an unexposed API. (Fixed in 2.5.9)</p></li><li><p> Prevented  from being resurrected when a\nfinalizer is attached, resolving memory leaks that could occur with\n in the presence of exceptions. (Fixed in 2.5.10)</p></li><li><p> Suppressed the gcc download prompt that could appear during\n output on Windows systems without MSVC or with an\nimproperly installed gcc.</p></li><li><p>Ensured compatibility with monkey patched  or \nfunctions, which are used in some testing scenarios.</p></li><li><p> Improved the determinism of the JSON statistics\noutput by sorting keys, enabling reliable build comparisons.</p></li><li><p> Fixed a memory leak in  with finalizers,\nwhich could lead to significant memory consumption when using\n and encountering exceptions.</p></li><li><p> Optimized empty generators (an optimization result) to\navoid generating unused context code, eliminating C compilation\nwarnings.</p></li><li><p> Fixed a reference leak affecting the  value\nin . While typically , this could lead to\nobservable reference leaks in certain cases.</p></li><li><p> Improved handling of  and \nresurrection, preventing memory leaks with  and\n, and ensuring correct execution of  code in\ncoroutines.</p></li><li><p> Corrected the handling of  objects\nresurrecting during deallocation. While not explicitly demonstrated,\nthis addresses potential issues similar to those encountered with\ncoroutines, particularly for old-style coroutines created with the\n decorator.</p></li><li><p> Fixed a potential crash during runtime trace collection by\nensuring timely initialization of the output mechanism.</p></li>","contentLength":6936,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EuroPython Society: Board Report for January 2025","url":"https://www.europython-society.org/board-report-for-january-2025/","date":1739372917,"author":"","guid":160,"unread":true,"content":"<p>The top priority for the board in January was finishing the hiring of our event manager. We’re super excited to introduce Anežka Müller! Anežka is a freelance event manager and a longtime member of the Czech Python community. She’s a member of the Pyvec board, co-organizes PyLadies courses, PyCon CZ, Brno Pyvo, and Brno Python Pizza. She’ll be working closely with the board and OPS team, mainly managing communication with service providers. Welcome onboard! </p><p>Our second priority was onboarding teams. We’re happy that we already have the Programme team in place—they started early and launched the Call for Proposals at the beginning of January. We’ve onboarded a few more teams and are in the process of bringing in the rest.</p><p>Our third priority was improving our grant programme in order to support more events with our limited budget and to make it more clear and transparent. We went through past data, came up with a new proposal, discussed it, voted on it, and have already published it on our <a href=\"https://www.europython-society.org/changes-in-the-grants-programme-for-2025/\">blog</a>. </p><ul><li>Updating onboarding/offboarding checklists for Volunteers and Board Members</li><li>Various infrastructure updates including new website deployment and self-hosted previews for Pull Requests to the website.</li><li>Setting up EPS AWS account.</li><li>Working out the Grant Guidelines update for 2025</li><li>Attending PyConWeb and FOSDEM</li><li>Reviewing updates to the Sponsors setup and packages for 2025</li><li>More documentation, sharing know-how and reviewing new proposals.</li></ul><ul><li>Brand strategy: Analysis of social media posts from previous years and web analytics. Call with a European open-source maintainer and a call with a local events organizer about EP content.</li><li>Comms &amp; design: Call for proposal announcements, EP 2024 video promotions, speaker mentorship, and newsletter. Video production - gathering videos from speakers, video post-production, and scheduling them on YouTube shorts, and social media.</li><li>Event management coordination: Calls with the event manager and discussions about previous events.</li><li>Grants: Work on new grant guidelines and related comms.</li><li>Team onboarding: Calls with potential comms team members and coordination.</li><li>PR: Delivering a lightning talk at FOSDEM.</li></ul><ul><li>Offboarding the old board</li><li>Onboarding new team members</li><li>Administrative work on Grants</li></ul><ul><li>Worked on the Grants proposal</li><li>Follow-up with team members</li><li>Community outreach: FOSDEM</li></ul><ul><li>Working on various infrastructure updates, mostly related to the website.</li><li>Reviewing Pull Requests for the website and the internal bot</li><li>Working on the infrastructure team proposal.</li></ul><ul><li>Timeline: Discussion with the Programme Team, and planning to do the same with the other teams.</li><li>Visa Request letter: Setup and Test Visa Request Automation for the current year</li><li>Team selection discussion with past volunteers</li></ul>","contentLength":2708,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python Morsels: Avoid over-commenting in Python","url":"https://www.pythonmorsels.com/avoid-comments/","date":1739372739,"author":"","guid":159,"unread":true,"content":"<h2>Documenting instead of commenting</h2><p>Here is a comment I would not write in my code:</p><div><pre><code></code></pre></div><p>That comment seems to describe what this code does... so why would I  write it?</p><p>I do like that comment, but I would prefer to write it as a <a href=\"https://www.pythonmorsels.com/docstrings/\" target=\"_blank\">docstring</a> instead:</p><div><pre><code></code></pre></div><p>Documentation strings are for conveying the purpose of function, class, or module, typically at a high level.\nUnlike comments, they can be read by Python's built-in  function:</p><div><pre><code></code></pre></div><p>Docstrings are also read by other documentation-oriented tools, like <a href=\"https://www.sphinx-doc.org\" target=\"_blank\">Sphinx</a>.</p><h2>Non-obvious variables and values</h2><p>Here's a potentially helpful comment:</p>","contentLength":557,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python Keywords: An Introduction","url":"https://realpython.com/python-keywords/","date":1739368800,"author":"Real Python","guid":96,"unread":true,"content":"<p>Python keywords are reserved words with specific functions and restrictions in the language. Currently, Python has thirty-five keywords and four soft keywords. These keywords are always available in Python, which means you don’t need to import them. Understanding how to use them correctly is fundamental for building Python programs.</p><p><strong>By the end of this tutorial, you’ll understand that:</strong></p><ul><li>There are  and  in Python.</li><li>You can get a list of all keywords using  from the  module.</li><li> in Python act as keywords only in specific contexts.</li><li> are keywords that have been deprecated and turned into functions in Python 3.</li></ul><p>In this article, you’ll find a basic introduction to all Python keywords and soft keywords along with other resources that will be helpful for learning more about each keyword.</p><div><p> Test your knowledge with our interactive “Python Keywords: An Introduction” quiz. You’ll receive a score upon completion to help you track your learning progress:</p><div><div><a href=\"https://realpython.com/quizzes/python-keywords/\"></a><p>In this quiz, you'll test your understanding of Python keywords and soft keywords. These reserved words have specific functions and restrictions in Python, and understanding how to use them correctly is fundamental for building Python programs.</p></div></div></div><p>Python keywords are special reserved words that have specific meanings and purposes and can’t be used for anything but those specific purposes. These keywords are always available—you’ll never have to import them into your code.</p><p>Python keywords are different from Python’s <a href=\"https://docs.python.org/3/library/functions.html\">built-in functions and types</a>. The built-in functions and types are also always available, but they aren’t as restrictive as the keywords in their usage. </p><p>An example of something you  do with Python keywords is assign something to them. If you try, then you’ll get a . You won’t get a  if you try to assign something to a built-in function or type, but it still isn’t a good idea. For a more in-depth explanation of ways keywords can be misused, check out <a href=\"https://realpython.com/invalid-syntax-python/#misspelling-missing-or-misusing-python-keywords\">Invalid Syntax in Python: Common Reasons for SyntaxError</a>.</p><p>There are <a href=\"https://docs.python.org/3/reference/lexical_analysis.html#keywords\">thirty-five keywords</a> in Python. Here’s a list of them, each linked to its relevant section in this tutorial:</p><p>Two keywords have additional uses beyond their initial use cases. The  keyword is also <a href=\"https://realpython.com/python-keywords/#the-else-keyword-used-with-loops\">used with loops</a> and <a href=\"https://realpython.com/python-keywords/#the-else-keyword-used-with-try-and-except\">with  and </a> in addition to in conditional statements. The  keyword is most commonly used in  statements, but also used <a href=\"https://realpython.com/python-keywords/#the-as-keyword-used-with-with\">with the  keyword</a>.</p><p>The list of Python keywords and soft keywords has changed over time. For example, the  and  keywords weren’t added until Python 3.7. Also, both  and  were keywords in Python 2.7 but were turned into built-in functions in Python 3 and no longer appear in the keywords list.</p><p>As mentioned above, you’ll get an error if you try to assign something to a Python keyword. Soft keywords, on the other hand, aren’t that strict. They syntactically act as keywords only in certain conditions.</p><p>This new capability was made possible thanks to the introduction of the <a href=\"https://realpython.com/python39-new-features/#a-more-powerful-python-parser\">PEG parser</a> in Python 3.9, which changed how the interpreter reads the source code.</p><p>Leveraging the PEG parser allowed for the introduction of <a href=\"https://realpython.com/structural-pattern-matching/\">structural pattern matching</a> in Python. In order to use intuitive syntax, the authors picked , , and  for the pattern matching statements. Notably,  and  are widely used for this purpose in many other programming languages.</p><p>To prevent conflicts with existing Python code that already used , , and  as variable or function names, Python developers decided to introduce the concept of soft keywords.</p><p>Currently, there are four  in Python:</p><p>You can use the links above to jump to the soft keywords you’d like to read about, or you can continue reading for a guided tour.</p><h2>Value Keywords: , , </h2><p>There are three Python keywords that are used as values. These values are <a href=\"https://python-patterns.guide/gang-of-four/singleton/\">singleton</a> values that can be used over and over again and always reference the exact same object. You’ll most likely see and use these values a lot.</p><p>There are a few terms used in the sections below that may be new to you. They’re defined here, and you should be aware of their meaning before proceeding:</p>","contentLength":4020,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EuroPython Society: Changes in the Grants Programme for 2025","url":"https://www.europython-society.org/changes-in-the-grants-programme-for-2025/","date":1739366190,"author":"","guid":158,"unread":true,"content":"<ul><li>We are increasing transparency and reducing ambiguity in the guidelines.</li><li>We would like to support more events with our limited budget</li><li>We’ve introduced caps for events in order to make sure all grants are fairly given and we can support more communities.</li><li>We’ve set aside 10% of our budget for the local community. </li></ul><p>The EPS introduced a Grant Programme in 2017. Since then, we have granted almost EUR 350k through the programme, partly via EuroPython Finaid and by directly supporting other Python events and projects across Europe. In the last two years, the Grant Programme has grown to EUR 100k per year, with even more requests coming in.</p><p>With this growth come new challenges in how to distribute funds fairly so that more events can benefit. Looking at data from the past two years, we’ve often been close to or over our budget. The guidelines haven’t been updated in a while. As grant requests become more complex, we’d like to simplify and clarify the process, and better explain it on our website.</p><p>We would also like to acknowledge that EuroPython, when traveling around Europe, has an additional impact on the host country, and we’d like to set aside part of the budget for the local community.</p><p>The Grant Programme is also a primary funding source for EuroPython Finaid. To that end, we aim to allocate 30% of the total Grant Programme budget to Finaid, an increase from the previous 25%.</p><ul><li>We’ve updated the <a href=\"https://www.europython-society.org/grants\">text on our website</a>, and split it into multiple sub-pages to make it easier to navigate. The website now includes a checklist of what we would like to see in a grant application, and a checklist for the Grants Workgroup – so that when you apply for the Grant you already know the steps that it will go through later and when you can expect an answer from us.</li><li>We looked at the data from previous years, and size and timing of the grant requests. With the growing number and size of the grants, to make it more accessible to smaller conferences and conferences happening later in the year, we decided to introduce max caps per grant and split the budget equally between the first and second half of the year. We would also explicitly split the total budget into three categories – 30% goes to the EuroPython finaid, 10% is reserved for projects in the host country. The remaining 60% of the budget goes to fund other Python Conferences. This is similar to the split in previous years, but more explicit and transparent.</li></ul><p>Using 2024 data, and the budget available for Community Grants (60% of total), we’ve simulated different budget caps and found a sweet spot at 6000EUR, where we are able to support all the requests with most of the grants being below that limit. For 2025 we expect to receive a similar or bigger number of requests.</p><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><img src=\"https://www.europython-society.org/content/images/2025/02/image-1.png\" alt=\"alt\" width=\"1418\" height=\"496\"><p>We are introducing a special 10% pool of money to be used on projects in the host country (in 2025 that’s again Czech Republic). This pool is set aside at the beginning of the year, with one caveat that we would like to deploy it in the first half of the year. Whatever is left unused goes back to the Community Pool to be used in second half of the year.</p><ul><li>Fairer Funding: By spreading our grants out during the year, conferences that happen later won’t miss out.</li><li>Easy to Follow: Clear rules and deadlines cut down on confusion about how much you can get and what it’s for.</li><li>Better Accountability: We ask for simple post-event reports so we can see where the money went and what impact it made.</li><li>Stronger Community: Funding more events grows our Python network across Europe, helping everyone learn, connect, and collaborate.</li></ul>","contentLength":3581,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quiz: Python Keywords: An Introduction","url":"https://realpython.com/quizzes/python-keywords/","date":1739361600,"author":"Real Python","guid":95,"unread":true,"content":"<p>Python keywords are reserved words with specific functions and restrictions in the language. These keywords are always available in Python, which means you don’t need to import them. Understanding how to use them correctly is fundamental for building Python programs.</p>","contentLength":269,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Zato Blog: Modern REST API Tutorial in Python","url":"https://zato.io/en/blog/modern-rest-api-tutorial-in-python.html","date":1739347200,"author":"","guid":157,"unread":true,"content":"<div>\n  2025-02-12, by Dariusz Suchojad\n<img src=\"https://upcdn.io/kW15bqq/raw/root/static/blog/authors/dsuch.webp\" alt=\"\" width=\"35\"></div><p>Great APIs don't win theoretical arguments - they just prefer to work reliably and to make developers' lives easier.</p><p>Here's a tutorial on what building production APIs is really about: creating interfaces that are practical in usage,\nwhile keeping your systems maintainable for years to come.</p>","contentLength":326,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kushal Das: pass using stateless OpenPGP command line interface","url":"https://kushaldas.in/posts/pass-using-stateless-openpgp-command-line-interface.html","date":1739337973,"author":"","guid":156,"unread":true,"content":"<p><a href=\"https://kushaldas.in/posts/using-openpgp-card-tool-git-with-git.html\">Yesterday</a> I wrote about how\nI am using a different tool for  signing and verification. Next, I\nreplaced my  usage. I have a <a href=\"https://kushaldas.in/github.com/kushaldas/password-store/compare/master...card\">small\npatch</a> to use\nstateless OpenPGP command line interface (SOP). It is an implementation\nagonostic standard for handling OpenPGP messages. You can read the whole <a href=\"https://datatracker.ietf.org/doc/draft-dkg-openpgp-stateless-cli/\">SPEC\nhere</a>.</p><pre><code>cargo install rsop rsop-oct\n</code></pre><p>And copied the bash script from my repository to the path somewhere.</p><p>The  binary from  follows the same SOP standard but uses the\ncard to signing/decryption. I stored my public key in\n<code>~/.password-store/.gpg-key</code> file, which is in turn used for encryption.</p><p>Here nothing changed related my daily  usage, except the number of time I am typing my  :)</p>","contentLength":669,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python 3.14.0 alpha 5 is out","url":"https://pythoninsider.blogspot.com/2025/02/python-3140-alpha-5-is-out.html","date":1739302860,"author":"Hugo","guid":148,"unread":true,"content":"<p>Here comes the antepenultimate alpha.</p><p><strong>This is an early developer preview of Python\n3.14</strong></p><p>Python 3.14 is still in development. This release, 3.14.0a5, is the\nfifth of seven planned alpha releases.</p><p>Alpha releases are intended to make it easier to test the current\nstate of new features and bug fixes and to test the release process.</p><p>During the alpha phase, features may be added up until the start of\nthe beta phase (2025-05-06) and, if necessary, may be modified or\ndeleted up until the release candidate phase (2025-07-22). Please keep\nin mind that this is a preview release and its use is\n recommended for production environments.</p><p>Many new features for Python 3.14 are still being planned and\nwritten. Among the new major new features and changes so far:</p><p>The next pre-release of Python 3.14 will be the penultimate alpha,\n3.14.0a6, currently scheduled for 2025-03-14.</p><p>2025-01-29 marked the start of a new lunar year, the Year of the\nSnake 🐍 (and the Year of Python?).</p><p>For centuries, π was often approximated as 3 in China. Some time\nbetween the years 1 and 5 CE, astronomer, librarian, mathematician and\npolitician Liu Xin (劉歆) calculated π as 3.154.</p><p>Around 130 CE, mathematician, astronomer, and geographer Zhang Heng\n(張衡, 78–139) compared the celestial circle with the diameter of the\nearth as 736:232 to get 3.1724. He also came up with a formula for the\nratio between a cube and inscribed sphere as 8:5, implying the ratio of\na square’s area to an inscribed circle is √8:√5. From this, he\ncalculated π as √10 (~3.162).</p><p>Third century mathematician Liu Hui (刘徽) came up with an algorithm\nfor calculating π iteratively: calculate the area of a polygon inscribed\nin a circle, then as the number of sides of the polygon is increased,\nthe area becomes closer to that of the circle, from which you can\napproximate π.</p><p>This algorithm is similar to the method used by Archimedes in the 3rd\ncentury BCE and Ludolph van Ceulen in the 16th century CE (see <a href=\"https://blog.python.org/2024/11/python-3140-alpha-2-released.html\">3.14.0a2\n  release notes</a>), but Archimedes only went up to a 96-sided polygon\n(96-gon). Liu Hui went up to a 192-gon to approximate π as 157/50 (3.14)\nand later a 3072-gon for 3.14159.</p><p>Liu Hu wrote a commentary on the book The Nine Chapters on the\nMathematical Art which included his π approximations.</p><p>In the fifth century, astronomer, inventor, mathematician,\npolitician, and writer Zu Chongzhi (祖沖之, 429–500) used Liu Hui’s\nalgorithm to inscribe a 12,288-gon to compute π between 3.1415926 and\n3.1415927, correct to seven decimal places. This was more accurate than\nHellenistic calculations and wouldn’t be improved upon for 900\nyears.</p><p>Thanks to all of the many volunteers who help make Python Development\nand these releases possible! Please consider supporting our efforts by\nvolunteering yourself or through organisation contributions to the <a href=\"https://www.python.org/psf-landing/\">Python Software\nFoundation</a>.</p><p>Regards from a remarkably snowless Helsinki,</p><p>Your release team, Hugo van KemenadeSteve Dower</p>","contentLength":2941,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"PyCoder’s Weekly: Issue #668: NumPy, Compiling Python 1.0, BytesIO, and More (Feb. 11, 2025)","url":"https://pycoders.com/issues/668","date":1739302200,"author":"","guid":155,"unread":true,"content":"<div><p> In this video course, you’ll learn how to use NumPy by exploring several interesting examples. You’ll read data from a file into an array and analyze structured arrays to perform a reconciliation. You’ll also learn how to quickly chart an analysis &amp; turn a custom function into a vectorized function.</p></div><div><p> This tutorial will help you master Python string splitting. You’ll learn to use , , and  to effectively handle whitespace, custom delimiters, and multiline text, which will level up your data parsing skills.</p></div><div><p> Python developers use Posit Package Manager to mirror public &amp; internally developed repos within their firewalls. Get reporting on known vulnerabilities to proactively address potential threats. High-security environments can even run air-gapped.</p></div><div><p> The author was recently invited with other senior devs to give a lightning talk on their personal development philosophy. This post captures those thoughts.</p></div><img src=\"https://pycoders.com/issues/668/open/feed\" width=\"1\" height=\"1\" alt=\"alt\"><p><em>[ Subscribe to 🐍 PyCoder’s Weekly 💌 – Get the best Python news, articles, and tutorials delivered to your inbox once a week <a href=\"https://pycoders.com/?utm_source=pycoders&amp;utm_medium=feed&amp;utm_campaign=footer\">&gt;&gt; Click here to learn more</a> ]</em></p>","contentLength":1084,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python Insider: Python 3.14.0 alpha 5 is out","url":"https://pythoninsider.blogspot.com/2025/02/python-3140-alpha-5-is-out.html","date":1739291158,"author":"","guid":154,"unread":true,"content":"<p>Here comes the antepenultimate alpha.</p><p><strong>This is an early developer preview of Python\n3.14</strong></p><p>Python 3.14 is still in development. This release, 3.14.0a5, is the\nfifth of seven planned alpha releases.</p><p>Alpha releases are intended to make it easier to test the current\nstate of new features and bug fixes and to test the release process.</p><p>During the alpha phase, features may be added up until the start of\nthe beta phase (2025-05-06) and, if necessary, may be modified or\ndeleted up until the release candidate phase (2025-07-22). Please keep\nin mind that this is a preview release and its use is\n recommended for production environments.</p><p>Many new features for Python 3.14 are still being planned and\nwritten. Among the new major new features and changes so far:</p><p>The next pre-release of Python 3.14 will be the penultimate alpha,\n3.14.0a6, currently scheduled for 2025-03-14.</p><p>2025-01-29 marked the start of a new lunar year, the Year of the\nSnake 🐍 (and the Year of Python?).</p><p>For centuries, π was often approximated as 3 in China. Some time\nbetween the years 1 and 5 CE, astronomer, librarian, mathematician and\npolitician Liu Xin (劉歆) calculated π as 3.154.</p><p>Around 130 CE, mathematician, astronomer, and geographer Zhang Heng\n(張衡, 78–139) compared the celestial circle with the diameter of the\nearth as 736:232 to get 3.1724. He also came up with a formula for the\nratio between a cube and inscribed sphere as 8:5, implying the ratio of\na square’s area to an inscribed circle is √8:√5. From this, he\ncalculated π as √10 (~3.162).</p><p>Third century mathematician Liu Hui (刘徽) came up with an algorithm\nfor calculating π iteratively: calculate the area of a polygon inscribed\nin a circle, then as the number of sides of the polygon is increased,\nthe area becomes closer to that of the circle, from which you can\napproximate π.</p><p>This algorithm is similar to the method used by Archimedes in the 3rd\ncentury BCE and Ludolph van Ceulen in the 16th century CE (see <a href=\"https://blog.python.org/2024/11/python-3140-alpha-2-released.html\">3.14.0a2\n  release notes</a>), but Archimedes only went up to a 96-sided polygon\n(96-gon). Liu Hui went up to a 192-gon to approximate π as 157/50 (3.14)\nand later a 3072-gon for 3.14159.</p><p>Liu Hu wrote a commentary on the book The Nine Chapters on the\nMathematical Art which included his π approximations.</p><p>In the fifth century, astronomer, inventor, mathematician,\npolitician, and writer Zu Chongzhi (祖沖之, 429–500) used Liu Hui’s\nalgorithm to inscribe a 12,288-gon to compute π between 3.1415926 and\n3.1415927, correct to seven decimal places. This was more accurate than\nHellenistic calculations and wouldn’t be improved upon for 900\nyears.</p><p>Thanks to all of the many volunteers who help make Python Development\nand these releases possible! Please consider supporting our efforts by\nvolunteering yourself or through organisation contributions to the <a href=\"https://www.python.org/psf-landing/\">Python Software\nFoundation</a>.</p><p>Regards from a remarkably snowless Helsinki,</p><p>Your release team, Hugo van KemenadeSteve Dower</p>","contentLength":2941,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Building a Python Command-Line To-Do App With Typer","url":"https://realpython.com/courses/build-command-line-todo-app-typer/","date":1739282400,"author":"Real Python","guid":94,"unread":true,"content":"<p>Building an application to manage your  can be an interesting project when you’re learning a new programming language or trying to take your skills to the next level. In this video course, you’ll build a functional to-do application for the command line using Python and <a href=\"https://typer.tiangolo.com/\">Typer</a>, which is a relatively young library for creating powerful command-line interface (CLI) applications in almost no time.</p><p>With a project like this, you’ll apply a wide set of core programming skills while building a real-world application with real features and requirements.</p><p><strong>In this video course, you’ll learn how to:</strong></p><ul><li>Build a functional  with a  in Python</li><li>Use Typer to add , , and  to your to-do app</li><li>Test your Python to-do application with Typer’s  and </li></ul>","contentLength":734,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Kushal Das: Using openpgp-card-tool-git with git","url":"https://kushaldas.in/posts/using-openpgp-card-tool-git-with-git.html","date":1739272360,"author":"","guid":153,"unread":true,"content":"<p>One of the power of Unix systems comes from the various small tools and how\nthey work together. One such new tool I am using for some time is for  &amp;  using OpenPGP and my Yubikey for the actual signing\noperation via\n<a href=\"https://crates.io/crates/openpgp-card-tool-git\">openpgp-card-tool-git</a>. I\nreplaced the standard  for this usecase with the  command from this\nproject.</p><h3>Installation &amp; configuration</h3><pre><code>cargo install openpgp-card-tool-git\n</code></pre><p>Then you will have to configuration your (in my case the global configuration) git configuration.</p><pre><code>git config --global gpg.program &lt;path to oct-git&gt;\n</code></pre><p>I am assuming that you already had it configured before for signing, otherwise\nyou have to run the following two commands too.</p><pre><code>git config --global commit.gpgsign true\ngit config --global tag.gpgsign true\n</code></pre><p>Before you start using it, you want to save the pin in your system keyring.</p><p>Use the following command.</p><p>That is it, now your  will sign the commits using  tool.</p><p>In the next blog post I will show how to use the other tools from the \n<a href=\"https://crates.io/users/hko-s\">author</a> for various different OpenPGP oeprations.</p>","contentLength":1007,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Django Weblog: DSF member of the month - Lily Foote","url":"https://www.djangoproject.com/weblog/2025/feb/10/dsf-member-of-the-month-lily-foote/","date":1739249491,"author":"","guid":152,"unread":true,"content":"<p>For February 2025, we welcome Lily Foote (<a href=\"https://fosstodon.org/@lilyf\">@lilyf</a>) as our DSF member of the month! ⭐</p><p>Lily Foote is a contributor to Django core for many years, especially on the ORM. She is currently a member of the Django 6.x <a href=\"https://docs.djangoproject.com/en/dev/internals/organization/#steering-council\">Steering Council</a> and she has been a DSF member since March 2021. \nYou can learn more about Lily by visiting <a href=\"https://github.com/LilyFoote\">her GitHub profile</a>.</p><p>Let’s spend some time getting to know Lily better!</p><h4>Can you tell us a little about yourself (hobbies, education, etc)</h4><p>My name is Lily Foote and I’ve been contributing to Django for most of my career. I’ve also recently got into Rust and I’m excited about using Rust in Python projects. When I’m not programming, I love hiking, climbing and dancing (Ceilidh)! I also really enjoying playing board games and role playing games (e.g. Dungeons and Dragons).</p><h4>How did you start using Django?</h4><p>I’d taught myself Python in my final year at university by doing <a href=\"https://projecteuler.net/\">Project Euler</a> problems and then decided I wanted to learn how to make a website. Django was the first Python web framework I looked at and it worked really well for me.</p><h4>What other framework do you know and if there is anything you would like to have in Django if you had magical powers?</h4><p>I’ve done a small amount with Flask and FastAPI. More than any new features, I think the thing that I’d most like to see is more long-term contributors to spread the work of keeping Django awesome.</p><h4>What projects are you working on now?</h4><p>The side project I’m most excited about is <a href=\"https://github.com/LilyFoote/django-rusty-templates\">Django Rusty Templates</a>, which is a re-implementation of Django’s templating language in Rust.</p><h4>Which Django libraries are your favorite (core or 3rd party)?</h4><h4>What are the top three things in Django that you like?</h4><p>Django Conferences, the mentorship program Djangonaut Space and the whole community!</p><h4>You have been a mentor multiple times with GSoC and Djangonaut Space program, what is required according to you to be a good mentor?</h4><p>I think being willing to invest time is really important. Checking in with your mentees frequently and being an early reviewer of their work. I think this helps keep their motivation up and allows for small corrections early on.</p><h4>Any advice for future contributors?</h4><p>Start small and as you get more familiar with Django and the process of contributing you can take on bigger issues. Also be patient with reviewers – Django has high standards, but is mostly maintained by volunteers with limited time.</p><p>Yes! It’s a huge honour! Since January, we’ve been meeting weekly and it feels like we’ve hardly scratched the surface of what we want to achieve. The biggest thing we’re trying to tackle is how to improve the contribution experience – especially evaluating new feature ideas – without draining everyone’s time and energy.</p><h4>You have a lot of knowledge in the Django ORM, how did you start to contribute to this part?</h4><p>I added the Greatest and Least expressions in Django 1.9, with the support of one of the core team at the time. After that, I kept showing up (especially at conference sprints) and finding a new thing to tackle.</p><h4>Is there anything else you’d like to say?</h4><p><strong>Thank you for doing the interview, Lily!</strong></p>","contentLength":3110,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Quansight Labs Blog: PEP 517 build system popularity","url":"https://labs.quansight.org/blog/pep-517-build-system-popularity","date":1739232000,"author":"","guid":150,"unread":true,"content":"<article>Analysis of PEP 517 build backends used in 8000 top PyPI packages</article>","contentLength":65,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Seth Michael Larson: Building software for connection (#2: Consensus)","url":"https://sethmlarson.dev/building-software-for-connection-consensus?utm_campaign=rss","date":1739232000,"author":"","guid":151,"unread":true,"content":"<p>In the <a href=\"http://sethmlarson.dev/building-software-for-connection-local-first\">previous article</a> we concluded that a persistent always-on internet\nconnection isn't required for software to elicit feelings of connection between humans.</p><div><div><p>Building on this conclusion: let's explore how Animal Crossing software was able to intercommunicate without requiring\na centralized server and infrastructure and the trade-offs for these design decisions.</p></div></div><h2>Distributing digital goods without the internet</h2><p>Animal Crossing has over 1,000 unique items that need to be collected\nfor a complete <a href=\"https://nookipedia.com/wiki/Catalog\">catalog</a>, including furniture, wallpapers, clothing, parasols, and carpets.\nMany of these items are quite rare or were only programmed to be accessible\nthrough an official Nintendo-affiliated distribution such as a magazine or online contest.</p><p>Beyond official distributions, it's clear Animal Crossings' designer, Katsuya Eguchi,\nwanted players to  to complete their catalogs.\nThe game incentivized trading items between towns by assigning\none “<a href=\"https://nookipedia.com/wiki/Fruit\">native fruit</a>” (Apple, Orange, Cherry, Peach, or Pear) and\nrandomly making a subset of items harder to find than others depending\non a <a href=\"https://nookipedia.com/wiki/Group\">hidden “item group” variable</a> (either A, B, or C).</p><p>Items could be exchanged between players when one player visits another town,\nbut this required physically bringing your memory card to another\nplayers' GameCube. The GameCube might have come with a handle, but the 'cube wasn't exactly a . Sharing a physical space isn't something you can do with everyone or on a regular basis.</p><div><div><p>So what did Katsuya Eguchi design for Animal Crossing? To allow for item distributions from magazines and contests and to make player-to-player item sharing easier Animal Crossing included a feature called “<a href=\"https://nookipedia.com/wiki/Secret_code\">secret codes</a>”.</p><p>This feature worked by allowing players to exchange 28-character codes with Tom Nook for items. Players could also generate codes for their friends to “send” an item from their own game to a different town. Codes could be shared by writing them on a paper note, instant message, or text message.</p></div></div><h2>The forgotten durability of offline software</h2><div><div><p>\nThis <a href=\"https://www.reddit.com/r/Gamecube/comments/1gqfbae\">Reddit comment thread</a> from the GameCube subreddit was the initial inspiration for this entire series.\nThe post is about someone's niece who just started playing Animal Crossing for the first time.\nThe Redditor asked folks to send items to their nieces' town using the secret code system.\n</p><p>This ended up surprising many folks that this system \n in a game that was over 23 years old!\nFor reference, Nintendo Wi-Fi Connection and Nintendo Network were only available for 8 and 13 years respectively.\nBelow are a handful of the comments from the thread:</p><blockquote><ul><li>“For real does this still work lol?”</li></ul></blockquote></div></div><p>It's hard not to take these comments as indicators that something is\n with internet-connected software today. What had to go wrong for a \nsystem continuing to work to ? Many consumers' \nexperience with \nsoftware products\ntoday is that they become useless e-waste after some far-away service is \ndiscontinued a few years after purchase.</p><p>My intuition from this is that software that <em>requires centralized servers and infrastructure to function</em>\nwill have shorter lifetimes than software which is offline or only\nopportunistically uses online functionality.</p><p>I don't think this is particularly insightful,\nmore dependencies always means less resilience. But if we're building software for human connection then the software\nshould optimally only be limited by the <em>availability of humans to connect</em>.</p><h2>What is centralization good for?</h2><div><div><p>Animal Crossings' secret code system is far from perfect. The system is easily abusable, as the same secret codes can be\nreused over-and-over by the same user to duplicate items without ever expiring. The only limit was that 3 codes could be used per day.</p></div></div><p>Not long after Animal Crossing's release\nthe secret code algorithm was <a href=\"https://togenyanweb.appspot.com/Yokai/eplus/eplus.html\">reverse-engineered</a> so secret codes \nfor any item could be created for any town and recipient name as if they came from an official Nintendo distribution.\nThis was possible because the secret code system relied on \"<a href=\"https://en.wikipedia.org/wiki/Security_through_obscurity\">security through obscurity</a>\".</p><p>Could  be the answer to preventing these abuses?</p><p>The most interesting property that a centralized authority approach\nprovides is : forcing everyone to play by the same rules. By storing\nthe “single source-of-truth” a central authority is able to prevent abuses\nlike the ones mentioned above.</p><p>For example, a centralized “secret code issuing server” could generate\nnew unique codes per-use and check each code's validity\nagainst a database to prevent users from generating their\nown illegitimate codes or codes being re-used multiple times.</p><p>The problem with\ncentralized consensus is it tends to be  to cover the entire software state.\nA centralized server can generate codes perfectly, but how can that same server\n that the items you're exchanging for codes were obtained legitimately? To know this\nthe server would <em>also need to track item legitimacy</em>, leading to software which requires\nan internet connection to operate.</p><p>This is optimal from a correctness perspective, but as was noted earlier,\nI suspect that if such a server was a mandatory part of the secret code system\nin Animal Crossing that the system <em>would likely not be usable today</em>.</p><p>This seems like a trade-off, <em>which future would you rather have?</em></p><h2>Redesigning Animal Crossing secret codes</h2><p>If I were designing Animal Crossings' secret code system with modern hardware, what would it look like?\nHow can we keep the offline fall-back while providing consensus and being less\nabusable, especially for official distributions.</p><p>I would likely use a <a href=\"https://en.wikipedia.org/wiki/Public-key_cryptography\">public-key cryptographic</a> system for official distributions,\nembedding a certificate that could be used to “verify” that specific secret codes\noriginated from the expected centralized entity. Codes that are accepted would be\nrecorded to prevent reusing the same code multiple times in the same town.\nUsing public-key cryptography prevents the\nsystem from being reverse-engineered to distribute arbitrary items until the certificate\nprivate key was cracked.</p><p>For sharing items between players I would implement a system where each town\ngenerated a public and private key and the public key was shared to other towns\nwhenever the software was able to, such as when a player visited the other town.\nPlayers would only be able to send items to players that they have visited\n(which for Animal Crossing <em>required physical presence</em>, more on this later!)</p><p>Each sender could store a <a href=\"https://en.wikipedia.org/wiki/Cryptographic_nonce\">nonce</a> value for\neach potential recipient. Embedding that nonce into the secret code would allow\nthe recipients' software to verify that the specific code hadn't been used yet.\nThe nonce wouldn't have to be long to avoid simple reusing of codes.</p><p>Both above systems would require much more data to be embedded into each “secret\ncode” compared to the 28-character codes from the GameCube. For this I would\nuse QR codes to embed over 2KB of data into a single QR code. Funnily enough,\nAnimal Crossing New Leaf and onwards <a href=\"https://nookipedia.com/wiki/QR_code\">use QR code technology</a> for players to share design patterns.</p><p>This design is still abusable if users can modify their software or hardware\nbut doesn't suffer from the trivial-to-exploit flaws of Animal Crossing's secret code system.</p><h2>Decentralized global consensus?</h2><div><div><p>What if we could have the best of both worlds: we want consensus\nthat is both  and . At least today, we are out of luck.</p><p>Decentralized global consensus is <a href=\"https://bitcoin.org/bitcoin.pdf\">technologically feasible</a>, but the existing solutions\n(mostly blockchains)\nare expensive (both in energy and capital) and can't handle throughput on any sort of \nmeaningful scale.</p></div></div><p>There are many other decentralized consensus systems that \nare able to form “pockets” of <em>useful peer-to-peer consensus</em> using a fraction of\nthe resources, such as email, <a href=\"https://en.wikipedia.org/wiki/BitTorrent\">BitTorrent</a>, <a href=\"https://activitypub.rocks/\">ActivityPub</a>, and <a href=\"https://nostr.com/\">Nostr</a>.\nThese systems are only possible by adding  or by only guaranteeing .</p><h2>When is global consensus needed?</h2><p>Obviously global consensus is important for certain classes of software like \nfinancial, civics, and infrastructure, but I wonder how the necessity\nof consensus in software changes for software with different risk\nprofiles.</p><p>For software which has fewer risks associated with misuse is there as much\nneed for global consensus?\nHow can  be designed to reduce risk and require\nless consensus to be effective? If global consensus and centralized \nservers become unnecessary, can we expect  to be usable \non much longer timescales, <em>essentially for as long as there are users?</em></p>","contentLength":8378,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Python Morsels: Newlines and escape sequences in Python","url":"https://www.pythonmorsels.com/newlines-and-escape-sequences/","date":1739200649,"author":"","guid":149,"unread":true,"content":"<p>This string contains a newline character:</p><div><pre><code></code></pre></div><p>That's what  represents: a newline character.</p><p>If we print this string, we'll see that  becomes an  newline:</p><p>Why does Python represent a newline as ?</p><h2>Escape sequences in Python</h2><p>Every character in a Python …</p>","contentLength":244,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Join Strings in Python","url":"https://realpython.com/python-join-string/","date":1739196000,"author":"Real Python","guid":93,"unread":true,"content":"<p>Python’s built-in string method  lets you combine string elements from an iterable into a single string, using a separator that you specify. You call  on the separator, passing the iterable of strings to join.</p><p><strong>By the end of this tutorial, you’ll understand that:</strong></p><ul><li>You use  in Python to  with a .</li><li>A  is the piece of text you want <strong>inserted between each substring</strong>.</li><li>To join list elements, you <strong>call  on a separator string</strong>, passing the list as the argument.</li><li><strong>inserts the separator between each list element</strong> to form a single string.</li><li>The  method  that is the concatenation of the elements in the iterable, separated by the specified string.</li><li>For smaller string concatenation tasks, you can use the <strong>concatenation operator ()</strong> or  instead of .</li></ul><p>Python’s built-in <a href=\"https://docs.python.org/3/library/stdtypes.html#str.join\"></a> method gives you a quick and reliable way to combine multiple strings into a single string. Whether you need to format output or assemble data for storage,  provides a clean and efficient approach for joining strings from an <a href=\"https://realpython.com/python-iterators-iterables/\">iterable</a>.</p><p>In the upcoming sections, you’ll learn the basic usage of  to concatenate strings effectively. You’ll then apply that knowledge to real-world scenarios, from building CSV files to constructing custom log outputs. You’ll also discover some surprising pitfalls and learn how to avoid them.</p><div><p> Test your knowledge with our interactive “How to Join Strings in Python” quiz. You’ll receive a score upon completion to help you track your learning progress:</p><div><div><a href=\"https://realpython.com/quizzes/python-join-string/\"></a><p>Test your understanding of Python's .join() string method for combining strings, handling edge cases, and optimizing performance.</p></div></div></div><h2>How to Join Strings in Python Using </h2><p>To use the string method , you call  on a separator string and pass an <a href=\"https://realpython.com/ref/glossary/iterable/\">iterable</a> of other strings as the argument. The method returns a single string, where it has inserted the separator string between each element of the iterable:</p><p>In this example, you joined a list of words into one sentence, separated by spaces.</p><p>At first glance, this usage might look a little backward. In many other <a href=\"https://realpython.com/python-strings/\">string operations</a>, you call the method on the main string that you want to manipulate. However, with , you call the method on the separator string, then pass the iterable of strings that you want to combine:</p><p>This example achieves the same result as the earlier one but splits the process into two steps. Defining  separately makes the code more readable and avoids the potentially odd-looking syntax of calling  directly on a short string literal.</p><div role=\"alert\"><p> Remember that  is a  method, which means that you’ll need to call it on a  string object. Keeping that in mind may help you remember why you need to call it on the separator string.</p></div><p>You rarely see code that’s written in multiple steps where you assign the separator string to a variable, like you did in the example above.</p><p>In typical usage, you call  directly on the separator string, all in one line. This approach is more concise and highlights that any valid string can be your separator, whether it’s whitespace, a dash, or a multicharacter substring.</p><h3>Join With an Empty String</h3><p>What if you don’t want any separator at all, but just want to <a href=\"https://realpython.com/python-string-concatenation/\">concatenate</a> the items? One valid approach is to use an empty string () as the separator:</p><p>This code snippet concatenates the letters in the list, forming a single string . Using an empty string as the separator is a great way to assemble strings without a delimiter between them.</p><p>Since  can take any iterable of strings—not just lists—you can even pass a string as an argument. Because strings are iterable, Python iterates over each character in that string, considering each character as a separate element:</p><p>By calling  on  and passing the string , you effectively place a comma between every single character in . This might not always be what you intend, but it’s a neat trick to keep in mind if you ever need to treat each character as a separate element.</p>","contentLength":3847,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["python"]}