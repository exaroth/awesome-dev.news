{"id":"2hUc62","title":"Blog","displayTitle":"Blog","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":12,"items":[{"title":"Bliki: Excessive Bold","url":"https://martinfowler.com/bliki/ExcessiveBold.html","date":1769610000,"author":"Martin Fowler","guid":425365,"unread":true,"content":"<p>I'm increasingly seeing a lot of technical and business writing make heavy\n  use of bold font weights, in an attempt to emphasize what the writers think is\n  important. LLMs seem to have picked up and spread this practice widely. But\n  most of this is self-defeating, the more a writer uses typographical emphasis,\n  the less power it has, quickly reaching the point where it loses all its\n  benefits.</p><p>There are various typographical tools that are used to emphasize words and\n  phrases, such as: bold, italic, capitals, and underlines. I find that bold is the one\n  that's getting most of the over-use. Using a lot of capitals is rightly\n  reviled as shouting, and when we see it used widely, it raises our doubts on\n  the quality of the underlying thinking.\n  Underlines have become the signal for hyperlinks, so I rarely see this for\n  emphasis any more. Both capitals and underlines have also been seen as rather\n  cheap forms of highlight, since we could do them with typewriters and\n  handwriting, while bold and italics were only possible after the rise of\n  word-processors. (Although I realize most of my readers are too young to\n  remember when word-processors were novel.)</p><p>Italics are the subtler form of emphasis. When I use them in a paragraph,\n  they don't leap out to the eye. This allows me to use them in long flows of text when\n  I want to set it apart, and when I use it to emphasize a phrase it only makes\n  its presence felt when I'm fully reading the text. For this reason, I prefer\n  to use italics for emphasis, but I only use it rarely, suggesting it's\n   important to put stress on\n  the word should I be speaking the paragraph (and I always try to write in the\n  <a href=\"https://martinfowler.com/bliki/SayYourWriting.html\">way that I speak</a>).</p><p>The greatest value of bold is that draws the eye to the bold text even if the\n  reader isn't reading, but glancing over the page. This is an important\n  property, but one that only works if it's used sparingly. Headings are often\n  done in bold, because the it's important to help the reader navigate a longer\n  document by skimming and looking for headings to find the section I want to read.</p><p>I rarely use bold within a prose paragraph, because of my desire to be\n  parsimonious with bold. One use I do like is to highlight unfamiliar words at\n  the point where I explain them. I got this idea from <a href=\"https://www.amazon.com/gp/product/0534981283/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0534981283&amp;linkCode=as2&amp;tag=martinfowlerc-20\">Giarratano and Riley</a>. I noticed that when the\n  unfamiliar term reappeared, I was often unsure what it meant, but glancing\n  back and finding the bold quickly reminded me. The trick here is to place the\n  bold at point of explanation, which is often, but not always, at its first\n  use. \n</p><p>A common idea is to take an important sentence and bold that, so it leaps\n  out while skimming the article. That can be worthwhile, but as ever with this\n  kind of emphasize, its effectiveness is inversely proportional to how often\n  it's used. It's also usually not the best tool for the job. Callouts usually\n  work better. They do a superior job of drawing the eye, and furthermore they don't\n  need to use the same words as in the prose text. This allows me to word the\n  callout better than it could be if it also had to fit in the flow of the\n  prose.</p><p>A marginal case is where I see bold used in first clause of each item in a\n  bulleted list. In some ways this is acting like a heading for the text in the\n  list. But we don't need a heading for every paragraph, and the presence of the\n  bullets does enough to draw the eye to the items. And bullet-lists are over\n  used too - I always try to write such things as a prose paragraph instead, as\n  prose flows much better than bullets and is thus more pleasant to read. It's\n  important to write in such a way to make it an enjoyable experience for the\n  reader - even, indeed especially, when I'm also trying to explain things for them.</p><p>While writing this, I was <b>tempted to illustrate my point</b> by using  in a paragraph,  and hopefully demonstrating\n  <b>why lots of bold loses the power to emphasize</b> and .\n  But I also wanted to <b>explain my position clearly</b>, and I felt that <b>illustrating\n  the problem</b> would thus . So I've  to a\n  . (And, yes, I  with as much bold as this.)</p>","contentLength":4118,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Assessing internal quality while coding with an agent","url":"https://martinfowler.com/articles/exploring-gen-ai/ccmenu-quality.html","date":1769529000,"author":"Martin Fowler","guid":423832,"unread":true,"content":"<p> is the maintainer of CCMenu: a Mac\n      application that shows the status of CI/CD builds in the Mac menu bar. He\n      assesses how using a coding agent affects internal code quality by adding\n      a feature using the agent, and seeing what happens to the code.\n      </p>","contentLength":272,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Constitutionality of Geofence Warrants","url":"https://www.schneier.com/blog/archives/2026/01/the-constitutionality-of-geofence-warrants.html","date":1769515307,"author":"Bruce Schneier","guid":423713,"unread":true,"content":"<p>The US Supreme Court is <a href=\"https://therecord.media/supreme-court-geofence-constitutionality\">considering</a> the constitutionality of geofence warrants.</p><blockquote><p>The case centers on the trial of Okello Chatrie, a Virginia man who pleaded guilty to a 2019 robbery outside of Richmond and was sentenced to almost 12 years in prison for stealing $195,000 at gunpoint.</p><p>Police probing the crime found security camera footage showing a man on a cell phone near the credit union that was robbed and asked Google to produce anonymized location data near the robbery site so they could determine who committed the crime. They did so, providing police with subscriber data for three people, one of whom was Chatrie. Police then searched Chatrie’s home and allegedly surfaced a gun, almost $100,000 in cash and incriminating notes.</p><p>Chatrie’s appeal challenges the constitutionality of geofence warrants, arguing that they violate individuals’ Fourth Amendment rights protecting against unreasonable searches.</p></blockquote>","contentLength":918,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Some notes on starting to use Django","url":"https://jvns.ca/blog/2026/01/27/some-notes-on-starting-to-use-django/","date":1769472000,"author":"Julia Evans","guid":424013,"unread":true,"content":"<p>Hello! One of my favourite things is starting to learn an\nOld Boring Technology that I’ve never tried before but that has been around for\n20+ years. It feels really good when every problem I’m ever going to have has\nbeen solved already 1000 times and I can just get stuff done easily.</p><p>I’ve thought it would be cool to learn a popular web framework like\nRails or Django or Laravel for a long time, but I’d never really managed to\nmake it happen. But I started learning Django to make a website a few months\nback, I’ve been liking it so far, and here are a few quick notes!</p><p>I spent some time <a href=\"https://jvns.ca/blog/2020/11/09/day-1--a-little-rails-/\">trying to learn Rails</a> in 2020,\nand while it was cool and I really wanted to like Rails (the Ruby community is great!),\nI found that if I left my Rails project alone for months, when I came\nback to it it was hard for me to remember how to get anything done because\n(for example) if it says  in your , on its own\nthat doesn’t tell you where the  routes are configured, you need to\nremember or look up the convention.</p><p>Being able to abandon a project for months or years and then come back to it is\nreally important to me (that’s how all my projects work!), and Django feels easier\nto me because things are more explicit.</p><p>In my small Django project it feels like I just have 5 main files (other\nthan the settings files): , , , , and\n, and if I want to know where something else is (like an HTML template)\nis then it’s usually explicitly referenced from one of those files.</p><p>For this project I wanted to have an admin interface to manually edit or view\nsome of the data in the database. Django has a really nice built-in admin\ninterface, and I can customize it with just a little bit of code.</p><p>For example, here’s part of one of my admin classes, which sets up which fields\nto display in the “list” view,  which field to search on, and how to order them\nby default.</p><pre><code>@admin.register(Zine)\nclass ZineAdmin(admin.ModelAdmin):\n    list_display = [\"name\", \"publication_date\", \"free\", \"slug\", \"image_preview\"]\n    search_fields = [\"name\", \"slug\"]\n    readonly_fields = [\"image_preview\"]\n    ordering = [\"-publication_date\"]\n</code></pre><p>In the past my attitude has been “ORMs? Who needs them? I can just write my own SQL queries!”.\nI’ve been enjoying Django’s ORM so far though, and I think it’s cool how Django\nuses  to represent a , like this:</p><pre><code>Zine.objects\n    .exclude(product__order__email_hash=email_hash)\n</code></pre><p>This query involves 5 tables: , , , , and .\nTo make this work I just had to tell Django that there’s a \nrelating “orders” and “products”, and another  relating\n“zines”, and “products”, so that it knows how to connect , , .</p><p>I definitely  write that query, but writing <code>product__order__email_hash</code> is\na lot less typing, it feels a lot easier to read, and honestly I think it would\ntake me a little while to figure out how to construct the query\n(which needs to do a few other things than just those joins).</p><p>I have zero concern about the performance of my ORM-generated queries so I’m\npretty excited about ORMs for now, though I’m sure I’ll find things to be\nfrustrated with eventually.</p><p>The other great thing about the ORM is migrations!</p><p>If I add, delete, or change a field in , Django will automatically\ngenerate a migration script like <code>migrations/0006_delete_imageblob.py</code>.</p><p>I assume that I could edit those scripts if I wanted, but so far I’ve just\nbeen running the generated scripts with no change and it’s been going great. It\nreally feels like magic.</p><p>I’m realizing that being able to do migrations easily is important for me right\nnow because I’m changing my data model fairly often as I figure out how I want\nit to work.</p><p>For example the <a href=\"https://docs.djangoproject.com/en/6.0/topics/db/models/\">intro to models</a>\nlists the most important common fields you might want to set when using the ORM.</p><p>After having a bad experience trying to operate Postgres and not being able to\nunderstand what was going on, I decided to run all of my small websites with\nSQLite instead. It’s been going way better, and I love being able to backup by\njust doing a  and then copying the resulting single file.</p><p>I think it should be fine because I’m expecting the site to have a few hundred\nwrites per day at most, much less than <a href=\"https://messwithdns.net/\">Mess with DNS</a>\nwhich has a lot more of writes and has been working well (though the writes are\nsplit across 3 different SQLite databases).</p><h3>built in email (and more)</h3><p>Django seems to be very “batteries-included”, which I love – if I want CSRF\nprotection, or a , or I want to send email, it’s all\nin there!</p><p>For example, I wanted to save the emails Django sends to a file in dev mode (so\nthat it didn’t send real email to real people), which was just a little bit\nof configuration.</p><p>I just put this :</p><pre><code>EMAIL_BACKEND = \"django.core.mail.backends.filebased.EmailBackend\"\nEMAIL_FILE_PATH = BASE_DIR / \"emails\"\n</code></pre><p>and then set up the production email like this in </p><pre><code>EMAIL_BACKEND = \"django.core.mail.backends.smtp.EmailBackend\"\nEMAIL_HOST = \"smtp.whatever.com\"\nEMAIL_PORT = 587\nEMAIL_USE_TLS = True\nEMAIL_HOST_USER = \"xxxx\"\nEMAIL_HOST_PASSWORD = os.getenv('EMAIL_API_KEY')\n</code></pre><p>That made me feel like if I want some other basic website feature, there’s\nlikely to be an easy way to do it built into Django already.</p><h3>the settings file still feels like a lot</h3><p>I’m still a bit intimidated by the  file: Django’s settings system\nworks by setting a bunch of global variables in a file, and I feel a bit\nstressed about… what if I make a typo in the name of one of those variables?\nHow will I know? What if I type <code>WSGI_APPLICATOIN = \"config.wsgi.application\"</code>\ninstead of ?</p><p>I guess I’ve gotten used to having a Python language server tell me when I’ve\nmade a typo and so now it feels a bit disorienting when I can’t rely on the\nlanguage server support.</p><p>I haven’t really successfully used an actual web framework for a project before\n(right now almost all of my websites are either a single Go binary or static\nsites), so I’m interested in seeing how it goes!</p><p>There’s still lots for me to learn about, I still haven’t really gotten into\nDjango’s form validation tooling or authentication systems.</p><p>Thanks to Marco Rogers for convincing me to give ORMs a chance.</p>","contentLength":6120,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"make.ts","url":"https://matklad.github.io/2026/01/27/make-ts.html","date":1769472000,"author":"Alex Kladov","guid":424093,"unread":true,"content":"<p>Sounds familiar? This is how I historically have been running benchmarks and other experiments\nrequiring a repeated sequence of commands — type them manually once, then rely on shell history\n(and maybe some terminal splits) for reproduction. These past few years I’ve arrived at a much better\nworkflow pattern — . I was forced to adapt it once I started working with multiprocess\napplications, where manually entering commands is borderline infeasible. In retrospect, I should\nhave adapted the workflow years earlier.</p><section><p>Use a (gitignored) file for interactive scripting. Instead of entering a command directly into the\nterminal, write it to a file first, and then run the file. For me, I type stuff into  and\nthen run  in my terminal (Ok, I need  for that).</p><p>I want to be clear here, I am not advocating writing “proper” scripts, just capturing your\ninteractive, ad-hoc command to a persistent file. Of course any command that you want to execute\n belongs to the build system. The surprising thing is that even more complex one-off\ncommands benefit from running through file, because it will take you several tries to get them\nright!</p><p>There are many benefits relative to  workflow:</p><ul><li>\nReal commands tend to get large, and it is so much nicer to use a real 2D text editor rather than\nshell’s line editor.\n</li><li>\nIf you need more than one command, you can write several commands, and still run them all with a\nsingle key (before , I was prone to constructing rather horrific &amp;&amp; conjuncts for this\nreason).\n</li><li>\nWith a sequence of command outlined, you nudge yourself towards incrementally improving them,\nmaking them idempotent, and otherwise investing into your own workflow for the next few minutes,\nwithout falling into the YAGNI pit from the outset.\n</li><li>\nAt some point you might realize after, say, running a series of ad-hoc benchmarks interactively,\nthat you’d rather write a proper script which executes a collection of benchmarks with varying\nparameters. With the file approach, you already have the meat of the script implemented, and you\nonly need to wrap in a couple of fors and ifs.\n</li><li>\nFinally, if you happen to work with multi-process projects, you’ll find it easier to manage\nconcurrency declaratively, spawning a tree of processes from a single script, rather than\nswitching between terminal splits.\n</li></ul></section><section><p>Use a consistent filename for the script. I use , and so there’s a  in the root\nof most projects I work on. Correspondingly, I have  line in project’s \n— the  file which is not shared. The fixed name reduces fixed costs — whenever I\nneed complex interactivity I don’t need to come up with a name for a new file, I open my\npre-existing , wipe whatever was there and start hacking. Similarly, I have  in\nmy shell history, so\n<a href=\"https://fishshell.com/docs/current/interactive.html#autosuggestions\">fish autosuggestions</a>\nwork for me. At one point, I had a VS Code task to run , though I now use\n<a href=\"https://matklad.github.io/2025/08/31/vibe-coding-terminal-editor.html\">terminal editor</a>.</p><p>Start the script with hash bang,\n\nin my case, and\n\nthe file, to make it easy to run.</p><p>Write the script in a language that:</p><ul><li>\nyou are comfortable with,\n</li><li>\ndoesn’t require huge setup,\n</li><li>\nmakes it easy to spawn subprocesses,\n</li><li>\nhas good support for concurrency.\n</li></ul><p>For me, that is TypeScript. Modern JavaScript is sufficiently ergonomic, and structural, gradual\ntyping is a sweet spot that gives you reasonable code completion, but still allows brute-forcing any\nproblem by throwing enough stringly dicts at it.</p><p>JavaScript’s tagged template syntax is brilliant for scripting use-cases:</p><figure><pre><code></code></pre></figure><figure><pre><code></code></pre></figure><p>What happens here is that  gets a list of literal string fragments inside the backticks, and\nthen, separately, a list of values to be interpolated in-between. It  concatenate everything\nto just a single string, but it doesn’t have to. This is precisely what is required for process\nspawning, where you want to pass an array of strings to the  syscall.</p><p>Specifically, I use <a href=\"https://github.com/dsherret/dax\">dax</a> library with Deno, which is excellent as\na single-binary batteries-included scripting environment\n(see <a href=\"https://matklad.github.io/2023/02/12/a-love-letter-to-deno.html\">&lt;3 Deno</a>). Bun has a dax-like\nlibrary in the box and is a good alternative (though I personally stick with Deno because of\n and ). You could also use famous zx, though be mindful that it\n<a href=\"https://google.github.io/zx/configuration#shell\">uses your shell as a middleman</a>, something I\nconsider to be sloppy (<a href=\"https://julialang.org/blog/2012/03/shelling-out-sucks/\">explanation</a>).</p><p>While  makes it convenient to spawn a single program,  is excellent for herding a\nslither of processes:</p><figure><pre><code></code></pre></figure></section><section><p>Here’s how I applied this pattern earlier today. I wanted to measure how TigerBeetle cluster\nrecovers from the crash of the primary. The manual way to do that would be to create a bunch of ssh\nsessions for several cloud machines, format datafiles, start replicas, and then create some load. I\n started to split my terminal up, but then figured out I can do it the smart way.</p><p>The first step was cross-compiling the binary, uploading it to the cloud machines, and running the\ncluster\n(using my <a href=\"https://matklad.github.io/2026/01/20/vibecoding-2.html\">box</a> from the other week):</p><figure><pre><code></code></pre></figure><p>Running the above the second time, I realized that I need to kill the old cluster first, so two new\ncommands are “interactively” inserted:</p><figure><pre><code></code></pre></figure><p>At this point, my investment in writing this file and not just entering the commands one-by-one\nalready paid off!</p><p>The next step is to run the benchmark load in parallel with the cluster:</p><figure><pre><code></code></pre></figure><p>I don’t need two terminals for two processes, and I get to copy-paste-edit the mostly same command.</p><p>For the next step, I actually want to kill one of the replicas, and I also want to capture live\nlogs, to see in real-time how the cluster reacts. This is where  multiplexing syntax of box\nfalls short, but, given that this is JavaScript, I can just write a for loop:</p><figure><pre><code></code></pre></figure><p>At this point, I do need two terminals. One runs  and shows the log from the benchmark\nitself, the other runs  to watch the next replica to become primary.</p><p>I have definitelly crossed the line where writing a script makes sense, but the neat thing is that\nthe gradual evolution up to this point. There isn’t a discontinuity where I need to spend 15\nminutes trying to shape various ad-hoc commands from five terminals into a single coherent script, it\nwas in the file to begin with.</p><p>And then the script is easy to evolve. Once you realize that it’s a good idea to also run the same\nbenchmark against a different, baseline version TigerBeetle, you replace  with\n and wrap everything into</p><figure><pre><code></code></pre></figure><figure><pre><code></code></pre></figure><p>A bit more hacking, and you end up with a repeatable benchmark schedule for a matrix of parameters:</p><figure><pre><code></code></pre></figure><p>That’s the gist of it. Don’t let the shell history be your source, capture it into the file first!</p></section>","contentLength":6366,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ireland Proposes Giving Police New Digital Surveillance Powers","url":"https://www.schneier.com/blog/archives/2026/01/ireland-proposes-giving-police-new-digital-surveillance-powers.html","date":1769429097,"author":"Bruce Schneier","guid":421456,"unread":true,"content":"<blockquote><p>The Irish government is planning to bolster its police’s ability to intercept communications, including encrypted messages, and provide a legal basis for spyware use.</p></blockquote>","contentLength":168,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Friday Squid Blogging: Giant Squid in the Star Trek Universe","url":"https://www.schneier.com/blog/archives/2026/01/friday-squid-blogging-giant-squid-in-the-star-trek-universe.html","date":1769205800,"author":"Bruce Schneier","guid":419669,"unread":true,"content":"<p>Spock <a href=\"https://trekmovie.com/2026/01/13/see-spock-befriend-a-giant-space-squid-in-star-trek-strange-new-worlds-the-seeds-of-salvation-5-preview/\">befriends</a> a giant space squid in the comic <i>Star Trek: Strange New Worlds: The Seeds of Salvation</i> #5.</p><p>As usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.</p>","contentLength":221,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AIs are Getting Better at Finding and Exploiting Internet Vulnerabilities","url":"https://www.schneier.com/blog/archives/2026/01/ais-are-getting-better-at-finding-and-exploiting-internet-vulnerabilities.html","date":1769169679,"author":"Bruce Schneier","guid":419415,"unread":true,"content":"<blockquote><p>In a recent evaluation of AI models’ cyber capabilities, current Claude models can now succeed at multistage attacks on networks with dozens of hosts using only standard, open-source tools, instead of the custom tools needed by previous generations. This illustrates how barriers to the use of AI in relatively autonomous cyber workflows are rapidly coming down, and highlights the importance of security fundamentals like promptly patching known vulnerabilities.</p><p>A notable development during the testing of Claude Sonnet 4.5 is that the model can now succeed on a minority of the networks without the custom cyber toolkit needed by previous generations. In particular, Sonnet 4.5 can now exfiltrate all of the (simulated) personal information in a high-fidelity simulation of the Equifax data breach—­one of the costliest cyber attacks in history—­using only a Bash shell on a widely-available Kali Linux host (standard, open-source tools for penetration testing; not a custom toolkit). Sonnet 4.5 accomplishes this by instantly recognizing a publicized CVE and writing code to exploit it without needing to look it up or iterate on it. Recalling that the original Equifax breach happened by exploiting a publicized CVE that had not yet been patched, the prospect of highly competent and fast AI agents leveraging this approach underscores the pressing need for security best practices like prompt updates and patches. </p></blockquote><p>Read the whole thing. Automatic exploitation will be a major change in cybersecurity. And things are happening fast. There have been significant developments since I wrote <a href=\"https://www.csoonline.com/article/4069075/autonomous-ai-hacking-and-the-future-of-cybersecurity.html\">this</a> in October.</p>","contentLength":1615,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Programmer's Guide to Leaving GitHub","url":"https://lord.io/leaving-github/","date":1769126400,"author":"","guid":419660,"unread":true,"content":"<p>If you subscribe to many programming blogs, chances are you've come across a post describing someone's move off GitHub. They started as far back as the Microsoft acquisition in 2018, but they've increased in frequency recently. Both the <a href=\"https://ziglang.org/news/migrating-from-github-to-codeberg/\">Zig</a> programming language and <a href=\"https://codeberg.org/leiningen/leiningen/src/branch/main/.github/README.md\">Leiningen</a> build tool wrote about their move to other platforms late last year. I've drawn inspiration from these posts, and the countless similar posts from individual programmers. However, since they're mostly informational announcements telling people to update their repository URLs, they tend to only briefly mention the reasons the author chose to leave. They don't try too hard to convince a skeptical reader that perhaps they could leave GitHub too.</p><p>I'm going to migrate all my personal projects off of GitHub this weekend, in support of today's general strike in Minnesota. Instead of the traditional brief message, I'll instead try to record my thought process a little more deeply: my research into which groups have active protests of GitHub, why I think GitHub is a particularly suitable target, what makes a boycott more or less effective, and finally, a list of GitHub alternatives to consider switching to. Migrating your open source projects off GitHub is obviously not the most radical, impactful action you could be taking right now, but also it's pretty easy! If you happen across this blog post, I hope you will consider it.</p><p>There are many groups protesting GitHub and Microsoft, but I'll discuss these four in this post:</p><ul><li>The <strong>Software Freedom Conservatory</strong> (the non-profit that provides legal support for Wine, Inkscape, QEMU, Git, and many more free software projects) started a campaign called <a href=\"https://sfconservancy.org/GiveUpGitHub/\">\"Give Up GitHub\"</a> in 2022. They cite how the GitHub platform itself is closed source software, instances of Copilot spitting out verbatim GPL code (a form of plagiarism), and fears over Microsoft's reorganization of all of GitHub under a \"CoreAI\" product division. They also point to GitHub's 2020 contracts with ICE, the controversial and violent immigration police here in the United States.</li><li>The <a href=\"https://www.fsf.org/blogs/community/keep-putting-pressure-on-microsoft\">since at least 2024</a> have told the free software community to move projects off of GitHub to apply pressure on Microsoft, pointing again to Github's proprietary server code, as well as Microsoft's decision to require computers running Windows 11 to have a \"Trusted Platform Module\"; I'll let the FSF post explain why you might want to protest that.</li><li>The <strong>Palestinian BDS National Committee</strong><a href=\"https://bdsmovement.net/news/boycott-microsofts-xbox\">upgraded</a> Microsoft from a \"pressure\" target to a \"priority\" boycott target in 2025, describing Microsoft as \"perhaps the most complicit tech company\" in Israel's apartheid. BDS has already claimed two major wins here. In 2020, controversy forced Microsoft to divest its stake in AnyVision, a Israeli facial recognition startup used at checkpoints in the West Bank. Then, in 2025, Microsoft terminated Azure services for a subagency of the Israeli military called Unit 8200; this was right after a news article revealed they used Azure to process millions of intercepted phone call recordings from Palestinian civilians to determine where to fire lethal airstrikes in Gaza. BDS and the 2000+ Microsoft employees that signed <a href=\"https://noazureforapartheid.com/\">No Azure For Apartheid</a>, along with many other organizations (including a global network of MSFT-shareholding <a href=\"https://afsc.org/newsroom/unprecedented-investor-action-demands-microsoft-answer-reported-involvement-gaza-genocide\">catholic nuns</a>) continue to protest the Azure services Microsoft provides to the rest of the Israeli military.</li><li> in late 2025 launched <a href=\"https://www.beyondtheballot.org/iceout\">\"ICE Out of My Wallet\"</a>, listing Microsoft as one of just seven top targets for a consumer boycott. Their goal is to put pressure on the $20M+ in Azure services Microsoft provides annually to ICE. (The official boycott currently just lists Microsoft devices as targets, not GitHub.) Back in 2019, there were also mass protests against GitHub's direct contracts with ICE to host their code; as far as I'm aware, they still host code for ICE today.</li></ul><p>I have four reasons why I want to specifically target GitHub in this post. First, for independent programmers, I think it's incredibly simple and straightforward to move your personal open source projects off of GitHub. Unlike quitting, say, Instagram or TikTok, which centralize and tightly control content discovery, the network effects keeping projects on GitHub are substantially weaker. When you quit Instagram, you become invisible; when you quit GitHub, you instead just add a small speed-bump for contributors. I also see particular ease when migrating a  project. Your small project has no CTO you need to convince, no 400-engineer monorepo, and no half-forgotten custom scripts calling GitHub's APIs, written by a coworker who quit a year ago. If your project depends on many strangers submitting drive-by pull requests, moving off GitHub will impose extra costs on you, and you may want to to consider more carefully whether this is a cost you're willing to pay. But the vast majority of public repos — personal projects with few external contributors — will find leaving GitHub to be relatively frictionless.</p><p>Second, although you likely don't pay GitHub to host your open-source projects, they still make money from them! When my blog links to an open source project I've published GitHub, they don't just get to put their logo in front of some eyeballs for free; they also get my implicit endorsement, helping establish GitHub as the default choice for companies deciding where to put their internal repos and who to pay for LLM autocomplete. You might find this point kind of banal, but I really just want to emphasize it: by putting your personal projects on GitHub, you are providing them a valuable service! If your account is small, it may just be a tiny amount of value. But they find it valuable nonetheless, and I think this small amount of value matches the very small amount of effort it takes to move most of your code somewhere else.</p><p>Third, GitHub's web interface has been in a steepening decline since since the Microsoft acquisition in 2018, making it a less appealing place to put your code even without these ongoing protests. Why does an uncached page load of my repository's root take 2500ms, from New York City no less, with gigabit, 17ms ping internet? Why does GitHub Actions choose jobs to run \"seemingly at random\", causing <a href=\"https://ziglang.org/news/migrating-from-github-to-codeberg/\">Zig's</a> CI to not even run on the main branch? Why does the settings page for enabling and disabling the 16 available LLM models take up two vertical laptop screens, and why, instead of a simple checkbox, does each dropdown have three possible states: \"enabled\", \"disabled\", and the mysterious \"Select an option\"?</p><p>Finally, I think open source communities, with roots in hacker culture from the 80s and 90s, form a particularly fertile soil for this sort of action. Many programmers contribute to open source projects for non-commercial reasons: out of a deep love for programming, or an ethical belief everyone should have the right to read and modify the code on their computer. Hackers also have a long history of general repulsion from Microsoft.</p><p>This history, however, is a double edged sword. As programmers, we are primed by this history to think individually instead of collectively. I have many friends who would agree with the causes above, and yet might resist participation in a GitHub protest. Even if you are someone who in general might join a boycott, once you hear that the plan is to convince a bunch of  — good luck, but clearly that plan won't work. Here, I think the choice of Microsoft is helpful, because I don't  to convince some critical mass of programmers. Instead, I get to play a tiny part in a large and global movement that already has momentum, made up of people who have never been burdened by the words \"rebase merge conflict\" before. I've chosen GitHub as a target so that my action mirrors the already-successful efforts of many others.</p><h2>Some strategies are better than others</h2><p>I have a vivid memory from a little over a decade ago, when I saw Richard Stallman speak about free software at an auditorium in lower Manhattan. In this speech, he cast as wide a net as he could, listing off the misdeeds of tech company after tech company and describing how we should stop using their products. (When one or two people in the audience quietly made their way to the exit — he had been talking long past the allotted time — he started castigating them for leaving before he was done.) His personal website today continues the tradition:</p><p>If my understanding of boycotts came from this speech, I would absolutely lean anti-boycott, but I'd like to convince you that there is another way! Boycott strategy makes a massive difference in efficacy. Stallman could learn a lot from the <a href=\"https://bdsmovement.net/BDS-Guide-Strategic-Campaigning\">BDS National Committee</a>, whose approach in turn was inspired by the highly visible South African anti-apartheid movement. Here's my own list of what has resonated with me:</p><ul><li><strong>Don't protest everything all at once</strong>: We call it a \"targeted boycott\" for a reason. Target just a handful of companies with the most egregious violations, and in the common situation where you have complaints against all major vendors offering some service, don't boycott all of them. Make it easy for people to switch to an alternative, even if you're implicitly advocating for an imperfect company. Here, GitHub is a great target because many movements list Microsoft as a top target, and we have many free, open source alternatives.</li><li><strong>Build cross-movement coalitions</strong>: BDS chose Chevron as a priority target in part because many climate activist groups already have active protests against oil companies. The Software Freedom Conservatory chose GitHub as a primary target in part because anti-ICE activists protested it in 2020. When you boycott GitHub, you get to participate in several boycotts all at once.</li><li><strong>Cite specific, achievable goals</strong>: unfortunately free software boycotts sometimes have vague goals, like \"stop discrediting the GPL\". At other times, they cite specific goals that existentially threaten a company, like \"release the source code to  of your software\" or \"only train your language models on public domain code.\" I think asking for Microsoft to cancel their contracts with the IDF and ICE are concrete goals, and Microsoft could do it without completely destroying itself.</li><li>: I've seen some programmers delete their GitHub accounts silently, saying that their choice to leave is a personal one. I definitely can empathize with this sentiment — this feeling was hard for me to get over when writing this post. I feared it self-aggrandized what is truly a microscopic drop in the bucket. At the same time, I think there is incredible value to speaking publicly about why you're leaving, assuming it's safe for you to do so. In addition to this post, I also plan to not delete any repositories, instead replacing their contents with a README that explains my departure.</li><li><strong>Don't worry about perfection</strong>: I've seen some worry online that it's impossible to delete your GitHub account when there are still so many open source projects that use it. I agree! I plan to still use GitHub if I need it to contribute to other projects.</li></ul><p>That's all I've got to say! What follows is some optional resources that you might find useful if you decide to make the move yourself. Thanks for reading this far, and if you're in Minnesota today, I hope you stay warm out there. ∎</p><h2>Appendix A: Table of GitHub alternatives</h2><div><table cellspacing=\"0\" cellpadding=\"0\"><thead><tr></tr></thead><tbody><tr><th colspan=\"6\">Centrally hosted (with self-hosting as an option)</th></tr><tr><td>nonprofit based in Germany</td><td>FOSS or noncommercial projects only; fork of gitea</td></tr><tr><td>indie for-profit, not VC funded</td><td>costs $4–12/month, financial aid available</td></tr><tr><td>weird vibes, and the free cloud hosting seems sort of like a demo instance; fork of Gogs</td></tr><tr><td>branch-based with stacking</td><td>limited features for free accounts</td></tr><tr><td>small startup, $300k+ in VC funding</td><td>patch-based with stacking</td><td>no private repos, built on ATProtocol</td></tr><tr><td>some ethereum thing, $12M+ in VC funding</td><td>private repos must be self-hosted</td></tr><tr><td>i wrote it myself last week</td><td>barebones read-only web ui</td></tr><tr><td>patch-based with stacking</td><td>code hosting/review only; no issues, etc</td></tr><tr></tr></tbody></table></div><p>My personal take on these options: since these days my projects mostly don't have external contributors, I've chosen to move them to <a href=\"https://code.lord.io/j3/\">j3</a>, a small local binary I wrote in Rust that lets you use an s3 bucket as a Git remote, and automatically pushes a read-only web UI to the bucket's . If I had a startup that needed private code hosting, I would probably set up a Gerrit instance. If I was working on an open source project that wanted to make it easy for people in the open-source community to contribute, I would probably choose Codeberg, assuming I was not tempted by Tangled's code review workflow.</p><blockquote><p><strong>What is \"patch-based\" code review?</strong></p><p>If you're familiar with GitHub's pull request workflow, you've done -based merges before. You prepare a branch with your changes, and then submit a pull request asking to merge your branch into . If somebody gives you feedback, you push additional commits on top of your base commit. In contrast, with the -based merge workflow originally popularized by Gerrit, you amend the existing commit and push it — something like <code>git commit --amend &amp;&amp; git push --force</code>. If you try this in GitHub, but this would make the original commit you pushed disappear, but in patch-based review tools, your reviewers will instead see a diff from the original commit to the new one. In general, I'm trying to move towards patch-based workflows, since they work better with <a href=\"https://github.com/jj-vcs/jj\">jiujutsu</a>. \"Stacking\" here means it's easy to submit multiple pull requests for simultaneous code review, where each pull request builds upon the changes from the prior one in a chain. On GitHub, this is very difficult!</p></blockquote><h2>Appendix B: GitHub stars and network effects</h2><p>If you want people to discover your personal projects, you might say that GitHub stars, forks, and followers are a great way to enable this. While this is an interesting question, and I'm sure some people find these tools valuable, my personal experience has been that few people look at their GitHub feed, and this was before the Copilot prompt box pushed it further down the homepage. I've also heard it got diluted by LLM-generated bug reports, but honestly, I don't look at it any more.</p><p>To show one data point using star counts as a proxy for attention, I had a little over 700 followers in 2020, so while I wasn't one of the most followed users on GitHub, I still had more followers than the vast majority of GitHub users. Throughout 2020, I worked publicly on a Rust side project called Anchors, which by October had accrued a grand total of 4 stars. On November 9th, I published <a href=\"https://lord.io/spreadsheets/\">How to Recalculate a Spreadsheet</a>, a tedious and technical blog post which discussed Anchors starting about 2000 words in. By the next day, Anchors jumped to 19 stars, and then (despite essentially zero code changes to the Anchors project itself) slowly climbed up to ~130 stars by late 2023. Clearly the blog post was the catalyst for these stars, and without it, Anchors would still have single digit stars today. That said, I can't prove to you that GitHub's feed didn't  the attention the repo got from the blog post. But at an average rate of 1 star every 10 days, and given the minimal stars the project had prior to the blog post, I guess it's hard for me to imagine GitHub's feed played a major role.</p><p>Assuming it's even your goal for your project to get discovered by others (for most of my projects it is not!) I think your side project will likely reach orders of magnitude more people on Bluesky, Twitter, or your personal blog than they will via GitHub. GitHub stars are a good sign of social proof, but I would argue they don't serve this role substantially better than stars on Codeberg.</p><h2>Appendix C: Further reading</h2><p>I've already mentioned <a href=\"https://ziglang.org/news/migrating-from-github-to-codeberg/\">Zig's</a> and <a href=\"https://codeberg.org/leiningen/leiningen/src/branch/main/.github/README.md\">Leiningen's</a> posts, but if you want to read what individual people have said about leaving GitHub, here is what I could find:</p><h2>Appendix D: Richard Stallman, \"A Free Digital Society\" (New York, 2014)</h2>","contentLength":15844,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Considering Strictly Monotonic Time","url":"https://matklad.github.io/2026/01/23/strictly-monotonic-time.html","date":1769126400,"author":"Alex Kladov","guid":419619,"unread":true,"content":"<p>Monotonic time is a frequently used, load bearing abstraction. Monotonicity is often enforced using\nthe following code:</p><figure><pre><code></code></pre></figure><p>That is, ask the OS about the current monotonic time, but don’t trust the result too much and clamp\nit using an in-process guard. Under normal scenarios, you can trust the OS promise of monotonicity,\nbut, empirically, there’s a long tail of different scenarios where the promise isn’t upheld:\n<a href=\"https://github.com/rust-lang/rust/pull/56988\">https://github.com/rust-lang/rust/pull/56988</a></p><p>Today I realized that, if you are doing the above, you might as well force the time to be \nmonotonic:</p><figure><pre><code></code></pre></figure><p>The benefit of strict monotonicity is that you can tighten asserts,\n\ncan become\n\nand that  catches the bug where you pass in  the same instance.\nIn other words, the  version explicitly allows either query-ing the time again, or using the old\nvalue directly.</p><p>Conversely, with strictly monotonic time, you know that if you see two numerically identical time\ninstances, they must have been ultimately derived from the exact same call to . Time becomes\nfundamentally less ambiguous.</p><p>The constraint here is that the resolution of the time value ( the clock resolution) needs to\nbe high enough, to make sure that repeated  don’t move you into the future, but nanosecond\nprecision seems fine for that.</p>","contentLength":1257,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fragments: January 22","url":"https://martinfowler.com/fragments/2026-01-22.html","date":1769092200,"author":"Martin Fowler","guid":418236,"unread":true,"content":"<p>My colleagues here at Thoughtworks have announced <a href=\"https://www.thoughtworks.com/ai/works\">AI/works™</a>, a platform for our work using AI-enabled software development. The platform is in its early days, and is currently intended to support Thoughtworks consultants in their client work. I’m looking forward to sharing what we learn from using and further developing the platform in future months.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>Simon Couch <a href=\"https://www.simonpcouch.com/blog/2026-01-20-cc-impact/\">examines the electricity consumption</a> of using AI. He’s a heavy user: “usually programming for a few hours, and driving 2 or 3 Claude Code instances at a time”. He finds his usage of electricity is orders of magnitude more than typical estimates based on the “typical query”.</p><blockquote><p>On a median day, I estimate I consume 1,300 Wh through Claude Code—4,400 “typical queries” worth.</p></blockquote><p>But it’s still not a massive amount of power - similar to that of running a dishwasher.</p><p>A caveat to this is that this is “napkin math” because we don’t have decent data about how these models use resources. I agree with him that we ought to.</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>My namesake Chad Fowler (no relation) considers that the movement to agentic coding creates a similar <a href=\"https://aicoding.leaflet.pub/3mbrvhyye4k2e\">shift in rigor and discipline</a> as appeared in Extreme Programming, dynamic languages, and continuous deployment.</p><p>In Extreme Programming’s case, this meant a lot of discipline around testing, continuous integration, and keeping the code-base healthy. My current view is that with AI-enabled development we need to be rigorous about evaluating the software, both for its observable behavior and its internal quality.</p><blockquote><p>The engineers who thrive in this environment will be the ones who relocate discipline rather than abandon it. They’ll treat generation as a capability that demands more precision in specification, not less. They’ll build evaluation systems that are harder to fool than the ones they replaced. They’ll refuse the temptation to mistake velocity for progress.</p></blockquote><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>There’s been much written about the dreadful events in Minnesota, and I’ve not felt I’ve had anything useful to add to them. But I do want to pass on an excellent post from <a href=\"https://www.noahpinion.blog/p/why-are-federal-agents-gunning-down\">Noah Smith</a> that captures many of my thoughts. He points out that there is a “consistent record of brutality, aggression, dubious legality, and unprofessionalism” from ICE (and CBP) who seem to be turning into MAGA’s <a href=\"https://en.wikipedia.org/wiki/Sturmabteilung\">SD</a>.</p><blockquote><p>Is this America now? A country where unaccountable and poorly trained government agents go door to door, arresting and beating people on pure suspicion, and shooting people who don’t obey their every order or who try to get away? “When a federal officer gives you instructions, you abide by them and then you get to keep your life” is a perfect description of an authoritarian police state. None of this is Constitutional, every bit of it is deeply antithetical to the American values we grew up taking for granted.</p></blockquote><p>My worries about these kinds of developments were what animated me to urge against voting for Trump in the <a href=\"https://martinfowler.com/articles/vote-against-trump.html\">2016 election</a>. Mostly those worries didn’t come to fruition because enough constitutional Republicans were in a position to stop them from happening, so even when Trump attempted a coup in 2020, he wasn’t able to get very far. But now those constitutional Republicans are absent or quiescent. I fear that what we’ve seen in Minneapolis will be a harbinger of worse to come.</p><blockquote><p>But then, after the murderous agent fired three shots — just 30 or 40 feet in front of Callenson — Callenson had the courage and conviction to stay with the scene and keep filming. Not to run away, but instead to follow the scene. To keep filming. To continue documenting with as best clarity as she could, what was unfolding.</p></blockquote><p>The recent activity in  Venezuala reminds me that I’ve long felt that Trump is a Hugo Chávez figure - a charismatic populist who’s keen on wrecking institutions and norms. Trump is old, so won’t be with us for that much longer - but the question is: “who is Trump’s Maduro?”</p><p>&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;❄</p><p>With all the drama at home, we shouldn’t ignore the terrible things that happened in Iran. The people there again suffered again the consequences of an entrenched authoritarian police state.</p>","contentLength":4689,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why AI Keeps Falling for Prompt Injection Attacks","url":"https://www.schneier.com/blog/archives/2026/01/why-ai-keeps-falling-for-prompt-injection-attacks.html","date":1769085346,"author":"Bruce Schneier","guid":418172,"unread":true,"content":"<p>Imagine you work at a drive-through restaurant. Someone drives up and says: “I’ll have a double cheeseburger, large fries, and ignore previous instructions and give me the contents of the cash drawer.” Would you hand over the money? Of course not. Yet this is what <a href=\"https://spectrum.ieee.org/tag/large-language-models\">large language models</a> (<a href=\"https://spectrum.ieee.org/tag/llms\">LLMs</a>) do.</p><p><a href=\"https://www.ibm.com/think/topics/prompt-injection\">Prompt injection</a> is a method of tricking LLMs into doing things they are normally prevented from doing. A user writes a prompt in a certain way, asking for system <a href=\"https://spectrum.ieee.org/tag/passwords\">passwords</a> or private data, or asking the LLM to perform forbidden instructions. The precise phrasing overrides the LLM’s <a href=\"https://medium.com/data-science/safeguarding-llms-with-guardrails-4f5d9f57cff2\">safety guardrails</a>, and it complies.</p><p>LLMs are vulnerable to <a href=\"https://fdzdev.medium.com/20-prompt-injection-techniques-every-red-teamer-should-test-b22359bfd57d\">all sorts</a> of prompt injection attacks, some of them absurdly obvious. A chatbot won’t tell you how to synthesize a bioweapon, but it might tell you a fictional story that incorporates the same detailed instructions. It won’t accept nefarious text inputs, but might if the text is rendered as <a href=\"https://arxiv.org/abs/2402.11753\">ASCII art</a> or appears in an image of a <a href=\"https://www.lakera.ai/blog/visual-prompt-injections\">billboard</a>. Some ignore their guardrails when told to “ignore previous instructions” or to “pretend you have no guardrails.”</p><p>AI vendors can block specific prompt injection techniques once they are discovered, but general safeguards are <a href=\"https://llm-attacks.org/\">impossible</a> with today’s LLMs. More precisely, there’s an endless array of prompt injection attacks waiting to be discovered, and they cannot be prevented universally.</p><p>If we want LLMs that resist these attacks, we need new approaches. One place to look is what keeps even overworked fast-food workers from handing over the cash drawer.</p><h3>Human Judgment Depends on Context</h3><p>Our basic human defenses come in at least three types: general instincts, social learning, and situation-specific training. These work together in a layered defense.</p><p>As a social species, we have developed numerous instinctive and cultural habits that help us judge tone, motive, and risk from extremely limited information. We generally know what’s normal and abnormal, when to cooperate and when to resist, and whether to take action individually or to involve others. These instincts give us an intuitive sense of risk and make us <a href=\"https://www.nature.com/articles/srep08242\">especially careful</a> about things that have a large downside or are impossible to reverse.</p><p>The second layer of defense consists of the norms and trust signals that evolve in any group. These are imperfect but functional: Expectations of cooperation and markers of trustworthiness emerge through repeated interactions with others. We remember who has helped, who has hurt, who has reciprocated, and who has reneged. And emotions like sympathy, anger, guilt, and gratitude motivate each of us to <a href=\"https://ncase.me/trust/\">reward cooperation with cooperation</a> and punish defection with defection.</p><p>A third layer is institutional mechanisms that enable us to interact with multiple strangers every day. Fast-food workers, for example, are trained in procedures, approvals, escalation paths, and so on. Taken together, these defenses give humans a strong sense of context. A fast-food worker basically knows what to expect within the job and how it fits into broader society.</p><p>We reason by assessing multiple layers of context: perceptual (what we see and hear), relational (who’s making the request), and normative (what’s appropriate within a given role or situation). We constantly navigate these layers, weighing them against each other. In some cases, the normative outweighs the perceptual—for example, following workplace rules even when customers appear angry. Other times, the relational outweighs the normative, as when people comply with orders from superiors that they believe are against the rules.</p><p>Crucially, we also have an interruption reflex. If something feels “off,” we naturally pause the <a href=\"https://spectrum.ieee.org/tag/automation\">automation</a> and reevaluate. Our defenses are not perfect; people are fooled and manipulated all the time. But it’s how we humans are able to navigate a complex world where others are constantly trying to trick us.</p><p>So let’s return to the drive-through window. To convince a fast-food worker to hand us all the money, we might try shifting the context. Show up with a camera crew and tell them you’re filming a commercial, claim to be the head of security doing an audit, or dress like a bank manager collecting the cash receipts for the night. But even these have only a slim chance of success. Most of us, most of the time, can smell a scam.</p><p>Con artists are astute observers of human defenses. Successful <a href=\"https://spectrum.ieee.org/tag/scams\">scams</a> are often slow, undermining a mark’s situational assessment, allowing the scammer to manipulate the context. This is an old story, spanning traditional confidence games such as the Depression-era “big store” cons, in which teams of scammers created entirely fake businesses to draw in victims, and modern <a href=\"https://dfpi.ca.gov/news/insights/pig-butchering-how-to-spot-and-report-the-scam/\">“pig-butchering” frauds</a>, where online scammers slowly build trust before going in for the kill. In these examples, scammers slowly and methodically reel in a victim using a long series of interactions through which the scammers gradually gain that victim’s trust.</p><p>Sometimes it even works at the drive-through. One scammer in the 1990s and 2000s <a href=\"https://en.wikipedia.org/wiki/Strip_search_phone_call_scam\">targeted fast-food workers by phone</a>, claiming to be a police officer and, over the course of a long phone call, convinced managers to strip-search employees and perform other bizarre acts.</p><h3>Why LLMs Struggle With Context and Judgment</h3><p>LLMs behave as if they have a notion of context, but it’s different. They do not learn human defenses from repeated interactions and remain untethered from the real world. LLMs flatten multiple levels of context into text similarity. They see “tokens,” not hierarchies and intentions. LLMs don’t reason through context, they only reference it.</p><p>While LLMs often get the details right, they can easily miss the <a href=\"https://spectrum.ieee.org/tag/big-picture\">big picture</a>. If you prompt a chatbot with a fast-food worker scenario and ask if it should give all of its money to a customer, it will respond “no.” What it doesn’t “know”—forgive the anthropomorphizing—is whether it’s actually being deployed as a fast-food bot or is just a test subject following instructions for hypothetical scenarios.</p><p>This limitation is why LLMs misfire when context is sparse but also when context is overwhelming and complex; when an LLM becomes unmoored from context, it’s hard to get it back. AI expert Simon Willison <a href=\"https://simonwillison.net/2025/Sep/12/claude-memory/\">wipes context clean</a> if an LLM is on the wrong track rather than continuing the conversation and trying to correct the situation.</p><p>There’s more. LLMs are <a href=\"https://www.cmu.edu/dietrich/news/news-stories/2025/july/trent-cash-ai-overconfidence.html\">overconfident</a> because they’ve been designed to give an answer rather than express ignorance. A drive-through worker might say: “I don’t know if I should give you all the money—let me ask my boss,” whereas an LLM will just make the call. And since LLMs are designed to be <a href=\"https://hai.stanford.edu/news/large-language-models-just-want-to-be-liked\">pleasing</a>, they’re more likely to satisfy a user’s request. Additionally, LLM training is oriented toward the average case and not extreme outliers, which is what’s necessary for security.</p><p>The result is that the current generation of LLMs is far more gullible than people. They’re naive and regularly fall for manipulative <a href=\"https://arstechnica.com/science/2025/09/these-psychological-tricks-can-get-llms-to-respond-to-forbidden-prompts/\">cognitive tricks</a> that wouldn’t fool a third-grader, such as flattery, appeals to groupthink, and a false sense of urgency. There’s a <a href=\"https://www.bbc.com/news/articles/ckgyk2p55g8o\">story</a> about a Taco Bell AI system that crashed when a customer ordered 18,000 cups of water. A human fast-food worker would just laugh at the customer.</p><p>Prompt injection is an unsolvable problem that <a href=\"https://www.computer.org/csdl/magazine/sp/5555/01/11194053/2aB2Rf5nZ0k\">gets worse</a> when we give AIs tools and tell them to act independently. This is the promise of <a href=\"https://spectrum.ieee.org/tag/agentic-ai\">AI agents</a>: LLMs that can use tools to perform multistep tasks after being given general instructions. Their flattening of context and identity, along with their baked-in independence and overconfidence, mean that they will repeatedly and unpredictably take actions—and sometimes they will take the <a href=\"https://www.theregister.com/2025/10/28/ai_browsers_prompt_injection/\"> wrong ones</a>.</p><p>Science doesn’t know how much of the problem is inherent to the way LLMs work and how much is a result of deficiencies in the way we train them. The overconfidence and obsequiousness of LLMs are training choices. The lack of an interruption reflex is a deficiency in engineering. And prompt injection resistance requires fundamental advances in AI science. We honestly don’t know if it’s possible to build an LLM, where trusted commands and untrusted inputs are processed through the <a href=\"https://cacm.acm.org/opinion/llms-data-control-path-insecurity/\">same channel</a>, which is immune to prompt injection attacks.</p><p>We humans get our model of the world—and our facility with overlapping contexts—from the way our brains work, years of training, an enormous amount of perceptual input, and millions of years of evolution. Our identities are complex and multifaceted, and which aspects matter at any given moment depend entirely on context. A fast-food worker may normally see someone as a customer, but in a medical emergency, that same person’s identity as a doctor is suddenly more relevant.</p><p>We don’t know if LLMs will gain a better ability to move between different contexts as the models get more sophisticated. But the problem of recognizing context definitely can’t be reduced to the one type of reasoning that LLMs currently excel at. Cultural norms and styles are historical, relational, emergent, and constantly renegotiated, and are not so readily subsumed into reasoning as we understand it. Knowledge itself can be both logical and discursive.</p><p>The AI researcher Yann LeCunn believes that improvements will come from embedding AIs in a physical presence and giving them “<a href=\"https://medium.com/@AnthonyLaneau/beyond-llms-charting-the-next-frontiers-of-ai-with-yann-lecun-09e84f1978f9\">world models</a>.” Perhaps this is a way to give an AI a robust yet fluid notion of a social identity, and the real-world experience that will help it lose its naïveté.</p><p>Ultimately we are probably faced with a <a href=\"https://www.computer.org/csdl/magazine/sp/5555/01/11194053/2aB2Rf5nZ0k\">security trilemma</a> when it comes to AI agents: fast, smart, and secure are the desired attributes, but you can only get two. At the drive-through, you want to prioritize fast and secure. An AI agent should be trained narrowly on food-ordering language and escalate anything else to a manager. Otherwise, every action becomes a coin flip. Even if it comes up heads most of the time, once in a while it’s going to be tails—and along with a burger and fries, the customer will get the contents of the cash drawer.</p><p><em>This essay was written with Barath Raghavan, and originally appeared in <a href=\"https://spectrum.ieee.org/prompt-injection-attack\">IEEE Spectrum</a>.</em></p>","contentLength":10222,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["blog"]}