{"id":"2hUc62","title":"Blog","displayTitle":"Blog","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":12,"items":[{"title":"Surveillance Used by a Drug Cartel","url":"https://www.schneier.com/blog/archives/2025/07/surveillance-used-by-a-drug-cartel.html","date":1751540802,"author":"Bruce Schneier","guid":183113,"unread":true,"content":"<p>Once you build a surveillance system, you <a href=\"https://www.theguardian.com/world/2025/jun/27/sinaloa-cartel-fbi-hackers\">can’t control</a> who will use it:</p><blockquote><p>A hacker working for the Sinaloa drug cartel was able to obtain an FBI official’s phone records and use Mexico City’s surveillance cameras to help track and kill the agency’s informants in 2018, according to a new US justice department report.</p><p>The incident was disclosed in a justice department inspector general’s audit of the FBI’s efforts to mitigate the effects of “ubiquitous technical surveillance,” a term used to describe the global proliferation of cameras and the thriving trade in vast stores of communications, travel, and location data.</p><p>The report said the hacker identified an FBI assistant legal attaché at the US embassy in Mexico City and was able to use the attaché’s phone number “to obtain calls made and received, as well as geolocation data.” The report said the hacker also “used Mexico City’s camera system to follow the [FBI official] through the city and identify people the [official] met with.”</p></blockquote>","contentLength":1022,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tools: Code Is All You Need","url":"https://lucumr.pocoo.org/2025/7/3/tools/","date":1751500800,"author":"Armin Ronacher","guid":183031,"unread":true,"content":"<p>If you've been following me on Twitter, you know I'm not a big fan of MCP\n(<a href=\"https://en.wikipedia.org/wiki/Model_Context_Protocol\">Model Context Protocol</a>)\nright now.  It's not that I dislike the idea; I just haven't found it to work as\nadvertised.  In my view, MCP suffers from two major flaws:</p><ol><li><strong>It isn’t truly composable.</strong>  Most composition happens through inference.</li><li><strong>It demands too much context.</strong>  You must supply significant upfront input, and\nevery tool invocation consumes even more context than simply writing and\nrunning code.</li></ol><p>A quick experiment makes this clear: try completing a GitHub task with the\nGitHub MCP, then repeat it with the  CLI tool.  You'll almost certainly\nfind the latter uses context far more efficiently and you get to your intended\nresults quicker.</p><p>I want to address some of the feedback I've received on my stance on this.  I\nevaluated MCP extensively in the context of agentic coding, where its\nlimitations were easiest to observe.  One piece of feedback is that MCP might\nnot make a ton of sense for general code generation, because models are already\nvery good at that but they make a lot of sense for end-user applications, like,\nsay, automating a domain-specific task in a financial company.  Another one is\nthat I need to look at the world of the future, where models will be able to\nreach many more tools and handle much more complex tasks.</p><p>My current take is that my data indicates that current MCP will always be harder\nto use than writing code, primarily due to the reliance on inference.  If you\nlook at the approaches today for pushing towards higher tool counts, the\nproposals all include a layer of filtering.  You pass all your tools to an LLM\nand ask it to filter it down based on the task at hand.  So far, there hasn't\nbeen much better approaches proposed.</p><p>The main reason I believe this will most likely also hold true — that you\nshouldn't be using MCP in its current form even for non-programming,\ndomain-specific tasks — is that even in those cases code generation just is the\nbetter choice because of the ability to compose.</p><h2>Replace Yourself With A Shellscript</h2><p>The way to think about this problem is that when you don't have an AI, and\nyou're solving a problem as a software engineer, your tool of choice is code.\nPerhaps as a non-software engineer, code is out of reach.  Many many tasks\npeople do by hand are actually automatable through software.  The challenge is\nfinding someone to write that software.  If you're working in a niche\nenvironment and you're not a programmer yourself, you might not pick up a\nprogramming book to learn how to code, and you might not find a developer\nwilling to provide you with a custom piece of software to solve your specific\nproblem.  And yes, maybe your task requires some inference, but many do need\nthem all the time.</p><p>There is a reason we say “to replace oneself with a shell script”, it's because\nthat has been happening for a long time.  With LLMs and programming, the idea is\nthat rather than replacing yourself with a shell script, you're replacing\nyourself with an LLM.  But you run into three problems: cost, speed, and general\nreliability.  All these problems are what we need to deal with <em>before we can\neven think of tool usage</em> or MCP.  We need to figure out how to ensure that our\nautomated task actually works correctly at scale.</p><p>The key to automation is really to automate things that will happen over and\nover.  You're not going to automate a one-shot change that will never recur.\nYou're going to start automating the things where the machine can truly give you\na productivity boost because you're going to do it once or twice, figure out how\nto make it work, and then have the machine repeat it a thousand times.  For that\nrepetition, there's a very strong argument to be made for always using code.\nThat's because if we instruct the machine to use inference to do it, it might\nwork, particularly for small tasks, but it requires validation which can take\nalmost the same time as doing it in the first place.  Getting an LLM to\ncalculate for you sort of works, but it's much better for the LLM to write the\nPython code to do the calculation.  Why?  First, you can review the formula, not\nthe calculation.  We can it ourselves or we can use the LLM as a judge to figure\nout if the  is correct.  Don't really have to validate that Python\ncalculates correct, you can rely on that.  So, by opting for code generation for\ntask solving, we get a little closer to being able to verify and validate the\nprocess ourselves, rather than hoping the LLM inferred correctly.</p><p>This obviously goes way beyond calculation.  Take, for instance, this blog.  I\nconverted this entire blob from reStructuredText to Markdown recently.  I put\nthis conversion off for a really long time, partly because I was a little too\nlazy.  But also, when I was lazy enough to consider deploying an LLM for it, I\njust didn't trust it to do the conversion itself without regressing somewhere.\nI was worried that if it ran out of context, it might start hallucinating text\nor change wording slightly.  It's just that I worried about subtle regressions\ntoo much.</p><p>I still used an LLM for it, but I asked it to do that transformation in a\ndifferent way: through code.</p><ol><li><p>I asked the LLM to perform the core transformation from reStructuredText to\nMarkdown but I also asked it to do this in a way that uses the underlying AST\n(Abstract Syntax Tree).  So, I instructed it to parse the reStructuredText\ninto an actual reStructuredText AST, then convert that to a Markdown AST, and\nfinally render it to HTML, just like it did before. This gave me an intermediate\ntransformation step and a comparable end result.</p></li><li><p>Then, I asked it to write a script that compares the old HTML with the new HTML,\nperforms the diffing after some basic cleanup it deemed necessary for\ncomparison.  I asked it to consider what kind of conversion errors were\nactually acceptable.  So, it read through its own scripts to see where it might\nnot match the original output due to known technical limitations (e.g.,\nfootnotes render differently between the Markdown library I'm using and the\nreStructuredText library, so even if the syntax matches correctly, the HTML\nwould look different).  I asked it to compensate for this in that script.</p></li><li><p>After that was done, I asked it to create a third script, which I could run\nover the output of hundreds of files to analyze the differece to go back into\nthe agentic loop for another iteration tep.</p></li></ol><p>Then I kicked off off this in a loop.  I did not provide all the posts, I\nstarted with 10 until differences were low and then had it do it for all.  It\ndid this for maybe 30 minutes or so until I came back to it and found it in a\npretty acceptable state.</p><p>What's key about this transformation is not so much that the LLM was capable of\npulling it off, but that I actually trusted this process at the end because I\ncould review the approach.  Not only that, I also tried to ask another LLM what\nit thinks of the code that another LLM wrote, and the changes.  It gave me much\nhigher confidence that what was going on would not lose data.  It felt right to\nme.  It felt like a mechanical process that was fundamentally correct, and I was\nable to observe it and do spot checks.  At worst, the regressions were minor\nMarkdown syntax errors, but the text itself wouldn't have been corrupted.</p><p>Another key here is also that because the inference is rather constant, the cost\nof inference in this process scales with the number of iteration steps and the\nsample size, but it doesn't depend on how many documents I'm wanting to convert\noverall.  Eventually, I just had it run over all documents all the time but\nrunning it over 15 docs vs 150 docs is more or less the same effort, because the\nfinal LLM based analysis step did not have that many more things to review (it\nalready skipped over all minor differences in the files).</p><p>This is a long-winded way of saying that this entire transformation went through\ncode.  It's a pipeline that starts with human input, produces code, does an LLM\nas a judge step and iterates.  And you can take this transformation and apply it\nto a general task as well.</p><p>To give an example, one MCP you might be using is Playwright.  I find it very\nhard to replace Playwright with a code approach  because what\nyou're essentially doing is remotely controlling your browser.  The task you're\ngiving it largely involves reading the page, understanding what's on it, and\nclicking the next button.  That's the kind of scenario where it's very hard to\neliminate inference at each step.</p><p>However, if you already know what the page is — for instance, if you're\nnavigating your own app you're working on — then you can actually start telling\nit to write a Playwright Python script instead and run that.  This script can\nperform many of those steps sequentially without any inference.  I've noticed\nthat this approach is significantly quicker, and because it understands your\ncode, it still generally produces correct results.  It doesn't need to navigate,\nread page contents, find a button, or press an input in real-time.  Instead, it\nwill write a single Python script that automates the entire process in one go,\nrequiring very little context by comparison. </p><p>This process is repeatable.  Once the script is written, I can execute it 100,\n200, or even 300 times without requiring any further inference.  This is a\nsignificant advantage that an MCP typically cannot offer.  It's incredibly\nchallenging to get an LLM to understand generic, abstract MCP tool calls.  I\nwish I could, for example, embed an MCP client directly into a shell script,\nallowing me to run remote MCP services efficiently via code generation, but\nactually doing that is incredibly hard because the tools are not written with\nnon inference based automation in mind.</p><p>Also, as ironic as it is: I'm a human, not an MCP client.  I can run and debug a\nscript, I cannot even figure out how to reliably do MCP calls.  It's always a\ngamble and incredibly hard to debug.  I love using the little tools that Claude\nCode generates while generating code.  Some of those I had it convert into long\nterm additions to my development process.</p><p>I don't know.  But it's an interesting moment to think what we could potentially\ndo to make code generation for purposeful agentic coding better.  The weird\nthing is that MCP is actually pretty great when it works.  But it feels in the\ncurrent form too much like a dead end that cannot be scaled up, particularly to\nautomation at scale because it relies on inference too much.</p><p>So maybe we need to look at ways to find a better abstraction for what MCP is\ngreat at, and code generation.  For that that we might need to build better\nsandboxes and maybe start looking at how we can expose APIs in ways that allow\nan agent to do some sort of fan out / fan in for inference.  Effectively we want\nto do as much in generated code as we can, but then use the magic of LLMs after\nbulk code execution to judge what we did.</p><p>I can also imagine that it might be quite interesting to do code generation in a\nway that also provides enough context for an LLM to explain in human language to\na non programmer what the script is doing.  That might enable these flows to be\nused by human users that are not developers themselves.</p><p>In any case I can only encourage people to bypass MCP and to explore what else\nis possible.  LLMs can do so much more if you give them the power to write code.</p><p>Here are some more posts you might want to read or videos you might want to\nwatch:</p><ul><li>Drew Breunig's post “<a href=\"https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html\">How to fix your context</a>”\nwhich covers some attempts to improve MCP tool selection if you cannot avoid\nit.</li><li>Manuel Odendahl's excellent “<a href=\"https://www.youtube.com/watch?v=J3oJqan2Gv8\">MCPs are Boring</a>”\ntalk from AI Engineer that was one of the first to point to the challenges\nwith MCP.</li></ul>","contentLength":11719,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Integrating Long-Term Memory with Gemini 2.5","url":"https://www.philschmid.de/gemini-with-memory","date":1751500800,"author":"","guid":183176,"unread":true,"content":"<article>This guide shows you how to add long-term memory to your Gemini 2.5 chatbot using the Gemini API and Mem0.</article>","contentLength":106,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Organizations Need Expert Generalists","url":"https://martinfowler.com/articles/expert-generalist.html#WhyOrganizationsNeedExpertGeneralists","date":1751465100,"author":"Martin Fowler","guid":182730,"unread":true,"content":"<p>In complex environments, the characteristics of Expert Generalists lead\n      Gitanjali, and I thus complete our article by summarizing the value of\n      them to be particularly valuable in driving tasks to completion. Unmesh,\n      this skill.</p>","contentLength":245,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ubuntu Disables Spectre/Meltdown Protections","url":"https://www.schneier.com/blog/archives/2025/07/ubuntu-disables-spectre-meltdown-protections.html","date":1751454142,"author":"Bruce Schneier","guid":180462,"unread":true,"content":"<p>A whole class of speculative execution attacks against CPUs <a href=\"https://www.schneier.com/blog/archives/2018/01/spectre_and_mel_1.html\">were published</a> in 2018. They seemed pretty catastrophic at the time. But the fixes were as well. Speculative execution was a way to speed up CPUs, and removing those enhancements resulted in significant performance drops.</p><p>Now, people are rethinking the trade-off. Ubuntu <a href=\"https://bugs.launchpad.net/ubuntu/+source/intel-compute-runtime/+bug/2110131\">has disabled</a> some protections, resulting in  20% performance boost.</p><blockquote><p>After discussion between Intel and Canonical’s security teams, we are in agreement that Spectre no longer needs to be mitigated for the GPU at the Compute Runtime level. At this point, Spectre has been mitigated in the kernel, and a clear warning from the Compute Runtime build serves as a notification for those running modified kernels without those patches. For these reasons, we feel that Spectre mitigations in Compute Runtime no longer offer enough security impact to justify the current performance tradeoff.</p></blockquote><p>I agree with this trade-off. These attacks are hard to get working, and it’s not easy to exfiltrate useful data. There are way easier ways to attack systems.</p>","contentLength":1073,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Expert Generalists need specialists (and LLMs)","url":"https://martinfowler.com/articles/expert-generalist.html#ExpertGeneralistsStillNeedSpecialists","date":1751375820,"author":"Martin Fowler","guid":178927,"unread":true,"content":"<p>While we've spent this article praising the Expert Generalist, Unmesh,\n      Gitanjali, and I simultaneously do not deny the value of specialist\n      knowledge. To be the most efficient, a team needs some specialist skill.\n      We've also observed that Expert Generalist capabilities are considerably\n      more valuable when working with LLMs.</p>","contentLength":346,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Iranian Blackout Affected Misinformation Campaigns","url":"https://www.schneier.com/blog/archives/2025/07/iranian-blackout-affected-misinformation-campaigns.html","date":1751368071,"author":"Bruce Schneier","guid":178866,"unread":true,"content":"<p>Dozens of accounts on X that promoted Scottish independence <a href=\"https://www.scottishdailyexpress.co.uk/news/politics/iranian-pro-scottish-independence-accounts-35450209\">went dark</a> during an internet blackout in Iran.</p><p>Well, that’s one way to identify fake accounts and misinformation campaigns.</p>","contentLength":184,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Cybersecurity Fears Affect Confidence in Voting Systems","url":"https://www.schneier.com/blog/archives/2025/06/cyberattacks-shake-voters-trust-in-elections.html","date":1751281536,"author":"Bruce Schneier","guid":176564,"unread":true,"content":"<p>American democracy runs on trust, and that trust is cracking.</p><p>Nearly half of Americans, both Democrats and Republicans, question whether elections are <a href=\"https://news.gallup.com/poll/651185/partisan-split-election-integrity-gets-even-wider.aspx\">conducted fairly</a>. Some voters accept election results only <a href=\"https://worldjusticeproject.org/our-work/research-and-data/rule-law-united-states\">when their side wins</a>. The problem isn’t just political polarization—it’s a creeping <a href=\"https://www.pewresearch.org/politics/2018/10/29/elections-in-america-concerns-over-security-divisions-over-expanding-access-to-voting/\">erosion of trust</a> in the machinery of democracy itself.</p><p>Commentators blame ideological tribalism, <a href=\"https://www.nytimes.com/2024/01/09/business/media/election-disinformation-2024.html\">misinformation campaigns</a> and <a href=\"https://www.nytimes.com/2022/06/15/opinion/social-media-polarization-democracy.html\">partisan echo chambers</a> for this crisis of trust. But these explanations miss a critical piece of the puzzle: a growing unease with the digital infrastructure that now underpins nearly every aspect of how Americans vote.</p><p>The digital transformation of American elections has been swift and sweeping. Just two decades ago, most people voted using mechanical levers or punch cards. Today, <a href=\"https://electionlab.mit.edu/research/voting-technology\">over 95% of ballots</a> are counted electronically. Digital systems have replaced poll books, taken over voter identity verification processes and are integrated into registration, counting, auditing and voting systems.</p><p>This technological leap has made voting more accessible and efficient, and <a href=\"https://www.scientificamerican.com/article/voting-has-never-been-more-secure-than-it-is-right-now/\">sometimes more secure</a>. But these new systems are also more complex. And that complexity plays into the hands of those looking to undermine democracy.</p><p>In recent years, authoritarian regimes have refined a <a href=\"https://cyberscoop.com/china-midterms-elections-influence-nord-hacking/\">chillingly effective strategy</a> to chip away at Americans’ faith in democracy by relentlessly sowing doubt about the tools U.S. states use to conduct elections. It’s a sustained <a href=\"https://www.brookings.edu/articles/misinformation-is-eroding-the-publics-confidence-in-democracy/\">campaign to fracture civic faith</a> and make Americans believe that democracy is rigged, especially when their side loses.</p><p>This is not cyberwar in the traditional sense. There’s no evidence that anyone has managed to break into voting machines and alter votes. But cyberattacks on election systems don’t need to succeed to have an effect. Even a single failed intrusion, magnified by sensational headlines and political echo chambers, is enough to shake public trust. By feeding into existing anxiety about the complexity and opacity of digital systems, adversaries create <a href=\"https://www.nytimes.com/2024/04/01/business/media/china-online-disinformation-us-election.html\">fertile ground for disinformation and conspiracy theories</a>.</p><p>To test this dynamic, we launched a study to uncover precisely how cyberattacks corroded trust in the vote during the 2024 U.S. presidential race. We surveyed more than 3,000 voters before and after election day, testing them using a series of fictional but highly realistic breaking news reports depicting cyberattacks against critical infrastructure. We randomly assigned participants to watch different types of news reports: some depicting cyberattacks on election systems, others on unrelated infrastructure such as the power grid, and a third, neutral control group.</p><p>The results, which are under peer review, were both striking and sobering. Mere exposure to reports of cyberattacks <a href=\"https://drive.google.com/file/d/1M0iGIYk_WsxumppZ4ZEVAANS4CC9lTaQ/view\">undermined trust in the electoral process</a>—regardless of partisanship. Voters who supported the losing candidate experienced the greatest drop in trust, with two-thirds of Democratic voters showing heightened skepticism toward the election results.</p><p>But winners too showed diminished confidence. Even though most Republican voters, buoyed by their victory, accepted the overall security of the election, the majority of those who viewed news reports about cyberattacks remained suspicious.</p><p>The attacks didn’t even have to be related to the election. Even cyberattacks against critical infrastructure such as utilities had spillover effects. Voters seemed to extrapolate: “If the power grid can be hacked, why should I believe that voting machines are secure?”</p><p>Strikingly, voters who used digital machines to cast their ballots were the most rattled. For this group of people, belief in the accuracy of the vote count fell by nearly twice as much as that of voters who cast their ballots by mail and who didn’t use any technology. Their firsthand experience with the sorts of systems being portrayed as vulnerable personalized the threat.</p><p>It’s not hard to see why. When you’ve just used a touchscreen to vote, and then you see a news report about a digital system being breached, the leap in logic isn’t far.</p><p>Our data suggests that in a digital society, perceptions of trust—and distrust—are fluid, contagious and easily activated. The cyber domain isn’t just about networks and code. <a href=\"https://doi.org/10.1093/jogss/ogac042\">It’s also about emotions</a>: fear, vulnerability and uncertainty.</p><p>Does this mean we should scrap electronic voting machines? Not necessarily.</p><p>Every election system, digital or analog, has flaws. And in many respects, today’s high-tech systems have solved the problems of the past with voter-verifiable paper ballots. Modern voting machines reduce human error, increase accessibility and speed up the vote count. No one misses the <a href=\"https://www.nytimes.com/2000/11/12/us/counting-the-vote-the-ballots-after-cards-are-poked-the-confetti-can-count.html\">hanging chads</a> of 2000.</p><p>But technology, no matter how advanced, cannot instill legitimacy on its own. It must be paired with something harder to code: public trust. In an environment where foreign adversaries amplify every flaw, cyberattacks can trigger spirals of suspicion. It is no longer enough for elections to be secure – voters must also <a href=\"https://www.theguardian.com/commentisfree/2018/apr/18/american-elections-hack-bruce-scheier\">perceive them to be secure</a>.</p><p>That’s why <a href=\"https://www.nytimes.com/2024/08/22/learning/2024-election-teaching-resources.html\">public education</a> surrounding elections is now as vital to election security as firewalls and encrypted networks. It’s vital that voters understand how elections are run, how they’re protected and how failures are caught and corrected. Election officials, civil society groups and researchers can teach <a href=\"https://verifiedvoting.org/audits/\">how audits work</a>, host open-source verification demonstrations and ensure that high-tech electoral processes are comprehensible to voters.</p><p>We believe this is an essential investment in democratic resilience. But it needs to be proactive, not reactive. By the time the doubt takes hold, it’s already too late.</p><p>Just as crucially, we are convinced that it’s time to rethink the very nature of cyber threats. People often imagine them in <a href=\"https://www.nytimes.com/2024/04/17/us/politics/china-cyber-us-infrastructure.html\">military terms</a>. But that framework misses the true power of these threats. The danger of cyberattacks is not only that they can destroy infrastructure or steal classified secrets, but that they chip away at societal cohesion, sow anxiety and fray citizens’ confidence in democratic institutions. These attacks erode the very idea of truth itself by making people doubt that anything can be trusted.</p><p>If trust is the target, then we believe that elected officials should start to treat trust as a national asset: something to be built, renewed and defended. Because in the end, elections aren’t just about votes being counted—they’re about people believing that those votes count.</p><p>And in that belief lies the true firewall of democracy.</p><p><em>This essay was written with Ryan Shandler and Anthony J. DeMattee, and originally appeared in <a href=\"https://theconversation.com/cyberattacks-shake-voters-trust-in-elections-regardless-of-party-259368\">The Conversation</a>.</em></p>","contentLength":6705,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The New Skill in AI is Not Prompting, It's Context Engineering","url":"https://www.philschmid.de/context-engineering","date":1751241600,"author":"","guid":176692,"unread":true,"content":"<article>Context Engineering is the new skill in AI. It is about providing the right information and tools, in the right format, at the right time.</article>","contentLength":138,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Friday Squid Blogging: What to Do When You Find a Squid “Egg Mop”","url":"https://www.schneier.com/blog/archives/2025/06/friday-squid-blogging-what-to-do-when-you-find-a-squid-egg-mop.html","date":1751058286,"author":"Bruce Schneier","guid":183112,"unread":true,"content":"<p><a href=\"https://news.stv.tv/north/what-are-squid-egg-mops-and-what-to-do-if-you-find-one\">Tips</a> on what to do if you find a mop of squid eggs.</p><p>As usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.</p>","contentLength":166,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Age of Integrity","url":"https://www.schneier.com/blog/archives/2025/06/the-age-of-integrity.html","date":1751022174,"author":"Bruce Schneier","guid":183111,"unread":true,"content":"<p>We need to talk about data integrity.</p><p>Narrowly, the term refers to ensuring that data isn’t tampered with, either in transit or in storage. Manipulating account balances in bank databases, removing entries from criminal records, and murder by removing notations about allergies from medical records are all integrity attacks.</p><p>More broadly, integrity refers to ensuring that data is correct and accurate from the point it is collected, through all the ways it is used, modified, transformed, and eventually deleted. Integrity-related incidents include malicious actions, but also inadvertent mistakes.</p><p>We tend not to think of them this way, but we have many primitive integrity measures built into our computer systems. The reboot process, which returns a computer to a known good state, is an integrity measure. The undo button is another integrity measure. Any of our systems that detect hard drive errors, file corruption, or dropped internet packets are integrity measures.</p><p>Just as a website leaving personal data exposed even if no one accessed it counts as a privacy breach, a system that fails to guarantee the accuracy of its data counts as an integrity breach – even if no one deliberately manipulated that data.</p><p>Integrity has always been important, but as we start using massive amounts of data to both train and operate AI systems, data integrity will become more critical than ever.</p><p>Most of the attacks against AI systems are integrity attacks. Affixing small stickers on road signs to fool AI driving systems is an integrity violation. Prompt injection attacks are another integrity violation. In both cases, the AI model can’t distinguish between legitimate data and malicious input: visual in the first case, text instructions in the second. Even worse, the AI model can’t distinguish between legitimate data and malicious commands.</p><p>Any attacks that manipulate the training data, the model, the input, the output, or the feedback from the interaction back into the model is an integrity violation. If you’re building an AI system, integrity is your biggest security problem. And it’s one we’re going to need to think about, talk about, and figure out how to solve.</p><p>Web 3.0 – the distributed, decentralized, intelligent web of tomorrow – is all about data integrity. It’s not just AI. Verifiable, trustworthy, accurate data and computation are necessary parts of cloud computing, peer-to-peer social networking, and distributed data storage. Imagine a world of driverless cars, where the cars communicate with each other about their intentions and road conditions. That doesn’t work without integrity. And neither does a smart power grid, or reliable mesh networking. There are no trustworthy AI agents without integrity.</p><p>We’re going to have to solve a small language problem first, though. Confidentiality is to confidential, and availability is to available, as integrity is to what? The analogous word is “integrous,” but that’s such an obscure word that it’s not in the Merriam-Webster dictionary, even in its unabridged version. I propose that we re-popularize the word, starting here.</p><p>We need research into integrous system design.</p><p>We need research into a series of hard problems that encompass both data and computational integrity. How do we test and measure integrity? How do we build verifiable sensors with auditable system outputs? How to we build integrous data processing units? How do we recover from an integrity breach? These are just a few of the questions we will need to answer once we start poking around at integrity.</p><p>There are deep questions here, deep as the internet. Back in the 1960s, the internet was designed to answer a basic security question: Can we build an available network in a world of availability failures? More recently, we turned to the question of privacy: Can we build a confidential network in a world of confidentiality failures? I propose that the current version of this question needs to be this: Can we build an integrous network in a world of integrity failures? Like the two version of this question that came before: the answer isn’t obviously “yes,” but it’s not obviously “no,” either.</p><p>Let’s start thinking about integrous system design. And let’s start using the word in conversation. The more we use it, the less weird it will sound. And, who knows, maybe someday the American Dialect Society will choose it as the word of the year.</p>","contentLength":4436,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"All color is best-effort","url":"https://fasterthanli.me/articles/all-color-is-best-effort","date":1751009400,"author":"Amos Wenger","guid":183072,"unread":true,"content":"<p data-bo=\"224\">I do not come to you with answers today, but rather some observations and a lot of questions.</p><a href=\"https://fasterthanli.me/articles/all-color-is-best-effort#the-weird-glitch\"></a><p data-bo=\"340\">Recently I was editing some video and I noticed this:</p><p data-bo=\"748\">Not what the finger is pointing at — the dots.</p><p data-bo=\"798\">Here are the separate layers this image is made up of: the background is a stock image\nI’ve licensed from Envato Elements:</p><p data-bo=\"1001\">Because I use it as a background image, I’ve cranked down the exposition in the Color tab:</p><a href=\"https://fasterthanli.me/articles/all-color-is-best-effort#playing-with-color-spaces\"></a><a href=\"https://fasterthanli.me/articles/all-color-is-best-effort#cie-chromaticity-diagram\"></a><a href=\"https://fasterthanli.me/articles/all-color-is-best-effort#our-first-transfer-function\"></a><a href=\"https://fasterthanli.me/articles/all-color-is-best-effort#parade-scope\"></a><a href=\"https://fasterthanli.me/articles/all-color-is-best-effort#more-transfer-functions\"></a><a href=\"https://fasterthanli.me/articles/all-color-is-best-effort#how-white-is-your-white\"></a><a href=\"https://fasterthanli.me/articles/all-color-is-best-effort#conclusion\"></a>","contentLength":410,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["blog"]}