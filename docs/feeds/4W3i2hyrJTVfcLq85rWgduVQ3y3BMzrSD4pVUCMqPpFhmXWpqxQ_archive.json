{"id":"4W3i2hyrJTVfcLq85rWgduVQ3y3BMzrSD4pVUCMqPpFhmXWpqxQ","title":"Hacker News: Front Page","displayTitle":"HN Front","url":"https://hnrss.org/frontpage?points=75","feedLink":"https://news.ycombinator.com/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":16,"items":[{"title":"Generating Voronoi Diagrams Using Fortune's Algorithm (With Odin)","url":"https://redpenguin101.github.io/html/posts/2025_01_21_voronoi.html","date":1739011277,"author":"redpenguin101","guid":237,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42982015"},{"title":"LINUX is obsolete (1992)","url":"https://groups.google.com/g/comp.os.minix/c/wlhw16QWltI","date":1738987528,"author":"talles","guid":236,"unread":true,"content":"Sorry, but I just can't resist this thread...:-)<div><p>&gt;In article &lt;<a href=\"https://groups.google.com/g/comp.os.minix/c/wlhw16QWltI\" data-email-masked=\"\" rel=\"nofollow\">1992Jan29.2...@klaava.Helsinki.FI</a>&gt; <a href=\"https://groups.google.com/g/comp.os.minix/c/wlhw16QWltI\" data-email-masked=\"\" rel=\"nofollow\">torv...@klaava.Helsinki.FI</a> (Linus Benedict Torvalds) writes:&gt;&gt;You use this [being a professor] as an excuse for the limitations of minix? <p>&gt;The limitations of MINIX relate at least partly to my being a professor:</p>&gt;An explicit design goal was to make it run on cheap hardware so students<p>&gt;could afford it.  In particular, for years it ran on a regular 4.77 MHZ PC</p>&gt;with no hard disk.  </p></div><p>And an explicit design goal of Linux was to take advantage of the specialfeatures of the 386 architecture.  So what exactly is your point?  Different<p>design goals get you different designs.  You ought to know that.</p></p><div><p>&gt;You could do everything here including modify and recompile&gt;the system.  Just for the record, as of about 1 year ago, there were two<p>&gt;versions, one for the PC (360K diskettes) and one for the 286/386 (1.2M).</p>&gt;The PC version was outselling the 286/386 version by 2 to 1.  I don't have<p>&gt;figures, but my guess is that the fraction of the 60 million existing PCs that</p>&gt;are 386/486 machines as opposed to 8088/286/680x0 etc is small.  Among students</p></div><p>I find it very interesting that you claim here that Minix was designedprimarily for cheap hardware (in particular, the IBM PC/XT with no hard<p>disk) and yet elsewhere have also mentioned the virtues of being portable</p>across hardware platforms.  Well, if you insist on designing the thing<p>with the lowest common denominator as your basis, that's fine, but of</p>course the end result will be less than pretty unless designed *very*</p><div><p>&gt;Making software free, but only for folks with enough money&gt;to buy first class hardware is an interesting concept.</p></div><p>Except that Linux was designed more for the purposes of the designer thananything else.  If I were writing an OS, I'd design it to suit myself, too.<p>It's just that Linus was nice enough to share his code with the rest of us.</p></p><div><p>&gt;Of course 5 years from now that will be different, but 5 years from now &gt;everyone will be running free GNU on their 200 MIPS, 64M SPARCstation-5.</p></div><p>Maybe.  But by then, the 386/486 will probably be where the PC is now:everyone will have one and they'll be dirt cheap.  The timing will be<p>about right.  In which case Linux will fit right in, wouldn't you say?</p></p><div><p>&gt;&gt;Re 2: your job is being a professor and researcher: That's one hell of a&gt;&gt;good excuse for some of the brain-damages of minix. I can only hope (and<p>&gt;&gt;assume) that Amoeba doesn't suck like minix does.</p>&gt;Amoeba was not designed to run on an 8088 with no hard disk.</p></div><p>Here's a question for you: as a general rule, when you go to design anoperating system, do you design it for specific capabilities and then run<p>it on whatever hardware will do the job, or do you design it with the</p>hardware as a target and fit the capabilities to the hardware?  With respect<p>to Minix, it seems you did the latter, but I don't know whether or not you</p>did that with Amoeba.</p><div><p>&gt;&gt;If this was the only criterion for the \"goodness\" of a kernel, you'd be&gt;&gt;right.  What you don't mention is that minix doesn't do the micro-kernel<p>&gt;&gt;thing very well, and has problems with real multitasking (in the</p>&gt;&gt;kernel).  If I had made an OS that had problems with a multithreading<p>&gt;&gt;filesystem, I wouldn't be so fast to condemn others: in fact, I'd do my</p>&gt;&gt;damndest to make others forget about the fiasco.<p>&gt;A multithreaded file system is only a performance hack.  </p></p></div><p>Bull.  A multithreaded file system has a completely different design thana single-threaded file system and has different design criteria than a<p>single-threaded file system.</p></p><div><p>&gt;When there is only one job active, the normal case on a small PC, it buys&gt;you nothing and adds complexity to the code.  </p></div><p>If there is only going to be one job active anyway then *why bother withmultitasking at all*????</p><p>If you're going to implement multitasking, then don't do a halfway jobof it.  On the other hand, if you're going to assume that there will be<p>only one job active anyway, then don't bother with multitasking (after</p>all, it *does* complicate things :-).</p><div><p>&gt;On machines fast enough to&gt;support multiple users, you probably have enough buffer cache to insure a<p>&gt;hit cache hit rate, in which case multithreading also buys you nothing.  </p></p></div><p>Maybe.  Multiple users means multiple things being done simultaneously.  Iwouldn't bet on the buffer cache buying you so much that multithreading<p>makes no difference.  It's one thing if the users are doing something</p>simple, like editing a file.  It's another thing if they're compiling,<p>reading news, or other things that touch lots of different files.</p></p><div><p>&gt;It is only a win when there are multiple processes actually doing real disk&gt;I/O.  </p></div><p>Which happens a *lot* when you're running multiple users.  Or when you'rea machine hooked up to the net and handling news traffic.</p><div><p>&gt;Whether it is worth making the system more complicated for this case is&gt;at least debatable.</p></div><p>Oh, come on.  How tough is it to implement a multi-threaded file system?All you need is a decent *buffered* (preferably infinitely so)<p>message-passing system and a way to save your current state when you send</p>out a request to the device driver(s) to perform some work (and obviously<p>some way to restore that state).  Minix has the second via the setjmp()/</p>longjmp() mechanism, but lacks the former in a serious way.</p><div><p>&gt;I still maintain the point that designing a monolithic kernel in 1991 is&gt;a fundamental error.  </p></div><p>Not if you're trying to implement the system call semantics of Unix in areasonably simple and elegant way.</p><div><p>&gt;Be thankful you are not my student.  You would not&gt;get a high grade for such a design :-)</p></div><p>Why not?  What's this big thing against monolithic kernels?  There arecertain classes of problems for which a monolithic kernel is a more<p>appropriate design than a microkernel architecture.  I think implementing</p>Unix semantics with a minimum of fuss is one such problem.</p><p>Unless you can suggest an elegant way to terminate a system call uponreceipt of a signal from within a microkernel OS?</p><div><p>&gt;&gt;The fact is that linux is more portable than minix.  What? I hear you&gt;&gt;say.  It's true - but not in the sense that ast means: I made linux as<p>&gt;&gt;conformant to standards as I knew how (without having any POSIX standard</p>&gt;&gt;in front of me).  Porting things to linux is generally /much/ easier<p>&gt;&gt;than porting them to minix.</p>&gt;MINIX was designed before POSIX, and is now being (slowly) POSIXized as <p>&gt;everyone who follows this newsgroup knows.  Everyone agrees that user-level </p>&gt;standards are a good idea.  As an aside, I congratulate you for being able <p>&gt;to write a POSIX-conformant system without having the POSIX standard in front </p>&gt;of you. I find it difficult enough after studying the standard at great length.&gt;My point is that writing a new operating system that is closely tied to any<p>&gt;particular piece of hardware, especially a weird one like the Intel line,</p>&gt;is basically wrong.  </p></div><p>Weird as the Intel line may be, it's *the* most popular line, by severaltimes.  So it's not like it's *that* big a loss.  And Intel hardware is<p>at least relatively cheap to come by, regardless of what your students</p>might tell you (why do you think they all own PCs?)...</p><div><p>&gt;An OS itself should be easily portable to new hardware&gt;platforms.  </p></div><p>As long as you don't sacrifice too much in the way of performance orarchitectural elegance in order to gain this.  Unfortunately, that's<p>*exactly* what happened with Minix: in attempting to implement it on</p>hardware of the lowest caliber, you ended up having to make design<p>decisions with respect to the architecture and implementation that have</p>made vintage Minix unusable as anything more than a personal toy operating<p>system.  For example: why didn't you implement a system call server as</p>a layer between the file system and user programs?  My guess: you didn't<p>have enough memory on the target machine to do it.</p></p><p>Put another way: you hit your original goal right on target, and are tobe applauded for that.  But in doing so, you missed a lot of other<p>targets that wouldn't have been hard to hit as well, with some</p>consideration of them.  I think.  But I wasn't there when you were making<p>the decisions, so it's real hard for me to say for sure.  I'm speaking</p>from hindsight, but you had the tough problem of figuring out what to do</p><p>Now, *modified* Minix is usable.  Add a bigger buffer cache.  Modify itso that it can take advantage of 386 protected mode.  Fix the tty driver<p>so that it will give you multiple consoles.  Fix the rs232 driver to deal</p>with DCD/DTR and do the right thing when carrier goes away.  Fix the pipes<p>so that read and write requests don't fail just because they happen to be</p>bigger than the size of a physical pipe.  Add shared text segments so you<p>maximize the use of your RAM.  Fix the scheduler so that it deals with</p>character I/O bound processes in a reasonable way.</p><div><p>&gt;When OS/360 was written in assembler for the IBM 360&gt;25 years ago, they probably could be excused.  When MS-DOS was written<p>&gt;specifically for the 8088 ten years ago, this was less than brilliant, as</p>&gt;IBM and Microsoft now only too painfully realize. </p></div><p>Yeah, right.  Just what hardware do you think they'd like to port DOS to,anyway?  I can't think of any.  I don't think IBM or Microsoft are<p>regretting *that* particular aspect of DOS.  Rather, they're probably</p>regretting the fact that it was written for the address space provided</p><p>MS-DOS isn't less than brilliant because it was written for one machinearchitecture.  It's less than brilliant because it doesn't do anything<p>well, *regardless* of its portability or lack thereof.</p></p><div><p>&gt;Writing a new OS only for the<p>&gt;386 in 1991 gets you your second 'F' for this term.  But if you do real well</p>&gt;on the final exam, you can still pass the course.</p></div><p>He made his code freely redistributable.  *You* didn't even do that.  Justfor that move alone, he scores points in my book.  Of course, the<p>distribution technology available to him is much better than what was</p>available when you did Minix, so it's hard to fault you for that...</p><p>But I must admit, Minix is still one hell of a bargain, and I would neverhesitate to recommend it to anyone who wants to learn something about Unix<p>and operating systems in general.  As a working operating system (i.e.,</p>one intended for a multi-user environment), however, I'd hesitate to<p>recommend it, except that there really aren't any good alternatives</p>(except Linux, of course, at least tentatively.  I can't say for sure,<p>since I haven't checked out Linux yet), since it doesn't have the performance</p>capabilities that a working operating system needs.</p>","contentLength":10396,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42980283"},{"title":"Ghostwriter – use the reMarkable2 as an interface to vision-LLMs","url":"https://github.com/awwaiid/ghostwriter","date":1738983777,"author":"wonger_","guid":235,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42979986"},{"title":"Starlink in the Falkland Islands – A national emergency situation?","url":"https://www.openfalklands.com/february-2025-starlink-in-the-falkland-islands-a-national-emergency-situation/","date":1738982495,"author":"pelagicAustral","guid":234,"unread":true,"content":"<p>In yesterday’s (Thursday) <a href=\"https://www.openfalklands.com/february-2025-falkland-islands-starlink-status/\" target=\"_blank\" rel=\"noopener\">OpenFalklands blog</a>, I noted that while a week may seem long in politics, even a single day can feel like an eternity when it comes to Starlink developments in the Falklands.</p><p>And then, ‘Black Friday’ arrived on Friday, 7th of February!</p><p>This morning, some Falkland Islands Starlink users began experiencing service terminations as their 60-day roaming period expired, following Starlink’s Terms &amp; Conditions.</p><h3>Illegal use of Starlink in the Falkland Islands.</h3><p>Regardless of differing opinions, it is now an established fact that hundreds of Starlink terminals are in use in the Falkland Islands. The underlying reasons for this widespread adoption have been discussed extensively elsewhere and will not be reiterated here.</p><p>The high level of Starlink usage sparked a <a href=\"https://www.openfalklands.com/the-falkland-islands-starlink-petition-group-town-hall-presentation/\" target=\"_blank\" rel=\"noopener\">successful petition</a> backed by 70% of the island’s population. This petition demanded both a reduction of the £5,400 FIG VSAT licence fee and formal approval for Starlink’s operation in the Falkland Islands.</p><p>In response, a Starlink Select Committee – comprising all of the island’s MLAs – convened from July to October 2024. The committee formally endorsed the petition’s demands, and the proposal was subsequently forwarded to the Falkland Islands Government (FIG) for implementation. However, the effective date for this approval has now been delayed until April.</p><p>Because Sure International holds an exclusive monopoly telecommunications licence, Starlink’s use in the islands is currently illegal. Nonetheless, this restriction has not prevented the widespread installation of hundreds of Starlink terminals, which remain unlicensed.</p><p>At this time, Starlink has not received an official government statement endorsing its use in the Falkland Islands – a prerequisite for adding the territory to Starlink’s approved list of service areas. As a result, using Starlink in the islands continues to be illegal and is considered a criminal offence.</p><h3>The £5,400 FIG VSAT licence</h3><p>In addition to the hundreds of unlicensed Starlink terminals operating on the islands, two groups of users are deemed “legal” by FIG – even though Starlink has not yet received formal permission to provide service in the Falkland Islands.</p><p>Starlink’s low Earth orbit (LEO) satellites are classified as very small aperture terminal (VSAT), a contentious categorisation. This definition was partly adopted to prevent islanders from self-provisioning internet services, thereby protecting Sure International’s telecommunications monopoly. Notably, the original legislation included an exemption for Falkland Islands government entities, allowing them to use Starlink without requiring a VSAT licence.</p><p>In 2024, several government departments took advantage of this exemption to install Starlink terminals – a move that garnered widespread support. Among the early adopters were FIG’s IT department and the Falkland Islands Development Corporation (FIDC). The KEMH is ‘earmarked’ for Starlink use, but it has yet to be installed.</p><p>That same year, rising demand from individuals and local businesses prompted the Communications Regulator to issue a limited number of FIG VSAT licences. Although the exact number remains undisclosed outside of government circles, estimates suggest that approximately fourteen licences were granted, including, among others, most of the island’s fishing companies, the inter-island ferry, and International Tours &amp; Travel the local agent for LATAM flights.</p><p>It is important to emphasize that until FIG formally permits Starlink to operate in the Falkland Islands, any use of Starlink remains officially illegal. Consequently, neither of these two user groups are operating within a fully legal framework no differently than the hundreds of consumer ‘illegal’ users.</p><p>Questionable FIG-issued VSAT licences effectively permit Starlink usage from a FIG perspective, even though the service is still legally classified as a criminal act.</p><p><strong>Starlink users who have paid £5,400 for a FIG VSAT licence are not, in any way, in a beneficial position compared to the hundreds of&nbsp; ‘illegal’ consumer users and cannot be considered to be so.</strong></p><p>A message from the Communications Regulator was distributed this morning.</p><blockquote><p><em>I’ve had reports this morning that some users have had their Starlink services disabled. If you have got back to me already with the below information, then this has already been passed to a team at Starlink who I understand will work to keep the service on. </em></p><p><em>If you haven’t got back to me with the information below, then please do so asap. &nbsp; I hope that you haven’t lost access and please be assured I am working to address this. So sorry for any inconvenience caused – which I am sure would be significant! &nbsp; Many thanks – and do give me a call if you need!”</em></p></blockquote><p>There is currently no ethical or legal basis for Starlink to differentiate between supplying service to users holding FIG VSAT licences and the hundreds of unlicensed users on the Falkland Islands.</p><p>Requesting such differentiation is highly controversial. It would force Starlink into an ethically and legally precarious position – essentially endorsing a select group of users while its service remains a criminal offence under Falkland Islands law. In this context, holding a FIG VSAT licence does not change the legal status of Starlink usage.</p><h3>An emergency needs emergency actions.</h3><p>The sudden shutdown of Starlink services clearly qualifies as a National Emergency due to the widespread and unforeseen consequences such an action would have. Moreover, the government finds itself in a difficult position concerning holders of a FIG VSAT licence as they are threatened too.</p><p>For instance, if Sure Falkland Islands Intelsat satellite(s) were damaged by space debris – thereby cutting off the islands’ communications – the situation would undoubtedly be classified as a National Emergency.</p><p>Allowing the current situation to continue until April seems untenable, especially since many more Starlink users risk losing service as their roaming periods expire in the coming months. This issue could be resolved in a number of days if a National Emergency were declared.</p><p>During the COVID-19 crisis in 2020, a National Emergency was declared within half a day, demonstrating how quickly decisive action can be taken when circumstances demand it.</p><blockquote><p> “Nothing contained in or done under the authority of a law shall be held to be inconsistent with or in contravention of any of the provisions of this Chapter, except for sections 2, 3, 4, 6(2)(a), 6(5), 6(6), 6(7) and 6(…), to the extent that the law authorises the taking of measures during any period of public emergency that are reasonably justifiable for addressing the situation in the Falkland Islands during that period.”</p></blockquote><p>It is important to note that the declaration of a National Emergency can only be made by the Falkland Islands Government following an emergency meeting of the EXCO.</p><p>Surely, it must be to everyone’s benefit to get this situation resolved as soon as possible by permitting Starlink to operate in the Falkland Islands now?</p><p>Sure’s post this morning.<img loading=\"lazy\" decoding=\"async\" src=\"https://www.openfalklands.com/wp-content/uploads/sites/12/2025/02/surecomeback-post.png\" alt=\"\" width=\"1045\" height=\"482\" srcset=\"https://www.openfalklands.com/wp-content/uploads/sites/12/2025/02/surecomeback-post.png 1045w, https://www.openfalklands.com/wp-content/uploads/sites/12/2025/02/surecomeback-post-300x138.png 300w, https://www.openfalklands.com/wp-content/uploads/sites/12/2025/02/surecomeback-post-1024x472.png 1024w, https://www.openfalklands.com/wp-content/uploads/sites/12/2025/02/surecomeback-post-768x354.png 768w\" sizes=\"auto, (max-width: 1045px) 100vw, 1045px\"></p><p>Chris Gare, OpenFalklands February 2025, copyright OpenFalklands</p>","contentLength":7183,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42979869"},{"title":"VSCode’s SSH agent is bananas","url":"https://fly.io/blog/vscode-ssh-wtf/","date":1738977932,"author":"zdyxry","guid":233,"unread":true,"content":"<p>We’re interested in getting integrated into the flow VSCode uses to do remote editing over SSH, because everybody is using VSCode now, and, in particular, they’re using forks of VSCode that generate code with LLMs. </p><div><p>”hallucination” is what we call it when LLMs get code wrong; “engineering” is what we call it when people do.</p></div><p>LLM-generated code is <a href=\"https://nicholas.carlini.com/writing/2024/how-i-use-ai.html\" title=\"\">useful in the general case</a> if you know what you’re doing. But it’s ultra-useful if you can close the loop between the LLM and the execution environment (with an “Agent” setup). There’s lots to say about this, but for the moment: it’s a semi-effective antidote to hallucination: the LLM generates the code, the agent scaffolding runs the code, the code generates errors, the agent feeds it back to the LLM, the process iterates. </p><p>So, obviously, the issue here is you don’t want this iterative development process happening on your development laptop, because LLMs have boundary issues, and they’ll iterate on your system configuration just as happily on the Git project you happen to be working in. A thing you’d really like to be able to do: run a closed-loop agent-y (“agentic”? is that what we say now) configuration for an LLM, on a clean-slate Linux instance that spins up instantly and that can’t screw you over in any way. You get where we’re going with this.</p><p>Anyways! I would like to register a concern.</p><p>Emacs hosts the spiritual forebearer of remote editing systems, a blob of hyper-useful Elisp called <a href=\"https://www.gnu.org/software/tramp/\" title=\"\">“Tramp”</a>. If you can hook Tramp up to any kind of interactive environment — usually, an SSH session — where it can run Bourne shell commands, it can extend Emacs to that environment.</p><p>So, VSCode has a feature like Tramp. Which, neat, right? You’d think, take Tramp, maybe simplify it a bit, switch out Elisp for Typescript.</p><p>Unlike Tramp, which lives off the land on the remote connection, VSCode mounts a full-scale invasion: it runs a Bash snippet stager that downloads an agent, including a binary installation of Node. </p><p>The agent runs over port-forwarded SSH. It establishes a WebSockets connection back to your running VSCode front-end. The underlying protocol on that connection can:</p><ul><li>Wander around the filesystem\n</li><li>Launch its own shell PTY processes\n</li></ul><p>In security-world, there’s a name for tools that work this way. I won’t say it out loud, because that’s not fair to VSCode, but let’s just say the name is murid in nature.</p><p>I would be a little nervous about letting people VSCode-remote-edit stuff on dev servers, and apoplectic if that happened during an incident on something in production. </p><p>It turns out we don’t have to care about any of this to get a custom connection to a Fly Machine working in VSCode, so none of this matters in any kind of deep way, but: we’ve decided to just be a blog again, so: we had to learn this, and now you do too.</p>","contentLength":2855,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42979467"},{"title":"Show HN: ExpenseOwl – Simple, self-hosted expense tracker","url":"https://github.com/Tanq16/ExpenseOwl","date":1738961818,"author":"import-base64","guid":202,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42977388"},{"title":"Do-nothing scripting: the key to gradual automation (2019)","url":"https://blog.danslimmon.com/2019/07/15/do-nothing-scripting-the-key-to-gradual-automation/","date":1738957696,"author":"tehnub","guid":232,"unread":true,"content":"<p>Every ops team has some manual procedures that they haven’t gotten around to automating yet. <a href=\"https://landing.google.com/sre/sre-book/chapters/eliminating-toil/\">Toil</a> can never be totally eliminated.</p><p>Very often, the biggest toil center for a team at a growing company will be its procedure for modifying infrastructure or its procedure for provisioning user accounts. Partial instructions for the latter might look like this:</p><ol><li>Create an SSH key pair for the user.</li><li>Commit the public key to Git and push to master.</li><li>Wait for the build job to finish.</li><li>Find the user’s email address in the employee directory.</li><li>Send the user their private key via 1Password.</li></ol><p>This is a relatively short example. Sometimes there are 20 steps in the process. Sometimes there are branches and special cases to keep track of as you go. Over time, these procedures can become unmanageably large and complex.</p><p>Procedures like this are frustrating because they’re focus-intensive yet require very little thought. They demand our full attention, but our attention isn’t rewarded with interesting problems or satisfying solutions – just another checkbox checked. I have a word for a procedure like this: a .</p><p>We know that this procedure is ripe for automation. We can easily see how to automate any given step. And we know that a computer could carry out the instructions with far greater speed and accuracy than we can, and with less tendency toward <a href=\"https://risk-engineering.org/concept/Rasmussen-practical-drift\">practical drift</a>.</p><p>However, automating slogs sometimes feels like an all-or-nothing proposition. Sure, we could write a script to handle step 2, or step 5. But that wouldn’t  make the procedure any less cumbersome. It would lead to a proliferation of single-purpose scripts with different conventions and expectations, and you’d still have to follow a documented multi-step procedure for using those scripts.</p><p>This perception of futility is the problem we really need to solve in order to escape from these manual slogs. I’ve found an approach that works pretty reliably: .</p><p>Almost any slog can be turned into a . A do-nothing script is a script that encodes the instructions of a slog, encapsulating each step in a function. For the example procedure above, we could write the following do-nothing script:</p><div><pre title=\"\">import sys\n\ndef wait_for_enter():\n    raw_input(\"Press Enter to continue: \")\n\nclass CreateSSHKeypairStep(object):\n    def run(self, context):\n        print(\"Run:\")\n        print(\"   ssh-keygen -t rsa -f ~/{0}\".format(context[\"username\"]))\n        wait_for_enter()\n\nclass GitCommitStep(object):\n    def run(self, context):\n        print(\"Copy ~/new_key.pub into the `user_keys` Git repository, then run:\")\n        print(\"    git commit {0}\".format(context[\"username\"]))\n        print(\"    git push\")\n        wait_for_enter()\n\nclass WaitForBuildStep(object):\n    build_url = \"http://example.com/builds/user_keys\"\n    def run(self, context):\n        print(\"Wait for the build job at {0} to finish\".format(self.build_url))\n        wait_for_enter()\n\nclass RetrieveUserEmailStep(object):\n    dir_url = \"http://example.com/directory\"\n    def run(self, context):\n        print(\"Go to {0}\".format(self.dir_url))\n        print(\"Find the email address for user `{0}`\".format(context[\"username\"]))\n        context[\"email\"] = raw_input(\"Paste the email address and press enter: \")\n\nclass SendPrivateKeyStep(object):\n    def run(self, context):\n        print(\"Go to 1Password\")\n        print(\"Paste the contents of ~/new_key into a new document\")\n        print(\"Share the document with {0}\".format(context[\"email\"]))\n        wait_for_enter()\n\nif __name__ == \"__main__\":\n    context = {\"username\": sys.argv[1]}\n    procedure = [\n        CreateSSHKeypairStep(),\n        GitCommitStep(),\n        WaitForBuildStep(),\n        RetrieveUserEmailStep(),\n        SendPrivateKeyStep(),\n    ]\n    for step in procedure:\n        step.run(context)\n    print(\"Done.\")\n</pre></div><p>This script doesn’t actually  any of the steps of the procedure. That’s why it’s called a do-nothing script. It feeds the user a step at a time and waits for them to complete each step manually.</p><p>At first glance, it might not be obvious that this script provides value. Maybe it looks like all we’ve done is make the instructions harder to read. But the value of a do-nothing script is immense:</p><ul><li>It’s now much less likely that you’ll lose your place and skip a step. This makes it easier to maintain focus and power through the slog.</li><li>Each step of the procedure is now encapsulated in a function, which makes it possible to replace the text in any given step with code that performs the action automatically.</li><li>Over time, you’ll develop a library of useful steps, which will make future automation tasks more efficient.</li></ul><p>A do-nothing script doesn’t save your team any manual effort. It lowers the activation energy for automating tasks, which allows the team to eliminate toil over time.</p>","contentLength":4783,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42976698"},{"title":"Show HN: A website that heatmaps your city based on your housing preferences","url":"https://theretowhere.com/","date":1738952620,"author":"WiggleGuy","guid":201,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42975803"},{"title":"A brief history of code signing at Mozilla","url":"https://hearsum.ca/posts/history-of-code-signing-at-mozilla/","date":1738950709,"author":"todsacerdoti","guid":231,"unread":true,"content":"<p>Shipping large software to end-user devices is a complicated process. Shipping large software  to end-user devices is even more complicated. Signing the things that ship to end-user devices is one of those complications, and it gets even more complicated when you sign thousands of artifacts per day.</p><p>Mozilla has been signing Firefox in some form beginning with Firefox 1.0. This began with detached GPG signatures for builds, and progressed to Authenticode signing for Windows installers in Firefox 1.0.1. Since then it has evolved over time to encompass other platforms, other types of files within our products, and other ways that we ship (such as our own update packages). This post will provide a overview of the what, when, why, and how of code signing at Mozilla over the past ~20 years.</p><h3>Early GPG &amp; Authenticode Signing</h3><p>When we first began signing, it happened on a Windows machine. Late in the release process, after Windows installers had been built, we would download all of the release artifacts to this machine, sign the Windows installers, and generate detached GPG signatures for those before pushing the artifacts elsewhere.</p><p>At this time, the private keys and certificates were held on a USB stick that was kept removed from the machine at-rest. A Release Engineer needed to be physically present in Mountain View to perform this step. Once inserted, signing could be done via Remote Desktop rather than at the physical machine (but don't forget to remove the USB stick afterwards!).</p><p>GPG signing was done with the standard GPG tools, running in cygwin. Authenticode signing was also done with the standard (at the time) Microsoft 'signcode.exe' tool. An annoying fact about that tool, is that it only accepted the necessary passphrase from a GUI dialog. To work around this, we had an <a href=\"https://en.wikipedia.org/wiki/AutoIt\">AutoIt</a> script running in the background that injected the passphrase into this dialog whenever it popped up. This interesting way of automating the process meant that mouse movements or keyboard interaction at the wrong time could interfere with the signing process.</p><p>This process was partly scripted, but there was still a series of ~15 commands someone had to run by hand (and not mess up) to get everything done. You can see these commands for yourself in our now-ancient <a href=\"https://wiki.mozilla.org/ReleaseEngineering/Unified_Release_Process#Sign_builds\">Unified Release Process</a> documentation.</p><h3>Windows internal file signing</h3><p>Careful readers may have noted that early Authenticode signing only covered the Firefox installer itself, not the EXEs and DLLs inside of it. At some point (I haven't gone to the effort of tracking down exactly where...) we started signing these inner files as well. This process seems to have been <a href=\"https://wiki.mozilla.org/ReleaseEngineering/Unified_Release_Process#Signing_windows_files\">lost to the sands of time</a>, but I seem to recall it worked very similarly to the installer signing process, but without the GPG parts.</p><h3>Improved signing on Windows</h3><p>The first notable improvement we had to this process was to automate most of the copy/pasting that was done from the wiki. This came in the form of <a href=\"https://github.com/mozilla/build-tools/blob/dba69406faad0c8e7a016150a3f5761ef83914d2/release/signing/Makefile\">a Makefile that with a few mere inputs</a>, would download, sign, and re-upload the signed builds. The main benefit of this was reduced opportunity for human error.</p><p>Despite the signing process now being very quick once it gets started, it could still sometimes take hours or longer to begin the process. Typically this would happen if our build and repack processes finished at a time when no Release Engineer was around to begin signing. This was solved with what we called \"autosign\". Rather than require a Release Engineer to be around at the right moment, we adjusted our scripts to allow them to <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=558464#c1\">be started ahead of time</a>, and be smart enough to know when all of the files it needs to sign are ready. This work eliminated all wait time between builds being ready and signing running.</p><h3>Signing Windows builds...on Linux!</h3><p>In 2011, <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=509158#c10\">signing was rearchitected altogether</a>. In short, the idea was to move signing to a highly secured Linux server, and sign builds through an API as part of the build process. This allowed builds to be signed as they were produced, and reduced the number of times builds had to move from one server to another before they shipped.\n\nAn obvious question here is how we would manage to sign Windows binaries on Linux...as it turns out, the mono project had <a href=\"https://manpages.debian.org/testing/mono-devel/signcode.1.en.html\">its own version of signcode that ran natively on Linux</a> that we were able to make use of.</p><p>Shortly after (and perhaps even motivating - I'm not sure at this point) the aforementioned signing server work, we <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=699700\">began signing our MAR (Mozilla ARchive) packages</a> that update users from an older version of Firefox to a newer version. Thanks to the earlier work, it was fairly trivial to use the same architecture to sign these files.</p><p>Unfortunately, there were no tools available at the time to sign macOS builds on anything except a fairly modern macOS machine. For this reason, we had to run additional copies of our signing server on macOS and sign those builds with them. (If you've ever had to run macOS as a server you'll know just how unfortunate this was...)</p><h3>Taskcluster/signingscript/iscript</h3><p>In 2018, Mozilla migrated its CI and Release automation from our aging Buildbot systems to <a href=\"https://taskcluster.net/\">Taskcluster</a>. As part of this, signing tasks moved to specialized Taskcluster workers known as \"signingscript\" and \"iscript\", used for signing non-macOS and macOS builds respectively. These specialized workers continued to outsource the actual work of signing to the previously discussed signing servers.</p><p>An important part of this change is the introduction of <a href=\"https://scriptworker.readthedocs.io/en/latest/chain_of_trust.html\">Chain of Trust</a>, a significant security enhancement that helps ensure that only authentic artifacts are signed to this day.</p><p><a href=\"https://github.com/mozilla-services/autograph\">Autograph</a> is Mozilla's modern code signing service. It was built specifically to provide a signing service that allowed us to keep private key material in Hardware Security Modules (HSMs). Migrating release signing to it was a huge improvement over the existing signing server where Release Engineers had direct access to such things. It was initially used for signing XPIs and APKs, but by the end of 2019 we had migrated all non-macOS signing to it and retired the old Linux signing servers.</p><p>In addition to the security enhancements it brought, we saw great performance wins with it as well, largely in thanks to it's support for <a href=\"https://github.com/mozilla-services/autograph/blob/main/docs/architecture.md#overview\"> only requiring a hash of the bytes being signed to be sent over the wire</a>. (This requires that the client has some advanced knowledge of the file being signed, but it saves a  amount of network traffic at our scale.)\n\n</p><h3>Notarization with rcodesign</h3>\n\nIn 2023 we started making use of <a href=\"https://gregoryszorc.com/docs/apple-codesign/0.17.0/apple_codesign_rcodesign.html\">rcodesign</a> to <a href=\"https://github.com/mozilla-releng/scriptworker-scripts/pull/714\">notarize and staple our macOS builds</a>. While actual macOS code signing itself continues to happen on macOS machines, this allowed us to move at least some of our operations into the cloud and reduce our reliance on mac hardware.\n\n<p>I've mentioned a number of tools and technology that we use as part of signing, but I've purposely glossed over some details in the interest of brevity. The following section is a glossary of sorts, and introduces some more under the hood tools that we use as part of signing. If you're interested in the gory details, the links below should be enough to find them for yourself! Or you can stop by <a href=\"https://chat.mozilla.org/#/room/#firefox-ci:mozilla.org\">#firefox-ci on Matrix to ask questions!</a></p><p>Winsign is a <a href=\"https://github.com/mozilla-releng/winsign\">python library for signing and manipulating Authenticode signatures</a>. It relies on osslsigncode for writing signatures, and supports signing directly with a private key, or outsourcing the signing process to a passed in function. The latter is what we use, and it's how we inject a call to Autograph into the signing process.</p><p>In 2021 we began shipping Firefox as an MSIX package. As part of this we discovered that osslsigncode does not support signing MSIX packages. Luckily for us, Microsoft's MSIX packaging tools are open source and run on Linux, and we found a <a href=\"https://github.com/microsoft/msix-packaging/issues/340#issuecomment-620797067\">fork that contained most of what was needed</a> to support signing. With a few additional modifications, we were able to support signing these packages in our existing systems.</p><p><a href=\"https://gregoryszorc.com/docs/apple-codesign/0.17.0/index.html\">apple-codesign</a> is a very exciting project from Gregory Szorc which provides 3rd party tools capable of signing, notarizing, and stapling .app bundles and other Apple formats such as .pkg and .dmg. These tools run on Linux, and as noted above, we're already making use of them to notarize and staple our .app bundles.\n\nWe're extremely excited about this project, and grateful to Gregory Szorc for all the effort he's bit into it. In the future we're looking forward to migrating our actual code signing to these tools which would (finally) allow us to retire our dedicated macOS signing machines.</p><p><a href=\"https://github.com/mozilla-releng/build-mar\">mardor</a> is a python tool to manage, and most importantly, sign, MAR files. In the days before Autograph it was used to directly sign MAR files. These days we only use it to inject signatures made by Autograph into the files, similar to our usage of osslsigncode.</p><p><a href=\"https://github.com/mozilla-releng/scriptworker-scripts/tree/master/signingscript\">signingscript</a> is the glue between our CI system (Taskcluster) and Autograph. Through a combination of the tools listed above, custom code in signingscript itself, and communication with Autograph it produces signed builds. It is additionally responsible for notarizing and stapling our macOS builds.</p><p><a href=\"https://github.com/mozilla-releng/scriptworker-scripts/tree/master/iscript\">iscript</a> is essentially a pared down version of signingscript (in fact their code is both derived from our early signing server code), and is responsible for signing our macOS builds. iscript runs on a small cluster of mac minis, which are a huge pain in the butt to manage.\n\n</p>\nAs noted in an earlier section <a href=\"https://github.com/mozilla-services/autograph\">Autograph</a> is our modern code signing service. It has a simple HTTP API that accepts signing requests and returns signed data or files. In addition to signing various artifacts that we ship it also makes <a href=\"https://github.com/mozilla-services/autograph/blob/main/signer/contentsignaturepki/README.md\">Content Signatures</a> on behalf of addons.mozilla.org, aus5.mozilla.org/Balrog (our update server), and some other backend services that Firefox communicates with, helping to ensure the security and integrity of requests made between Firefox and Mozilla-run services.\n\n<p>What a ride it's been over the last 20 years! We've gone from signing nothing to signing nearly everything in some form. Signing started off as a very manual process, and now happens seamlessly thousands of times per day.</p><p>I don't think it would be possible to name everyone that contributed to this, but it took the ideas and efforts of tens, if not hundreds, of people to get to this point: release engineers, build system experts, security folks, and many others were all critical to getting us where we are today.</p><p>I've got this post as brief as possible, but if you're interested in more details on any parts here feel free to reach out!</p>","contentLength":10486,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42975436"},{"title":"U.K. orders Apple to let it spy on users’ encrypted accounts","url":"https://www.washingtonpost.com/technology/2025/02/07/apple-encryption-backdoor-uk/","date":1738914305,"author":"Despegar","guid":229,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42970412"},{"title":"A colorful Game of Life","url":"https://colorlife.quick.jaredforsyth.com/","date":1738846517,"author":"azhenley","guid":228,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42961868"},{"title":"Hotline for modern Apple systems","url":"https://github.com/mierau/hotline","date":1738825286,"author":"tonymet","guid":227,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42959841"},{"title":"Implementing a Game Boy emulator in Ruby","url":"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/","date":1738816363,"author":"Kerrick","guid":226,"unread":true,"content":"<p>I created a Game Boy emulator in Ruby and released it as a gem called rubyboy!\n(I’d be happy if you could give it a star!)</p><p>And now it runs in the browser using WebAssembly!</p><p>While explaining the implementation process of Ruby Boy, I’ll introduce the points where I got stuck and the techniques I devised.\nI’ll also introduce what I did to optimize Ruby Boy.</p><p>Finally, I’ll show how Ruby Boy works in the browser using WebAssembly.</p><h2>Why I Created a Game Boy Emulator<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#why-i-created-a-game-boy-emulator\">#</a></h2><ul><li>I wanted to do some personal development, but since web services incur maintenance costs, I wanted to create something that could be maintained for free</li><li>As I use Ruby for work, I had been wanting to create a Ruby gem for a while</li><li>Developing a game emulator has “clear goals &amp; is fun when it works”, so it seemed like it would be easier to maintain motivation<ul><li>In particular, I have a special attachment to the Game Boy</li></ul></li></ul><p>→ Let’s create a Game Boy emulator in Ruby and release it as a gem!</p><p>The following image is the architecture of the Game Boy:</p><p>The goal is to implement a program that emulates this hardware.\nThe class diagram of Ruby Boy and the roles of each class are as follows:</p><ul><li>Lcd: Handles screen rendering</li><li>Bus: Controller for implementing memory-mapped I/O. Mediates the reading and writing of configuration values from the CPU to various hardware</li><li>Cpu: Reads instructions from ROM, interprets and executes them</li><li>Registers: Performs reading and writing of registers</li><li>Cartridge: Performs reading and writing of ROM and RAM in the cartridge. Implementation differs for each type of MBC chip (explained later)</li><li>Apu: Generates audio data</li><li>Rom: Loads the game program from the cartridge</li><li>Ram: Performs reading and writing of RAM data in the cartridge and Game Boy</li><li>Interrupt: Manages interrupts. Interrupts are performed from the following three classes</li><li>Timer: Counts the number of cycles</li><li>Ppu: Generates pixel information to be rendered on the display</li><li>Joypad: Receives button inputs from the Game Boy</li></ul><p>In Ruby Boy, synchronization between components is achieved by having the CPU execute instructions and advancing the cycle count of Ppu, Timer, and Apu by the number of cycles taken for execution.\nTherefore, the contents of the main loop are as follows:</p><div><pre tabindex=\"0\"><code data-lang=\"ruby\"></code></pre></div><p>I have compiled my implementation notes in a <a href=\"https://zenn.dev/sacckey/scraps/380c2f3ad3318d\">scrap</a>. I will explain by extracting from this.</p><p>The UI part that handles screen rendering, audio playback, and keyboard input was implemented using SDL2 via the <a href=\"https://github.com/ffi/ffi\">Ruby-FFI gem</a>.\nI created a <a href=\"https://github.com/sacckey/rubyboy/blob/main/lib/rubyboy/sdl.rb\">wrapper class</a> that aggregates the necessary SDL2 methods, and the design is to call SDL2 methods from there.</p><p>First, I made it possible to load and use the game data.\nFor example, the title is stored at 0x0134~0x0143, so it can be retrieved as follows:</p><div><pre tabindex=\"0\"><code data-lang=\"ruby\"></code></pre></div><h3>Implementation of MBC (Memory Bank Controller)<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#implementation-of-mbc-memory-bank-controller\">#</a></h3><p>Many Game Boy games use MBC (Memory Bank Controller), which achieves address space expansion through bank switching.\nThere are different types of MBC chips such as MBC1, MBC3, MBC5, etc., each with different sizes of usable ROM and RAM, so implementation specific to the type of MBC chip is necessary.\nRuby Boy supports NoMBC (without MBC) and MBC1 games, and I used the Factory pattern to return the appropriate MBC implementation. By adding chip implementations and case handling, it’s possible to support other types of MBC chips as well.</p><div><pre tabindex=\"0\"><code data-lang=\"ruby\"></code></pre></div><p>I implemented a program that repeats the following CPU execution cycle:</p><ul><li>Fetch instruction from ROM</li></ul><p>To maintain motivation, instead of implementing all CPU and PPU processes at once, I first aimed to run the following minimal test ROM:</p><p>For debugging, I used a Game Boy emulator called <a href=\"https://bgb.bircd.org/\">BGB</a>. It’s useful because you can execute step by step while displaying register and memory information, allowing you to compare the behavior with your own CPU.</p><p>I checked the required CPU instructions using BGB and implemented them. Then, implementing the PPU’s bg rendering process will make the test pass.</p><p>Next, I implemented all instructions and interrupt handling, aiming to pass two CPU test ROMs: <a href=\"https://github.com/retrio/gb-test-roms/tree/master/cpu_instrs/\">cpu_instrs</a> and <a href=\"https://github.com/retrio/gb-test-roms/tree/master/instr_timing\">instr_timing</a>.</p><h4>Points Where I Got Stuck<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#points-where-i-got-stuck\">#</a></h4><ul><li>When setting the value of f in , I hadn’t set the lower 4 bits to 0000<ul><li>The lower 4 bits of the f register are always 0000</li></ul></li><li>The c flag calculation was incorrect for two CPU instructions (opcode=0xe8, 0xf8):  and .<ul><li>It passed with <code>cflag = (@sp &amp; 0xff) + (byte &amp; 0xff) &gt; 0xff</code></li></ul></li></ul><p>By fixing these, it successfully passed.</p><p>…The rendering looks a bit off, but the CPU processing is OK.</p><p>I aimed to implement the remaining rendering processes and pass <a href=\"https://github.com/mattcurrie/dmg-acid2\">dmg-acid2</a>, which is a test ROM for PPU.</p><p>The test will pass by implementing window and sprite rendering, interrupt handling, and DMA transfer.\nCare must be taken with the priority of sprite display.</p><p>Now that rendering is possible, implementing the Joypad will make games playable.\nThe following is a video of running a game called <a href=\"https://tangramgames.dk/tobutobugirl/\">Tobu Tobu Girl</a>:</p><p>At this point, the game became operational! However, it’s extremely slow.\nFrom here on, I worked on optimization.</p><p>I’ll introduce what I did to optimize Ruby Boy.\nThese techniques are not limited to emulator implementation and are likely applicable for improving the performance of Ruby programs in general.</p><ul><li>PC: MacBook Pro (13-inch, 2018)</li><li>Processor: 2.3 GHz Quad-Core Intel Core i5</li><li>Memory: 16 GB 2133 MHz LPDDR3</li></ul><p>I measured the time it took to execute the first 1500 frames of Tobu Tobu Girl without audio and rendering, repeating the measurement three times.\nSince benchmarking will be done repeatedly, I recommend preparing a dedicated program and setting up a system where you can start benchmarking immediately with a command execution.</p><p>I used the Stackprof gem.</p><p>It can be used simply by enclosing the area you want to measure in a block, and it’s recommended because it has low overhead.</p><p>By enabling YJIT, Ruby’s JIT compiler, the FPS improved.\nYJIT has become practical from Ruby 3.2, and can be enabled by adding the  option at runtime.</p><pre tabindex=\"0\"><code>Ruby: 3.2.2\nYJIT: false\n1: 36.740829 sec\n2: 36.468515 sec\n3: 36.177083 sec\nFPS: 41.1385591742566\n\nRuby: 3.2.2\nYJIT: true\n1: 32.305559 sec\n2: 32.094778 sec\n3: 31.889601 sec\nFPS: 46.73385499531633\n</code></pre><p>FPS: 41.1385591742566 → 46.73385499531633</p><h4>Avoid Creating a Hash for Sprites Every Time<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#avoid-creating-a-hash-for-sprites-every-time\">#</a></h4><p>According to Stackprof results, the render_sprites method is becoming a bottleneck.</p><pre tabindex=\"0\"><code>==================================\n  Mode: cpu(1000)\n  Samples: 9081 (1.08% miss rate)\n  GC: 4 (0.04%)\n==================================\n     TOTAL    (pct)     SAMPLES    (pct)     FRAME\n      3727  (41.0%)        1920  (21.1%)     Rubyboy::Ppu#render_sprites\n      1800  (19.8%)        1800  (19.8%)     Rubyboy::Operand#initialize\n      1448  (15.9%)        1448  (15.9%)     Integer#zero?\n      3346  (36.8%)        1296  (14.3%)     Enumerable#each_slice\n       919  (10.1%)         919  (10.1%)     Integer#&lt;&lt;\n       424   (4.7%)         424   (4.7%)     Integer#&lt;=&gt;\n      3552  (39.1%)         294   (3.2%)     Array#each\n...\n</code></pre><p>Let’s investigate further to see which part within render_sprites is the bottleneck.</p><pre tabindex=\"0\"><code>  code:\n                                  |   220  |     def render_sprites\n    3    (0.0%)                   |   221  |       return if @lcdc[LCDC[:sprite_enable]].zero?\n                                  |   222  |\n    2    (0.0%)                   |   223  |       sprite_height = @lcdc[LCDC[:sprite_size]].zero? ? 8 : 16\n                                  |   224  |       sprites = []\n                                  |   225  |       cnt = 0\n 3346   (36.8%)                   |   226  |       @oam.each_slice(4).each do |sprite_attr|\n                                  |   227  |         sprite = {\n                                  |   228  |           y: (sprite_attr[0] - 16) % 256,\n                                  |   229  |           x: (sprite_attr[1] - 8) % 256,\n                                  |   230  |           tile_index: sprite_attr[2],\n                                  |   231  |           flags: sprite_attr[3]\n                                  |   232  |         }\n                                  |   233  |         next if sprite[:y] &gt; @ly || sprite[:y] + sprite_height &lt;= @ly\n                                  |   234  |\n                                  |   235  |         sprites &lt;&lt; sprite\n                                  |   236  |         cnt += 1\n   15    (0.2%) /    15   (0.2%)  |   237  |         break if cnt == 10\n 1887   (20.8%) /  1887  (20.8%)  |   238  |       end\n  386    (4.3%) /    12   (0.1%)  |   239  |       sprites = sprites.sort_by.with_index { |sprite, i| [-sprite[:x], -i] }\n                                  |   240  |\n...\n</code></pre><p>Line 226’s block occupies a high percentage of execution time. Upon closer inspection, it creates a Hash called sprite, and then adds sprite to an array called sprites if it meets certain conditions.\nBy modifying this to create sprite only when the conditions are met, the speed improved.</p><p>FPS: 46.73385499531633 → 49.2233733053377</p><p>In this way, I steadily continued to identify and fix bottlenecks.</p><h4>Calculate tile_map_addr outside the loop<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#calculate-tile_map_addr-outside-the-loop\">#</a></h4><p>FPS: 49.2233733053377 → 56.6580741129914</p><h4>Calculate tile_index outside the loop<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#calculate-tile_index-outside-the-loop\">#</a></h4><p>FPS: 56.6580741129914 → 60.44140113483162</p><p>These are based on the basic principle “do outside the loop what can be done outside the loop”, but it’s critically important for emulators. Resolving these issues dramatically improved performance.</p><p>At this point, Ruby Boy achieved about 60 FPS without rendering, but hit a wall.\nThere’s a trade-off between optimization and code readability. For example, abandoning the use of constants and directly writing mysterious integers would make it faster, but that’s not desirable.</p><p>It got incredibly fast!!!!\nRuby 3.3 was faster than I imagined. Thank you so much 🙏\nBy the way, this <a href=\"https://twitter.com/sacckey/status/1740342734857306595\">comparison post</a> was even reposted by Matz. I’m thrilled.</p><p>Thanks to Ruby 3.3, performance improved significantly, but in exchange? GC occurrences increased dramatically.</p><pre tabindex=\"0\"><code>rubyboy % stackprof stackprof-cpu-myapp.dump\n==================================\n  Mode: cpu(1000)\n  Samples: 16405 (4.57% miss rate)\n  GC: 5593 (34.09%)\n==================================\n     TOTAL    (pct)     SAMPLES    (pct)     FRAME\n      3688  (22.5%)        3688  (22.5%)     (sweeping)\n      2332  (14.2%)        2109  (12.9%)     Enumerable#flat_map\n      2050  (12.5%)        2050  (12.5%)     Integer#&lt;=&gt;\n      5593  (34.1%)        1679  (10.2%)     (garbage collection)\n      1038   (6.3%)        1038   (6.3%)     Rubyboy::Ppu#to_signed_byte\n      1004   (6.1%)        1004   (6.1%)     Rubyboy::SDL.RenderClear\n       646   (3.9%)         646   (3.9%)     Rubyboy::Ppu#get_pixel\n       437   (2.7%)         437   (2.7%)     Integer#&gt;&gt;\n       701   (4.3%)         332   (2.0%)     Rubyboy::Ppu#render_sprites\n      1354   (8.3%)         278   (1.7%)     Rubyboy::Lcd#draw\n      3825  (23.3%)         257   (1.6%)     Rubyboy::Ppu#step\n      1627   (9.9%)         255   (1.6%)     Rubyboy::Ppu#render_bg\n       633   (3.9%)         247   (1.5%)     Enumerable#each_slice\n       230   (1.4%)         230   (1.4%)     Rubyboy::Registers#read8\n       226   (1.4%)         226   (1.4%)     (marking)\n...\n</code></pre><p>Also, in Pokemon Red, the performance from the title screen to the professor’s dialogue scene was still heavy, so resolving these issues became the next goal.</p><p>I used HeapProfiler to detect GC occurrence locations.</p><p>This can also be easily used by enclosing the area you want to detect in a block, but be careful as it may stop returning detection results when running for a long time.</p><p>Execution results (partial)</p><pre tabindex=\"0\"><code>rubyboy % heap-profiler tmp/report\nTotal allocated: 563.01 MB (4198804 objects)\nTotal retained: 10.13 kB (252 objects)\n\nallocated memory by file\n-----------------------------------\n 454.17 MB  rubyboy/lib/rubyboy/cpu.rb\n  93.18 MB  rubyboy/lib/rubyboy/ppu.rb\n  10.06 MB  rubyboy/lib/rubyboy/apu.rb\n\nallocated memory by class\n-----------------------------------\n 462.20 MB  Hash\n  49.79 MB  Array\n  14.61 MB  Enumerator\n\nallocated objects by file\n-----------------------------------\n   2839605  rubyboy/lib/rubyboy/cpu.rb\n   1105342  rubyboy/lib/rubyboy/ppu.rb\n    251462  rubyboy/lib/rubyboy/apu.rb\n\nallocated objects by class\n-----------------------------------\n   2888757  Hash\n    416967  Array\n    273888  &lt;memo&gt; (IMEMO)\n    273888  &lt;ifunc&gt; (IMEMO)\n    251442  Float\n\nretained memory by file\n-----------------------------------\n   3.92 kB  rubyboy/lib/rubyboy/cpu.rb\n   2.20 kB  rubyboy/lib/rubyboy/ppu.rb\n\nretained objects by file\n-----------------------------------\n        98  rubyboy/lib/rubyboy/cpu.rb\n        54  rubyboy/lib/rubyboy/ppu.rb\n        24  rubyboy/lib/rubyboy.rb\n        18  rubyboy/lib/rubyboy/lcd.rb\n        18  rubyboy/lib/rubyboy/apu.rb\n</code></pre><p>Looking at this, it is clear that creating a large number of Hashes within the Cpu class is the cause of GC occurrences.</p><h4>Change instruction arguments from Hash to Symbol<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#change-instruction-arguments-from-hash-to-symbol\">#</a></h4><div><pre tabindex=\"0\"><code data-lang=\"diff\"></code></pre></div><h4>Avoid creating Hash when referencing flags<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#avoid-creating-hash-when-referencing-flags\">#</a></h4><div><pre tabindex=\"0\"><code data-lang=\"diff\"></code></pre></div><p>With these modifications, GC occurrences were reduced to 2.71%.</p><p>At this point, the benchmark and Stackprof results are as follows:\nIt’s important to note that this result was measured with rendering enabled and at the heaviest part of Pokemon Red, so comparison with previous results is not meaningful.</p><pre tabindex=\"0\"><code>Ruby: 3.3.0\nYJIT: true\n1: 26.798767 sec\nFPS: 55.97272441676141\n</code></pre><pre tabindex=\"0\"><code>==================================\n  Mode: cpu(1000)\n  Samples: 10430 (5.57% miss rate)\n  GC: 283 (2.71%)\n==================================\n     TOTAL    (pct)     SAMPLES    (pct)     FRAME\n      2275  (21.8%)        2275  (21.8%)     Integer#&lt;=&gt;\n      1267  (12.1%)        1267  (12.1%)     Rubyboy::SDL.RenderClear\n      1186  (11.4%)        1186  (11.4%)     Rubyboy::Ppu#to_signed_byte\n      2366  (22.7%)         864   (8.3%)     Rubyboy::Ppu#render_bg\n       784   (7.5%)         784   (7.5%)     Rubyboy::Ppu#get_pixel\n      1773  (17.0%)         641   (6.1%)     Rubyboy::Ppu#render_window\n       992   (9.5%)         415   (4.0%)     Rubyboy::Ppu#render_sprites\n       334   (3.2%)         334   (3.2%)     Integer#&gt;&gt;\n       852   (8.2%)         319   (3.1%)     Enumerable#each_slice\n      5453  (52.3%)         311   (3.0%)     Rubyboy::Ppu#step\n      4199  (40.3%)         213   (2.0%)     Integer#times\n       188   (1.8%)         188   (1.8%)     Rubyboy::Timer#step\n       187   (1.8%)         187   (1.8%)     (sweeping)\n       142   (1.4%)         142   (1.4%)     Rubyboy::SDL.UpdateTexture\n       129   (1.2%)         129   (1.2%)     Array#size\n       426   (4.1%)         114   (1.1%)     Rubyboy::Ppu#get_color\n       851   (8.2%)         109   (1.0%)     Array#each\n       981   (9.4%)         105   (1.0%)     Rubyboy::Cpu#get_value\n       283   (2.7%)          85   (0.8%)     (garbage collection)\n...\n</code></pre><p>While GC has been reduced, performance is still below 60 FPS, and  (number comparison) appears to be the bottleneck.\nNumber comparisons occur frequently in address-based branching like the following:</p><div><pre tabindex=\"0\"><code data-lang=\"ruby\"></code></pre></div><p>To eliminate these comparisons, I created an array called  in preprocessing, which contains the correspondence between addresses and processes. This allows for calling with just array reference during execution.</p><div><pre tabindex=\"0\"><code data-lang=\"ruby\"></code></pre></div><p>This technique was inspired by <a href=\"https://github.com/mame/optcarrot\">Optcarrot</a>, a NES emulator written in Ruby.</p><p>Let’s run the benchmark and Stackprof again.</p><pre tabindex=\"0\"><code>rubyboy % RUBYOPT=--yjit bundle exec rubyboy bench\nRuby: 3.3.0\nYJIT: true\n1: 21.75409 sec\nFPS: 68.95255099156066\n</code></pre><pre tabindex=\"0\"><code>rubyboy % bundle exec stackprof stackprof-cpu-myapp.dump\n==================================\n  Mode: cpu(1000)\n  Samples: 9505 (6.87% miss rate)\n  GC: 325 (3.42%)\n==================================\n     TOTAL    (pct)     SAMPLES    (pct)     FRAME\n      1238  (13.0%)        1238  (13.0%)     Rubyboy::Ppu#to_signed_byte\n      1208  (12.7%)        1208  (12.7%)     Rubyboy::SDL.RenderClear\n      2558  (26.9%)         907   (9.5%)     Rubyboy::Ppu#render_bg\n       865   (9.1%)         865   (9.1%)     Rubyboy::Ppu#get_pixel\n       849   (8.9%)         849   (8.9%)     Rubyboy::Cartridge::Mbc1#set_methods\n      1803  (19.0%)         663   (7.0%)     Rubyboy::Ppu#render_window\n      1053  (11.1%)         460   (4.8%)     Rubyboy::Ppu#render_sprites\n      5782  (60.8%)         346   (3.6%)     Rubyboy::Ppu#step\n       906   (9.5%)         343   (3.6%)     Enumerable#each_slice\n       313   (3.3%)         313   (3.3%)     Integer#&gt;&gt;\n      4412  (46.4%)         245   (2.6%)     Integer#times\n       237   (2.5%)         237   (2.5%)     (sweeping)\n       197   (2.1%)         197   (2.1%)     Rubyboy::Timer#step\n       193   (2.0%)         193   (2.0%)     Rubyboy::SDL.UpdateTexture\n      1141  (12.0%)         162   (1.7%)     Rubyboy::Bus#set_methods\n       433   (4.6%)         134   (1.4%)     Rubyboy::Ppu#get_color\n       114   (1.2%)         114   (1.2%)     Array#size\n       478   (5.0%)         109   (1.1%)     Rubyboy::Cpu#get_value\n       918   (9.7%)          99   (1.0%)     Array#each\n        75   (0.8%)          75   (0.8%)     Rubyboy::Cpu#increment_pc_by_byte\n      9180  (96.6%)          68   (0.7%)     Rubyboy::Console#bench\n       325   (3.4%)          65   (0.7%)     (garbage collection)\n        49   (0.5%)          49   (0.5%)     Integer#&lt;=&gt;\n...\n</code></pre><p>The FPS improved from 55.97272441676141 to 68.95255099156066, and the proportion of  was reduced from 21.8% to 0.5%.\nThere’s still room for further optimization, but having achieved the goal, I’m considering this complete for now.</p><p>I had considered the optimization complete, but when I tried it in the browser with ruby.wasm, it turned out to be slow, so I decided to optimize further.</p><p>For benchmarking, I used the same method as in Part 1: measuring the time to execute the first 1500 frames of Tobu Tobu Girl three times, without audio and rendering. Here are the current benchmark results:</p><pre tabindex=\"0\"><code>rubyboy % RUBYOPT=--yjit bundle exec rubyboy-bench\nRuby: 3.3.0\nYJIT: true\n1: 11.963271 sec\n2: 11.610802 sec\n3: 11.64308 sec\nFPS: 127.77864241325811\n</code></pre><p>In the current implementation, frame data is generated pixel by pixel during rendering. This causes significant overhead.\nTo address this, I modified the implementation to generate frame data when VRAM is updated and cache it. During rendering, it just needs to reference the cached data.</p><p>I also focused on other performance bottlenecks: optimizing the render_bg method and changing the pixel format of the frame data.</p><p>These optimizations achieved more than a 2x speedup!\nHere are the optimizations and FPS changes (details omitted):</p><ul><li>Cache tile data (<a href=\"https://github.com/sacckey/rubyboy/commit/6eb4f77fd1cf23ade795da92a2eac0857a0f31fc\">commit</a>) → 133FPS</li><li>Cache tile_map data (<a href=\"https://github.com/sacckey/rubyboy/commit/99a24a0706e83d785f65b39aebbe85932ebe56a5\">commit</a>) → 151FPS</li><li>Cache palette data (<a href=\"https://github.com/sacckey/rubyboy/commit/2eea5261743c8846364ddb1651b45495863c9298\">commit</a>) → 159FPS</li><li>Cache sprite data (<a href=\"https://github.com/sacckey/rubyboy/commit/eb1a23efbafe1e2bc53bd573a3270dff55838dc9\">commit</a>) → 185FPS</li><li>Change pixel format from RGB24 to ABGR8888 (<a href=\"https://github.com/sacckey/rubyboy/commit/d898688845c09e3ce7f6ae1ed1f303d8d8e8ef24\">commit</a>) → 219FPS</li><li>Optimize render_bg with tile-based processing (<a href=\"https://github.com/sacckey/rubyboy/commit/50e7ccdd15d1043ef021cbda597a0edf305e5b92\">commit</a>) → 263FPS</li><li>Use reverse and sort for sprite ordering (<a href=\"https://github.com/sacckey/rubyboy/commit/731794d73e81a0312c14865dea4de6f5cf210ac2\">commit</a>) → 274FPS</li></ul><p>FPS: 127.77864241325811 → 274.6885154318787</p><h2>Works in browser with ruby.wasm<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#works-in-browser-with-rubywasm\">#</a></h2><p>I made Ruby Boy run in the browser using WebAssembly!</p><p>In this chapter, I explain how Ruby Boy runs in the browser. It should also be helpful for people who want to run Ruby programs in the browser.</p><pre tabindex=\"0\"><code>+----------------+       DOM Events           +----------------+\n|   index.html   |     (Keyboard &amp; ROM)       |    index.js    |\n|   (Browser)    |---------------------------&gt;| (Main Thread)  |\n|                |&lt;---------------------------|                |\n|                |   Frame Data (ImageData)   |                |\n+----------------+                            +----------------+\n                                                     |  ^\n                                                     |  |\n                                            Keyboard |  |  Frame Data\n                                              States |  |  (ArrayBuffer)\n                                                     v  |\n+----------------+                            +----------------+\n|  rubyboy.wasm  |      Keyboard States       |   worker.js    |\n| (GB Emulator)  |&lt;---------------------------| (Game Thread)  |\n|                |---------------------------&gt;|                |\n|                |  Frame Data (Uint8Array)   |                |\n+----------------+                            +----------------+\n</code></pre><ul><li>index.js: Main thread. Sends keyboard input and ROM file input to the Worker, and updates canvas with frame data received from the Worker.</li><li>worker.js: Worker thread. Processes input events from the main thread, runs Ruby Boy and sends frame data to the main thread.</li><li>rubyboy.wasm: Ruby Boy packaged as Wasm. Emulates the Game Boy and generates frame data.</li></ul><h3>Converting Ruby Boy to Wasm<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#converting-ruby-boy-to-wasm\">#</a></h3><p>Converting a Ruby Program to a Wasm package consists of two steps:</p><ol><li>Build CRuby to Wasm to create ruby.wasm. (Dependent gems are installed during the build process.)</li><li>Pack Ruby Program into ruby.wasm to create a program-specific wasm.</li></ol><p>The following diagram illustrates these steps:</p><pre tabindex=\"0\"><code>+--------------+\n|    gems      |   build\n|     +        | ---------&gt;&gt; ruby.wasm ─┐\n|    CRuby     |                         |\n+--------------+                         |   pack\n                                         + --------&gt;&gt; ruby_with_program.wasm\n+--------------+                         |\n| Ruby Program | -----------------------┘\n+--------------+\n</code></pre><p>These build and pack operations are performed using the ruby_wasm gem.</p><p>The ruby_wasm gem, js gem (mentioned later), npm packages, and pre-built binaries are available in the following repository:</p><p>Using the ruby_wasm gem to create a wasm file that includes dependent gems.\nFor browser execution, the js gem is also required and should be installed alongside.</p><pre tabindex=\"0\"><code>$ bundle add ruby_wasm js\n$ bundle exec rbwasm build --ruby-version 3.3 -o ruby-js.wasm\n</code></pre><h5>Tips: Building only required gems<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#tips-building-only-required-gems\">#</a></h5><p>When running , all dependent gems in  are built.\nTo exclude unnecessary gems like rspec or rubocop from the build, specify them in <code>RubyWasm::Packager::EXCLUDED_GEMS</code> and execute the command directly.</p><p>For Ruby Boy, only the js gem is needed, so adding all other gems to  as follows:</p><div><pre tabindex=\"0\"><code data-lang=\"ruby\"></code></pre></div><p>Pack the Ruby Boy code into the previously created ruby-js.wasm.</p><pre tabindex=\"0\"><code># Pack Ruby Boy code located in ./lib\n$ bundle exec rbwasm pack ruby-js.wasm --dir ./lib::/lib -o rubyboy.wasm\n</code></pre><p>Now that rubyboy.wasm is complete, let’s run it in the browser.</p><p>System Architecture (revisited)</p><pre tabindex=\"0\"><code>+----------------+       DOM Events           +----------------+\n|   index.html   |     (Keyboard &amp; ROM)       |    index.js    |\n|   (Browser)    |---------------------------&gt;| (Main Thread)  |\n|                |&lt;---------------------------|                |\n|                |   Frame Data (ImageData)   |                |\n+----------------+                            +----------------+\n                                                     |  ^\n                                                     |  |\n                                            Keyboard |  |  Frame Data\n                                              States |  |  (ArrayBuffer)\n                                                     v  |\n+----------------+                            +----------------+\n|  rubyboy.wasm  |      Keyboard States       |   worker.js    |\n| (GB Emulator)  |&lt;---------------------------| (Game Thread)  |\n|                |---------------------------&gt;|                |\n|                |  Frame Data (Uint8Array)   |                |\n+----------------+                            +----------------+\n</code></pre><p>Next, I’ll explain the processing details of worker.js and rubyboy.wasm in the lower part.</p><div><pre tabindex=\"0\"><code data-lang=\"js:worker.js\"></code></pre></div><p>Inside the Worker, creating a VM by passing rubyboy.wasm to the DefaultRubyVM method. Ruby Boy code runs on this VM.</p><p> is a Map that represents the root directory <a href=\"https://github.com/ruby/ruby.wasm/blob/main/packages/npm-packages/ruby-wasm-wasi/src/browser.ts#L25\">preopened</a> by DefaultRubyVM.\nSending ROM data to the VM and receiving frame data from the VM through this Map.</p><div><pre tabindex=\"0\"><code data-lang=\"js:worker.js\"></code></pre></div><p>The Worker executes Ruby Boy’s  on the VM, reads the frame data written to /video.data, and posts it to index.js. index.js updates the canvas with the received frame data.\nRepeating this process draws the game screen.</p><p>The implementation of Ruby Boy’s  is below:</p><div><pre tabindex=\"0\"><code data-lang=\"ruby:executor.rb\"></code></pre></div><p>The exec method receives current button inputs (direction keys, A, B, Start, Select), emulates the Game Boy, and writes frame data to /video.data.</p><p>In Ruby Boy, frame data is managed as a Uint32 array in ABGR format like , converting this using  to a Uint8 array in RGBA format like  for canvas use.</p><h4>Emulator Development is Fun<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#emulator-development-is-fun\">#</a></h4><p>As initially planned, I was able to implement while having fun. While it’s enjoyable when an emulator runs, I think a major factor is the abundance of documentation and test ROMs. Especially, since the test ROMs provide feedback on incorrect parts, I was able to progress without getting stuck and could refactor easily.\nAlso, I’m happy that I could run the cartridges that were lying dormant at my parents’ home.</p><p>Install it now with !</p><h4>Learned About Low-Level Technology<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#learned-about-low-level-technology\">#</a></h4><p>Through implementing programs that mimic CPU, memory, registers, RAM, etc., I was able to deepen my knowledge about their roles and operations. It was enjoyable to see things I knew theoretically actually come up, leading to “so that’s what it meant” discoveries. How about using this for experimental subjects in universities or technical colleges?</p><h4>Gained Experience in Program Optimization<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#gained-experience-in-program-optimization\">#</a></h4><p>I experienced the steady process of “creating a benchmark program, running a profiler, and fixing suspicious areas” for optimization. I believe my resolution for optimization has improved and my sense for detecting bottlenecks has sharpened.</p><h4>Experienced Designing and Implementing a Larger Program<a hidden=\"\" aria-hidden=\"true\" href=\"https://sacckey.dev/posts/implementing-a-game-boy-emulator-in-ruby/#experienced-designing-and-implementing-a-larger-program\">#</a></h4><p>I hadn’t written many large programs outside of web programming, so it was good to gain that experience. With emulators, I felt it was important to appropriately distribute responsibilities among classes and write generalized programs to increase reusability (especially for the CPU).</p><ul><li>Happy with the simple syntax!</li><li>Delighted by the many thoughtful methods!</li><li>Pleased with the abundance of useful gems!</li><li>Frustrated by the slow processing speed!<ul><li>Glad that it’s significantly faster than before thanks to YJIT’s evolution!</li></ul></li></ul><p>I’m planning to work on the following:</p><ul><li>Improving the benchmark system<ul><li>Want to make it usable as a benchmark program for Ruby</li></ul></li></ul><p>These are articles about creating Game Boy emulators. I referred to them for implementation approaches, techniques, and potential pitfalls 🙏</p><ul><li><a href=\"https://www.slideshare.net/mametter/ruby-65182128\">Ruby で高速なプログラムを書く | PPT</a><ul><li>Presentation slides by the creator of <a href=\"https://github.com/mame/optcarrot\">Optcarrot</a>. These slides are packed with essential information about optimizing Ruby programs. I was able to achieve the optimization of Ruby Boy by referring to these slides.</li></ul></li></ul><ul><li><a href=\"https://gbdev.io/pandocs/\">Pan Docs</a><ul><li>A page that covers Game Boy specifications comprehensively, used like a dictionary.</li></ul></li><li><a href=\"https://gbdev.io/gb-opcodes/optables/\">Game Boy CPU (SM83) instruction set</a><ul><li>CPU specification table. It displays a list of each instruction’s content, opcode, cycle count, and updated flags, and also provides JSON. I implemented CPU instructions while referring to this.</li></ul></li><li><a href=\"https://techbookfest.org/product/sBn8hcABDYBMeZxGvpWapf?productVariantID=2q95kwuw4iuRAkJea4BnKT\">Rustで作るGAME BOYエミュレータ：低レイヤ技術部</a><ul><li>A book about implementing a Game Boy emulator in Rust. It sets goals for each chapter, allowing for step-by-step progress. The explanations for each chapter are quite detailed, and it’s recommended even if you’re implementing in a language other than Rust. It was especially helpful for implementing PPU and APU.</li></ul></li></ul><p>I referenced the following articles and implementations for WebAssembly support:</p>","contentLength":27107,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42959110"},{"title":"Station of despair: What to do if you get stuck at end of Tokyo Chuo Rapid Line","url":"https://soranews24.com/2024/12/21/station-of-despair-what-to-do-if-you-get-stuck-at-the-end-of-tokyos-chuo-rapid-line/","date":1738746761,"author":"edward","guid":225,"unread":true,"content":"<p>In Japan, a handful of train stations are known as , or  There’s nothing wrong with these stations themselves, though, and the towns they’re in aren’t dirty, dangerous, or otherwise anything to fear. So why the abandon-all-hope designation? <strong>Because they’re places where some people get stuck having to spend the night after the last train, but nobody really wants to</strong>.</p><p>To qualify as a station of despair, a station has to be the last stop on its line, in a remote area, but also on a line that has a major population center and entertainment district somewhere. <strong>Basically, if there’s a neighborhood where people are getting drunk, then trying to take the train line home but falling asleep and missing their stop, only to wake up at the end of the line in the middle of nowhere with no way to get home until the next morning, then that’s a station of despair</strong>.</p><p>For the Tokyo area, one of the more infamous stations of despair is , in . Otsuki is <strong>the last stop of the Chuo Line (Rapid)</strong>, which starts in the east at Tokyo Station and runs through downtown drinking and dining districts such as Shinjuku, Ochanomizu, and Kichijoji before heading out into the suburbs west of downtown, and then into the rural environs of Yamanashi.</p><p>▼ From Tokyo Station to Otsuki Station takes a little less than two hours.</p><p>With Christmas parties and New Year’s celebrations coming up, our Japanese-language reporter  figures there’s a pretty good chance he might accidentally end up in Otsuki one of these nights, so to prepare for that eventuality he decided to go to Otsuki Station on purpose to see what the area is like late at night, arriving at about 9:40 p.m.</p><p>▼ While he didn’t get drunk before getting on the train, he did try to catch some Zs along the way, for a more realistic simulation.</p><p>Arriving at Otsuki, Ahiruneko stepped off the train and onto the platform, and his immediate thought was<strong> “Oh geeeeezzzz is it cold!”</strong></p><p>Otsuki is closer to Mt. Fuji than it is to downtown Tokyo, and the increased elevation means much lower temperatures in winter, particularly after sundown. So while dressing warm is always a good idea when going out at this time of year, it’s especially important if you think you might end up at this station of despair.</p><p>▼ As another sign that you’re far from the big city, Otsuki Station has a woody, log cabin-type aesthetic going on.</p><p>Immediately wanting to get out of the cold, Ahiruneko has happy to spot <strong>a cozy-looking waiting room inside the station</strong>.</p><p>Inside are tables, benches, local tourism information, and a row of gacha capsule toy machines.</p><p>However, <strong>the waiting room is only open until midnight</strong>, so holing up there until the trains start running again in the morning isn’t an option if you’ve missed the last train home for the night. So it was time for Ahiruneko to hit the streets of late-night Otsuki, where he found…</p><p>…not a whole lot that was open.</p><p>Sure, Otsuki might be on the same train line as the bars and clubs of Shinjuku, where the party goes all-night long each and every night. In Otsuki, though, there’s a much stronger early-to-bed, early-to-rise sort of vibe.</p><p>Yeah, there are  (pubs), but they tend to close earlier than they do in the big cities. The branch of chain  (庄屋) near the station is never open past 11:30 p.m., and on some nights closes as early as 10, and the station area’s  (魚民) closes at midnight, so neither one will work if you’re looking for a place to nurse a drink until the morning trains.</p><p><strong>Since izakaya were out, Ahiruneko started looking for a 24-hour convenience store with an eat-in corner</strong> where he could kill time. Once again, though, convenience stores are fewer and farther between in Otsuki than the big city. Now freezing from the cold, Ahiruneko felt his spirits pick up when he spotted the familiar red-and-yellow signage of a Daily Yamazaki convenience store…</p><p>…only to have his heart broken when he found out that the space is actually occupied by a branch of mini gym Chocozap.</p><p>▼ The corner location and large windows really do make it look like this place was originally a convenience store, though.</p><p>Luckily, Ahiruneko was able to stumble across an actual convenience store when he found a  branch.</p><p>▼ Here’s a map of the route to Lawson from Otsuki Station, so that you don’t have to rely on luck when you’re already unlucky enough to have ended up at a station of despair.</p><p>As further proof of how quiet Otsuki is at night, the Lawson’s parking lot was full of cars driven by people who needed to take a break from driving but had no other place to do it.</p><p><strong>This Lawson does have an eat-in-counter, but with only three seats, you’re going to need to keep your fingers crossed if you’re hoping for a spot to camp out at until morning</strong>.</p><p>There is another convenience store close to the station, a, but unfortunately without any sort of eat-in space. It is a pretty big store, though, so you can at least warm yourself up while browsing the aisles for a bit, and stock up on supplies for when you have to head back out into the night.</p><p>▼ Walking route from Otsuki Station to 7-Eleven</p><p>Probably the best option, without springing for a full-on hotel, that Ahiruneko came across was a branch of .</p><p>Big Echo is a  parlor chain. Some of its more rural branches, instead of being tucked away inside a mixed-use commercial building, are instead little private karaoke shacks on the side of the road, and the ones in Otsuki are open all night, so you can rent one and just crash on its sofa without singing anything.</p><p>▼ Otsuki Station to Big Echo</p><p>Finally, if you’re resigned to just getting a hotel room in Otsuki while you wait for the train, there actually is a very large branch of about a 10-minute walk from Otsuki Station, on the opposite side of the tracks from the places we’ve shown so far in this article.</p><p>Opened in 2022, the Otsuki Toyoko Inn is , considering that the town itself only has about 20,000 people and isn’t a top-tier tourism destination. Rumor has it that Toyoko Inn built this branch at least in part to capitalize on potential business generated by the nearby station of despair.</p><p>We don’t have access to Toyoko Inn’s booking records, but if that rumor is true, it would imply that there’s high demand for its rooms during celebratory seasons like winter holidays, though, so it might be hard to find a vacancy at this time of year, and the prices might be inflated too.</p><p>In a magnanimous show of mercy, our boss didn’t actually make Ahiruneko spend the night on the streets of Otsuki, and his simulation/exploration was timed so that he’d still be able to catch a train home, though it wasn’t until he was back in his kitchen and scarfing down a bowl of piping hot noodles that he finally got the severe chill of the Otsuki night air out of his system.</p><p>All of which is to say that the best plan is to check your return train schedule before you hit the bars, drink within your limits, and avoid getting stuck at a station of despair this holiday season. If you do, though, hopefully the options Ahiruneko found will help get you through the night.</p>","contentLength":7096,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42945980"},{"title":"Visual explanations of mathematics (2020)","url":"https://agilescientific.com/blog/2020/2/25/visual-explanations-of-mathematics","date":1738718705,"author":"thunderbong","guid":224,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42942204"},{"title":"The PS2’s backwards compatibility from the engineer who built it (2020)","url":"https://freelansations.medium.com/the-story-of-the-ps2s-backwards-compatibility-from-the-engineer-who-built-it-ec39cf5a0353","date":1738670195,"author":"msephton","guid":223,"unread":true,"content":"<p>It was 1996 when I first joined Sony Computer Entertainment as part of the second wave of newly graduated hires at the time. Back then, I think SCE’s research and development team was made up of all of around maybe 50 people, with Ken Kutaragi standing at the helm while guys like me were at the very bottom of the ladder. If I remember correctly, I was hired just after it had been announced that Square entered the ranks of Sony’s third party developers. Around the time that Final Fantasy VII was coming out, I had a chance to watch the cutscenes for it and, like a lot of people, vividly recall the shock at seeing Aerith meet her untimely demise so dramatically…</p><p>I believe my first job after joining SCE was to program a video converter of sorts that would take a movie file and apply filters to it. That also happened to be the first program I ever wrote professionally. The thing is, when I entered the team, I was probably the least useful member out of everyone there. I’m not exaggerating when I say that, either. I had no real electrical engineering skills to speak of whatsoever and I didn’t even know how to boot up Windows 3.1, let alone how to write any programs. Even now, I can’t help but wonder what people at Sony saw in me when they decided to hire me.</p><p>Luckily, I got the chance to learn how to program computers thanks to a training program that the company ran. The material was easy for me to grasp and I came away from that training feeling like I could program just about anything. After I was done with that training, I did a lot of odds and ends. I was put in charge of everything from inspecting CD emulators to model data converters, libc, and more. It was in the midst of that work, around 1998 — at least, I think it was around then — that all of us in that division were briefed on the next generation PlayStation hardware.</p><p>After that point, the research and development group was split into two teams. One team obviously continued to focus on the then-current PlayStation hardware, while the other one set their sights on the next generation. I knew that I, for one, as someone who always likes experiencing new things, wanted to work in the latter team. I think I interviewed to join them because I recall later being specifically assigned to it, something that really excited me.</p><p>Once I was brought onto the PlayStation 2 team, I was given the task of making PS1 games play on the new system. Back then, it was normal for your old games to not be able to run on newer consoles, but SCE wanted to buck that trend, which I thought was forward-thinking of them. Given how I had only been with the company for a few years at that point, too, I was really pleased that I was allowed to work on something so important.</p><p>When this decision to make the PS2 backwards compatible with PS1 games had been made, the plan was already for the PS2 to reuse the main processor on the PS1 as an input/output processor for the new hardware. The catch, however, was that none of the other hardware from the PS1 was, at that point, going to be included, meaning that the rest of it would have to be emulated with software. Having been involved with the software engineering side of things up until that point, it was up to me to write the emulator for the PS1’s SPU, or its sound hardware.</p><p>The PS2’s sound chip is structured into two parts: the core and the digital signal processor. A senior member of the team who worked specifically in sound engineering tackled the emulation work on the DSP side, while I focused my attention on the core. To that end, we took up shop in a room set up for us at a subcontractor and secluded ourselves as we got to work writing the necessary programming. There were no windows inside that room and I remember regularly arguing with the other engineer while we worked. It wasn’t all bad, though, as we became really close friends as a result of that time together.</p><p>I don’t remember quite how long we’d been working, but one day, everything was upended unceremoniously. As it turned out, the PS1’s sound chip  going to be included as part of the PS2’s internals after all, meaning that all of our work was thrown out of the window.</p><p>The SPU emulator that we had been writing was rendered useless, leaving our roles up in the air since the adoption of the PS1’s sound chip didn’t come at the expense of the PS2’s own new sound processor. We speculated about what would come next, like, say, potentially writing test vectors for that new sound processor. My next assignment, however, came as a huge surprise.</p><p>Specifically, I was put in charge of emulating the PS1’s graphics processor, a request that utterly baffled me. Someone else was already supposed to be taking care of that and when I asked what was going on, I was told that they were quitting the company and that it was on me to pick up where they left off, no ifs, ands, or buts. Suffice it to say, after doing sound work up until that point, switching gears to the graphics side of things was quite the shift. But that didn’t ultimately matter, as I wasn’t given much of a say one way or the other. Like it or not, I had to accept the order, even if the whole ordeal was nothing short of confusing.</p><p>That’s not to say that I thought it was going to be an impossible hill to climb, however. In my mind, I view emulators as a sort of converter in and of themselves, ones that primarily take orders designed for old processors and translate them into ones that the new target processor can understand and execute. In that sense, even if sound and graphics hardware have their fair share of differences, in the end, they’re both still fundamentally sending commands. All an emulator is doing is changing the shape and flow of those commands. So long as an emulator is fully tested, it should all work out in the end, even if that’s obviously the really tough part in practice.</p><p>By the time that I inherited the GPU emulation work, the previous person in charge had thankfully already laid down a basic framework, so I didn’t have to start completely from scratch. My first order of business was to therefore get up to speed on the GPU specifications for both the PS1 and PS2. After that, I set about implementing missing functions as I initially tried to focus on reprogramming the PS1’s GPU commands.</p><p>The first PS1 game that booted up in the PS2’s emulator was Ridge Racer. As a launch title for the PS1, it felt pretty profound that out of all the games in the system’s library to be chosen as the very first target to get up and running, it was Ridge Racer that was chosen for that honor. I pondered the significance of it being a first of sorts once again for the PS2 as I turned the device on.</p><p>That being said, the initial results were hardly perfect, to put it very, very kindly. The race queen who appears at the start of every race, for instance, was rendered as a mosaic rather than a proper sprite. Plus, when you’d complete a lap, the screen turned pink. Still, I was just pleased to see the game running at all. Even if the only thing that was actually being emulated was the GPU, that’s when I knew it was going to be possible to achieve PS1 backwards compatibility on the PS2 with that level of software emulation.</p><p>Early in the morning on March 2, 1999, I was standing behind the stage curtains at the Tokyo International Forum, where the PlayStation 2 was going to be officially unveiled to the world later that day at the PlayStation Meeting 1999. My role was to perform a live demonstration of the console’s backwards compatibility with the PS1 once the functionality was announced during the presentation.</p><p>I had been on standby since the night before to prepare for the event. Several months had passed since Ridge Racer first booted up and progress on the GPU emulator had come a long way. A number of PS1 games were now able to run on it, with Crash Bandicoot: Warped being the best of the bunch. For that reason, it was chosen as the game to show off the PS2’s backwards compatibility. There was only one problem: sometimes it froze in emulation.</p><p>It goes without saying that there’d be big trouble if the game locked in the middle of the demo in front of such a large audience. Unfortunately, I hadn’t nailed down what was causing these freezes to happen. All I could figure out was that as long as Crash kept moving, the game remained stable for whatever reason. Knowing that, I stayed awake all night, endlessly playing the game on development PS2 hardware. Luckily, I wasn’t alone in this endeavor, as I had one other person on hand to help play through the game with me. The gameplay feed in our monitor was also set up such that it could be shown off on the big screen on stage during the conference with the flick of a switch. As you might expect, I screwed around with that switch and had a fun time with it. As for why we simply couldn’t start playing the morning of the announcement, that was because there was a chance the emulator itself wouldn’t load and there wouldn’t be enough time to fix it right then and there. As a result, as surprising as it might sound, it was therefore logistically safer to simply keep the system running all night once it had booted up.</p><p>Thankfully, we made it through that night without incident. The system stayed operational as the big show was approaching that day. It can’t be understated how important of an event it was, either. Sony CEO Nobuyuki Idei himself was in attendance to offer his support. Tech demos were rolled out that showed off the power of the PS2’s Emotion Engine and Graphics Synthesizer. From behind the curtains, I didn’t have a great view of what was happening, but I could tell that people were definitely responding to it and cheering. Everything was going according to plan. Then, soon enough, it was time for the backwards compatibility reveal.</p><p>Believe it not, I honestly don’t remember much of what happened in that moment. The plan during the Crash Bandicoot demo was for me to play the game as normal, leaping over obstacles and proceeding deeper and deeper into the stage. But when it came time to play the game in earnest, I really struggled with it and kept running into one particular obstacle in the stage I just couldn’t get past. From there, my memory is a complete blank. I can’t tell you whether I managed to get my act together or not.</p><p>Evidently, though, things seemed to pan out all right in the end because the announcement was greeted with applause despite my bad showing of it. All told, the event was a great success.</p><p>The PlayStation 2 was eventually released in Japan on March 4, 2000. Work on the PS1 emulator was mostly completed around New Year’s, if I’m not mistaken. In the end, there were a handful of games that just wouldn’t run properly, resulting in us compiling a public blacklist of PS1 games that players wouldn’t be able to play on the system.</p><p>After the Japanese hardware launch came the ones in North America and Europe, whose respective PS1 games the emulator naturally also supported. Right before their releases, I went to Sony’s American and European offices to assist with debugging work, which was the first time I ever went abroad. The PS2 ultimately wasn’t 100 percent backwards compatible with the PS1 back catalog, but it nevertheless supported nearly all of it. When I look back on it now, that assignment is probably the most important one I’ve ever had in my career.</p><p>Ken Kutaragi set a high bar for us at his team, telling us to always measure the quality of our work based on whether it was truly the absolute best in class globally. When I think about what I’ve done in my own lifetime that meets that goal, the first thing that comes to mind is the work I did on the PS1 backwards compatibility. That’s how proud I am of it.</p><p>To be absolutely clear, I couldn’t have possibly done it alone and had a lot of people help me along the way. In the end, if it hadn’t been me who pulled it off, somebody else would have. Regardless, the fact I was able to see such a huge project through to the very end is something I take great pride in. I can only hope I have another opportunity to do something similar again in my lifetime.</p>","contentLength":12251,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=42931241"}],"tags":["dev","hn"]}