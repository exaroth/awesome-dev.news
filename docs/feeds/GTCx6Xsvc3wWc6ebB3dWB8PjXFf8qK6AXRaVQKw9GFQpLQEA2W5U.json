{"id":"GTCx6Xsvc3wWc6ebB3dWB8PjXFf8qK6AXRaVQKw9GFQpLQEA2W5U","title":"Google Developers Blog","displayTitle":"Google Developers","url":"https://developers.googleblog.com/rss/","feedLink":"https://developers.googleblog.com/rss/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":21,"items":[{"title":"The Google Developer Program is evolving","url":"https://developers.googleblog.com/en/google-developer-program-join-connect-code/","date":1755896716,"author":"","guid":237084,"unread":true,"content":"<article>The Google Developer Program is rolling out major updates to make its tools and community more accessible and powerful. These enhancements include a new flexible monthly subscription tier, a centralized GDP Forum for collaboration, and increased Gemini CLI access for all members.</article>","contentLength":280,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Announcing Imagen 4 Fast and the general availability of the Imagen 4 family in the Gemini API","url":"https://developers.googleblog.com/en/announcing-imagen-4-fast-and-imagen-4-family-generally-available-in-the-gemini-api/","date":1755896716,"author":"","guid":237085,"unread":true,"content":"<article>Google announces the general availability of Imagen 4, its advanced text-to-image model, in the Gemini API and Google AI Studio, featuring significant improvements in text rendering. The new Imagen 4 Fast model, designed for speed and rapid image generation, is now available alongside Imagen 4 and Imagen 4 Ultra, with Imagen 4 and Imagen 4 Ultra also supporting up to 2K resolution image generation.</article>","contentLength":401,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The agentic experience: Is MCP the right tool for your AI future?","url":"https://developers.googleblog.com/en/the-agentic-experience-is-mcp-the-right-tool-for-your-ai-future/","date":1755822006,"author":"","guid":235966,"unread":true,"content":"<article>Apigee helps enterprises integrate large language models (LLMs) into existing API ecosystems securely and scalably, addressing challenges like authentication and authorization not fully covered by the evolving Model Context Protocol (MCP), and offering an open-source MCP server example that demonstrates how to implement enterprise-ready API security for AI agents.</article>","contentLength":366,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Build with Veo 3, now available in the Gemini API","url":"https://developers.googleblog.com/en/veo-3-now-available-gemini-api/","date":1755803580,"author":"","guid":235873,"unread":true,"content":"<article>Veo 3, Google’s latest AI video generation model, is now available in paid preview via the Gemini API and Google AI Studio. Unveiled at Google I/O 2025, Veo 3 can generate both video and synchronized audio, including dialogue, background sounds, and even animal noises. This model delivers realistic visuals, natural lighting, and physics, with accurate lip syncing and sound that matches on-screen action.</article>","contentLength":408,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing Opal: describe, create, and share your AI mini-apps","url":"https://developers.googleblog.com/en/introducing-opal/","date":1755803580,"author":"","guid":235874,"unread":true,"content":"<article>Opal is a new experimental tool from Google Labs that helps you compose prompts into dynamic, multi-step mini-apps using natural language, removing the need for code, allowing users to build and deploy shareable AI apps with powerful features and seamless integration with existing Google tools.</article>","contentLength":295,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Veo 3 Fast and new image-to-video capabilities","url":"https://developers.googleblog.com/en/veo-3-fast-image-to-video-capabilities-now-available-gemini-api/","date":1755803580,"author":"","guid":235875,"unread":true,"content":"<article>Google introduces Veo 3 Fast, an optimized model for speed and price, along with new image-to-video capabilities for both Veo 3 and Veo 3 Fast, enabling developers to efficiently create high-quality video content from text or still images, with varying pricing based on the model and audio inclusion, now available in the Gemini API.</article>","contentLength":333,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"People of AI podcast Season 5 is here: Meet the builders shaping the future","url":"https://developers.googleblog.com/en/people-of-ai-podcast-season-5/","date":1755796656,"author":"","guid":235820,"unread":true,"content":"<article>Co-hosted by Ashley Oldacre and Christina Warren, People of AI podcast's Season 5 will focus on the builders in the space of AI, highlighting the unique journeys, challenges, and triumphs of these innovators.</article>","contentLength":208,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing Gemma 3 270M: The compact model for hyper-efficient AI","url":"https://developers.googleblog.com/en/introducing-gemma-3-270m/","date":1755796656,"author":"","guid":235821,"unread":true,"content":"<article>Google's new Gemma 3 270M is a compact, 270-million parameter model offering energy efficiency, production-ready quantization, and strong instruction-following, making it a powerful solution for task-specific fine-tuning in on-device and research settings.</article>","contentLength":256,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What's new in Gemini Code Assist","url":"https://developers.googleblog.com/en/new-in-gemini-code-assist/","date":1755796656,"author":"","guid":235822,"unread":true,"content":"<article>Gemini Code Assist's Agent Mode, now available in VS Code (Preview) and IntelliJ (Stable), streamlines complex coding tasks by proposing detailed plans for user review and approval. This intelligent, collaborative approach, enhanced with features like inline diffs and persistent chat history, aims to boost developer productivity and efficiency.</article>","contentLength":346,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Unlock Gemini’s reasoning: A step-by-step guide to logprobs on Vertex AI","url":"https://developers.googleblog.com/en/unlock-gemini-reasoning-with-logprobs-on-vertex-ai/","date":1755743659,"author":"","guid":234856,"unread":true,"content":"<article>The `logprobs` feature has been officially introduced in the Gemini API on Vertex AI, provides insight into the model's decision-making by showing probability scores for chosen and alternative tokens. This step-by-step guide will walk you through how to enable and interpret this feature and apply it to powerful use cases such as confident classification, dynamic autocomplete, and quantitative RAG evaluation.</article>","contentLength":411,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stanford’s Marin foundation model: The first fully open model developed using JAX","url":"https://developers.googleblog.com/en/stanfords-marin-foundation-model-first-fully-open-model-developed-using-jax/","date":1755720378,"author":"","guid":234723,"unread":true,"content":"<article>The Marin project aims to expand the definition of 'open' in AI to include the entire scientific process, not just the model itself, by making the complete development journey accessible and reproducible. This effort, powered by the JAX framework and its Levanter tool, allows for deep scrutiny, trust in, and building upon foundation models, fostering a more transparent future for AI research.</article>","contentLength":395,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gemini Embedding: Powering RAG and context engineering","url":"https://developers.googleblog.com/en/gemini-embedding-powering-rag-context-engineering/","date":1755720378,"author":"","guid":234724,"unread":true,"content":"<article>The Gemini Embedding model enhances AI applications, particularly through context engineering, which is being successfully adopted by various organizations across industries to power context-aware systems, leading to significant improvements in performance, accuracy, and efficiency.</article>","contentLength":283,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gemini CLI + VS Code: Native diffing and context-aware workflows","url":"https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/","date":1755713248,"author":"","guid":234674,"unread":true,"content":"<article>The latest Gemini CLI update provides a deep IDE integration within VS Code for intelligent, context-aware suggestions, and native in-editor diffing, allowing developers to review and modify proposed changes directly within the diff view for a more efficient workflow.</article>","contentLength":268,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Introducing LangExtract: A Gemini powered information extraction library","url":"https://developers.googleblog.com/en/introducing-langextract-a-gemini-powered-information-extraction-library/","date":1755702371,"author":"","guid":234600,"unread":true,"content":"<article>LangExtract is a new open-source Python library powered by Gemini models for extracting structured information from unstructured text, offering precise source grounding, reliable structured outputs using controlled generation, optimized long-context extraction, interactive visualization, and flexible LLM backend support.</article>","contentLength":322,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Unleashing new AI capabilities for popular frameworks in Firebase Studio","url":"https://developers.googleblog.com/en/new-ai-capabilities-for-popular-frameworks-in-firebase-studio/","date":1755677357,"author":"","guid":234424,"unread":true,"content":"<article>New AI capabilities for popular frameworks in Firebase Studio include AI-optimized templates, streamlined integration with Firebase backend services, and the ability to fork workspaces for experimentation and collaboration, making AI-assisted app development more intuitive and faster for developers worldwide.</article>","contentLength":310,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Gemini 2.5 Flash-Lite is now stable and generally available","url":"https://developers.googleblog.com/en/gemini-25-flash-lite-is-now-stable-and-generally-available/","date":1755641210,"author":"","guid":233510,"unread":true,"content":"<article>Gemini 2.5 Flash-Lite, previously in preview, is now stable and generally available. This cost-efficient model is ~1.5x faster than 2.0 Flash-Lite and 2.0 Flash, offers high quality, and includes 2.5 family features like a 1 million-token context window and multimodality.</article>","contentLength":272,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A roboticist's journey with JAX: Finding efficiency in optimal control and simulation","url":"https://developers.googleblog.com/en/a-roboticists-journey-with-jax/","date":1755641210,"author":"","guid":233511,"unread":true,"content":"<article>Max's journey introduces LQRax, a JAX-native LQR solver, which exemplifies the growing JAX robotics ecosystem that includes tools like Brax, MJX, and JaxSim, highlighting the benefits of JAX for computational efficiency in optimal control and simulation, and for seamlessly integrating model-based and learning-based approaches.</article>","contentLength":328,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meet Jules’ sharpest critic and most valuable ally","url":"https://developers.googleblog.com/en/meet-jules-sharpest-critic-and-most-valuable-ally/","date":1755623108,"author":"","guid":233421,"unread":true,"content":"<article>Jules' critic functionality addresses potential issues like subtle bugs and missed edge cases in AI-generated code by acting as a peer reviewer within the generation process. This \"critic-augmented generation\" means proposed code changes undergo adversarial review, allowing Jules to improve its output and ultimately deliver higher-quality, pre-reviewed code.</article>","contentLength":360,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Train a GPT2 model with JAX on TPU for free","url":"https://developers.googleblog.com/en/train-gpt2-model-with-jax-on-tpu/","date":1755619560,"author":"","guid":233389,"unread":true,"content":"<article>Build and train a GPT2 model from scratch using JAX on Google TPUs, with a complete Python notebook for free-tier Colab or Kaggle. Learn how to define a hardware mesh, partition model parameters and input data for data parallelism, and optimize the model training process.</article>","contentLength":272,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Conversational image segmentation with Gemini 2.5","url":"https://developers.googleblog.com/en/conversational-image-segmentation-gemini-2-5/","date":1755551093,"author":"","guid":231787,"unread":true,"content":"<article>Gemini's advanced capability for conversational image segmentation allows intuitive interaction with visual data by understanding complex phrases, conditional logic, and abstract concepts, streamlining developer experience and opening doors for new applications in media editing, safety monitoring, and damage assessment.</article>","contentLength":321,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"URL context tool for Gemini API now generally available","url":"https://developers.googleblog.com/en/url-context-tool-for-gemini-api-now-generally-available/","date":1755540444,"author":"","guid":231735,"unread":true,"content":"<article>The Gemini API's URL Context tool is now generally available, allowing developers to ground prompts using web content instead of manual uploads. This release expands support to PDFs and images.</article>","contentLength":193,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["googledev"]}